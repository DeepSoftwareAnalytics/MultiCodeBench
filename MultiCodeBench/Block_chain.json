[
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def save_binary(output_file, state, fill)",
        "start_line": "66",
        "end_line": "72",
        "file_path": "contrib/asmap/asmap-tool.py",
        "docstring": "The function saves a binary representation of the state to an output file.\\nIt converts the state to binary using the provided fill value and attempts to write the binary content to the output file.\\nIf an OSError occurs during the file writing process, it exits the program with an error message indicating the issue with the output file.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "9415670ed66b",
        "ground_truth": "def save_binary(output_file, state, fill):\n    contents = state.to_binary(fill=fill)\n    try:\n        output_file.write(contents)\n        output_file.close()\n    except OSError as err:\n        sys.exit(f\"Output file '{output_file.name}' cannot be written to: {err.strerror}.\")",
        "import_statements": [
            "import argparse",
            "import sys",
            "import ipaddress",
            "import math",
            "import asmap"
        ],
        "reference_api": [
            "sys.exit",
            "output_file.close",
            "state.to_binary",
            "output_file.write"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "state.to_binary",
            "output_file.write",
            "output_file.close"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def save_text(output_file, state, fill, overlapping)",
        "start_line": "74",
        "end_line": "84",
        "file_path": "contrib/asmap/asmap-tool.py",
        "docstring": "# The function saves text data from the state to an output file.\\nIt iterates through entries obtained from the state, converting each prefix to a network format and printing it along with the ASN to the output file.\\nIf an OSError occurs while writing to the file or closing it, the function exits the program with an error message indicating the issue with the output file.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5be785f75570",
        "ground_truth": "def save_text(output_file, state, fill, overlapping):\n    for prefix, asn in state.to_entries(fill=fill, overlapping=overlapping):\n        net = asmap.prefix_to_net(prefix)\n        try:\n            print(f\"{net} AS{asn}\", file=output_file)\n        except OSError as err:\n            sys.exit(f\"Output file '{output_file.name}' cannot be written to: {err.strerror}.\")\n    try:\n        output_file.close()\n    except OSError as err:\n        sys.exit(f\"Output file '{output_file.name}' cannot be written to: {err.strerror}.\")",
        "import_statements": [
            "import argparse",
            "import sys",
            "import ipaddress",
            "import math",
            "import asmap"
        ],
        "reference_api": [
            "print",
            "output_file.close",
            "sys.exit",
            "asmap.prefix_to_net",
            "state.to_entries"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "asmap.prefix_to_net",
                "code": "def prefix_to_net(prefix: list[bool]) -> Union[ipaddress.IPv4Network,ipaddress.IPv6Network]:\n    \"\"\"The reverse operation of net_to_prefix.\"\"\"\n    # Convert to number\n    netrange = sum(b << (127 - i) for i, b in enumerate(prefix))\n    num_bits = len(prefix)\n    assert num_bits <= 128\n\n    # Return IPv4 range if in ::ffff:0:0/96\n    if num_bits >= 96 and (netrange >> 32) == 0xffff:\n        return ipaddress.IPv4Network((netrange & 0xffffffff, num_bits - 96), True)\n\n    # Return IPv6 range otherwise.\n    return ipaddress.IPv6Network((netrange, num_bits), True)"
            }
        ],
        "third_party": [
            "state.to_entries",
            "output_file.close"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def net_to_prefix(net: Union[ipaddress.IPv4Network,ipaddress.IPv6Network]) -> list[bool]",
        "start_line": "18",
        "end_line": "34",
        "file_path": "contrib/asmap/asmap.py",
        "docstring": "# The function converts an IPv4 or IPv6 network into a prefix represented as a list of bits.\\nIt first calculates the number of bits and the network range from the network address.\\nFor IPv4 networks, it remaps them to the IPv4-mapped IPv6 range by adjusting the number of bits and the network range.\\nIt then strips unused bottom bits and returns the prefix as a list of boolean values representing each bit in the network range.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "447645766fc8",
        "ground_truth": "def net_to_prefix(net: Union[ipaddress.IPv4Network,ipaddress.IPv6Network]) -> list[bool]:\n    \"\"\"\n    Convert an IPv4 or IPv6 network to a prefix represented as a list of bits.\n     IPv4 ranges are remapped to their IPv4-mapped IPv6 range (::ffff:0:0/96).\n    \"\"\"\n    num_bits = net.prefixlen\n    netrange = int.from_bytes(net.network_address.packed, 'big')\n     # Map an IPv4 prefix into IPv6 space.\n    if isinstance(net, ipaddress.IPv4Network):\n        num_bits += 96\n        netrange += 0xffff00000000\n     # Strip unused bottom bits.\n    assert (netrange & ((1 << (128 - num_bits)) - 1)) == 0\n    return [((netrange >> (127 - i)) & 1) != 0 for i in range(num_bits)]",
        "import_statements": [
            "import copy",
            "import ipaddress",
            "import random",
            "import unittest",
            "from collections.abc import Callable, Iterable",
            "from enum import Enum",
            "from functools import total_ordering",
            "from typing import Optional, Union, overload"
        ],
        "reference_api": [
            "int.from_bytes",
            "range",
            "isinstance"
        ],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def prefix_to_net(prefix: list[bool]) -> Union[ipaddress.IPv4Network,ipaddress.IPv6Network]",
        "start_line": "36",
        "end_line": "48",
        "file_path": "contrib/asmap/asmap.py",
        "docstring": "# The function converts a prefix represented as a list of bits back into an IPv4 or IPv6 network.\\nIt first converts the list of bits into a numeric network range and calculates the number of bits.\\nIf the number of bits is 96 or more and the network range matches the IPv4-mapped IPv6 range, it returns the corresponding IPv4 network.\\nOtherwise, it returns the IPv6 network based on the numeric network range and number of bits.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "61dddcb6ffa1",
        "ground_truth": "def prefix_to_net(prefix: list[bool]) -> Union[ipaddress.IPv4Network,ipaddress.IPv6Network]:\n    \"\"\"The reverse operation of net_to_prefix.\"\"\"\n    # Convert to number\n    netrange = sum(b << (127 - i) for i, b in enumerate(prefix))\n    num_bits = len(prefix)\n    assert num_bits <= 128\n     # Return IPv4 range if in ::ffff:0:0/96\n    if num_bits >= 96 and (netrange >> 32) == 0xffff:\n        return ipaddress.IPv4Network((netrange & 0xffffffff, num_bits - 96), True)\n     # Return IPv6 range otherwise.\n    return ipaddress.IPv6Network((netrange, num_bits), True)",
        "import_statements": [
            "import copy",
            "import ipaddress",
            "import random",
            "import unittest",
            "from collections.abc import Callable, Iterable",
            "from enum import Enum",
            "from functools import total_ordering",
            "from typing import Optional, Union, overload"
        ],
        "reference_api": [
            "len",
            "sum",
            "ipaddress.IPv4Network",
            "ipaddress.IPv6Network",
            "enumerate"
        ],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def _to_entries_flat(self, fill: bool = False) -> list[ASNEntry]",
        "start_line": "357",
        "end_line": "377",
        "file_path": "contrib/asmap/asmap.py",
        "docstring": "The function \\_to\\_entries\\_flat(self, fill: bool = False) -> list[ASNEntry]: converts an ASMap object into a list of non-overlapping (prefix, asn) tuples.\\nIt uses a recursive helper function called recurse(node: list) -> list[ASNEntry]: to traverse a trie structure.\\nThe recursion differentiates between nodes with one child and those with two children.\\nFor nodes with two children, it appends False and True to the prefix list, recursively processing both children.\\nIf the fill parameter is True, it merges adjacent entries with the same ASN.\\nThe result is a flattened list of prefixes with their corresponding ASNs.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a29f870a85b7",
        "ground_truth": "def _to_entries_flat(self, fill: bool = False) -> list[ASNEntry]:\n    \"\"\"Convert an ASMap object to a list of non-overlapping (prefix, asn) objects.\"\"\"\n    prefix : list[bool] = []\n    def recurse(node: list) -> list[ASNEntry]:\n        ret = []\n        if len(node) == 1:\n            if node[0] > 0:\n                ret = [(list(prefix), node[0])]\n        elif len(node) == 2:\n            prefix.append(False)\n            ret = recurse(node[0])\n            prefix[-1] = True\n            ret += recurse(node[1])\n            prefix.pop()\n            if fill and len(ret) > 1:\n                asns = set(x[1] for x in ret)\n                if len(asns) == 1:\n                    ret = [(list(prefix), list(asns)[0])]\n        return ret\n    return recurse(self._trie)",
        "import_statements": [
            "import copy",
            "import ipaddress",
            "import random",
            "import unittest",
            "from collections.abc import Callable, Iterable",
            "from enum import Enum",
            "from functools import total_ordering",
            "from typing import Optional, Union, overload"
        ],
        "reference_api": [
            "list",
            "prefix.pop",
            "len",
            "set",
            "prefix.append",
            "recurse"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "prefix.append",
            "recurse",
            "recurse",
            "prefix.pop"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def __copy__(self) -> \"ASMap\"",
        "start_line": "676",
        "end_line": "681",
        "file_path": "contrib/asmap/asmap.py",
        "docstring": "The function \\_\\_copy\\_\\_(self) -> \"ASMap\": creates and returns a new instance of the ASMap class that is a deep copy of the current instance.\\nIt ensures that the state of the new ASMap object is completely independent of the original by performing a deep copy of the trie structure.\\nThis allows the new ASMap instance to operate without sharing any state with the original instance.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "8e0890611078",
        "ground_truth": "def __copy__(self) -> \"ASMap\":\n    \"\"\"Construct a copy of this ASMap object. Its state will not be shared.\"\"\"\n    ret = ASMap()\n    #pylint: disable=protected-access\n    ret._set_trie(copy.deepcopy(self._trie))\n    return ret",
        "import_statements": [
            "import copy",
            "import ipaddress",
            "import random",
            "import unittest",
            "from collections.abc import Callable, Iterable",
            "from enum import Enum",
            "from functools import total_ordering",
            "from typing import Optional, Union, overload"
        ],
        "reference_api": [
            "ASMap",
            "ret._set_trie",
            "copy.deepcopy"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "ASMap",
            "ret._set_trie"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def get_filenames_to_examine(base_directory)",
        "start_line": "66",
        "end_line": "71",
        "file_path": "contrib/devtools/copyright_header.py",
        "docstring": "The function get\\_filenames\\_to\\_examine(base\\_directory): generates and returns a sorted list of absolute paths for project files in the specified base directory.\\nIt first retrieves the root directory of the git repository, then obtains a list of filenames in the base directory using git.\\nThe function filters these filenames based on certain include/exclude criteria and constructs their absolute paths before returning the sorted list.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a653bb344809",
        "ground_truth": "def get_filenames_to_examine(base_directory):\n    \"Returns an array of absolute paths to any project files in the base_directory that pass the include/exclude filters\"\n    root = call_git_toplevel()\n    filenames = call_git_ls(base_directory)\n    return sorted([os.path.join(root, filename) for filename in filenames if\n                   applies_to_file(filename)])",
        "import_statements": [
            "import re",
            "import fnmatch",
            "import sys",
            "import subprocess",
            "import datetime",
            "import os"
        ],
        "reference_api": [
            "call_git_ls",
            "join",
            "sorted",
            "call_git_toplevel",
            "applies_to_file"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "call_git_toplevel",
                "code": "def call_git_toplevel():\n    \"Returns the absolute path to the project root\"\n    return subprocess.check_output(GIT_TOPLEVEL_CMD).strip().decode(\"utf-8\")"
            },
            {
                "name": "call_git_ls",
                "code": "def call_git_ls(base_directory):\n    out = subprocess.check_output([*GIT_LS_CMD, base_directory])\n    return [f for f in out.decode(\"utf-8\").split('\\n') if f != '']"
            },
            {
                "name": "applies_to_file",
                "code": "def applies_to_file(filename):\n    for excluded_dir in EXCLUDE_DIRS:\n        if filename.startswith(excluded_dir):\n            return False\n    return ((EXCLUDE_COMPILED.match(filename) is None) and\n            (INCLUDE_COMPILED.match(filename) is not None))"
            }
        ],
        "third_party": [
            "join"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def create_updated_copyright_line(line, last_git_change_year)",
        "start_line": "360",
        "end_line": "375",
        "file_path": "contrib/devtools/copyright_header.py",
        "docstring": "The function create\\_updated\\_copyright\\_line(line, last\\_git\\_change\\_year): updates the copyright year range in a given line of text.\\nIt splits the line to separate the portion before and after the copyright notice.\\nThe function extracts the year range, parses the start and end years, and checks if the end year is earlier than the last git change year.\\nIf the end year is earlier, it updates the end year to the last git change year and reconstructs the line with the new year range.\\nIf the end year is not earlier, it returns the original line.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c541eb79aa88",
        "ground_truth": "def create_updated_copyright_line(line, last_git_change_year):\n    copyright_splitter = 'Copyright (c) '\n    copyright_split = line.split(copyright_splitter)\n    # Preserve characters on line that are ahead of the start of the copyright\n    # notice - they are part of the comment block and vary from file-to-file.\n    before_copyright = copyright_split[0]\n    after_copyright = copyright_split[1]\n     space_split = after_copyright.split(' ')\n    year_range = space_split[0]\n    start_year, end_year = parse_year_range(year_range)\n    if end_year >= last_git_change_year:\n        return line\n    return (before_copyright + copyright_splitter +\n            year_range_to_str(start_year, last_git_change_year) + ' ' +\n            ' '.join(space_split[1:]))",
        "import_statements": [
            "import re",
            "import fnmatch",
            "import sys",
            "import subprocess",
            "import datetime",
            "import os"
        ],
        "reference_api": [
            "join",
            "parse_year_range",
            "year_range_to_str",
            "line.split",
            "after_copyright.split"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parse_year_range",
                "code": "def parse_year_range(year_range):\n    year_split = year_range.split('-')\n    start_year = year_split[0]\n    if len(year_split) == 1:\n        return start_year, start_year\n    return start_year, year_split[1]"
            },
            {
                "name": "year_range_to_str",
                "code": "def year_range_to_str(start_year, end_year):\n    if start_year == end_year:\n        return start_year\n    return \"%s-%s\" % (start_year, end_year)"
            }
        ],
        "third_party": [
            "line.split",
            "after_copyright.split",
            "join"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def memory_usage(period, bufsize, when)",
        "start_line": "217",
        "end_line": "227",
        "file_path": "contrib/devtools/headerssync-params.py",
        "docstring": "The function memory\\_usage(period, bufsize, when): calculates the memory requirements for a given configuration based on period and buffer size.\\nIt computes the per-peer memory usage for a timewarp chain and the main chain.\\nFor the timewarp chain, it determines memory usage by dividing the maximum headers by the period.\\nFor the main chain, it calculates memory usage by dividing the minimum chain work headers by the period and adding the product of buffer size and compact header size.\\nThe function returns the maximum memory usage among the two calculated values, as well as the individual memory usages for the main chain and timewarp chain.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "b75c9f635aa8",
        "ground_truth": "def memory_usage(period, bufsize, when):\n    \"\"\"How much memory (max,mainchain,timewarp) does the (period,bufsize) configuration need?\"\"\"\n     # Per-peer memory usage for a timewarp chain that never meets minchainwork\n    mem_timewarp = find_max_headers(when) // period\n    # Per-peer memory usage for being fed the main chain\n    mem_mainchain = (MINCHAINWORK_HEADERS // period) + bufsize * COMPACT_HEADER_SIZE\n    # Maximum per-peer memory usage\n    max_mem = max(mem_timewarp, mem_mainchain)\n     return max_mem, mem_mainchain, mem_timewarp",
        "import_statements": [
            "from math import log, exp, sqrt",
            "from datetime import datetime, timedelta",
            "import random"
        ],
        "reference_api": [
            "find_max_headers",
            "max"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "find_max_headers",
                "code": "def find_max_headers(when):\n    \"\"\"Compute the maximum number of headers a valid Bitcoin chain can have at given time.\"\"\"\n    # When exploiting the timewarp attack, this can be up to 6 per second since genesis.\n    return 6 * ((when - GENESIS_TIME) // timedelta(seconds=1))"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def check_ELF_control_flow(binary) -> bool",
        "start_line": "108",
        "end_line": "117",
        "file_path": "contrib/devtools/security-check.py",
        "docstring": "The function check\\_ELF\\_control\\_flow(binary) -> bool: checks if an ELF binary has control flow instrumentation.\\nIt retrieves the address of the main function in the binary and then obtains 4 bytes of content from that address.\\nIf the retrieved content matches the byte sequence [243, 15, 30, 250], which corresponds to the endbr64 instruction, the function returns True, indicating the presence of control flow instrumentation.\\nIf the content does not match, it returns False.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cf97715245b8",
        "ground_truth": "def check_ELF_control_flow(binary) -> bool:\n    '''\n    Check for control flow instrumentation\n    '''\n    main = binary.get_function_address('main')\n    content = binary.get_content_from_virtual_address(main, 4, lief.Binary.VA_TYPES.AUTO)\n     if content.tolist() == [243, 15, 30, 250]: # endbr64\n        return True\n    return False",
        "import_statements": [
            "import sys",
            "import lief"
        ],
        "reference_api": [
            "binary.get_function_address",
            "binary.get_content_from_virtual_address",
            "content.tolist"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "binary.get_function_address",
            "binary.get_content_from_virtual_address",
            "content.tolist"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def process_nodes(g, f, structname)",
        "start_line": "137",
        "end_line": "153",
        "file_path": "contrib/seeds/generate-seeds.py",
        "docstring": "The function process\\_nodes(g, f, structname): generates a static array of uint8\\_t values and writes it to a file.\\nIt begins by writing the array declaration with the given struct name to the output file.\\nFor each line in the input file, it removes comments and strips whitespace.\\nIf the line is not empty, it parses the specification and serializes it using bip155.\\nThe serialized data is converted to a comma-separated string of hexadecimal values and written to the output file.\\nThe function continues this process for all lines and concludes by closing the array declaration in the output file.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d0f8d4a1cf4e",
        "ground_truth": "def process_nodes(g, f, structname):\n    g.write('static const uint8_t %s[] = {\\n' % structname)\n    for line in f:\n        comment = line.find('#')\n        if comment != -1:\n            line = line[0:comment]\n        line = line.strip()\n        if not line:\n            continue\n         spec = parse_spec(line)\n        if spec is None:  # ignore this entry (e.g. no longer supported addresses like TORV2)\n            continue\n        blob = bip155_serialize(spec)\n        hoststr = ','.join(('0x%02x' % b) for b in blob)\n        g.write(f'    {hoststr},\\n')\n    g.write('};\\n')",
        "import_statements": [
            "from base64 import b32decode",
            "from enum import Enum",
            "import sys",
            "import os",
            "import re"
        ],
        "reference_api": [
            "join",
            "line.find",
            "parse_spec",
            "line.strip",
            "g.write",
            "bip155_serialize"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parse_spec",
                "code": "def parse_spec(s):\n    '''Convert endpoint string to BIP155 (networkID, addr, port) tuple.'''\n    match = re.match(r'\\[([0-9a-fA-F:]+)\\](?::([0-9]+))?$', s)\n    if match: # ipv6\n        host = match.group(1)\n        port = match.group(2)\n    elif s.count(':') > 1: # ipv6, no port\n        host = s\n        port = ''\n    else:\n        (host,_,port) = s.partition(':')\n\n    if not port:\n        port = 0\n    else:\n        port = int(port)\n\n    host = name_to_bip155(host)\n\n    if host[0] == BIP155Network.TORV2:\n        return None  # TORV2 is no longer supported, so we ignore it\n    else:\n        return host + (port, )"
            },
            {
                "name": "bip155_serialize",
                "code": "def bip155_serialize(spec):\n    '''\n    Serialize (networkID, addr, port) tuple to BIP155 binary format.\n    '''\n    r = b\"\"\n    r += spec[0].value.to_bytes(1, \"little\")\n    r += ser_compact_size(len(spec[1]))\n    r += spec[1]\n    r += spec[2].to_bytes(2, \"big\")\n    return r"
            }
        ],
        "third_party": [
            "g.write",
            "line.find",
            "line.strip",
            "join",
            "g.write",
            "g.write"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def print_image(img, threshold=128)",
        "start_line": "50",
        "end_line": "69",
        "file_path": "contrib/signet/getcoins.py",
        "docstring": "The function print\\_image(img, threshold=128): prints a black-and-white image to the terminal using braille unicode characters.\\nIt calculates the number of blocks required to represent the image based on its dimensions.\\nFor each block, it initializes a character with the base braille unicode value and iterates over the pixels within the block.\\nIf a pixel's intensity is below the specified threshold, it sets the corresponding bit in the braille character.\\nAfter processing all pixels in a block, it appends the braille character to a line, which is printed to the terminal.\\nThis process repeats for all blocks, resulting in a text-based representation of the image.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4d1504626673",
        "ground_truth": "def print_image(img, threshold=128):\n    '''Print black-and-white image to terminal in braille unicode characters.'''\n    x_blocks = (img.size[0] + BW - 1) // BW\n    y_blocks = (img.size[1] + BH - 1) // BH\n     for yb in range(y_blocks):\n        line = []\n        for xb in range(x_blocks):\n            ch = BASE\n            for y in range(BH):\n                for x in range(BW):\n                    try:\n                        val = img.getpixel((xb * BW + x, yb * BH + y))\n                    except IndexError:\n                        pass\n                    else:\n                        if val[0] < threshold:\n                            ch |= BIT_PER_PIXEL[y][x]\n            line.append(chr(ch))\n        print(''.join(line))",
        "import_statements": [
            "import argparse",
            "import io",
            "import requests",
            "import subprocess",
            "import sys",
            "import xml.etree.ElementTree"
        ],
        "reference_api": [
            "join",
            "line.append",
            "print",
            "chr",
            "img.getpixel",
            "range"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "img.getpixel",
                "code": "def getpixel(self, pos):\n        return self._grid[pos[1]][pos[0]]"
            }
        ],
        "third_party": [
            "line.append",
            "join"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def bitcoin_cli(rpc_command_and_params)",
        "start_line": "87",
        "end_line": "95",
        "file_path": "contrib/signet/getcoins.py",
        "docstring": "The function bitcoin\\_cli(rpc\\_command\\_and\\_params): executes a Bitcoin CLI command with the specified parameters.\\nIt constructs the command by combining the base command, additional arguments, and the provided RPC command and parameters.\\nThe function attempts to run the command and return its output as a decoded string.\\nIf the command binary is not found, it raises a SystemExit with an appropriate error message.\\nIf the command execution fails, it raises a SystemExit with the full command line and an error message.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "69276e422dbd",
        "ground_truth": "def bitcoin_cli(rpc_command_and_params):\n    argv = [args.cmd] + args.bitcoin_cli_args + rpc_command_and_params\n    try:\n        return subprocess.check_output(argv).strip().decode()\n    except FileNotFoundError:\n        raise SystemExit(f\"The binary {args.cmd} could not be found\")\n    except subprocess.CalledProcessError:\n        cmdline = ' '.join(argv)\n        raise SystemExit(f\"-----\\nError while calling {cmdline} (see output above).\")",
        "import_statements": [
            "import argparse",
            "import io",
            "import requests",
            "import subprocess",
            "import sys",
            "import xml.etree.ElementTree"
        ],
        "reference_api": [
            "join",
            "decode",
            "SystemExit",
            "strip",
            "subprocess.check_output"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "decode",
            "strip",
            "join"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def set_up_logger(is_verbose: bool = True) -> logging.Logger",
        "start_line": "68",
        "end_line": "77",
        "file_path": "contrib/verify-binaries/verify.py",
        "docstring": "The function set\\_up\\_logger(is\\_verbose: bool = True) -> logging.Logger: configures and returns a logger that writes to stderr.\\nIt creates a logger with the module's name and sets its level to INFO if verbose, otherwise to WARNING.\\nA StreamHandler is added to the logger to output logs to stderr, with its level set to DEBUG.\\nA log message formatter is defined and applied to the handler.\\nFinally, the handler is added to the logger, and the configured logger is returned.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "6ccbcb5fea04",
        "ground_truth": "def set_up_logger(is_verbose: bool = True) -> logging.Logger:\n    \"\"\"Set up a logger that writes to stderr.\"\"\"\n    log = logging.getLogger(__name__)\n    log.setLevel(logging.INFO if is_verbose else logging.WARNING)\n    console = logging.StreamHandler(sys.stderr)  # log to stderr\n    console.setLevel(logging.DEBUG)\n    formatter = logging.Formatter('[%(levelname)s] %(message)s')\n    console.setFormatter(formatter)\n    log.addHandler(console)\n    return log",
        "import_statements": [
            "import argparse",
            "import difflib",
            "import json",
            "import logging",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import shutil",
            "import tempfile",
            "import textwrap",
            "import urllib.request",
            "import urllib.error",
            "import enum",
            "from hashlib import sha256",
            "from pathlib import PurePath, Path"
        ],
        "reference_api": [
            "logging.getLogger",
            "logging.StreamHandler",
            "log.addHandler",
            "console.setFormatter",
            "console.setLevel",
            "log.setLevel",
            "logging.Formatter"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "log.setLevel",
            "console.setLevel",
            "console.setFormatter",
            "log.addHandler"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def download_lines_with_urllib(url) -> tuple[bool, list[str]]",
        "start_line": "119",
        "end_line": "128",
        "file_path": "contrib/verify-binaries/verify.py",
        "docstring": "The function download\\_lines\\_with\\_urllib(url) -> tuple[bool, list[str]]: retrieves the content of a file from a given URL using HTTP.\\nIt attempts to open the URL and read its lines, returning a tuple with True and a list of decoded, stripped lines if successful.\\nIf an HTTPError or any other exception occurs, it logs a warning message and returns a tuple with False and an empty list.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "25e1820c90da",
        "ground_truth": "def download_lines_with_urllib(url) -> tuple[bool, list[str]]:\n    \"\"\"Get (success, text lines of a file) over HTTP.\"\"\"\n    try:\n        return (True, [\n            line.strip().decode() for line in urllib.request.urlopen(url).readlines()])\n    except urllib.error.HTTPError as e:\n        log.warning(f\"HTTP request to {url} failed (HTTPError): {e}\")\n    except Exception as e:\n        log.warning(f\"HTTP request to {url} failed ({e})\")\n    return (False, [])",
        "import_statements": [
            "import argparse",
            "import difflib",
            "import json",
            "import logging",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import shutil",
            "import tempfile",
            "import textwrap",
            "import urllib.request",
            "import urllib.error",
            "import enum",
            "from hashlib import sha256",
            "from pathlib import PurePath, Path"
        ],
        "reference_api": [
            "urlopen",
            "decode",
            "readlines",
            "line.strip",
            "log.warning"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "decode",
            "line.strip",
            "readlines",
            "urlopen",
            "log.warning",
            "log.warning"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "def verify_binary_hashes(hashes_to_verify: list[list[str]]) -> tuple[ReturnCode, dict[str, str]]",
        "start_line": "433",
        "end_line": "452",
        "file_path": "contrib/verify-binaries/verify.py",
        "docstring": "The function verify\\_binary\\_hashes(hashes\\_to\\_verify: list[list[str]]) -> tuple[ReturnCode, dict[str, str]]: verifies the integrity of binary files by comparing their SHA-256 hashes against expected values.\\nIt initializes lists for offending files and a dictionary to map filenames to their calculated hashes.\\nFor each file, it reads the file's content, computes its SHA-256 hash, and compares it with the expected hash.\\nIf the hashes do not match, the file is added to the offending files list; otherwise, the file and its hash are added to the dictionary.\\nIf there are any offending files, it logs a critical error and returns an integrity failure code with the dictionary.\\nIf all hashes match, it returns a success code with the dictionary.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "92678ae2c770",
        "ground_truth": "def verify_binary_hashes(hashes_to_verify: list[list[str]]) -> tuple[ReturnCode, dict[str, str]]:\n    offending_files = []\n    files_to_hashes = {}\n     for hash_expected, binary_filename in hashes_to_verify:\n        with open(binary_filename, 'rb') as binary_file:\n            hash_calculated = sha256(binary_file.read()).hexdigest()\n        if hash_calculated != hash_expected:\n            offending_files.append(binary_filename)\n        else:\n            files_to_hashes[binary_filename] = hash_calculated\n     if offending_files:\n        joined_files = '\\n'.join(offending_files)\n        log.critical(\n            \"Hashes don't match.\\n\"\n            f\"Offending files:\\n{joined_files}\")\n        return (ReturnCode.INTEGRITY_FAILURE, files_to_hashes)\n     return (ReturnCode.SUCCESS, files_to_hashes)",
        "import_statements": [
            "import argparse",
            "import difflib",
            "import json",
            "import logging",
            "import os",
            "import subprocess",
            "import re",
            "import sys",
            "import shutil",
            "import tempfile",
            "import textwrap",
            "import urllib.request",
            "import urllib.error",
            "import enum",
            "from hashlib import sha256",
            "from pathlib import PurePath, Path"
        ],
        "reference_api": [
            "sha256",
            "join",
            "hexdigest",
            "offending_files.append",
            "binary_file.read",
            "log.critical",
            "open"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "hexdigest",
            "sha256",
            "binary_file.read",
            "offending_files.append",
            "join",
            "log.critical"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool ArgsManager::ReadSettingsFile(std::vector<std::string>* errors)",
        "start_line": "400",
        "end_line": "421",
        "file_path": "src/common/args.cpp",
        "docstring": "The function ArgsManager::ReadSettingsFile(std::vector<std::string>* errors) reads and processes a settings file for the ArgsManager class.\\nIt first determines the path to the settings file and returns true if the settings file is disabled.\\nIt locks the arguments, clears existing read-write settings, and attempts to read the settings file into m_settings.rw_settings while collecting any read errors.\\nIf reading fails, it saves the errors and returns false.\\nFor each setting read, it splits the key into section and argument name, and logs a message if the argument name is unknown.\\nIf successful, it returns true.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "81d8527e4187",
        "ground_truth": "bool ArgsManager::ReadSettingsFile(std::vector<std::string>* errors)\n{\n    fs::path path;\n    if (!GetSettingsPath(&path, /* temp= */ false)) {\n        return true; // Do nothing if settings file disabled.\n    }\n     LOCK(cs_args);\n    m_settings.rw_settings.clear();\n    std::vector<std::string> read_errors;\n    if (!common::ReadSettings(path, m_settings.rw_settings, read_errors)) {\n        SaveErrors(read_errors, errors);\n        return false;\n    }\n    for (const auto& setting : m_settings.rw_settings) {\n        KeyInfo key = InterpretKey(setting.first); // Split setting key into section and argname\n        if (!GetArgFlags('-' + key.name)) {\n            LogPrintf(\"Ignoring unknown rw_settings value %s\\n\", setting.first);\n        }\n    }\n    return true;\n}",
        "import_statements": [
            "#include <common/args.h>\n",
            "#include <chainparamsbase.h>\n",
            "#include <common/settings.h>\n",
            "#include <logging.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/chaintype.h>\n",
            "#include <util/check.h>\n",
            "#include <util/fs.h>\n",
            "#include <util/fs_helpers.h>\n",
            "#include <util/strencodings.h>\n",
            "#include <algorithm>\n",
            "#include <cassert>\n",
            "#include <cstdint>\n",
            "#include <cstdlib>\n",
            "#include <cstring>\n",
            "#include <map>\n",
            "#include <optional>\n",
            "#include <stdexcept>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <variant>\n"
        ],
        "reference_api": [
            "InterpretKey",
            "LOCK",
            "SaveErrors",
            "GetArgFlags",
            "GetSettingsPath",
            "m_settings.rw_settings.clear",
            "LogPrintf",
            "common::ReadSettings"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "InterpretKey",
                "code": "KeyInfo InterpretKey(std::string key)\n{\n    KeyInfo result;\n    // Split section name from key name for keys like \"testnet.foo\" or \"regtest.bar\"\n    size_t option_index = key.find('.');\n    if (option_index != std::string::npos) {\n        result.section = key.substr(0, option_index);\n        key.erase(0, option_index + 1);\n    }\n    if (key.substr(0, 2) == \"no\") {\n        key.erase(0, 2);\n        result.negated = true;\n    }\n    result.name = key;\n    return result;\n}"
            },
            {
                "name": "SaveErrors",
                "code": "static void SaveErrors(const std::vector<std::string> errors, std::vector<std::string>* error_out)\n{\n    for (const auto& error : errors) {\n        if (error_out) {\n            error_out->emplace_back(error);\n        } else {\n            LogPrintf(\"%s\\n\", error);\n        }\n    }\n}"
            },
            {
                "name": "GetArgFlags",
                "code": "std::optional<unsigned int> ArgsManager::GetArgFlags(const std::string& name) const\n{\n    LOCK(cs_args);\n    for (const auto& arg_map : m_available_args) {\n        const auto search = arg_map.second.find(name);\n        if (search != arg_map.second.end()) {\n            return search->second.m_flags;\n        }\n    }\n    return std::nullopt;\n}"
            },
            {
                "name": "GetSettingsPath",
                "code": "bool ArgsManager::GetSettingsPath(fs::path* filepath, bool temp, bool backup) const\n{\n    fs::path settings = GetPathArg(\"-settings\", BITCOIN_SETTINGS_FILENAME);\n    if (settings.empty()) {\n        return false;\n    }\n    if (backup) {\n        settings += \".bak\";\n    }\n    if (filepath) {\n        *filepath = fsbridge::AbsPathJoin(GetDataDirNet(), temp ? settings + \".tmp\" : settings);\n    }\n    return true;\n}"
            }
        ],
        "third_party": [
            "LOCK",
            "m_settings.rw_settings.clear",
            "LogPrintf",
            "common::ReadSettings"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool ArgsManager::WriteSettingsFile(std::vector<std::string>* errors, bool backup) const",
        "start_line": "423",
        "end_line": "441",
        "file_path": "src/common/args.cpp",
        "docstring": "The function ArgsManager::WriteSettingsFile(std::vector<std::string>* errors, bool backup) const writes the current settings to a file, optionally creating a backup.\\nIt first determines the paths for the main settings file and a temporary file.\\nIf the paths cannot be determined, it throws a logic error indicating that dynamic settings are disabled.\\nThe function locks the arguments, then attempts to write the settings to the temporary file, collecting any write errors.\\nIf writing fails, it saves the errors and returns false.\\nIf writing succeeds, it renames the temporary file to the main settings file.\\nIf renaming fails, it saves the error and returns false.\\nIf both writing and renaming succeed, it returns true.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cf79454dbb56",
        "ground_truth": "bool ArgsManager::WriteSettingsFile(std::vector<std::string>* errors, bool backup) const\n{\n    fs::path path, path_tmp;\n    if (!GetSettingsPath(&path, /*temp=*/false, backup) || !GetSettingsPath(&path_tmp, /*temp=*/true, backup)) {\n        throw std::logic_error(\"Attempt to write settings file when dynamic settings are disabled.\");\n    }\n     LOCK(cs_args);\n    std::vector<std::string> write_errors;\n    if (!common::WriteSettings(path_tmp, m_settings.rw_settings, write_errors)) {\n        SaveErrors(write_errors, errors);\n        return false;\n    }\n    if (!RenameOver(path_tmp, path)) {\n        SaveErrors({strprintf(\"Failed renaming settings file %s to %s\\n\", fs::PathToString(path_tmp), fs::PathToString(path))}, errors);\n        return false;\n    }\n    return true;\n}",
        "import_statements": [
            "#include <common/args.h>\n",
            "#include <chainparamsbase.h>\n",
            "#include <common/settings.h>\n",
            "#include <logging.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/chaintype.h>\n",
            "#include <util/check.h>\n",
            "#include <util/fs.h>\n",
            "#include <util/fs_helpers.h>\n",
            "#include <util/strencodings.h>\n",
            "#include <algorithm>\n",
            "#include <cassert>\n",
            "#include <cstdint>\n",
            "#include <cstdlib>\n",
            "#include <cstring>\n",
            "#include <map>\n",
            "#include <optional>\n",
            "#include <stdexcept>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <variant>\n"
        ],
        "reference_api": [
            "fs::PathToString",
            "LOCK",
            "SaveErrors",
            "GetSettingsPath",
            "common::WriteSettings",
            "strprintf",
            "RenameOver",
            "std::logic_error"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "SaveErrors",
                "code": "static void SaveErrors(const std::vector<std::string> errors, std::vector<std::string>* error_out)\n{\n    for (const auto& error : errors) {\n        if (error_out) {\n            error_out->emplace_back(error);\n        } else {\n            LogPrintf(\"%s\\n\", error);\n        }\n    }\n}"
            },
            {
                "name": "GetSettingsPath",
                "code": "bool ArgsManager::GetSettingsPath(fs::path* filepath, bool temp, bool backup) const\n{\n    fs::path settings = GetPathArg(\"-settings\", BITCOIN_SETTINGS_FILENAME);\n    if (settings.empty()) {\n        return false;\n    }\n    if (backup) {\n        settings += \".bak\";\n    }\n    if (filepath) {\n        *filepath = fsbridge::AbsPathJoin(GetDataDirNet(), temp ? settings + \".tmp\" : settings);\n    }\n    return true;\n}"
            }
        ],
        "third_party": [
            "fs::PathToString",
            "LOCK",
            "common::WriteSettings",
            "strprintf",
            "RenameOver"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void ArgsManager::LogArgs() const",
        "start_line": "828",
        "end_line": "838",
        "file_path": "src/common/args.cpp",
        "docstring": "The function ArgsManager::LogArgs() const logs the current configuration and settings.\\nIt locks the arguments and iterates over read-only configuration settings, logging each one with a \"Config file arg:\" prefix.\\nNext, it iterates over read-write settings, logging each one with a \"Setting file arg:\" prefix and its corresponding value.\\nFinally, it logs command-line options with a \"Command-line arg:\" prefix.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "66c3d0ff61f2",
        "ground_truth": "void ArgsManager::LogArgs() const\n{\n    LOCK(cs_args);\n    for (const auto& section : m_settings.ro_config) {\n        logArgsPrefix(\"Config file arg:\", section.first, section.second);\n    }\n    for (const auto& setting : m_settings.rw_settings) {\n        LogPrintf(\"Setting file arg: %s = %s\\n\", setting.first, setting.second.write());\n    }\n    logArgsPrefix(\"Command-line arg:\", \"\", m_settings.command_line_options);\n}",
        "import_statements": [
            "#include <common/args.h>\n",
            "#include <chainparamsbase.h>\n",
            "#include <common/settings.h>\n",
            "#include <logging.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/chaintype.h>\n",
            "#include <util/check.h>\n",
            "#include <util/fs.h>\n",
            "#include <util/fs_helpers.h>\n",
            "#include <util/strencodings.h>\n",
            "#include <algorithm>\n",
            "#include <cassert>\n",
            "#include <cstdint>\n",
            "#include <cstdlib>\n",
            "#include <cstring>\n",
            "#include <map>\n",
            "#include <optional>\n",
            "#include <stdexcept>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <variant>\n"
        ],
        "reference_api": [
            "LogPrintf",
            "LOCK",
            "logArgsPrefix",
            "setting.second.write"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "logArgsPrefix",
                "code": "void ArgsManager::logArgsPrefix(\n    const std::string& prefix,\n    const std::string& section,\n    const std::map<std::string, std::vector<common::SettingsValue>>& args) const\n{\n    std::string section_str = section.empty() ? \"\" : \"[\" + section + \"] \";\n    for (const auto& arg : args) {\n        for (const auto& value : arg.second) {\n            std::optional<unsigned int> flags = GetArgFlags('-' + arg.first);\n            if (flags) {\n                std::string value_str = (*flags & SENSITIVE) ? \"****\" : value.write();\n                LogPrintf(\"%s %s%s=%s\\n\", prefix, section_str, arg.first, value_str);\n            }\n        }\n    }\n}"
            }
        ],
        "third_party": [
            "LogPrintf",
            "LOCK",
            "setting.second.write"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void CBloomFilter::insert(Span<const unsigned char> vKey)",
        "start_line": "49",
        "end_line": "59",
        "file_path": "src/common/bloom.cpp",
        "docstring": "The function CBloomFilter::insert(Span<const unsigned char> vKey) adds a key to the bloom filter.\\nIt first checks if the filter data is empty to avoid a divide-by-zero error.\\nFor each hash function, it calculates an index by hashing the key with the current hash function.\\nIt then sets the corresponding bit in the filter data based on the calculated index.\\nThis process repeats for all configured hash functions, ensuring the key is added to the bloom filter.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "891f991c8c71",
        "ground_truth": "void CBloomFilter::insert(Span<const unsigned char> vKey)\n{\n    if (vData.empty()) // Avoid divide-by-zero (CVE-2013-5700)\n        return;\n    for (unsigned int i = 0; i < nHashFuncs; i++)\n    {\n        unsigned int nIndex = Hash(i, vKey);\n        // Sets bit nIndex of vData\n        vData[nIndex >> 3] |= (1 << (7 & nIndex));\n    }\n}",
        "import_statements": [
            "#include <common/bloom.h>\n",
            "#include <hash.h>\n",
            "#include <primitives/transaction.h>\n",
            "#include <random.h>\n",
            "#include <script/script.h>\n",
            "#include <script/solver.h>\n",
            "#include <span.h>\n",
            "#include <streams.h>\n",
            "#include <util/fastrange.h>\n",
            "#include <algorithm>\n",
            "#include <cmath>\n",
            "#include <cstdlib>\n",
            "#include <limits>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "vData.empty",
            "Hash"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "Hash",
                "code": "inline unsigned int CBloomFilter::Hash(unsigned int nHashNum, Span<const unsigned char> vDataToHash) const\n{\n    // 0xFBA4C795 chosen as it guarantees a reasonable bit difference between nHashNum values.\n    return MurmurHash3(nHashNum * 0xFBA4C795 + nTweak, vDataToHash) % (vData.size() * 8);\n}"
            }
        ],
        "third_party": [
            "vData.empty"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool CBloomFilter::contains(Span<const unsigned char> vKey) const",
        "start_line": "68",
        "end_line": "80",
        "file_path": "src/common/bloom.cpp",
        "docstring": "The function CBloomFilter::contains(Span<const unsigned char> vKey) const checks if a key is present in the bloom filter.\\nIt first verifies if the filter data is empty to avoid a divide-by-zero error and returns true if it is.\\nFor each hash function, it calculates an index by hashing the key and checks if the corresponding bit in the filter data is set.\\nIf any bit is not set, it returns false, indicating the key is not present.\\nIf all bits are set, it returns true, indicating the key is likely present in the bloom filter.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4cfdf3dcbc26",
        "ground_truth": "bool CBloomFilter::contains(Span<const unsigned char> vKey) const\n{\n    if (vData.empty()) // Avoid divide-by-zero (CVE-2013-5700)\n        return true;\n    for (unsigned int i = 0; i < nHashFuncs; i++)\n    {\n        unsigned int nIndex = Hash(i, vKey);\n        // Checks bit nIndex of vData\n        if (!(vData[nIndex >> 3] & (1 << (7 & nIndex))))\n            return false;\n    }\n    return true;\n}",
        "import_statements": [
            "#include <common/bloom.h>\n",
            "#include <hash.h>\n",
            "#include <primitives/transaction.h>\n",
            "#include <random.h>\n",
            "#include <script/script.h>\n",
            "#include <script/solver.h>\n",
            "#include <span.h>\n",
            "#include <streams.h>\n",
            "#include <util/fastrange.h>\n",
            "#include <algorithm>\n",
            "#include <cmath>\n",
            "#include <cstdlib>\n",
            "#include <limits>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "vData.empty",
            "Hash"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "Hash",
                "code": "inline unsigned int CBloomFilter::Hash(unsigned int nHashNum, Span<const unsigned char> vDataToHash) const\n{\n    // 0xFBA4C795 chosen as it guarantees a reasonable bit difference between nHashNum values.\n    return MurmurHash3(nHashNum * 0xFBA4C795 + nTweak, vDataToHash) % (vData.size() * 8);\n}"
            }
        ],
        "third_party": [
            "vData.empty"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool IsConfSupported(KeyInfo& key, std::string& error)",
        "start_line": "78",
        "end_line": "90",
        "file_path": "src/common/config.cpp",
        "docstring": "The function IsConfSupported(KeyInfo& key, std::string& error) checks if a configuration key is supported and sets an error message if it is not.\\nIf the key name is \"conf\", it sets an error message indicating that \"conf\" cannot be set in the configuration file and suggests using \"includeconf=\" instead, returning false.\\nIf the key name is \"reindex\", it allows the configuration but logs a warning about potential performance issues due to reindexing on every restart, returning true.\\nFor all other keys, it returns true, indicating support.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a89cd61460fd",
        "ground_truth": "bool IsConfSupported(KeyInfo& key, std::string& error) {\n    if (key.name == \"conf\") {\n        error = \"conf cannot be set in the configuration file; use includeconf= if you want to include additional config files\";\n        return false;\n    }\n    if (key.name == \"reindex\") {\n        // reindex can be set in a config file but it is strongly discouraged as this will cause the node to reindex on\n        // every restart. Allow the config but throw a warning\n        LogPrintf(\"Warning: reindex=1 is set in the configuration file, which will significantly slow down startup. Consider removing or commenting out this option for better performance, unless there is currently a condition which makes rebuilding the indexes necessary\\n\");\n        return true;\n    }\n    return true;\n}",
        "import_statements": [
            "#include <common/args.h>\n",
            "#include <common/settings.h>\n",
            "#include <logging.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/chaintype.h>\n",
            "#include <util/fs.h>\n",
            "#include <util/string.h>\n",
            "#include <algorithm>\n",
            "#include <cassert>\n",
            "#include <cstdlib>\n",
            "#include <fstream>\n",
            "#include <iostream>\n",
            "#include <list>\n",
            "#include <map>\n",
            "#include <memory>\n",
            "#include <optional>\n",
            "#include <string>\n",
            "#include <string_view>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "LogPrintf"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "LogPrintf"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool FeeModeFromString(const std::string& mode_string, FeeEstimateMode& fee_estimate_mode)",
        "start_line": "66",
        "end_line": "76",
        "file_path": "src/common/messages.cpp",
        "docstring": "The function FeeModeFromString(const std::string& mode_string, FeeEstimateMode& fee_estimate_mode) converts a string representation of a fee mode into its corresponding FeeEstimateMode enum value.\\nIt converts the input string to uppercase and searches for a matching key in the FeeModeMap.\\nIf a match is found, it assigns the corresponding enum value to fee_estimate_mode and returns true.\\nIf no match is found, it returns false, indicating that the conversion was unsuccessful.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c7fa4937731b",
        "ground_truth": "bool FeeModeFromString(const std::string& mode_string, FeeEstimateMode& fee_estimate_mode)\n{\n    auto searchkey = ToUpper(mode_string);\n    for (const auto& pair : FeeModeMap()) {\n        if (ToUpper(pair.first) == searchkey) {\n            fee_estimate_mode = pair.second;\n            return true;\n        }\n    }\n    return false;\n}",
        "import_statements": [
            "#include <common/messages.h>\n",
            "#include <common/types.h>\n",
            "#include <policy/fees.h>\n",
            "#include <node/types.h>\n",
            "#include <tinyformat.h>\n",
            "#include <util/strencodings.h>\n",
            "#include <util/string.h>\n",
            "#include <util/translation.h>\n",
            "#include <cassert>\n",
            "#include <map>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "ToUpper",
            "FeeModeMap"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "ToUpper",
            "FeeModeMap"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool WriteSettings(const fs::path& path,\n    const std::map<std::string, SettingsValue>& values,\n    std::vector<std::string>& errors)",
        "start_line": "123",
        "end_line": "144",
        "file_path": "src/common/settings.cpp",
        "docstring": "The function WriteSettings(const fs::path& path, const std::map<std::string, SettingsValue>& values, std::vector<std::string>& errors) writes configuration settings to a file.\\nIt creates a SettingsValue object and adds an auto-generated warning comment indicating the file is managed by the application.\\nIt then adds each setting key-value pair to the SettingsValue object.\\nThe function attempts to open the specified file for writing.\\nIf opening the file fails, it records an error message and returns false.\\nIf the file opens successfully, it writes the settings to the file with indentation for readability, closes the file, and returns true.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "83689ccf7c21",
        "ground_truth": "bool WriteSettings(const fs::path& path,\n    const std::map<std::string, SettingsValue>& values,\n    std::vector<std::string>& errors)\n{\n    SettingsValue out(SettingsValue::VOBJ);\n    // Add auto-generated warning comment\n    out.pushKV(SETTINGS_WARN_MSG_KEY, strprintf(\"This file is automatically generated and updated by %s. Please do not edit this file while the node \"\n                                                \"is running, as any changes might be ignored or overwritten.\", PACKAGE_NAME));\n    // Push settings values\n    for (const auto& value : values) {\n        out.pushKVEnd(value.first, value.second);\n    }\n    std::ofstream file;\n    file.open(path);\n    if (file.fail()) {\n        errors.emplace_back(strprintf(\"Error: Unable to open settings file %s for writing\", fs::PathToString(path)));\n        return false;\n    }\n    file << out.write(/* prettyIndent= */ 4, /* indentLevel= */ 1) << std::endl;\n    file.close();\n    return true;\n}",
        "import_statements": [
            "#include <common/settings.h>\n",
            "#include <config/bitcoin-config.h> // IWYU pragma: keep\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/fs.h>\n",
            "#include <algorithm>\n",
            "#include <fstream>\n",
            "#include <iterator>\n",
            "#include <map>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "file.close",
            "fs::PathToString",
            "errors.emplace_back",
            "file.fail",
            "out.write",
            "out.pushKV",
            "file.open",
            "out.pushKVEnd",
            "strprintf"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "file.close",
            "fs::PathToString",
            "errors.emplace_back",
            "file.fail",
            "out.write",
            "out.pushKV",
            "file.open",
            "out.pushKVEnd",
            "strprintf"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool OnlyHasDefaultSectionSetting(const Settings& settings, const std::string& section, const std::string& name)",
        "start_line": "248",
        "end_line": "261",
        "file_path": "src/common/settings.cpp",
        "docstring": "The function OnlyHasDefaultSectionSetting(const Settings& settings, const std::string& section, const std::string& name) checks if a setting exists only in the default section of the configuration and not in any other source.\\nIt initializes flags to track the presence of the setting in the default section and other sources.\\nThe function merges settings for the specified section and name, updating the flags based on the source of each setting.\\nIf the setting is found in the default section and not overridden by the user in other sections or on the command line, the function returns true, indicating that warnings about the setting being ignored should be enabled.\\nOtherwise, it returns false.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "6fe63bb578f8",
        "ground_truth": "bool OnlyHasDefaultSectionSetting(const Settings& settings, const std::string& section, const std::string& name)\n{\n    bool has_default_section_setting = false;\n    bool has_other_setting = false;\n    MergeSettings(settings, section, name, [&](SettingsSpan span, Source source) {\n        if (span.empty()) return;\n        else if (source == Source::CONFIG_FILE_DEFAULT_SECTION) has_default_section_setting = true;\n        else has_other_setting = true;\n    });\n    // If a value is set in the default section and not explicitly overwritten by the\n    // user on the command line or in a different section, then we want to enable\n    // warnings about the value being ignored.\n    return has_default_section_setting && !has_other_setting;\n}",
        "import_statements": [
            "#include <common/settings.h>\n",
            "#include <config/bitcoin-config.h> // IWYU pragma: keep\n",
            "#include <tinyformat.h>\n",
            "#include <univalue.h>\n",
            "#include <util/fs.h>\n",
            "#include <algorithm>\n",
            "#include <fstream>\n",
            "#include <iterator>\n",
            "#include <map>\n",
            "#include <string>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "span.empty",
            "MergeSettings"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "MergeSettings",
                "code": "static void MergeSettings(const Settings& settings, const std::string& section, const std::string& name, Fn&& fn)\n{\n    // Merge in the forced settings\n    if (auto* value = FindKey(settings.forced_settings, name)) {\n        fn(SettingsSpan(*value), Source::FORCED);\n    }\n    // Merge in the command-line options\n    if (auto* values = FindKey(settings.command_line_options, name)) {\n        fn(SettingsSpan(*values), Source::COMMAND_LINE);\n    }\n    // Merge in the read-write settings\n    if (const SettingsValue* value = FindKey(settings.rw_settings, name)) {\n        fn(SettingsSpan(*value), Source::RW_SETTINGS);\n    }\n    // Merge in the network-specific section of the config file\n    if (!section.empty()) {\n        if (auto* map = FindKey(settings.ro_config, section)) {\n            if (auto* values = FindKey(*map, name)) {\n                fn(SettingsSpan(*values), Source::CONFIG_FILE_NETWORK_SECTION);\n            }\n        }\n    }\n    // Merge in the default section of the config file\n    if (auto* map = FindKey(settings.ro_config, \"\")) {\n        if (auto* values = FindKey(*map, name)) {\n            fn(SettingsSpan(*values), Source::CONFIG_FILE_DEFAULT_SECTION);\n        }\n    }\n}"
            }
        ],
        "third_party": [
            "span.empty"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "std::string UrlDecode(std::string_view url_encoded)",
        "start_line": "12",
        "end_line": "39",
        "file_path": "src/common/url.cpp",
        "docstring": "The function UrlDecode(std::string_view url_encoded) decodes a URL-encoded string.\\nIt initializes an empty string with reserved space to store the decoded result.\\nThe function iterates through each character of the input string, checking for percent-encoded sequences.\\nIf a '%' character is found followed by two valid hexadecimal digits, it converts these digits to their corresponding ASCII character and appends it to the result string, skipping the next two characters in the process.\\nIf the '%' sequence is invalid, it adds the '%' character as is.\\nAll other characters are directly appended to the result string.\\nThe function returns the decoded string.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "271973f132d2",
        "ground_truth": "std::string UrlDecode(std::string_view url_encoded)\n{\n    std::string res;\n    res.reserve(url_encoded.size());\n     for (size_t i = 0; i < url_encoded.size(); ++i) {\n        char c = url_encoded[i];\n        // Special handling for percent which should be followed by two hex digits\n        // representing an octet values, see RFC 3986, Section 2.1 Percent-Encoding\n        if (c == '%' && i + 2 < url_encoded.size()) {\n            unsigned int decoded_value{0};\n            auto [p, ec] = std::from_chars(url_encoded.data() + i + 1, url_encoded.data() + i + 3, decoded_value, 16);\n             // Only if there is no error and the pointer is set to the end of\n            // the string, we can be sure both characters were valid hex\n            if (ec == std::errc{} && p == url_encoded.data() + i + 3) {\n                res += static_cast<char>(decoded_value);\n                // Next two characters are part of the percent encoding\n                i += 2;\n                continue;\n            }\n            // In case of invalid percent encoding, add the '%' and continue\n        }\n        res += c;\n    }\n     return res;\n}",
        "import_statements": [
            "#include <common/url.h>\n",
            "#include <charconv>\n",
            "#include <string>\n",
            "#include <string_view>\n",
            "#include <system_error>\n"
        ],
        "reference_api": [
            "url_encoded.size",
            "static_cast<char>",
            "res.reserve",
            "url_encoded.data",
            "std::from_chars"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "url_encoded.size",
            "static_cast<char>",
            "res.reserve",
            "url_encoded.data"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void ChaCha20::Crypt(Span<const std::byte> input, Span<std::byte> output) noexcept",
        "start_line": "303",
        "end_line": "330",
        "file_path": "src/crypto/chacha20.cpp",
        "docstring": "The function ChaCha20::Crypt(Span<const std::byte> input, Span<std::byte> output) noexcept encrypts or decrypts data using the ChaCha20 algorithm.\\nIt first checks that the input and output spans are of equal size and returns if there is no data to process.\\nIf there is leftover data in the buffer, it processes as much of the input as possible using the remaining buffer, updates the buffer state, and adjusts the input and output spans.\\nFor larger input sizes, it processes full blocks of data directly with the ChaCha20 algorithm.\\nIf there is any remaining input after processing full blocks, it generates a new keystream block and XORs it with the remaining input data, updating the buffer state accordingly.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "431053ee8936",
        "ground_truth": "void ChaCha20::Crypt(Span<const std::byte> input, Span<std::byte> output) noexcept\n{\n    assert(input.size() == output.size());\n     if (!input.size()) return;\n    if (m_bufleft) {\n        unsigned reuse = std::min<size_t>(m_bufleft, input.size());\n        for (unsigned i = 0; i < reuse; i++) {\n            output[i] = input[i] ^ m_buffer[m_aligned.BLOCKLEN - m_bufleft + i];\n        }\n        m_bufleft -= reuse;\n        output = output.subspan(reuse);\n        input = input.subspan(reuse);\n    }\n    if (input.size() >= m_aligned.BLOCKLEN) {\n        size_t blocks = input.size() / m_aligned.BLOCKLEN;\n        m_aligned.Crypt(input.first(blocks * m_aligned.BLOCKLEN), output.first(blocks * m_aligned.BLOCKLEN));\n        output = output.subspan(blocks * m_aligned.BLOCKLEN);\n        input = input.subspan(blocks * m_aligned.BLOCKLEN);\n    }\n    if (!input.empty()) {\n        m_aligned.Keystream(m_buffer);\n        for (unsigned i = 0; i < input.size(); i++) {\n            output[i] = input[i] ^ m_buffer[i];\n        }\n        m_bufleft = m_aligned.BLOCKLEN - input.size();\n    }\n}",
        "import_statements": [
            "#include <crypto/common.h>\n",
            "#include <crypto/chacha20.h>\n",
            "#include <support/cleanse.h>\n",
            "#include <span.h>\n",
            "#include <algorithm>\n",
            "#include <bit>\n",
            "#include <string.h>\n"
        ],
        "reference_api": [
            "input.empty",
            "m_aligned.Keystream",
            "output.subspan",
            "output.size",
            "std::min<size_t>",
            "input.subspan",
            "input.first",
            "m_aligned.Crypt",
            "input.size",
            "assert",
            "output.first"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "input.empty",
            "m_aligned.Keystream",
            "output.subspan",
            "output.size",
            "input.subspan",
            "input.first",
            "m_aligned.Crypt",
            "input.size",
            "assert",
            "output.first"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void AEADChaCha20Poly1305::Encrypt(Span<const std::byte> plain1, Span<const std::byte> plain2, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> cipher) noexcept",
        "start_line": "69",
        "end_line": "81",
        "file_path": "src/crypto/chacha20poly1305.cpp",
        "docstring": "The function AEADChaCha20Poly1305::Encrypt(Span<const std::byte> plain1, Span<const std::byte> plain2, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> cipher) noexcept encrypts data using the AEAD ChaCha20-Poly1305 algorithm.\\nIt first ensures the output cipher span is large enough to hold the combined plaintext and expansion size.\\nThe function encrypts the first plaintext span (plain1) and the second plaintext span (plain2) using the ChaCha20 cipher starting at block 1, storing the results in the cipher span.\\nAfter encrypting the data, it seeks to block 0 of the ChaCha20 cipher and computes an authentication tag using the additional authenticated data (aad) and the combined ciphertext, storing the tag at the end of the cipher span.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "faf1d68376ca",
        "ground_truth": "void AEADChaCha20Poly1305::Encrypt(Span<const std::byte> plain1, Span<const std::byte> plain2, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> cipher) noexcept\n{\n    assert(cipher.size() == plain1.size() + plain2.size() + EXPANSION);\n     // Encrypt using ChaCha20 (starting at block 1).\n    m_chacha20.Seek(nonce, 1);\n    m_chacha20.Crypt(plain1, cipher.first(plain1.size()));\n    m_chacha20.Crypt(plain2, cipher.subspan(plain1.size()).first(plain2.size()));\n     // Seek to block 0, and compute tag using key drawn from there.\n    m_chacha20.Seek(nonce, 0);\n    ComputeTag(m_chacha20, aad, cipher.first(cipher.size() - EXPANSION), cipher.last(EXPANSION));\n}",
        "import_statements": [
            "#include <crypto/chacha20poly1305.h>\n",
            "#include <crypto/common.h>\n",
            "#include <crypto/chacha20.h>\n",
            "#include <crypto/poly1305.h>\n",
            "#include <span.h>\n",
            "#include <support/cleanse.h>\n",
            "#include <assert.h>\n",
            "#include <cstddef>\n"
        ],
        "reference_api": [
            "m_chacha20.Seek",
            "cipher.subspan(plain1.size()).first",
            "m_chacha20.Crypt",
            "cipher.size",
            "ComputeTag",
            "cipher.last",
            "plain2.size",
            "cipher.first",
            "cipher.subspan",
            "assert",
            "plain1.size"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "ComputeTag",
                "code": "void ComputeTag(ChaCha20& chacha20, Span<const std::byte> aad, Span<const std::byte> cipher, Span<std::byte> tag) noexcept\n{\n    static const std::byte PADDING[16] = {{}};\n\n    // Get block of keystream (use a full 64 byte buffer to avoid the need for chacha20's own buffering).\n    std::byte first_block[ChaCha20Aligned::BLOCKLEN];\n    chacha20.Keystream(first_block);\n\n    // Use the first 32 bytes of the first keystream block as poly1305 key.\n    Poly1305 poly1305{Span{first_block}.first(Poly1305::KEYLEN)};\n\n    // Compute tag:\n    // - Process the padded AAD with Poly1305.\n    const unsigned aad_padding_length = (16 - (aad.size() % 16)) % 16;\n    poly1305.Update(aad).Update(Span{PADDING}.first(aad_padding_length));\n    // - Process the padded ciphertext with Poly1305.\n    const unsigned cipher_padding_length = (16 - (cipher.size() % 16)) % 16;\n    poly1305.Update(cipher).Update(Span{PADDING}.first(cipher_padding_length));\n    // - Process the AAD and plaintext length with Poly1305.\n    std::byte length_desc[Poly1305::TAGLEN];\n    WriteLE64(UCharCast(length_desc), aad.size());\n    WriteLE64(UCharCast(length_desc + 8), cipher.size());\n    poly1305.Update(length_desc);\n\n    // Output tag.\n    poly1305.Finalize(tag);\n}"
            }
        ],
        "third_party": [
            "m_chacha20.Seek",
            "cipher.subspan(plain1.size()).first",
            "m_chacha20.Crypt",
            "cipher.size",
            "cipher.last",
            "plain2.size",
            "cipher.first",
            "cipher.subspan",
            "assert",
            "plain1.size"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool AEADChaCha20Poly1305::Decrypt(Span<const std::byte> cipher, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> plain1, Span<std::byte> plain2) noexcept",
        "start_line": "83",
        "end_line": "97",
        "file_path": "src/crypto/chacha20poly1305.cpp",
        "docstring": "The function AEADChaCha20Poly1305::Decrypt(Span<const std::byte> cipher, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> plain1, Span<std::byte> plain2) noexcept decrypts data using the AEAD ChaCha20-Poly1305 algorithm.\\nIt first checks that the cipher span size matches the combined size of plain1, plain2, and the expansion.\\nThe function seeks to block 0 of the ChaCha20 cipher and computes the expected authentication tag using the additional authenticated data (aad) and the ciphertext excluding the tag.\\nIf the computed tag does not match the tag in the cipher, the function returns false, indicating authentication failure.\\nIf the tag is valid, it decrypts the first part of the ciphertext into plain1 and the second part into plain2, starting at block 1 of the ChaCha20 cipher.\\nThe function returns true, indicating successful decryption and authentication.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "42ed585ae6b1",
        "ground_truth": "bool AEADChaCha20Poly1305::Decrypt(Span<const std::byte> cipher, Span<const std::byte> aad, Nonce96 nonce, Span<std::byte> plain1, Span<std::byte> plain2) noexcept\n{\n    assert(cipher.size() == plain1.size() + plain2.size() + EXPANSION);\n     // Verify tag (using key drawn from block 0).\n    m_chacha20.Seek(nonce, 0);\n    std::byte expected_tag[EXPANSION];\n    ComputeTag(m_chacha20, aad, cipher.first(cipher.size() - EXPANSION), expected_tag);\n    if (timingsafe_bcmp_internal(UCharCast(expected_tag), UCharCast(cipher.last(EXPANSION).data()), EXPANSION)) return false;\n     // Decrypt (starting at block 1).\n    m_chacha20.Crypt(cipher.first(plain1.size()), plain1);\n    m_chacha20.Crypt(cipher.subspan(plain1.size()).first(plain2.size()), plain2);\n    return true;\n}",
        "import_statements": [
            "#include <crypto/chacha20poly1305.h>\n",
            "#include <crypto/common.h>\n",
            "#include <crypto/chacha20.h>\n",
            "#include <crypto/poly1305.h>\n",
            "#include <span.h>\n",
            "#include <support/cleanse.h>\n",
            "#include <assert.h>\n",
            "#include <cstddef>\n"
        ],
        "reference_api": [
            "m_chacha20.Seek",
            "cipher.subspan(plain1.size()).first",
            "ComputeTag",
            "cipher.size",
            "UCharCast",
            "timingsafe_bcmp_internal",
            "cipher.last",
            "m_chacha20.Crypt",
            "plain2.size",
            "cipher.first",
            "cipher.subspan",
            "assert",
            "cipher.last(EXPANSION).data",
            "plain1.size"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "ComputeTag",
                "code": "void ComputeTag(ChaCha20& chacha20, Span<const std::byte> aad, Span<const std::byte> cipher, Span<std::byte> tag) noexcept\n{\n    static const std::byte PADDING[16] = {{}};\n\n    // Get block of keystream (use a full 64 byte buffer to avoid the need for chacha20's own buffering).\n    std::byte first_block[ChaCha20Aligned::BLOCKLEN];\n    chacha20.Keystream(first_block);\n\n    // Use the first 32 bytes of the first keystream block as poly1305 key.\n    Poly1305 poly1305{Span{first_block}.first(Poly1305::KEYLEN)};\n\n    // Compute tag:\n    // - Process the padded AAD with Poly1305.\n    const unsigned aad_padding_length = (16 - (aad.size() % 16)) % 16;\n    poly1305.Update(aad).Update(Span{PADDING}.first(aad_padding_length));\n    // - Process the padded ciphertext with Poly1305.\n    const unsigned cipher_padding_length = (16 - (cipher.size() % 16)) % 16;\n    poly1305.Update(cipher).Update(Span{PADDING}.first(cipher_padding_length));\n    // - Process the AAD and plaintext length with Poly1305.\n    std::byte length_desc[Poly1305::TAGLEN];\n    WriteLE64(UCharCast(length_desc), aad.size());\n    WriteLE64(UCharCast(length_desc + 8), cipher.size());\n    poly1305.Update(length_desc);\n\n    // Output tag.\n    poly1305.Finalize(tag);\n}"
            },
            {
                "name": "timingsafe_bcmp_internal",
                "code": "int timingsafe_bcmp_internal(const unsigned char* b1, const unsigned char* b2, size_t n) noexcept\n{\n    const unsigned char *p1 = b1, *p2 = b2;\n    int ret = 0;\n    for (; n > 0; n--)\n        ret |= *p1++ ^ *p2++;\n    return (ret != 0);\n}"
            }
        ],
        "third_party": [
            "m_chacha20.Seek",
            "cipher.subspan(plain1.size()).first",
            "cipher.size",
            "UCharCast",
            "cipher.last",
            "m_chacha20.Crypt",
            "plain2.size",
            "cipher.first",
            "cipher.subspan",
            "assert",
            "cipher.last(EXPANSION).data",
            "plain1.size"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void FSChaCha20Poly1305::NextPacket() noexcept",
        "start_line": "106",
        "end_line": "122",
        "file_path": "src/crypto/chacha20poly1305.cpp",
        "docstring": "The function FSChaCha20Poly1305::NextPacket() noexcept manages the key rekeying process for the FSChaCha20Poly1305 encryption algorithm.\\nIt increments the packet counter and checks if it has reached the rekey interval.\\nIf so, it generates a full block of keystream using the current AEAD state, even though only 32 bytes are needed for the new key.\\nThe function then sets the new key for the AEAD context using the first 32 bytes of the generated keystream.\\nThe keystream block is securely wiped from memory.\\nFinally, the function resets the packet counter and increments the rekey counter to track the number of rekey operations performed.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5bed9c896500",
        "ground_truth": "void FSChaCha20Poly1305::NextPacket() noexcept\n{\n    if (++m_packet_counter == m_rekey_interval) {\n        // Generate a full block of keystream, to avoid needing the ChaCha20 buffer, even though\n        // we only need KEYLEN (32) bytes.\n        std::byte one_block[ChaCha20Aligned::BLOCKLEN];\n        m_aead.Keystream({0xFFFFFFFF, m_rekey_counter}, one_block);\n        // Switch keys.\n        m_aead.SetKey(Span{one_block}.first(KEYLEN));\n        // Wipe the generated keystream (a copy remains inside m_aead, which will be cleaned up\n        // once it cycles again, or is destroyed).\n        memory_cleanse(one_block, sizeof(one_block));\n        // Update counters.\n        m_packet_counter = 0;\n        ++m_rekey_counter;\n    }\n}",
        "import_statements": [
            "#include <crypto/chacha20poly1305.h>\n",
            "#include <crypto/common.h>\n",
            "#include <crypto/chacha20.h>\n",
            "#include <crypto/poly1305.h>\n",
            "#include <span.h>\n",
            "#include <support/cleanse.h>\n",
            "#include <assert.h>\n",
            "#include <cstddef>\n"
        ],
        "reference_api": [
            "Span{one_block}.first",
            "m_aead.SetKey",
            "memory_cleanse",
            "m_aead.Keystream"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "Span{one_block}.first",
            "m_aead.SetKey",
            "memory_cleanse",
            "m_aead.Keystream"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "std::string HexStr(const Span<const uint8_t> s)",
        "start_line": "29",
        "end_line": "43",
        "file_path": "src/crypto/hex_base.cpp",
        "docstring": "The function HexStr(const Span<const uint8_t> s) converts a span of bytes into a hexadecimal string representation.\\nIt initializes an empty string of double the size of the input span to hold the hex characters.\\nThe function uses a precomputed byte-to-hex map to efficiently convert each byte to its corresponding two-character hex representation.\\nFor each byte in the input span, it copies the hex representation to the output string using std::memcpy.\\nAfter processing all bytes, it asserts that the output string's length matches the expected size and returns the resulting hexadecimal string.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d039f8670ed0",
        "ground_truth": "std::string HexStr(const Span<const uint8_t> s)\n{\n    std::string rv(s.size() * 2, '\\0');\n    static constexpr auto byte_to_hex = CreateByteToHexMap();\n    static_assert(sizeof(byte_to_hex) == 512);\n     char* it = rv.data();\n    for (uint8_t v : s) {\n        std::memcpy(it, byte_to_hex[v].data(), 2);\n        it += 2;\n    }\n     assert(it == rv.data() + rv.size());\n    return rv;\n}",
        "import_statements": [
            "#include <crypto/hex_base.h>\n",
            "#include <array>\n",
            "#include <cstring>\n",
            "#include <string>\n"
        ],
        "reference_api": [
            "std::memcpy",
            "s.size",
            "CreateByteToHexMap",
            "byte_to_hex[v].data",
            "assert",
            "rv.size",
            "rv.data"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "CreateByteToHexMap",
                "code": "constexpr std::array<ByteAsHex, 256> CreateByteToHexMap()\n{\n    constexpr char hexmap[16] = {'0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'a', 'b', 'c', 'd', 'e', 'f'};\n\n    std::array<ByteAsHex, 256> byte_to_hex{};\n    for (size_t i = 0; i < byte_to_hex.size(); ++i) {\n        byte_to_hex[i][0] = hexmap[i >> 4];\n        byte_to_hex[i][1] = hexmap[i & 15];\n    }\n    return byte_to_hex;\n}"
            }
        ],
        "third_party": [
            "s.size",
            "byte_to_hex[v].data",
            "assert",
            "rv.size",
            "rv.data"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void CHKDF_HMAC_SHA256_L32::Expand32(const std::string& info, unsigned char hash[OUTPUT_SIZE])",
        "start_line": "15",
        "end_line": "21",
        "file_path": "src/crypto/hkdf_sha256_32.cpp",
        "docstring": "The function CHKDF_HMAC_SHA256_L32::Expand32(const std::string& info, unsigned char hash[OUTPUT_SIZE]) generates a 32-byte key using the HMAC-SHA256 algorithm.\\nIt first asserts that the info string size is 128 bytes or less.\\nThe function then initializes a constant value of 1 and uses HMAC-SHA256 with the previously stored pseudorandom key (m_prk).\\nIt writes the info string and the constant value to the HMAC-SHA256 instance and finalizes the hash computation, storing the resulting 32-byte hash in the provided output array.",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7039ce75fd04",
        "ground_truth": "void CHKDF_HMAC_SHA256_L32::Expand32(const std::string& info, unsigned char hash[OUTPUT_SIZE])\n{\n    // expand a 32byte key (single round)\n    assert(info.size() <= 128);\n    static const unsigned char one[1] = {1};\n    CHMAC_SHA256(m_prk, 32).Write((const unsigned char*)info.data(), info.size()).Write(one, 1).Finalize(hash);\n}",
        "import_statements": [
            "#include <crypto/hkdf_sha256_32.h>\n",
            "#include <assert.h>\n",
            "#include <string.h>\n"
        ],
        "reference_api": [
            "CHMAC_SHA256",
            "CHMAC_SHA256(m_prk, 32).Write((const unsigned char*)info.data(), info.size()).Write",
            "CHMAC_SHA256(m_prk, 32).Write",
            "info.data",
            "info.size",
            "assert",
            "CHMAC_SHA256(m_prk, 32).Write((const unsigned char*)info.data(), info.size()).Write(one, 1).Finalize"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "CHMAC_SHA256",
            "CHMAC_SHA256(m_prk, 32).Write((const unsigned char*)info.data(), info.size()).Write",
            "CHMAC_SHA256(m_prk, 32).Write",
            "info.data",
            "info.size",
            "assert",
            "CHMAC_SHA256(m_prk, 32).Write((const unsigned char*)info.data(), info.size()).Write(one, 1).Finalize"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "CHMAC_SHA256::CHMAC_SHA256(const unsigned char* key, size_t keylen)",
        "start_line": "9",
        "end_line": "27",
        "file_path": "src/crypto/hmac_sha256.cpp",
        "docstring": "The constructor CHMAC_SHA256::CHMAC_SHA256(const unsigned char* key, size_t keylen) initializes an HMAC-SHA256 instance with the provided key.\\nIf the key length is 64 bytes or less, it copies the key into a 64-byte array (rkey) and pads it with zeros.\\nIf the key length exceeds 64 bytes, it hashes the key using SHA-256 and pads the resulting 32-byte hash to 64 bytes.\\nThe constructor then XORs each byte of rkey with 0x5c and writes it to the outer SHA-256 context.\\nNext, it XORs each byte of rkey with 0x36 (after removing the previous 0x5c XOR) and writes it to the inner SHA-256 context.\\nThis sets up the inner and outer states for the HMAC-SHA256 algorithm.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "825f968ce8b8",
        "ground_truth": "CHMAC_SHA256::CHMAC_SHA256(const unsigned char* key, size_t keylen)\n{\n    unsigned char rkey[64];\n    if (keylen <= 64) {\n        memcpy(rkey, key, keylen);\n        memset(rkey + keylen, 0, 64 - keylen);\n    } else {\n        CSHA256().Write(key, keylen).Finalize(rkey);\n        memset(rkey + 32, 0, 32);\n    }\n     for (int n = 0; n < 64; n++)\n        rkey[n] ^= 0x5c;\n    outer.Write(rkey, 64);\n     for (int n = 0; n < 64; n++)\n        rkey[n] ^= 0x5c ^ 0x36;\n    inner.Write(rkey, 64);\n}",
        "import_statements": [
            "#include <crypto/hmac_sha256.h>\n",
            "#include <string.h>\n"
        ],
        "reference_api": [
            "CSHA256().Write(key, keylen).Finalize",
            "outer.Write",
            "inner.Write",
            "CSHA256",
            "memset",
            "CSHA256().Write",
            "memcpy"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "CSHA256().Write(key, keylen).Finalize",
            "outer.Write",
            "inner.Write",
            "CSHA256",
            "CSHA256().Write"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "CRIPEMD160& CRIPEMD160::Write(const unsigned char* data, size_t len)",
        "start_line": "247",
        "end_line": "271",
        "file_path": "src/crypto/ripemd160.cpp",
        "docstring": "The function CRIPEMD160::Write(const unsigned char* data, size_t len) processes input data for the RIPEMD-160 hashing algorithm.\\nIt updates the internal state with the provided data in chunks of 64 bytes.\\nIf there is existing buffered data, it fills the buffer to 64 bytes, processes it, and then clears the buffer.\\nThe function then processes any remaining full 64-byte chunks directly from the input data.\\nIf there is leftover data that does not complete a full 64-byte chunk, it is copied into the buffer.\\nThe function updates the total number of processed bytes and returns a reference to the current object.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f1bc485e516f",
        "ground_truth": "CRIPEMD160& CRIPEMD160::Write(const unsigned char* data, size_t len)\n{\n    const unsigned char* end = data + len;\n    size_t bufsize = bytes % 64;\n    if (bufsize && bufsize + len >= 64) {\n        // Fill the buffer, and process it.\n        memcpy(buf + bufsize, data, 64 - bufsize);\n        bytes += 64 - bufsize;\n        data += 64 - bufsize;\n        ripemd160::Transform(s, buf);\n        bufsize = 0;\n    }\n    while (end - data >= 64) {\n        // Process full chunks directly from the source.\n        ripemd160::Transform(s, data);\n        bytes += 64;\n        data += 64;\n    }\n    if (end > data) {\n        // Fill the buffer with what remains.\n        memcpy(buf + bufsize, data, end - data);\n        bytes += end - data;\n    }\n    return *this;\n}",
        "import_statements": [
            "#include <crypto/ripemd160.h>\n",
            "#include <crypto/common.h>\n",
            "#include <string.h>\n"
        ],
        "reference_api": [
            "ripemd160::Transform",
            "memcpy"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "ripemd160::Transform"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "std::unique_ptr<interfaces::Init> spawnProcess(const char* new_exe_name) override",
        "start_line": "36",
        "end_line": "47",
        "file_path": "src/ipc/interfaces.cpp",
        "docstring": "The function std::unique_ptr<interfaces::Init> spawnProcess(const char* new_exe_name) override launches a new process and establishes an IPC connection with it.\\nIt spawns the new process using m_process->spawn, which returns a file descriptor and the process ID (pid).\\nIt logs the process launch details and connects to the new process using m_protocol->connect, obtaining an Init interface pointer.\\nA cleanup function is added to handle the process termination, which waits for the spawned process to exit and logs the exit status.\\nThe function returns the Init interface pointer for the newly spawned process.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f3e323ce8b4d",
        "ground_truth": "std::unique_ptr<interfaces::Init> spawnProcess(const char* new_exe_name) override\n{\n    int pid;\n    int fd = m_process->spawn(new_exe_name, m_process_argv0, pid);\n    LogPrint(::BCLog::IPC, \"Process %s pid %i launched\\n\", new_exe_name, pid);\n    auto init = m_protocol->connect(fd, m_exe_name);\n    Ipc::addCleanup(*init, [this, new_exe_name, pid] {\n        int status = m_process->waitSpawned(pid);\n        LogPrint(::BCLog::IPC, \"Process %s pid %i exited with status %i\\n\", new_exe_name, pid, status);\n    });\n    return init;\n}",
        "import_statements": [
            "#include <common/system.h>\n",
            "#include <interfaces/init.h>\n",
            "#include <interfaces/ipc.h>\n",
            "#include <ipc/capnp/protocol.h>\n",
            "#include <ipc/process.h>\n",
            "#include <ipc/protocol.h>\n",
            "#include <logging.h>\n",
            "#include <tinyformat.h>\n",
            "#include <util/fs.h>\n",
            "#include <cstdio>\n",
            "#include <cstdlib>\n",
            "#include <functional>\n",
            "#include <memory>\n",
            "#include <stdexcept>\n",
            "#include <string.h>\n",
            "#include <string>\n",
            "#include <unistd.h>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "m_process->spawn",
            "LogPrint",
            "m_process->waitSpawned",
            "m_protocol->connect",
            "Ipc::addCleanup"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "m_process->spawn",
            "LogPrint",
            "m_process->waitSpawned",
            "m_protocol->connect",
            "Ipc::addCleanup"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool startSpawnedProcess(int argc, char* argv[], int& exit_status) override",
        "start_line": "48",
        "end_line": "58",
        "file_path": "src/ipc/interfaces.cpp",
        "docstring": "The function startSpawnedProcess(int argc, char* argv[], int& exit_status) override attempts to start a spawned process and manage its execution.\\nIt initializes the exit status to EXIT_FAILURE and a file descriptor to -1.\\nThe function then checks if the process can be spawned using the provided arguments, updating the file descriptor if successful.\\nIf the process cannot be spawned, it returns false.\\nIf spawning is successful, it uses m_protocol to serve the process using the file descriptor, executable name, and initialization data.\\nAfter serving, it sets the exit status to EXIT_SUCCESS and returns true, indicating the process was managed successfully.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5a1a82df95ed",
        "ground_truth": "bool startSpawnedProcess(int argc, char* argv[], int& exit_status) override\n{\n    exit_status = EXIT_FAILURE;\n    int32_t fd = -1;\n    if (!m_process->checkSpawned(argc, argv, fd)) {\n        return false;\n    }\n    m_protocol->serve(fd, m_exe_name, m_init);\n    exit_status = EXIT_SUCCESS;\n    return true;\n}",
        "import_statements": [
            "#include <common/system.h>\n",
            "#include <interfaces/init.h>\n",
            "#include <interfaces/ipc.h>\n",
            "#include <ipc/capnp/protocol.h>\n",
            "#include <ipc/process.h>\n",
            "#include <ipc/protocol.h>\n",
            "#include <logging.h>\n",
            "#include <tinyformat.h>\n",
            "#include <util/fs.h>\n",
            "#include <cstdio>\n",
            "#include <cstdlib>\n",
            "#include <functional>\n",
            "#include <memory>\n",
            "#include <stdexcept>\n",
            "#include <string.h>\n",
            "#include <string>\n",
            "#include <unistd.h>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "m_protocol->serve",
            "m_process->checkSpawned"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "m_protocol->serve",
            "m_process->checkSpawned"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "bool checkSpawned(int argc, char* argv[], int& fd) override",
        "start_line": "38",
        "end_line": "56",
        "file_path": "src/ipc/process.cpp",
        "docstring": "The function checkSpawned(int argc, char* argv[], int& fd) override determines if the current process was spawned with a specific argument for inter-process communication (IPC).\\nIt first checks if the process was started with exactly three arguments and if the second argument is \"-ipcfd\".\\nIf these conditions are not met, the function returns false, indicating the process was not spawned correctly.\\nIf the conditions are met, it attempts to parse the third argument as an integer to obtain the file descriptor (fd).\\nIf parsing fails, it throws a runtime error with a descriptive message.\\nIf parsing succeeds, it returns true, indicating the process was correctly spawned and the file descriptor is valid for IPC.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "3b5008d54443",
        "ground_truth": "bool checkSpawned(int argc, char* argv[], int& fd) override\n{\n    // If this process was not started with a single -ipcfd argument, it is\n    // not a process spawned by the spawn() call above, so return false and\n    // do not try to serve requests.\n    if (argc != 3 || strcmp(argv[1], \"-ipcfd\") != 0) {\n        return false;\n    }\n    // If a single -ipcfd argument was provided, return true and get the\n    // file descriptor so Protocol::serve() can be called to handle\n    // requests from the parent process. The -ipcfd argument is not valid\n    // in combination with other arguments because the parent process\n    // should be able to control the child process through the IPC protocol\n    // without passing information out of band.\n    if (!ParseInt32(argv[2], &fd)) {\n        throw std::runtime_error(strprintf(\"Invalid -ipcfd number '%s'\", argv[2]));\n    }\n    return true;\n}",
        "import_statements": [
            "#include <ipc/process.h>\n",
            "#include <ipc/protocol.h>\n",
            "#include <mp/util.h>\n",
            "#include <tinyformat.h>\n",
            "#include <util/fs.h>\n",
            "#include <util/strencodings.h>\n",
            "#include <cstdint>\n",
            "#include <cstdlib>\n",
            "#include <exception>\n",
            "#include <iostream>\n",
            "#include <stdexcept>\n",
            "#include <string.h>\n",
            "#include <system_error>\n",
            "#include <unistd.h>\n",
            "#include <utility>\n",
            "#include <vector>\n"
        ],
        "reference_api": [
            "strcmp",
            "ParseInt32",
            "std::runtime_error",
            "strprintf"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "ParseInt32",
            "strprintf"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "interfaces::BlockInfo MakeBlockInfo(const CBlockIndex* index, const CBlock* data)",
        "start_line": "14",
        "end_line": "27",
        "file_path": "src/kernel/chain.cpp",
        "docstring": "The function interfaces::BlockInfo MakeBlockInfo(const CBlockIndex* index, const CBlock* data) creates and returns a BlockInfo object populated with information from a given block index and block data.\\nIt initializes the BlockInfo object with the block hash from the index, or a zero hash if the index is null.\\nIf the index is provided, it fills in additional fields such as the previous block hash, block height, maximum block time, file number, and data position, with a thread lock on cs_main for accessing shared state.\\nFinally, it assigns the provided block data to the BlockInfo object and returns it.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "423c00cff1bc",
        "ground_truth": "interfaces::BlockInfo MakeBlockInfo(const CBlockIndex* index, const CBlock* data)\n{\n    interfaces::BlockInfo info{index ? *index->phashBlock : uint256::ZERO};\n    if (index) {\n        info.prev_hash = index->pprev ? index->pprev->phashBlock : nullptr;\n        info.height = index->nHeight;\n        info.chain_time_max = index->GetBlockTimeMax();\n        LOCK(::cs_main);\n        info.file_number = index->nFile;\n        info.data_pos = index->nDataPos;\n    }\n    info.data = data;\n    return info;\n}",
        "import_statements": [
            "#include <chain.h>\n",
            "#include <interfaces/chain.h>\n",
            "#include <kernel/chain.h>\n",
            "#include <sync.h>\n",
            "#include <uint256.h>\n"
        ],
        "reference_api": [
            "index->GetBlockTimeMax",
            "LOCK"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "index->GetBlockTimeMax",
            "LOCK"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "void ApplyCoinHash(MuHash3072& muhash, const COutPoint& outpoint, const Coin& coin)",
        "start_line": "63",
        "end_line": "68",
        "file_path": "src/kernel/coinstats.cpp",
        "docstring": "The function ApplyCoinHash(MuHash3072& muhash, const COutPoint& outpoint, const Coin& coin) updates a MuHash3072 object with the hash of a given coin and outpoint.\\nIt creates a DataStream object and serializes the outpoint and coin into it using TxOutSer.\\nThen, it inserts the serialized data into the MuHash3072 object by converting the DataStream into a UCharSpan and calling muhash.Insert with it.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "8f97e7d74508",
        "ground_truth": "void ApplyCoinHash(MuHash3072& muhash, const COutPoint& outpoint, const Coin& coin)\n{\n    DataStream ss{};\n    TxOutSer(ss, outpoint, coin);\n    muhash.Insert(MakeUCharSpan(ss));\n}",
        "import_statements": [
            "#include <kernel/coinstats.h>\n",
            "#include <chain.h>\n",
            "#include <coins.h>\n",
            "#include <crypto/muhash.h>\n",
            "#include <hash.h>\n",
            "#include <logging.h>\n",
            "#include <node/blockstorage.h>\n",
            "#include <primitives/transaction.h>\n",
            "#include <script/script.h>\n",
            "#include <serialize.h>\n",
            "#include <span.h>\n",
            "#include <streams.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <uint256.h>\n",
            "#include <util/check.h>\n",
            "#include <util/overflow.h>\n",
            "#include <validation.h>\n",
            "#include <cassert>\n",
            "#include <iosfwd>\n",
            "#include <iterator>\n",
            "#include <map>\n",
            "#include <memory>\n",
            "#include <string>\n",
            "#include <utility>\n"
        ],
        "reference_api": [
            "muhash.Insert",
            "MakeUCharSpan",
            "TxOutSer"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "TxOutSer",
                "code": "static void TxOutSer(T& ss, const COutPoint& outpoint, const Coin& coin)\n{\n    ss << outpoint;\n    ss << static_cast<uint32_t>((coin.nHeight << 1) + coin.fCoinBase);\n    ss << coin.out;\n}"
            }
        ],
        "third_party": [
            "muhash.Insert",
            "MakeUCharSpan"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "bitcoin/bitcoin",
        "function_declaration": "static void FinalizeHash(MuHash3072& muhash, CCoinsStats& stats)",
        "start_line": "186",
        "end_line": "191",
        "file_path": "src/kernel/coinstats.cpp",
        "docstring": "The function FinalizeHash(MuHash3072& muhash, CCoinsStats& stats) finalizes the MuHash3072 computation and updates the given CCoinsStats object with the result.\\nIt calls the Finalize method on the muhash object, storing the resulting hash in a uint256 variable named out.\\nFinally, it assigns this hash to the hashSerialized field of the stats object.\n",
        "language": "CPP",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "83467d1c2b9e",
        "ground_truth": "static void FinalizeHash(MuHash3072& muhash, CCoinsStats& stats)\n{\n    uint256 out;\n    muhash.Finalize(out);\n    stats.hashSerialized = out;\n}",
        "import_statements": [
            "#include <kernel/coinstats.h>\n",
            "#include <chain.h>\n",
            "#include <coins.h>\n",
            "#include <crypto/muhash.h>\n",
            "#include <hash.h>\n",
            "#include <logging.h>\n",
            "#include <node/blockstorage.h>\n",
            "#include <primitives/transaction.h>\n",
            "#include <script/script.h>\n",
            "#include <serialize.h>\n",
            "#include <span.h>\n",
            "#include <streams.h>\n",
            "#include <sync.h>\n",
            "#include <tinyformat.h>\n",
            "#include <uint256.h>\n",
            "#include <util/check.h>\n",
            "#include <util/overflow.h>\n",
            "#include <validation.h>\n",
            "#include <cassert>\n",
            "#include <iosfwd>\n",
            "#include <iterator>\n",
            "#include <map>\n",
            "#include <memory>\n",
            "#include <string>\n",
            "#include <utility>\n"
        ],
        "reference_api": [
            "muhash.Finalize"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "muhash.Finalize"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "async function fetchPaginatedData(url)",
        "start_line": "18",
        "end_line": "41",
        "file_path": "build/changelog.js",
        "docstring": "The function fetchPaginatedData(url) asynchronously fetches paginated data from a given URL.\\nIt initializes the page number to 1 and an empty array to store all the fetched data.\\nIn a loop, it fetches data from the URL with the current page number appended as a query parameter, using the provided headers.\\nIf the fetch response is not successful, it throws an error with the status code.\\nIt then parses the response as JSON and checks if the data array is empty.\\nIf empty, it breaks the loop, indicating no more data is available.\\nIf not, it concatenates the fetched data to the allData array and increments the page number.\\nFinally, it returns the aggregated data.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "008b4a2db063",
        "ground_truth": "async function fetchPaginatedData(url) {\n    let page = 1;\n    let allData = [];\n     while (true) {\n        console.log(`Fetching page ${page}...`)\n        const response = await fetch(`${url}&page=${page}`, { headers });\n         if (!response.ok) {\n            throw new Error(`Failed to fetch data from ${url}. Status: ${response.status}`);\n        }\n         const data = await response.json();\n         if (data.length === 0) {\n            break; // No more data\n        }\n         allData = allData.concat(data);\n        page++;\n    }\n     return allData;\n}",
        "import_statements": [
            "fs/promises",
            "child_process"
        ],
        "reference_api": [
            "console.log",
            "response.json",
            "allData.concat",
            "fetch"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "response.json",
            "allData.concat"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "async function fetchAndWriteFullChangelog()",
        "start_line": "54",
        "end_line": "64",
        "file_path": "build/changelog.js",
        "docstring": "The function fetchAndWriteFullChangelog() asynchronously generates and writes a full changelog to a file.\\nIt first retrieves all tags using the getAllTags function and initializes a changelog string with a header.\\nIt then generates the changelog content by mapping the tag names and passing them to the generateChangelog function.\\nThe resulting content is written to a file named 'CHANGELOG.md' using fs.writeFile.\\nIf successful, it logs a success message to the console.\\nIf an error occurs at any step, it catches the error and logs an error message to the console.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "432b29437687",
        "ground_truth": "async function fetchAndWriteFullChangelog() {\n    try {\n        const tags = await getAllTags();\n        let changelog = '# Changelog\\n\\n';\n        const changelogContent = await generateChangelog(tags.map (tag => tag.name));\n        await fs.writeFile('CHANGELOG.md', changelogContent);\n        console.log('Changelog created successfully.');\n    } catch (error) {\n        console.error('Error fetching data:', error.message);\n    }\n}",
        "import_statements": [
            "fs/promises",
            "child_process"
        ],
        "reference_api": [
            "tags.map",
            "console.log",
            "console.error",
            "fs.writeFile",
            "getAllTags",
            "generateChangelog"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getAllTags",
                "code": "async function getAllTags() {\n    return await fetchPaginatedData(tagsUrl);\n}"
            },
            {
                "name": "generateChangelog",
                "code": "async function generateChangelog(tags) {\n    let changelog = '# Changelog\\n\\n';\n\n    const prs = await getAllPRs();\n    for (let i = 0; i < tags.length - 1; i++) {\n        const currentTag = tags[i];\n        const nextTag = tags[i + 1];\n\n        changelog += `## ${nextTag.name}\\n\\n`;\n\n        const commitsBetweenTags = await getCommitsBetweenTags(currentTag.name, nextTag.name);\n\n        commitsBetweenTags.forEach(commit => {\n            const pr = prs.find(pr => pr.merge_commit_sha === commit);\n            if (pr) changelog += `- ${pr.title} [#${pr.number}](${pr.html_url})\\n`;\n        });\n\n        changelog += '\\n\\n';\n    }\n\n    return changelog;\n}"
            }
        ],
        "third_party": [
            "tags.map",
            "fs.writeFile"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "function overwriteFileAndFolder (path, content)",
        "start_line": "26",
        "end_line": "32",
        "file_path": "build/csharpTranspiler.ts",
        "docstring": "The function overwriteFileAndFolder(path, content) ensures that a file and its containing folder exist, then writes content to the file.\\nIt first checks if the specified path exists using fs.existsSync.\\nIf the path does not exist, it calls checkCreateFolder to create the necessary folder structure.\\nAfter ensuring the folder exists, it calls overwriteFile and writeFile to write the specified content to the file.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ba51428acc4e",
        "ground_truth": "function overwriteFileAndFolder (path, content) {\n    if (!(fs.existsSync(path))) {\n        checkCreateFolder (path);\n    }\n    overwriteFile (path, content);\n    writeFile (path, content);\n}",
        "import_statements": [
            "ast-transpiler",
            "typescript",
            "path",
            "../js/src/base/errors.js",
            "path",
            "./fsLocal.js",
            "process",
            "fs",
            "ololog",
            "ansicolor",
            "./transpile.js",
            "util",
            "../js/src/base/errorHierarchy.js",
            "piscina",
            "./transpile.js",
            "../js/src/base/functions.js"
        ],
        "reference_api": [
            "checkCreateFolder",
            "writeFile",
            "fs.existsSync",
            "overwriteFile"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "checkCreateFolder",
            "writeFile",
            "fs.existsSync",
            "overwriteFile"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "createExchangesWrappers(): string[]",
        "start_line": "598",
        "end_line": "608",
        "file_path": "build/csharpTranspiler.ts",
        "docstring": "The function createExchangesWrappers(): string[] generates a list of C# wrapper class definitions for each exchange ID.\\nIt initializes an array with a comment indicating the start of class wrappers.\\nFor each exchange ID, it capitalizes the first letter and removes the '.ts' extension to create a class name.\\nIt constructs a C# class definition with a constructor that calls the base class constructor with optional arguments.\\nThe generated class definitions are added to the array.\\nFinally, the function returns the array of class definitions.",
        "language": "TypeScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a12dc202fc88",
        "ground_truth": "createExchangesWrappers(): string[] {\n    // in csharp classes should be Capitalized, so I'm creating a wrapper class for each exchange\n    const res: string[] = ['// class wrappers'];\n    exchangeIds.forEach(exchange => {\n        const capitalizedExchange = exchange.charAt(0).toUpperCase() + exchange.slice(1);\n        const capitalName = capitalizedExchange.replace('.ts','');\n        const constructor = `public ${capitalName}(object args = null) : base(args) { }`\n        res.push(`public class  ${capitalName}: ${exchange.replace('.ts','')} { ${constructor} }`)\n    });\n    return res;\n}",
        "import_statements": [
            "import Transpiler from \"ast-transpiler\";",
            "Transpiler",
            "import ts from \"typescript\";",
            "ts",
            "import path from 'path'",
            "path",
            "import errors from \"../js/src/base/errors.js\"",
            "errors",
            "import { basename, join, resolve } from 'path'",
            "{ basename, join, resolve }",
            "{ basename, join, resolve }",
            "basename",
            "join",
            "resolve",
            "import { createFolderRecursively, replaceInFile, overwriteFile, writeFile, checkCreateFolder } from './fsLocal.js'",
            "{ createFolderRecursively, replaceInFile, overwriteFile, writeFile, checkCreateFolder }",
            "{ createFolderRecursively, replaceInFile, overwriteFile, writeFile, checkCreateFolder }",
            "createFolderRecursively",
            "replaceInFile",
            "overwriteFile",
            "writeFile",
            "checkCreateFolder",
            "import { platform } from 'process'",
            "{ platform }",
            "{ platform }",
            "platform",
            "import fs from 'fs'",
            "fs",
            "import log from 'ololog'",
            "log",
            "import ansi from 'ansicolor'",
            "ansi",
            "import {Transpiler as OldTranspiler, parallelizeTranspiling } from \"./transpile.js\";",
            "{Transpiler as OldTranspiler, parallelizeTranspiling }",
            "{Transpiler as OldTranspiler, parallelizeTranspiling }",
            "Transpiler as OldTranspiler",
            "parallelizeTranspiling",
            "import { promisify } from 'util';",
            "{ promisify }",
            "{ promisify }",
            "promisify",
            "import errorHierarchy from '../js/src/base/errorHierarchy.js'",
            "errorHierarchy",
            "import Piscina from 'piscina';",
            "Piscina",
            "import { isMainEntry } from \"./transpile.js\";",
            "{ isMainEntry }",
            "{ isMainEntry }",
            "isMainEntry",
            "import { unCamelCase } from \"../js/src/base/functions.js\";",
            "{ unCamelCase }",
            "{ unCamelCase }",
            "unCamelCase"
        ],
        "reference_api": [
            "exchange.charAt",
            "exchange.replace",
            "capitalizedExchange.replace",
            "exchange.slice",
            "exchange.charAt(0).toUpperCase",
            "res.push"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "exchange.charAt",
                "code": " "
            },
            {
                "name": "exchange.replace",
                "code": " "
            },
            {
                "name": "capitalizedExchange.replace",
                "code": " "
            },
            {
                "name": "exchange.slice",
                "code": " "
            },
            {
                "name": "exchange.charAt(0).toUpperCase",
                "code": " "
            },
            {
                "name": "res.push",
                "code": " "
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "const sortByCountry = (a, b) =>",
        "start_line": "290",
        "end_line": "304",
        "file_path": "build/export-exchanges.js",
        "docstring": "The function sortByCountry is a comparator used to sort objects based on their 'country / region' property.\\nIf the 'country / region' of object a is greater than that of object b, it returns 1.\\nIf it is less, it returns -1.\\nIf the 'country / region' properties are equal, it further compares the objects by their 'id' property.\\nIf the 'id' of object a is greater than that of object b, it returns 1.\\nIf it is less, it returns -1.\\nIf both 'country / region' and 'id' properties are equal, it returns 0, indicating equality.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d90c932a5b68",
        "ground_truth": "const sortByCountry = (a, b) => {\n    if (a['country / region'] > b['country / region']) {\n        return 1\n    } else if (a['country / region'] < b['country / region']) {\n        return -1;\n    } else {\n        if (a['id'] > b['id']) {\n            return 1;\n        } else if (a['id'] < b['id']) {\n            return -1;\n        } else {\n            return 0;\n        }\n    }\n}",
        "import_statements": [
            "fs",
            "ololog",
            "ansicolor",
            "url",
            "./countries.js",
            "child_process",
            "./fsLocal.js",
            "as-table",
            "util"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "function flatten (nested, result = [])",
        "start_line": "501",
        "end_line": "508",
        "file_path": "build/export-exchanges.js",
        "docstring": "The function flatten(nested, result = []) recursively flattens a nested object structure into a flat array of keys.\\nIt iterates over each key in the nested object, pushing the key to the result array.\\nIf the value associated with the key is itself an object with keys, the function recursively flattens this nested object, passing the current result array to accumulate keys.\\nThe function returns the final result array containing all the keys from the nested object structure.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c488da890a04",
        "ground_truth": "function flatten (nested, result = []) {\n    for (const key in nested) {\n        result.push (key)\n        if (Object.keys (nested[key]).length)\n            flatten (nested[key], result)\n    }\n    return result\n}",
        "import_statements": [
            "fs",
            "ololog",
            "ansicolor",
            "url",
            "./countries.js",
            "child_process",
            "./fsLocal.js",
            "as-table",
            "util"
        ],
        "reference_api": [
            "result.push",
            "flatten",
            "Object.keys"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "result.push",
            "flatten"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "function copyFile (oldName, newName)",
        "start_line": "11",
        "end_line": "17",
        "file_path": "build/fsLocal.js",
        "docstring": "The function copyFile(oldName, newName) copies the contents of a file from oldName to newName.\\nIt first reads the contents of the file specified by oldName using fs.readFileSync with 'utf8' encoding.\\nIf a file with the name newName already exists, it truncates the file to clear its contents using fs.truncateSync.\\nFinally, it writes the read contents to the file specified by newName using fs.writeFileSync.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1ce27f05fe86",
        "ground_truth": "function copyFile (oldName, newName) {\n    const contents = fs.readFileSync (oldName, 'utf8')\n    if (fs.existsSync (newName)) {\n        fs.truncateSync (newName)\n    }\n    fs.writeFileSync (newName, contents)\n}",
        "import_statements": [
            "fs",
            "path"
        ],
        "reference_api": [
            "fs.writeFileSync",
            "fs.existsSync",
            "fs.readFileSync",
            "fs.truncateSync"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "fs.writeFileSync",
            "fs.existsSync",
            "fs.readFileSync",
            "fs.truncateSync"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "function createFolderRecursively (folder)",
        "start_line": "41",
        "end_line": "46",
        "file_path": "build/fsLocal.js",
        "docstring": "The function createFolderRecursively(folder) creates a folder and all its parent directories recursively.\\nIt splits the folder path into its components using the system's path separator.\\nFor each level of the path, from the root to the full path, it calls the createFolder function, passing the path components joined together.\\nThis ensures that each intermediate directory is created if it does not already exist.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "bff319d9f324",
        "ground_truth": "function createFolderRecursively (folder) {\n    const parts = folder.split (path.sep)\n    for (let i = 1; i <= parts.length; i++) {\n        createFolder (path.join.apply (null, parts.slice (0, i)))\n    }\n}",
        "import_statements": [
            "fs",
            "path"
        ],
        "reference_api": [
            "path.join.apply",
            "parts.slice",
            "createFolder",
            "folder.split"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "path.join.apply",
            "parts.slice",
            "createFolder",
            "folder.split"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "transpileJavaScriptToPython3 ({ js, className, removeEmptyLines })",
        "start_line": "1019",
        "end_line": "1053",
        "file_path": "build/transpile.js",
        "docstring": "The function transpileJavaScriptToPython3({ js, className, removeEmptyLines }) converts JavaScript code to Python 3 code.\\nIt starts by replacing JavaScript syntax with Python syntax using regex patterns obtained from getPythonRegexes.\\nIf removeEmptyLines is true, it removes any empty lines from the Python code.\\nIt then strips comments and checks if the resulting code is empty, adding a 'pass' statement if necessary.\\nThe function converts specific Unicode characters in single quotes to Python's Unicode format and handles special cases for OrderedDicts by adjusting their syntax.\\nFunction names are converted from camelCase to snake_case using unCamelCase.\\nIf a className is provided, it modifies super() calls to include the class name and self.\\nFinally, it returns the transpiled Python 3 code.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1f07006aa516",
        "ground_truth": "transpileJavaScriptToPython3 ({ js, className, removeEmptyLines }) {\n    // transpile JS \u2192 Python 3\n    let python3Body = this.regexAll (js, this.getPythonRegexes ())\n    if (removeEmptyLines) {\n        python3Body = python3Body.replace (/$\\s*$/gm, '')\n    }\n    const strippedPython3BodyWithoutComments = python3Body.replace (/^[\\s]+#.+$/gm, '')\n    if (!strippedPython3BodyWithoutComments.match(/[^\\s]/)) {\n        python3Body += '\\n        pass'\n    }\n    python3Body = python3Body.replace (/\\'([\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f\u670d\u52a1\u7aef\u5fd9\u788c]+)\\'/gm, \"u'$1'\")\n    // special case for Python OrderedDicts\n    let orderedDictRegex = /\\.ordered\\s+\\(\\{([^\\}]+)\\}\\)/g\n    let orderedDictMatches = undefined\n    while (orderedDictMatches = orderedDictRegex.exec (python3Body)) {\n        let replaced = orderedDictMatches[1].replace (/^(\\s+)([^\\:]+)\\:\\s*([^\\,]+)\\,$/gm, '$1($2, $3),')\n        python3Body = python3Body.replace (orderedDictRegex, '\\.ordered([' + replaced + '])')\n    }\n    // snake case function names\n    python3Body = python3Body.replace (/def (\\w+)/g, (match, group1) => 'def ' + unCamelCase (group1))\n    // special case for Python super\n    if (className) {\n        python3Body = python3Body.replace (/super\\./g, 'super(' + className + ', self).')\n    }\n    return python3Body\n}",
        "import_statements": [
            "fs",
            "path",
            "ololog",
            "ansicolor",
            "util",
            "../js/src/base/errors.js",
            "../js/src/base/functions.js",
            "../js/src/base/Exchange.js",
            "path",
            "./fsLocal.js",
            "url",
            "../js/src/base/errorHierarchy.js",
            "process",
            "os",
            "child_process",
            "node:url",
            "piscina",
            "ast-transpiler"
        ],
        "reference_api": [
            "this.getPythonRegexes",
            "unCamelCase",
            "orderedDictRegex.exec",
            "orderedDictMatches[1].replace",
            "this.regexAll",
            "strippedPython3BodyWithoutComments.match",
            "transpileJavaScriptToPython3",
            "python3Body.replace"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "this.getPythonRegexes",
                "code": "getPythonRegexes () {\n\n        return [\n            [ /Array\\.isArray\\s*\\(([^\\)]+)\\)/g, 'isinstance($1, list)' ],\n            [ /Number\\.isInteger\\s*\\(([^\\)]+)\\)/g, 'isinstance($1, int)' ],\n            [ /([^\\(\\s]+)\\s+instanceof\\s+String/g, 'isinstance($1, str)' ],\n            [ /([^\\(\\s]+)\\s+instanceof\\s+([^\\)\\s]+)/g, 'isinstance($1, $2)' ],\n\n            // convert javascript primitive types to python ones\n            [ /(^\\s+(?:let|const|var)\\s+\\w+:\\s+)string/mg, '$1str' ],\n            [ /(^\\s+(?:let|const|var)\\s+\\w+:\\s+)Dict/mg, '$1dict' ], // remove from now\n            // [ /(^\\s+(?:let|const|var)\\s+\\w+:\\s+)Int/mg, '$1int' ], // remove from now\n            // [ /(^\\s+(?:let|const|var)\\s+\\w+:\\s+)Number/mg, '$1float' ], // remove from now\n            [ /(^\\s+(?:let|const|var)\\s+\\w+:\\s+)any/mg, '$1Any' ], // remove from now\n\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\=\\=\\=?\\s+\\'undefined\\'/g, '$1[$2] is None' ],\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\!\\=\\=?\\s+\\'undefined\\'/g, '$1[$2] is not None' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'undefined\\'/g, '$1 is None' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'undefined\\'/g, '$1 is not None' ],\n            [ /typeof\\s+(.+?)\\s+\\=\\=\\=?\\s+\\'undefined\\'/g, '$1 is None' ],\n            [ /typeof\\s+(.+?)\\s+\\!\\=\\=?\\s+\\'undefined\\'/g, '$1 is not None' ],\n\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\=\\=\\=?\\s+\\'number\\'/g, \"isinstance($1[$2], numbers.Real)\" ],\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\!\\=\\=?\\s+\\'number\\'/g, \"(not isinstance($1[$2], numbers.Real))\" ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'number\\'/g, \"isinstance($1, numbers.Real)\" ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'boolean\\'/g, \"isinstance($1, bool)\" ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'number\\'/g, \"(not isinstance($1, numbers.Real))\" ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'boolean\\'/g, \"(not isinstance($1, bool))\" ],\n\n            [ /([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\=\\=\\=?\\s+undefined/g, '$1[$2] is None' ],\n            [ /([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\!\\=\\=?\\s+undefined/g, '$1[$2] is not None' ],\n            [ /([^\\s]+)\\s+\\=\\=\\=?\\s+undefined/g, '$1 is None' ],\n            [ /([^\\s]+)\\s+\\!\\=\\=?\\s+undefined/g, '$1 is not None' ],\n            [ /(.+?)\\s+\\=\\=\\=?\\s+undefined/g, '$1 is None' ],\n            [ /(.+?)\\s+\\!\\=\\=?\\s+undefined/g, '$1 is not None' ],\n            //\n            // too broad, have to rewrite these cause they don't work\n            //\n            // [ /([^\\s]+)\\s+\\=\\=\\=?\\s+true/g, 'isinstance($1, bool) and ($1 is True)' ],\n            // [ /([^\\s]+)\\s+\\!\\=\\=?\\s+true/g, 'isinstance($1, bool) and ($1 is not True)' ],\n            // [ /([^\\s]+)\\s+\\=\\=\\=?\\s+false/g, 'isinstance($1, bool) and ($1 is False)' ],\n            // [ /([^\\s]+)\\s+\\!\\=\\=?\\s+false/g, 'isinstance($1, bool) and ($1 is not False)' ],\n\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\=\\=\\=?\\s+\\'string\\'/g, 'isinstance($1[$2], str)' ],\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\!\\=\\=?\\s+\\'string\\'/g, 'not isinstance($1[$2], str)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'string\\'/g, 'isinstance($1, str)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'string\\'/g, 'not isinstance($1, str)' ],\n\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\=\\=\\=?\\s+\\'object\\'/g, 'isinstance($1[$2], dict)' ],\n            [ /typeof\\s+([^\\s\\[]+)(?:\\s|\\[(.+?)\\])\\s+\\!\\=\\=?\\s+\\'object\\'/g, 'not isinstance($1[$2], dict)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'object\\'/g, 'isinstance($1, dict)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'object\\'/g, 'not isinstance($1, dict)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\=\\=\\=?\\s+\\'function\\'/g, 'callable($1)' ],\n            [ /typeof\\s+([^\\s]+)\\s+\\!\\=\\=?\\s+\\'function\\'/g, 'not callable($1)' ],\n\n            [ /undefined/g, 'None' ],\n            [ /\\=\\=\\=?/g, '==' ],\n            [ /\\!\\=\\=?/g, '!=' ],\n            [ /this\\.stringToBinary\\s*\\((.*)\\)/g, '$1' ],\n            [ /\\.shift\\s*\\(\\)/g, '.pop(0)' ],\n            // beware of .reverse() in python, because opposed to JS, python does in-place, so \n            // only cases like `x = x.reverse ()` should be transpiled, which will resul as \n            // `x.reverse()` in python. otherwise, if transpiling `x = y.reverse()`, then the\n            // left side `x = `will be removed and only `y.reverse()` will end up in python\n            [ /\\s+(\\w+)\\s\\=\\s(.*?)\\.reverse\\s\\(/g, '$2.reverse(' ], \n            [ /Number\\.MAX_SAFE_INTEGER/g, 'float(\\'inf\\')'],\n            [ /function\\s*(\\w+\\s*\\([^)]+\\))\\s*{/g, 'def $1:'],\n            // [ /\\.replaceAll\\s*\\(([^)]+)\\)/g, '.replace($1)' ], // still not a part of the standard\n            [ /replaceAll\\s*/g, 'replace'],\n            [ /assert\\s*\\((.+)\\);/g, 'assert $1'],\n            [ /Promise\\.all\\s*\\(([^\\)]+)\\)/g, 'asyncio.gather(*$1)' ],\n            [ /Precise\\.stringAdd\\s/g, 'Precise.string_add' ],\n            [ /Precise\\.stringMul\\s/g, 'Precise.string_mul' ],\n            [ /Precise\\.stringDiv\\s/g, 'Precise.string_div' ],\n            [ /Precise\\.stringSub\\s/g, 'Precise.string_sub' ],\n            [ /Precise\\.stringAbs\\s/g, 'Precise.string_abs' ],\n            [ /Precise\\.stringNeg\\s/g, 'Precise.string_neg' ],\n            [ /Precise\\.stringMod\\s/g, 'Precise.string_mod' ],\n            [ /Precise\\.stringEquals\\s/g, 'Precise.string_equals' ],\n            [ /Precise\\.stringEq\\s/g, 'Precise.string_eq' ],\n            [ /Precise\\.stringMin\\s/g, 'Precise.string_min' ],\n            [ /Precise\\.stringMax\\s/g, 'Precise.string_max' ],\n            [ /Precise\\.stringGt\\s/g, 'Precise.string_gt' ],\n            [ /Precise\\.stringGe\\s/g, 'Precise.string_ge' ],\n            [ /Precise\\.stringLt\\s/g, 'Precise.string_lt' ],\n            [ /Precise\\.stringLe\\s/g, 'Precise.string_le' ],\n            [ /Precise\\.stringOr\\s/g, 'Precise.string_or' ],\n            [ /\\.padEnd\\s/g, '.ljust'],\n            [ /\\.padStart\\s/g, '.rjust' ],\n\n        // insert common regexes in the middle (critical)\n        ].concat (this.getCommonRegexes ()).concat ([\n\n            // [ /this\\.urlencode\\s/g, '_urlencode.urlencode ' ], // use self.urlencode instead\n            [ /([a-zA-Z0-9_]+) in this(:?[^.])/g, 'hasattr(self, $1)$2' ],\n            // [ /this\\[[a-zA-Z0-9_]+\\]/g, 'getattr(self, $1)' ],\n            [ /this\\[([a-zA-Z0-9_]+)\\] = (.*?);/g, 'setattr(self, $1, $2)' ],\n            [ /this\\./g, 'self.' ],\n            [ /([^a-zA-Z\\'])this([^a-zA-Z])/g, '$1self$2' ],\n            [ /\\[\\s*([^\\]]+)\\s\\]\\s=/g, '$1 =' ],\n            [ /((?:let|const|var) \\w+\\: )([0-9a-zA-Z]+)\\[\\]/, '$1List[$2]' ],  // typed variable with list type\n            [ /((?:let|const|var) \\w+\\: )([0-9a-zA-Z]+)\\[\\]\\[\\]/, '$1List[List[$2]]' ],  // typed variables with double list type\n            [ /(^|[^a-zA-Z0-9_])(?:let|const|var)\\s\\[\\s*([^\\]]+)\\s\\]/g, '$1$2' ],\n            [ /(^|[^a-zA-Z0-9_])(?:let|const|var)\\s\\{\\s*([^\\}]+)\\s\\}\\s\\=\\s([^\\;]+)/g, '$1$2 = (lambda $2: ($2))(**$3)' ],\n            [ /(^|[^a-zA-Z0-9_])(?:let|const|var)\\s/g, '$1' ],\n            [ /Object\\.keys\\s*\\((.*)\\)\\.length/g, '$1' ],\n            [ /Object\\.keys\\s*\\((.*)\\)/g, 'list($1.keys())' ],\n            [ /Object\\.values\\s*\\((.*)\\)/g, 'list($1.values())' ],\n            [ /\\[([^\\]]+)\\]\\.join\\s*\\(([^\\)]+)\\)/g, \"$2.join([$1])\" ],\n            [ /hash\\s*\\(([^,]+)\\, \\'(sha[0-9])\\'/g, \"hash($1, '$2'\" ],\n            [ /hmac\\s*\\(([^,]+)\\, ([^,]+)\\, \\'(md5)\\'/g, 'hmac($1, $2, hashlib.$3' ],\n            [ /hmac\\s*\\(([^,]+)\\, ([^,]+)\\, \\'(sha[0-9]+)\\'/g, 'hmac($1, $2, hashlib.$3' ],\n            [ /throw new ([\\S]+) \\((.*)\\)/g, 'raise $1($2)'],\n            [ /throw ([\\S]+)/g, 'raise $1'],\n            [ /try {/g, 'try:'],\n            [ /\\}\\s+catch \\(([\\S]+)\\) {/g, 'except Exception as $1:'],\n            [ /([\\s\\(])extend(\\s)/g, '$1self.extend$2' ],\n            [ /\\} else if/g, 'elif' ],\n            [ /else if/g, 'elif' ],\n            [ /if\\s+\\((.*)\\)\\s+\\{/g, 'if $1:' ],\n            [ /if\\s+\\((.*)\\)\\s*[\\n]/g, \"if $1:\\n\" ],\n            [ /\\}\\s*else\\s*\\{/g, 'else:' ],\n            [ /else\\s*[\\n]/g, \"else:\\n\" ],\n            [ /for\\s+\\(([a-zA-Z0-9_]+)\\s*=\\s*([^\\;\\s]+\\s*)\\;[^\\<\\>\\=]+(?:\\<=|\\>=|<|>)\\s*(.*)\\.length\\s*\\;[^\\)]+\\)\\s*{/g, 'for $1 in range($2, len($3)):'],\n            [ /for\\s+\\(([a-zA-Z0-9_]+)\\s*=\\s*([^\\;\\s]+\\s*)\\;[^\\<\\>\\=]+(?:\\<=|\\>=|<|>)\\s*(.*)\\s*\\;[^\\)]+\\)\\s*{/g, 'for $1 in range($2, $3):'],\n            [ /\\s\\|\\|\\s/g, ' or ' ],\n            [ /\\s\\&\\&\\s/g, ' and ' ],\n            [ /\\!([^\\s\\='\"])/g, 'not $1'],\n            [ /\\.push\\s*\\(([\\s\\S]+?)\\);/g, '.append($1);' ],\n            [ /^(\\s*}\\s*$)+/gm, '' ],\n            [ /\\;(\\s+?\\/\\/.+?)/g, '$1' ],\n            [ /\\;$/gm, '' ],\n            [ /\\.toUpperCase\\s*/g, '.upper' ],\n            [ /\\.toLowerCase\\s*/g, '.lower' ],\n            [ /\\.startsWith\\s*/g, '.startswith' ],\n            [ /\\.endsWith\\s*/g, '.endswith' ],\n            [ /\\.trim\\s*/g, '.strip' ],\n            [ /(\\b)String(\\b)/g, '$1str$2'],\n            [ /JSON\\.stringify\\s*/g, 'json.dumps' ],\n            [ /JSON\\.parse\\s*/g, \"json.loads\" ],\n            // [ /([^\\(\\s]+)\\.includes\\s+\\(([^\\)]+)\\)/g, '$2 in $1' ],\n            // [ /\\'%([^\\']+)\\'\\.sprintf\\s*\\(([^\\)]+)\\)/g, \"'{:$1}'.format($2)\" ],\n            [ /([^\\s]+)\\.toFixed\\s*\\(([0-9]+)\\)/g, \"format($1, '.$2f')\" ],\n            [ /([^\\s]+)\\.toFixed\\s*\\(([^\\)]+)\\)/g, \"format($1, '.' + str($2) + 'f')\" ],\n            [ /parseFloat\\s*/g, 'float'],\n            [ /parseInt\\s*/g, 'int'],\n            [ /self\\[([^\\]+]+)\\]/g, 'getattr(self, $1)' ],\n            [ /Math\\.floor\\s*\\(([^\\)]+)\\)/g, 'int(math.floor($1))' ],\n            [ /Math\\.abs\\s*\\(([^\\)]+)\\)/g, 'abs($1)' ],\n            [ /Math\\.pow\\s*\\(([^\\)]+)\\)/g, 'math.pow($1)' ],\n            [ /Math\\.round\\s*\\(([^\\)]+)\\)/g, 'int(round($1))' ],\n            [ /Math\\.ceil\\s*\\(([^\\)]+)\\)/g, 'int(math.ceil($1))' ],\n            [ /Math\\.log/g, 'math.log' ],\n            [ /([a-zA-Z0-9_\\.]*\\([^\\)]+\\)|[^\\s]+)\\s+\\?\\s*([^\\:]+)\\s+\\:\\s*([^\\n]+)/g, '$2 if $1 else $3'],\n            [ /([^\\s]+)\\.slice \\(([^\\,\\)]+)\\,\\s?([^\\)]+)\\)/g, '$1[$2:$3]' ],\n            [ /([^\\s]+)\\.slice \\(([^\\)\\:]+)\\)/g, '$1[$2:]' ],\n            [ /([^\\s(:]+)\\.length/g, 'len($1)' ],\n            [ /(^|\\s)\\/\\//g, '$1#' ],\n            [ /([^\\n\\s]) #/g, '$1  #' ],   // PEP8 E261\n            [ /\\.indexOf/g, '.find'],\n            [ /(\\s|\\()true/g, '$1True'],\n            [ /(\\s|\\()false/g, '$1False'],\n            [ /([^\\s]+\\s*\\(\\))\\.toString\\s+\\(\\)/g, 'str($1)' ],\n            [ /([^\\s]+)\\.toString \\(\\)/g, 'str($1)' ],\n            [ /([^\\s]+)\\.join\\s*\\(\\s*([^\\)\\[\\]]+?)\\s*\\)/g, '$2.join($1)' ],\n            [ /Math\\.(max|min)\\s/g, '$1' ],\n            [ / = new /g, ' = ' ], // python does not have a 'new' keyword\n            [ /console\\.log\\s/g, 'print' ],\n            [ /process\\.exit\\s+/g, 'sys.exit' ],\n            [ /(while \\(.*\\)) {/, '$1\\:' ], // While loops replace bracket with :\n            [ /([^:+=\\/\\*\\s-]+) \\(/g, '$1(' ], // PEP8 E225 remove whitespaces before left ( round bracket\n            [ /\\sand\\(/g, ' and (' ],\n            [ /\\sor\\(/g, ' or (' ],\n            [ /\\snot\\(/g, ' not (' ],\n            [ /\\[ /g, '[' ],              // PEP8 E201 remove whitespaces after left [ square bracket\n            [ /\\{ /g, '{' ],              // PEP8 E201 remove whitespaces after left { bracket\n            [ /(?<=[^\\s#]) \\]/g, ']' ],    // PEP8 E202 remove whitespaces before right ] square bracket\n            [ /(?<=[^\\s#]) \\}/g, '}' ],    // PEP8 E202 remove whitespaces before right } bracket\n            [ /([^a-z\\_])(elif|if|or|else)\\(/g, '$1$2 \\(' ], // a correction for PEP8 E225 side-effect for compound and ternary conditionals\n            [ /\\!\\=\\sTrue/g, 'is not True' ], // a correction for PEP8 E712, it likes \"is not True\", not \"!= True\"\n            [ /\\=\\=\\sTrue/g, 'is True' ], // a correction for PEP8 E712, it likes \"is True\", not \"== True\"\n            [ /\\sdelete\\s/g, ' del ' ],\n            [ /(?<!#.+)null/, 'None' ],\n            [ /\\/\\*\\*/, '\\\"\\\"\\\"' ], // Doc strings\n            [ / \\*\\//, '\\\"\\\"\\\"' ], // Doc strings\n            [ /\\[([^\\[\\]]*)\\]\\{@link (.*)\\}/g, '`$1 <$2>`' ], // docstring item with link\n            [ /\\s+\\* @method/g, '' ], // docstring @method\n            [ /(\\s+) \\* @description (.*)/g, '$1$2' ], // docstring description\n            [ /\\s+\\* @name .*/g, '' ], // docstring @name\n            [ /(\\s+) \\* @see( .*)/g, '$1:see:$2' ], // docstring @see\n            [ /(\\s+ \\* @(param|returns) {[^}]*)string(\\[\\])?([^}]*}.*)/g, '$1str$3$4' ], // docstring type conversion\n            [ /(\\s+ \\* @(param|returns) {[^}]*)object(\\[\\])?([^}]*}.*)/g, '$1dict$3$4' ], // docstring type conversion\n            [ /(\\s+) \\* @returns ([^\\{])/g, '$1:returns: $2' ], // docstring return\n            [ /(\\s+) \\* @returns \\{(.+)\\}/g, '$1:returns $2:' ], // docstring return\n            [ /(\\s+ \\* @param \\{[\\]\\[\\|a-zA-Z]+\\} )([a-zA-Z0-9_-]+)\\.([a-zA-Z0-9_-]+) (.*)/g, '$1$2[\\'$3\\'] $4' ], // docstring params.anything\n            [ /(\\s+) \\* @([a-z]+) \\{([\\]\\[a-zA-Z\\|]+)\\} ([a-zA-Z0-9_\\-\\.\\[\\]\\']+)/g, '$1:$2 $3 $4:' ], // docstring param\n        ])\n    }"
            },
            {
                "name": "this.regexAll",
                "code": "regexAll (text, array) {\n        for (const i in array) {\n            let regex = array[i][0]\n            let replaceStringOrCallback = array[i][1]\n            const flags = (typeof regex === 'string') ? 'g' : undefined\n            regex = new RegExp (regex, flags)\n            if (typeof array[i][1] !== 'function') {\n                text = text.replace (regex, replaceStringOrCallback)\n            } else {\n                text = text.replace (regex, function (matched) {\n                    return replaceStringOrCallback (matched)\n                })\n            }\n        }\n        return text\n    }"
            },
            {
                "name": "transpileJavaScriptToPython3",
                "code": "transpileJavaScriptToPython3 ({ js, className, removeEmptyLines }) {\n\n        // transpile JS \u2192 Python 3\n        let python3Body = this.regexAll (js, this.getPythonRegexes ())\n\n        if (removeEmptyLines) {\n            python3Body = python3Body.replace (/$\\s*$/gm, '')\n        }\n\n        const strippedPython3BodyWithoutComments = python3Body.replace (/^[\\s]+#.+$/gm, '')\n\n        if (!strippedPython3BodyWithoutComments.match(/[^\\s]/)) {\n            python3Body += '\\n        pass'\n        }\n\n        python3Body = python3Body.replace (/\\'([\u0430\u0431\u0432\u0433\u0434\u0435\u0451\u0436\u0437\u0438\u0439\u043a\u043b\u043c\u043d\u043e\u043f\u0440\u0441\u0442\u0443\u0444\u0445\u0446\u0447\u0448\u0449\u044a\u044b\u044c\u044d\u044e\u044f\u670d\u52a1\u7aef\u5fd9\u788c]+)\\'/gm, \"u'$1'\")\n\n        // special case for Python OrderedDicts\n        let orderedDictRegex = /\\.ordered\\s+\\(\\{([^\\}]+)\\}\\)/g\n        let orderedDictMatches = undefined\n        while (orderedDictMatches = orderedDictRegex.exec (python3Body)) {\n            let replaced = orderedDictMatches[1].replace (/^(\\s+)([^\\:]+)\\:\\s*([^\\,]+)\\,$/gm, '$1($2, $3),')\n            python3Body = python3Body.replace (orderedDictRegex, '\\.ordered([' + replaced + '])')\n        }\n\n        // snake case function names\n        python3Body = python3Body.replace (/def (\\w+)/g, (match, group1) => 'def ' + unCamelCase (group1))\n\n        // special case for Python super\n        if (className) {\n            python3Body = python3Body.replace (/super\\./g, 'super(' + className + ', self).')\n        }\n\n        return python3Body\n    }\n\n    // ------------------------------------"
            }
        ],
        "third_party": [
            "unCamelCase",
            "orderedDictRegex.exec",
            "orderedDictMatches[1].replace",
            "strippedPython3BodyWithoutComments.match",
            "python3Body.replace"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "function isMainEntry(metaUrl)",
        "start_line": "2672",
        "end_line": "2685",
        "file_path": "build/transpile.js",
        "docstring": "The function isMainEntry(metaUrl) checks if the current module is the main entry point of the application.\\nIt first verifies if the import.meta.url starts with 'file:'.\\nIf true, it converts the metaUrl to a file path using url.fileURLToPath.\\nIt then compares this module path to process.argv[1], which holds the script file executed by Node.js.\\nIf they match, the function returns true, indicating that the module is the main entry.\\nIt also checks if the module path matches process.argv[1] without the .js extension and returns true if they match.\\nIf neither condition is met, the function returns false.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c854a8edbe64",
        "ground_truth": "function isMainEntry(metaUrl) {\n    // https://exploringjs.com/nodejs-shell-scripting/ch_nodejs-path.html#detecting-if-module-is-main\n    if (import.meta.url.startsWith('file:')) {\n        const modulePath = url.fileURLToPath(metaUrl);\n        if (process.argv[1] === modulePath) {\n            return true;\n        }\n        // when called without .js extension\n        if (process.argv[1] === modulePath.replace('.js','')) {\n            return true;\n        }\n    }\n    return false;\n}",
        "import_statements": [
            "fs",
            "path",
            "ololog",
            "ansicolor",
            "util",
            "../js/src/base/errors.js",
            "../js/src/base/functions.js",
            "../js/src/base/Exchange.js",
            "path",
            "./fsLocal.js",
            "url",
            "../js/src/base/errorHierarchy.js",
            "process",
            "os",
            "child_process",
            "node:url",
            "piscina",
            "ast-transpiler"
        ],
        "reference_api": [
            "import.meta.url.startsWith",
            "modulePath.replace",
            "url.fileURLToPath"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "import.meta.url.startsWith",
            "modulePath.replace",
            "url.fileURLToPath"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public virtual object safeListN(object dictionaryOrList, object keys, object defaultValue = null)",
        "start_line": "89",
        "end_line": "107",
        "file_path": "cs/ccxt/base/Exchange.BaseMethods.cs",
        "docstring": "The function safeListN(object dictionaryOrList, object keys, object defaultValue = null) safely extracts a list from a dictionary or list.\\nIt first retrieves a value using the safeValueN method with the provided dictionary or list, keys, and default value.\\nIf the retrieved value is null, it returns the default value.\\nIf the retrieved value is a list or an object of a generic list type, it returns the value.\\nOtherwise, it returns the default value.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ff4a04a3cb5b",
        "ground_truth": "public virtual object safeListN(object dictionaryOrList, object keys, object defaultValue = null)\n{\n    /**\n     * @ignore\n     * @method\n     * @description safely extract an Array from dictionary or list\n     * @returns {Array | undefined}\n     */\n    object value = this.safeValueN(dictionaryOrList, keys, defaultValue);\n    if (isTrue(isEqual(value, null)))\n    {\n        return defaultValue;\n    }\n    if (isTrue(((value is IList<object>) || (value.GetType().IsGenericType && value.GetType().GetGenericTypeDefinition().IsAssignableFrom(typeof(List<>))))))\n    {\n        return value;\n    }\n    return defaultValue;\n}",
        "import_statements": [],
        "reference_api": [
            "isEqual",
            "value.GetType().GetGenericTypeDefinition().IsAssignableFrom",
            "value.GetType",
            "this.safeValueN",
            "isTrue",
            "value.GetType().GetGenericTypeDefinition"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "isEqual",
            "value.GetType().GetGenericTypeDefinition().IsAssignableFrom",
            "value.GetType",
            "this.safeValueN",
            "isTrue",
            "value.GetType().GetGenericTypeDefinition"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public virtual object findMessageHashes(WebSocketClient client, object element)",
        "start_line": "349",
        "end_line": "362",
        "file_path": "cs/ccxt/base/Exchange.BaseMethods.cs",
        "docstring": "The function findMessageHashes(WebSocketClient client, object element) searches for message hashes in a WebSocketClient that contain a specified element.\\nIt initializes an empty list called result to store the matching message hashes.\\nThe function retrieves all message hashes from the client's futures dictionary keys and iterates through them.\\nFor each message hash, it checks if the element is present within the hash by verifying if the index is greater than or equal to 0.\\nIf the element is found in the message hash, it adds the hash to the result list.\\nFinally, the function returns the list of matching message hashes.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "925ce0ae7899",
        "ground_truth": "public virtual object findMessageHashes(WebSocketClient client, object element)\n{\n    object result = new List<object>() {};\n    object messageHashes = new List<object>(((IDictionary<string, ccxt.Exchange.Future>)client.futures).Keys);\n    for (object i = 0; isLessThan(i, getArrayLength(messageHashes)); postFixIncrement(ref i))\n    {\n        object messageHash = getValue(messageHashes, i);\n        if (isTrue(isGreaterThanOrEqual(getIndexOf(messageHash, element), 0)))\n        {\n            ((IList<object>)result).Add(messageHash);\n        }\n    }\n    return result;\n}",
        "import_statements": [],
        "reference_api": [
            "isLessThan",
            "((IList<object>)result).Add",
            "getValue",
            "postFixIncrement",
            "getIndexOf",
            "isTrue",
            "isGreaterThanOrEqual",
            "getArrayLength"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "isLessThan",
            "((IList<object>)result).Add",
            "getValue",
            "postFixIncrement",
            "getIndexOf",
            "isTrue",
            "isGreaterThanOrEqual",
            "getArrayLength"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public virtual object filterByLimit(object array, object limit = null, object key = null, object fromStart = null)",
        "start_line": "364",
        "end_line": "397",
        "file_path": "cs/ccxt/base/Exchange.BaseMethods.cs",
        "docstring": "The function filterByLimit filters an array based on a specified limit, sorting key, and direction.\\nIt sets default values for the key as \"timestamp\" and fromStart as false.\\nIf the limit is defined, it checks the length of the array and proceeds if the array is not empty.\\nThe function determines if the array is sorted in ascending order based on the key by comparing the first and last elements.\\nDepending on the fromStart flag and the array's order, it slices the array accordingly:\\n- If fromStart is true and the limit exceeds the array length, it adjusts the limit to the array length.\\n- It slices the array from the start or end based on the ascending order and fromStart flag.\\nFinally, it returns the filtered array.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cf1747b4e0bc",
        "ground_truth": "public virtual object filterByLimit(object array, object limit = null, object key = null, object fromStart = null)\n{\n    key ??= \"timestamp\";\n    fromStart ??= false;\n    if (isTrue(this.valueIsDefined(limit)))\n    {\n        object arrayLength = getArrayLength(array);\n        if (isTrue(isGreaterThan(arrayLength, 0)))\n        {\n            object ascending = true;\n            if (isTrue((inOp(getValue(array, 0), key))))\n            {\n                object first = getValue(getValue(array, 0), key);\n                object last = getValue(getValue(array, subtract(arrayLength, 1)), key);\n                if (isTrue(isTrue(!isEqual(first, null)) && isTrue(!isEqual(last, null))))\n                {\n                    ascending = isLessThanOrEqual(first, last); // true if array is sorted in ascending order based on 'timestamp'\n                }\n            }\n            if (isTrue(fromStart))\n            {\n                if (isTrue(isGreaterThan(limit, arrayLength)))\n                {\n                    limit = arrayLength;\n                }\n                array = ((bool) isTrue(ascending)) ? this.arraySlice(array, 0, limit) : this.arraySlice(array, prefixUnaryNeg(ref limit));\n            } else\n            {\n                array = ((bool) isTrue(ascending)) ? this.arraySlice(array, prefixUnaryNeg(ref limit)) : this.arraySlice(array, 0, limit);\n            }\n        }\n    }\n    return array;\n}",
        "import_statements": [],
        "reference_api": [
            "isEqual",
            "this.arraySlice",
            "this.valueIsDefined",
            "getValue",
            "isGreaterThan",
            "subtract",
            "isLessThanOrEqual",
            "inOp",
            "isTrue",
            "prefixUnaryNeg",
            "getArrayLength"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "isEqual",
            "this.arraySlice",
            "this.valueIsDefined",
            "getValue",
            "isGreaterThan",
            "subtract",
            "isLessThanOrEqual",
            "inOp",
            "isTrue",
            "prefixUnaryNeg",
            "getArrayLength"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public async virtual Task<object> fetchMarginMode(object symbol, object parameters = null)",
        "start_line": "601",
        "end_line": "612",
        "file_path": "cs/ccxt/base/Exchange.BaseMethods.cs",
        "docstring": "The function fetchMarginMode asynchronously fetches the margin mode for a given trading symbol.\\nIt initializes parameters to an empty dictionary if not provided.\\nThe function checks if the exchange supports fetching margin modes by evaluating this.has[\"fetchMarginModes\"].\\nIf supported, it calls fetchMarginModes with the symbol and parameters, awaits the result, and returns the margin mode for the symbol using safeDict.\\nIf fetching margin modes is not supported, it throws a NotSupported exception indicating the feature is not available for the current exchange.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "2d707f4c211b",
        "ground_truth": "public async virtual Task<object> fetchMarginMode(object symbol, object parameters = null)\n{\n    parameters ??= new Dictionary<string, object>();\n    if (isTrue(getValue(this.has, \"fetchMarginModes\")))\n    {\n        object marginModes = await this.fetchMarginModes(new List<object>() {symbol}, parameters);\n        return this.safeDict(marginModes, symbol);\n    } else\n    {\n        throw new NotSupported ((string)add(this.id, \" fetchMarginMode() is not supported yet\")) ;\n    }\n}",
        "import_statements": [],
        "reference_api": [
            "getValue",
            "this.fetchMarginModes",
            "this.safeDict",
            "isTrue",
            "add"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "getValue",
            "this.fetchMarginModes",
            "this.safeDict",
            "isTrue",
            "add"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public static Int64 CalculateCrc32(string data, bool signed, int? bound = null)",
        "start_line": "484",
        "end_line": "505",
        "file_path": "cs/ccxt/base/Exchange.Crypto.cs",
        "docstring": "The function CalculateCrc32(string data, bool signed, int? bound = null) calculates the CRC32 checksum of a given string.\\nIt initializes a checksum table using the polynomial 0xEDB88320.\\nThe table is built by iterating through all possible byte values and applying bitwise operations.\\nThe function converts the input string to an ASCII byte array and computes the CRC32 checksum using the precomputed table.\\nIt starts with an initial value of 0xFFFFFFFF and processes each byte of the input data.\\nThe final checksum is bitwise complemented and returned as a signed or unsigned 64-bit integer, based on the signed parameter.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "250231128e1b",
        "ground_truth": "public static Int64 CalculateCrc32(string data, bool signed, int? bound = null)\n{\n    // https://gist.github.com/martin31821/6a4736521043233bf7cdc05aa785149d\n    var s_generator = 0xEDB88320;\n    var m_checksumTable = Enumerable.Range(0, 256).Select(i =>\n    {\n        var tableEntry = (uint)i;\n        for (var j = 0; j < 8; ++j)\n        {\n            tableEntry = ((tableEntry & 1) != 0)\n                ? (s_generator ^ (tableEntry >> 1))\n                : (tableEntry >> 1);\n        }\n        return tableEntry;\n    }).ToArray();\n    var arrayOfBytes = Encoding.ASCII.GetBytes(data);\n    var result = ~arrayOfBytes.Aggregate(0xFFFFFFFF, (checksumRegister, currentByte) =>\n                  (m_checksumTable[(checksumRegister & 0xFF) ^ Convert.ToByte(currentByte)] ^ (checksumRegister >> 8)));\n    return (!signed) ? Convert.ToInt64(result) : Convert.ToInt64((int)result);\n}",
        "import_statements": [
            "using System.Text",
            "using System.Security.Cryptography",
            "using System.IO.Compression",
            "using Cryptography.ECDSA",
            "using Nethereum.Util",
            "using Org.BouncyCastle.Crypto.Parameters",
            "using Org.BouncyCastle.OpenSsl",
            "using Org.BouncyCastle.Asn1.Nist",
            "using Org.BouncyCastle.Crypto.Signers",
            "using Org.BouncyCastle.Crypto.Generators",
            "using Org.BouncyCastle.Crypto",
            "using Org.BouncyCastle.Security"
        ],
        "reference_api": [
            "Encoding.ASCII.GetBytes",
            "Enumerable.Range(0, 256).Select(i =>\n        {\n            var tableEntry = (uint)i;\n            for (var j = 0; j < 8; ++j)\n            {\n                tableEntry = ((tableEntry & 1) != 0)\n                    ? (s_generator ^ (tableEntry >> 1))\n                    : (tableEntry >> 1);\n            }\n            return tableEntry;\n        }).ToArray",
            "Enumerable.Range(0, 256).Select",
            "arrayOfBytes.Aggregate",
            "Enumerable.Range",
            "Convert.ToInt64",
            "Convert.ToByte"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "Encoding.ASCII.GetBytes",
            "Enumerable.Range(0, 256).Select(i =>\n        {\n            var tableEntry = (uint)i;\n            for (var j = 0; j < 8; ++j)\n            {\n                tableEntry = ((tableEntry & 1) != 0)\n                    ? (s_generator ^ (tableEntry >> 1))\n                    : (tableEntry >> 1);\n            }\n            return tableEntry;\n        }).ToArray",
            "Enumerable.Range(0, 256).Select",
            "arrayOfBytes.Aggregate",
            "Enumerable.Range",
            "Convert.ToInt64",
            "Convert.ToByte"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public static byte[] SignP256(object msg, string pemPrivateKey, string hashName, out int recoveryId)",
        "start_line": "641",
        "end_line": "658",
        "file_path": "cs/ccxt/base/Exchange.Crypto.cs",
        "docstring": "The function SignP256 signs a message using the P-256 elliptic curve and a given PEM-encoded private key.\\nIt defines a delegate function to return the hash algorithm name.\\nThe function retrieves the curve parameters for P-256 and converts the message to a UTF-8 byte array.\\nIt reads the PEM-encoded private key and converts it to an ECDsa object.\\nThe message is then signed using SHA-256, producing a signature.\\nThe function also hashes the message using a specified hash algorithm.\\nIt initializes an ECDsaSigner object and sets the recoveryId to 0.\\nThe function extracts the 'r' and 's' components from the signature and returns the signature byte array.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "e33a4ebbc369",
        "ground_truth": "public static byte[] SignP256(object msg, string pemPrivateKey, string hashName, out int recoveryId)\n{\n    string algoDelegate() => hashName as string;\n    var curveParams = NistNamedCurves.GetByName(\"P-256\");\n    var rawBytes = Encoding.UTF8.GetBytes((string)msg);\n    var ecPrivateKeyParameters = ReadPemPrivateKey(pemPrivateKey, curveParams);\n    ECDsa ecdsa = ConvertToECDsa(ecPrivateKeyParameters);\n    byte[] signature = ecdsa.SignData(rawBytes, HashAlgorithmName.SHA256);\n    var hashed = HashBytes(msg, algoDelegate);\n    var signer = new ECDsaSigner();\n    recoveryId = 0; // check this later;\n    var r = signature.Take(32).ToArray();\n    var s = signature.Skip(32).ToArray();\n    return signature;\n}",
        "import_statements": [
            "using System.Text",
            "using System.Security.Cryptography",
            "using System.IO.Compression",
            "using Cryptography.ECDSA",
            "using Nethereum.Util",
            "using Org.BouncyCastle.Crypto.Parameters",
            "using Org.BouncyCastle.OpenSsl",
            "using Org.BouncyCastle.Asn1.Nist",
            "using Org.BouncyCastle.Crypto.Signers",
            "using Org.BouncyCastle.Crypto.Generators",
            "using Org.BouncyCastle.Crypto",
            "using Org.BouncyCastle.Security"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "private static ECPrivateKeyParameters ReadPemPrivateKey(string pemContents, Org.BouncyCastle.Asn1.X9.X9ECParameters curveParameters)",
        "start_line": "659",
        "end_line": "678",
        "file_path": "cs/ccxt/base/Exchange.Crypto.cs",
        "docstring": "The function ReadPemPrivateKey(string pemContents, Org.BouncyCastle.Asn1.X9.X9ECParameters curveParameters) reads and extracts an EC private key from a PEM-encoded string.\\nIt initializes a StringReader with the PEM contents and creates a PemReader to read the PEM object.\\nIf the PEM object is an AsymmetricCipherKeyPair, it extracts the private key parameters as ECPrivateKeyParameters.\\nIt then creates and returns a new ECPrivateKeyParameters object with the extracted private key and the provided curve parameters.\\nIf the PEM object does not contain an EC private key in the expected format, it throws an InvalidCastException.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "88ee55f3c8d7",
        "ground_truth": "private static ECPrivateKeyParameters ReadPemPrivateKey(string pemContents, Org.BouncyCastle.Asn1.X9.X9ECParameters curveParameters)\n{\n    using (TextReader textReader = new StringReader(pemContents))\n    {\n        PemReader pemReader = new PemReader(textReader);\n        object pemObject = pemReader.ReadObject();\n        // Handling AsymmetricCipherKeyPair\n        if (pemObject is Org.BouncyCastle.Crypto.AsymmetricCipherKeyPair keyPair)\n        {\n            // return keyPair.Private as ECPrivateKeyParameters;\n            var privateKeyParameters = keyPair.Private as ECPrivateKeyParameters;\n            return new ECPrivateKeyParameters(privateKeyParameters.D, new ECDomainParameters(curveParameters.Curve, curveParameters.G, curveParameters.N, curveParameters.H, curveParameters.GetSeed()));\n        }\n        else\n        {\n            throw new InvalidCastException(\"The PEM file does not contain an EC private key in an expected format.\");\n        }\n    }\n}",
        "import_statements": [
            "using System.Text",
            "using System.Security.Cryptography",
            "using System.IO.Compression",
            "using Cryptography.ECDSA",
            "using Nethereum.Util",
            "using Org.BouncyCastle.Crypto.Parameters",
            "using Org.BouncyCastle.OpenSsl",
            "using Org.BouncyCastle.Asn1.Nist",
            "using Org.BouncyCastle.Crypto.Signers",
            "using Org.BouncyCastle.Crypto.Generators",
            "using Org.BouncyCastle.Crypto",
            "using Org.BouncyCastle.Security"
        ],
        "reference_api": [
            "pemReader.ReadObject",
            "curveParameters.GetSeed"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "pemReader.ReadObject",
            "curveParameters.GetSeed"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": " private object[] ConvertToArray(object obj)",
        "start_line": "23",
        "end_line": "39",
        "file_path": "cs/ccxt/base/Exchange.ETH.cs",
        "docstring": "The function ConvertToArray(object obj) converts a given object to an array of objects.\\nIt first casts the input object to an IList of objects and then converts it to an array.\\nFor each item in the array, it checks if the item is a dictionary or a list of objects.\\nIf the item is a list of objects, it recursively converts the item to an array using ConvertToArray.\\nThe function returns the resulting array of objects.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f04cb83c08ed",
        "ground_truth": "private object[] ConvertToArray(object obj)\n{\n    var array = (obj as IList<object>).ToArray();\n    for (var i = 0; i < array.Length; i++)\n    {\n        var item = array[i];\n        if (item is IDictionary<string, object>)\n        {\n            // array[i] = ConvertToDictionary(item);\n        }\n        else if (item is IList<object>)\n        {\n            array[i] = ConvertToArray(item);\n        }\n    }\n    return array;\n}",
        "import_statements": [
            "using Nethereum.ABI",
            "using Nethereum.ABI.Model",
            "using Nethereum",
            "using Nethereum.ABI.ABIDeserialisation",
            "using Nethereum.ABI.EIP712",
            "using Nethereum.Signer.EIP712",
            "using System.Linq",
            "using System.Text",
            "using System.Numerics"
        ],
        "reference_api": [
            "(obj as IList<object>).ToArray",
            "ConvertToArray"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "ConvertToArray",
                "code": "private object[] ConvertToArray(object obj)\n    {\n        var array = (obj as IList<object>).ToArray();\n        for (var i = 0; i < array.Length; i++)\n        {\n            var item = array[i];\n            if (item is IDictionary<string, object>)\n            {\n                // array[i] = ConvertToDictionary(item);\n            }\n            else if (item is IList<object>)\n            {\n                array[i] = ConvertToArray(item);\n            }\n        }\n        return array;\n    }"
            }
        ],
        "third_party": [
            "(obj as IList<object>).ToArray"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public static byte[] ConvertHexStringToByteArray(string hexString)",
        "start_line": "23",
        "end_line": "38",
        "file_path": "cs/ccxt/base/Exchange.Encode.cs",
        "docstring": "The function ConvertHexStringToByteArray(string hexString) converts a hexadecimal string to a byte array.\\nIt first checks if the length of the hex string is even, throwing an ArgumentException if it is not.\\nIt then initializes a byte array with a length of half the hex string length.\\nThe function iterates over the hex string in 2-character increments, converts each substring to a byte, and stores it in the byte array.\\nFinally, it returns the byte array.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "bce18a212bb8",
        "ground_truth": "public static byte[] ConvertHexStringToByteArray(string hexString)\n{\n    if (hexString.Length % 2 != 0)\n    {\n        throw new ArgumentException(\"The hex string must have an even number of characters.\", nameof(hexString));\n    }\n    byte[] bytes = new byte[hexString.Length / 2];\n    for (int i = 0; i < hexString.Length; i += 2)\n    {\n        string hexSubstring = hexString.Substring(i, 2);\n        bytes[i / 2] = Convert.ToByte(hexSubstring, 16);\n    }\n    return bytes;\n}",
        "import_statements": [
            "using System.Security.Cryptography",
            "using System.Text",
            "using Cryptography.ECDSA",
            "using MiniMessagePack",
            "using dict = Dictionary<string, object>",
            "using list = List<object>"
        ],
        "reference_api": [
            "Convert.ToByte",
            "nameof",
            "hexString.Substring"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "Convert.ToByte",
            "nameof",
            "hexString.Substring"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public string urlencodeWithArrayRepeat(object parameters)",
        "start_line": "182",
        "end_line": "203",
        "file_path": "cs/ccxt/base/Exchange.Encode.cs",
        "docstring": "The function urlencodeWithArrayRepeat(object parameters) converts a dictionary of parameters into a URL-encoded query string.\\nIt casts the input object to a dictionary and retrieves its keys as a list of strings.\\nIt initializes an output list to store key-value pairs.\\nFor each key, it checks if the associated value is a list of objects.\\nIf the value is a list, it iterates through the list and adds each key-item pair to the output list.\\nIf the value is not a list, it adds the key-value pair directly to the output list.\\nFinally, it joins the output list items with \"&\" and returns the resulting query string.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "e03c100d1267",
        "ground_truth": "public string urlencodeWithArrayRepeat(object parameters)\n{\n    var paramaters = (dict)parameters;\n    var keys = new List<string>(((dict)paramaters).Keys);\n    var outList = new List<object>();\n    foreach (string key in keys)\n    {\n        var value = paramaters[key];\n        if (value is IList<object>)\n        {\n            foreach (var item in (IList<object>)value)\n            {\n                outList.Add(key + \"=\" + item);\n            }\n        }\n        else\n        {\n            outList.Add(key + \"=\" + value);\n        }\n    }\n    return string.Join(\"&\", outList);\n}",
        "import_statements": [
            "using System.Security.Cryptography",
            "using System.Text",
            "using Cryptography.ECDSA",
            "using MiniMessagePack",
            "using dict = Dictionary<string, object>",
            "using list = List<object>"
        ],
        "reference_api": [
            "string.Join",
            "outList.Add"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "string.Join",
            "outList.Add"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public string urlencodeNested(object paramaters)",
        "start_line": "205",
        "end_line": "234",
        "file_path": "cs/ccxt/base/Exchange.Encode.cs",
        "docstring": "The function urlencodeNested(object paramaters) converts a nested dictionary into a URL-encoded query string.\\nIt initializes an empty query string using System.Web.HttpUtility.ParseQueryString.\\nIt retrieves the keys of the top-level dictionary and iterates through them.\\nFor each key, it checks if the corresponding value is a dictionary.\\nIf it is a nested dictionary, it retrieves the keys of this nested dictionary and iterates through them, adding key-value pairs to the query string in a nested format.\\nBoolean values are converted to lowercase strings (\"true\" or \"false\").\\nIf the value is not a dictionary, it adds the key-value pair directly to the query string.\\nFinally, it returns the URL-encoded query string.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "80f1c3785583",
        "ground_truth": "public string urlencodeNested(object paramaters)\n{\n    // stub check this out\n    var queryString = System.Web.HttpUtility.ParseQueryString(string.Empty);\n    var keys = new List<string>(((dict)paramaters).Keys);\n    foreach (string key in keys)\n    {\n        var value = ((dict)paramaters)[key];\n        if (value != null && value.GetType() == typeof(dict))\n        {\n            var keys2 = new List<string>(((dict)value).Keys);\n            foreach (string key2 in keys2)\n            {\n                var value2 = ((dict)value)[key2];\n                var finalValue = value2.ToString();\n                if (value2.GetType() == typeof(bool))\n                {\n                    finalValue = finalValue.ToLower(); // c# uses \"True\" and \"False\" instead of \"true\" and \"false\" $:(\n                }\n                queryString.Add(key + \"[\" + key2 + \"]\", finalValue);\n            }\n        }\n        else\n        {\n            queryString.Add(key, value.ToString());\n        }\n    }\n    return queryString.ToString();\n}",
        "import_statements": [
            "using System.Security.Cryptography",
            "using System.Text",
            "using Cryptography.ECDSA",
            "using MiniMessagePack",
            "using dict = Dictionary<string, object>",
            "using list = List<object>"
        ],
        "reference_api": [
            "value2.GetType",
            "System.Web.HttpUtility.ParseQueryString",
            "value2.ToString",
            "value.GetType",
            "value.ToString",
            "queryString.ToString",
            "queryString.Add",
            "finalValue.ToLower"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "value2.GetType",
            "System.Web.HttpUtility.ParseQueryString",
            "value2.ToString",
            "value.GetType",
            "value.ToString",
            "queryString.ToString",
            "queryString.Add",
            "finalValue.ToLower"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public object arrayConcat(object aa, object bb)",
        "start_line": "128",
        "end_line": "155",
        "file_path": "cs/ccxt/base/Exchange.Functions.cs",
        "docstring": "The function arrayConcat(object aa, object bb) concatenates two lists of objects or two lists of tasks into a single list.\\nIf the input objects aa and bb are lists of objects, it iterates through both lists, adding each element to a new output list, which it then returns.\\nIf the input objects are lists of tasks, it performs a similar operation, iterating through both lists of tasks, adding each task to a new output list of tasks, and then returns the concatenated list.\\nIf the input objects are neither lists of objects nor lists of tasks, the function returns null.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4902bd5b5805",
        "ground_truth": "public object arrayConcat(object aa, object bb)\n{\n    // if (aa.GetType() == typeof(List<object>))\n    if (aa is List<object>)\n    {\n        var a = (List<object>)aa;\n        var b = (List<object>)bb;\n        var outList = new List<object>();\n        foreach (object elem in a)\n            outList.Add(elem);\n        foreach (object elem in b)\n            outList.Add(elem);\n        return outList;\n    }\n    if (aa.GetType() == typeof(List<Task<object>>))\n    {\n        var a = (List<Task<object>>)aa;\n        var b = (List<Task<object>>)bb;\n        var outList = new List<Task<object>>();\n        foreach (var elem in a)\n            outList.Add(elem);\n        foreach (var elem in b)\n            outList.Add(elem);\n        return outList;\n    }\n    return null;\n}",
        "import_statements": [
            "using Newtonsoft.Json",
            "using System.Text.RegularExpressions",
            "using dict = Dictionary<string, object>"
        ],
        "reference_api": [
            "aa.GetType",
            "outList.Add"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "aa.GetType",
            "outList.Add"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public Precise(object number2, object dec2 = null)",
        "start_line": "15",
        "end_line": "41",
        "file_path": "cs/ccxt/base/Exchange.Precise.cs",
        "docstring": "The constructor Precise(object number2, object dec2 = null) initializes a Precise object with a number and optionally, a specified number of decimals.\\nIt converts dec2 to an integer if provided, otherwise sets it to Int32.MinValue.\\nThe number2 object is converted to a string.\\nIf dec2 is not provided, it checks for scientific notation in the number string and adjusts the number and decimal places accordingly.\\nIt removes the decimal point from the number and converts it to a BigInteger, storing the adjusted decimal places.\\nIf dec2 is provided, it directly converts the number to a BigInteger and uses the specified decimals.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7631d873e9ef",
        "ground_truth": "public Precise(object number2, object dec2 = null)\n{\n    var dec = (dec2 != null) ? Convert.ToInt32(dec2) : Int32.MinValue;\n    var number = number2.ToString();\n    if (dec == Int32.MinValue)\n    {\n        var modified = 0;\n        var numberLowerCase = ((string)number).ToLower();\n        if (numberLowerCase.IndexOf('e') > -1)\n        {\n            var parts = numberLowerCase.Split('e');\n            number = parts[0];\n            modified = int.Parse(parts[1]);\n        }\n        var decimalIndex = number.IndexOf('.');\n        var newDecimals = (decimalIndex > -1) ? number.Length - decimalIndex - 1 : 0;\n        this.decimals = newDecimals;\n        var integerString = number.Replace(\".\", \"\");\n        this.integer = BigInteger.Parse(integerString);\n        this.decimals = Convert.ToInt32(this.decimals) - modified;\n    }\n    else\n    {\n        this.integer = BigInteger.Parse(number);\n        this.decimals = dec;\n    }\n}",
        "import_statements": [
            "using System.Numerics"
        ],
        "reference_api": [
            "numberLowerCase.IndexOf",
            "((string)number).ToLower",
            "number2.ToString",
            "int.Parse",
            "number.Replace",
            "numberLowerCase.Split",
            "number.IndexOf",
            "BigInteger.Parse",
            "Convert.ToInt32"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "numberLowerCase.IndexOf",
            "((string)number).ToLower",
            "number2.ToString",
            "int.Parse",
            "number.Replace",
            "numberLowerCase.Split",
            "number.IndexOf",
            "BigInteger.Parse"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public Precise div(Precise other, object precision2 = null)",
        "start_line": "50",
        "end_line": "72",
        "file_path": "cs/ccxt/base/Exchange.Precise.cs",
        "docstring": "The function div(Precise other, object precision2 = null) performs division between two Precise objects with a specified precision.\\nIt sets the precision to 18 if not provided and calculates the distance between the current object's decimals and the other object's decimals, adjusted by the precision.\\nDepending on the distance value, it adjusts the numerator by multiplying or dividing the integer value by the appropriate power of 10.\\nIt then divides the adjusted numerator by the other object's integer value.\\nFinally, it returns a new Precise object initialized with the result and the specified precision.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "b4f76f8604a3",
        "ground_truth": "public Precise div(Precise other, object precision2 = null)\n{\n    precision2 = precision2 ?? 18;\n    var precision = Convert.ToInt32(precision2);\n    var distance = precision - Convert.ToInt32(this.decimals) + Convert.ToInt32(other.decimals);\n    BigInteger numerator = 0;\n    if (distance == 0)\n    {\n        numerator = this.integer;\n    }\n    else if (distance < 0)\n    {\n        var exponent = BigInteger.Pow(baseNumber, -distance);\n        numerator = this.integer / exponent;\n    }\n    else\n    {\n        var exponent = BigInteger.Pow(baseNumber, distance);\n        numerator = this.integer * exponent;\n    }\n    var result = numerator / other.integer;\n    return new Precise(result.ToString(), precision);\n}",
        "import_statements": [
            "using System.Numerics"
        ],
        "reference_api": [
            "BigInteger.Pow",
            "Convert.ToInt32",
            "result.ToString"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "BigInteger.Pow",
            "result.ToString"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "private void initHttpClient()",
        "start_line": "37",
        "end_line": "53",
        "file_path": "cs/ccxt/base/Exchange.cs",
        "docstring": "The function initHttpClient initializes the HttpClient for the instance based on proxy settings.\\nIt checks if an HTTP proxy is specified and not empty.\\nIf an HTTP proxy is present, it creates a WebProxy object with the HTTP proxy and initializes the HttpClient with an HttpClientHandler using this proxy.\\nIf no HTTP proxy is set but an HTTPS proxy is specified and not empty, it performs a similar initialization using the HTTPS proxy.\\nIf neither proxy is specified, it initializes the HttpClient without any proxy settings.\n",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "54b8ce500074",
        "ground_truth": "private void initHttpClient()\n{\n    if (this.httpProxy != null && this.httpProxy.ToString().Length > 0)\n    {\n        var proxy = new WebProxy(this.httpProxy.ToString());\n        this.httpClient = new HttpClient(new HttpClientHandler { Proxy = proxy });\n    }\n    else if (this.httpsProxy != null && this.httpsProxy.ToString().Length > 0)\n    {\n        var proxy = new WebProxy(this.httpsProxy.ToString());\n        this.httpClient = new HttpClient(new HttpClientHandler { Proxy = proxy });\n    }\n    else\n    {\n        this.httpClient = new HttpClient();\n    }\n}",
        "import_statements": [
            "using System.Text",
            "using System.Text.RegularExpressions",
            "using System.Globalization",
            "using System.Net",
            "using dict = Dictionary<string, object>"
        ],
        "reference_api": [
            "this.httpProxy.ToString",
            "this.httpsProxy.ToString"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "this.httpProxy.ToString",
            "this.httpsProxy.ToString"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public async virtual Task<object> callAsync(object implicitEndpoint2, object parameters = null)",
        "start_line": "354",
        "end_line": "373",
        "file_path": "cs/ccxt/base/Exchange.cs",
        "docstring": "The async function callAsync(object implicitEndpoint2, object parameters = null) performs an API call to a specified endpoint.\\nIt initializes parameters to an empty dictionary if not provided and casts the implicitEndpoint2 to a string.\\nIt checks if the transformedApi dictionary contains the specified endpoint, and if found, retrieves the endpoint information.\\nIt extracts the HTTP method, path, API, and cost from the endpoint information.\\nThe function then calls fetch2 with the extracted details, passing the parameters and cost, and awaits the result.\\nIf the endpoint is not found in the transformedApi dictionary, it throws an exception indicating the endpoint was not found.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "84bb7a6d0a10",
        "ground_truth": "public async virtual Task<object> callAsync(object implicitEndpoint2, object parameters = null)\n{\n    parameters ??= new Dictionary<string, object>();\n    var implicitEndpoint = (string)implicitEndpoint2;\n    if (this.transformedApi.TryGetValue(implicitEndpoint, out var info))\n    {\n        var endpointInfo = info as dict;\n        var method = endpointInfo[\"method\"] as String;\n        var path = endpointInfo[\"path\"] as String;\n        var api = endpointInfo[\"api\"];\n        var cost = endpointInfo[\"cost\"] != null ? endpointInfo[\"cost\"] : 1;\n        // return await this.fetch2(path, api, method, new dict(), new dict(), (dict)parameters, new dict { { \"cost\", cost } });\n        // var res = await this.fetch2(path, api, method, parameters, new dict(), new dict(), new dict { { \"cost\", cost } });\n        var res = await this.fetch2(path, api, method, parameters, new dict(), null, new dict { { \"cost\", cost } }); // body null here, does it make a difference?\n        return res;\n    }\n    throw new Exception(\"Endpoint not found!\");\n}",
        "import_statements": [
            "using System.Text",
            "using System.Text.RegularExpressions",
            "using System.Globalization",
            "using System.Net",
            "using dict = Dictionary<string, object>"
        ],
        "reference_api": [
            "this.fetch2",
            "this.transformedApi.TryGetValue"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "this.fetch2",
            "this.transformedApi.TryGetValue"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "public async virtual Task<object> loadMarketsHelper(bool reload = false, dict parameters = null)",
        "start_line": "414",
        "end_line": "434",
        "file_path": "cs/ccxt/base/Exchange.cs",
        "docstring": "The async function loadMarketsHelper(bool reload = false, dict parameters = null) loads market data, optionally forcing a reload.\\nIf reload is false and market data is already loaded (markets is not null), it checks if markets_by_id is null.\\nIf markets_by_id is null, it calls setMarkets with the existing markets and returns the result.\\nIf markets_by_id is not null, it returns the existing markets.\\nIf reload is true or market data is not loaded, it checks if the API supports fetching currencies (fetchCurrencies).\\nIf supported, it fetches the currencies.\\nIt then fetches the market data by calling fetchMarkets and calls setMarkets with the fetched markets and currencies, returning the result.",
        "language": "CSharp",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "be63bbb6ed3b",
        "ground_truth": "public async virtual Task<object> loadMarketsHelper(bool reload = false, dict parameters = null)\n{\n    if (!reload && this.markets != null)\n    {\n        if (this.markets_by_id == null)\n        {\n            return this.setMarkets(this.markets);\n        }\n        // return Task.FromResult(this.markets);\n        return this.markets;\n    }\n    object currencies = null;\n    var has = this.has as dict;\n    if (has[\"fetchCurrencies\"] != null)\n    {\n        currencies = await this.fetchCurrencies();\n    }\n    var markets = await this.fetchMarkets();\n    return this.setMarkets(markets, currencies);\n}",
        "import_statements": [
            "using System.Text",
            "using System.Text.RegularExpressions",
            "using System.Globalization",
            "using System.Net",
            "using dict = Dictionary<string, object>"
        ],
        "reference_api": [
            "this.fetchMarkets",
            "this.fetchCurrencies",
            "this.setMarkets"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "this.fetchMarkets",
            "this.fetchCurrencies",
            "this.setMarkets"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "handleErrors(code, reason, url, method, headers, body, response, requestHeaders, requestBody)",
        "start_line": "1049",
        "end_line": "1061",
        "file_path": "js/src/ace.js",
        "docstring": "The function handleErrors handles HTTP errors in API responses.\\nIf the response is undefined, it returns undefined to fall back to the default error handler.\\nIt constructs a feedback string using the instance ID and response body.\\nIt retrieves the status code from the response, defaulting to 200 if not present.\\nIf the status code is greater than 200, it converts the status code to a string and attempts to throw an exception matching the exact or broad status code using the throwExactlyMatchedException and throwBroadlyMatchedException methods, respectively.\\nIf no exceptions are thrown, it returns undefined.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "2698d9b47036",
        "ground_truth": "handleErrors(code, reason, url, method, headers, body, response, requestHeaders, requestBody) {\n    if (response === undefined) {\n        return undefined; // fallback to the default error handler\n    }\n    const feedback = this.id + ' ' + body;\n    const status = this.safeNumber(response, 'status', 200);\n    if (status > 200) {\n        const statusStr = status.toString();\n        this.throwExactlyMatchedException(this.exceptions['exact'], statusStr, feedback);\n        this.throwBroadlyMatchedException(this.exceptions['broad'], statusStr, feedback);\n    }\n    return undefined;\n}",
        "import_statements": [
            "./abstract/ace.js",
            "./base/errors.js",
            "./base/Precise.js",
            "./base/functions/number.js",
            "./static_dependencies/noble-hashes/sha256.js"
        ],
        "reference_api": [
            "handleErrors",
            "this.throwExactlyMatchedException",
            "status.toString",
            "this.throwBroadlyMatchedException",
            "this.safeNumber"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "handleErrors",
                "code": "handleErrors(code, reason, url, method, headers, body, response, requestHeaders, requestBody) {\n        if (response === undefined) {\n            return undefined; // fallback to the default error handler\n        }\n        const feedback = this.id + ' ' + body;\n        const status = this.safeNumber(response, 'status', 200);\n        if (status > 200) {\n            const statusStr = status.toString();\n            this.throwExactlyMatchedException(this.exceptions['exact'], statusStr, feedback);\n            this.throwBroadlyMatchedException(this.exceptions['broad'], statusStr, feedback);\n        }\n        return undefined;\n    }"
            }
        ],
        "third_party": [
            "this.throwExactlyMatchedException",
            "status.toString",
            "this.throwBroadlyMatchedException",
            "this.safeNumber"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "parseBalance(response)",
        "start_line": "952",
        "end_line": "980",
        "file_path": "js/src/ace.js",
        "docstring": "The function parseBalance(response) processes and formats the balance data from an API response.\\nIt initializes a result object with an 'info' key containing the original response.\\nFor each balance entry in the response, it extracts the currency name, converts it to a standardized currency code, and retrieves the total amount and available cash amount.\\nIt creates an account object with 'free' (available) and 'total' (total amount) fields.\\nThis account object is added to the result object under the corresponding currency code.\\nFinally, it returns the result object, ensuring the balance is safely structured using the safeBalance method.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cc3d66c1960a",
        "ground_truth": "parseBalance(response) {\n    //\n    //     [\n    //         {\n    //             \"currencyId\": 4,\n    //             \"amount\": 6.896,\n    //             \"cashAmount\": 6.3855,\n    //             \"uid\": 123,\n    //             \"currencyName\": \"BTC\"\n    //         }\n    //     ]\n    //\n    const result = {\n        'info': response,\n    };\n    for (let i = 0; i < response.length; i++) {\n        const balance = response[i];\n        const currencyId = this.safeString(balance, 'currencyName');\n        const code = this.safeCurrencyCode(currencyId);\n        const amount = this.safeString(balance, 'amount');\n        const available = this.safeString(balance, 'cashAmount');\n        const account = {\n            'free': available,\n            'total': amount,\n        };\n        result[code] = account;\n    }\n    return this.safeBalance(result);\n}",
        "import_statements": [
            "./abstract/ace.js",
            "./base/errors.js",
            "./base/Precise.js",
            "./base/functions/number.js",
            "./static_dependencies/noble-hashes/sha256.js"
        ],
        "reference_api": [
            "this.safeBalance",
            "this.safeString",
            "parseBalance",
            "this.safeCurrencyCode"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parseBalance",
                "code": "parseBalance(response) {\n        //\n        //     [\n        //         {\n        //             \"currencyId\": 4,\n        //             \"amount\": 6.896,\n        //             \"cashAmount\": 6.3855,\n        //             \"uid\": 123,\n        //             \"currencyName\": \"BTC\"\n        //         }\n        //     ]\n        //\n        const result = {\n            'info': response,\n        };\n        for (let i = 0; i < response.length; i++) {\n            const balance = response[i];\n            const currencyId = this.safeString(balance, 'currencyName');\n            const code = this.safeCurrencyCode(currencyId);\n            const amount = this.safeString(balance, 'amount');\n            const available = this.safeString(balance, 'cashAmount');\n            const account = {\n                'free': available,\n                'total': amount,\n            };\n            result[code] = account;\n        }\n        return this.safeBalance(result);\n    }"
            }
        ],
        "third_party": [
            "this.safeBalance",
            "this.safeString",
            "this.safeCurrencyCode"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "ccxt/ccxt",
        "function_declaration": "async fetchMyTrades(symbol = undefined, since = undefined, limit = undefined, params = {})",
        "start_line": "893",
        "end_line": "951",
        "file_path": "js/src/ace.js",
        "docstring": "The async function fetchMyTrades(symbol = undefined, since = undefined, limit = undefined, params = {}) retrieves the user's trade history from the exchange.\\nIt first loads the market data by calling loadMarkets().\\nIt then initializes a request object and sets the quoteCurrencyId and baseCurrencyId if the market ID is defined.\\nIf a limit is provided, it adds a size parameter to the request, specifying the number of trades to fetch.\\nThe function sends the request to the privatePostV2OrderGetTradeList endpoint, extending it with any additional parameters.\\nIt extracts the list of trades from the response and parses them using parseTrades, returning the parsed trade data for the specified market, time period, and limit.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c9b8fda66945",
        "ground_truth": "async fetchMyTrades(symbol = undefined, since = undefined, limit = undefined, params = {}) {\n    /**\n     * @method\n     * @name ace#fetchMyTrades\n     * @description fetch all trades made by the user\n     * @see https://github.com/ace-exchange/ace-official-api-docs/blob/master/api_v2.md#open-api---trade-list\n     * @param {string} symbol unified symbol of the market to fetch trades for\n     * @param {int} [since] timestamp in ms of the earliest trade to fetch\n     * @param {int} [limit] the maximum amount of trades to fetch\n     * @param {object} [params] extra parameters specific to the exchange API endpoint\n     * @returns {Trade[]} a list of [trade structures]{@link https://docs.ccxt.com/#/?id=public-trades}\n     */\n    await this.loadMarkets();\n    const market = this.safeMarket(symbol);\n    const request = {\n    // 'buyOrSell': 1,\n    // 'start': 0,\n    };\n    if (market['id'] !== undefined) {\n        request['quoteCurrencyId'] = market['quoteId'];\n        request['baseCurrencyId'] = market['baseId'];\n    }\n    if (limit !== undefined) {\n        request['size'] = limit; // default 10, max 500\n    }\n    const response = await this.privatePostV2OrderGetTradeList(this.extend(request, params));\n    //\n    //     {\n    //         \"attachment\": [\n    //             {\n    //                 \"buyOrSell\": 1,\n    //                 \"orderNo\": \"16708156853695560053601100247906\",\n    //                 \"num\": \"1\",\n    //                 \"price\": \"16895\",\n    //                 \"orderAmount\": \"16895\",\n    //                 \"tradeNum\": \"0.1\",\n    //                 \"tradePrice\": \"16895\",\n    //                 \"tradeAmount\": \"1689.5\",\n    //                 \"fee\": \"0\",\n    //                 \"feeSave\": \"0\",\n    //                 \"status\": 1,\n    //                 \"isSelf\": false,\n    //                 \"tradeNo\": \"16708186395087940051961000274150\",\n    //                 \"tradeTime\": \"2022-12-12 12:17:19\",\n    //                 \"tradeTimestamp\": 1670818639508,\n    //                 \"quoteCurrencyId\": 14,\n    //                 \"quoteCurrencyName\": \"USDT\",\n    //                 \"baseCurrencyId\": 2,\n    //                 \"baseCurrencyName\": \"BTC\"\n    //             }\n    //         ],\n    //         \"message\": null,\n    //         \"parameters\": null,\n    //         \"status\": 200\n    //     }\n    //\n    const trades = this.safeList(response, 'attachment', []);\n    return this.parseTrades(trades, market, since, limit);\n}",
        "import_statements": [
            "./abstract/ace.js",
            "./base/errors.js",
            "./base/Precise.js",
            "./base/functions/number.js",
            "./static_dependencies/noble-hashes/sha256.js"
        ],
        "reference_api": [
            "this.loadMarkets",
            "this.privatePostV2OrderGetTradeList",
            "async",
            "this.safeList",
            "this.parseTrades",
            "this.safeMarket",
            "this.extend"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "this.loadMarkets",
            "this.privatePostV2OrderGetTradeList",
            "async",
            "this.safeList",
            "this.parseTrades",
            "this.safeMarket",
            "this.extend"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def start_analysis_entries_exits(args: Dict[str, Any]) -> None",
        "start_line": "50",
        "end_line": "63",
        "file_path": "freqtrade/commands/analyze_commands.py",
        "docstring": "The function start_analysis_entries_exits(args: Dict[str, Any]) -> None initializes and starts the analysis mode for entry and exit reasons in trading strategies.\\nIt imports the process_entry_exit_reasons function from freqtrade.data.entryexitanalysis.\\nThe function sets up the configuration using setup_analyze_configuration with the provided arguments and the RunMode.BACKTEST mode.\\nIt logs a message indicating that freqtrade is starting in analysis mode.\\nFinally, it calls process_entry_exit_reasons with the configured settings to analyze the entry and exit reasons.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "75a68dea4781",
        "ground_truth": "def start_analysis_entries_exits(args: Dict[str, Any]) -> None:\n    \"\"\"\n    Start analysis script\n    :param args: Cli args from Arguments()\n    :return: None\n    \"\"\"\n    from freqtrade.data.entryexitanalysis import process_entry_exit_reasons\n     # Initialize configuration\n    config = setup_analyze_configuration(args, RunMode.BACKTEST)\n     logger.info(\"Starting freqtrade in analysis mode\")\n     process_entry_exit_reasons(config)",
        "import_statements": [
            "import logging",
            "from pathlib import Path",
            "from typing import Any, Dict",
            "from freqtrade.configuration import setup_utils_configuration",
            "from freqtrade.enums import RunMode",
            "from freqtrade.exceptions import ConfigurationError, OperationalException"
        ],
        "reference_api": [
            "setup_analyze_configuration",
            "logger.info",
            "process_entry_exit_reasons"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "setup_analyze_configuration",
                "code": "def setup_analyze_configuration(args: Dict[str, Any], method: RunMode) -> Dict[str, Any]:\n    \"\"\"\n    Prepare the configuration for the entry/exit reason analysis module\n    :param args: Cli args from Arguments()\n    :param method: Bot running mode\n    :return: Configuration\n    \"\"\"\n    config = setup_utils_configuration(args, method)\n\n    no_unlimited_runmodes = {\n        RunMode.BACKTEST: \"backtesting\",\n    }\n    if method in no_unlimited_runmodes.keys():\n        from freqtrade.data.btanalysis import get_latest_backtest_filename\n\n        if \"exportfilename\" in config:\n            if config[\"exportfilename\"].is_dir():\n                btfile = Path(get_latest_backtest_filename(config[\"exportfilename\"]))\n                signals_file = f\"{config['exportfilename']}/{btfile.stem}_signals.pkl\"\n            else:\n                if config[\"exportfilename\"].exists():\n                    btfile = Path(config[\"exportfilename\"])\n                    signals_file = f\"{btfile.parent}/{btfile.stem}_signals.pkl\"\n                else:\n                    raise ConfigurationError(f\"{config['exportfilename']} does not exist.\")\n        else:\n            raise ConfigurationError(\"exportfilename not in config.\")\n\n        if not Path(signals_file).exists():\n            raise OperationalException(\n                f\"Cannot find latest backtest signals file: {signals_file}.\"\n                \"Run backtesting with `--export signals`.\"\n            )\n\n    return config"
            }
        ],
        "third_party": [
            "process_entry_exit_reasons"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def deploy_new_config(config_path: Path, selections: Dict[str, Any]) -> None",
        "start_line": "222",
        "end_line": "250",
        "file_path": "freqtrade/commands/build_config_commands.py",
        "docstring": "The function deploy_new_config(config_path: Path, selections: Dict[str, Any]) -> None generates and writes a new configuration file based on user selections and template files.\\nIt imports TemplateNotFound from jinja2.exceptions to handle missing templates.\\nThe function attempts to get the specific exchange template based on the user's selected exchange name from MAP_EXCHANGE_CHILDCLASS.\\nIt uses render_template to render the exchange-specific configuration template and assigns it to selections[\"exchange\"].\\nIf the specified template is not found, it defaults to a generic exchange template.\\nIt then renders the main configuration template using the updated selections and logs messages indicating where the config file will be written and advising the user to review the configuration contents.\\nFinally, it writes the rendered configuration text to the specified config_path.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1d3e4e908cab",
        "ground_truth": "def deploy_new_config(config_path: Path, selections: Dict[str, Any]) -> None:\n    \"\"\"\n    Applies selections to the template and writes the result to config_path\n    :param config_path: Path object for new config file. Should not exist yet\n    :param selections: Dict containing selections taken by the user.\n    \"\"\"\n    from jinja2.exceptions import TemplateNotFound\n     try:\n        exchange_template = MAP_EXCHANGE_CHILDCLASS.get(\n            selections[\"exchange_name\"], selections[\"exchange_name\"]\n        )\n         selections[\"exchange\"] = render_template(\n            templatefile=f\"subtemplates/exchange_{exchange_template}.j2\", arguments=selections\n        )\n    except TemplateNotFound:\n        selections[\"exchange\"] = render_template(\n            templatefile=\"subtemplates/exchange_generic.j2\", arguments=selections\n        )\n     config_text = render_template(templatefile=\"base_config.json.j2\", arguments=selections)\n     logger.info(f\"Writing config to `{config_path}`.\")\n    logger.info(\n        \"Please make sure to check the configuration contents and adjust settings to your needs.\"\n    )\n     config_path.write_text(config_text)",
        "import_statements": [
            "import logging",
            "import secrets",
            "from pathlib import Path",
            "from typing import Any, Dict, List",
            "from questionary import Separator, prompt",
            "from freqtrade.configuration import sanitize_config",
            "from freqtrade.configuration.config_setup import setup_utils_configuration",
            "from freqtrade.configuration.detect_environment import running_in_docker",
            "from freqtrade.configuration.directory_operations import chown_user_directory",
            "from freqtrade.constants import UNLIMITED_STAKE_AMOUNT",
            "from freqtrade.enums import RunMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.exchange import MAP_EXCHANGE_CHILDCLASS, available_exchanges",
            "from freqtrade.util import render_template"
        ],
        "reference_api": [
            "config_path.write_text",
            "logger.info",
            "MAP_EXCHANGE_CHILDCLASS.get",
            "render_template"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "MAP_EXCHANGE_CHILDCLASS.get",
            "render_template",
            "render_template",
            "render_template",
            "config_path.write_text"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def start_new_config(args: Dict[str, Any]) -> None",
        "start_line": "253",
        "end_line": "271",
        "file_path": "freqtrade/commands/build_config_commands.py",
        "docstring": "The function start_new_config(args: Dict[str, Any]) -> None initializes the process of creating a new configuration file.\\nIt retrieves the config path from the provided arguments and sets the appropriate ownership for the directory containing the config file using chown_user_directory.\\nIf the config file already exists, it prompts the user to decide whether to overwrite it using ask_user_overwrite.\\nIf the user agrees to overwrite, it deletes the existing file; otherwise, it raises an OperationalException to notify the user to delete the file or use a different name.\\nNext, it collects configuration selections from the user using ask_user_config and then calls deploy_new_config to generate and write the new configuration file based on these selections.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "fcbda39172c5",
        "ground_truth": "def start_new_config(args: Dict[str, Any]) -> None:\n    \"\"\"\n    Create a new strategy from a template\n    Asking the user questions to fill out the template accordingly.\n    \"\"\"\n     config_path = Path(args[\"config\"][0])\n    chown_user_directory(config_path.parent)\n    if config_path.exists():\n        overwrite = ask_user_overwrite(config_path)\n        if overwrite:\n            config_path.unlink()\n        else:\n            raise OperationalException(\n                f\"Configuration file `{config_path}` already exists. \"\n                \"Please delete it or use a different configuration file name.\"\n            )\n    selections = ask_user_config()\n    deploy_new_config(config_path, selections)",
        "import_statements": [
            "import logging",
            "import secrets",
            "from pathlib import Path",
            "from typing import Any, Dict, List",
            "from questionary import Separator, prompt",
            "from freqtrade.configuration import sanitize_config",
            "from freqtrade.configuration.config_setup import setup_utils_configuration",
            "from freqtrade.configuration.detect_environment import running_in_docker",
            "from freqtrade.configuration.directory_operations import chown_user_directory",
            "from freqtrade.constants import UNLIMITED_STAKE_AMOUNT",
            "from freqtrade.enums import RunMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.exchange import MAP_EXCHANGE_CHILDCLASS, available_exchanges",
            "from freqtrade.util import render_template"
        ],
        "reference_api": [
            "OperationalException",
            "chown_user_directory",
            "config_path.unlink",
            "ask_user_overwrite",
            "deploy_new_config",
            "ask_user_config",
            "config_path.exists",
            "Path"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "chown_user_directory",
                "code": "def chown_user_directory(directory: Path) -> None:\n    \"\"\"\n    Use Sudo to change permissions of the home-directory if necessary\n    Only applies when running in docker!\n    \"\"\"\n    if running_in_docker():\n        try:\n            import subprocess  # noqa: S404\n\n            subprocess.check_output([\"sudo\", \"chown\", \"-R\", \"ftuser:\", str(directory.resolve())])\n        except Exception:\n            logger.warning(f\"Could not chown {directory}\")"
            },
            {
                "name": "ask_user_overwrite",
                "code": "def ask_user_overwrite(config_path: Path) -> bool:\n    questions = [\n        {\n            \"type\": \"confirm\",\n            \"name\": \"overwrite\",\n            \"message\": f\"File {config_path} already exists. Overwrite?\",\n            \"default\": False,\n        },\n    ]\n    answers = prompt(questions)\n    return answers[\"overwrite\"]"
            },
            {
                "name": "ask_user_config",
                "code": "def ask_user_config() -> Dict[str, Any]:\n    \"\"\"\n    Ask user a few questions to build the configuration.\n    Interactive questions built using https://github.com/tmbo/questionary\n    :returns: Dict with keys to put into template\n    \"\"\"\n    questions: List[Dict[str, Any]] = [\n        {\n            \"type\": \"confirm\",\n            \"name\": \"dry_run\",\n            \"message\": \"Do you want to enable Dry-run (simulated trades)?\",\n            \"default\": True,\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"stake_currency\",\n            \"message\": \"Please insert your stake currency:\",\n            \"default\": \"USDT\",\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"stake_amount\",\n            \"message\": f\"Please insert your stake amount (Number or '{UNLIMITED_STAKE_AMOUNT}'):\",\n            \"default\": \"unlimited\",\n            \"validate\": lambda val: val == UNLIMITED_STAKE_AMOUNT or validate_is_float(val),\n            \"filter\": lambda val: (\n                '\"' + UNLIMITED_STAKE_AMOUNT + '\"' if val == UNLIMITED_STAKE_AMOUNT else val\n            ),\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"max_open_trades\",\n            \"message\": \"Please insert max_open_trades (Integer or -1 for unlimited open trades):\",\n            \"default\": \"3\",\n            \"validate\": lambda val: validate_is_int(val),\n        },\n        {\n            \"type\": \"select\",\n            \"name\": \"timeframe_in_config\",\n            \"message\": \"Time\",\n            \"choices\": [\"Have the strategy define timeframe.\", \"Override in configuration.\"],\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"timeframe\",\n            \"message\": \"Please insert your desired timeframe (e.g. 5m):\",\n            \"default\": \"5m\",\n            \"when\": lambda x: x[\"timeframe_in_config\"] == \"Override in configuration.\",\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"fiat_display_currency\",\n            \"message\": (\n                \"Please insert your display Currency for reporting \"\n                \"(leave empty to disable FIAT conversion):\"\n            ),\n            \"default\": \"USD\",\n        },\n        {\n            \"type\": \"select\",\n            \"name\": \"exchange_name\",\n            \"message\": \"Select exchange\",\n            \"choices\": [\n                \"binance\",\n                \"binanceus\",\n                \"bingx\",\n                \"gate\",\n                \"htx\",\n                \"kraken\",\n                \"kucoin\",\n                \"okx\",\n                Separator(\"------------------\"),\n                \"other\",\n            ],\n        },\n        {\n            \"type\": \"confirm\",\n            \"name\": \"trading_mode\",\n            \"message\": \"Do you want to trade Perpetual Swaps (perpetual futures)?\",\n            \"default\": False,\n            \"filter\": lambda val: \"futures\" if val else \"spot\",\n            \"when\": lambda x: x[\"exchange_name\"] in [\"binance\", \"gate\", \"okx\", \"bybit\"],\n        },\n        {\n            \"type\": \"autocomplete\",\n            \"name\": \"exchange_name\",\n            \"message\": \"Type your exchange name (Must be supported by ccxt)\",\n            \"choices\": available_exchanges(),\n            \"when\": lambda x: x[\"exchange_name\"] == \"other\",\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"exchange_key\",\n            \"message\": \"Insert Exchange Key\",\n            \"when\": lambda x: not x[\"dry_run\"],\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"exchange_secret\",\n            \"message\": \"Insert Exchange Secret\",\n            \"when\": lambda x: not x[\"dry_run\"],\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"exchange_key_password\",\n            \"message\": \"Insert Exchange API Key password\",\n            \"when\": lambda x: not x[\"dry_run\"] and x[\"exchange_name\"] in (\"kucoin\", \"okx\"),\n        },\n        {\n            \"type\": \"confirm\",\n            \"name\": \"telegram\",\n            \"message\": \"Do you want to enable Telegram?\",\n            \"default\": False,\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"telegram_token\",\n            \"message\": \"Insert Telegram token\",\n            \"when\": lambda x: x[\"telegram\"],\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"telegram_chat_id\",\n            \"message\": \"Insert Telegram chat id\",\n            \"when\": lambda x: x[\"telegram\"],\n        },\n        {\n            \"type\": \"confirm\",\n            \"name\": \"api_server\",\n            \"message\": \"Do you want to enable the Rest API (includes FreqUI)?\",\n            \"default\": False,\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"api_server_listen_addr\",\n            \"message\": (\n                \"Insert Api server Listen Address (0.0.0.0 for docker, \"\n                \"otherwise best left untouched)\"\n            ),\n            \"default\": \"127.0.0.1\" if not running_in_docker() else \"0.0.0.0\",  # noqa: S104\n            \"when\": lambda x: x[\"api_server\"],\n        },\n        {\n            \"type\": \"text\",\n            \"name\": \"api_server_username\",\n            \"message\": \"Insert api-server username\",\n            \"default\": \"freqtrader\",\n            \"when\": lambda x: x[\"api_server\"],\n        },\n        {\n            \"type\": \"password\",\n            \"name\": \"api_server_password\",\n            \"message\": \"Insert api-server password\",\n            \"when\": lambda x: x[\"api_server\"],\n        },\n    ]\n    answers = prompt(questions)\n\n    if not answers:\n        # Interrupted questionary sessions return an empty dict.\n        raise OperationalException(\"User interrupted interactive questions.\")\n    # Ensure default is set for non-futures exchanges\n    answers[\"trading_mode\"] = answers.get(\"trading_mode\", \"spot\")\n    answers[\"margin_mode\"] = \"isolated\" if answers.get(\"trading_mode\") == \"futures\" else \"\"\n    # Force JWT token to be a random string\n    answers[\"api_server_jwt_key\"] = secrets.token_hex()\n    answers[\"api_server_ws_token\"] = secrets.token_urlsafe(25)\n\n    return answers"
            },
            {
                "name": "deploy_new_config",
                "code": "def deploy_new_config(config_path: Path, selections: Dict[str, Any]) -> None:\n    \"\"\"\n    Applies selections to the template and writes the result to config_path\n    :param config_path: Path object for new config file. Should not exist yet\n    :param selections: Dict containing selections taken by the user.\n    \"\"\"\n    from jinja2.exceptions import TemplateNotFound\n\n    try:\n        exchange_template = MAP_EXCHANGE_CHILDCLASS.get(\n            selections[\"exchange_name\"], selections[\"exchange_name\"]\n        )\n\n        selections[\"exchange\"] = render_template(\n            templatefile=f\"subtemplates/exchange_{exchange_template}.j2\", arguments=selections\n        )\n    except TemplateNotFound:\n        selections[\"exchange\"] = render_template(\n            templatefile=\"subtemplates/exchange_generic.j2\", arguments=selections\n        )\n\n    config_text = render_template(templatefile=\"base_config.json.j2\", arguments=selections)\n\n    logger.info(f\"Writing config to `{config_path}`.\")\n    logger.info(\n        \"Please make sure to check the configuration contents and adjust settings to your needs.\"\n    )\n\n    config_path.write_text(config_text)"
            }
        ],
        "third_party": [
            "Path",
            "config_path.exists",
            "config_path.unlink",
            "OperationalException"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def start_download_data(args: Dict[str, Any]) -> None",
        "start_line": "40",
        "end_line": "52",
        "file_path": "freqtrade/commands/data_commands.py",
        "docstring": "The function start_download_data(args: Dict[str, Any]) -> None initializes the process of downloading data for a specified exchange.\\nIt sets up the configuration using setup_utils_configuration with the provided arguments and the RunMode.UTIL_EXCHANGE mode.\\nThe function then checks the data download configuration for any issues using _check_data_config_download_sanity.\\nIt attempts to execute the data download by calling download_data_main with the configured settings.\\nIf a KeyboardInterrupt is received (e.g., the user presses Ctrl+C), it catches the exception and exits the program gracefully with a message indicating that the process was aborted.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1688dd5b3115",
        "ground_truth": "def start_download_data(args: Dict[str, Any]) -> None:\n    \"\"\"\n    Download data (former download_backtest_data.py script)\n    \"\"\"\n    config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)\n     _check_data_config_download_sanity(config)\n     try:\n        download_data_main(config)\n     except KeyboardInterrupt:\n        sys.exit(\"SIGINT received, aborting ...\")",
        "import_statements": [
            "import logging",
            "import sys",
            "from collections import defaultdict",
            "from typing import Any, Dict",
            "from freqtrade.configuration import TimeRange, setup_utils_configuration",
            "from freqtrade.constants import DATETIME_PRINT_FORMAT, DL_DATA_TIMEFRAMES, Config",
            "from freqtrade.data.converter import (\n    convert_ohlcv_format,\n    convert_trades_format,\n    convert_trades_to_ohlcv,\n)",
            "from freqtrade.data.history import download_data_main",
            "from freqtrade.enums import CandleType, RunMode, TradingMode",
            "from freqtrade.exceptions import ConfigurationError",
            "from freqtrade.exchange import timeframe_to_minutes",
            "from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist",
            "from freqtrade.resolvers import ExchangeResolver",
            "from freqtrade.util import print_rich_table",
            "from freqtrade.util.migrations import migrate_data"
        ],
        "reference_api": [
            "_check_data_config_download_sanity",
            "setup_utils_configuration",
            "download_data_main",
            "sys.exit"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "_check_data_config_download_sanity",
                "code": "def _check_data_config_download_sanity(config: Config) -> None:\n    if \"days\" in config and \"timerange\" in config:\n        raise ConfigurationError(\n            \"--days and --timerange are mutually exclusive. \"\n            \"You can only specify one or the other.\"\n        )\n\n    if \"pairs\" not in config:\n        raise ConfigurationError(\n            \"Downloading data requires a list of pairs. \"\n            \"Please check the documentation on how to configure this.\"\n        )"
            }
        ],
        "third_party": [
            "setup_utils_configuration",
            "download_data_main"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def start_convert_trades(args: Dict[str, Any]) -> None",
        "start_line": "55",
        "end_line": "91",
        "file_path": "freqtrade/commands/data_commands.py",
        "docstring": "The function start_convert_trades(args: Dict[str, Any]) -> None initializes the process of converting downloaded trade data to OHLCV format for specified timeframes.\\nIt sets up the configuration using setup_utils_configuration with the provided arguments and the RunMode.UTIL_EXCHANGE mode.\\nA TimeRange object is initialized, and the stake currency is removed from the configuration to skip irrelevant checks.\\nIf the configuration does not specify timeframes, it sets a default value.\\nThe function initializes an exchange instance using ExchangeResolver.load_exchange with validation disabled.\\nIt manually validates the specified timeframes and retrieves a list of available trading pairs from the exchange, including inactive pairs if specified in the configuration.\\nThe function expands the list of trading pairs using dynamic_expand_pairlist and converts the downloaded trade data to OHLCV format for the specified timeframes and pairs using convert_trades_to_ohlcv.\\nAdditional settings like data directory, timerange, erase flag, and data formats are passed to the conversion function.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "379aa5247dc0",
        "ground_truth": "def start_convert_trades(args: Dict[str, Any]) -> None:\n    config = setup_utils_configuration(args, RunMode.UTIL_EXCHANGE)\n     timerange = TimeRange()\n     # Remove stake-currency to skip checks which are not relevant for datadownload\n    config[\"stake_currency\"] = \"\"\n     if \"timeframes\" not in config:\n        config[\"timeframes\"] = DL_DATA_TIMEFRAMES\n     # Init exchange\n    exchange = ExchangeResolver.load_exchange(config, validate=False)\n    # Manual validations of relevant settings\n     for timeframe in config[\"timeframes\"]:\n        exchange.validate_timeframes(timeframe)\n    available_pairs = [\n        p\n        for p in exchange.get_markets(\n            tradable_only=True, active_only=not config.get(\"include_inactive\")\n        ).keys()\n    ]\n     expanded_pairs = dynamic_expand_pairlist(config, available_pairs)\n     # Convert downloaded trade data to different timeframes\n    convert_trades_to_ohlcv(\n        pairs=expanded_pairs,\n        timeframes=config[\"timeframes\"],\n        datadir=config[\"datadir\"],\n        timerange=timerange,\n        erase=bool(config.get(\"erase\")),\n        data_format_ohlcv=config[\"dataformat_ohlcv\"],\n        data_format_trades=config[\"dataformat_trades\"],\n        candle_type=config.get(\"candle_type_def\", CandleType.SPOT),\n    )",
        "import_statements": [
            "import logging",
            "import sys",
            "from collections import defaultdict",
            "from typing import Any, Dict",
            "from freqtrade.configuration import TimeRange, setup_utils_configuration",
            "from freqtrade.constants import DATETIME_PRINT_FORMAT, DL_DATA_TIMEFRAMES, Config",
            "from freqtrade.data.converter import (\n    convert_ohlcv_format,\n    convert_trades_format,\n    convert_trades_to_ohlcv,\n)",
            "from freqtrade.data.history import download_data_main",
            "from freqtrade.enums import CandleType, RunMode, TradingMode",
            "from freqtrade.exceptions import ConfigurationError",
            "from freqtrade.exchange import timeframe_to_minutes",
            "from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist",
            "from freqtrade.resolvers import ExchangeResolver",
            "from freqtrade.util import print_rich_table",
            "from freqtrade.util.migrations import migrate_data"
        ],
        "reference_api": [
            "keys",
            "convert_trades_to_ohlcv",
            "dynamic_expand_pairlist",
            "config.get",
            "bool",
            "exchange.get_markets",
            "setup_utils_configuration",
            "TimeRange",
            "exchange.validate_timeframes",
            "ExchangeResolver.load_exchange"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "dynamic_expand_pairlist",
                "code": "def dynamic_expand_pairlist(config: Config, markets: List[str]) -> List[str]:\n    expanded_pairs = expand_pairlist(config[\"pairs\"], markets)\n    if config.get(\"freqai\", {}).get(\"enabled\", False):\n        corr_pairlist = config[\"freqai\"][\"feature_parameters\"][\"include_corr_pairlist\"]\n        expanded_pairs += [pair for pair in corr_pairlist if pair not in config[\"pairs\"]]\n\n    return expanded_pairs"
            }
        ],
        "third_party": [
            "setup_utils_configuration",
            "TimeRange",
            "ExchangeResolver.load_exchange",
            "exchange.validate_timeframes",
            "keys",
            "exchange.get_markets",
            "config.get",
            "convert_trades_to_ohlcv",
            "config.get",
            "config.get"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def download_and_install_ui(dest_folder: Path, dl_url: str, version: str)",
        "start_line": "123",
        "end_line": "139",
        "file_path": "freqtrade/commands/deploy_commands.py",
        "docstring": "The function download_and_install_ui(dest_folder: Path, dl_url: str, version: str) downloads and installs a UI package from a specified URL to a destination folder.\\nIt logs the download URL and fetches the content from the URL with a specified timeout.\\nIt creates the destination folder and any necessary parent directories.\\nUsing the ZipFile class, it extracts the downloaded content into the destination folder.\\nFor each file in the zip archive, it checks if it's a directory and creates it if necessary.\\nFor files, it writes the file content to the appropriate location in the destination folder.\\nFinally, it writes the version information to a \".uiversion\" file in the destination folder.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "6deb2188fc23",
        "ground_truth": "def download_and_install_ui(dest_folder: Path, dl_url: str, version: str):\n    from io import BytesIO\n    from zipfile import ZipFile\n     logger.info(f\"Downloading {dl_url}\")\n    resp = requests.get(dl_url, timeout=req_timeout).content\n    dest_folder.mkdir(parents=True, exist_ok=True)\n    with ZipFile(BytesIO(resp)) as zf:\n        for fn in zf.filelist:\n            with zf.open(fn) as x:\n                destfile = dest_folder / fn.filename\n                if fn.is_dir():\n                    destfile.mkdir(exist_ok=True)\n                else:\n                    destfile.write_bytes(x.read())\n    with (dest_folder / \".uiversion\").open(\"w\") as f:\n        f.write(version)",
        "import_statements": [
            "import logging",
            "import sys",
            "from pathlib import Path",
            "from typing import Any, Dict, Optional, Tuple",
            "import requests",
            "from freqtrade.configuration import setup_utils_configuration",
            "from freqtrade.configuration.directory_operations import copy_sample_files, create_userdata_dir",
            "from freqtrade.constants import USERPATH_STRATEGIES",
            "from freqtrade.enums import RunMode",
            "from freqtrade.exceptions import ConfigurationError, OperationalException",
            "from freqtrade.util import render_template, render_template_with_fallback"
        ],
        "reference_api": [
            "dest_folder.mkdir",
            "f.write",
            "x.read",
            "requests.get",
            "destfile.write_bytes",
            "ZipFile",
            "logger.info",
            "destfile.mkdir",
            "zf.open",
            "open",
            "fn.is_dir",
            "BytesIO"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "requests.get",
            "dest_folder.mkdir",
            "ZipFile",
            "BytesIO",
            "zf.open",
            "fn.is_dir",
            "destfile.mkdir",
            "destfile.write_bytes",
            "x.read",
            "f.write"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def setup_utils_configuration(\n    args: Dict[str, Any], method: RunMode, *, set_dry: bool = True\n) -> Dict[str, Any]",
        "start_line": "13",
        "end_line": "30",
        "file_path": "freqtrade/configuration/config_setup.py",
        "docstring": "The function setup_utils_configuration(args: Dict[str, Any], method: RunMode, *, set_dry: bool = True) -> Dict[str, Any] initializes and configures the utility settings for a specified run mode.\\nIt creates a Configuration object using the provided arguments and method, then retrieves the configuration dictionary using get_config().\\nIf set_dry is True, it ensures that the dry_run mode is enabled in the configuration.\\nIt validates the configuration for consistency with preliminary checks using validate_config_consistency().\\nFinally, it returns the validated configuration dictionary.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "6b93d6e7f63f",
        "ground_truth": "def setup_utils_configuration(\n    args: Dict[str, Any], method: RunMode, *, set_dry: bool = True\n) -> Dict[str, Any]:\n    \"\"\"\n    Prepare the configuration for utils subcommands\n    :param args: Cli args from Arguments()\n    :param method: Bot running mode\n    :return: Configuration\n    \"\"\"\n    configuration = Configuration(args, method)\n    config = configuration.get_config()\n     # Ensure these modes are using Dry-run\n    if set_dry:\n        config[\"dry_run\"] = True\n    validate_config_consistency(config, preliminary=True)\n     return config",
        "import_statements": [
            "import logging",
            "from typing import Any, Dict",
            "from freqtrade.enums import RunMode"
        ],
        "reference_api": [
            "Configuration",
            "configuration.get_config",
            "validate_config_consistency"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "Configuration",
            "configuration.get_config",
            "validate_config_consistency"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": " def _process_trading_options(self, config: Config) -> None:",
        "start_line": "132",
        "end_line": "146",
        "file_path": "freqtrade/configuration/configuration.py",
        "docstring": "The function _process_trading_options(self, config: Config) -> None processes trading options based on the provided configuration.\\nIt first checks if the run mode in the configuration is one of the trade modes specified in TRADE_MODES.\\nIf not, it returns without making any changes.\\nIf \"dry_run\" is enabled in the configuration, it logs this information.\\nIt then checks if the database URL (db_url) is either None or the default production URL, and if so, sets it to the default dry-run URL.\\nIf \"dry_run\" is disabled, it ensures the db_url is set to the default production URL if not already specified, and logs that dry run is disabled.\\nFinally, it logs the database URL being used, obscuring sensitive details with parse_db_uri_for_logging.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a4f62c94f7fb",
        "ground_truth": "def _process_trading_options(self, config: Config) -> None:\n    if config[\"runmode\"] not in TRADE_MODES:\n        return\n    if config.get(\"dry_run\", False):\n        logger.info(\"Dry run is enabled\")\n        if config.get(\"db_url\") in [None, constants.DEFAULT_DB_PROD_URL]:\n            # Default to in-memory db for dry_run if not specified\n            config[\"db_url\"] = constants.DEFAULT_DB_DRYRUN_URL\n    else:\n        if not config.get(\"db_url\"):\n            config[\"db_url\"] = constants.DEFAULT_DB_PROD_URL\n        logger.info(\"Dry run is disabled\")\n    logger.info(f'Using DB: \"{parse_db_uri_for_logging(config[\"db_url\"])}\"')",
        "import_statements": [
            "import ast",
            "import logging",
            "import warnings",
            "from copy import deepcopy",
            "from pathlib import Path",
            "from typing import Any, Callable, Dict, List, Optional, Tuple",
            "from freqtrade import constants",
            "from freqtrade.configuration.deprecated_settings import process_temporary_deprecated_settings",
            "from freqtrade.configuration.directory_operations import create_datadir, create_userdata_dir",
            "from freqtrade.configuration.environment_vars import enironment_vars_to_dict",
            "from freqtrade.configuration.load_config import load_file, load_from_files",
            "from freqtrade.constants import Config",
            "from freqtrade.enums import NON_UTIL_MODES, TRADE_MODES, CandleType, RunMode, TradingMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.loggers import setup_logging",
            "from freqtrade.misc import deep_merge_dicts, parse_db_uri_for_logging"
        ],
        "reference_api": [
            "parse_db_uri_for_logging",
            "logger.info",
            "config.get"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parse_db_uri_for_logging",
                "code": "def parse_db_uri_for_logging(uri: str):\n    \"\"\"\n    Helper method to parse the DB URI and return the same DB URI with the password censored\n    if it contains it. Otherwise, return the DB URI unchanged\n    :param uri: DB URI to parse for logging\n    \"\"\"\n    parsed_db_uri = urlparse(uri)\n    if not parsed_db_uri.netloc:  # No need for censoring as no password was provided\n        return uri\n    pwd = parsed_db_uri.netloc.split(\":\")[1].split(\"@\")[0]\n    return parsed_db_uri.geturl().replace(f\":{pwd}@\", \":*****@\")"
            }
        ],
        "third_party": [
            "config.get",
            "config.get",
            "config.get"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def process_removed_setting(\n    config: Config, section1: str, name1: str, section2: Optional[str], name2: str\n) -> None",
        "start_line": "36",
        "end_line": "52",
        "file_path": "freqtrade/configuration/deprecated_settings.py",
        "docstring": "The function process_removed_setting(config: Config, section1: str, name1: str, section2: Optional[str], name2: str) -> None handles the migration of a removed configuration setting to a new location.\\nIt checks if the specified setting (name1) exists in the removed section (section1) of the configuration.\\nIf the setting is found, it constructs the new section and setting name (section2.name2) and raises a ConfigurationError.\\nThe error message informs the user that the setting has been moved and instructs them to update their configuration accordingly by deleting the old setting and using the new one.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "8fc2c7b1494d",
        "ground_truth": "def process_removed_setting(\n    config: Config, section1: str, name1: str, section2: Optional[str], name2: str\n) -> None:\n    \"\"\"\n    :param section1: Removed section\n    :param name1: Removed setting name\n    :param section2: new section for this key\n    :param name2: new setting name\n    \"\"\"\n    section1_config = config.get(section1, {})\n    if name1 in section1_config:\n        section_2 = f\"{section2}.{name2}\" if section2 else f\"{name2}\"\n        raise ConfigurationError(\n            f\"Setting `{section1}.{name1}` has been moved to `{section_2}. \"\n            f\"Please delete it from your configuration and use the `{section_2}` \"\n            \"setting instead.\"\n        )",
        "import_statements": [
            "import logging",
            "from typing import Optional",
            "from freqtrade.constants import Config",
            "from freqtrade.exceptions import ConfigurationError, OperationalException"
        ],
        "reference_api": [
            "ConfigurationError",
            "config.get"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "config.get",
            "ConfigurationError"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def chown_user_directory(directory: Path) -> None",
        "start_line": "34",
        "end_line": "45",
        "file_path": "freqtrade/configuration/directory_operations.py",
        "docstring": "The function chown_user_directory(directory: Path) -> None changes the ownership of the specified directory to 'ftuser' when running in a Docker environment.\\nIt first checks if the code is running in Docker using the running_in_docker() function.\\nIf it is, it attempts to use the subprocess module to execute the 'sudo chown -R ftuser:' command on the resolved directory path.\\nIf the command fails, it logs a warning indicating that the ownership change for the directory could not be completed.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a0508728a994",
        "ground_truth": "def chown_user_directory(directory: Path) -> None:\n    \"\"\"\n    Use Sudo to change permissions of the home-directory if necessary\n    Only applies when running in docker!\n    \"\"\"\n    if running_in_docker():\n        try:\n            import subprocess  # noqa: S404\n             subprocess.check_output([\"sudo\", \"chown\", \"-R\", \"ftuser:\", str(directory.resolve())])\n        except Exception:\n            logger.warning(f\"Could not chown {directory}\")",
        "import_statements": [
            "import logging",
            "import shutil",
            "from pathlib import Path",
            "from typing import Optional",
            "from freqtrade.configuration.detect_environment import running_in_docker",
            "from freqtrade.constants import (\n    USER_DATA_FILES,\n    USERPATH_FREQAIMODELS,\n    USERPATH_HYPEROPTS,\n    USERPATH_NOTEBOOKS,\n    USERPATH_STRATEGIES,\n    Config,\n)",
            "from freqtrade.exceptions import OperationalException"
        ],
        "reference_api": [
            "directory.resolve",
            "logger.warning",
            "running_in_docker",
            "str",
            "subprocess.check_output"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "running_in_docker",
                "code": "def running_in_docker() -> bool:\n    \"\"\"\n    Check if we are running in a docker container\n    \"\"\"\n    return os.environ.get(\"FT_APP_ENV\") == \"docker\""
            }
        ],
        "third_party": [
            "directory.resolve"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def copy_sample_files(directory: Path, overwrite: bool = False) -> None",
        "start_line": "89",
        "end_line": "108",
        "file_path": "freqtrade/configuration/directory_operations.py",
        "docstring": "The function copy_sample_files(directory: Path, overwrite: bool = False) -> None copies sample files to a specified directory, with an option to overwrite existing files.\\nIt first checks if the given directory exists and raises an OperationalException if it does not.\\nThe source directory for the templates is set relative to the current file's parent directory.\\nFor each source and target pair in USER_DATA_FILES, it constructs the target directory path and verifies its existence, raising an OperationalException if it does not exist.\\nFor each target file, if it exists and overwrite is not enabled, it logs a warning and skips copying.\\nIf overwrite is enabled, it logs a warning and proceeds to copy the file from the source directory to the target directory.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "0151bddb63a1",
        "ground_truth": "def copy_sample_files(directory: Path, overwrite: bool = False) -> None:\n    \"\"\"\n    Copy files from templates to User data directory.\n    :param directory: Directory to copy data to\n    :param overwrite: Overwrite existing sample files\n    \"\"\"\n    if not directory.is_dir():\n        raise OperationalException(f\"Directory `{directory}` does not exist.\")\n    sourcedir = Path(__file__).parents[1] / \"templates\"\n    for source, target in USER_DATA_FILES.items():\n        targetdir = directory / target\n        if not targetdir.is_dir():\n            raise OperationalException(f\"Directory `{targetdir}` does not exist.\")\n        targetfile = targetdir / source\n        if targetfile.exists():\n            if not overwrite:\n                logger.warning(f\"File `{targetfile}` exists already, not deploying sample file.\")\n                continue\n            logger.warning(f\"File `{targetfile}` exists already, overwriting.\")\n        shutil.copy(str(sourcedir / source), str(targetfile))",
        "import_statements": [
            "import logging",
            "import shutil",
            "from pathlib import Path",
            "from typing import Optional",
            "from freqtrade.configuration.detect_environment import running_in_docker",
            "from freqtrade.constants import (\n    USER_DATA_FILES,\n    USERPATH_FREQAIMODELS,\n    USERPATH_HYPEROPTS,\n    USERPATH_NOTEBOOKS,\n    USERPATH_STRATEGIES,\n    Config,\n)",
            "from freqtrade.exceptions import OperationalException"
        ],
        "reference_api": [
            "OperationalException",
            "directory.is_dir",
            "USER_DATA_FILES.items",
            "shutil.copy",
            "targetfile.exists",
            "logger.warning",
            "Path",
            "str",
            "targetdir.is_dir"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "directory.is_dir",
            "OperationalException",
            "Path",
            "USER_DATA_FILES.items",
            "targetdir.is_dir",
            "OperationalException",
            "targetfile.exists"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def load_config_file(path: str) -> Dict[str, Any]",
        "start_line": "54",
        "end_line": "77",
        "file_path": "freqtrade/configuration/load_config.py",
        "docstring": "The function load_config_file(path: str) -> Dict[str, Any] loads and parses a configuration file from a specified path.\\nIf the path is \"-\", it reads the configuration from standard input (stdin); otherwise, it reads from the file at the given path.\\nThe function uses rapidjson to parse the configuration file with a specified parsing mode.\\nIf the file is not found, it raises an OperationalException with a message indicating the file is missing.\\nIf there is a JSON decoding error, it logs the error range in the configuration file and raises a ConfigurationError with a message prompting the user to check the configuration segment or syntax.\\nFinally, it returns the parsed configuration as a dictionary.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d30e0889002f",
        "ground_truth": "def load_config_file(path: str) -> Dict[str, Any]:\n    \"\"\"\n    Loads a config file from the given path\n    :param path: path as str\n    :return: configuration as dictionary\n    \"\"\"\n    try:\n        # Read config from stdin if requested in the options\n        with Path(path).open() if path != \"-\" else sys.stdin as file:\n            config = rapidjson.load(file, parse_mode=CONFIG_PARSE_MODE)\n    except FileNotFoundError:\n        raise OperationalException(\n            f'Config file \"{path}\" not found!'\n            \" Please create a config file or check whether it exists.\"\n        ) from None\n    except rapidjson.JSONDecodeError as e:\n        err_range = log_config_error_range(path, str(e))\n        raise ConfigurationError(\n            f\"{e}\\nPlease verify the following segment of your configuration:\\n{err_range}\"\n            if err_range\n            else \"Please verify your configuration file for syntax errors.\"\n        )\n     return config",
        "import_statements": [
            "import logging",
            "import re",
            "import sys",
            "from copy import deepcopy",
            "from pathlib import Path",
            "from typing import Any, Dict, List, Optional",
            "import rapidjson",
            "from freqtrade.constants import MINIMAL_CONFIG, Config",
            "from freqtrade.exceptions import ConfigurationError, OperationalException",
            "from freqtrade.misc import deep_merge_dicts"
        ],
        "reference_api": [
            "OperationalException",
            "log_config_error_range",
            "rapidjson.load",
            "ConfigurationError",
            "Path",
            "str",
            "open"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "log_config_error_range",
                "code": "def log_config_error_range(path: str, errmsg: str) -> str:\n    \"\"\"\n    Parses configuration file and prints range around error\n    \"\"\"\n    if path != \"-\":\n        offsetlist = re.findall(r\"(?<=Parse\\serror\\sat\\soffset\\s)\\d+\", errmsg)\n        if offsetlist:\n            offset = int(offsetlist[0])\n            text = Path(path).read_text()\n            # Fetch an offset of 80 characters around the error line\n            subtext = text[offset - min(80, offset) : offset + 80]\n            segments = subtext.split(\"\\n\")\n            if len(segments) > 3:\n                # Remove first and last lines, to avoid odd truncations\n                return \"\\n\".join(segments[1:-1])\n            else:\n                return subtext\n    return \"\""
            }
        ],
        "third_party": [
            "Path",
            "rapidjson.load",
            "OperationalException",
            "ConfigurationError"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def adjust_start_if_necessary(\n        self, timeframe_secs: int, startup_candles: int, min_date: datetime\n    ) -> None",
        "start_line": "102",
        "end_line": "120",
        "file_path": "freqtrade/configuration/timerange.py",
        "docstring": "The function adjust_start_if_necessary adjusts the start timestamp (startts) if required.\\nIt takes three parameters: timeframe_secs (timeframe in seconds), startup_candles (number of startup candles), and min_date (minimum start date as a datetime object).\\nIf starttype is not set or the combination of startup_candles and min_date is greater than or equal to startts, it logs a warning that the start date is being moved to account for the startup time.\\nIt then updates startts to be the timestamp of min_date plus the product of timeframe_secs and startup_candles, and sets starttype to \"date\".\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "14d7e6716435",
        "ground_truth": "def adjust_start_if_necessary(\n    self, timeframe_secs: int, startup_candles: int, min_date: datetime\n) -> None:\n    \"\"\"\n    Adjust startts by <startup_candles> candles.\n    Applies only if no startup-candles have been available.\n    :param timeframe_secs: Timeframe in seconds e.g. `timeframe_to_seconds('5m')`\n    :param startup_candles: Number of candles to move start-date forward\n    :param min_date: Minimum data date loaded. Key kriterium to decide if start-time\n                     has to be moved\n    :return: None (Modifies the object in place)\n    \"\"\"\n    if not self.starttype or (startup_candles and min_date.timestamp() >= self.startts):\n        # If no startts was defined, or backtest-data starts at the defined backtest-date\n        logger.warning(\n            \"Moving start-date by %s candles to account for startup time.\", startup_candles\n        )\n        self.startts = int(min_date.timestamp() + timeframe_secs * startup_candles)\n        self.starttype = \"date\"",
        "import_statements": [
            "import logging",
            "import re",
            "from datetime import datetime, timezone",
            "from typing import Optional",
            "from typing_extensions import Self",
            "from freqtrade.constants import DATETIME_PRINT_FORMAT",
            "from freqtrade.exceptions import ConfigurationError"
        ],
        "reference_api": [
            "logger.warning",
            "int",
            "min_date.timestamp"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "min_date.timestamp",
            "min_date.timestamp"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def trim_dataframe(\n    df: DataFrame, timerange, *, df_date_col: str = \"date\", startup_candles: int = 0\n) -> DataFrame",
        "start_line": "138",
        "end_line": "157",
        "file_path": "freqtrade/data/converter/converter.py",
        "docstring": "The function trim_dataframe(df: DataFrame, timerange, *, df_date_col: str = \"date\", startup_candles: int = 0) -> DataFrame trims a DataFrame based on a timerange and optional startup candles.\\nIf startup_candles is specified, it removes the first startup_candles rows from the DataFrame.\\nIf startup_candles is not specified and timerange.starttype is \"date\", it filters the DataFrame to include only rows where the date column is greater than or equal to timerange.startdt.\\nAdditionally, if timerange.stoptype is \"date\", it filters the DataFrame to include only rows where the date column is less than or equal to timerange.stopdt.\\nThe function returns the trimmed DataFrame.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "02d098994c47",
        "ground_truth": "def trim_dataframe(\n    df: DataFrame, timerange, *, df_date_col: str = \"date\", startup_candles: int = 0\n) -> DataFrame:\n    \"\"\"\n    Trim dataframe based on given timerange\n    :param df: Dataframe to trim\n    :param timerange: timerange (use start and end date if available)\n    :param df_date_col: Column in the dataframe to use as Date column\n    :param startup_candles: When not 0, is used instead the timerange start date\n    :return: trimmed dataframe\n    \"\"\"\n    if startup_candles:\n        # Trim candles instead of timeframe in case of given startup_candle count\n        df = df.iloc[startup_candles:, :]\n    else:\n        if timerange.starttype == \"date\":\n            df = df.loc[df[df_date_col] >= timerange.startdt, :]\n    if timerange.stoptype == \"date\":\n        df = df.loc[df[df_date_col] <= timerange.stopdt, :]\n    return df",
        "import_statements": [
            "import logging",
            "from typing import Dict",
            "from pandas import DataFrame, to_datetime",
            "from freqtrade.constants import DEFAULT_DATAFRAME_COLUMNS, Config",
            "from freqtrade.enums import CandleType, TradingMode"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def trades_list_to_df(trades: TradeList, convert: bool = True)",
        "start_line": "55",
        "end_line": "68",
        "file_path": "freqtrade/data/converter/trade_converter.py",
        "docstring": "The function trades_list_to_df(trades: TradeList, convert: bool = True) converts a list of trades into a DataFrame.\\nIf the trades list is empty, it initializes an empty DataFrame with columns defined by DEFAULT_TRADES_COLUMNS.\\nIf the trades list is not empty, it creates a DataFrame from the trades list using DEFAULT_TRADES_COLUMNS as the column names.\\nIf the convert parameter is True, it converts the data types of the DataFrame using the trades_convert_types function.\\nFinally, it returns the resulting DataFrame.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d3745d76e69d",
        "ground_truth": "def trades_list_to_df(trades: TradeList, convert: bool = True):\n    \"\"\"\n    convert trades list to dataframe\n    :param trades: List of Lists with constants.DEFAULT_TRADES_COLUMNS as columns\n    \"\"\"\n    if not trades:\n        df = DataFrame(columns=DEFAULT_TRADES_COLUMNS)\n    else:\n        df = DataFrame(trades, columns=DEFAULT_TRADES_COLUMNS)\n     if convert:\n        df = trades_convert_types(df)\n     return df",
        "import_statements": [
            "import logging",
            "from pathlib import Path",
            "from typing import Dict, List",
            "from pandas import DataFrame, to_datetime",
            "from freqtrade.configuration import TimeRange",
            "from freqtrade.constants import (\n    DEFAULT_DATAFRAME_COLUMNS,\n    DEFAULT_TRADES_COLUMNS,\n    TRADES_DTYPES,\n    Config,\n    TradeList,\n)",
            "from freqtrade.enums import CandleType, TradingMode",
            "from freqtrade.exceptions import OperationalException"
        ],
        "reference_api": [
            "DataFrame",
            "trades_convert_types"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "trades_convert_types",
                "code": "def trades_convert_types(trades: DataFrame) -> DataFrame:\n    \"\"\"\n    Convert Trades dtypes and add 'date' column\n    \"\"\"\n    trades = trades.astype(TRADES_DTYPES)\n    trades[\"date\"] = to_datetime(trades[\"timestamp\"], unit=\"ms\", utc=True)\n    return trades"
            }
        ],
        "third_party": [
            "DataFrame",
            "DataFrame"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def load_data(\n    datadir: Path,\n    timeframe: str,\n    pairs: List[str],\n    *,\n    timerange: Optional[TimeRange] = None,\n    fill_up_missing: bool = True,\n    startup_candles: int = 0,\n    fail_without_data: bool = False,\n    data_format: str = \"feather\",\n    candle_type: CandleType = CandleType.SPOT,\n    user_futures_funding_rate: Optional[int] = None,\n) -> Dict[str, DataFrame]",
        "start_line": "79",
        "end_line": "133",
        "file_path": "freqtrade/data/history/history_utils.py",
        "docstring": "The function load_data(\\ndatadir: Path,\\ntimeframe: str,\\npairs: List[str],\\n*,\\ntimerange: Optional[TimeRange] = None,\\nfill_up_missing: bool = True,\\nstartup_candles: int = 0,\\nfail_without_data: bool = False,\\ndata_format: str = \"feather\",\\ncandle_type: CandleType = CandleType.SPOT,\\nuser_futures_funding_rate: Optional[int] = None,\\n) -> Dict[str, DataFrame] loads historical trading data for the specified pairs and returns it as a dictionary of DataFrames.\\nIf startup_candles is greater than 0 and a timerange is provided, it logs the use of the indicator startup period.\\nIt initializes a data handler based on the specified data directory and format.\\nFor each trading pair, it calls load_pair_history to load the historical data, passing various parameters including timeframe, data directory, timerange, fill_up_missing, startup_candles, data handler, and candle type.\\nIf historical data is found and not empty, it adds the data to the result dictionary.\\nIf the data is empty and the candle type is FUNDING_RATE with a user-specified funding rate, it logs a warning.\\nIf the candle type is neither SPOT nor FUTURES, it adds an empty DataFrame with appropriate columns to the result dictionary.\\nIf fail_without_data is True and no data is found, it raises an OperationalException.\\nFinally, it returns the result dictionary containing the loaded data.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "891fe1f15ccf",
        "ground_truth": "def load_data(\n    datadir: Path,\n    timeframe: str,\n    pairs: List[str],\n    *,\n    timerange: Optional[TimeRange] = None,\n    fill_up_missing: bool = True,\n    startup_candles: int = 0,\n    fail_without_data: bool = False,\n    data_format: str = \"feather\",\n    candle_type: CandleType = CandleType.SPOT,\n    user_futures_funding_rate: Optional[int] = None,\n) -> Dict[str, DataFrame]:\n    \"\"\"\n    Load ohlcv history data for a list of pairs.\n     :param datadir: Path to the data storage location.\n    :param timeframe: Timeframe (e.g. \"5m\")\n    :param pairs: List of pairs to load\n    :param timerange: Limit data to be loaded to this timerange\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\n    :param startup_candles: Additional candles to load at the start of the period\n    :param fail_without_data: Raise OperationalException if no data is found.\n    :param data_format: Data format which should be used. Defaults to json\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    :return: dict(<pair>:<Dataframe>)\n    \"\"\"\n    result: Dict[str, DataFrame] = {}\n    if startup_candles > 0 and timerange:\n        logger.info(f\"Using indicator startup period: {startup_candles} ...\")\n     data_handler = get_datahandler(datadir, data_format)\n     for pair in pairs:\n        hist = load_pair_history(\n            pair=pair,\n            timeframe=timeframe,\n            datadir=datadir,\n            timerange=timerange,\n            fill_up_missing=fill_up_missing,\n            startup_candles=startup_candles,\n            data_handler=data_handler,\n            candle_type=candle_type,\n        )\n        if not hist.empty:\n            result[pair] = hist\n        else:\n            if candle_type is CandleType.FUNDING_RATE and user_futures_funding_rate is not None:\n                logger.warn(f\"{pair} using user specified [{user_futures_funding_rate}]\")\n            elif candle_type not in (CandleType.SPOT, CandleType.FUTURES):\n                result[pair] = DataFrame(columns=[\"date\", \"open\", \"close\", \"high\", \"low\", \"volume\"])\n     if fail_without_data and not result:\n        raise OperationalException(\"No data found. Terminating.\")\n    return result",
        "import_statements": [
            "import logging",
            "import operator",
            "from datetime import datetime, timedelta",
            "from pathlib import Path",
            "from typing import Dict, List, Optional, Tuple",
            "from pandas import DataFrame, concat",
            "from freqtrade.configuration import TimeRange",
            "from freqtrade.constants import (\n    DATETIME_PRINT_FORMAT,\n    DEFAULT_DATAFRAME_COLUMNS,\n    DL_DATA_TIMEFRAMES,\n    DOCS_LINK,\n    Config,\n)",
            "from freqtrade.data.converter import (\n    clean_ohlcv_dataframe,\n    convert_trades_to_ohlcv,\n    ohlcv_to_dataframe,\n    trades_df_remove_duplicates,\n    trades_list_to_df,\n)",
            "from freqtrade.data.history.datahandlers import IDataHandler, get_datahandler",
            "from freqtrade.enums import CandleType, TradingMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist",
            "from freqtrade.util import dt_ts, format_ms_time",
            "from freqtrade.util.datetime_helpers import dt_now",
            "from freqtrade.util.migrations import migrate_data"
        ],
        "reference_api": [
            "OperationalException",
            "logger.warn",
            "DataFrame",
            "load_pair_history",
            "logger.info",
            "get_datahandler"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "load_pair_history",
                "code": "def load_pair_history(\n    pair: str,\n    timeframe: str,\n    datadir: Path,\n    *,\n    timerange: Optional[TimeRange] = None,\n    fill_up_missing: bool = True,\n    drop_incomplete: bool = False,\n    startup_candles: int = 0,\n    data_format: Optional[str] = None,\n    data_handler: Optional[IDataHandler] = None,\n    candle_type: CandleType = CandleType.SPOT,\n) -> DataFrame:\n    \"\"\"\n    Load cached ohlcv history for the given pair.\n\n    :param pair: Pair to load data for\n    :param timeframe: Timeframe (e.g. \"5m\")\n    :param datadir: Path to the data storage location.\n    :param data_format: Format of the data. Ignored if data_handler is set.\n    :param timerange: Limit data to be loaded to this timerange\n    :param fill_up_missing: Fill missing values with \"No action\"-candles\n    :param drop_incomplete: Drop last candle assuming it may be incomplete.\n    :param startup_candles: Additional candles to load at the start of the period\n    :param data_handler: Initialized data-handler to use.\n                         Will be initialized from data_format if not set\n    :param candle_type: Any of the enum CandleType (must match trading mode!)\n    :return: DataFrame with ohlcv data, or empty DataFrame\n    \"\"\"\n    data_handler = get_datahandler(datadir, data_format, data_handler)\n\n    return data_handler.ohlcv_load(\n        pair=pair,\n        timeframe=timeframe,\n        timerange=timerange,\n        fill_missing=fill_up_missing,\n        drop_incomplete=drop_incomplete,\n        startup_candles=startup_candles,\n        candle_type=candle_type,\n    )"
            }
        ],
        "third_party": [
            "get_datahandler",
            "DataFrame",
            "OperationalException"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]",
        "start_line": "526",
        "end_line": "540",
        "file_path": "freqtrade/data/history/history_utils.py",
        "docstring": "The function get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime] calculates the overall time range covered by the provided data.\\nIt iterates through each DataFrame in the data dictionary, extracting the minimum and maximum dates from the \"date\" column of each DataFrame and converting them to Python datetime objects.\\nIt then compiles these date ranges into a list called timeranges.\\nThe function returns a tuple containing the earliest start date and the latest end date from the list of date ranges, using the min and max functions with operator.itemgetter to identify the appropriate elements.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "b9fc2db56238",
        "ground_truth": "def get_timerange(data: Dict[str, DataFrame]) -> Tuple[datetime, datetime]:\n    \"\"\"\n    Get the maximum common timerange for the given backtest data.\n     :param data: dictionary with preprocessed backtesting data\n    :return: tuple containing min_date, max_date\n    \"\"\"\n    timeranges = [\n        (frame[\"date\"].min().to_pydatetime(), frame[\"date\"].max().to_pydatetime())\n        for frame in data.values()\n    ]\n    return (\n        min(timeranges, key=operator.itemgetter(0))[0],\n        max(timeranges, key=operator.itemgetter(1))[1],\n    )",
        "import_statements": [
            "import logging",
            "import operator",
            "from datetime import datetime, timedelta",
            "from pathlib import Path",
            "from typing import Dict, List, Optional, Tuple",
            "from pandas import DataFrame, concat",
            "from freqtrade.configuration import TimeRange",
            "from freqtrade.constants import (\n    DATETIME_PRINT_FORMAT,\n    DEFAULT_DATAFRAME_COLUMNS,\n    DL_DATA_TIMEFRAMES,\n    DOCS_LINK,\n    Config,\n)",
            "from freqtrade.data.converter import (\n    clean_ohlcv_dataframe,\n    convert_trades_to_ohlcv,\n    ohlcv_to_dataframe,\n    trades_df_remove_duplicates,\n    trades_list_to_df,\n)",
            "from freqtrade.data.history.datahandlers import IDataHandler, get_datahandler",
            "from freqtrade.enums import CandleType, TradingMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.plugins.pairlist.pairlist_helpers import dynamic_expand_pairlist",
            "from freqtrade.util import dt_ts, format_ms_time",
            "from freqtrade.util.datetime_helpers import dt_now",
            "from freqtrade.util.migrations import migrate_data"
        ],
        "reference_api": [
            "min",
            "operator.itemgetter",
            "to_pydatetime",
            "max",
            "data.values"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "to_pydatetime",
            "to_pydatetime",
            "data.values"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def load_backtest_metadata(filename: Union[Path, str]) -> Dict[str, Any]",
        "start_line": "140",
        "end_line": "154",
        "file_path": "freqtrade/data/btanalysis.py",
        "docstring": "The function load_backtest_metadata(filename: Union[Path, str]) -> Dict[str, Any] loads metadata for backtesting from a specified file.\\nIt first resolves the full metadata filename using get_backtest_metadata_filename.\\nThe function attempts to open the resolved filename and load its contents as JSON using json_load.\\nIf the file is not found, it returns an empty dictionary.\\nIf any other exception occurs during the loading process, it raises an OperationalException with a message indicating an unexpected error while loading backtest metadata, preserving the original exception as the cause.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "27a8b9439d62",
        "ground_truth": "def load_backtest_metadata(filename: Union[Path, str]) -> Dict[str, Any]:\n    \"\"\"\n    Read metadata dictionary from backtest results file without reading and deserializing entire\n    file.\n    :param filename: path to backtest results file.\n    :return: metadata dict or None if metadata is not present.\n    \"\"\"\n    filename = get_backtest_metadata_filename(filename)\n    try:\n        with filename.open() as fp:\n            return json_load(fp)\n    except FileNotFoundError:\n        return {}\n    except Exception as e:\n        raise OperationalException(\"Unexpected error while loading backtest metadata.\") from e",
        "import_statements": [
            "import logging",
            "from copy import copy",
            "from datetime import datetime, timezone",
            "from pathlib import Path",
            "from typing import Any, Dict, List, Literal, Optional, Union",
            "from freqtrade.constants import LAST_BT_RESULT_FN, IntOrInf",
            "from freqtrade.exceptions import ConfigurationError, OperationalException",
            "from freqtrade.misc import file_dump_json, json_load",
            "from freqtrade.optimize.backtest_caching import get_backtest_metadata_filename",
            "from freqtrade.persistence import LocalTrade, Trade, init_db",
            "from freqtrade.types import BacktestHistoryEntryType, BacktestResultType"
        ],
        "reference_api": [
            "filename.open",
            "get_backtest_metadata_filename",
            "OperationalException",
            "json_load"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "get_backtest_metadata_filename",
                "code": "def get_backtest_metadata_filename(filename: Union[Path, str]) -> Path:\n    \"\"\"Return metadata filename for specified backtest results file.\"\"\"\n    filename = Path(filename)\n    return filename.parent / Path(f\"{filename.stem}.meta{filename.suffix}\")"
            },
            {
                "name": "json_load",
                "code": "def json_load(datafile: TextIO) -> Any:\n    \"\"\"\n    load data with rapidjson\n    Use this to have a consistent experience,\n    set number_mode to \"NM_NATIVE\" for greatest speed\n    \"\"\"\n    return rapidjson.load(datafile, number_mode=rapidjson.NM_NATIVE)"
            }
        ],
        "third_party": [
            "filename.open",
            "OperationalException"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def _load_backtest_analysis_data(backtest_dir: Path, name: str)",
        "start_line": "22",
        "end_line": "39",
        "file_path": "freqtrade/data/entryexitanalysis.py",
        "docstring": "The function _load_backtest_analysis_data(backtest_dir: Path, name: str) loads analysis data for backtesting from a specified directory.\\nIt first checks if backtest_dir is a directory.\\nIf it is, it constructs a path (scpf) to a pickle file using the latest backtest filename and appending the name parameter.\\nIf backtest_dir is not a directory, it constructs the path using the parent directory and the stem of backtest_dir.\\nThe function then attempts to open the pickle file in binary read mode and load its contents using joblib.load, logging a message indicating successful loading.\\nIf an exception occurs, it logs an error message and returns None.\\nFinally, it returns the loaded data.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ce5ea2849d1e",
        "ground_truth": "def _load_backtest_analysis_data(backtest_dir: Path, name: str):\n    if backtest_dir.is_dir():\n        scpf = Path(\n            backtest_dir,\n            Path(get_latest_backtest_filename(backtest_dir)).stem + \"_\" + name + \".pkl\",\n        )\n    else:\n        scpf = Path(backtest_dir.parent / f\"{backtest_dir.stem}_{name}.pkl\")\n     try:\n        with scpf.open(\"rb\") as scp:\n            loaded_data = joblib.load(scp)\n            logger.info(f\"Loaded {name} candles: {str(scpf)}\")\n    except Exception as e:\n        logger.error(f\"Cannot load {name} data from pickled results: \", e)\n        return None\n     return loaded_data",
        "import_statements": [
            "import logging",
            "from pathlib import Path",
            "from typing import List",
            "import joblib",
            "from freqtrade.configuration import TimeRange",
            "from freqtrade.constants import Config",
            "from freqtrade.data.btanalysis import (\n    get_latest_backtest_filename,\n    load_backtest_data,\n    load_backtest_stats,\n)",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.util import print_df_rich_table"
        ],
        "reference_api": [
            "get_latest_backtest_filename",
            "joblib.load",
            "backtest_dir.is_dir",
            "logger.info",
            "Path",
            "str",
            "logger.error",
            "scpf.open"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "get_latest_backtest_filename",
                "code": "def get_latest_backtest_filename(directory: Union[Path, str]) -> str:\n    \"\"\"\n    Get latest backtest export based on '.last_result.json'.\n    :param directory: Directory to search for last result\n    :return: string containing the filename of the latest backtest result\n    :raises: ValueError in the following cases:\n        * Directory does not exist\n        * `directory/.last_result.json` does not exist\n        * `directory/.last_result.json` has the wrong content\n    \"\"\"\n    return get_latest_optimize_filename(directory, \"backtest\")"
            }
        ],
        "third_party": [
            "backtest_dir.is_dir",
            "Path",
            "Path",
            "Path",
            "scpf.open",
            "joblib.load"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def combine_dataframes_by_column(\n    data: Dict[str, pd.DataFrame], column: str = \"close\"\n) -> pd.DataFrame",
        "start_line": "34",
        "end_line": "49",
        "file_path": "freqtrade/data/metrics.py",
        "docstring": "The function combine_dataframes_by_column(data: Dict[str, pd.DataFrame], column: str = \"close\") -> pd.DataFrame combines multiple DataFrames by a specified column.\\nIt first checks if the data dictionary is empty and raises a ValueError if no data is provided.\\nThe function then concatenates the specified column from each DataFrame in the data dictionary into a single DataFrame (df_comb).\\nEach DataFrame is set to use the \"date\" column as the index, and the specified column is renamed to the corresponding key from the data dictionary.\\nThe resulting DataFrame (df_comb) contains the combined data with each column representing the specified column from the original DataFrames.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1d5350329f00",
        "ground_truth": "def combine_dataframes_by_column(\n    data: Dict[str, pd.DataFrame], column: str = \"close\"\n) -> pd.DataFrame:\n    \"\"\"\n    Combine multiple dataframes \"column\"\n    :param data: Dict of Dataframes, dict key should be pair.\n    :param column: Column in the original dataframes to use\n    :return: DataFrame with the column renamed to the dict key.\n    :raise: ValueError if no data is provided.\n    \"\"\"\n    if not data:\n        raise ValueError(\"No data provided.\")\n    df_comb = pd.concat(\n        [data[pair].set_index(\"date\").rename({column: pair}, axis=1)[pair] for pair in data], axis=1\n    )\n    return df_comb",
        "import_statements": [
            "import logging",
            "import math",
            "from dataclasses import dataclass",
            "from datetime import datetime",
            "from typing import Dict, Tuple"
        ],
        "reference_api": [
            "ValueError",
            "set_index",
            "pd.concat",
            "rename"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "pd.concat",
            "rename",
            "set_index"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def calculate_csum(trades: pd.DataFrame, starting_balance: float = 0) -> Tuple[float, float]",
        "start_line": "225",
        "end_line": "241",
        "file_path": "freqtrade/data/metrics.py",
        "docstring": "The function calculate_csum(trades: pd.DataFrame, starting_balance: float = 0) -> Tuple[float, float] calculates the cumulative sum of trade profits and returns the minimum and maximum cumulative sums.\\nIt first checks if the trades DataFrame is empty and raises a ValueError if it is.\\nIt then creates a new DataFrame (csum_df) and calculates the cumulative sum of the \"profit_abs\" column from the trades DataFrame, storing it in the \"sum\" column of csum_df.\\nThe function calculates the minimum and maximum values of the cumulative sum, adding the starting_balance to each.\\nFinally, it returns the minimum and maximum cumulative sums as a tuple.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1aa682bb201b",
        "ground_truth": "def calculate_csum(trades: pd.DataFrame, starting_balance: float = 0) -> Tuple[float, float]:\n    \"\"\"\n    Calculate min/max cumsum of trades, to show if the wallet/stake amount ratio is sane\n    :param trades: DataFrame containing trades (requires columns close_date and profit_percent)\n    :param starting_balance: Add starting balance to results, to show the wallets high / low points\n    :return: Tuple (float, float) with cumsum of profit_abs\n    :raise: ValueError if trade-dataframe was found empty.\n    \"\"\"\n    if len(trades) == 0:\n        raise ValueError(\"Trade dataframe empty.\")\n     csum_df = pd.DataFrame()\n    csum_df[\"sum\"] = trades[\"profit_abs\"].cumsum()\n    csum_min = csum_df[\"sum\"].min() + starting_balance\n    csum_max = csum_df[\"sum\"].max() + starting_balance\n     return csum_min, csum_max",
        "import_statements": [
            "import logging",
            "import math",
            "from dataclasses import dataclass",
            "from datetime import datetime",
            "from typing import Dict, Tuple"
        ],
        "reference_api": [
            "min",
            "cumsum",
            "ValueError",
            "len",
            "max",
            "pd.DataFrame"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "pd.DataFrame",
            "cumsum"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def _find_trades_for_stoploss_range(self, df, pair: str, stoploss_range) -> list",
        "start_line": "420",
        "end_line": "432",
        "file_path": "freqtrade/edge/edge_positioning.py",
        "docstring": "The function _find_trades_for_stoploss_range(self, df, pair: str, stoploss_range) -> list identifies trades within a specified stoploss range.\\nIt extracts relevant columns from the DataFrame (df), including \"enter_long\", \"exit_long\", \"date\", and OHLC (open, high, low, close) values.\\nThe function initializes an empty list (result) to store the identified trades.\\nFor each stoploss value in the stoploss_range, it calls the method _detect_next_stop_or_sell_point with the extracted columns, the rounded stoploss value, and the pair identifier.\\nThe results from each call are concatenated to the result list.\\nFinally, the function returns the list of identified trades.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "3ea153cc033e",
        "ground_truth": "def _find_trades_for_stoploss_range(self, df, pair: str, stoploss_range) -> list:\n    buy_column = df[\"enter_long\"].values\n    sell_column = df[\"exit_long\"].values\n    date_column = df[\"date\"].values\n    ohlc_columns = df[[\"open\", \"high\", \"low\", \"close\"]].values\n    result: list = []\n    for stoploss in stoploss_range:\n        result += self._detect_next_stop_or_sell_point(\n            buy_column, sell_column, date_column, ohlc_columns, round(stoploss, 6), pair\n        )\n    return result",
        "import_statements": [
            "import logging",
            "from collections import defaultdict",
            "from copy import deepcopy",
            "from datetime import timedelta",
            "from typing import Any, Dict, List, NamedTuple",
            "from pandas import DataFrame",
            "from freqtrade.configuration import TimeRange",
            "from freqtrade.constants import DATETIME_PRINT_FORMAT, UNLIMITED_STAKE_AMOUNT, Config",
            "from freqtrade.data.history import get_timerange, load_data, refresh_data",
            "from freqtrade.enums import CandleType, ExitType, RunMode",
            "from freqtrade.exceptions import OperationalException",
            "from freqtrade.exchange import timeframe_to_seconds",
            "from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist",
            "from freqtrade.strategy.interface import IStrategy",
            "from freqtrade.util import dt_now"
        ],
        "reference_api": [
            "round",
            "self._detect_next_stop_or_sell_point"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "self._detect_next_stop_or_sell_point",
                "code": "def _detect_next_stop_or_sell_point(\n        self, buy_column, sell_column, date_column, ohlc_columns, stoploss, pair: str\n    ):\n        \"\"\"\n        Iterate through ohlc_columns in order to find the next trade\n        Next trade opens from the first buy signal noticed to\n        The sell or stoploss signal after it.\n        It then cuts OHLC, buy_column, sell_column and date_column.\n        Cut from (the exit trade index) + 1.\n\n        Author: https://github.com/mishaker\n        \"\"\"\n\n        result: list = []\n        start_point = 0\n\n        while True:\n            open_trade_index = utf1st.find_1st(buy_column, 1, utf1st.cmp_equal)\n\n            # Return empty if we don't find trade entry (i.e. buy==1) or\n            # we find a buy but at the end of array\n            if open_trade_index == -1 or open_trade_index == len(buy_column) - 1:\n                break\n            else:\n                # When a buy signal is seen,\n                # trade opens in reality on the next candle\n                open_trade_index += 1\n\n            open_price = ohlc_columns[open_trade_index, 0]\n            stop_price = open_price * (stoploss + 1)\n\n            # Searching for the index where stoploss is hit\n            stop_index = utf1st.find_1st(\n                ohlc_columns[open_trade_index:, 2], stop_price, utf1st.cmp_smaller\n            )\n\n            # If we don't find it then we assume stop_index will be far in future (infinite number)\n            if stop_index == -1:\n                stop_index = float(\"inf\")\n\n            # Searching for the index where sell is hit\n            sell_index = utf1st.find_1st(sell_column[open_trade_index:], 1, utf1st.cmp_equal)\n\n            # If we don't find it then we assume sell_index will be far in future (infinite number)\n            if sell_index == -1:\n                sell_index = float(\"inf\")\n\n            # Check if we don't find any stop or sell point (in that case trade remains open)\n            # It is not interesting for Edge to consider it so we simply ignore the trade\n            # And stop iterating there is no more entry\n            if stop_index == sell_index == float(\"inf\"):\n                break\n\n            if stop_index <= sell_index:\n                exit_index = open_trade_index + stop_index\n                exit_type = ExitType.STOP_LOSS\n                exit_price = stop_price\n            elif stop_index > sell_index:\n                # If exit is SELL then we exit at the next candle\n                exit_index = open_trade_index + sell_index + 1\n\n                # Check if we have the next candle\n                if len(ohlc_columns) - 1 < exit_index:\n                    break\n\n                exit_type = ExitType.EXIT_SIGNAL\n                exit_price = ohlc_columns[exit_index, 0]\n\n            trade = {\n                \"pair\": pair,\n                \"stoploss\": stoploss,\n                \"profit_ratio\": \"\",\n                \"profit_abs\": \"\",\n                \"open_date\": date_column[open_trade_index],\n                \"close_date\": date_column[exit_index],\n                \"trade_duration\": \"\",\n                \"open_rate\": round(open_price, 15),\n                \"close_rate\": round(exit_price, 15),\n                \"exit_type\": exit_type,\n            }\n\n            result.append(trade)\n\n            # Giving a view of exit_index till the end of array\n            buy_column = buy_column[exit_index:]\n            sell_column = sell_column[exit_index:]\n            date_column = date_column[exit_index:]\n            ohlc_columns = ohlc_columns[exit_index:]\n            start_point += exit_index\n\n        return result"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def get_tickers(self, symbols: Optional[List[str]] = None, cached: bool = False) -> Tickers",
        "start_line": "56",
        "end_line": "63",
        "file_path": "freqtrade/exchange/binance.py",
        "docstring": "The function get_tickers(self, symbols: Optional[List[str]] = None, cached: bool = False) -> Tickers retrieves ticker information for specified symbols.\\nIt first calls the superclass method get_tickers with the provided symbols and cached flag to obtain the ticker data.\\nIf the trading mode is set to TradingMode.FUTURES, it handles a specific case for Binance futures where bid/ask values are not included in the ticker data.\\nIn this case, it fetches the bid/ask values separately using fetch_bids_asks and combines them with the ticker data using deep_merge_dicts, ensuring null values are not overridden.\\nFinally, the function returns the combined ticker data.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "13cfab8156a8",
        "ground_truth": "def get_tickers(self, symbols: Optional[List[str]] = None, cached: bool = False) -> Tickers:\n    tickers = super().get_tickers(symbols=symbols, cached=cached)\n    if self.trading_mode == TradingMode.FUTURES:\n        # Binance's future result has no bid/ask values.\n        # Therefore we must fetch that from fetch_bids_asks and combine the two results.\n        bidsasks = self.fetch_bids_asks(symbols, cached)\n        tickers = deep_merge_dicts(bidsasks, tickers, allow_null_overrides=False)\n    return tickers",
        "import_statements": [
            "import logging",
            "from datetime import datetime, timezone",
            "from pathlib import Path",
            "from typing import Dict, List, Optional, Tuple",
            "import ccxt",
            "from freqtrade.enums import CandleType, MarginMode, PriceType, TradingMode",
            "from freqtrade.exceptions import DDosProtection, OperationalException, TemporaryError",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.exchange.common import retrier",
            "from freqtrade.exchange.types import OHLCVResponse, Tickers",
            "from freqtrade.misc import deep_merge_dicts, json_load"
        ],
        "reference_api": [
            "super",
            "deep_merge_dicts",
            "get_tickers",
            "self.fetch_bids_asks"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "get_tickers",
                "code": "def get_tickers(self, symbols: Optional[List[str]] = None, cached: bool = False) -> Tickers:\n        tickers = super().get_tickers(symbols=symbols, cached=cached)\n        if self.trading_mode == TradingMode.FUTURES:\n            # Binance's future result has no bid/ask values.\n            # Therefore we must fetch that from fetch_bids_asks and combine the two results.\n            bidsasks = self.fetch_bids_asks(symbols, cached)\n            tickers = deep_merge_dicts(bidsasks, tickers, allow_null_overrides=False)\n        return tickers"
            },
            {
                "name": "deep_merge_dicts",
                "code": "def deep_merge_dicts(source, destination, allow_null_overrides: bool = True):\n    \"\"\"\n    Values from Source override destination, destination is returned (and modified!!)\n    Sample:\n    >>> a = { 'first' : { 'rows' : { 'pass' : 'dog', 'number' : '1' } } }\n    >>> b = { 'first' : { 'rows' : { 'fail' : 'cat', 'number' : '5' } } }\n    >>> merge(b, a) == { 'first' : { 'rows' : { 'pass' : 'dog', 'fail' : 'cat', 'number' : '5' } } }\n    True\n    \"\"\"\n    for key, value in source.items():\n        if isinstance(value, dict):\n            # get node or create one\n            node = destination.setdefault(key, {})\n            deep_merge_dicts(value, node, allow_null_overrides)\n        elif value is not None or allow_null_overrides:\n            destination[key] = value\n\n    return destination"
            }
        ],
        "third_party": [
            "self.fetch_bids_asks"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": " def load_leverage_tiers(self) -> Dict[str, List[Dict]]",
        "start_line": "207",
        "end_line": "216",
        "file_path": "freqtrade/exchange/binance.py",
        "docstring": "The function load_leverage_tiers(self) -> Dict[str, List[Dict]] loads leverage tier information for trading pairs.\\nIf the trading mode is set to TradingMode.FUTURES, it checks if the configuration is in dry run mode.\\nIn dry run mode, it reads leverage tier data from a local JSON file named \"binance_leverage_tiers.json\" located in the same directory as the script, and loads the data using json_load.\\nIf not in dry run mode, it calls the method get_leverage_tiers to retrieve the leverage tier data from an external source.\\nIf the trading mode is not FUTURES, it returns an empty dictionary.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "75f06fc43aa7",
        "ground_truth": "def load_leverage_tiers(self) -> Dict[str, List[Dict]]:\n    if self.trading_mode == TradingMode.FUTURES:\n        if self._config[\"dry_run\"]:\n            leverage_tiers_path = Path(__file__).parent / \"binance_leverage_tiers.json\"\n            with leverage_tiers_path.open() as json_file:\n                return json_load(json_file)\n        else:\n            return self.get_leverage_tiers()\n    else:\n        return {}",
        "import_statements": [
            "import logging",
            "from datetime import datetime, timezone",
            "from pathlib import Path",
            "from typing import Dict, List, Optional, Tuple",
            "import ccxt",
            "from freqtrade.enums import CandleType, MarginMode, PriceType, TradingMode",
            "from freqtrade.exceptions import DDosProtection, OperationalException, TemporaryError",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.exchange.common import retrier",
            "from freqtrade.exchange.types import OHLCVResponse, Tickers",
            "from freqtrade.misc import deep_merge_dicts, json_load"
        ],
        "reference_api": [
            "self.get_leverage_tiers",
            "leverage_tiers_path.open",
            "json_load",
            "Path"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "json_load",
                "code": "def json_load(datafile: TextIO) -> Any:\n    \"\"\"\n    load data with rapidjson\n    Use this to have a consistent experience,\n    set number_mode to \"NM_NATIVE\" for greatest speed\n    \"\"\"\n    return rapidjson.load(datafile, number_mode=rapidjson.NM_NATIVE)"
            }
        ],
        "third_party": [
            "Path",
            "leverage_tiers_path.open",
            "self.get_leverage_tiers"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def dry_run_liquidation_price(\n        self,\n        pair: str,\n        open_rate: float,  # Entry price of position\n        is_short: bool,\n        amount: float,\n        stake_amount: float,\n        leverage: float,\n        wallet_balance: float,  # Or margin balance\n        mm_ex_1: float = 0.0,  # (Binance) Cross only\n        upnl_ex_1: float = 0.0,  # (Binance) Cross only\n    ) -> Optional[float]",
        "start_line": "142",
        "end_line": "201",
        "file_path": "freqtrade/exchange/bybit.py",
        "docstring": "The function dry_run_liquidation_price calculates the estimated liquidation price for a leveraged trading position in dry run mode.\\nIt takes several parameters including the trading pair, entry price, position type (short or long), amount, stake amount, leverage, wallet balance, and optional parameters for cross margin mode (mm_ex_1 and upnl_ex_1).\\nThe function retrieves the market details for the given pair and the maintenance margin ratio and amount using get_maintenance_ratio_and_amt.\\nIf the trading mode is FUTURES and the margin mode is ISOLATED, it calculates the initial margin rate based on the leverage.\\nFor short positions, it calculates the liquidation price using the formula open_rate * (1 + initial_margin_rate - mm_ratio).\\nFor long positions, it uses the formula open_rate * (1 - initial_margin_rate + mm_ratio).\\nIf the market uses inverse contracts, it raises an OperationalException since inverse contracts are not supported.\\nIf the trading mode and margin mode conditions are not met, it raises an OperationalException indicating that only isolated futures are supported for leverage trading.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "578367a216e1",
        "ground_truth": "def dry_run_liquidation_price(\n    self,\n    pair: str,\n    open_rate: float,  # Entry price of position\n    is_short: bool,\n    amount: float,\n    stake_amount: float,\n    leverage: float,\n    wallet_balance: float,  # Or margin balance\n    mm_ex_1: float = 0.0,  # (Binance) Cross only\n    upnl_ex_1: float = 0.0,  # (Binance) Cross only\n) -> Optional[float]:\n    \"\"\"\n    Important: Must be fetching data from cached values as this is used by backtesting!\n    PERPETUAL:\n     bybit:\n      https://www.bybithelp.com/HelpCenterKnowledge/bybitHC_Article?language=en_US&id=000001067\n    Long:\n    Liquidation Price = (\n        Entry Price * (1 - Initial Margin Rate + Maintenance Margin Rate)\n        - Extra Margin Added/ Contract)\n    Short:\n    Liquidation Price = (\n        Entry Price * (1 + Initial Margin Rate - Maintenance Margin Rate)\n        + Extra Margin Added/ Contract)\n    Implementation Note: Extra margin is currently not used.\n    :param pair: Pair to calculate liquidation price for\n    :param open_rate: Entry price of position\n    :param is_short: True if the trade is a short, false otherwise\n    :param amount: Absolute value of position size incl. leverage (in base currency)\n    :param stake_amount: Stake amount - Collateral in settle currency.\n    :param leverage: Leverage used for this position.\n    :param trading_mode: SPOT, MARGIN, FUTURES, etc.\n    :param margin_mode: Either ISOLATED or CROSS\n    :param wallet_balance: Amount of margin_mode in the wallet being used to trade\n        Cross-Margin Mode: crossWalletBalance\n        Isolated-Margin Mode: isolatedWalletBalance\n    \"\"\"\n    market = self.markets[pair]\n    mm_ratio, _ = self.get_maintenance_ratio_and_amt(pair, stake_amount)\n    if self.trading_mode == TradingMode.FUTURES and self.margin_mode == MarginMode.ISOLATED:\n        if market[\"inverse\"]:\n            raise OperationalException(\"Freqtrade does not yet support inverse contracts\")\n        initial_margin_rate = 1 / leverage\n        # See docstring - ignores extra margin!\n        if is_short:\n            return open_rate * (1 + initial_margin_rate - mm_ratio)\n        else:\n            return open_rate * (1 - initial_margin_rate + mm_ratio)\n    else:\n        raise OperationalException(\n            \"Freqtrade only supports isolated futures for leverage trading\"\n        )",
        "import_statements": [
            "import logging",
            "from datetime import datetime, timedelta",
            "from typing import Any, Dict, List, Optional, Tuple",
            "import ccxt",
            "from freqtrade.constants import BuySell",
            "from freqtrade.enums import CandleType, MarginMode, PriceType, TradingMode",
            "from freqtrade.exceptions import DDosProtection, ExchangeError, OperationalException, TemporaryError",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.exchange.common import retrier",
            "from freqtrade.util.datetime_helpers import dt_now, dt_ts"
        ],
        "reference_api": [
            "self.get_maintenance_ratio_and_amt",
            "OperationalException"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "self.get_maintenance_ratio_and_amt",
            "OperationalException",
            "OperationalException"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def get_leverage_tiers(self) -> Dict[str, List[Dict]]",
        "start_line": "253",
        "end_line": "270",
        "file_path": "freqtrade/exchange/bybit.py",
        "docstring": "The function get_leverage_tiers retrieves leverage tier information for trading pairs.\\nIt first attempts to load cached leverage tiers using load_cached_leverage_tiers with the configured stake currency and a cache duration of one day.\\nIf cached tiers are found, it returns them.\\nIf no cached tiers are available, it fetches the leverage tiers from the exchange by calling the superclass method get_leverage_tiers.\\nAfter fetching the tiers, it caches them using cache_leverage_tiers with the retrieved tiers and the configured stake currency.\\nFinally, it returns the fetched leverage tiers.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c46eb69f5352",
        "ground_truth": "def get_leverage_tiers(self) -> Dict[str, List[Dict]]:\n    \"\"\"\n    Cache leverage tiers for 1 day, since they are not expected to change often, and\n    bybit requires pagination to fetch all tiers.\n    \"\"\"\n    # Load cached tiers\n    tiers_cached = self.load_cached_leverage_tiers(\n        self._config[\"stake_currency\"], timedelta(days=1)\n    )\n    if tiers_cached:\n        return tiers_cached\n    # Fetch tiers from exchange\n    tiers = super().get_leverage_tiers()\n    self.cache_leverage_tiers(tiers, self._config[\"stake_currency\"])\n    return tiers",
        "import_statements": [
            "import logging",
            "from datetime import datetime, timedelta",
            "from typing import Any, Dict, List, Optional, Tuple",
            "import ccxt",
            "from freqtrade.constants import BuySell",
            "from freqtrade.enums import CandleType, MarginMode, PriceType, TradingMode",
            "from freqtrade.exceptions import DDosProtection, ExchangeError, OperationalException, TemporaryError",
            "from freqtrade.exchange import Exchange",
            "from freqtrade.exchange.common import retrier",
            "from freqtrade.util.datetime_helpers import dt_now, dt_ts"
        ],
        "reference_api": [
            "super",
            "self.load_cached_leverage_tiers",
            "get_leverage_tiers",
            "self.cache_leverage_tiers",
            "timedelta"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "self.load_cached_leverage_tiers",
            "timedelta",
            "get_leverage_tiers",
            "self.cache_leverage_tiers"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def _load_async_markets(self, reload: bool = False) -> Dict[str, Any]",
        "start_line": "574",
        "end_line": "585",
        "file_path": "freqtrade/exchange/exchange.py",
        "docstring": "The function _load_async_markets(self, reload: bool = False) -> Dict[str, Any] asynchronously loads market data.\\nIt uses the event loop to run the asynchronous method _api_async.load_markets with the reload flag and an empty params dictionary.\\nIf the loaded markets result in an exception, it raises that exception.\\nIf the operation times out, it logs a warning message with the reason for the timeout and raises a TemporaryError.\\nFinally, it returns the loaded market data.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "68a80cf49b62",
        "ground_truth": "def _load_async_markets(self, reload: bool = False) -> Dict[str, Any]:\n    try:\n        markets = self.loop.run_until_complete(\n            self._api_async.load_markets(reload=reload, params={})\n        )\n        if isinstance(markets, Exception):\n            raise markets\n        return markets\n    except asyncio.TimeoutError as e:\n        logger.warning(\"Could not load markets. Reason: %s\", e)\n        raise TemporaryError from e",
        "import_statements": [
            "import asyncio",
            "import inspect",
            "import logging",
            "import signal",
            "from copy import deepcopy",
            "from datetime import datetime, timedelta, timezone",
            "from math import floor, isnan",
            "from threading import Lock",
            "from typing import Any, Coroutine, Dict, List, Literal, Optional, Tuple, Union",
            "import ccxt",
            "from cachetools import TTLCache",
            "from ccxt import TICK_SIZE",
            "from dateutil import parser",
            "from pandas import DataFrame, concat",
            "from freqtrade.constants import (\n    DEFAULT_AMOUNT_RESERVE_PERCENT,\n    NON_OPEN_EXCHANGE_STATES,\n    BidAsk,\n    BuySell,\n    Config,\n    EntryExit,\n    ExchangeConfig,\n    ListPairsWithTimeframes,\n    MakerTaker,\n    OBLiteral,\n    PairWithTimeframe,\n)",
            "from freqtrade.data.converter import clean_ohlcv_dataframe, ohlcv_to_dataframe, trades_dict_to_list",
            "from freqtrade.enums import (\n    OPTIMIZE_MODES,\n    TRADE_MODES,\n    CandleType,\n    MarginMode,\n    PriceType,\n    RunMode,\n    TradingMode,\n)",
            "from freqtrade.exceptions import (\n    ConfigurationError,\n    DDosProtection,\n    ExchangeError,\n    InsufficientFundsError,\n    InvalidOrderException,\n    OperationalException,\n    PricingError,\n    RetryableOrderError,\n    TemporaryError,\n)",
            "from freqtrade.exchange.common import (\n    API_FETCH_ORDER_RETRY_COUNT,\n    remove_exchange_credentials,\n    retrier,\n    retrier_async,\n)",
            "from freqtrade.exchange.exchange_utils import (\n    ROUND,\n    ROUND_DOWN,\n    ROUND_UP,\n    amount_to_contract_precision,\n    amount_to_contracts,\n    amount_to_precision,\n    contracts_to_amount,\n    date_minus_candles,\n    is_exchange_known_ccxt,\n    market_is_active,\n    price_to_precision,\n)",
            "from freqtrade.exchange.exchange_utils_timeframe import (\n    timeframe_to_minutes,\n    timeframe_to_msecs,\n    timeframe_to_next_date,\n    timeframe_to_prev_date,\n    timeframe_to_seconds,\n)",
            "from freqtrade.exchange.exchange_ws import ExchangeWS",
            "from freqtrade.exchange.types import OHLCVResponse, OrderBook, Ticker, Tickers",
            "from freqtrade.misc import (\n    chunks,\n    deep_merge_dicts,\n    file_dump_json,\n    file_load_json,\n    safe_value_fallback2,\n)",
            "from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist",
            "from freqtrade.util import dt_from_ts, dt_now",
            "from freqtrade.util.datetime_helpers import dt_humanize_delta, dt_ts, format_ms_time",
            "from freqtrade.util.periodic_cache import PeriodicCache"
        ],
        "reference_api": [
            "run_until_complete",
            "logger.warning",
            "load_markets",
            "isinstance"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "run_until_complete",
            "load_markets"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def validate_stakecurrency(self, stake_currency: str) -> None",
        "start_line": "621",
        "end_line": "639",
        "file_path": "freqtrade/exchange/exchange.py",
        "docstring": "The function validate_stakecurrency(self, stake_currency: str) -> None validates the provided stake currency against the available markets.\\nIf the _markets attribute is not loaded, it raises an OperationalException, indicating that markets could not be loaded and prompting the user to investigate the error.\\nIt retrieves the available quote currencies using get_quote_currencies().\\nIf the provided stake currency is not in the list of quote currencies, it raises a ConfigurationError, informing the user that the stake currency is not available on the exchange and listing the available currencies.\n",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "8280c7bdd5de",
        "ground_truth": "def validate_stakecurrency(self, stake_currency: str) -> None:\n    \"\"\"\n    Checks stake-currency against available currencies on the exchange.\n    Only runs on startup. If markets have not been loaded, there's been a problem with\n    the connection to the exchange.\n    :param stake_currency: Stake-currency to validate\n    :raise: OperationalException if stake-currency is not available.\n    \"\"\"\n    if not self._markets:\n        raise OperationalException(\n            \"Could not load markets, therefore cannot start. \"\n            \"Please investigate the above error for more details.\"\n        )\n    quote_currencies = self.get_quote_currencies()\n    if stake_currency not in quote_currencies:\n        raise ConfigurationError(\n            f\"{stake_currency} is not available as stake on {self.name}. \"\n            f\"Available currencies are: {', '.join(quote_currencies)}\"\n        )",
        "import_statements": [
            "import asyncio",
            "import inspect",
            "import logging",
            "import signal",
            "from copy import deepcopy",
            "from datetime import datetime, timedelta, timezone",
            "from math import floor, isnan",
            "from threading import Lock",
            "from typing import Any, Coroutine, Dict, List, Literal, Optional, Tuple, Union",
            "import ccxt",
            "from cachetools import TTLCache",
            "from ccxt import TICK_SIZE",
            "from dateutil import parser",
            "from pandas import DataFrame, concat",
            "from freqtrade.constants import (\n    DEFAULT_AMOUNT_RESERVE_PERCENT,\n    NON_OPEN_EXCHANGE_STATES,\n    BidAsk,\n    BuySell,\n    Config,\n    EntryExit,\n    ExchangeConfig,\n    ListPairsWithTimeframes,\n    MakerTaker,\n    OBLiteral,\n    PairWithTimeframe,\n)",
            "from freqtrade.data.converter import clean_ohlcv_dataframe, ohlcv_to_dataframe, trades_dict_to_list",
            "from freqtrade.enums import (\n    OPTIMIZE_MODES,\n    TRADE_MODES,\n    CandleType,\n    MarginMode,\n    PriceType,\n    RunMode,\n    TradingMode,\n)",
            "from freqtrade.exceptions import (\n    ConfigurationError,\n    DDosProtection,\n    ExchangeError,\n    InsufficientFundsError,\n    InvalidOrderException,\n    OperationalException,\n    PricingError,\n    RetryableOrderError,\n    TemporaryError,\n)",
            "from freqtrade.exchange.common import (\n    API_FETCH_ORDER_RETRY_COUNT,\n    remove_exchange_credentials,\n    retrier,\n    retrier_async,\n)",
            "from freqtrade.exchange.exchange_utils import (\n    ROUND,\n    ROUND_DOWN,\n    ROUND_UP,\n    amount_to_contract_precision,\n    amount_to_contracts,\n    amount_to_precision,\n    contracts_to_amount,\n    date_minus_candles,\n    is_exchange_known_ccxt,\n    market_is_active,\n    price_to_precision,\n)",
            "from freqtrade.exchange.exchange_utils_timeframe import (\n    timeframe_to_minutes,\n    timeframe_to_msecs,\n    timeframe_to_next_date,\n    timeframe_to_prev_date,\n    timeframe_to_seconds,\n)",
            "from freqtrade.exchange.exchange_ws import ExchangeWS",
            "from freqtrade.exchange.types import OHLCVResponse, OrderBook, Ticker, Tickers",
            "from freqtrade.misc import (\n    chunks,\n    deep_merge_dicts,\n    file_dump_json,\n    file_load_json,\n    safe_value_fallback2,\n)",
            "from freqtrade.plugins.pairlist.pairlist_helpers import expand_pairlist",
            "from freqtrade.util import dt_from_ts, dt_now",
            "from freqtrade.util.datetime_helpers import dt_humanize_delta, dt_ts, format_ms_time",
            "from freqtrade.util.periodic_cache import PeriodicCache"
        ],
        "reference_api": [
            "self.get_quote_currencies",
            "OperationalException",
            "ConfigurationError",
            "join"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "self.get_quote_currencies",
                "code": "def get_quote_currencies(self) -> List[str]:\n        \"\"\"\n        Return a list of supported quote currencies\n        \"\"\"\n        markets = self.markets\n        return sorted(set([x[\"quote\"] for _, x in markets.items()]))"
            }
        ],
        "third_party": [
            "OperationalException",
            "ConfigurationError",
            "join"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def list_available_exchanges(all_exchanges: bool) -> List[ValidExchangesType]",
        "start_line": "119",
        "end_line": "132",
        "file_path": "freqtrade/exchange/exchange_utils.py",
        "docstring": "The function list_available_exchanges(all_exchanges: bool) -> List[ValidExchangesType] generates a list of available exchanges.\\nIf all_exchanges is True, it retrieves the list of all exchanges using ccxt_exchanges(); otherwise, it retrieves a list of available exchanges using available_exchanges().\\nIt imports ExchangeResolver from freqtrade.resolvers.exchange_resolver and retrieves a dictionary of subclassed exchanges by searching all objects in ExchangeResolver.\\nThe function then builds a list of valid exchanges (exchanges_valid) by iterating through the exchanges list and using _build_exchange_list_entry to create entries, incorporating the subclassed exchange information.\\nFinally, it returns the list of valid exchanges.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "769debd38f58",
        "ground_truth": "def list_available_exchanges(all_exchanges: bool) -> List[ValidExchangesType]:\n    \"\"\"\n    :return: List of tuples with exchangename, valid, reason.\n    \"\"\"\n    exchanges = ccxt_exchanges() if all_exchanges else available_exchanges()\n    from freqtrade.resolvers.exchange_resolver import ExchangeResolver\n     subclassed = {e[\"name\"].lower(): e for e in ExchangeResolver.search_all_objects({}, False)}\n     exchanges_valid: List[ValidExchangesType] = [\n        _build_exchange_list_entry(e, subclassed) for e in exchanges\n    ]\n     return exchanges_valid",
        "import_statements": [
            "from datetime import datetime, timedelta, timezone",
            "from math import ceil, floor",
            "from typing import Any, Dict, List, Optional, Tuple",
            "import ccxt",
            "from ccxt import (\n    DECIMAL_PLACES,\n    ROUND,\n    ROUND_DOWN,\n    ROUND_UP,\n    SIGNIFICANT_DIGITS,\n    TICK_SIZE,\n    TRUNCATE,\n    decimal_to_precision,\n)",
            "from freqtrade.exchange.common import (\n    BAD_EXCHANGES,\n    EXCHANGE_HAS_OPTIONAL,\n    EXCHANGE_HAS_REQUIRED,\n    SUPPORTED_EXCHANGES,\n)",
            "from freqtrade.exchange.exchange_utils_timeframe import timeframe_to_minutes, timeframe_to_prev_date",
            "from freqtrade.types import ValidExchangesType",
            "from freqtrade.util import FtPrecise"
        ],
        "reference_api": [
            "available_exchanges",
            "ccxt_exchanges",
            "lower",
            "ExchangeResolver.search_all_objects",
            "_build_exchange_list_entry"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "ccxt_exchanges",
                "code": "def ccxt_exchanges(ccxt_module: Optional[CcxtModuleType] = None) -> List[str]:\n    \"\"\"\n    Return the list of all exchanges known to ccxt\n    \"\"\"\n    return ccxt_module.exchanges if ccxt_module is not None else ccxt.exchanges"
            },
            {
                "name": "available_exchanges",
                "code": "def available_exchanges(ccxt_module: Optional[CcxtModuleType] = None) -> List[str]:\n    \"\"\"\n    Return exchanges available to the bot, i.e. non-bad exchanges in the ccxt list\n    \"\"\"\n    exchanges = ccxt_exchanges(ccxt_module)\n    return [x for x in exchanges if validate_exchange(x)[0]]"
            },
            {
                "name": "_build_exchange_list_entry",
                "code": "def _build_exchange_list_entry(\n    exchange_name: str, exchangeClasses: Dict[str, Any]\n) -> ValidExchangesType:\n    valid, comment, is_dex = validate_exchange(exchange_name)\n    result: ValidExchangesType = {\n        \"name\": exchange_name,\n        \"valid\": valid,\n        \"supported\": exchange_name.lower() in SUPPORTED_EXCHANGES,\n        \"comment\": comment,\n        \"dex\": is_dex,\n        \"trade_modes\": [{\"trading_mode\": \"spot\", \"margin_mode\": \"\"}],\n    }\n    if resolved := exchangeClasses.get(exchange_name.lower()):\n        supported_modes = [{\"trading_mode\": \"spot\", \"margin_mode\": \"\"}] + [\n            {\"trading_mode\": tm.value, \"margin_mode\": mm.value}\n            for tm, mm in resolved[\"class\"]._supported_trading_mode_margin_pairs\n        ]\n        result.update(\n            {\n                \"trade_modes\": supported_modes,\n            }\n        )\n\n    return result"
            }
        ],
        "third_party": [
            "lower",
            "ExchangeResolver.search_all_objects"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def timeframe_to_next_date(timeframe: str, date: Optional[datetime] = None) -> datetime:",
        "start_line": "69",
        "end_line": "79",
        "file_path": "freqtrade/exchange/exchange_utils_timeframe.py",
        "docstring": "The function timeframe_to_next_date(timeframe: str, date: Optional[datetime] = None) -> datetime calculates the next date that aligns with a given timeframe.\\nIf no date is provided, it uses the current UTC date and time.\\nIt rounds the provided (or current) date up to the next interval specified by the timeframe using ccxt.Exchange.round_timeframe and converts the result to seconds.\\nFinally, it converts the timestamp back to a datetime object using dt_from_ts and returns it.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "36a16298354d",
        "ground_truth": "def timeframe_to_next_date(timeframe: str, date: Optional[datetime] = None) -> datetime:\n    \"\"\"\n    Use Timeframe and determine next candle.\n    :param timeframe: timeframe in string format (e.g. \"5m\")\n    :param date: date to use. Defaults to now(utc)\n    :returns: date of next candle (with utc timezone)\n    \"\"\"\n    if not date:\n        date = datetime.now(timezone.utc)\n    new_timestamp = ccxt.Exchange.round_timeframe(timeframe, dt_ts(date), ROUND_UP) // 1000\n    return dt_from_ts(new_timestamp)",
        "import_statements": [
            "from datetime import datetime, timezone",
            "from typing import Optional",
            "import ccxt",
            "from ccxt import ROUND_DOWN, ROUND_UP",
            "from freqtrade.util.datetime_helpers import dt_from_ts, dt_ts"
        ],
        "reference_api": [
            "dt_ts",
            "round_timeframe",
            "datetime.now",
            "dt_from_ts"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "dt_ts",
                "code": "def dt_ts(dt: Optional[datetime] = None) -> int:\n    \"\"\"\n    Return dt in ms as a timestamp in UTC.\n    If dt is None, return the current datetime in UTC.\n    \"\"\"\n    if dt:\n        return int(dt.timestamp() * 1000)\n    return int(time() * 1000)"
            },
            {
                "name": "dt_from_ts",
                "code": "def dt_from_ts(timestamp: float) -> datetime:\n    \"\"\"\n    Return a datetime from a timestamp.\n    :param timestamp: timestamp in seconds or milliseconds\n    \"\"\"\n    if timestamp > 1e10:\n        # Timezone in ms - convert to seconds\n        timestamp /= 1000\n    return datetime.fromtimestamp(timestamp, tz=timezone.utc)"
            }
        ],
        "third_party": [
            "round_timeframe"
        ]
    },
    {
        "subclass": "Bitcoin",
        "owner/repo": "freqtrade/freqtrade",
        "function_declaration": "def stoploss_from_open(\n    open_relative_stop: float, current_profit: float, is_short: bool = False, leverage: float = 1.0\n) -> float",
        "start_line": "106",
        "end_line": "140",
        "file_path": "freqtrade/strategy/strategy_helper.py",
        "docstring": "The function stoploss_from_open(open_relative_stop: float, current_profit: float, is_short: bool = False, leverage: float = 1.0) -> float calculates the stop-loss percentage from the open position based on the current profit, leverage, and whether the position is short or long.\\nIt first adjusts the current profit by dividing it by the leverage.\\nIf the adjusted current profit is -1 (for longs) or 1 (for shorts), indicating an undefined scenario, it returns the maximum value of 1.\\nFor short positions, it calculates the stop-loss using the formula: -1 + ((1 - open_relative_stop / leverage) / (1 - _current_profit)).\\nFor long positions, it uses the formula: 1 - ((1 + open_relative_stop / leverage) / (1 + _current_profit)).\\nIt ensures that the stop-loss value is non-negative by taking the maximum of the calculated stop-loss (multiplied by leverage) and 0.0.\\nThe function returns the resulting stop-loss value.",
        "language": "Python",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "6a3f2b1d345d",
        "ground_truth": "def stoploss_from_open(\n    open_relative_stop: float, current_profit: float, is_short: bool = False, leverage: float = 1.0\n) -> float:\n    \"\"\"\n    Given the current profit, and a desired stop loss value relative to the trade entry price,\n    return a stop loss value that is relative to the current price, and which can be\n    returned from `custom_stoploss`.\n     The requested stop can be positive for a stop above the open price, or negative for\n    a stop below the open price. The return value is always >= 0.\n    `open_relative_stop` will be considered as adjusted for leverage if leverage is provided..\n     Returns 0 if the resulting stop price would be above/below (longs/shorts) the current price\n     :param open_relative_stop: Desired stop loss percentage, relative to the open price,\n                               adjusted for leverage\n    :param current_profit: The current profit percentage\n    :param is_short: When true, perform the calculation for short instead of long\n    :param leverage: Leverage to use for the calculation\n    :return: Stop loss value relative to current price\n    \"\"\"\n     # formula is undefined for current_profit -1 (longs) or 1 (shorts), return maximum value\n    _current_profit = current_profit / leverage\n    if (_current_profit == -1 and not is_short) or (is_short and _current_profit == 1):\n        return 1\n     if is_short is True:\n        stoploss = -1 + ((1 - open_relative_stop / leverage) / (1 - _current_profit))\n    else:\n        stoploss = 1 - ((1 + open_relative_stop / leverage) / (1 + _current_profit))\n     # negative stoploss values indicate the requested stop price is higher/lower\n    # (long/short) than the current price\n    return max(stoploss * leverage, 0.0)",
        "import_statements": [
            "from typing import Optional",
            "from freqtrade.exchange import timeframe_to_minutes"
        ],
        "reference_api": [
            "max"
        ],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func NewTransactor(keyin io.Reader, passphrase string) (*TransactOpts, error)",
        "start_line": "45",
        "end_line": "56",
        "file_path": "accounts/abi/bind/auth.go",
        "docstring": "The function NewTransactor(keyin io.Reader, passphrase string) (*TransactOpts, error) creates a new transaction signer using a private key read from an input source and decrypted with a passphrase.\\nIt logs a warning indicating that NewTransactor is deprecated in favor of NewTransactorWithChainID.\\nThe function reads the key data from the provided io.Reader (keyin).\\nIf reading fails, it returns an error.\\nIt then decrypts the key using the provided passphrase with keystore.DecryptKey.\\nIf decryption fails, it returns an error.\\nIf successful, it creates and returns a new transaction signer (TransactOpts) using the decrypted private key with NewKeyedTransactor.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "25e22b7c9e5c",
        "ground_truth": "func NewTransactor(keyin io.Reader, passphrase string) (*TransactOpts, error) {\n log.Warn(\"WARNING: NewTransactor has been deprecated in favour of NewTransactorWithChainID\")\n json, err := io.ReadAll(keyin)\n if err != nil {\n  return nil, err\n }\n key, err := keystore.DecryptKey(json, passphrase)\n if err != nil {\n  return nil, err\n }\n return NewKeyedTransactor(key.PrivateKey), nil\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"crypto/ecdsa\"\n\t\"errors\"\n\t\"io\"\n\t\"math/big\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/accounts/external\"\n\t\"github.com/ethereum/go-ethereum/accounts/keystore\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n)"
        ],
        "reference_api": [
            "log.Warn",
            "keystore.DecryptKey",
            "NewKeyedTransactor",
            "io.ReadAll"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "NewKeyedTransactor",
                "code": "func NewKeyedTransactor(key *ecdsa.PrivateKey) *TransactOpts {\n\tlog.Warn(\"WARNING: NewKeyedTransactor has been deprecated in favour of NewKeyedTransactorWithChainID\")\n\tkeyAddr := crypto.PubkeyToAddress(key.PublicKey)\n\tsigner := types.HomesteadSigner{}\n\treturn &TransactOpts{\n\t\tFrom: keyAddr,\n\t\tSigner: func(address common.Address, tx *types.Transaction) (*types.Transaction, error) {\n\t\t\tif address != keyAddr {\n\t\t\t\treturn nil, ErrNotAuthorized\n\t\t\t}\n\t\t\tsignature, err := crypto.Sign(signer.Hash(tx).Bytes(), key)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn tx.WithSignature(signer, signature)\n\t\t},\n\t\tContext: context.Background(),\n\t}\n}"
            }
        ],
        "third_party": [
            "log.Warn",
            "keystore.DecryptKey"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func NewTransactorWithChainID(keyin io.Reader, passphrase string, chainID *big.Int) (*TransactOpts, error)",
        "start_line": "107",
        "end_line": "117",
        "file_path": "accounts/abi/bind/auth.go",
        "docstring": "The function NewTransactorWithChainID(keyin io.Reader, passphrase string, chainID *big.Int) (*TransactOpts, error) creates a new transaction signer with a specified chain ID.\\nIt reads the key data from the provided io.Reader (keyin) and handles any errors that occur during reading.\\nIt decrypts the key using the provided passphrase with keystore.DecryptKey, returning an error if decryption fails.\\nIf successful, it creates and returns a new transaction signer (TransactOpts) with the decrypted private key and the specified chain ID using NewKeyedTransactorWithChainID.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a21344a856f0",
        "ground_truth": "func NewTransactorWithChainID(keyin io.Reader, passphrase string, chainID *big.Int) (*TransactOpts, error) {\n json, err := io.ReadAll(keyin)\n if err != nil {\n  return nil, err\n }\n key, err := keystore.DecryptKey(json, passphrase)\n if err != nil {\n  return nil, err\n }\n return NewKeyedTransactorWithChainID(key.PrivateKey, chainID)\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"crypto/ecdsa\"\n\t\"errors\"\n\t\"io\"\n\t\"math/big\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/accounts/external\"\n\t\"github.com/ethereum/go-ethereum/accounts/keystore\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n)"
        ],
        "reference_api": [
            "NewKeyedTransactorWithChainID",
            "keystore.DecryptKey",
            "io.ReadAll"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "NewKeyedTransactorWithChainID",
                "code": "func NewKeyedTransactorWithChainID(key *ecdsa.PrivateKey, chainID *big.Int) (*TransactOpts, error) {\n\tif chainID == nil {\n\t\treturn nil, ErrNoChainID\n\t}\n\tkeyAddr := crypto.PubkeyToAddress(key.PublicKey)\n\tsigner := types.LatestSignerForChainID(chainID)\n\treturn &TransactOpts{\n\t\tFrom: keyAddr,\n\t\tSigner: func(address common.Address, tx *types.Transaction) (*types.Transaction, error) {\n\t\t\tif address != keyAddr {\n\t\t\t\treturn nil, ErrNotAuthorized\n\t\t\t}\n\t\t\tsignature, err := crypto.Sign(signer.Hash(tx).Bytes(), key)\n\t\t\tif err != nil {\n\t\t\t\treturn nil, err\n\t\t\t}\n\t\t\treturn tx.WithSignature(signer, signature)\n\t\t},\n\t\tContext: context.Background(),\n\t}, nil\n}"
            }
        ],
        "third_party": [
            "keystore.DecryptKey"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (c *BoundContract) Transact(opts *TransactOpts, method string, params ...interface{}) (*types.Transaction, error)",
        "start_line": "235",
        "end_line": "244",
        "file_path": "accounts/abi/bind/base.go",
        "docstring": "The function Transact on the BoundContract struct executes a transaction for a specified contract method with given parameters.\\nIt takes TransactOpts for transaction options, a method name as a string, and a variadic number of parameters.\\nIt first packs the method name and parameters into ABI-encoded input data using c.abi.Pack.\\nIf packing fails, it returns an error.\\nIf successful, it calls the transact method on the contract, passing the transaction options, contract address, and the packed input data, and returns the resulting transaction and any error.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a074edbe4b83",
        "ground_truth": "func (c *BoundContract) Transact(opts *TransactOpts, method string, params ...interface{}) (*types.Transaction, error) {\n // Otherwise pack up the parameters and invoke the contract\n input, err := c.abi.Pack(method, params...)\n if err != nil {\n  return nil, err\n }\n // todo(rjl493456442) check whether the method is payable or not,\n // reject invalid transaction at the first place\n return c.transact(opts, &c.address, input)\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts/abi\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/event\"\n)"
        ],
        "reference_api": [
            "c.transact",
            "c.abi.Pack"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "c.transact",
            "c.abi.Pack"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (c *BoundContract) getNonce(opts *TransactOpts) (uint64, error)",
        "start_line": "378",
        "end_line": "384",
        "file_path": "accounts/abi/bind/base.go",
        "docstring": "The function getNonce on the BoundContract struct retrieves the nonce for a transaction.\\nIt takes a TransactOpts object as input.\\nIf the Nonce field in TransactOpts is nil, it calls c.transactor.PendingNonceAt with the transaction context and sender address to get the current pending nonce.\\nIf the Nonce field is not nil, it directly returns the uint64 value of the specified nonce.\\nThe function returns the nonce and any error encountered during the process.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "9c6021549c75",
        "ground_truth": "func (c *BoundContract) getNonce(opts *TransactOpts) (uint64, error) {\n if opts.Nonce == nil {\n  return c.transactor.PendingNonceAt(ensureContext(opts.Context), opts.From)\n } else {\n  return opts.Nonce.Uint64(), nil\n }\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts/abi\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/event\"\n)"
        ],
        "reference_api": [
            "opts.Nonce.Uint64",
            "ensureContext",
            "c.transactor.PendingNonceAt"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "ensureContext",
                "code": "func ensureContext(ctx context.Context) context.Context {\n\tif ctx == nil {\n\t\treturn context.Background()\n\t}\n\treturn ctx\n}"
            }
        ],
        "third_party": [
            "opts.Nonce.Uint64",
            "c.transactor.PendingNonceAt"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (c *BoundContract) UnpackLog(out interface{}, event string, log types.Log) error",
        "start_line": "510",
        "end_line": "530",
        "file_path": "accounts/abi/bind/base.go",
        "docstring": "The function UnpackLog on the BoundContract struct decodes a log entry into a given output structure for a specific event.\\nIt first checks if the log entry has any topics; if not, it returns an errNoEventSignature error.\\nIt then verifies that the first topic matches the event's ID from the contract's ABI; if it does not, it returns an errEventSignatureMismatch error.\\nIf the log entry contains data, it unpacks the data into the provided output interface using the contract's ABI and returns any error encountered.\\nNext, it gathers the indexed arguments of the event.\\nFinally, it parses the remaining topics (excluding the first one) into the output structure based on the indexed arguments and returns any error encountered during this process.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "09a8d3569724",
        "ground_truth": "func (c *BoundContract) UnpackLog(out interface{}, event string, log types.Log) error {\n // Anonymous events are not supported.\n if len(log.Topics) == 0 {\n  return errNoEventSignature\n }\n if log.Topics[0] != c.abi.Events[event].ID {\n  return errEventSignatureMismatch\n }\n if len(log.Data) > 0 {\n  if err := c.abi.UnpackIntoInterface(out, event, log.Data); err != nil {\n   return err\n  }\n }\n var indexed abi.Arguments\n for _, arg := range c.abi.Events[event].Inputs {\n  if arg.Indexed {\n   indexed = append(indexed, arg)\n  }\n }\n return abi.ParseTopics(out, indexed, log.Topics[1:])\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"strings\"\n\t\"sync\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts/abi\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/event\"\n)"
        ],
        "reference_api": [
            "append",
            "c.abi.UnpackIntoInterface",
            "len",
            "abi.ParseTopics"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "append",
            "c.abi.UnpackIntoInterface",
            "len",
            "abi.ParseTopics"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func WaitMined(ctx context.Context, b DeployBackend, tx *types.Transaction) (*types.Receipt, error)",
        "start_line": "32",
        "end_line": "56",
        "file_path": "accounts/abi/bind/util.go",
        "docstring": "The function WaitMined(ctx context.Context, b DeployBackend, tx *types.Transaction) (*types.Receipt, error) waits for a transaction to be mined and returns the transaction receipt.\\nIt creates a ticker that triggers every second to query the transaction receipt and stops the ticker when the function returns.\\nA logger is initialized with the transaction hash for logging purposes.\\nThe function enters a loop where it attempts to retrieve the transaction receipt using b.TransactionReceipt with the provided context and transaction hash.\\nIf the receipt is successfully retrieved, it returns the receipt and nil error.\\nIf the error indicates that the transaction is not yet mined (ethereum.NotFound), it logs a trace message indicating this.\\nIf another error occurs, it logs a trace message with the error details.\\nThe function uses a select statement to either return nil and the context error if the context is done, or wait for the next tick to reattempt receipt retrieval.\\nThis process continues until the transaction receipt is successfully retrieved or the context is canceled.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7755d9b11653",
        "ground_truth": "func WaitMined(ctx context.Context, b DeployBackend, tx *types.Transaction) (*types.Receipt, error) {\n queryTicker := time.NewTicker(time.Second)\n defer queryTicker.Stop()\n  logger := log.New(\"hash\", tx.Hash())\n for {\n  receipt, err := b.TransactionReceipt(ctx, tx.Hash())\n  if err == nil {\n   return receipt, nil\n  }\n   if errors.Is(err, ethereum.NotFound) {\n   logger.Trace(\"Transaction not yet mined\")\n  } else {\n   logger.Trace(\"Receipt retrieval failed\", \"err\", err)\n  }\n   // Wait for the next round.\n  select {\n  case <-ctx.Done():\n   return nil, ctx.Err()\n  case <-queryTicker.C:\n  }\n }\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/log\"\n)"
        ],
        "reference_api": [
            "queryTicker.Stop",
            "ctx.Err",
            "logger.Trace",
            "ctx.Done",
            "tx.Hash",
            "time.NewTicker",
            "b.TransactionReceipt",
            "log.New",
            "errors.Is"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "queryTicker.Stop",
            "ctx.Err",
            "logger.Trace",
            "ctx.Done",
            "tx.Hash",
            "b.TransactionReceipt",
            "log.New"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func WaitDeployed(ctx context.Context, b DeployBackend, tx *types.Transaction) (common.Address, error)",
        "start_line": "60",
        "end_line": "79",
        "file_path": "accounts/abi/bind/util.go",
        "docstring": "The function WaitDeployed(ctx context.Context, b DeployBackend, tx *types.Transaction) (common.Address, error) waits for a contract deployment transaction to be mined and verifies the deployment.\\nIt first checks if the transaction is a contract creation transaction by verifying that tx.To() is nil.\\nIf not, it returns an error indicating the transaction is not a contract creation.\\nIt calls WaitMined to wait for the transaction to be mined and retrieve the receipt.\\nIf WaitMined returns an error, it propagates the error.\\nIf the receipt's ContractAddress is a zero address, it returns an error indicating a zero address.\\nIt then retrieves the contract code at the ContractAddress using b.CodeAt.\\nIf the code retrieval is successful but the code length is zero, it sets the error to ErrNoCodeAfterDeploy.\\nFinally, it returns the ContractAddress and any error encountered.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f8c0d70a2299",
        "ground_truth": "func WaitDeployed(ctx context.Context, b DeployBackend, tx *types.Transaction) (common.Address, error) {\n if tx.To() != nil {\n  return common.Address{}, errors.New(\"tx is not contract creation\")\n }\n receipt, err := WaitMined(ctx, b, tx)\n if err != nil {\n  return common.Address{}, err\n }\n if receipt.ContractAddress == (common.Address{}) {\n  return common.Address{}, errors.New(\"zero address\")\n }\n // Check that code has indeed been deployed at the address.\n // This matters on pre-Homestead chains: OOG in the constructor\n // could leave an empty account behind.\n code, err := b.CodeAt(ctx, receipt.ContractAddress, nil)\n if err == nil && len(code) == 0 {\n  err = ErrNoCodeAfterDeploy\n }\n return receipt.ContractAddress, err\n}",
        "import_statements": [
            "import (\n\t\"context\"\n\t\"errors\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/log\"\n)"
        ],
        "reference_api": [
            "WaitMined",
            "len",
            "b.CodeAt",
            "tx.To",
            "errors.New"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "WaitMined",
                "code": "func WaitMined(ctx context.Context, b DeployBackend, tx *types.Transaction) (*types.Receipt, error) {\n\tqueryTicker := time.NewTicker(time.Second)\n\tdefer queryTicker.Stop()\n\n\tlogger := log.New(\"hash\", tx.Hash())\n\tfor {\n\t\treceipt, err := b.TransactionReceipt(ctx, tx.Hash())\n\t\tif err == nil {\n\t\t\treturn receipt, nil\n\t\t}\n\n\t\tif errors.Is(err, ethereum.NotFound) {\n\t\t\tlogger.Trace(\"Transaction not yet mined\")\n\t\t} else {\n\t\t\tlogger.Trace(\"Receipt retrieval failed\", \"err\", err)\n\t\t}\n\n\t\t// Wait for the next round.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil, ctx.Err()\n\t\tcase <-queryTicker.C:\n\t\t}\n\t}\n}"
            }
        ],
        "third_party": [
            "len",
            "b.CodeAt",
            "tx.To"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (abi ABI) Pack(name string, args ...interface{}) ([]byte, error)",
        "start_line": "63",
        "end_line": "83",
        "file_path": "accounts/abi/abi.go",
        "docstring": "The function Pack in the ABI struct encodes the arguments for a contract method call or constructor into a byte slice.\\nIf the method name is an empty string, it treats it as a constructor and packs the arguments using the constructor's input types, returning the packed arguments and any error encountered.\\nIf a method name is provided, it looks up the method in the ABI's Methods map.\\nIf the method does not exist, it returns an error indicating the method was not found.\\nIf the method is found, it packs the arguments using the method's input types, appends the method's ID to the packed arguments, and returns the resulting byte slice and any error encountered.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "313b87fdf789",
        "ground_truth": "func (abi ABI) Pack(name string, args ...interface{}) ([]byte, error) {\n // Fetch the ABI of the requested method\n if name == \"\" {\n  // constructor\n  arguments, err := abi.Constructor.Inputs.Pack(args...)\n  if err != nil {\n   return nil, err\n  }\n  return arguments, nil\n }\n method, exist := abi.Methods[name]\n if !exist {\n  return nil, fmt.Errorf(\"method '%s' not found\", name)\n }\n arguments, err := method.Inputs.Pack(args...)\n if err != nil {\n  return nil, err\n }\n // Pack up the method ID too if not a constructor and return\n return append(method.ID, arguments...), nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"io\"\n\t\"math/big\"\n\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n)"
        ],
        "reference_api": [
            "append",
            "abi.Constructor.Inputs.Pack",
            "fmt.Errorf",
            "method.Inputs.Pack"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "append",
            "abi.Constructor.Inputs.Pack",
            "method.Inputs.Pack"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (arguments Arguments) Copy(v interface{}, values []interface{}) error",
        "start_line": "113",
        "end_line": "128",
        "file_path": "accounts/abi/argument.go",
        "docstring": "The function Copy in the Arguments struct copies provided values into a given variable based on the argument definitions.\\nIt first ensures that the provided variable (v) is a pointer; if not, it returns an error indicating a non-pointer was provided.\\nIf the values slice is empty and there are non-indexed arguments, it returns an error indicating no values were provided while arguments were expected.\\nIf the values slice is empty and there are no arguments, it returns nil as there is nothing to copy.\\nIf the arguments are a tuple, it calls copyTuple to copy the values into the variable.\\nOtherwise, it calls copyAtomic to copy the first value from the values slice into the variable.\\nThe function returns any error encountered during the copying process.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "708fecd0afbc",
        "ground_truth": "func (arguments Arguments) Copy(v interface{}, values []interface{}) error {\n // make sure the passed value is arguments pointer\n if reflect.Ptr != reflect.ValueOf(v).Kind() {\n  return fmt.Errorf(\"abi: Unpack(non-pointer %T)\", v)\n }\n if len(values) == 0 {\n  if len(arguments.NonIndexed()) != 0 {\n   return errors.New(\"abi: attempting to copy no values while arguments are expected\")\n  }\n  return nil // Nothing to copy, return\n }\n if arguments.isTuple() {\n  return arguments.copyTuple(v, values)\n }\n return arguments.copyAtomic(v, values[0])\n}",
        "import_statements": [
            "import (\n\t\"encoding/json\"\n\t\"errors\"\n\t\"fmt\"\n\t\"reflect\"\n\t\"strings\"\n)"
        ],
        "reference_api": [
            "fmt.Errorf",
            "reflect.ValueOf",
            "arguments.isTuple",
            "arguments.copyTuple",
            "len",
            "arguments.copyAtomic",
            "errors.New",
            "reflect.ValueOf(v).Kind",
            "arguments.NonIndexed"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "reflect.ValueOf",
            "arguments.isTuple",
            "arguments.copyTuple",
            "len",
            "arguments.copyAtomic",
            "reflect.ValueOf(v).Kind",
            "arguments.NonIndexed"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func ConvertType(in interface{}, proto interface{}) interface{} ",
        "start_line": "41",
        "end_line": "51",
        "file_path": "accounts/abi/reflect.go",
        "docstring": "The function ConvertType converts an input value (in) to the type of a prototype value (proto).\\nIt first retrieves the reflect.Type of the prototype.\\nIf the type of the input value is convertible to the prototype type, it converts the input value to the prototype type using reflection and returns the converted value.\\nIf the types are not directly convertible, it attempts to set the prototype value using the set function, passing the reflect.Value representations of the prototype and input values.\\nIf the set function encounters an error, it panics with the error.\\nIf the conversion or setting is successful, it returns the prototype value with the new value.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "53d98a14dbdd",
        "ground_truth": "func ConvertType(in interface{}, proto interface{}) interface{} {\n protoType := reflect.TypeOf(proto)\n if reflect.TypeOf(in).ConvertibleTo(protoType) {\n  return reflect.ValueOf(in).Convert(protoType).Interface()\n }\n // Use set as a last ditch effort\n if err := set(reflect.ValueOf(proto), reflect.ValueOf(in)); err != nil {\n  panic(err)\n }\n return proto\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"reflect\"\n\t\"strings\"\n)"
        ],
        "reference_api": [
            "reflect.ValueOf(in).Convert(protoType).Interface",
            "reflect.ValueOf",
            "reflect.ValueOf(in).Convert",
            "set",
            "reflect.TypeOf",
            "reflect.TypeOf(in).ConvertibleTo",
            "panic"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "set",
                "code": "func set(dst, src reflect.Value) error {\n\tdstType, srcType := dst.Type(), src.Type()\n\tswitch {\n\tcase dstType.Kind() == reflect.Interface && dst.Elem().IsValid() && (dst.Elem().Type().Kind() == reflect.Ptr || dst.Elem().CanSet()):\n\t\treturn set(dst.Elem(), src)\n\tcase dstType.Kind() == reflect.Ptr && dstType.Elem() != reflect.TypeOf(big.Int{}):\n\t\treturn set(dst.Elem(), src)\n\tcase srcType.AssignableTo(dstType) && dst.CanSet():\n\t\tdst.Set(src)\n\tcase dstType.Kind() == reflect.Slice && srcType.Kind() == reflect.Slice && dst.CanSet():\n\t\treturn setSlice(dst, src)\n\tcase dstType.Kind() == reflect.Array:\n\t\treturn setArray(dst, src)\n\tcase dstType.Kind() == reflect.Struct:\n\t\treturn setStruct(dst, src)\n\tdefault:\n\t\treturn fmt.Errorf(\"abi: cannot unmarshal %v in to %v\", src.Type(), dst.Type())\n\t}\n\treturn nil\n}"
            }
        ],
        "third_party": [
            "reflect.ValueOf(in).Convert(protoType).Interface",
            "reflect.ValueOf",
            "reflect.ValueOf(in).Convert",
            "reflect.TypeOf",
            "reflect.TypeOf(in).ConvertibleTo",
            "panic"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func parseToken(unescapedSelector string, isIdent bool) (string, string, error)",
        "start_line": "42",
        "end_line": "59",
        "file_path": "accounts/abi/selector_parser.go",
        "docstring": "The function parseToken(unescapedSelector string, isIdent bool) (string, string, error) parses a token from an unescaped selector string.\\nIt first checks if the input string is empty and returns an error if it is.\\nIt retrieves the first character of the string and initializes a position counter.\\nIf the first character is not an alphabetic character or a valid identifier symbol (when isIdent is true), it returns an error indicating an invalid token start.\\nIt then iterates through the string, checking if each character is alphabetic, a digit, or a valid identifier symbol (when isIdent is true).\\nThe loop breaks when a character does not meet these criteria.\\nFinally, it returns the parsed token (substring from the start to the current position), the remaining string, and nil as the error.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d2665d5bb4a9",
        "ground_truth": "func parseToken(unescapedSelector string, isIdent bool) (string, string, error) {\n if len(unescapedSelector) == 0 {\n  return \"\", \"\", errors.New(\"empty token\")\n }\n firstChar := unescapedSelector[0]\n position := 1\n if !(isAlpha(firstChar) || (isIdent && isIdentifierSymbol(firstChar))) {\n  return \"\", \"\", fmt.Errorf(\"invalid token start: %c\", firstChar)\n }\n for position < len(unescapedSelector) {\n  char := unescapedSelector[position]\n  if !(isAlpha(char) || isDigit(char) || (isIdent && isIdentifierSymbol(char))) {\n   break\n  }\n  position++\n }\n return unescapedSelector[:position], unescapedSelector[position:], nil\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n)"
        ],
        "reference_api": [
            "fmt.Errorf",
            "isIdentifierSymbol",
            "isAlpha",
            "len",
            "errors.New",
            "isDigit"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "isIdentifierSymbol",
                "code": "func isIdentifierSymbol(c byte) bool {\n\treturn c == '$' || c == '_'\n}"
            },
            {
                "name": "isAlpha",
                "code": "func isAlpha(c byte) bool {\n\treturn (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')\n}"
            },
            {
                "name": "isDigit",
                "code": "func isDigit(c byte) bool {\n\treturn c >= '0' && c <= '9'\n}"
            }
        ],
        "third_party": [
            "len"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func parseElementaryType(unescapedSelector string) (string, string, error) ",
        "start_line": "65",
        "end_line": "85",
        "file_path": "accounts/abi/selector_parser.go",
        "docstring": "The function parseElementaryType(unescapedSelector string) (string, string, error) parses an elementary type from an unescaped selector string.\\nIt first calls parseToken with the unescaped selector and false for the isIdent flag to parse the initial type token.\\nIf parseToken returns an error, it formats and returns an error indicating the failure to parse the elementary type.\\nIf successful, it initializes parsedType with the parsed token and rest with the remaining string.\\nIt then enters a loop to handle array types, checking if the rest string starts with a '[' character.\\nIf so, it appends the '[' to parsedType and removes it from rest.\\nIt continues to append digit characters to parsedType and remove them from rest until no more digits are found.\\nIf rest is empty or the next character is not ']', it returns an error indicating a failure to parse the array.\\nIf successful, it appends the ']' to parsedType and removes it from rest.\\nFinally, it returns the parsedType, the remaining rest string, and nil as the error.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "124324361039",
        "ground_truth": "func parseElementaryType(unescapedSelector string) (string, string, error) {\n parsedType, rest, err := parseToken(unescapedSelector, false)\n if err != nil {\n  return \"\", \"\", fmt.Errorf(\"failed to parse elementary type: %v\", err)\n }\n // handle arrays\n for len(rest) > 0 && rest[0] == '[' {\n  parsedType = parsedType + string(rest[0])\n  rest = rest[1:]\n  for len(rest) > 0 && isDigit(rest[0]) {\n   parsedType = parsedType + string(rest[0])\n   rest = rest[1:]\n  }\n  if len(rest) == 0 || rest[0] != ']' {\n   return \"\", \"\", fmt.Errorf(\"failed to parse array: expected ']', got %c\", unescapedSelector[0])\n  }\n  parsedType = parsedType + string(rest[0])\n  rest = rest[1:]\n }\n return parsedType, rest, nil\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n)"
        ],
        "reference_api": [
            "fmt.Errorf",
            "string",
            "parseToken",
            "len",
            "isDigit"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parseToken",
                "code": "func parseToken(unescapedSelector string, isIdent bool) (string, string, error) {\n\tif len(unescapedSelector) == 0 {\n\t\treturn \"\", \"\", errors.New(\"empty token\")\n\t}\n\tfirstChar := unescapedSelector[0]\n\tposition := 1\n\tif !(isAlpha(firstChar) || (isIdent && isIdentifierSymbol(firstChar))) {\n\t\treturn \"\", \"\", fmt.Errorf(\"invalid token start: %c\", firstChar)\n\t}\n\tfor position < len(unescapedSelector) {\n\t\tchar := unescapedSelector[position]\n\t\tif !(isAlpha(char) || isDigit(char) || (isIdent && isIdentifierSymbol(char))) {\n\t\t\tbreak\n\t\t}\n\t\tposition++\n\t}\n\treturn unescapedSelector[:position], unescapedSelector[position:], nil\n}"
            },
            {
                "name": "isDigit",
                "code": "func isDigit(c byte) bool {\n\treturn c >= '0' && c <= '9'\n}"
            }
        ],
        "third_party": [
            "string",
            "len"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func parseType(unescapedSelector string) (interface{}, string, error)",
        "start_line": "112",
        "end_line": "121",
        "file_path": "accounts/abi/selector_parser.go",
        "docstring": "The function parseType(unescapedSelector string) (interface{}, string, error) parses a type from an unescaped selector string.\\nIt first checks if the input string is empty and returns an error if it is.\\nIf the first character of the string is '(', it calls parseCompositeType to handle parsing composite types and returns its result.\\nIf the first character is not '(', it calls parseElementaryType to handle parsing elementary types and returns its result.\\nThis function determines the type of parsing needed based on the first character of the unescaped selector.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "0ec8c1e45498",
        "ground_truth": "func parseType(unescapedSelector string) (interface{}, string, error) {\n if len(unescapedSelector) == 0 {\n  return nil, \"\", errors.New(\"empty type\")\n }\n if unescapedSelector[0] == '(' {\n  return parseCompositeType(unescapedSelector)\n } else {\n  return parseElementaryType(unescapedSelector)\n }\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n)"
        ],
        "reference_api": [
            "errors.New",
            "len",
            "parseElementaryType",
            "parseCompositeType"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parseElementaryType",
                "code": "func parseElementaryType(unescapedSelector string) (string, string, error) {\n\tparsedType, rest, err := parseToken(unescapedSelector, false)\n\tif err != nil {\n\t\treturn \"\", \"\", fmt.Errorf(\"failed to parse elementary type: %v\", err)\n\t}\n\t// handle arrays\n\tfor len(rest) > 0 && rest[0] == '[' {\n\t\tparsedType = parsedType + string(rest[0])\n\t\trest = rest[1:]\n\t\tfor len(rest) > 0 && isDigit(rest[0]) {\n\t\t\tparsedType = parsedType + string(rest[0])\n\t\t\trest = rest[1:]\n\t\t}\n\t\tif len(rest) == 0 || rest[0] != ']' {\n\t\t\treturn \"\", \"\", fmt.Errorf(\"failed to parse array: expected ']', got %c\", unescapedSelector[0])\n\t\t}\n\t\tparsedType = parsedType + string(rest[0])\n\t\trest = rest[1:]\n\t}\n\treturn parsedType, rest, nil\n}"
            },
            {
                "name": "parseCompositeType",
                "code": "func parseCompositeType(unescapedSelector string) ([]interface{}, string, error) {\n\tif len(unescapedSelector) == 0 || unescapedSelector[0] != '(' {\n\t\treturn nil, \"\", fmt.Errorf(\"expected '(', got %c\", unescapedSelector[0])\n\t}\n\tparsedType, rest, err := parseType(unescapedSelector[1:])\n\tif err != nil {\n\t\treturn nil, \"\", fmt.Errorf(\"failed to parse type: %v\", err)\n\t}\n\tresult := []interface{}{parsedType}\n\tfor len(rest) > 0 && rest[0] != ')' {\n\t\tparsedType, rest, err = parseType(rest[1:])\n\t\tif err != nil {\n\t\t\treturn nil, \"\", fmt.Errorf(\"failed to parse type: %v\", err)\n\t\t}\n\t\tresult = append(result, parsedType)\n\t}\n\tif len(rest) == 0 || rest[0] != ')' {\n\t\treturn nil, \"\", fmt.Errorf(\"expected ')', got '%s'\", rest)\n\t}\n\tif len(rest) >= 3 && rest[1] == '[' && rest[2] == ']' {\n\t\treturn append(result, \"[]\"), rest[3:], nil\n\t}\n\treturn result, rest[1:], nil\n}"
            }
        ],
        "third_party": [
            "len"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func ParseTopics(out interface{}, fields Arguments, topics []common.Hash) error ",
        "start_line": "115",
        "end_line": "121",
        "file_path": "accounts/abi/topics.go",
        "docstring": "The function ParseTopics parses log topics into a structured output based on provided arguments.\\nIt takes an output interface, fields of type Arguments, and a slice of topics.\\nThe function calls parseTopicWithSetter with fields, topics, and a setter function.\\nThe setter function takes an Argument and a reconstructed value, then sets the corresponding field in the output struct.\\nThe field is identified by converting the argument name to camel case using ToCamelCase, accessing it using reflection, and setting its value to the reconstructed value.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a9987732eac6",
        "ground_truth": "func ParseTopics(out interface{}, fields Arguments, topics []common.Hash) error {\n return parseTopicWithSetter(fields, topics,\n  func(arg Argument, reconstr interface{}) {\n   field := reflect.ValueOf(out).Elem().FieldByName(ToCamelCase(arg.Name))\n   field.Set(reflect.ValueOf(reconstr))\n  })\n}",
        "import_statements": [
            "import (\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"reflect\"\n\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/common/math\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n)"
        ],
        "reference_api": [
            "reflect.ValueOf(out).Elem",
            "ToCamelCase",
            "reflect.ValueOf",
            "reflect.ValueOf(out).Elem().FieldByName",
            "field.Set",
            "parseTopicWithSetter"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "parseTopicWithSetter",
                "code": "func parseTopicWithSetter(fields Arguments, topics []common.Hash, setter func(Argument, interface{})) error {\n\t// Sanity check that the fields and topics match up\n\tif len(fields) != len(topics) {\n\t\treturn errors.New(\"topic/field count mismatch\")\n\t}\n\t// Iterate over all the fields and reconstruct them from topics\n\tfor i, arg := range fields {\n\t\tif !arg.Indexed {\n\t\t\treturn errors.New(\"non-indexed field in topic reconstruction\")\n\t\t}\n\t\tvar reconstr interface{}\n\t\tswitch arg.Type.T {\n\t\tcase TupleTy:\n\t\t\treturn errors.New(\"tuple type in topic reconstruction\")\n\t\tcase StringTy, BytesTy, SliceTy, ArrayTy:\n\t\t\t// Array types (including strings and bytes) have their keccak256 hashes stored in the topic- not a hash\n\t\t\t// whose bytes can be decoded to the actual value- so the best we can do is retrieve that hash\n\t\t\treconstr = topics[i]\n\t\tcase FunctionTy:\n\t\t\tif garbage := binary.BigEndian.Uint64(topics[i][0:8]); garbage != 0 {\n\t\t\t\treturn fmt.Errorf(\"bind: got improperly encoded function type, got %v\", topics[i].Bytes())\n\t\t\t}\n\t\t\tvar tmp [24]byte\n\t\t\tcopy(tmp[:], topics[i][8:32])\n\t\t\treconstr = tmp\n\t\tdefault:\n\t\t\tvar err error\n\t\t\treconstr, err = toGoType(0, arg.Type, topics[i].Bytes())\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t\t// Use the setter function to store the value\n\t\tsetter(arg, reconstr)\n\t}\n\n\treturn nil\n}"
            }
        ],
        "third_party": [
            "reflect.ValueOf(out).Elem",
            "ToCamelCase",
            "reflect.ValueOf",
            "reflect.ValueOf(out).Elem().FieldByName",
            "field.Set"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (api *ExternalSigner) Accounts() []accounts.Account",
        "start_line": "109",
        "end_line": "129",
        "file_path": "accounts/external/backend.go",
        "docstring": "The function Accounts in the ExternalSigner struct retrieves a list of accounts from an external API.\\nIt initializes an empty slice of accounts.Account.\\nIt calls api.listAccounts() to get the list of account addresses.\\nIf an error occurs during this call, it logs the error and returns the empty slice.\\nFor each address in the response, it appends an accounts.Account to the slice with the URL scheme set to \"extapi\" and the path set to api.endpoint.\\nIt then locks the cache mutex, updates the cache with the retrieved accounts, and unlocks the mutex.\\nFinally, it returns the slice of accounts.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f5b9496eb4fc",
        "ground_truth": "func (api *ExternalSigner) Accounts() []accounts.Account {\n var accnts []accounts.Account\n res, err := api.listAccounts()\n if err != nil {\n  log.Error(\"account listing failed\", \"error\", err)\n  return accnts\n }\n for _, addr := range res {\n  accnts = append(accnts, accounts.Account{\n   URL: accounts.URL{\n    Scheme: \"extapi\",\n    Path:   api.endpoint,\n   },\n   Address: addr,\n  })\n }\n api.cacheMu.Lock()\n api.cache = accnts\n api.cacheMu.Unlock()\n return accnts\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"sync\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/common/hexutil\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/event\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\t\"github.com/ethereum/go-ethereum/rpc\"\n\t\"github.com/ethereum/go-ethereum/signer/core/apitypes\"\n)"
        ],
        "reference_api": [
            "api.listAccounts",
            "log.Error",
            "api.cacheMu.Lock",
            "api.cacheMu.Unlock",
            "append"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "api.listAccounts",
            "log.Error",
            "api.cacheMu.Lock",
            "api.cacheMu.Unlock",
            "append"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (api *ExternalSigner) Contains(account accounts.Account) bool",
        "start_line": "131",
        "end_line": "146",
        "file_path": "accounts/external/backend.go",
        "docstring": "The function Contains in the ExternalSigner struct checks if a given account is in the external signer's cache.\\nIt locks the cache for reading and defers unlocking until the function returns.\\nIf the cache is nil, indicating that accounts have not been fetched yet, it unlocks the cache and calls api.Accounts() to populate it, then re-locks the cache for reading.\\nIt iterates over the accounts in the cache.\\nIf it finds an account with the same address and either a matching URL or an empty URL, it returns true.\\nIf no matching account is found, it returns false.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "709a2d89d185",
        "ground_truth": "func (api *ExternalSigner) Contains(account accounts.Account) bool {\n api.cacheMu.RLock()\n defer api.cacheMu.RUnlock()\n if api.cache == nil {\n  // If we haven't already fetched the accounts, it's time to do so now\n  api.cacheMu.RUnlock()\n  api.Accounts()\n  api.cacheMu.RLock()\n }\n for _, a := range api.cache {\n  if a.Address == account.Address && (account.URL == (accounts.URL{}) || account.URL == api.URL()) {\n   return true\n  }\n }\n return false\n}",
        "import_statements": [
            "import (\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"sync\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/common/hexutil\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/event\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\t\"github.com/ethereum/go-ethereum/rpc\"\n\t\"github.com/ethereum/go-ethereum/signer/core/apitypes\"\n)"
        ],
        "reference_api": [
            "api.Accounts",
            "api.cacheMu.RLock",
            "api.URL",
            "api.cacheMu.RUnlock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "api.Accounts",
            "api.cacheMu.RLock",
            "api.URL",
            "api.cacheMu.RUnlock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (ac *accountCache) deleteByFile(path string)",
        "start_line": "133",
        "end_line": "147",
        "file_path": "accounts/keystore/account_cache.go",
        "docstring": "The function deleteByFile in the accountCache struct removes an account from the cache based on the provided file path.\\nIt locks the cache for writing and defers unlocking until the function returns.\\nIt performs a binary search on the ac.all slice to find the index of the account with the matching URL path.\\nIf a matching account is found, it removes the account from ac.all.\\nIt then updates the ac.byAddr map for the removed account's address.\\nIf the address has no more associated accounts, it deletes the address entry from the map; otherwise, it updates the entry with the remaining accounts.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "fb54fd18fc6e",
        "ground_truth": "func (ac *accountCache) deleteByFile(path string) {\n ac.mu.Lock()\n defer ac.mu.Unlock()\n i := sort.Search(len(ac.all), func(i int) bool { return ac.all[i].URL.Path >= path })\n  if i < len(ac.all) && ac.all[i].URL.Path == path {\n  removed := ac.all[i]\n  ac.all = append(ac.all[:i], ac.all[i+1:]...)\n  if ba := removeAccount(ac.byAddr[removed.Address], removed); len(ba) == 0 {\n   delete(ac.byAddr, removed.Address)\n  } else {\n   ac.byAddr[removed.Address] = ba\n  }\n }\n}",
        "import_statements": [
            "import (\n\t\"bufio\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"slices\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\tmapset \"github.com/deckarep/golang-set/v2\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/log\"\n)"
        ],
        "reference_api": [
            "removeAccount",
            "len",
            "sort.Search",
            "append",
            "ac.mu.Unlock",
            "delete",
            "ac.mu.Lock"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "removeAccount",
                "code": "func removeAccount(slice []accounts.Account, elem accounts.Account) []accounts.Account {\n\tfor i := range slice {\n\t\tif slice[i] == elem {\n\t\t\treturn append(slice[:i], slice[i+1:]...)\n\t\t}\n\t}\n\treturn slice\n}"
            }
        ],
        "third_party": [
            "len",
            "sort.Search",
            "append",
            "ac.mu.Unlock",
            "delete",
            "ac.mu.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func NewKeyForDirectICAP(rand io.Reader) *Key",
        "start_line": "148",
        "end_line": "164",
        "file_path": "accounts/keystore/key.go",
        "docstring": "The function NewKeyForDirectICAP generates a new cryptographic key specifically for Direct ICAP (International Bank Account Number format for Ethereum addresses).\\nIt creates a 64-byte slice and fills it with random bytes from the provided random source.\\nIf reading from the random source fails, it panics with an error message.\\nIt then creates a new bytes.Reader from the random bytes and uses it to generate a new ECDSA private key.\\nIf key generation fails, it panics with an error message.\\nIt creates a Key object from the ECDSA private key.\\nIf the generated key's address does not start with \"0x00\", it recursively calls NewKeyForDirectICAP to generate a new key.\\nIf the address is valid, it returns the Key object.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "511e09b842af",
        "ground_truth": "func NewKeyForDirectICAP(rand io.Reader) *Key {\n randBytes := make([]byte, 64)\n _, err := rand.Read(randBytes)\n if err != nil {\n  panic(\"key generation: could not read from random source: \" + err.Error())\n }\n reader := bytes.NewReader(randBytes)\n privateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), reader)\n if err != nil {\n  panic(\"key generation: ecdsa.GenerateKey failed: \" + err.Error())\n }\n key := newKeyFromECDSA(privateKeyECDSA)\n if !strings.HasPrefix(key.Address.Hex(), \"0x00\") {\n  return NewKeyForDirectICAP(rand)\n }\n return key\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"crypto/ecdsa\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/google/uuid\"\n)"
        ],
        "reference_api": [
            "newKeyFromECDSA",
            "make",
            "key.Address.Hex",
            "bytes.NewReader",
            "ecdsa.GenerateKey",
            "strings.HasPrefix",
            "err.Error",
            "crypto.S256",
            "NewKeyForDirectICAP",
            "rand.Read",
            "panic"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "newKeyFromECDSA",
                "code": "func newKeyFromECDSA(privateKeyECDSA *ecdsa.PrivateKey) *Key {\n\tid, err := uuid.NewRandom()\n\tif err != nil {\n\t\tpanic(fmt.Sprintf(\"Could not create random uuid: %v\", err))\n\t}\n\tkey := &Key{\n\t\tId:         id,\n\t\tAddress:    crypto.PubkeyToAddress(privateKeyECDSA.PublicKey),\n\t\tPrivateKey: privateKeyECDSA,\n\t}\n\treturn key\n}"
            },
            {
                "name": "NewKeyForDirectICAP",
                "code": "func NewKeyForDirectICAP(rand io.Reader) *Key {\n\trandBytes := make([]byte, 64)\n\t_, err := rand.Read(randBytes)\n\tif err != nil {\n\t\tpanic(\"key generation: could not read from random source: \" + err.Error())\n\t}\n\treader := bytes.NewReader(randBytes)\n\tprivateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), reader)\n\tif err != nil {\n\t\tpanic(\"key generation: ecdsa.GenerateKey failed: \" + err.Error())\n\t}\n\tkey := newKeyFromECDSA(privateKeyECDSA)\n\tif !strings.HasPrefix(key.Address.Hex(), \"0x00\") {\n\t\treturn NewKeyForDirectICAP(rand)\n\t}\n\treturn key\n}"
            }
        ],
        "third_party": [
            "make",
            "key.Address.Hex",
            "bytes.NewReader",
            "ecdsa.GenerateKey",
            "err.Error",
            "crypto.S256",
            "rand.Read",
            "panic"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func storeNewKey(ks keyStore, rand io.Reader, auth string) (*Key, accounts.Account, error)",
        "start_line": "174",
        "end_line": "188",
        "file_path": "accounts/keystore/key.go",
        "docstring": "The function storeNewKey generates and stores a new cryptographic key in a key store.\\nIt takes a key store (ks), a random source (rand), and an authentication string (auth) as inputs.\\nFirst, it generates a new key using newKey(rand).\\nIf key generation fails, it returns nil, an empty account, and the error.\\nIt then creates an accounts.Account object with the generated key's address and a URL pointing to the key file path in the key store.\\nIt attempts to store the key in the key store using ks.StoreKey, passing the key file path, the key, and the authentication string.\\nIf storing the key fails, it zeroes the private key and returns nil, the account, and the error.\\nIf successful, it returns the key, the account, and nil as the error.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cf96a9d7de0c",
        "ground_truth": "func storeNewKey(ks keyStore, rand io.Reader, auth string) (*Key, accounts.Account, error) {\n key, err := newKey(rand)\n if err != nil {\n  return nil, accounts.Account{}, err\n }\n a := accounts.Account{\n  Address: key.Address,\n  URL:     accounts.URL{Scheme: KeyStoreScheme, Path: ks.JoinPath(keyFileName(key.Address))},\n }\n if err := ks.StoreKey(a.URL.Path, key, auth); err != nil {\n  zeroKey(key.PrivateKey)\n  return nil, a, err\n }\n return key, a, err\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"crypto/ecdsa\"\n\t\"encoding/hex\"\n\t\"encoding/json\"\n\t\"fmt\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"strings\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/google/uuid\"\n)"
        ],
        "reference_api": [
            "zeroKey",
            "ks.StoreKey",
            "keyFileName",
            "ks.JoinPath",
            "newKey"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "keyFileName",
                "code": "func keyFileName(keyAddr common.Address) string {\n\tts := time.Now().UTC()\n\treturn fmt.Sprintf(\"UTC--%s--%s\", toISO8601(ts), hex.EncodeToString(keyAddr[:]))\n}"
            },
            {
                "name": "newKey",
                "code": "func newKey(rand io.Reader) (*Key, error) {\n\tprivateKeyECDSA, err := ecdsa.GenerateKey(crypto.S256(), rand)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\treturn newKeyFromECDSA(privateKeyECDSA), nil\n}"
            }
        ],
        "third_party": [
            "zeroKey",
            "ks.StoreKey",
            "ks.JoinPath"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (hub *Hub) writePairings() error",
        "start_line": "115",
        "end_line": "137",
        "file_path": "accounts/scwallet/hub.go",
        "docstring": "The function writePairings in the Hub struct writes the current smartcard pairings to a JSON file.\\nIt opens or creates a file named \"smartcards.json\" in the hub's data directory with read and write permissions.\\nIf opening the file fails, it returns the error.\\nIt defers closing the file until the function returns.\\nIt initializes a slice to hold the smartcard pairings and populates it with the current pairings from the hub.\\nIt marshals the slice into JSON format.\\nIf marshaling fails, it returns the error.\\nIt writes the JSON data to the opened file.\\nIf writing to the file fails, it returns the error.\\nIf all operations succeed, it returns nil, indicating no errors.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f83316d00258",
        "ground_truth": "func (hub *Hub) writePairings() error {\n pairingFile, err := os.OpenFile(filepath.Join(hub.datadir, \"smartcards.json\"), os.O_RDWR|os.O_CREATE, 0755)\n if err != nil {\n  return err\n }\n defer pairingFile.Close()\n  pairings := make([]smartcardPairing, 0, len(hub.pairings))\n for _, pairing := range hub.pairings {\n  pairings = append(pairings, pairing)\n }\n  pairingData, err := json.Marshal(pairings)\n if err != nil {\n  return err\n }\n  if _, err := pairingFile.Write(pairingData); err != nil {\n  return err\n }\n  return nil\n}",
        "import_statements": [
            "import (\n\t\"encoding/json\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/event\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n)"
        ],
        "reference_api": [
            "pairingFile.Close",
            "json.Marshal",
            "os.OpenFile",
            "len",
            "make",
            "append",
            "filepath.Join",
            "pairingFile.Write"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "pairingFile.Close",
            "os.OpenFile",
            "len",
            "make",
            "append",
            "pairingFile.Write"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (hub *Hub) Wallets() []accounts.Wallet",
        "start_line": "177",
        "end_line": "190",
        "file_path": "accounts/scwallet/hub.go",
        "docstring": "The function Wallets in the Hub struct returns a list of wallets currently managed by the hub.\\nIt first calls hub.refreshWallets() to ensure the wallet list is up-to-date.\\nIt locks the hub's state for reading using hub.stateLock.RLock() and defers the unlocking until the function returns.\\nIt creates a copy of the hub's wallets by initializing a slice with the same length as the hub's wallets and appending each wallet to the slice.\\nIt then sorts the copied wallets by URL using sort.Sort with accounts.WalletsByURL.\\nFinally, it returns the sorted slice of wallets.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c84f41d20e15",
        "ground_truth": "func (hub *Hub) Wallets() []accounts.Wallet {\n // Make sure the list of wallets is up to date\n hub.refreshWallets()\n  hub.stateLock.RLock()\n defer hub.stateLock.RUnlock()\n  cpy := make([]accounts.Wallet, 0, len(hub.wallets))\n for _, wallet := range hub.wallets {\n  cpy = append(cpy, wallet)\n }\n sort.Sort(accounts.WalletsByURL(cpy))\n return cpy\n}",
        "import_statements": [
            "import (\n\t\"encoding/json\"\n\t\"io\"\n\t\"os\"\n\t\"path/filepath\"\n\t\"sort\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/event\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n)"
        ],
        "reference_api": [
            "accounts.WalletsByURL",
            "hub.stateLock.RLock",
            "sort.Sort",
            "len",
            "make",
            "append",
            "hub.stateLock.RUnlock",
            "hub.refreshWallets"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "accounts.WalletsByURL",
            "hub.stateLock.RLock",
            "sort.Sort",
            "len",
            "make",
            "append",
            "hub.stateLock.RUnlock",
            "hub.refreshWallets"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) connect() error",
        "start_line": "193",
        "end_line": "214",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The connect method in the Wallet struct establishes a secure session with a wallet.\\nIt locks the wallet for exclusive access and defers unlocking until the function returns.\\nIt calls w.doselect() to retrieve app information, including the public key.\\nIf this call fails, it returns the error.\\nIt then creates a new secure channel session using NewSecureChannelSession with the wallet's card and the app's public key.\\nIf this call fails, it returns the error.\\nIt sets the wallet's public key to the app's public key and initializes a logger with the wallet's URL.\\nIt creates a new session with the wallet and the secure channel, storing it in w.session.\\nFinally, it returns nil, indicating successful connection.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f75153965dde",
        "ground_truth": "func (w *Wallet) connect() error {\n w.lock.Lock()\n defer w.lock.Unlock()\n  appinfo, err := w.doselect()\n if err != nil {\n  return err\n }\n  channel, err := NewSecureChannelSession(w.card, appinfo.PublicKey)\n if err != nil {\n  return err\n }\n  w.PublicKey = appinfo.PublicKey\n w.log = log.New(\"url\", w.URL())\n w.session = &Session{\n  Wallet:  w,\n  Channel: channel,\n }\n return nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "w.lock.Unlock",
            "w.doselect",
            "w.URL",
            "log.New",
            "NewSecureChannelSession",
            "w.lock.Lock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "w.lock.Unlock",
            "w.doselect",
            "w.URL",
            "log.New",
            "NewSecureChannelSession",
            "w.lock.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) ping() error",
        "start_line": "237",
        "end_line": "249",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function ping checks the connection status of a Wallet object.\\nIt first locks the wallet to ensure thread safety and defers unlocking until the function returns.\\nIf the wallet session is not paired, it returns nil, indicating no need to ping.\\nIf the wallet is paired, it calls the walletStatus method of the session to check the wallet's status.\\nIf walletStatus returns an error, it returns the error.\\nIf walletStatus is successful, it returns nil, indicating the wallet is connected and functioning properly.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "e073ec4a4e03",
        "ground_truth": "func (w *Wallet) ping() error {\n w.lock.Lock()\n defer w.lock.Unlock()\n  // We can't ping if not paired\n if !w.session.paired() {\n  return nil\n }\n if _, err := w.session.walletStatus(); err != nil {\n  return err\n }\n return nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "w.lock.Unlock",
            "w.session.paired",
            "w.session.walletStatus",
            "w.lock.Lock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "w.lock.Unlock",
            "w.session.paired",
            "w.session.walletStatus",
            "w.lock.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) Close() error",
        "start_line": "420",
        "end_line": "444",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function Close in the Wallet struct is responsible for properly closing the wallet, ensuring all resources are released.\\nIt first locks the wallet to ensure it was opened and retrieves the deriveQuit channel.\\nIt then unlocks the wallet.\\nIf the deriveQuit channel is not nil, it signals termination of self-derivations by sending an error channel on deriveQuit and waits for an error response, storing it in derr.\\nIt then locks the wallet again and defers unlocking until the function returns.\\nIt sets the deriveQuit and deriveReq fields to nil, indicating that the wallet is no longer deriving.\\nFinally, it releases the device connection using the w.release() method.\\nIf this release operation fails, it returns the error; otherwise, it returns the error stored in derr.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "eb46d7550a2e",
        "ground_truth": "func (w *Wallet) Close() error {\n // Ensure the wallet was opened\n w.lock.Lock()\n dQuit := w.deriveQuit\n w.lock.Unlock()\n  // Terminate the self-derivations\n var derr error\n if dQuit != nil {\n  errc := make(chan error)\n  dQuit <- errc\n  derr = <-errc // Save for later, we *must* close the USB\n }\n // Terminate the device connection\n w.lock.Lock()\n defer w.lock.Unlock()\n  w.deriveQuit = nil\n w.deriveReq = nil\n  if err := w.release(); err != nil {\n  return err\n }\n return derr\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "w.lock.Unlock",
            "w.release",
            "make",
            "w.lock.Lock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "w.lock.Unlock",
            "w.release",
            "make",
            "w.lock.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) Accounts() []accounts.Account",
        "start_line": "569",
        "end_line": "592",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function Accounts in the Wallet struct retrieves a list of accounts associated with the wallet.\\nIt first attempts self-derivation by sending a request on the deriveReq channel and waits for a response if the request is accepted.\\nIf self-derivation is offline, throttled, or busy, it skips this step.\\nThe function then locks the wallet for thread-safe access and defers unlocking until the function returns.\\nIt checks if the wallet is paired with a hub by calling w.Hub.pairing(w).\\nIf a pairing exists, it initializes a slice to hold the accounts and iterates over the paired accounts, creating account objects and appending them to the slice.\\nThe accounts are then sorted by their URL, and the sorted slice is returned.\\nIf no pairing exists, it returns nil.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "94e6f6690bd1",
        "ground_truth": "func (w *Wallet) Accounts() []accounts.Account {\n // Attempt self-derivation if it's running\n reqc := make(chan struct{}, 1)\n select {\n case w.deriveReq <- reqc:\n  // Self-derivation request accepted, wait for it\n  <-reqc\n default:\n  // Self-derivation offline, throttled or busy, skip\n }\n  w.lock.Lock()\n defer w.lock.Unlock()\n  if pairing := w.Hub.pairing(w); pairing != nil {\n  ret := make([]accounts.Account, 0, len(pairing.Accounts))\n  for address, path := range pairing.Accounts {\n   ret = append(ret, w.makeAccount(address, path))\n  }\n  sort.Sort(accounts.AccountsByURL(ret))\n  return ret\n }\n return nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "accounts.AccountsByURL",
            "w.Hub.pairing",
            "sort.Sort",
            "len",
            "make",
            "w.lock.Unlock",
            "append",
            "w.makeAccount",
            "w.lock.Lock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "accounts.AccountsByURL",
            "w.Hub.pairing",
            "sort.Sort",
            "len",
            "make",
            "w.lock.Unlock",
            "append",
            "w.makeAccount",
            "w.lock.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) Derive(path accounts.DerivationPath, pin bool) (accounts.Account, error)",
        "start_line": "624",
        "end_line": "642",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function Derive in the Wallet struct derives a new account based on the provided derivation path.\\nIt locks the wallet to ensure thread safety and defers unlocking until the function returns.\\nIt calls the derive method on the wallet's session with the provided derivation path to generate a new account.\\nIf the derivation fails, it returns an empty account and the error.\\nIf the pin parameter is true, it retrieves the wallet's pairing from the Hub, adds the derived account's address and path to the pairing, and updates the pairing in the Hub using setPairing.\\nIf updating the pairing fails, it returns the account and the error.\\nFinally, it returns the derived account and nil as the error.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5b2990eeac7b",
        "ground_truth": "func (w *Wallet) Derive(path accounts.DerivationPath, pin bool) (accounts.Account, error) {\n w.lock.Lock()\n defer w.lock.Unlock()\n  account, err := w.session.derive(path)\n if err != nil {\n  return accounts.Account{}, err\n }\n  if pin {\n  pairing := w.Hub.pairing(w)\n  pairing.Accounts[account.Address] = path\n  if err := w.Hub.setPairing(w, pairing); err != nil {\n   return accounts.Account{}, err\n  }\n }\n  return account, nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "w.Hub.pairing",
            "w.lock.Unlock",
            "w.session.derive",
            "w.Hub.setPairing",
            "w.lock.Lock"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "w.Hub.pairing",
            "w.lock.Unlock",
            "w.session.derive",
            "w.Hub.setPairing",
            "w.lock.Lock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (w *Wallet) findAccountPath(account accounts.Account) (accounts.DerivationPath, error)",
        "start_line": "776",
        "end_line": "797",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function findAccountPath in the Wallet struct retrieves the derivation path for a given account.\\nFirst, it checks if the account's address exists in the wallet's Hub pairing accounts map.\\nIf found, it returns the corresponding derivation path.\\nIf not, it checks if the account's URL scheme matches the wallet's scheme.\\nIf the schemes do not match, it returns an error indicating the mismatch.\\nIt then attempts to split the account's URL path into a URL and a path component.\\nIf the split is unsuccessful, it returns an error indicating an invalid URL format.\\nIt compares the extracted URL with the wallet's public key.\\nIf they do not match, it returns an error indicating that the URL is not for the wallet.\\nFinally, it parses and returns the derivation path from the path component.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "0e5f8265e4c4",
        "ground_truth": "func (w *Wallet) findAccountPath(account accounts.Account) (accounts.DerivationPath, error) {\n pairing := w.Hub.pairing(w)\n if path, ok := pairing.Accounts[account.Address]; ok {\n  return path, nil\n }\n  // Look for the path in the URL\n if account.URL.Scheme != w.Hub.scheme {\n  return nil, fmt.Errorf(\"scheme %s does not match wallet scheme %s\", account.URL.Scheme, w.Hub.scheme)\n }\n  url, path, found := strings.Cut(account.URL.Path, \"/\")\n if !found {\n  return nil, fmt.Errorf(\"invalid URL format: %s\", account.URL)\n }\n  if url != fmt.Sprintf(\"%x\", w.PublicKey[1:3]) {\n  return nil, fmt.Errorf(\"URL %s is not for this wallet\", account.URL)\n }\n  return accounts.ParseDerivationPath(path)\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "fmt.Errorf",
            "w.Hub.pairing",
            "accounts.ParseDerivationPath",
            "fmt.Sprintf",
            "strings.Cut"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "w.Hub.pairing",
            "accounts.ParseDerivationPath"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (s *Session) authenticate(pairing smartcardPairing) error",
        "start_line": "859",
        "end_line": "866",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function authenticate in the Session struct authenticates a session using a smartcard pairing.\\nIt takes a smartcardPairing object as input.\\nFirst, it checks if the public key of the session's wallet matches the public key in the pairing.\\nIf the keys do not match, it returns an error indicating that pairing cannot be done using another wallet's pairing.\\nIf the keys match, it sets the pairing key and pairing index in the session's channel to the values from the pairing object.\\nFinally, it calls s.Channel.Open() to open the channel and returns the result of this operation.\n",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7f67d57eb3de",
        "ground_truth": "func (s *Session) authenticate(pairing smartcardPairing) error {\n if !bytes.Equal(s.Wallet.PublicKey, pairing.PublicKey) {\n  return fmt.Errorf(\"cannot pair using another wallet's pairing; %x != %x\", s.Wallet.PublicKey, pairing.PublicKey)\n }\n s.Channel.PairingKey = pairing.PairingKey\n s.Channel.PairingIndex = pairing.PairingIndex\n return s.Channel.Open()\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "bytes.Equal",
            "s.Channel.Open",
            "fmt.Errorf"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "bytes.Equal",
            "s.Channel.Open"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethereum/go-ethereum",
        "function_declaration": "func (s *Session) publicKey() ([]byte, error)",
        "start_line": "1016",
        "end_line": "1026",
        "file_path": "accounts/scwallet/wallet.go",
        "docstring": "The function publicKey in the Session struct retrieves the public key from a secure channel.\\nIt calls s.Channel.transmitEncrypted with specific parameters to request the export of the public key.\\nIf an error occurs during transmission, it returns nil and the error.\\nIt initializes a new keyExport struct and unmarshals the response data into it using ASN.1 decoding with a specific tag parameter.\\nIf unmarshalling fails, it returns nil and the error.\\nIf successful, it returns the extracted public key.",
        "language": "Go",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "9c6c32227038",
        "ground_truth": "func (s *Session) publicKey() ([]byte, error) {\n response, err := s.Channel.transmitEncrypted(claSCWallet, insExportKey, exportP1Any, exportP2Pubkey, nil)\n if err != nil {\n  return nil, err\n }\n keys := new(keyExport)\n if _, err := asn1.UnmarshalWithParams(response.Data, keys, \"tag:1\"); err != nil {\n  return nil, err\n }\n return keys.PublicKey, nil\n}",
        "import_statements": [
            "import (\n\t\"bytes\"\n\t\"context\"\n\t\"crypto/hmac\"\n\t\"crypto/sha256\"\n\t\"crypto/sha512\"\n\t\"encoding/asn1\"\n\t\"encoding/binary\"\n\t\"errors\"\n\t\"fmt\"\n\t\"math/big\"\n\t\"regexp\"\n\t\"sort\"\n\t\"strings\"\n\t\"sync\"\n\t\"time\"\n\n\t\"github.com/ethereum/go-ethereum\"\n\t\"github.com/ethereum/go-ethereum/accounts\"\n\t\"github.com/ethereum/go-ethereum/common\"\n\t\"github.com/ethereum/go-ethereum/core/types\"\n\t\"github.com/ethereum/go-ethereum/crypto\"\n\t\"github.com/ethereum/go-ethereum/log\"\n\tpcsc \"github.com/gballet/go-libpcsclite\"\n\t\"github.com/status-im/keycard-go/derivationpath\"\n)"
        ],
        "reference_api": [
            "asn1.UnmarshalWithParams",
            "new",
            "s.Channel.transmitEncrypted"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "asn1.UnmarshalWithParams",
            "new",
            "s.Channel.transmitEncrypted"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function renounceRole(bytes32 role, address account) public virtual override(AccessControl, IAccessControl)",
        "start_line": "113",
        "end_line": "122",
        "file_path": "contracts/access/extensions/AccessControlDefaultAdminRules.sol",
        "docstring": "The function renounceRole allows an account to renounce a specified role.\\nIt overrides the renounceRole function in AccessControl and IAccessControl.\\nIf the role is DEFAULT_ADMIN_ROLE and the account is the current default admin, it checks for a pending default admin and a schedule.\\nIf there is a pending default admin, the schedule is not set, or the schedule has not passed, it reverts with an AccessControlEnforcedDefaultAdminDelay error.\\nIf the checks pass, it deletes the pending default admin schedule.\\nFinally, it calls the renounceRole function from the parent contract using super to complete the role renouncement.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "af5890ed6bd0",
        "ground_truth": "function renounceRole(bytes32 role, address account) public virtual override(AccessControl, IAccessControl) {\n    if (role == DEFAULT_ADMIN_ROLE && account == defaultAdmin()) {\n        (address newDefaultAdmin, uint48 schedule) = pendingDefaultAdmin();\n        if (newDefaultAdmin != address(0) || !_isScheduleSet(schedule) || !_hasSchedulePassed(schedule)) {\n            revert AccessControlEnforcedDefaultAdminDelay(schedule);\n        }\n        delete _pendingDefaultAdminSchedule;\n    }\n    super.renounceRole(role, account);\n}",
        "import_statements": [
            "import {IAccessControlDefaultAdminRules} from \"./IAccessControlDefaultAdminRules.sol\";",
            "import {AccessControl, IAccessControl} from \"../AccessControl.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {IERC5313} from \"../../interfaces/IERC5313.sol\";"
        ],
        "reference_api": [
            "defaultAdmin",
            "_hasSchedulePassed",
            "_isScheduleSet",
            "pendingDefaultAdmin",
            "super.renounceRole"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "pendingDefaultAdmin",
                "code": "function pendingDefaultAdmin() public view virtual returns (address newAdmin, uint48 schedule) {\n    return (_pendingDefaultAdmin, _pendingDefaultAdminSchedule);\n}"
            }
        ],
        "third_party": [
            "defaultAdmin",
            "_hasSchedulePassed",
            "_isScheduleSet",
            "pendingDefaultAdmin",
            "super.renounceRole"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _revokeRole(bytes32 role, address account) internal virtual override returns (bool)",
        "start_line": "146",
        "end_line": "151",
        "file_path": "contracts/access/extensions/AccessControlDefaultAdminRules.sol",
        "docstring": "The function _revokeRole is an internal virtual function that overrides a parent contract's method to revoke a role from an account.\\nIt first checks if the role being revoked is the DEFAULT_ADMIN_ROLE and if the account is the current default admin.\\nIf both conditions are true, it deletes the _currentDefaultAdmin variable.\\nFinally, it calls the parent contract's _revokeRole method with the role and account as arguments, and returns the result of this call.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "bec9d78d2a54",
        "ground_truth": "function _revokeRole(bytes32 role, address account) internal virtual override returns (bool) {\n    if (role == DEFAULT_ADMIN_ROLE && account == defaultAdmin()) {\n        delete _currentDefaultAdmin;\n    }\n    return super._revokeRole(role, account);\n}",
        "import_statements": [
            "import {IAccessControlDefaultAdminRules} from \"./IAccessControlDefaultAdminRules.sol\";",
            "import {AccessControl, IAccessControl} from \"../AccessControl.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {IERC5313} from \"../../interfaces/IERC5313.sol\";"
        ],
        "reference_api": [
            "super._revokeRole",
            "defaultAdmin"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "_revokeRole",
                "code": "function _revokeRole(bytes32 role, address account) internal virtual override returns (bool) {\n    bool revoked = super._revokeRole(role, account);\n    if (revoked) {\n        _roleMembers[role].remove(account);\n    }\n    return revoked;\n}"
            }
        ],
        "third_party": [
            "super._revokeRole",
            "defaultAdmin"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _beginDefaultAdminTransfer(address newAdmin) internal virtual",
        "start_line": "220",
        "end_line": "224",
        "file_path": "contracts/access/extensions/AccessControlDefaultAdminRules.sol",
        "docstring": "The function _beginDefaultAdminTransfer is an internal function that initiates the transfer of the default admin role to a new address.\\nIt calculates a new schedule by adding the current block timestamp to the value returned by defaultAdminDelay, then casts it to a uint48 using SafeCast.toUint48.\\nIt sets the pending default admin and the new schedule by calling _setPendingDefaultAdmin.\\nFinally, it emits the DefaultAdminTransferScheduled event with the new admin address and the new schedule timestamp.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d000d1d76549",
        "ground_truth": "function _beginDefaultAdminTransfer(address newAdmin) internal virtual {\n    uint48 newSchedule = SafeCast.toUint48(block.timestamp) + defaultAdminDelay();\n    _setPendingDefaultAdmin(newAdmin, newSchedule);\n    emit DefaultAdminTransferScheduled(newAdmin, newSchedule);\n}",
        "import_statements": [
            "import {IAccessControlDefaultAdminRules} from \"./IAccessControlDefaultAdminRules.sol\";",
            "import {AccessControl, IAccessControl} from \"../AccessControl.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {IERC5313} from \"../../interfaces/IERC5313.sol\";"
        ],
        "reference_api": [
            "_setPendingDefaultAdmin",
            "defaultAdminDelay",
            "SafeCast.toUint48"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "SafeCast.toUint48",
                "code": "function toUint48(uint256 value) internal pure returns (uint48) {\n    if (value > type(uint48).max) {\n        revert SafeCastOverflowedUintDowncast(48, value);\n    }\n    return uint48(value);\n}"
            },
            {
                "name": "defaultAdminDelay",
                "code": "function defaultAdminDelay() public view virtual returns (uint48) {\n    uint48 schedule = _pendingDelaySchedule;\n    return (_isScheduleSet(schedule) && _hasSchedulePassed(schedule)) ? _pendingDelay : _currentDelay;\n}"
            }
        ],
        "third_party": [
            "_setPendingDefaultAdmin"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _setPendingDefaultAdmin(address newAdmin, uint48 newSchedule) private",
        "start_line": "344",
        "end_line": "355",
        "file_path": "contracts/access/extensions/AccessControlDefaultAdminRules.sol",
        "docstring": "The function _setPendingDefaultAdmin sets a new pending default admin and its schedule.\\nIt first retrieves the current pending default admin schedule using pendingDefaultAdmin().\\nThen, it updates _pendingDefaultAdmin with the new admin address and _pendingDefaultAdminSchedule with the new schedule.\\nIf the old schedule is set and hasn't been accepted, indicated by _isScheduleSet(oldSchedule), it emits the DefaultAdminTransferCanceled event to signal the implicit cancellation of the previous pending default admin transfer.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "aca2f8b22224",
        "ground_truth": "function _setPendingDefaultAdmin(address newAdmin, uint48 newSchedule) private {\n    (, uint48 oldSchedule) = pendingDefaultAdmin();\n    _pendingDefaultAdmin = newAdmin;\n    _pendingDefaultAdminSchedule = newSchedule;\n    // An `oldSchedule` from `pendingDefaultAdmin()` is only set if it hasn't been accepted.\n    if (_isScheduleSet(oldSchedule)) {\n        // Emit for implicit cancellations when another default admin was scheduled.\n        emit DefaultAdminTransferCanceled();\n    }\n}",
        "import_statements": [
            "import {IAccessControlDefaultAdminRules} from \"./IAccessControlDefaultAdminRules.sol\";",
            "import {AccessControl, IAccessControl} from \"../AccessControl.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {IERC5313} from \"../../interfaces/IERC5313.sol\";"
        ],
        "reference_api": [
            "_isScheduleSet",
            "pendingDefaultAdmin"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_isScheduleSet",
            "pendingDefaultAdmin"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _setRoleAdmin(uint64 roleId, uint64 admin) internal virtual",
        "start_line": "320",
        "end_line": "328",
        "file_path": "contracts/access/manager/AccessManager.sol",
        "docstring": "The function _setRoleAdmin(uint64 roleId, uint64 admin) sets the admin role for a specific role.\\nIf the roleId is either ADMIN_ROLE or PUBLIC_ROLE, it reverts with an AccessManagerLockedRole error to prevent changes to these roles.\\nOtherwise, it updates the admin for the specified roleId in the _roles mapping.\\nAfter setting the new admin, it emits a RoleAdminChanged event with the roleId and the new admin value.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "28b8ad2f2e2c",
        "ground_truth": "function _setRoleAdmin(uint64 roleId, uint64 admin) internal virtual {\n    if (roleId == ADMIN_ROLE || roleId == PUBLIC_ROLE) {\n        revert AccessManagerLockedRole(roleId);\n    }\n    _roles[roleId].admin = admin;\n    emit RoleAdminChanged(roleId, admin);\n}",
        "import_statements": [
            "import {IAccessManager} from \"./IAccessManager.sol\";",
            "import {IAccessManaged} from \"./IAccessManaged.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Multicall} from \"../../utils/Multicall.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function schedule(\n        address target,\n        bytes calldata data,\n        uint48 when\n    ) public virtual returns (bytes32 operationId, uint32 nonce)",
        "start_line": "432",
        "end_line": "466",
        "file_path": "contracts/access/manager/AccessManager.sol",
        "docstring": "The function schedule schedules a delayed operation for execution.\\nIt takes the target address, calldata, and a timestamp as inputs.\\nFirst, it retrieves the caller's address and checks the restrictions that apply to the caller for the targeted function using _canCallExtended.\\nIt calculates the minimum allowed timestamp by adding a setback to the current timestamp.\\nIf the delay is not authorized or the requested timing is too soon, it reverts with an AccessManagerUnauthorizedCall error.\\nIt then sets the execution time to the maximum of the requested time and the minimum allowed time.\\nIt calculates the operation ID by hashing the caller, target, and data, and checks if the operation is already scheduled using _checkNotScheduled.\\nIt increments the nonce and updates the schedule with the execution time and nonce.\\nFinally, it emits an OperationScheduled event with the operation details and returns the operation ID and nonce.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "280bc2849dfd",
        "ground_truth": "function schedule(\n    address target,\n    bytes calldata data,\n    uint48 when\n) public virtual returns (bytes32 operationId, uint32 nonce) {\n    address caller = _msgSender();\n    // Fetch restrictions that apply to the caller on the targeted function\n    (, uint32 setback) = _canCallExtended(caller, target, data);\n    uint48 minWhen = Time.timestamp() + setback;\n    // If call with delay is not authorized, or if requested timing is too soon, revert\n    if (setback == 0 || (when > 0 && when < minWhen)) {\n        revert AccessManagerUnauthorizedCall(caller, target, _checkSelector(data));\n    }\n    // Reuse variable due to stack too deep\n    when = uint48(Math.max(when, minWhen)); // cast is safe: both inputs are uint48\n    // If caller is authorised, schedule operation\n    operationId = hashOperation(caller, target, data);\n    _checkNotScheduled(operationId);\n    unchecked {\n        // It's not feasible to overflow the nonce in less than 1000 years\n        nonce = _schedules[operationId].nonce + 1;\n    }\n    _schedules[operationId].timepoint = when;\n    _schedules[operationId].nonce = nonce;\n    emit OperationScheduled(operationId, nonce, when, caller, target, data);\n    // Using named return values because otherwise we get stack too deep\n}",
        "import_statements": [
            "import {IAccessManager} from \"./IAccessManager.sol\";",
            "import {IAccessManaged} from \"./IAccessManaged.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Multicall} from \"../../utils/Multicall.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_checkSelector",
            "_msgSender",
            "_checkNotScheduled",
            "Math.max",
            "_canCallExtended",
            "Time.timestamp",
            "hashOperation"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "_msgSender",
                "code": "function _msgSender() internal view virtual returns (address) {\n    return msg.sender;\n}"
            },
            {
                "name": "_checkNotScheduled",
                "code": "function _checkNotScheduled(bytes32 operationId) private view {\n    uint48 prevTimepoint = _schedules[operationId].timepoint;\n    if (prevTimepoint != 0 && !_isExpired(prevTimepoint)) {\n        revert AccessManagerAlreadyScheduled(operationId);\n    }\n}"
            },
            {
                "name": "hashOperation",
                "code": "function hashOperation(\n    address target,\n    uint256 value,\n    bytes calldata data,\n    bytes32 predecessor,\n    bytes32 salt\n) public pure virtual returns (bytes32) {\n    return keccak256(abi.encode(target, value, data, predecessor, salt));\n}"
            }
        ],
        "third_party": [
            "_checkSelector",
            "Math.max",
            "_canCallExtended",
            "Time.timestamp",
            "hashOperation"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function execute(address target, bytes calldata data) public payable virtual returns (uint32)",
        "start_line": "484",
        "end_line": "515",
        "file_path": "contracts/access/manager/AccessManager.sol",
        "docstring": "The function execute in a smart contract performs a secure and authorized call to a target contract with specified data.\\nIt starts by determining the caller's address using _msgSender().\\nIt fetches the restrictions applicable to the caller for the targeted function using _canCallExtended.\\nIf the call is not authorized (both immediate is false and setback is 0), it reverts with AccessManagerUnauthorizedCall.\\nIt hashes the operation using hashOperation and initializes a nonce.\\nIf a setback is required or the operation is scheduled, it consumes a scheduled operation using _consumeScheduledOp.\\nIt marks the target and selector as authorized by updating _executionId with a hashed execution identifier.\\nThe function call is then performed using Address.functionCallWithValue with the target, data, and msg.value.\\nAfter the call, it resets _executionId to its previous value.\\nFinally, it returns the nonce.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "e639983b8a7d",
        "ground_truth": "function execute(address target, bytes calldata data) public payable virtual returns (uint32) {\n    address caller = _msgSender();\n    // Fetch restrictions that apply to the caller on the targeted function\n    (bool immediate, uint32 setback) = _canCallExtended(caller, target, data);\n    // If call is not authorized, revert\n    if (!immediate && setback == 0) {\n        revert AccessManagerUnauthorizedCall(caller, target, _checkSelector(data));\n    }\n    bytes32 operationId = hashOperation(caller, target, data);\n    uint32 nonce;\n    // If caller is authorised, check operation was scheduled early enough\n    // Consume an available schedule even if there is no currently enforced delay\n    if (setback != 0 || getSchedule(operationId) != 0) {\n        nonce = _consumeScheduledOp(operationId);\n    }\n    // Mark the target and selector as authorised\n    bytes32 executionIdBefore = _executionId;\n    _executionId = _hashExecutionId(target, _checkSelector(data));\n    // Perform call\n    Address.functionCallWithValue(target, data, msg.value);\n    // Reset execute identifier\n    _executionId = executionIdBefore;\n    return nonce;\n}",
        "import_statements": [
            "import {IAccessManager} from \"./IAccessManager.sol\";",
            "import {IAccessManaged} from \"./IAccessManaged.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Multicall} from \"../../utils/Multicall.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_checkSelector",
            "getSchedule",
            "_msgSender",
            "_hashExecutionId",
            "Address.functionCallWithValue",
            "_canCallExtended",
            "_consumeScheduledOp",
            "hashOperation"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "hashOperation",
                "code": "function hashOperation(\n    address target,\n    uint256 value,\n    bytes calldata data,\n    bytes32 predecessor,\n    bytes32 salt\n) public pure virtual returns (bytes32) {\n    return keccak256(abi.encode(target, value, data, predecessor, salt));\n}"
            }
        ],
        "third_party": [
            "_checkSelector",
            "getSchedule",
            "_msgSender",
            "_hashExecutionId",
            "Address.functionCallWithValue",
            "_canCallExtended",
            "_consumeScheduledOp",
            "hashOperation"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _checkAuthorized() private",
        "start_line": "590",
        "end_line": "601",
        "file_path": "contracts/access/manager/AccessManager.sol",
        "docstring": "The function _checkAuthorized is a private function that checks if the caller is authorized to perform the current operation.\\nIt retrieves the caller's address using _msgSender() and checks if the caller can immediately call the current function or if there is a delay using _canCallSelf.\\nIf the caller is not immediately authorized, it checks the delay.\\nIf the delay is zero, it retrieves the required role and reverts with an AccessManagerUnauthorizedAccount error.\\nIf there is a delay, it consumes the scheduled operation by calling _consumeScheduledOp with the hash of the operation.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "05f359c910eb",
        "ground_truth": "function _checkAuthorized() private {\n    address caller = _msgSender();\n    (bool immediate, uint32 delay) = _canCallSelf(caller, _msgData());\n    if (!immediate) {\n        if (delay == 0) {\n            (, uint64 requiredRole, ) = _getAdminRestrictions(_msgData());\n            revert AccessManagerUnauthorizedAccount(caller, requiredRole);\n        } else {\n            _consumeScheduledOp(hashOperation(caller, address(this), _msgData()));\n        }\n    }\n}",
        "import_statements": [
            "import {IAccessManager} from \"./IAccessManager.sol\";",
            "import {IAccessManaged} from \"./IAccessManaged.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Multicall} from \"../../utils/Multicall.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_msgSender",
            "_canCallSelf",
            "_getAdminRestrictions",
            "hashOperation",
            "_msgData",
            "_consumeScheduledOp"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_msgSender",
            "_canCallSelf",
            "_getAdminRestrictions",
            "hashOperation",
            "_msgData",
            "_consumeScheduledOp"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _countVote(\n        uint256 proposalId,\n        address account,\n        uint8 support,\n        uint256 totalWeight,\n        bytes memory // params\n    ) internal virtual override returns (uint256)",
        "start_line": "76",
        "end_line": "101",
        "file_path": "contracts/governance/extensions/GovernorCountingSimple.sol",
        "docstring": "The _countVote function records a vote for a specific proposal.\\nIt takes a proposal ID, voter address, support type, and total weight of the vote as parameters.\\nIt accesses the ProposalVote struct for the given proposal ID.\\nIf the account has already voted, it reverts with GovernorAlreadyCastVote.\\nIf not, it marks the account as having voted.\\nBased on the support type (Against, For, or Abstain), it increments the corresponding vote count by the total weight.\\nIf the support type is invalid, it reverts with GovernorInvalidVoteType.\\nIt returns the total weight of the vote.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a4c5e5eeb62f",
        "ground_truth": "function _countVote(\n    uint256 proposalId,\n    address account,\n    uint8 support,\n    uint256 totalWeight,\n    bytes memory // params\n) internal virtual override returns (uint256) {\n    ProposalVote storage proposalVote = _proposalVotes[proposalId];\n    if (proposalVote.hasVoted[account]) {\n        revert GovernorAlreadyCastVote(account);\n    }\n    proposalVote.hasVoted[account] = true;\n    if (support == uint8(VoteType.Against)) {\n        proposalVote.againstVotes += totalWeight;\n    } else if (support == uint8(VoteType.For)) {\n        proposalVote.forVotes += totalWeight;\n    } else if (support == uint8(VoteType.Abstain)) {\n        proposalVote.abstainVotes += totalWeight;\n    } else {\n        revert GovernorInvalidVoteType();\n    }\n    return totalWeight;\n}",
        "import_statements": [
            "import {Governor} from \"../Governor.sol\";"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _cancel(\n        address[] memory targets,\n        uint256[] memory values,\n        bytes[] memory calldatas,\n        bytes32 descriptionHash\n    ) internal virtual override returns (uint256)",
        "start_line": "282",
        "end_line": "317",
        "file_path": "contracts/governance/extensions/GovernorTimelockAccess.sol",
        "docstring": "The function _cancel internally overrides a virtual function to cancel a proposal.\\nIt takes arrays of targets, values, and calldatas, along with a description hash.\\nIt calls the parent contract's _cancel function with these parameters and retrieves the proposalId.\\nIt then gets the ETA (estimated time of arrival) of the proposal using SafeCast to convert it to uint48.\\nThe function accesses the execution plan for the proposalId from the _executionPlan mapping.\\nIf the proposal has been scheduled (indicated by a non-zero ETA), it iterates over the targets.\\nFor each target, it retrieves manager data, including whether the operation has a delay and its nonce.\\nIf the execution plan includes a delay, it hashes the operation and checks if the nonce matches the current nonce of the operation.\\nIf they match, it attempts to cancel the operation using the _manager's cancel function.\\nFinally, it returns the proposalId.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "30a8b1e547b1",
        "ground_truth": "function _cancel(\n    address[] memory targets,\n    uint256[] memory values,\n    bytes[] memory calldatas,\n    bytes32 descriptionHash\n) internal virtual override returns (uint256) {\n    uint256 proposalId = super._cancel(targets, values, calldatas, descriptionHash);\n    uint48 etaSeconds = SafeCast.toUint48(proposalEta(proposalId));\n    ExecutionPlan storage plan = _executionPlan[proposalId];\n    // If the proposal has been scheduled it will have an ETA and we may have to externally cancel\n    if (etaSeconds != 0) {\n        for (uint256 i = 0; i < targets.length; ++i) {\n            (, bool withDelay, uint32 nonce) = _getManagerData(plan, i);\n            // Only attempt to cancel if the execution plan included a delay\n            if (withDelay) {\n                bytes32 operationId = _manager.hashOperation(address(this), targets[i], calldatas[i]);\n                // Check first if the current operation nonce is the one that we observed previously. It could\n                // already have been cancelled and rescheduled. We don't want to cancel unless it is exactly the\n                // instance that we previously scheduled.\n                if (nonce == _manager.getNonce(operationId)) {\n                    // It is important that all calls have an opportunity to be cancelled. We chose to ignore\n                    // potential failures of some of the cancel operations to give the other operations a chance to\n                    // be properly cancelled. In particular cancel might fail if the operation was already cancelled\n                    // by guardians previously. We don't match on the revert reason to avoid encoding assumptions\n                    // about specific errors.\n                    try _manager.cancel(address(this), targets[i], calldatas[i]) {} catch {}\n                }\n            }\n        }\n    }\n    return proposalId;\n}",
        "import_statements": [
            "import {Governor} from \"../Governor.sol\";",
            "import {AuthorityUtils} from \"../../access/manager/AuthorityUtils.sol\";",
            "import {IAccessManager} from \"../../access/manager/IAccessManager.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {Math} from \"../../utils/math/Math.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_manager.hashOperation",
            "_manager.cancel",
            "_getManagerData",
            "super._cancel",
            "proposalEta",
            "SafeCast.toUint48",
            "nonce == _manager.getNonce"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "SafeCast.toUint48",
                "code": "function toUint48(uint256 value) internal pure returns (uint48) {\n    if (value > type(uint48).max) {\n        revert SafeCastOverflowedUintDowncast(48, value);\n    }\n    return uint48(value);\n}"
            }
        ],
        "third_party": [
            "_manager.hashOperation",
            "_manager.cancel",
            "_getManagerData",
            "super._cancel",
            "proposalEta",
            "SafeCast.toUint48",
            "nonce == _manager.getNonce"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function CLOCK_MODE() public view virtual override returns (string memory)",
        "start_line": "46",
        "end_line": "52",
        "file_path": "contracts/governance/extensions/GovernorVotes.sol",
        "docstring": "The function CLOCK_MODE retrieves the clock mode from a token contract.\\nIt attempts to call the CLOCK_MODE function on the token contract by using the try keyword.\\nIf the call is successful, it returns the clock mode string obtained from the token contract.\\nIf the call fails (due to an error or the function not existing), it catches the exception and returns a default clock mode string \"mode=blocknumber&from=default\".",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "791a85db379f",
        "ground_truth": "function CLOCK_MODE() public view virtual override returns (string memory) {\n    try token().CLOCK_MODE() returns (string memory clockmode) {\n        return clockmode;\n    } catch {\n        return \"mode=blocknumber&from=default\";\n    }\n}",
        "import_statements": [
            "import {Governor} from \"../Governor.sol\";",
            "import {IVotes} from \"../utils/IVotes.sol\";",
            "import {IERC5805} from \"../../interfaces/IERC5805.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "token().CLOCK_MODE",
            "token"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "token().CLOCK_MODE",
            "token"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function getPastTotalSupply(uint256 timepoint) public view virtual returns (uint256)",
        "start_line": "109",
        "end_line": "115",
        "file_path": "contracts/governance/utils/Votes.sol",
        "docstring": "The function getPastTotalSupply(uint256 timepoint) retrieves the total supply of tokens at a specific past timepoint.\\nIt first gets the current timepoint using the clock() function.\\nIf the requested timepoint is greater than or equal to the current timepoint, it reverts with an error, as future lookups are not allowed.\\nIf the timepoint is valid, it calls the _totalCheckpoints.upperLookupRecent function, passing the timepoint cast to a 48-bit unsigned integer, and returns the total supply at that timepoint.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d22004c2cfdc",
        "ground_truth": "function getPastTotalSupply(uint256 timepoint) public view virtual returns (uint256) {\n    uint48 currentTimepoint = clock();\n    if (timepoint >= currentTimepoint) {\n        revert ERC5805FutureLookup(timepoint, currentTimepoint);\n    }\n    return _totalCheckpoints.upperLookupRecent(SafeCast.toUint48(timepoint));\n}",
        "import_statements": [
            "import {IERC5805} from \"../../interfaces/IERC5805.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Nonces} from \"../../utils/Nonces.sol\";",
            "import {EIP712} from \"../../utils/cryptography/EIP712.sol\";",
            "import {Checkpoints} from \"../../utils/structs/Checkpoints.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {ECDSA} from \"../../utils/cryptography/ECDSA.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_totalCheckpoints.upperLookupRecent",
            "SafeCast.toUint48",
            "clock"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "SafeCast.toUint48",
                "code": "function toUint48(uint256 value) internal pure returns (uint48) {\n    if (value > type(uint48).max) {\n        revert SafeCastOverflowedUintDowncast(48, value);\n    }\n    return uint48(value);\n}"
            }
        ],
        "third_party": [
            "_totalCheckpoints.upperLookupRecent",
            "SafeCast.toUint48",
            "clock"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _delegate(address account, address delegatee) internal virtual ",
        "start_line": "168",
        "end_line": "174",
        "file_path": "contracts/governance/utils/Votes.sol",
        "docstring": "The function _delegate internally handles the delegation of voting power from one address to another.\\nIt takes two parameters: the account that is delegating and the delegatee to whom the voting power is delegated.\\nFirst, it retrieves the current delegate of the account using delegates(account) and stores it in oldDelegate.\\nIt then updates the delegate of the account to the new delegatee.\\nThe function emits a DelegateChanged event to log the change of delegation.\\nFinally, it calls _moveDelegateVotes to adjust the voting units, moving them from the old delegate to the new delegatee based on the voting units of the account.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "9bd702ec52ce",
        "ground_truth": "function _delegate(address account, address delegatee) internal virtual {\n    address oldDelegate = delegates(account);\n    _delegatee[account] = delegatee;\n    emit DelegateChanged(account, oldDelegate, delegatee);\n    _moveDelegateVotes(oldDelegate, delegatee, _getVotingUnits(account));\n}",
        "import_statements": [
            "import {IERC5805} from \"../../interfaces/IERC5805.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Nonces} from \"../../utils/Nonces.sol\";",
            "import {EIP712} from \"../../utils/cryptography/EIP712.sol\";",
            "import {Checkpoints} from \"../../utils/structs/Checkpoints.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {ECDSA} from \"../../utils/cryptography/ECDSA.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_moveDelegateVotes",
            "delegates",
            "_getVotingUnits"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "_getVotingUnits",
                "code": "function _getVotingUnits(address account) internal view override returns (uint256) {\n    return _votingUnits[account];\n}"
            }
        ],
        "third_party": [
            "_moveDelegateVotes",
            "delegates",
            "_getVotingUnits"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": " function _transferVotingUnits(address from, address to, uint256 amount) internal virtual",
        "start_line": "180",
        "end_line": "188",
        "file_path": "contracts/governance/utils/Votes.sol",
        "docstring": "The function _transferVotingUnits handles the transfer of voting units between addresses.\\nIf the from address is the zero address, it adds the amount to the total checkpoints by calling _push with _totalCheckpoints, _add, and the amount cast to uint208.\\nIf the to address is the zero address, it subtracts the amount from the total checkpoints by calling _push with _totalCheckpoints, _subtract, and the amount cast to uint208.\\nIt then moves the delegate votes from the delegate of the from address to the delegate of the to address by calling _moveDelegateVotes with delegates(from), delegates(to), and the amount.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "40468a57a47e",
        "ground_truth": "function _transferVotingUnits(address from, address to, uint256 amount) internal virtual {\n    if (from == address(0)) {\n        _push(_totalCheckpoints, _add, SafeCast.toUint208(amount));\n    }\n    if (to == address(0)) {\n        _push(_totalCheckpoints, _subtract, SafeCast.toUint208(amount));\n    }\n    _moveDelegateVotes(delegates(from), delegates(to), amount);\n}",
        "import_statements": [
            "import {IERC5805} from \"../../interfaces/IERC5805.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {Nonces} from \"../../utils/Nonces.sol\";",
            "import {EIP712} from \"../../utils/cryptography/EIP712.sol\";",
            "import {Checkpoints} from \"../../utils/structs/Checkpoints.sol\";",
            "import {SafeCast} from \"../../utils/math/SafeCast.sol\";",
            "import {ECDSA} from \"../../utils/cryptography/ECDSA.sol\";",
            "import {Time} from \"../../utils/types/Time.sol\";"
        ],
        "reference_api": [
            "_push",
            "_moveDelegateVotes",
            "SafeCast.toUint208",
            "delegates"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "SafeCast.toUint208",
                "code": "function toUint208(uint256 value) internal pure returns (uint208) {\n    if (value > type(uint208).max) {\n        revert SafeCastOverflowedUintDowncast(208, value);\n    }\n    return uint208(value);\n}"
            }
        ],
        "third_party": [
            "_push",
            "SafeCast.toUint208",
            "delegates"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _setBeacon(address newBeacon) private",
        "start_line": "133",
        "end_line": "144",
        "file_path": "contracts/proxy/ERC1967/ERC1967Utils.sol",
        "docstring": "The function _setBeacon sets a new beacon address for an ERC1967-compliant contract.\\nIt first checks if the new beacon address contains code; if not, it reverts with an ERC1967InvalidBeacon error.\\nIt then stores the new beacon address in the BEACON_SLOT using StorageSlot.getAddressSlot.\\nNext, it retrieves the implementation address from the new beacon by calling the implementation() function of the IBeacon interface.\\nIt checks if the implementation address contains code; if not, it reverts with an ERC1967InvalidImplementation error.\\nThis function ensures the new beacon and its implementation are valid and properly stored.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1114e93aa28b",
        "ground_truth": "function _setBeacon(address newBeacon) private {\n    if (newBeacon.code.length == 0) {\n        revert ERC1967InvalidBeacon(newBeacon);\n    }\n    StorageSlot.getAddressSlot(BEACON_SLOT).value = newBeacon;\n    address beaconImplementation = IBeacon(newBeacon).implementation();\n    if (beaconImplementation.code.length == 0) {\n        revert ERC1967InvalidImplementation(beaconImplementation);\n    }\n}",
        "import_statements": [
            "import {IBeacon} from \"../beacon/IBeacon.sol\";",
            "import {IERC1967} from \"../../interfaces/IERC1967.sol\";",
            "import {Address} from \"../../utils/Address.sol\";",
            "import {StorageSlot} from \"../../utils/StorageSlot.sol\";"
        ],
        "reference_api": [
            "StorageSlot.getAddressSlot",
            "IBeacon(newBeacon).implementation",
            "IBeacon"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "StorageSlot.getAddressSlot",
                "code": "function getAddressSlot(bytes32 slot) public view returns (address) {\n    return slot.getAddressSlot().value;\n}"
            }
        ],
        "third_party": [
            "StorageSlot.getAddressSlot",
            "IBeacon(newBeacon).implementation",
            "IBeacon"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function checkOnERC1155BatchReceived(\n        address operator,\n        address from,\n        address to,\n        uint256[] memory ids,\n        uint256[] memory values,\n        bytes memory data\n    ) internal",
        "start_line": "58",
        "end_line": "86",
        "file_path": "contracts/token/ERC1155/utils/ERC1155Utils.sol",
        "docstring": "The function checkOnERC1155BatchReceived verifies if a contract at address to correctly handles ERC1155 batch transfers.\\nIt checks if the code at the to address is non-empty.\\nIf it is, it attempts to call the onERC1155BatchReceived function on the IERC1155Receiver interface.\\nIt passes the operator, from, ids, values, and data parameters.\\nIf the call returns a response not equal to the expected selector, it reverts with an ERC1155InvalidReceiver error.\\nIf the call fails, it checks the returned error reason.\\nIf the reason is empty, it reverts with an ERC1155InvalidReceiver error indicating a non-IERC1155Receiver implementer.\\nIf the reason is not empty, it reverts with the provided error reason using inline assembly.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ff957a7a48bd",
        "ground_truth": "function checkOnERC1155BatchReceived(\n    address operator,\n    address from,\n    address to,\n    uint256[] memory ids,\n    uint256[] memory values,\n    bytes memory data\n) internal {\n    if (to.code.length > 0) {\n        try IERC1155Receiver(to).onERC1155BatchReceived(operator, from, ids, values, data) returns (\n            bytes4 response\n        ) {\n            if (response != IERC1155Receiver.onERC1155BatchReceived.selector) {\n                // Tokens rejected\n                revert IERC1155Errors.ERC1155InvalidReceiver(to);\n            }\n        } catch (bytes memory reason) {\n            if (reason.length == 0) {\n                // non-IERC1155Receiver implementer\n                revert IERC1155Errors.ERC1155InvalidReceiver(to);\n            } else {\n                /// @solidity memory-safe-assembly\n                assembly {\n                    revert(add(32, reason), mload(reason))\n                }\n            }\n        }\n    }\n}",
        "import_statements": [
            "import {IERC1155Receiver} from \"../IERC1155Receiver.sol\";",
            "import {IERC1155Errors} from \"../../../interfaces/draft-IERC6093.sol\";"
        ],
        "reference_api": [
            "IERC1155Receiver",
            "IERC1155Receiver(to).onERC1155BatchReceived"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "IERC1155Receiver",
            "IERC1155Receiver(to).onERC1155BatchReceived"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function balanceOfBatch(\n        address[] memory accounts,\n        uint256[] memory ids\n    ) public view virtual returns (uint256[] memory)",
        "start_line": "75",
        "end_line": "90",
        "file_path": "contracts/token/ERC1155/ERC1155.sol",
        "docstring": "The function balanceOfBatch retrieves the balances of multiple accounts for multiple token IDs.\\nIt takes two arrays as input: accounts and ids.\\nFirst, it checks if the lengths of the accounts and ids arrays are equal.\\nIf not, it reverts with an ERC1155InvalidArrayLength error.\\nIt initializes a new array, batchBalances, to store the balances, with a length equal to the accounts array.\\nIt then iterates over each account and token ID, calling balanceOf to get the balance for each pair and storing the result in batchBalances.\\nFinally, it returns the batchBalances array.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "fa104ec3c081",
        "ground_truth": "function balanceOfBatch(\n    address[] memory accounts,\n    uint256[] memory ids\n) public view virtual returns (uint256[] memory) {\n    if (accounts.length != ids.length) {\n        revert ERC1155InvalidArrayLength(ids.length, accounts.length);\n    }\n    uint256[] memory batchBalances = new uint256[](accounts.length);\n    for (uint256 i = 0; i < accounts.length; ++i) {\n        batchBalances[i] = balanceOf(accounts.unsafeMemoryAccess(i), ids.unsafeMemoryAccess(i));\n    }\n    return batchBalances;\n}",
        "import_statements": [
            "import {IERC1155} from \"./IERC1155.sol\";",
            "import {IERC1155MetadataURI} from \"./extensions/IERC1155MetadataURI.sol\";",
            "import {ERC1155Utils} from \"./utils/ERC1155Utils.sol\";",
            "import {Context} from \"../../utils/Context.sol\";",
            "import {IERC165, ERC165} from \"../../utils/introspection/ERC165.sol\";",
            "import {Arrays} from \"../../utils/Arrays.sol\";",
            "import {IERC1155Errors} from \"../../interfaces/draft-IERC6093.sol\";"
        ],
        "reference_api": [
            "accounts.unsafeMemoryAccess",
            "new uint256[]",
            "balanceOf",
            "ids.unsafeMemoryAccess"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "accounts.unsafeMemoryAccess",
                "code": "function unsafeMemoryAccess(address[] memory arr, uint256 pos) internal pure returns (address res) {\n    assembly {\n        res := mload(add(add(arr, 0x20), mul(pos, 0x20)))\n    }\n}"
            }
        ],
        "third_party": [
            "accounts.unsafeMemoryAccess",
            "new uint256[]",
            "balanceOf",
            "ids.unsafeMemoryAccess"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function royaltyInfo(uint256 tokenId, uint256 salePrice) public view virtual returns (address, uint256) ",
        "start_line": "61",
        "end_line": "74",
        "file_path": "contracts/token/common/ERC2981.sol",
        "docstring": "The function royaltyInfo retrieves royalty payment information for a given tokenId and salePrice.\\nIt first fetches the RoyaltyInfo for the specified tokenId from the _tokenRoyaltyInfo mapping.\\nIt extracts the royalty receiver and royalty fraction from the fetched data.\\nIf the receiver address is zero, it defaults to using _defaultRoyaltyInfo for the receiver and royalty fraction.\\nIt calculates the royalty amount by multiplying the sale price by the royalty fraction and dividing by _feeDenominator().\\nFinally, it returns the royalty receiver and the calculated royalty amount.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "2344831d8bea",
        "ground_truth": "function royaltyInfo(uint256 tokenId, uint256 salePrice) public view virtual returns (address, uint256) {\n    RoyaltyInfo storage _royaltyInfo = _tokenRoyaltyInfo[tokenId];\n    address royaltyReceiver = _royaltyInfo.receiver;\n    uint96 royaltyFraction = _royaltyInfo.royaltyFraction;\n    if (royaltyReceiver == address(0)) {\n        royaltyReceiver = _defaultRoyaltyInfo.receiver;\n        royaltyFraction = _defaultRoyaltyInfo.royaltyFraction;\n    }\n    uint256 royaltyAmount = (salePrice * royaltyFraction) / _feeDenominator();\n    return (royaltyReceiver, royaltyAmount);\n}",
        "import_statements": [
            "import {IERC2981} from \"../../interfaces/IERC2981.sol\";",
            "import {IERC165, ERC165} from \"../../utils/introspection/ERC165.sol\";"
        ],
        "reference_api": [
            "_feeDenominator"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "_feeDenominator",
                "code": "function _feeDenominator() internal pure virtual returns (uint96) {\n    return 10000;\n}"
            }
        ],
        "third_party": [
            "_feeDenominator"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function processMultiProof(\n        bytes32[] memory proof,\n        bool[] memory proofFlags,\n        bytes32[] memory leaves\n    ) internal pure returns (bytes32 merkleRoot)",
        "start_line": "109",
        "end_line": "158",
        "file_path": "contracts/utils/cryptography/MerkleProof.sol",
        "docstring": "The function processMultiProof validates and processes a Merkle multiproof to compute the Merkle root.\\nIt takes three parameters: proof (an array of bytes32 values), proofFlags (an array of boolean flags), and leaves (an array of bytes32 leaves).\\nIt initializes variables for the lengths of leaves, proof, and the total number of hashes to be computed.\\nIt checks the validity of the proof by ensuring the sum of leaves and proof lengths equals totalHashes + 1.\\nIt creates an array to store intermediate hashes and initializes positions for leaves, hashes, and proof.\\nIn a loop, it iterates over totalHashes, selecting values from leaves or hashes based on the current positions and proofFlags, then computes the hash using Hashes.commutativeKeccak256.\\nAfter the loop, it performs final validation and returns the last computed hash if totalHashes is greater than 0, the first leaf if leaves are provided, or the first proof element otherwise.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1e73c9aeca24",
        "ground_truth": "function processMultiProof(\n    bytes32[] memory proof,\n    bool[] memory proofFlags,\n    bytes32[] memory leaves\n) internal pure returns (bytes32 merkleRoot) {\n    // This function rebuilds the root hash by traversing the tree up from the leaves. The root is rebuilt by\n    // consuming and producing values on a queue. The queue starts with the `leaves` array, then goes onto the\n    // `hashes` array. At the end of the process, the last hash in the `hashes` array should contain the root of\n    // the Merkle tree.\n    uint256 leavesLen = leaves.length;\n    uint256 proofLen = proof.length;\n    uint256 totalHashes = proofFlags.length;\n    // Check proof validity.\n    if (leavesLen + proofLen != totalHashes + 1) {\n        revert MerkleProofInvalidMultiproof();\n    }\n    // The xxxPos values are \"pointers\" to the next value to consume in each array. All accesses are done using\n    // `xxx[xxxPos++]`, which return the current value and increment the pointer, thus mimicking a queue's \"pop\".\n    bytes32[] memory hashes = new bytes32[](totalHashes);\n    uint256 leafPos = 0;\n    uint256 hashPos = 0;\n    uint256 proofPos = 0;\n    // At each step, we compute the next hash using two values:\n    // - a value from the \"main queue\". If not all leaves have been consumed, we get the next leaf, otherwise we\n    //   get the next hash.\n    // - depending on the flag, either another value from the \"main queue\" (merging branches) or an element from the\n    //   `proof` array.\n    for (uint256 i = 0; i < totalHashes; i++) {\n        bytes32 a = leafPos < leavesLen ? leaves[leafPos++] : hashes[hashPos++];\n        bytes32 b = proofFlags[i]\n            ? (leafPos < leavesLen ? leaves[leafPos++] : hashes[hashPos++])\n            : proof[proofPos++];\n        hashes[i] = Hashes.commutativeKeccak256(a, b);\n    }\n    if (totalHashes > 0) {\n        if (proofPos != proofLen) {\n            revert MerkleProofInvalidMultiproof();\n        }\n        unchecked {\n            return hashes[totalHashes - 1];\n        }\n    } else if (leavesLen > 0) {\n        return leaves[0];\n    } else {\n        return proof[0];\n    }\n}",
        "import_statements": [
            "import {Hashes} from \"./Hashes.sol\";"
        ],
        "reference_api": [
            "new bytes32[]",
            "Hashes.commutativeKeccak256"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "Hashes.commutativeKeccak256",
                "code": "function commutativeKeccak256(bytes32 a, bytes32 b) internal pure returns (bytes32) {\n    return a < b ? _efficientKeccak256(a, b) : _efficientKeccak256(b, a);\n}"
            }
        ],
        "third_party": [
            "new bytes32[]",
            "Hashes.commutativeKeccak256"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function processMultiProofCalldata(\n        bytes32[] calldata proof,\n        bool[] calldata proofFlags,\n        bytes32[] memory leaves\n    ) internal pure returns (bytes32 merkleRoot)",
        "start_line": "165",
        "end_line": "214",
        "file_path": "contracts/utils/cryptography/MerkleProof.sol",
        "docstring": "The function processMultiProofCalldata calculates the Merkle root from a set of leaves and proof nodes using a multi-proof verification method.\\nIt takes three inputs: proof (calldata bytes32 array), proofFlags (calldata bool array), and leaves (memory bytes32 array).\\nFirst, it checks the validity of the proof by ensuring that the sum of leaves and proof lengths equals the total hashes plus one.\\nIf the check fails, it reverts with MerkleProofInvalidMultiproof.\\nIt initializes arrays and positions for leaves, hashes, and proof.\\nIt iterates through totalHashes, combining leaves and proofs based on proofFlags, and computes commutative Keccak-256 hashes to store in the hashes array.\\nAfter processing, it verifies the proof position.\\nIf there are total hashes, it returns the last hash; otherwise, it returns the first leaf or proof node based on the input lengths.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "112091b51442",
        "ground_truth": "function processMultiProofCalldata(\n    bytes32[] calldata proof,\n    bool[] calldata proofFlags,\n    bytes32[] memory leaves\n) internal pure returns (bytes32 merkleRoot) {\n    // This function rebuilds the root hash by traversing the tree up from the leaves. The root is rebuilt by\n    // consuming and producing values on a queue. The queue starts with the `leaves` array, then goes onto the\n    // `hashes` array. At the end of the process, the last hash in the `hashes` array should contain the root of\n    // the Merkle tree.\n    uint256 leavesLen = leaves.length;\n    uint256 proofLen = proof.length;\n    uint256 totalHashes = proofFlags.length;\n    // Check proof validity.\n    if (leavesLen + proofLen != totalHashes + 1) {\n        revert MerkleProofInvalidMultiproof();\n    }\n    // The xxxPos values are \"pointers\" to the next value to consume in each array. All accesses are done using\n    // `xxx[xxxPos++]`, which return the current value and increment the pointer, thus mimicking a queue's \"pop\".\n    bytes32[] memory hashes = new bytes32[](totalHashes);\n    uint256 leafPos = 0;\n    uint256 hashPos = 0;\n    uint256 proofPos = 0;\n    // At each step, we compute the next hash using two values:\n    // - a value from the \"main queue\". If not all leaves have been consumed, we get the next leaf, otherwise we\n    //   get the next hash.\n    // - depending on the flag, either another value from the \"main queue\" (merging branches) or an element from the\n    //   `proof` array.\n    for (uint256 i = 0; i < totalHashes; i++) {\n        bytes32 a = leafPos < leavesLen ? leaves[leafPos++] : hashes[hashPos++];\n        bytes32 b = proofFlags[i]\n            ? (leafPos < leavesLen ? leaves[leafPos++] : hashes[hashPos++])\n            : proof[proofPos++];\n        hashes[i] = Hashes.commutativeKeccak256(a, b);\n    }\n    if (totalHashes > 0) {\n        if (proofPos != proofLen) {\n            revert MerkleProofInvalidMultiproof();\n        }\n        unchecked {\n            return hashes[totalHashes - 1];\n        }\n    } else if (leavesLen > 0) {\n        return leaves[0];\n    } else {\n        return proof[0];\n    }\n}",
        "import_statements": [
            "import {Hashes} from \"./Hashes.sol\";"
        ],
        "reference_api": [
            "new bytes32[]",
            "Hashes.commutativeKeccak256"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "Hashes.commutativeKeccak256",
                "code": "function commutativeKeccak256(bytes32 a, bytes32 b) internal pure returns (bytes32) {\n    return a < b ? _efficientKeccak256(a, b) : _efficientKeccak256(b, a);\n}"
            }
        ],
        "third_party": [
            "new bytes32[]",
            "Hashes.commutativeKeccak256"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function functionCallWithValue(address target, bytes memory data, uint256 value) internal returns (bytes memory)",
        "start_line": "75",
        "end_line": "81",
        "file_path": "contracts/utils/Address.sol",
        "docstring": "The function functionCallWithValue performs a low-level call to a target address with specified data and value in wei.\\nIt first checks if the contract's balance is sufficient for the call.\\nIf the balance is insufficient, it reverts with an InsufficientBalance error, providing the current balance and the required value.\\nIt then executes the call to the target address with the provided value and data.\\nThe result of the call (success and returndata) is passed to verifyCallResultFromTarget, which verifies and returns the result of the call.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c1da233eaa27",
        "ground_truth": "function functionCallWithValue(address target, bytes memory data, uint256 value) internal returns (bytes memory) {\n    if (address(this).balance < value) {\n        revert Errors.InsufficientBalance(address(this).balance, value);\n    }\n    (bool success, bytes memory returndata) = target.call{value: value}(data);\n    return verifyCallResultFromTarget(target, success, returndata);\n}",
        "import_statements": [
            "import {Errors} from \"./Errors.sol\";"
        ],
        "reference_api": [
            "target.call{value: value}",
            "verifyCallResultFromTarget"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "target.call{value: value}",
            "verifyCallResultFromTarget"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function _revert(bytes memory returndata) private pure ",
        "start_line": "138",
        "end_line": "150",
        "file_path": "contracts/utils/Address.sol",
        "docstring": "The function _revert handles reverting a transaction with an optional revert reason.\\nIt checks if the returndata has a length greater than 0.\\nIf so, it uses Solidity's assembly to read the returndata length and revert the transaction with the provided reason.\\nIf returndata is empty, it reverts with a generic Errors.FailedCall() message.\\nThis function ensures that if an error message is present, it is properly bubbled up; otherwise, it provides a default error.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "d67cb7249849",
        "ground_truth": "function _revert(bytes memory returndata) private pure {\n    // Look for revert reason and bubble it up if present\n    if (returndata.length > 0) {\n        // The easiest way to bubble the revert reason is using memory via assembly\n        /// @solidity memory-safe-assembly\n        assembly {\n            let returndata_size := mload(returndata)\n            revert(add(32, returndata), returndata_size)\n        }\n    } else {\n        revert Errors.FailedCall();\n    }\n}",
        "import_statements": [
            "import {Errors} from \"./Errors.sol\";"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function toShortStringWithFallback(string memory value, string storage store) internal returns (ShortString)",
        "start_line": "89",
        "end_line": "96",
        "file_path": "contracts/utils/ShortStrings.sol",
        "docstring": "The function toShortStringWithFallback checks the length of a given string value and decides how to store it.\\nIf the string length is less than 32 bytes, it converts and returns it as a ShortString using toShortString.\\nIf the string length is 32 bytes or more, it stores the string in the provided storage slot and returns a wrapped FALLBACK_SENTINEL to indicate the use of a fallback storage mechanism.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1a1be4439d5b",
        "ground_truth": "function toShortStringWithFallback(string memory value, string storage store) internal returns (ShortString) {\n    if (bytes(value).length < 32) {\n        return toShortString(value);\n    } else {\n        StorageSlot.getStringSlot(store).value = value;\n        return ShortString.wrap(FALLBACK_SENTINEL);\n    }\n}",
        "import_statements": [
            "import {StorageSlot} from \"./StorageSlot.sol\";"
        ],
        "reference_api": [
            "toShortString",
            "ShortString.wrap",
            "StorageSlot.getStringSlot"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "toShortString",
                "code": "function toShortString(string memory str) internal pure returns (ShortString) {\n    bytes memory bstr = bytes(str);\n    if (bstr.length > 31) {\n        revert StringTooLong(str);\n    }\n    return ShortString.wrap(bytes32(uint256(bytes32(bstr)) | bstr.length));\n}"
            },
            {
                "name": "StorageSlot.getStringSlot",
                "code": "function getStringSlot(bytes32 slot) internal pure returns (StringSlot storage r) {\n    assembly (\"memory-safe\") {\n        r.slot := slot\n    }\n}"
            }
        ],
        "third_party": [
            "toShortString",
            "ShortString.wrap",
            "StorageSlot.getStringSlot"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "OpenZeppelin/openzeppelin-contracts",
        "function_declaration": "function toChecksumHexString(address addr) internal pure returns (string memory)",
        "start_line": "92",
        "end_line": "110",
        "file_path": "contracts/utils/Strings.sol",
        "docstring": "The function toChecksumHexString converts an Ethereum address to a checksummed hexadecimal string.\\nIt takes an address as input and returns a checksummed hexadecimal string.\\nFirst, it converts the address to a hex string and stores it in a bytes buffer.\\nThen, it computes the Keccak-256 hash of the hex part of the buffer, skipping the length and '0x' prefix.\\nIt iterates over the hex characters, starting from the end of the buffer.\\nFor each character, if the corresponding nibble in the hash is greater than 7 and the character is a lowercase letter (a-f), it converts the character to uppercase by XORing it with 0x20.\\nFinally, it returns the modified buffer as a string.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "28e9af392cd0",
        "ground_truth": "function toChecksumHexString(address addr) internal pure returns (string memory) {\n    bytes memory buffer = bytes(toHexString(addr));\n    // hash the hex part of buffer (skip length + 2 bytes, length 40)\n    uint256 hashValue;\n    assembly (\"memory-safe\") {\n        hashValue := shr(96, keccak256(add(buffer, 0x22), 40))\n    }\n    for (uint256 i = 41; i > 1; --i) {\n        // possible values for buffer[i] are 48 (0) to 57 (9) and 97 (a) to 102 (f)\n        if (hashValue & 0xf > 7 && uint8(buffer[i]) > 96) {\n            // case shift by xoring with 0x20\n            buffer[i] ^= 0x20;\n        }\n        hashValue >>= 4;\n    }\n    return string(buffer);\n}",
        "import_statements": [
            "import {Math} from \"./math/Math.sol\";",
            "import {SignedMath} from \"./math/SignedMath.sol\";"
        ],
        "reference_api": [
            "toHexString"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "toHexString",
                "code": "function toHexString(uint256 value, uint256 length) internal pure returns (string memory) {\n    uint256 localValue = value;\n    bytes memory buffer = new bytes(2 * length + 2);\n    buffer[0] = \"0\";\n    buffer[1] = \"x\";\n    for (uint256 i = 2 * length + 1; i > 1; --i) {\n        buffer[i] = HEX_DIGITS[localValue & 0xf];\n        localValue >>= 4;\n    }\n    if (localValue != 0) {\n        revert StringsInsufficientHexLength(value, length);\n    }\n    return string(buffer);\n}"
            }
        ],
        "third_party": [
            "toHexString"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "const skipSection = (section: string, unreleasedSection: string[]): string[] =>",
        "start_line": "37",
        "end_line": "48",
        "file_path": "scripts/changelog/src/sync.ts",
        "docstring": "The function skipSection removes a specified section and its subsequent content from an array of unreleased sections.\\nIt takes a section name and an array of unreleased sections as inputs.\\nIt finds the index of the specified section in the array.\\nIf the section is found, it searches for the next section header that starts with '###' after the specified section.\\nIf the next section header is found, it removes all elements between the specified section and the next section header from the array.\\nFinally, it returns the modified array of unreleased sections.",
        "language": "TypeScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ee28c6aacbd6",
        "ground_truth": "const skipSection = (section: string, unreleasedSection: string[]): string[] => {\n const index = unreleasedSection.indexOf(section);\n if (index !== -1) {\n  const nextSectionIndex = unreleasedSection.findIndex(\n   (el, i) => el.startsWith('###') && i > index,\n  );\n  if (nextSectionIndex !== -1) {\n   unreleasedSection.splice(index, nextSectionIndex - index);\n  }\n }\n return unreleasedSection;\n};",
        "import_statements": [
            "import { readFileSync, writeFileSync } from 'fs';",
            "{ readFileSync, writeFileSync }",
            "{ readFileSync, writeFileSync }",
            "readFileSync",
            "writeFileSync",
            "import {\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n} from './types';",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "ChangelogConfig",
            "DEFAULT_CHANGELOG_CONFIG",
            "ENTRY_SECTION_HEADERS",
            "GroupedUnreleasedEntries",
            "import { getListOfPackageNames } from './helpers';",
            "{ getListOfPackageNames }",
            "{ getListOfPackageNames }",
            "getListOfPackageNames"
        ],
        "reference_api": [
            "el.startsWith"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "el.startsWith",
                "code": "p"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "export const flattenSyncedUnreleasedEntries = (\n\tsyncedGroupedUnreleasedEntries: GroupedUnreleasedEntries,\n\tlistOfPackageNames: string[],\n) =>",
        "start_line": "134",
        "end_line": "156",
        "file_path": "scripts/changelog/src/sync.ts",
        "docstring": "The function flattenSyncedUnreleasedEntries flattens a nested structure of grouped unreleased entries into a single list of strings.\\nIt takes two arguments: syncedGroupedUnreleasedEntries, which is an object containing grouped entries, and listOfPackageNames, which is a list of package names.\\nThe function initializes an empty array flattenedSyncedUnreleasedEntries.\\nIt iterates over the keys of syncedGroupedUnreleasedEntries, adding each key to the flattened list followed by an empty string.\\nFor each key, it iterates over listOfPackageNames, formatting each package name as a header.\\nIf the header exists in the current element, it adds the header, an empty string, the associated entries, and another empty string to the flattened list.\\nThe function returns the flattened list of strings.\n",
        "language": "TypeScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "298789db9f1c",
        "ground_truth": "export const flattenSyncedUnreleasedEntries = (\n syncedGroupedUnreleasedEntries: GroupedUnreleasedEntries,\n listOfPackageNames: string[],\n) => {\n const flattenedSyncedUnreleasedEntries: string[] = [];\n for (const key of Object.keys(syncedGroupedUnreleasedEntries)) {\n  const element = syncedGroupedUnreleasedEntries[key];\n  flattenedSyncedUnreleasedEntries.push(key);\n  flattenedSyncedUnreleasedEntries.push('');\n  for (const packageName of listOfPackageNames) {\n   const formattedPackageEntryHeader = `#### ${packageName}`;\n   const element2 = element[formattedPackageEntryHeader];\n   if (element[formattedPackageEntryHeader] !== undefined) {\n    flattenedSyncedUnreleasedEntries.push(formattedPackageEntryHeader);\n    flattenedSyncedUnreleasedEntries.push('');\n    flattenedSyncedUnreleasedEntries.push(...element2);\n    flattenedSyncedUnreleasedEntries.push('');\n   }\n  }\n }\n  return flattenedSyncedUnreleasedEntries;\n};",
        "import_statements": [
            "import { readFileSync, writeFileSync } from 'fs';",
            "{ readFileSync, writeFileSync }",
            "{ readFileSync, writeFileSync }",
            "readFileSync",
            "writeFileSync",
            "import {\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n} from './types';",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "ChangelogConfig",
            "DEFAULT_CHANGELOG_CONFIG",
            "ENTRY_SECTION_HEADERS",
            "GroupedUnreleasedEntries",
            "import { getListOfPackageNames } from './helpers';",
            "{ getListOfPackageNames }",
            "{ getListOfPackageNames }",
            "getListOfPackageNames"
        ],
        "reference_api": [
            "flattenedSyncedUnreleasedEntries.push",
            "Object.keys"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "flattenedSyncedUnreleasedEntries.push",
                "code": "p"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "export const syncChangelogs = (commandName: string, args?: string[]) =>",
        "start_line": "159",
        "end_line": "184",
        "file_path": "scripts/changelog/src/sync.ts",
        "docstring": "The function syncChangelogs synchronizes changelog entries across different packages.\\nIt takes a command name and optional arguments as input.\\nIf the first argument ends with '.json', it parses it as the changelog configuration; otherwise, it uses the default configuration.\\nIt reads the root changelog file specified in the configuration and splits it into lines.\\nIt retrieves a list of package names from the specified packages directory path.\\nIt then gets and synchronizes grouped unreleased entries from the root changelog and the individual package changelogs.\\nThe synchronized entries are flattened and inserted into the root changelog, replacing the existing unreleased section.\\nFinally, the updated root changelog is written back to the file.\n",
        "language": "TypeScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ce6475a080b8",
        "ground_truth": "export const syncChangelogs = (commandName: string, args?: string[]) => {\n const CHANGELOG_CONFIG: ChangelogConfig =\n  args?.[0] !== undefined && args[0].endsWith('.json')\n   ? (JSON.parse(readFileSync(args[0], 'utf8')) as ChangelogConfig)\n   : DEFAULT_CHANGELOG_CONFIG;\n const parsedRootChangelog = readFileSync(CHANGELOG_CONFIG.rootChangelogPath, 'utf8').split(\n  /\\n/,\n );\n const listOfPackageNames = getListOfPackageNames(CHANGELOG_CONFIG.packagesDirectoryPath);\n const syncedGroupedUnreleasedEntries = getSyncedGroupedUnreleasedEntries(\n  listOfPackageNames,\n  CHANGELOG_CONFIG,\n  getRootGroupedUnreleasedEntries(getUnreleasedSection(parsedRootChangelog)),\n );\n const flattenedSyncedUnreleasedEntries = flattenSyncedUnreleasedEntries(\n  syncedGroupedUnreleasedEntries,\n  listOfPackageNames,\n );\n  // +2 is so the header, ## [Unreleased], and the newline after it don't get removed\n parsedRootChangelog.splice(\n  parsedRootChangelog.findIndex(item => item === '## [Unreleased]') + 2,\n );\n parsedRootChangelog.push(...flattenedSyncedUnreleasedEntries);\n writeFileSync(CHANGELOG_CONFIG.rootChangelogPath, parsedRootChangelog.join('\\n'));\n};",
        "import_statements": [
            "import { readFileSync, writeFileSync } from 'fs';",
            "{ readFileSync, writeFileSync }",
            "{ readFileSync, writeFileSync }",
            "readFileSync",
            "writeFileSync",
            "import {\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n} from './types';",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "{\n\tChangelogConfig,\n\tDEFAULT_CHANGELOG_CONFIG,\n\tENTRY_SECTION_HEADERS,\n\tGroupedUnreleasedEntries,\n}",
            "ChangelogConfig",
            "DEFAULT_CHANGELOG_CONFIG",
            "ENTRY_SECTION_HEADERS",
            "GroupedUnreleasedEntries",
            "import { getListOfPackageNames } from './helpers';",
            "{ getListOfPackageNames }",
            "{ getListOfPackageNames }",
            "getListOfPackageNames"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "function postProcessClassesDocs(configOptions)",
        "start_line": "24",
        "end_line": "43",
        "file_path": "scripts/docshelper/generatedoc.js",
        "docstring": "The function postProcessClassesDocs processes documentation files after they are generated.\\nIt takes a configOptions object as input.\\nFirst, it constructs the path to the classes directory based on the output directory specified in configOptions.out.\\nIt copies the contents of the classes directory to the output directory using copyDir, then cleans the classes directory using cleanDir.\\nIt tries to read all files in the output directory.\\nFor each file, it reads the file's content, replaces all occurrences of \".md\" with an empty string, and writes the modified content back to the file.\\nIf an error occurs while reading the directory, it logs an error message to the console.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "55672096f549",
        "ground_truth": "function postProcessClassesDocs(configOptions) {\n   const packagesPath = configOptions.out + '/classes/';\n   copyDir(packagesPath, configOptions.out);\n  cleanDir(packagesPath);\n   try {\n    const files = fs.readdirSync(configOptions.out);\n    files.forEach(function (file) {\n      const filePath = path.join(configOptions.out, file);\n      const data = fs.readFileSync(filePath, 'utf8');\n      const replacedData = data.replace(/\\.md/g, '');\n      fs.writeFileSync(filePath, replacedData, 'utf8');\n    });\n  } catch (err) {\n    console.log('Error getting directory information.');\n  }\n }",
        "import_statements": [],
        "reference_api": [
            "fs.writeFileSync",
            "console.log",
            "fs.readFileSync",
            "fs.readdirSync",
            "cleanDir",
            "data.replace",
            "files.forEach",
            "copyDir",
            "path.join"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "cleanDir",
                "code": "function cleanDir(dirPath) {\n  // Check if the directory exists\n  if (fs.existsSync(dirPath)) {\n    // Get all the files and subdirectories in the directory\n    const files = fs.readdirSync(dirPath);\n\n    // Loop through all the files and subdirectories\n    for (let file of files) {\n      // Get the full path of the file or subdirectory\n      const filePath = path.join(dirPath, file);\n\n      // Check if it's a file or a subdirectory\n      const stats = fs.statSync(filePath);\n      if (stats.isFile()) {\n        // If it's a file, delete it\n        fs.unlinkSync(filePath);\n      } else {\n        // If it's a subdirectory, recursively delete it\n        cleanDir(filePath);\n      }\n    }\n\n    // Finally, delete the directory itself\n    fs.rmdirSync(dirPath);\n  }\n}"
            },
            {
                "name": "copyDir",
                "code": "function copyDir(src, dest) {\n  // Create the destination folder if it doesn't exist\n  if (!fs.existsSync(dest)) {\n    fs.mkdirSync(dest);\n  }\n\n  // Read the source directory\n  const files = fs.readdirSync(src);\n\n  // Loop through all the files in the source directory\n  for (let file of files) {\n    // Get the full path of the file\n    const srcPath = path.join(src, file);\n    const destPath = path.join(dest, file);\n\n    // Get the file's stats\n    const stats = fs.statSync(srcPath);\n\n    // If the file is a directory, recursively copy it\n    if (stats.isDirectory()) {\n      copyDir(srcPath, destPath);\n    } else {\n      // If the file is a file, copy it\n      fs.copyFileSync(srcPath, destPath);\n    }\n  }\n}"
            }
        ],
        "third_party": [
            "fs.writeFileSync",
            "fs.readFileSync",
            "fs.readdirSync",
            "data.replace",
            "files.forEach",
            "path.join"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "function copyDir(src, dest)",
        "start_line": "76",
        "end_line": "102",
        "file_path": "scripts/docshelper/generatedoc.js",
        "docstring": "The function copyDir copies all files and subdirectories from a source directory to a destination directory.\\nFirst, it checks if the destination directory exists and creates it if it doesn't.\\nIt then reads the contents of the source directory and iterates over each file and subdirectory.\\nFor each item, it constructs the full source and destination paths and retrieves the item's stats.\\nIf the item is a directory, it recursively calls copyDir to copy the directory and its contents.\\nIf the item is a file, it copies the file to the destination path using fs.copyFileSync.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7bccb6aa7716",
        "ground_truth": "function copyDir(src, dest) {\n  // Create the destination folder if it doesn't exist\n  if (!fs.existsSync(dest)) {\n    fs.mkdirSync(dest);\n  }\n   // Read the source directory\n  const files = fs.readdirSync(src);\n   // Loop through all the files in the source directory\n  for (let file of files) {\n    // Get the full path of the file\n    const srcPath = path.join(src, file);\n    const destPath = path.join(dest, file);\n     // Get the file's stats\n    const stats = fs.statSync(srcPath);\n     // If the file is a directory, recursively copy it\n    if (stats.isDirectory()) {\n      copyDir(srcPath, destPath);\n    } else {\n      // If the file is a file, copy it\n      fs.copyFileSync(srcPath, destPath);\n    }\n  }\n}",
        "import_statements": [],
        "reference_api": [
            "fs.mkdirSync",
            "fs.readdirSync",
            "fs.statSync",
            "fs.existsSync",
            "copyDir",
            "stats.isDirectory",
            "fs.copyFileSync",
            "path.join"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "copyDir",
                "code": "function copyDir(src, dest) {\n  // Create the destination folder if it doesn't exist\n  if (!fs.existsSync(dest)) {\n    fs.mkdirSync(dest);\n  }\n\n  // Read the source directory\n  const files = fs.readdirSync(src);\n\n  // Loop through all the files in the source directory\n  for (let file of files) {\n    // Get the full path of the file\n    const srcPath = path.join(src, file);\n    const destPath = path.join(dest, file);\n\n    // Get the file's stats\n    const stats = fs.statSync(srcPath);\n\n    // If the file is a directory, recursively copy it\n    if (stats.isDirectory()) {\n      copyDir(srcPath, destPath);\n    } else {\n      // If the file is a file, copy it\n      fs.copyFileSync(srcPath, destPath);\n    }\n  }\n}"
            }
        ],
        "third_party": [
            "fs.mkdirSync",
            "fs.readdirSync",
            "fs.statSync",
            "fs.existsSync",
            "stats.isDirectory",
            "fs.copyFileSync",
            "path.join"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "web3/web3.js",
        "function_declaration": "const addAccount = async (address, privateKey) =>",
        "start_line": "15",
        "end_line": "40",
        "file_path": "scripts/gen_accounts.js",
        "docstring": "The async function addAccount adds a new account with a given address and private key to a web3 provider.\\nIt first retrieves the client URL using getSystemTestProvider().\\nIt creates a new Personal instance with the client URL to interact with the personal API.\\nIf accountList is empty, it fetches the existing accounts and sets the first account as mainAcc.\\nIt then creates a new Web3Eth instance with the client URL to interact with the Ethereum API.\\nIf the account with the specified address is not already in accountList, it imports the raw private key using web3Personal.importRawKey, adjusting the key format based on the backend.\\nFinally, it sends a transaction from mainAcc to the new account with a gas limit of 1,500,000 and a value of 1 ETH.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "af52461cb246",
        "ground_truth": "const addAccount = async (address, privateKey) => {\n let clientUrl = getSystemTestProvider();\n  const web3Personal = new Personal(clientUrl);\n if (accountList.length === 0) {\n  accountList = await web3Personal.getAccounts();\n  mainAcc = accountList[0];\n }\n const web3Eth = new Web3Eth(clientUrl);\n  if (!accountList.find(acc => acc.address === address)) {\n  await web3Personal.importRawKey(\n   ['geth', 'geth-manual'].includes(getSystemTestBackend())\n    ? privateKey.slice(2)\n    : privateKey,\n   '123456',\n  );\n }\n  await web3Eth.sendTransaction({\n  from: mainAcc,\n  to: address,\n  gas: 1500000,\n  value: '1000000000000000000',\n });\n};",
        "import_statements": [],
        "reference_api": [
            "['geth', 'geth-manual'].includes",
            "web3Personal.importRawKey",
            "web3Eth.sendTransaction",
            "getSystemTestProvider",
            "getSystemTestBackend",
            "web3Personal.getAccounts",
            "accountList.find",
            "privateKey.slice"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "['geth', 'geth-manual'].includes",
            "web3Personal.importRawKey",
            "web3Eth.sendTransaction",
            "getSystemTestProvider",
            "getSystemTestBackend",
            "web3Personal.getAccounts",
            "accountList.find",
            "privateKey.slice"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _verifyProof(HydraS1ProofData memory proofData) internal view virtual",
        "start_line": "167",
        "end_line": "179",
        "file_path": "contracts/attesters/hydra-s1/base/HydraS1Base.sol",
        "docstring": "The function _verifyProof verifies a Groth16 proof using the provided HydraS1ProofData.\\nIt calls the VERIFIER.verifyProof method with the proof and input data from proofData.\\nIf the verification is successful, the function does nothing.\\nIf the verification fails, it reverts the transaction with an InvalidGroth16Proof error.\\nIt catches various types of errors, including Error, Panic, and low-level errors, and reverts with the InvalidGroth16Proof error in each case.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "0998d3c4ec18",
        "ground_truth": "function _verifyProof(HydraS1ProofData memory proofData) internal view virtual {\n  try\n    VERIFIER.verifyProof(proofData.proof.a, proofData.proof.b, proofData.proof.c, proofData.input)\n  returns (bool success) {\n    if (!success) revert InvalidGroth16Proof('');\n  } catch Error(string memory reason) {\n    revert InvalidGroth16Proof(reason);\n  } catch Panic(uint256 /*errorCode*/) {\n    revert InvalidGroth16Proof('');\n  } catch (bytes memory /*lowLevelData*/) {\n    revert InvalidGroth16Proof('');\n  }\n}",
        "import_statements": [
            "import {IHydraS1Base} from './IHydraS1Base.sol';",
            "import {Attester} from '../../../core/Attester.sol';",
            "import {Initializable} from '@openzeppelin/contracts/proxy/utils/Initializable.sol';",
            "import {Request, Attestation, Claim} from '../../../core/libs/Structs.sol';",
            "import {HydraS1Verifier, HydraS1Lib, HydraS1Claim, HydraS1ProofData, HydraS1ProofInput, HydraS1GroupProperties} from '../libs/HydraS1Lib.sol';",
            "import {ICommitmentMapperRegistry} from '../../../periphery/utils/CommitmentMapperRegistry.sol';",
            "import {IAvailableRootsRegistry} from '../../../periphery/utils/AvailableRootsRegistry.sol';"
        ],
        "reference_api": [
            "VERIFIER.verifyProof"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "VERIFIER.verifyProof"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _hydraS1claim(Request memory self) internal pure returns (HydraS1Claim memory) ",
        "start_line": "25",
        "end_line": "43",
        "file_path": "contracts/attesters/hydra-s1/libs/HydraS1AccountboundLib.sol",
        "docstring": "The function _hydraS1claim extracts and processes a claim from a given Request struct.\\nIt takes a Request struct as input and returns a HydraS1Claim struct.\\nFirst, it retrieves the first claim from the self.claims array and validates it using the _validateClaim function.\\nIt then decodes the extraData field of the claim into a HydraS1AccountboundGroupProperties struct.\\nIt creates a HydraS1GroupProperties struct using the decoded data, including groupIndex, generationTimestamp, and isScore.\\nFinally, it returns a HydraS1Claim struct containing the claim's groupId, claimedValue, the destination from the Request, and the constructed HydraS1GroupProperties.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a3eed2073089",
        "ground_truth": "function _hydraS1claim(Request memory self) internal pure returns (HydraS1Claim memory) {\n  Claim memory claim = self.claims[0];\n  _validateClaim(claim);\n  HydraS1AccountboundGroupProperties memory groupProperties = abi.decode(\n    claim.extraData,\n    (HydraS1AccountboundGroupProperties)\n  );\n  HydraS1GroupProperties memory hydraS1GroupProperties = HydraS1GroupProperties(\n    groupProperties.groupIndex,\n    groupProperties.generationTimestamp,\n    groupProperties.isScore\n  );\n  return (\n    HydraS1Claim(claim.groupId, claim.claimedValue, self.destination, hydraS1GroupProperties)\n  );\n}",
        "import_statements": [
            "import {Claim, Request} from '../../../core/libs/Structs.sol';",
            "import {HydraS1Lib, HydraS1Claim, HydraS1GroupProperties} from './HydraS1Lib.sol';"
        ],
        "reference_api": [
            "HydraS1Claim",
            "abi.decode",
            "_validateClaim",
            "HydraS1GroupProperties"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "HydraS1Claim",
            "abi.decode",
            "_validateClaim",
            "HydraS1GroupProperties"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _validateClaim(Claim memory claim) internal pure",
        "start_line": "72",
        "end_line": "76",
        "file_path": "contracts/attesters/hydra-s1/libs/HydraS1AccountboundLib.sol",
        "docstring": "The function _validateClaim is an internal pure function that validates a claim by comparing its groupId with an expected groupId.\\nIt takes a Claim struct as input and generates an expectedGroupId using the _generateGroupIdFromEncodedProperties function on claim.extraData.\\nIf the claim's groupId does not match the expectedGroupId, it reverts the transaction with a GroupIdAndPropertiesMismatch error, providing the expected and actual groupIds.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "9df6ed838b09",
        "ground_truth": "function _validateClaim(Claim memory claim) internal pure {\n  uint256 expectedGroupId = _generateGroupIdFromEncodedProperties(claim.extraData);\n  if (claim.groupId != expectedGroupId)\n    revert GroupIdAndPropertiesMismatch(expectedGroupId, claim.groupId);\n}",
        "import_statements": [
            "import {Claim, Request} from '../../../core/libs/Structs.sol';",
            "import {HydraS1Lib, HydraS1Claim, HydraS1GroupProperties} from './HydraS1Lib.sol';"
        ],
        "reference_api": [
            "_generateGroupIdFromEncodedProperties"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_generateGroupIdFromEncodedProperties"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _claim(Request memory self) internal pure returns (HydraS1Claim memory) ",
        "start_line": "75",
        "end_line": "85",
        "file_path": "contracts/attesters/hydra-s1/libs/HydraS1Lib.sol",
        "docstring": "The _claim function processes and returns a HydraS1Claim structure from a given Request structure.\\nIt extracts the first claim from the request's claims array and validates it using _validateClaim.\\nIt decodes the claim's extraData field into a HydraS1GroupProperties structure using abi.decode.\\nIt constructs and returns a HydraS1Claim structure with the claim's groupId, claimedValue, the request's destination, and the decoded groupProperties.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "7494582596e7",
        "ground_truth": "function _claim(Request memory self) internal pure returns (HydraS1Claim memory) {\n  Claim memory claim = self.claims[0];\n  _validateClaim(claim);\n  HydraS1GroupProperties memory groupProperties = abi.decode(\n    claim.extraData,\n    (HydraS1GroupProperties)\n  );\n  return (HydraS1Claim(claim.groupId, claim.claimedValue, self.destination, groupProperties));\n}",
        "import_statements": [
            "import {Claim, Request} from '../../../core/libs/Structs.sol';",
            "import {HydraS1Verifier} from '@sismo-core/hydra-s1/contracts/HydraS1Verifier.sol';"
        ],
        "reference_api": [
            "HydraS1Claim",
            "abi.decode",
            "_validateClaim"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "HydraS1Claim",
            "abi.decode",
            "_validateClaim"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _beforeRecordAttestations(\n    Request calldata request,\n    bytes calldata proofData\n  ) internal virtual override",
        "start_line": "176",
        "end_line": "210",
        "file_path": "contracts/attesters/hydra-s1/HydraS1AccountboundAttester.sol",
        "docstring": "The _claim function processes and returns a HydraS1Claim structure from a given Request structure.\\nIt extracts the first claim from the request's claims array and validates it using _validateClaim.\\nIt decodes the claim's extraData field into a HydraS1GroupProperties structure using abi.decode.\\nIt constructs and returns a HydraS1Claim structure with the claim's groupId, claimedValue, the request's destination, and the decoded groupProperties.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "2d729a5eaf79",
        "ground_truth": "function _beforeRecordAttestations(\n  Request calldata request,\n  bytes calldata proofData\n) internal virtual override {\n  uint256 nullifier = proofData._getNullifier();\n  address previousNullifierDestination = _getDestinationOfNullifier(nullifier);\n  HydraS1Claim memory claim = request._claim();\n  // check if the nullifier has already been used previously, if so it may be on cooldown\n  if (\n    previousNullifierDestination != address(0) &&\n    previousNullifierDestination != claim.destination\n  ) {\n    uint32 cooldownDuration = _getCooldownDurationForGroupIndex(claim.groupProperties.groupIndex);\n    if (cooldownDuration == 0) {\n      revert CooldownDurationNotSetForGroupIndex(claim.groupProperties.groupIndex);\n    }\n    if (_isOnCooldown(nullifier, cooldownDuration)) {\n      uint16 burnCount = _getNullifierBurnCount(nullifier);\n      revert NullifierOnCooldown(\n        nullifier,\n        previousNullifierDestination,\n        burnCount,\n        cooldownDuration\n      );\n    }\n    // Delete the old Attestation linked to the nullifier before recording the new one (accountbound feature)\n    _deletePreviousAttestation(claim, previousNullifierDestination);\n    _setNullifierOnCooldownAndIncrementBurnCount(nullifier);\n  }\n  _setDestinationForNullifier(nullifier, request.destination);\n}",
        "import_statements": [
            "import {Ownable} from '@openzeppelin/contracts/access/Ownable.sol';",
            "import {IHydraS1AccountboundAttester} from './interfaces/IHydraS1AccountboundAttester.sol';",
            "import {Request, Attestation, Claim} from '../../core/libs/Structs.sol';",
            "import {HydraS1SimpleAttester, IAttester, HydraS1Lib, HydraS1ProofData, HydraS1Claim} from './HydraS1SimpleAttester.sol';"
        ],
        "reference_api": [
            "_deletePreviousAttestation",
            "_setDestinationForNullifier",
            "request._claim",
            "_getNullifierBurnCount",
            "_setNullifierOnCooldownAndIncrementBurnCount",
            "_getDestinationOfNullifier",
            "_getCooldownDurationForGroupIndex",
            "_isOnCooldown",
            "proofData._getNullifier"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_deletePreviousAttestation",
            "_setDestinationForNullifier",
            "request._claim",
            "_getNullifierBurnCount",
            "_setNullifierOnCooldownAndIncrementBurnCount",
            "_getDestinationOfNullifier",
            "_getCooldownDurationForGroupIndex",
            "_isOnCooldown",
            "proofData._getNullifier"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _deletePreviousAttestation(\n    HydraS1Claim memory claim,\n    address previousNullifierDestination\n  ) internal",
        "start_line": "269",
        "end_line": "280",
        "file_path": "contracts/attesters/hydra-s1/HydraS1AccountboundAttester.sol",
        "docstring": "The function _deletePreviousAttestation deletes a previous attestation from the attestation registry based on a given HydraS1Claim.\\nIt takes a claim and a previous nullifier destination address as inputs.\\nIt initializes two arrays, attestationOwners and attestationCollectionIds, each with one element.\\nIt sets the first element of attestationOwners to the previous nullifier destination address.\\nIt sets the first element of attestationCollectionIds to a value derived from the AUTHORIZED_COLLECTION_ID_FIRST constant and the group index from the claim's groupProperties.\\nFinally, it calls deleteAttestations on the ATTESTATIONS_REGISTRY with the prepared arrays to remove the specified attestation.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "cb503dc88b7d",
        "ground_truth": "function _deletePreviousAttestation(\n  HydraS1Claim memory claim,\n  address previousNullifierDestination\n) internal {\n  address[] memory attestationOwners = new address[](1);\n  uint256[] memory attestationCollectionIds = new uint256[](1);\n  attestationOwners[0] = previousNullifierDestination;\n  attestationCollectionIds[0] = AUTHORIZED_COLLECTION_ID_FIRST + claim.groupProperties.groupIndex;\n  ATTESTATIONS_REGISTRY.deleteAttestations(attestationOwners, attestationCollectionIds);\n}",
        "import_statements": [
            "import {Ownable} from '@openzeppelin/contracts/access/Ownable.sol';",
            "import {IHydraS1AccountboundAttester} from './interfaces/IHydraS1AccountboundAttester.sol';",
            "import {Request, Attestation, Claim} from '../../core/libs/Structs.sol';",
            "import {HydraS1SimpleAttester, IAttester, HydraS1Lib, HydraS1ProofData, HydraS1Claim} from './HydraS1SimpleAttester.sol';"
        ],
        "reference_api": [
            "new uint256[]",
            "ATTESTATIONS_REGISTRY.deleteAttestations",
            "new address[]"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "new uint256[]",
            "ATTESTATIONS_REGISTRY.deleteAttestations",
            "new address[]"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _getNextBurnCount(\n    uint256 nullifier,\n    address claimDestination\n  ) public view virtual returns (uint16)",
        "start_line": "301",
        "end_line": "315",
        "file_path": "contracts/attesters/hydra-s1/HydraS1AccountboundAttester.sol",
        "docstring": "The function _getNextBurnCount calculates the next burn count for a given nullifier and claim destination.\\nIt first retrieves the previous destination address associated with the nullifier using _getDestinationOfNullifier(nullifier).\\nIt then gets the current burn count of the nullifier using _getNullifierBurnCount(nullifier).\\nIf the previous nullifier destination is not the zero address and differs from the current claim destination, it increments the burn count by 1.\\nFinally, it returns the updated burn count.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "88ffeb335750",
        "ground_truth": "function _getNextBurnCount(\n  uint256 nullifier,\n  address claimDestination\n) public view virtual returns (uint16) {\n  address previousNullifierDestination = _getDestinationOfNullifier(nullifier);\n  uint16 burnCount = _getNullifierBurnCount(nullifier);\n  // If the attestation is minted on a new destination address\n  // the burnCount that will be encoded in the extraData of the Attestation should be incremented\n  if (\n    previousNullifierDestination != address(0) && previousNullifierDestination != claimDestination\n  ) {\n    burnCount += 1;\n  }\n  return burnCount;\n}",
        "import_statements": [
            "import {Ownable} from '@openzeppelin/contracts/access/Ownable.sol';",
            "import {IHydraS1AccountboundAttester} from './interfaces/IHydraS1AccountboundAttester.sol';",
            "import {Request, Attestation, Claim} from '../../core/libs/Structs.sol';",
            "import {HydraS1SimpleAttester, IAttester, HydraS1Lib, HydraS1ProofData, HydraS1Claim} from './HydraS1SimpleAttester.sol';"
        ],
        "reference_api": [
            "_getNullifierBurnCount",
            "_getDestinationOfNullifier"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_getNullifierBurnCount",
            "_getDestinationOfNullifier"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function recordAttestations(Attestation[] calldata attestations) external override whenNotPaused ",
        "start_line": "59",
        "end_line": "84",
        "file_path": "contracts/core/AttestationsRegistry.sol",
        "docstring": "The function recordAttestations records multiple attestations for a sender.\\nIt takes an array of Attestation structs as input and can only be called when the contract is not paused.\\nThe sender's address is retrieved using _msgSender().\\nFor each attestation in the array, it checks if the issuer is authorized for the given collectionId.\\nIf not authorized, it reverts with IssuerNotAuthorized.\\nIt retrieves the previous attestation value for the owner and collectionId, then updates the attestation data with the new values.\\nIt triggers a badge transfer event with the collectionId, owner, previous value, and new value, and emits an AttestationRecorded event with the attestation details.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "3814e3e6b11c",
        "ground_truth": "function recordAttestations(Attestation[] calldata attestations) external override whenNotPaused {\n  address issuer = _msgSender();\n  for (uint256 i = 0; i < attestations.length; i++) {\n    if (!_isAuthorized(issuer, attestations[i].collectionId))\n      revert IssuerNotAuthorized(issuer, attestations[i].collectionId);\n    uint256 previousAttestationValue = _attestationsData[attestations[i].collectionId][\n      attestations[i].owner\n    ].value;\n    _attestationsData[attestations[i].collectionId][attestations[i].owner] = AttestationData(\n      attestations[i].issuer,\n      attestations[i].value,\n      attestations[i].timestamp,\n      attestations[i].extraData\n    );\n    _triggerBadgeTransferEvent(\n      attestations[i].collectionId,\n      attestations[i].owner,\n      previousAttestationValue,\n      attestations[i].value\n    );\n    emit AttestationRecorded(attestations[i]);\n  }\n}",
        "import_statements": [
            "import {IAttestationsRegistry} from './interfaces/IAttestationsRegistry.sol';",
            "import {AttestationsRegistryConfigLogic} from './libs/attestations-registry/AttestationsRegistryConfigLogic.sol';",
            "import {AttestationsRegistryState} from './libs/attestations-registry/AttestationsRegistryState.sol';",
            "import {Range, RangeUtils} from './libs/utils/RangeLib.sol';",
            "import {Attestation, AttestationData} from './libs/Structs.sol';",
            "import {IBadges} from './interfaces/IBadges.sol';"
        ],
        "reference_api": [
            "_triggerBadgeTransferEvent",
            "_isAuthorized",
            "AttestationData",
            "_msgSender"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_triggerBadgeTransferEvent",
            "_isAuthorized",
            "AttestationData",
            "_msgSender"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function _triggerBadgeTransferEvent(\n    uint256 badgeTokenId,\n    address owner,\n    uint256 previousValue,\n    uint256 newValue\n  ) internal ",
        "start_line": "247",
        "end_line": "261",
        "file_path": "contracts/core/AttestationsRegistry.sol",
        "docstring": "The function _triggerBadgeTransferEvent triggers a badge transfer event based on the change in badge value.\\nIt takes the badge token ID, the owner's address, the previous value, and the new value as inputs.\\nIt determines if the new value is greater than the previous value, setting the operator to the current contract address.\\nIf the new value is greater, it sets the from address to zero and the to address to the owner, indicating a mint event.\\nIf the new value is less, it sets the from address to the owner and the to address to zero, indicating a burn event.\\nThe value of the event is the absolute difference between the new and previous values.\\nFinally, it calls BADGES.triggerTransferEvent with the appropriate parameters to trigger the event.\n",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "1e4ba430112c",
        "ground_truth": "function _triggerBadgeTransferEvent(\n  uint256 badgeTokenId,\n  address owner,\n  uint256 previousValue,\n  uint256 newValue\n) internal {\n  bool isGreaterValue = newValue > previousValue;\n  address operator = address(this);\n  address from = isGreaterValue ? address(0) : owner;\n  address to = isGreaterValue ? owner : address(0);\n  uint256 value = isGreaterValue ? newValue - previousValue : previousValue - newValue;\n  // if isGreaterValue is true, function triggers mint event. Otherwise triggers burn event.\n  BADGES.triggerTransferEvent(operator, from, to, badgeTokenId, value);\n}",
        "import_statements": [
            "import {IAttestationsRegistry} from './interfaces/IAttestationsRegistry.sol';",
            "import {AttestationsRegistryConfigLogic} from './libs/attestations-registry/AttestationsRegistryConfigLogic.sol';",
            "import {AttestationsRegistryState} from './libs/attestations-registry/AttestationsRegistryState.sol';",
            "import {Range, RangeUtils} from './libs/utils/RangeLib.sol';",
            "import {Attestation, AttestationData} from './libs/Structs.sol';",
            "import {IBadges} from './interfaces/IBadges.sol';"
        ],
        "reference_api": [
            "BADGES.triggerTransferEvent"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "BADGES.triggerTransferEvent"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function generateAttestations(\n    Request calldata request,\n    bytes calldata proofData\n  ) public override returns (Attestation[] memory)",
        "start_line": "49",
        "end_line": "70",
        "file_path": "contracts/core/Attester.sol",
        "docstring": "The function generateAttestations processes a request to generate attestations and returns an array of generated attestations.\\nIt first verifies the validity of the request using the provided proof data by calling _verifyRequest.\\nThen, it generates the attestations based on the request and proof data using buildAttestations.\\nBefore recording the attestations, it calls _beforeRecordAttestations for any necessary pre-processing.\\nIt records the generated attestations in the ATTESTATIONS_REGISTRY by calling recordAttestations.\\nAfter recording, it calls _afterRecordAttestations for any post-processing.\\nFor each generated attestation, it emits an AttestationGenerated event.\\nFinally, it returns the array of generated attestations.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5c4ff46f4ace",
        "ground_truth": "function generateAttestations(\n  Request calldata request,\n  bytes calldata proofData\n) public override returns (Attestation[] memory) {\n  // Verify if request is valid by verifying against proof\n  _verifyRequest(request, proofData);\n  // Generate the actual attestations from user request\n  Attestation[] memory attestations = buildAttestations(request, proofData);\n  _beforeRecordAttestations(request, proofData);\n  ATTESTATIONS_REGISTRY.recordAttestations(attestations);\n  _afterRecordAttestations(attestations);\n  for (uint256 i = 0; i < attestations.length; i++) {\n    emit AttestationGenerated(attestations[i]);\n  }\n  return attestations;\n}",
        "import_statements": [
            "import {IAttester} from './interfaces/IAttester.sol';",
            "import {IAttestationsRegistry} from './interfaces/IAttestationsRegistry.sol';",
            "import {Request, Attestation, AttestationData} from './libs/Structs.sol';"
        ],
        "reference_api": [
            "_verifyRequest",
            "ATTESTATIONS_REGISTRY.recordAttestations",
            "_afterRecordAttestations",
            "buildAttestations",
            "_beforeRecordAttestations"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_verifyRequest",
            "ATTESTATIONS_REGISTRY.recordAttestations",
            "_afterRecordAttestations",
            "buildAttestations",
            "_beforeRecordAttestations"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "sismo-core/sismo-badges",
        "function_declaration": "function batchGenerateAttestations(\n    address[] calldata attesters,\n    Request[] calldata requests,\n    bytes[] calldata proofDataArray\n  ) external override returns (Attestation[][] memory)",
        "start_line": "57",
        "end_line": "74",
        "file_path": "contracts/core/Front.sol",
        "docstring": "The function batchGenerateAttestations generates multiple attestations in a batch process.\\nIt takes three parameters: an array of attester addresses, an array of request objects, and an array of proof data.\\nIt initializes a 2D array, attestations, to store the generated attestations.\\nIt checks that all requests have the same destination address, reverting if any differ.\\nFor each attester, it calls _forwardAttestationsGeneration to generate attestations based on the provided attester, request, and proof data, and stores the result in the attestations array.\\nAfter processing all attesters, it calls _generateEarlyUserAttestation for the common destination.\\nFinally, it returns the 2D array of attestations.",
        "language": "Solidity",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "600fb1023d13",
        "ground_truth": "function batchGenerateAttestations(\n  address[] calldata attesters,\n  Request[] calldata requests,\n  bytes[] calldata proofDataArray\n) external override returns (Attestation[][] memory) {\n  Attestation[][] memory attestations = new Attestation[][](attesters.length);\n  address destination = requests[0].destination;\n  for (uint256 i = 0; i < attesters.length; i++) {\n    if (requests[i].destination != destination) revert DifferentRequestsDestinations();\n    attestations[i] = _forwardAttestationsGeneration(\n      attesters[i],\n      requests[i],\n      proofDataArray[i]\n    );\n  }\n  _generateEarlyUserAttestation(destination);\n  return attestations;\n}",
        "import_statements": [
            "import {IFront} from './interfaces/IFront.sol';",
            "import {IAttester} from './interfaces/IAttester.sol';",
            "import {IAttestationsRegistry} from './interfaces/IAttestationsRegistry.sol';",
            "import {Request, Attestation} from './libs/Structs.sol';"
        ],
        "reference_api": [
            "_generateEarlyUserAttestation",
            "_forwardAttestationsGeneration",
            "new Attestation[][]"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_generateEarlyUserAttestation",
            "_forwardAttestationsGeneration",
            "new Attestation[][]"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function dataSlice(data, start, end)",
        "start_line": "389",
        "end_line": "397",
        "file_path": "dist/ethers.js",
        "docstring": "The function dataSlice extracts a slice from a given data buffer and returns it as a hex string.\\nIt first converts the input data to a byte array using getBytes(data).\\nIf the end parameter is provided and exceeds the length of the byte array, it throws an assertion error with details about the buffer overrun.\\nIt then slices the byte array from the start index (defaulting to 0 if not provided) to the end index (defaulting to the length of the byte array if not provided).\\nFinally, it converts the sliced byte array to a hex string using hexlify and returns the result.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "dec66e37237b",
        "ground_truth": "function dataSlice(data, start, end) {\n    const bytes = getBytes(data);\n    if (end != null && end > bytes.length) {\n        assert(false, \"cannot slice beyond data bounds\", \"BUFFER_OVERRUN\", {\n            buffer: bytes, length: bytes.length, offset: end\n        });\n    }\n    return hexlify(bytes.slice((start == null) ? 0 : start, (end == null) ? bytes.length : end));\n}",
        "import_statements": [],
        "reference_api": [
            "getBytes",
            "assert",
            "bytes.slice",
            "hexlify"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getBytes",
                "code": "function getBytes(value, name) {\n    return _getBytes(value, name, false);\n}"
            },
            {
                "name": "assert",
                "code": "function assert(check, message, code, info) {\n    if (!check) {\n        throw makeError(message, code, info);\n    }\n}"
            },
            {
                "name": "bytes.slice",
                "code": "get bytes() { return new Uint8Array(this.#data); }"
            },
            {
                "name": "hexlify",
                "code": "function hexlify(data) {\n    const bytes = getBytes(data);\n    let result = \"0x\";\n    for (let i = 0; i < bytes.length; i++) {\n        const v = bytes[i];\n        result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];\n    }\n    return result;\n}"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function zeroPad(data, length, left)",
        "start_line": "409",
        "end_line": "425",
        "file_path": "dist/ethers.js",
        "docstring": "The function zeroPad pads a given data to a specified length with zero bytes.\\nIt takes three parameters: data (the data to be padded), length (the desired length after padding), and left (a boolean indicating if padding should be added to the left).\\nIt first converts the data to a byte array using getBytes.\\nIt checks if the specified length is greater than or equal to the byte array length, throwing an error if padding exceeds the data length.\\nIt creates a new Uint8Array of the specified length and fills it with zeros.\\nIf left is true, it sets the original byte array at the end of the result array.\\nOtherwise, it sets the original byte array at the beginning.\\nFinally, it returns the padded array as a hexadecimal string using hexlify.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ac0a0652eeff",
        "ground_truth": "function zeroPad(data, length, left) {\n    const bytes = getBytes(data);\n    assert(length >= bytes.length, \"padding exceeds data length\", \"BUFFER_OVERRUN\", {\n        buffer: new Uint8Array(bytes),\n        length: length,\n        offset: length + 1\n    });\n    const result = new Uint8Array(length);\n    result.fill(0);\n    if (left) {\n        result.set(bytes, length - bytes.length);\n    }\n    else {\n        result.set(bytes, 0);\n    }\n    return hexlify(result);\n}",
        "import_statements": [],
        "reference_api": [
            "getBytes",
            "result.set",
            "hexlify",
            "assert",
            "result.fill"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getBytes",
                "code": "function getBytes(value, name) {\n    return _getBytes(value, name, false);\n}"
            },
            {
                "name": "hexlify",
                "code": "function hexlify(data) {\n    const bytes = getBytes(data);\n    let result = \"0x\";\n    for (let i = 0; i < bytes.length; i++) {\n        const v = bytes[i];\n        result += HexCharacters[(v & 0xf0) >> 4] + HexCharacters[v & 0x0f];\n    }\n    return result;\n}"
            },
            {
                "name": "assert",
                "code": "function assert(check, message, code, info) {\n    if (!check) {\n        throw makeError(message, code, info);\n    }\n}"
            }
        ],
        "third_party": [
            "result.set",
            "result.fill"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function toBeHex(_value, _width)",
        "start_line": "606",
        "end_line": "628",
        "file_path": "dist/ethers.js",
        "docstring": "The function toBeHex converts a numeric value to its hexadecimal representation, optionally padding it to a specified width.\\nIt first retrieves and validates the input value using getUint and converts it to a hexadecimal string.\\nIf no width is provided, it ensures the resulting hex string has an even length by prepending a zero if necessary.\\nIf a width is specified, it validates the width using getNumber and checks that the value does not exceed the specified width, throwing an error if it does.\\nIt then pads the hex string with leading zeros to match the required width.\\nFinally, it returns the hex string prefixed with \"0x\".",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "03eacc2045e9",
        "ground_truth": "function toBeHex(_value, _width) {\n    const value = getUint(_value, \"value\");\n    let result = value.toString(16);\n    if (_width == null) {\n        // Ensure the value is of even length\n        if (result.length % 2) {\n            result = \"0\" + result;\n        }\n    }\n    else {\n        const width = getNumber(_width, \"width\");\n        assert(width * 2 >= result.length, `value exceeds width (${width} bytes)`, \"NUMERIC_FAULT\", {\n            operation: \"toBeHex\",\n            fault: \"overflow\",\n            value: _value\n        });\n        // Pad the value to the required width\n        while (result.length < (width * 2)) {\n            result = \"0\" + result;\n        }\n    }\n    return \"0x\" + result;\n}",
        "import_statements": [],
        "reference_api": [
            "assert",
            "getNumber",
            "value.toString",
            "getUint"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "assert",
                "code": "function assert(check, message, code, info) {\n    if (!check) {\n        throw makeError(message, code, info);\n    }\n}"
            },
            {
                "name": "getNumber",
                "code": "function getNumber(value, name) {\n    switch (typeof (value)) {\n        case \"bigint\":\n            assertArgument(value >= -maxValue && value <= maxValue, \"overflow\", name || \"value\", value);\n            return Number(value);\n        case \"number\":\n            assertArgument(Number.isInteger(value), \"underflow\", name || \"value\", value);\n            assertArgument(value >= -maxValue && value <= maxValue, \"overflow\", name || \"value\", value);\n            return value;\n        case \"string\":\n            try {\n                if (value === \"\") {\n                    throw new Error(\"empty string\");\n                }\n                return getNumber(BigInt(value), name);\n            }\n            catch (e) {\n                assertArgument(false, `invalid numeric string: ${e.message}`, name || \"value\", value);\n            }\n    }\n    assertArgument(false, \"invalid numeric value\", name || \"value\", value);\n}"
            },
            {
                "name": "value.toString",
                "code": "get value() { return this.#val; }"
            },
            {
                "name": "getUint",
                "code": "function getUint(value, name) {\n    const result = getBigInt(value, name);\n    assert(result >= BN_0$a, \"unsigned value cannot be negative\", \"NUMERIC_FAULT\", {\n        fault: \"overflow\", operation: \"getUint\", value\n    });\n    return result;\n}"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function encodeBase58(_value)",
        "start_line": "697",
        "end_line": "713",
        "file_path": "dist/ethers.js",
        "docstring": "The function encodeBase58 encodes a given value into a Base58 string.\\nIt first converts the input value to bytes using getBytes and then converts these bytes to a BigInt value using toBigInt.\\nIt initializes an empty string result to store the encoded Base58 string.\\nThe function then repeatedly divides the BigInt value by 58 (BN_58) and prepends the corresponding character from the Base58 alphabet (Alphabet) to the result string until the value is zero.\\nTo account for leading zeros in the original byte array, it adds the Base58 character for zero to the beginning of the result string for each leading zero byte in the input.\\nFinally, the function returns the Base58 encoded string.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c64e7c684866",
        "ground_truth": "function encodeBase58(_value) {\n    const bytes = getBytes(_value);\n    let value = toBigInt(bytes);\n    let result = \"\";\n    while (value) {\n        result = Alphabet[Number(value % BN_58)] + result;\n        value /= BN_58;\n    }\n    // Account for leading padding zeros\n    for (let i = 0; i < bytes.length; i++) {\n        if (bytes[i]) {\n            break;\n        }\n        result = Alphabet[0] + result;\n    }\n    return result;\n}",
        "import_statements": [],
        "reference_api": [
            "getBytes",
            "toBigInt",
            "Number"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getBytes",
                "code": "function getBytes(value, name) {\n    return _getBytes(value, name, false);\n}"
            },
            {
                "name": "toBigInt",
                "code": "function toBigInt(value) {\n    if (value instanceof Uint8Array) {\n        let result = \"0x0\";\n        for (const v of value) {\n            result += Nibbles$1[v >> 4];\n            result += Nibbles$1[v & 0x0f];\n        }\n        return BigInt(result);\n    }\n    return getBigInt(value);\n}"
            }
        ],
        "third_party": [
            "Number"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function _toUtf8String(codePoints) ",
        "start_line": "974",
        "end_line": "982",
        "file_path": "dist/ethers.js",
        "docstring": "The function _toUtf8String converts an array of Unicode code points into a UTF-8 string.\\nIt iterates through each code point in the codePoints array.\\nIf the code point is less than or equal to 0xffff, it converts it directly to a character using String.fromCharCode.\\nFor code points greater than 0xffff, it calculates the surrogate pair by subtracting 0x10000 and then splitting the code point into high and low surrogates, adding them to the appropriate ranges (0xd800 and 0xdc00, respectively).\\nIt then converts these surrogates to characters and joins them into a single string.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f003ccd50c08",
        "ground_truth": "function _toUtf8String(codePoints) {\n    return codePoints.map((codePoint) => {\n        if (codePoint <= 0xffff) {\n            return String.fromCharCode(codePoint);\n        }\n        codePoint -= 0x10000;\n        return String.fromCharCode((((codePoint >> 10) & 0x3ff) + 0xd800), ((codePoint & 0x3ff) + 0xdc00));\n    }).join(\"\");\n}",
        "import_statements": [],
        "reference_api": [
            "String.fromCharCode",
            "codePoints.map((codePoint) => {\n        if (codePoint <= 0xffff) {\n            return String.fromCharCode(codePoint);\n        }\n        codePoint -= 0x10000;\n        return String.fromCharCode((((codePoint >> 10) & 0x3ff) + 0xd800), ((codePoint & 0x3ff) + 0xdc00));\n    }).join",
            "codePoints.map"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "codePoints.map",
                "code": "map(callback, thisArg) {\n        const result = [];\n        for (let i = 0; i < this.length; i++) {\n            const item = this[i];\n            if (item instanceof Error) {\n                throwError(`index ${i}`, item);\n            }\n            result.push(callback.call(thisArg, item, i, this));\n        }\n        return result;\n    }"
            }
        ],
        "third_party": [
            "codePoints.map((codePoint) => {\n        if (codePoint <= 0xffff) {\n            return String.fromCharCode(codePoint);\n        }\n        codePoint -= 0x10000;\n        return String.fromCharCode((((codePoint >> 10) & 0x3ff) + 0xd800), ((codePoint & 0x3ff) + 0xdc00));\n    }).join"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "function decode(data, subs)",
        "start_line": "834",
        "end_line": "858",
        "file_path": "dist/wordlists-extra.js",
        "docstring": "The decode function processes a given data string by replacing specified substrings and parsing it into clumps based on certain patterns.\\nIt first iterates over subsChrs in reverse order, replacing occurrences in data with corresponding substrings from subs.\\nIt then uses a regular expression to find and replace specific patterns in the data: colons, digits, and words starting with a capital letter followed by lowercase letters.\\nFor digits, it adds semicolons to the clumps array based on the digit value.\\nFor other patterns, it adds the lowercase version of the item to the clumps array.\\nIf there are any leftover characters after this process, it throws an error.\\nFinally, it calls unfold on the clumps array twice, first with \";\" and then with \":\", and returns the result.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5bc5b89a15fc",
        "ground_truth": "function decode(data, subs) {\n    // Replace all the substitutions with their expanded form\n    for (let i = subsChrs.length - 1; i >= 0; i--) {\n        data = data.split(subsChrs[i]).join(subs.substring(2 * i, 2 * i + 2));\n    }\n    // Get all tle clumps; each suffix, first-increment and second-increment\n    const clumps = [];\n    const leftover = data.replace(/(:|([0-9])|([A-Z][a-z]*))/g, (all, item, semi, word) => {\n        if (semi) {\n            for (let i = parseInt(semi); i >= 0; i--) {\n                clumps.push(\";\");\n            }\n        }\n        else {\n            clumps.push(item.toLowerCase());\n        }\n        return \"\";\n    });\n    /* c8 ignore start */\n    if (leftover) {\n        throw new Error(`leftovers: ${JSON.stringify(leftover)}`);\n    }\n    /* c8 ignore stop */\n    return unfold(unfold(clumps, \";\"), \":\");\n}",
        "import_statements": [],
        "reference_api": [
            "JSON.stringify",
            "item.toLowerCase",
            "clumps.push",
            "data.replace",
            "unfold",
            "data.split",
            "data.split(subsChrs[i]).join",
            "parseInt",
            "subs.substring"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "data.split",
                "code": "function split(lst, le = false) {\n    let Ah = new Uint32Array(lst.length);\n    let Al = new Uint32Array(lst.length);\n    for (let i = 0; i < lst.length; i++) {\n        const { h, l } = fromBig(lst[i], le);\n        [Ah[i], Al[i]] = [h, l];\n    }\n    return [Ah, Al];\n}"
            }
        ],
        "third_party": [
            "item.toLowerCase",
            "clumps.push",
            "data.replace",
            "unfold",
            "data.split(subsChrs[i]).join",
            "subs.substring"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "const populateTransaction = async function (...args)",
        "start_line": "199",
        "end_line": "217",
        "file_path": "lib.commonjs/contract/contract.js",
        "docstring": "The async function populateTransaction constructs a transaction object with provided arguments.\\nIt first retrieves a function fragment using getFragment(...args).\\nIf the number of arguments matches the fragment inputs plus one, it assumes the last argument is an overrides object, which it copies and normalizes.\\nIf the overrides object contains a 'from' field, it resolves the address using resolveAddress and getResolver.\\nIf the number of arguments does not match the fragment inputs, it throws an error.\\nNext, it resolves the arguments using resolveArgs with the contract's runner and the fragment's inputs.\\nFinally, it constructs the transaction object by merging the overrides with properties resolved using resolveProperties, including the contract address and encoded function data, and returns this object.",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "231a2277a5a9",
        "ground_truth": "const populateTransaction = async function (...args) {\n    const fragment = getFragment(...args);\n    // If an overrides was passed in, copy it and normalize the values\n    let overrides = {};\n    if (fragment.inputs.length + 1 === args.length) {\n        overrides = await copyOverrides(args.pop());\n        if (overrides.from) {\n            overrides.from = await (0, index_js_2.resolveAddress)(overrides.from, getResolver(contract.runner));\n        }\n    }\n    if (fragment.inputs.length !== args.length) {\n        throw new Error(\"internal error: fragment inputs doesn't match arguments; should not happen\");\n    }\n    const resolvedArgs = await resolveArgs(contract.runner, fragment.inputs, args);\n    return Object.assign({}, overrides, await (0, index_js_3.resolveProperties)({\n        to: contract.getAddress(),\n        data: contract.interface.encodeFunctionData(fragment, resolvedArgs)\n    }));\n};",
        "import_statements": [],
        "reference_api": [
            "args.pop",
            "contract.interface.encodeFunctionData",
            "(0, index_js_3.resolveProperties)",
            "getFragment",
            "getResolver",
            "Object.assign",
            "(0, index_js_2.resolveAddress)",
            "contract.getAddress",
            "copyOverrides",
            "resolveArgs"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getResolver",
                "code": "function getResolver(value) {\n    if (value != null) {\n        if (canResolve(value)) {\n            return value;\n        }\n        if (value.provider) {\n            return value.provider;\n        }\n    }\n    return undefined;\n}"
            },
            {
                "name": "contract.getAddress",
                "code": "async getAddress() { return await getInternal(this).addrPromise; }"
            },
            {
                "name": "copyOverrides",
                "code": "async function copyOverrides(arg, allowed) {\n    // Make sure the overrides passed in are a valid overrides object\n    const _overrides = index_js_1.Typed.dereference(arg, \"overrides\");\n    (0, index_js_3.assertArgument)(typeof (_overrides) === \"object\", \"invalid overrides parameter\", \"overrides\", arg);\n    // Create a shallow copy (we'll deep-ify anything needed during normalizing)\n    const overrides = (0, provider_js_1.copyRequest)(_overrides);\n    (0, index_js_3.assertArgument)(overrides.to == null || (allowed || []).indexOf(\"to\") >= 0, \"cannot override to\", \"overrides.to\", overrides.to);\n    (0, index_js_3.assertArgument)(overrides.data == null || (allowed || []).indexOf(\"data\") >= 0, \"cannot override data\", \"overrides.data\", overrides.data);\n    // Resolve any from\n    if (overrides.from) {\n        overrides.from = overrides.from;\n    }\n    return overrides;\n}"
            },
            {
                "name": "resolveArgs",
                "code": "async function resolveArgs(_runner, inputs, args) {\n    // Recursively descend into args and resolve any addresses\n    const runner = getRunner(_runner, \"resolveName\");\n    const resolver = canResolve(runner) ? runner : null;\n    return await Promise.all(inputs.map((param, index) => {\n        return param.walkAsync(args[index], (type, value) => {\n            value = index_js_1.Typed.dereference(value, type);\n            if (type === \"address\") {\n                return (0, index_js_2.resolveAddress)(value, resolver);\n            }\n            return value;\n        });\n    }));\n}"
            }
        ],
        "third_party": [
            "args.pop",
            "contract.interface.encodeFunctionData",
            "(0, index_js_3.resolveProperties)",
            "getFragment",
            "(0, index_js_2.resolveAddress)"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "const send = async function (...args)",
        "start_line": "225",
        "end_line": "233",
        "file_path": "lib.commonjs/contract/contract.js",
        "docstring": "The async function send sends a transaction using a contract runner.\\nIt accepts multiple arguments and starts by assigning the contract.runner to a local variable runner.\\nIt then asserts that the runner can send transactions using the canSend function and throws an error if it cannot.\\nIt populates the transaction with the provided arguments using populateTransaction and sends it using runner.sendTransaction.\\nThe function retrieves the provider from the contract runner using getProvider.\\nFinally, it returns a new ContractTransactionResponse, passing the contract interface, provider, and the transaction object.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a13811d15d95",
        "ground_truth": "const send = async function (...args) {\n    const runner = contract.runner;\n    (0, index_js_3.assert)(canSend(runner), \"contract runner does not support sending transactions\", \"UNSUPPORTED_OPERATION\", { operation: \"sendTransaction\" });\n    const tx = await runner.sendTransaction(await populateTransaction(...args));\n    const provider = getProvider(contract.runner);\n    // @TODO: the provider can be null; make a custom dummy provider that will throw a\n    // meaningful error\n    return new wrappers_js_1.ContractTransactionResponse(contract.interface, provider, tx);\n};",
        "import_statements": [],
        "reference_api": [
            "getProvider",
            "canSend",
            "populateTransaction",
            "(0, index_js_3.assert)",
            "runner.sendTransaction"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "getProvider",
                "code": "function getProvider(value) {\n    if (value == null) {\n        return null;\n    }\n    return value.provider || null;\n}"
            },
            {
                "name": "canSend",
                "code": "function canSend(value) {\n    return (value && typeof (value.sendTransaction) === \"function\");\n}"
            }
        ],
        "third_party": [
            "populateTransaction",
            "(0, index_js_3.assert)",
            "runner.sendTransaction"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "const estimateGas = async function (...args)",
        "start_line": "234",
        "end_line": "238",
        "file_path": "lib.commonjs/contract/contract.js",
        "docstring": "The async function estimateGas estimates the gas required for a transaction.\\nIt first retrieves the runner capable of estimating gas using getRunner with the \"estimateGas\" operation.\\nIt asserts that the runner supports gas estimation using the canEstimate function.\\nIf the runner does not support gas estimation, it throws an error with the message \"contract runner does not support gas estimation\" and the operation \"UNSUPPORTED_OPERATION\".\\nIt then calls the runner's estimateGas method, passing in the populated transaction obtained from calling populateTransaction with the provided arguments, and returns the estimated gas.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "70348f702224",
        "ground_truth": "const estimateGas = async function (...args) {\n    const runner = getRunner(contract.runner, \"estimateGas\");\n    (0, index_js_3.assert)(canEstimate(runner), \"contract runner does not support gas estimation\", \"UNSUPPORTED_OPERATION\", { operation: \"estimateGas\" });\n    return await runner.estimateGas(await populateTransaction(...args));\n};",
        "import_statements": [],
        "reference_api": [
            "runner.estimateGas",
            "populateTransaction",
            "(0, index_js_3.assert)",
            "canEstimate",
            "getRunner"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "canEstimate",
                "code": "function canEstimate(value) {\n    return (value && typeof (value.estimateGas) === \"function\");\n}"
            },
            {
                "name": "getRunner",
                "code": "function getRunner(value, feature) {\n    if (value == null) {\n        return null;\n    }\n    if (typeof (value[feature]) === \"function\") {\n        return value;\n    }\n    if (value.provider && typeof (value.provider[feature]) === \"function\") {\n        return value.provider;\n    }\n    return null;\n}"
            }
        ],
        "third_party": [
            "runner.estimateGas",
            "populateTransaction",
            "(0, index_js_3.assert)"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "const staticCallResult = async function (...args)",
        "start_line": "239",
        "end_line": "255",
        "file_path": "lib.commonjs/contract/contract.js",
        "docstring": "The async function staticCallResult executes a static call on a contract.\\nIt first retrieves the runner using getRunner with the operation \"call\".\\nIt asserts that the runner supports calling using canCall, throwing an error if not supported.\\nIt populates the transaction with the provided arguments using populateTransaction.\\nIt initializes the result variable as \"0x\".\\nIt attempts to execute the call using runner.call with the populated transaction.\\nIf an error occurs and is identified as a call exception with data, it throws a contract-specific error using contract.interface.makeError.\\nOtherwise, it rethrows the original error.\\nAfter the call, it retrieves the function fragment using getFragment with the provided arguments.\\nFinally, it decodes and returns the function result using contract.interface.decodeFunctionResult with the fragment and the call result.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ee7df7228f0d",
        "ground_truth": "const staticCallResult = async function (...args) {\n    const runner = getRunner(contract.runner, \"call\");\n    (0, index_js_3.assert)(canCall(runner), \"contract runner does not support calling\", \"UNSUPPORTED_OPERATION\", { operation: \"call\" });\n    const tx = await populateTransaction(...args);\n    let result = \"0x\";\n    try {\n        result = await runner.call(tx);\n    }\n    catch (error) {\n        if ((0, index_js_3.isCallException)(error) && error.data) {\n            throw contract.interface.makeError(error.data, tx);\n        }\n        throw error;\n    }\n    const fragment = getFragment(...args);\n    return contract.interface.decodeFunctionResult(fragment, result);\n};",
        "import_statements": [],
        "reference_api": [
            "(0, index_js_3.isCallException)",
            "contract.interface.makeError",
            "contract.interface.decodeFunctionResult",
            "populateTransaction",
            "getFragment",
            "(0, index_js_3.assert)",
            "runner.call",
            "canCall",
            "getRunner"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "canCall",
                "code": "function canCall(value) {\n    return (value && typeof (value.call) === \"function\");\n}"
            },
            {
                "name": "getRunner",
                "code": "function getRunner(value, feature) {\n    if (value == null) {\n        return null;\n    }\n    if (typeof (value[feature]) === \"function\") {\n        return value;\n    }\n    if (value.provider && typeof (value.provider[feature]) === \"function\") {\n        return value.provider;\n    }\n    return null;\n}"
            }
        ],
        "third_party": [
            "(0, index_js_3.isCallException)",
            "contract.interface.makeError",
            "contract.interface.decodeFunctionResult",
            "populateTransaction",
            "getFragment",
            "(0, index_js_3.assert)",
            "runner.call"
        ]
    },
    {
        "subclass": "Ethereum",
        "owner/repo": "ethers-io/ethers.js",
        "function_declaration": "const listener = (log) =>",
        "start_line": "426",
        "end_line": "447",
        "file_path": "lib.commonjs/contract/contract.js",
        "docstring": "The function listener processes blockchain log events for a specific contract.\\nIt first checks if the fragment is null, and if so, it attempts to retrieve the event fragment using the log's topic from the contract's interface.\\nIf a valid fragment is found, it decodes the event log data and topics into arguments using the contract's interface.\\nIt then emits the event with the decoded arguments, creating a new ContractEventPayload instance.\\nIf no fragment is found, it emits the event with an empty argument list, creating a ContractUnknownEventPayload instance instead.\n",
        "language": "JavaScript",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4fcc6fb18eec",
        "ground_truth": "const listener = (log) => {\n    let foundFragment = fragment;\n    if (foundFragment == null) {\n        try {\n            foundFragment = contract.interface.getEvent(log.topics[0]);\n        }\n        catch (error) { }\n    }\n    // If fragment is null, we do not deconstruct the args to emit\n    if (foundFragment) {\n        const _foundFragment = foundFragment;\n        const args = fragment ? contract.interface.decodeEventLog(fragment, log.data, log.topics) : [];\n        emit(contract, event, args, (listener) => {\n            return new wrappers_js_1.ContractEventPayload(contract, listener, event, _foundFragment, log);\n        });\n    }\n    else {\n        emit(contract, event, [], (listener) => {\n            return new wrappers_js_1.ContractUnknownEventPayload(contract, listener, event, log);\n        });\n    }\n};",
        "import_statements": [],
        "reference_api": [
            "emit",
            "contract.interface.decodeEventLog",
            "contract.interface.getEvent"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "emit",
                "code": "async function emit(contract, event, args, payloadFunc) {\n    try {\n        await lastEmit;\n    }\n    catch (error) { }\n    const resultPromise = _emit(contract, event, args, payloadFunc);\n    lastEmit = resultPromise;\n    return await resultPromise;\n}"
            },
            {
                "name": "contract.interface.getEvent",
                "code": "getEvent(key) {\n        if (typeof (key) !== \"string\") {\n            key = key.format();\n        }\n        return buildWrappedEvent(this, key);\n    }"
            }
        ],
        "third_party": [
            "contract.interface.decodeEventLog"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static int aox_read_data         (GPPort *port, char *data, int size)",
        "start_line": "112",
        "end_line": "123",
        "file_path": "camlibs/aox/aox.c",
        "docstring": "The static function aox_read_data reads data from a specified port into a buffer.\\nIt initializes MAX_BULK to 0x1000, representing the maximum bulk read size.\\nThe function enters a while loop, which continues as long as the size of the data to be read is greater than 0.\\nInside the loop, it determines the length of the data to read in the current iteration, limited by MAX_BULK.\\nIt then calls gp_port_read to read the data from the port into the buffer.\\nAfter reading, it adjusts the data pointer and reduces the remaining size by the length of the data read.\\nFinally, the function returns 1 to indicate successful completion.",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "ba504a169aba",
        "ground_truth": "static int aox_read_data         (GPPort *port, char *data, int size)\n{\n int MAX_BULK = 0x1000;\n  while(size > 0) {\n  int len = (size>MAX_BULK)?MAX_BULK:size;\n         gp_port_read  (port, data, len); /* 0x84 = EP IN NEEDED HERE.*/\n      data += len;\n  size -= len;\n }\n        return 1;\n}",
        "import_statements": [
            "#include <config.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "#include <errno.h>\n",
            "#include <fcntl.h>\n",
            "#include <string.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include <gphoto2/gphoto2-port.h>\n",
            "#include \"aox.h\"\n"
        ],
        "reference_api": [
            "gp_port_read"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "gp_port_read"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "int aox_get_picture_size  (GPPort *port, int lo, int hi, int n, int k)",
        "start_line": "88",
        "end_line": "110",
        "file_path": "camlibs/aox/aox.c",
        "docstring": "The function aox_get_picture_size retrieves the size of a picture from a specified port.\\nIt initializes a buffer and a variable to hold the size, then runs specific read commands based on the provided conditions involving the lo, hi, n, and k parameters.\\nThe size is calculated by combining bytes read from the port.\\nIf the size is greater than or equal to a specified threshold, it returns an error.\\nOtherwise, it returns the calculated size.\n",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "2abb164b494b",
        "ground_truth": "int aox_get_picture_size  (GPPort *port, int lo, int hi, int n, int k)\n{\n  unsigned char c[4];\n        unsigned int size;\n memset (c,0,4);\n  GP_DEBUG(\"Running aox_get_picture_size for aox_pic%03i\\n\", k+1);\n  if ( ( (lo) && ( n ==k ) && (k ==0)) ) {\n      READ(port, 0x04, 0x1, 0x1, (char *)c, 2);\n }\n if ( ( (hi) && ( n < k ) && (n == 0))   ) {\n         READ(port, 0x04, 0x5, 0x1, (char *)c, 2);\n }\n READ(port, 0x05, n+1, 0x1, (char *)c, 4);\n size = (int)c[0] + (int)c[1]*0x100 + (int)c[2]*0x10000;\n GP_DEBUG(\" size of picture %i is 0x%x\\n\", k, size);\n if ( (size >= 0xfffff ) ) {return GP_ERROR;}\n GP_DEBUG(\"Leaving aox_get_picture_size\\n\");\n  return size;\n}",
        "import_statements": [
            "#include <config.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "#include <errno.h>\n",
            "#include <fcntl.h>\n",
            "#include <string.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include <gphoto2/gphoto2-port.h>\n",
            "#include \"aox.h\"\n"
        ],
        "reference_api": [
            "memset",
            "READ",
            "GP_DEBUG"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "READ",
            "GP_DEBUG"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static int\ncamera_summary (Camera *camera, CameraText *summary, GPContext *context)",
        "start_line": "102",
        "end_line": "116",
        "file_path": "camlibs/aox/library.c",
        "docstring": "The function camera_summary generates a summary of a camera with an Aox chipset.\\nIt takes a Camera object, a CameraText object, and a GPContext as parameters.\\nThe function retrieves the number of low-resolution and high-resolution pictures using aox_get_num_lo_pics and aox_get_num_hi_pics respectively.\\nIt then formats these values into a summary string and assigns it to summary->text, indicating the number of low-res, high-res, and total pictures.\\nFinally, the function returns GP_OK to indicate success.\n",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "381ff317cc3c",
        "ground_truth": "static int\ncamera_summary (Camera *camera, CameraText *summary, GPContext *context)\n{\n  int num_lo_pics =aox_get_num_lo_pics(camera->pl->info);\n int num_hi_pics =aox_get_num_hi_pics(camera->pl->info);\n      sprintf (summary->text,_(\"Your USB camera has an Aox chipset.\\n\"\n   \"Number of lo-res PICs = %i\\n\"\n   \"Number of hi-res PICs = %i\\n\"\n   \"Number of PICs = %i\\n\"\n          ), num_lo_pics, num_hi_pics, num_lo_pics+num_hi_pics);\n      return GP_OK;\n}",
        "import_statements": [
            "#include <config.h>\n",
            "#include <stdlib.h>\n",
            "#include <stdio.h>\n",
            "#include <string.h>\n",
            "#include <libgphoto2/bayer.h>\n",
            "#include <libgphoto2/gamma.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include \"aox.h\"\n",
            "#include <gphoto2/gphoto2-port.h>\n"
        ],
        "reference_api": [
            "sprintf",
            "_",
            "aox_get_num_hi_pics",
            "aox_get_num_lo_pics"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "_",
            "aox_get_num_hi_pics",
            "aox_get_num_lo_pics"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static int\nfile_list_func (CameraFilesystem *fs, const char *folder, CameraList *list,\n                void *data, GPContext *context)",
        "start_line": "129",
        "end_line": "152",
        "file_path": "camlibs/aox/library.c",
        "docstring": "The function file_list_func generates a list of picture filenames from a camera's filesystem.\\nIt takes parameters for the filesystem, folder, list, data, and context.\\nUsing the camera data, it retrieves the number of low-resolution (lo) and high-resolution (hi) pictures.\\nIt then iterates through the low-resolution pictures first, appending their filenames with a .raw extension to the list.\\nNext, it appends the high-resolution picture filenames with a .ppm extension to the list.\\nFinally, it returns a success status code, GP_OK.\n",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "a693d7a92c02",
        "ground_truth": "static int\nfile_list_func (CameraFilesystem *fs, const char *folder, CameraList *list,\n                void *data, GPContext *context)\n{\n        Camera *camera = data;\n int num_lo_pics = aox_get_num_lo_pics (camera->pl->info);\n int num_hi_pics = aox_get_num_hi_pics (camera->pl->info);\n int n = num_hi_pics + num_lo_pics;\n char name[30];\n int i;\n /* Low-resolution pictures are always downloaded first. We do not know\n  * yet how to process them, so they will remain in RAW format. */\n  for (i=0; i< num_lo_pics; i++){\n  snprintf( name, sizeof(name), \"aox_pic%03i.raw\", i+1 );\n  gp_list_append(list, name, NULL);\n }\n  for (i = num_lo_pics; i < n; i++){\n  snprintf( name, sizeof(name), \"aox_pic%03i.ppm\", i+1 );\n  gp_list_append(list, name, NULL);\n }\n     return GP_OK;\n}",
        "import_statements": [
            "#include <config.h>\n",
            "#include <stdlib.h>\n",
            "#include <stdio.h>\n",
            "#include <string.h>\n",
            "#include <libgphoto2/bayer.h>\n",
            "#include <libgphoto2/gamma.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include \"aox.h\"\n",
            "#include <gphoto2/gphoto2-port.h>\n"
        ],
        "reference_api": [
            "snprintf",
            "gp_list_append",
            "aox_get_num_hi_pics",
            "aox_get_num_lo_pics"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "gp_list_append",
                "code": "int\ngp_list_append (CameraList *list, const char *name, const char *value)\n{\n\tC_PARAMS (list && list->ref_count);\n\n\tif (list->used == list->max) {\n\t\tC_MEM (list->entry = realloc(list->entry,(list->max+100)*sizeof(struct _entry)));\n\t\tlist->max += 100;\n\t}\n\n\tif (name) {\n\t\tC_MEM (list->entry[list->used].name = strdup (name));\n\t} else {\n\t\tlist->entry[list->used].name = NULL;\n\t}\n\tif (value) {\n\t\tC_MEM (list->entry[list->used].value = strdup (value));\n\t} else {\n\t\tlist->entry[list->used].value = NULL;\n\t}\n        list->used++;\n        return (GP_OK);\n}"
            }
        ],
        "third_party": [
            "aox_get_num_hi_pics",
            "aox_get_num_lo_pics"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static int\nbarbie_read_response(GPPort *port, unsigned char *response, unsigned int size)",
        "start_line": "59",
        "end_line": "71",
        "file_path": "camlibs/barbie/barbie.c",
        "docstring": "The function barbie_read_response reads a response from a GPPort.\\nIt first reads a single byte from the port to check for an acknowledgment (ACK).\\nIf the ACK is not received or if there's an error in reading, it returns a GP_ERROR_IO_READ.\\nIf the ACK is correct, it initializes the response buffer to zero using memset.\\nFinally, it reads the actual response from the port into the response buffer and returns the result of this read operation.",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c1c2e4fade97",
        "ground_truth": "static int\nbarbie_read_response(GPPort *port, unsigned char *response, unsigned int size) {\n int x;\n char ack = 0;\n  /* Read the ACK */\n x=gp_port_read(port, &ack, 1);\n if ((ack != ACK)||(x<0))\n  return GP_ERROR_IO_READ;\n /* Read the Response */\n memset(response, 0, size);\n return gp_port_read(port, (char*)response, size);\n}",
        "import_statements": [
            "#include \"config.h\"\n",
            "#include <ctype.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "#include <string.h>\n",
            "#include <libgphoto2/bayer.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include \"libgphoto2/i18n.h\"\n"
        ],
        "reference_api": [
            "memset",
            "gp_port_read"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "gp_port_read"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static\nint barbie_exchange (GPPort *port, unsigned char *cmd, unsigned int cmd_size, unsigned char *resp, unsigned int resp_size)",
        "start_line": "73",
        "end_line": "88",
        "file_path": "camlibs/barbie/barbie.c",
        "docstring": "The function barbie_exchange attempts to exchange data with a device connected to a specified port up to 10 times.\\nIt writes a command to the port using gp_port_write and then reads the response using barbie_read_response.\\nIf the response indicates the device is not busy (resp[RESPONSE_BYTE] != '!'), the function returns 1 indicating success.\\nIf the device is busy, the function waits for 2 seconds before retrying.\\nIf all attempts fail or there is an error in writing or reading, the function returns 0 indicating failure.\n",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4d99fb730876",
        "ground_truth": "static\nint barbie_exchange (GPPort *port, unsigned char *cmd, unsigned int cmd_size, unsigned char *resp, unsigned int resp_size) {\n int count = 0;\n while (count++ < 10) {\n  if (gp_port_write(port, (char*)cmd, cmd_size) < GP_OK)\n   return (0);\n  if (barbie_read_response(port, resp, resp_size) < GP_OK)\n   return (0);\n  /* if it's not busy, return */\n  if (resp[RESPONSE_BYTE] != '!')\n   return (1);\n  /* if busy, sleep 2 seconds */\n  sleep(2);\n }\n return (0);\n}",
        "import_statements": [
            "#include \"config.h\"\n",
            "#include <ctype.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "#include <string.h>\n",
            "#include <libgphoto2/bayer.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include \"libgphoto2/i18n.h\"\n"
        ],
        "reference_api": [
            "sleep",
            "gp_port_write",
            "barbie_read_response"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "barbie_read_response",
                "code": "static int\nbarbie_read_response(GPPort *port, unsigned char *response, unsigned int size) {\n\tint x;\n\tchar ack = 0;\n\n\t/* Read the ACK */\n\tx=gp_port_read(port, &ack, 1);\n\tif ((ack != ACK)||(x<0))\n\t\treturn GP_ERROR_IO_READ;\n\t/* Read the Response */\n\tmemset(response, 0, size);\n\treturn gp_port_read(port, (char*)response, size);\n}"
            }
        ],
        "third_party": [
            "sleep",
            "gp_port_write"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "gphoto/libgphoto2",
        "function_declaration": "static unsigned char *\nbarbie_read_firmware(GPPort *port) ",
        "start_line": "124",
        "end_line": "155",
        "file_path": "camlibs/barbie/barbie.c",
        "docstring": "The function barbie_read_firmware retrieves the firmware from a device connected to a GPPort.\\nIt initializes a command array and response array, then sets the command bytes to request the firmware version.\\nIt sends the command to the device and receives the response.\\nThe response size is determined and memory is allocated to store the firmware data.\\nThe first byte of the firmware is set from the response and the rest is read from the port.\\nIf any read operation fails, the allocated memory is freed and the function returns NULL.\\nFinally, the function reads the footer and returns the firmware data.\n",
        "language": "C",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "3ea4cab53239",
        "ground_truth": "static unsigned char *\nbarbie_read_firmware(GPPort *port) {\n  unsigned char cmd[4];\n unsigned char resp[4];\n unsigned int size;\n char c;\n unsigned char *s = NULL;\n  GP_DEBUG (\"Getting Firmware...\");\n  memcpy(cmd, packet_1, 4);\n cmd[COMMAND_BYTE] = 'V';\n cmd[DATA1_BYTE]   = '0';\n if (barbie_exchange(port, cmd, 4, resp, 4) != 1)\n  return (0);\n /* we're getting the firmware revision */\n size = resp[2];\n s = malloc(size);\n memset(s, 0, size);\n s[0] = resp[3];\n if (gp_port_read(port, (char*)&s[1], size-1) < 0) {\n  free(s);\n  return (NULL);\n }\n /* read the footer */\n if (gp_port_read(port, &c, 1) < 0) {\n  free(s);\n  return (0);\n }\n return s;\n}",
        "import_statements": [
            "#include \"config.h\"\n",
            "#include <ctype.h>\n",
            "#include <stdio.h>\n",
            "#include <stdlib.h>\n",
            "#include <string.h>\n",
            "#include <libgphoto2/bayer.h>\n",
            "#include <gphoto2/gphoto2.h>\n",
            "#include \"libgphoto2/i18n.h\"\n"
        ],
        "reference_api": [
            "malloc",
            "free",
            "barbie_exchange",
            "memset",
            "gp_port_read",
            "memcpy",
            "GP_DEBUG"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "barbie_exchange",
                "code": "static\nint barbie_exchange (GPPort *port, unsigned char *cmd, unsigned int cmd_size, unsigned char *resp, unsigned int resp_size) {\n\tint count = 0;\n\twhile (count++ < 10) {\n\t\tif (gp_port_write(port, (char*)cmd, cmd_size) < GP_OK)\n\t\t\treturn (0);\n\t\tif (barbie_read_response(port, resp, resp_size) < GP_OK)\n\t\t\treturn (0);\n\t\t/* if it's not busy, return */\n\t\tif (resp[RESPONSE_BYTE] != '!')\n\t\t\treturn (1);\n\t\t/* if busy, sleep 2 seconds */\n\t\tsleep(2);\n\t}\n\treturn (0);\n}"
            }
        ],
        "third_party": [
            "gp_port_read",
            "GP_DEBUG"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public void useAppContext() throws Exception",
        "start_line": "20",
        "end_line": "25",
        "file_path": "app/src/androidTest/java/org/consenlabs/tokencore/ExampleInstrumentedTest.java",
        "docstring": "The function useAppContext tests the context of the application under test.\\nIt retrieves the application context using InstrumentationRegistry.getTargetContext().\\nThen, it asserts that the package name of the application context is \"org.consenlabs.tokencore\".\\nIf the package name does not match, the test will fail.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "eb8289ad9e0c",
        "ground_truth": "public void useAppContext() throws Exception {\n  // Context of the app under test.\n  Context appContext = InstrumentationRegistry.getTargetContext();\n  assertEquals(\"org.consenlabs.tokencore\", appContext.getPackageName());\n}",
        "import_statements": [
            "import android.content.Context;",
            "import android.support.test.InstrumentationRegistry;",
            "import android.support.test.runner.AndroidJUnit4;",
            "import org.junit.Test;",
            "import org.junit.runner.RunWith;",
            "import static org.junit.Assert.*;"
        ],
        "reference_api": [
            "getPackageName",
            "assertEquals",
            "getTargetContext"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "getPackageName",
            "assertEquals",
            "getTargetContext"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "private static Crypto createCrypto(String password, byte[] origin, String kdfType, boolean isCached)",
        "start_line": "70",
        "end_line": "93",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/Crypto.java",
        "docstring": "The function createCrypto initializes and returns a Crypto object using the specified password, origin data, key derivation function (kdfType), and caching option.\\nIt selects the key derivation function (PBKDF2 or SCrypt) and sets the cipher to CTR mode.\\nIt generates a random initialization vector (IV) and sets it in the cipher parameters.\\nThe function then derives a key using the password and, if caching is enabled, stores the derived key.\\nIt encrypts the origin data using the derived key and IV, storing the result as ciphertext.\\nFinally, it generates a message authentication code (MAC) for the encrypted data and returns the populated Crypto object.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "f1269788ef17",
        "ground_truth": "private static Crypto createCrypto(String password, byte[] origin, String kdfType, boolean isCached) {\n  Crypto crypto = PBKDF2Crypto.PBKDF2.equals(kdfType) ? PBKDF2Crypto.createPBKDF2Crypto() : SCryptCrypto.createSCryptCrypto();\n  crypto.setCipher(CTR);\n  byte[] iv = NumericUtil.generateRandomBytes(IV_LENGTH);\n  CipherParams cipherparams = new CipherParams();\n  cipherparams.setIv(NumericUtil.bytesToHex(iv));\n  crypto.setCipherparams(cipherparams);\n  byte[] derivedKey = crypto.getValidDerivedKey(password);\n  if (isCached) {\n    crypto.setCachedDerivedKey(new CachedDerivedKey(password, derivedKey));\n  }\n  byte[] encrypted = crypto.encrypt(derivedKey, iv, origin);\n  crypto.ciphertext = NumericUtil.bytesToHex(encrypted);\n  byte[] mac = Hash.generateMac(derivedKey, encrypted);\n  crypto.mac = NumericUtil.bytesToHex(mac);\n  return crypto;\n}",
        "import_statements": [
            "import org.consenlabs.tokencore.foundation.utils.CachedDerivedKey;",
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import com.fasterxml.jackson.annotation.JsonIgnore;",
            "import com.fasterxml.jackson.annotation.JsonProperty;",
            "import com.fasterxml.jackson.annotation.JsonSubTypes;",
            "import com.fasterxml.jackson.annotation.JsonTypeInfo;",
            "import com.google.common.base.Strings;",
            "import java.util.Arrays;"
        ],
        "reference_api": [
            "setCachedDerivedKey",
            "equals",
            "createSCryptCrypto",
            "setCipherparams",
            "setIv",
            "encrypt",
            "generateRandomBytes",
            "generateMac",
            "createPBKDF2Crypto",
            "getValidDerivedKey",
            "setCipher",
            "bytesToHex"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "setCachedDerivedKey",
                "code": "private void setCachedDerivedKey(CachedDerivedKey cachedDerivedKey) {\n    this.cachedDerivedKey = cachedDerivedKey;\n  }"
            },
            {
                "name": "createSCryptCrypto",
                "code": "public static Crypto createSCryptCrypto(String password, byte[] origin) {\n    return createCrypto(password, origin, SCryptCrypto.SCRYPT, false);\n  }"
            },
            {
                "name": "setCipherparams",
                "code": "public void setCipherparams(CipherParams cipherparams) {\n    this.cipherparams = cipherparams;\n  }"
            },
            {
                "name": "encrypt",
                "code": "private byte[] encrypt(byte[] derivedKey, byte[] iv, byte[] text) {\n\n    byte[] encryptKey = Arrays.copyOfRange(derivedKey, 0, 16);\n\n    if (CTR.equals(cipher)) {\n      return AES.encryptByCTRNoPadding(text, encryptKey, iv);\n    } else {\n      return AES.encryptByCBCNoPadding(text, encryptKey, iv);\n    }\n  }"
            },
            {
                "name": "createPBKDF2Crypto",
                "code": "public static Crypto createPBKDF2Crypto(String password, byte[] origin) {\n    return createCrypto(password, origin, PBKDF2Crypto.PBKDF2, false);\n  }"
            },
            {
                "name": "getValidDerivedKey",
                "code": "private byte[] getValidDerivedKey(String password) {\n    byte[] derivedKey = generateDerivedKey(password.getBytes());\n    if (this.mac == null) return derivedKey;\n    byte[] mac = NumericUtil.hexToBytes(this.mac);\n    byte[] cipherText = NumericUtil.hexToBytes(getCiphertext());\n\n    byte[] derivedMac = Hash.generateMac(derivedKey, cipherText);\n    if (Arrays.equals(derivedMac, mac)) {\n      return derivedKey;\n    } else {\n      throw new TokenException(Messages.WALLET_INVALID_PASSWORD);\n    }\n  }"
            },
            {
                "name": "setCipher",
                "code": "public void setCipher(String cipher) {\n    this.cipher = cipher;\n  }"
            }
        ],
        "third_party": [
            "setIv",
            "generateRandomBytes",
            "generateMac",
            "bytesToHex"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "private byte[] encrypt(byte[] derivedKey, byte[] iv, byte[] text)",
        "start_line": "157",
        "end_line": "166",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/Crypto.java",
        "docstring": "The function encrypt takes a derived key, an initialization vector (iv), and the plaintext (text) as input.\\nIt extracts the encryption key from the first 16 bytes of the derived key.\\nDepending on the cipher mode (CTR or CBC), it encrypts the plaintext using either AES encryption in CTR mode or CBC mode without padding.\\nIt returns the resulting encrypted byte array.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "997edf06074c",
        "ground_truth": "private byte[] encrypt(byte[] derivedKey, byte[] iv, byte[] text) {\n  byte[] encryptKey = Arrays.copyOfRange(derivedKey, 0, 16);\n  if (CTR.equals(cipher)) {\n    return AES.encryptByCTRNoPadding(text, encryptKey, iv);\n  } else {\n    return AES.encryptByCBCNoPadding(text, encryptKey, iv);\n  }\n}",
        "import_statements": [
            "import org.consenlabs.tokencore.foundation.utils.CachedDerivedKey;",
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import com.fasterxml.jackson.annotation.JsonIgnore;",
            "import com.fasterxml.jackson.annotation.JsonProperty;",
            "import com.fasterxml.jackson.annotation.JsonSubTypes;",
            "import com.fasterxml.jackson.annotation.JsonTypeInfo;",
            "import com.google.common.base.Strings;",
            "import java.util.Arrays;"
        ],
        "reference_api": [
            "copyOfRange",
            "encryptByCTRNoPadding",
            "equals",
            "encryptByCBCNoPadding"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "copyOfRange",
            "encryptByCTRNoPadding",
            "encryptByCBCNoPadding"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public static byte[] merkleHash(byte[] oriData)",
        "start_line": "80",
        "end_line": "102",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/Hash.java",
        "docstring": "The function merkleHash computes the Merkle root hash of the given data.\\nIt takes a byte array oriData as input and checks if it is null or empty, throwing an exception if so.\\nIt processes the data in chunks of 1024 bytes, hashing each chunk twice using SHA-256 and storing the hashes in a list.\\nIn a loop, it pairs adjacent hashes, concatenates them, and hashes the concatenated result twice using SHA-256, adding the new hashes back to the list.\\nThis process continues until a single hash remains, which is the Merkle root.\\nThe function returns the final hash.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "269f911c6089",
        "ground_truth": "public static byte[] merkleHash(byte[] oriData) {\n  if (oriData == null || oriData.length == 0) {\n    throw new IllegalArgumentException(\"data should not be null\");\n  }\n  int chunkSize = 1024;\n  List<byte[]> hashes = new ArrayList<>();\n  for (int pos = 0; pos < oriData.length; pos += chunkSize) {\n    int end = Math.min(pos + chunkSize, oriData.length);\n    hashes.add(Sha256Hash.hashTwice(Arrays.copyOfRange(oriData, pos, end)));\n  }\n  int j = 0;\n  for (int size = hashes.size(); size > 1; size = (size + 1) / 2) {\n    for (int i = 0; i < size; i += 2) {\n      int i2 = Math.min(i + 1, size - 1);\n      hashes.add(Sha256Hash.hashTwice(ByteUtil.concat(hashes.get(j + i), hashes.get(j + i2))));\n    }\n    j += size;\n  }\n  return hashes.get(hashes.size() - 1);\n}",
        "import_statements": [
            "import org.bitcoinj.core.Sha256Hash;",
            "import org.consenlabs.tokencore.foundation.utils.ByteUtil;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import java.security.InvalidKeyException;",
            "import java.security.MessageDigest;",
            "import java.security.NoSuchAlgorithmException;",
            "import java.util.ArrayList;",
            "import java.util.Arrays;",
            "import java.util.List;",
            "import javax.crypto.Mac;",
            "import javax.crypto.spec.SecretKeySpec;"
        ],
        "reference_api": [
            "copyOfRange",
            "min",
            "size",
            "concat",
            "get",
            "add",
            "hashTwice"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "copyOfRange",
            "min",
            "size",
            "concat",
            "get",
            "add",
            "hashTwice"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public Multihash(Type type, byte[] hash)",
        "start_line": "46",
        "end_line": "53",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/Multihash.java",
        "docstring": "The constructor Multihash initializes a Multihash object with a given Type and hash byte array.\\nIt first checks if the length of the hash exceeds 127 bytes and throws an IllegalStateException if it does.\\nNext, it verifies if the hash length matches the expected length for the provided Type, throwing an IllegalStateException if they do not match.\\nIf both checks pass, it assigns the provided Type and hash to the instance variables.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "4175a53e410f",
        "ground_truth": "public Multihash(Type type, byte[] hash) {\n  if (hash.length > 127)\n    throw new IllegalStateException(\"Unsupported hash size: \"+hash.length);\n  if (hash.length != type.length)\n    throw new IllegalStateException(\"Incorrect hash length: \" + hash.length + \" != \"+type.length);\n  this.type = type;\n  this.hash = hash;\n}",
        "import_statements": [
            "import org.bitcoinj.core.Base58;",
            "import java.io.ByteArrayOutputStream;",
            "import java.io.DataInput;",
            "import java.io.DataOutput;",
            "import java.io.IOException;",
            "import java.util.Arrays;",
            "import java.util.Map;",
            "import java.util.TreeMap;"
        ],
        "reference_api": [],
        "repo_defined_api_with_code": [],
        "third_party": []
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public String toHex()",
        "start_line": "103",
        "end_line": "112",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/Multihash.java",
        "docstring": "The function toHex converts a byte array to its hexadecimal string representation.\\nIt first converts the object's data to a byte array using toBytes().\\nIt then initializes a char array twice the length of the byte array to hold the hexadecimal characters.\\nFor each byte, it extracts the high and low nibble (4 bits) and maps them to their corresponding hexadecimal character from hexArray.\\nThe characters are placed in the appropriate positions in the char array.\\nFinally, the function returns a new String object created from the char array.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "917567b136cd",
        "ground_truth": "public String toHex() {\n  byte[] bytes = toBytes();\n  char[] hexChars = new char[bytes.length * 2];\n  for ( int j = 0; j < bytes.length; j++ ) {\n    int v = bytes[j] & 0xFF;\n    hexChars[j * 2] = hexArray[v >>> 4];\n    hexChars[j * 2 + 1] = hexArray[v & 0x0F];\n  }\n  return new String(hexChars);\n}",
        "import_statements": [
            "import org.bitcoinj.core.Base58;",
            "import java.io.ByteArrayOutputStream;",
            "import java.io.DataInput;",
            "import java.io.DataOutput;",
            "import java.io.IOException;",
            "import java.util.Arrays;",
            "import java.util.Map;",
            "import java.util.TreeMap;"
        ],
        "reference_api": [
            "toBytes"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "toBytes",
                "code": "private byte[] toBytes() {\n    byte[] res = new byte[hash.length+2];\n    res[0] = (byte)type.index;\n    res[1] = (byte)hash.length;\n    System.arraycopy(hash, 0, res, 2, hash.length);\n    return res;\n  }"
            }
        ],
        "third_party": []
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public static PBKDF2Crypto createPBKDF2Crypto()",
        "start_line": "22",
        "end_line": "29",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/PBKDF2Crypto.java",
        "docstring": "The function createPBKDF2Crypto initializes a PBKDF2Crypto object.\\nIt generates a random byte array of length SALT_LENGTH for the salt.\\nA PBKDF2Params object is created and the salt is set in hexadecimal format.\\nThe PBKDF2Params object is then assigned to the kdfparams field of the PBKDF2Crypto object.\\nFinally, the PBKDF2Crypto object is returned.\n",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "8aeb21b5828b",
        "ground_truth": "public static PBKDF2Crypto createPBKDF2Crypto() {\n  PBKDF2Crypto crypto = new PBKDF2Crypto();\n  byte[] salt = NumericUtil.generateRandomBytes(SALT_LENGTH);\n  PBKDF2Params pbkdf2Params = PBKDF2Params.createPBKDF2Params();\n  pbkdf2Params.setSalt(NumericUtil.bytesToHex(salt));\n  crypto.kdfparams = pbkdf2Params;\n  return crypto;\n}",
        "import_statements": [
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import org.spongycastle.crypto.digests.SHA256Digest;",
            "import org.spongycastle.crypto.generators.PKCS5S2ParametersGenerator;",
            "import org.spongycastle.crypto.params.KeyParameter;"
        ],
        "reference_api": [
            "bytesToHex",
            "createPBKDF2Params",
            "setSalt",
            "generateRandomBytes"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "bytesToHex",
            "createPBKDF2Params",
            "setSalt",
            "generateRandomBytes"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public byte[] generateDerivedKey(byte[] password)",
        "start_line": "32",
        "end_line": "41",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/crypto/PBKDF2Crypto.java",
        "docstring": "The function generateDerivedKey generates a derived key from a given password using PBKDF2 with SHA-256.\\nIt retrieves PBKDF2 parameters and checks if the PRF (pseudo-random function) is supported.\\nIf the PRF is not supported, it throws a TokenException.\\nIt initializes a PKCS5S2ParametersGenerator with SHA-256 digest and sets the password, salt, and iteration count for key derivation.\\nFinally, it generates and returns the derived key as a byte array.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "187ddab8057d",
        "ground_truth": "public byte[] generateDerivedKey(byte[] password) {\n  PBKDF2Params params = this.kdfparams;\n  if (!PBKDF2Params.PRF.equals(params.getPrf())) {\n    throw new TokenException(Messages.PRF_UNSUPPORTED);\n  }\n  PKCS5S2ParametersGenerator generator = new PKCS5S2ParametersGenerator(new SHA256Digest());\n  generator.init(password, NumericUtil.hexToBytes(params.getSalt()), params.getC());\n  return ((KeyParameter) generator.generateDerivedParameters(256)).getKey();\n}",
        "import_statements": [
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import org.spongycastle.crypto.digests.SHA256Digest;",
            "import org.spongycastle.crypto.generators.PKCS5S2ParametersGenerator;",
            "import org.spongycastle.crypto.params.KeyParameter;"
        ],
        "reference_api": [
            "equals",
            "getC",
            "generateDerivedParameters",
            "init",
            "hexToBytes",
            "getKey",
            "getPrf",
            "getSalt"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "getC",
            "generateDerivedParameters",
            "init",
            "hexToBytes",
            "getKey",
            "getPrf",
            "getSalt"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "private static byte[] encode(byte[] bytesValue, int offset)",
        "start_line": "27",
        "end_line": "48",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/foundation/rlp/RlpEncoder.java",
        "docstring": "The encode function processes a byte array for encoding based on its length and offset.\\nIf the byte array has a single byte value within the range 0x00 to 0x7f and the offset equals STRING_OFFSET, it returns the original array.\\nFor byte arrays with lengths up to 55, it prepends a length byte and returns the result.\\nFor longer arrays, it encodes the length into a minimal byte array, prepends this length along with an offset byte, and returns the concatenated result.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "5534b0a0c9da",
        "ground_truth": "private static byte[] encode(byte[] bytesValue, int offset) {\n    if (bytesValue.length == 1\n            && offset == STRING_OFFSET\n            && bytesValue[0] >= (byte) 0x00\n            && bytesValue[0] <= (byte) 0x7f) {\n        return bytesValue;\n    } else if (bytesValue.length <= 55) {\n        byte[] result = new byte[bytesValue.length + 1];\n        result[0] = (byte) (offset + bytesValue.length);\n        System.arraycopy(bytesValue, 0, result, 1, bytesValue.length);\n        return result;\n    } else {\n        byte[] encodedStringLength = toMinimalByteArray(bytesValue.length);\n        byte[] result = new byte[bytesValue.length + encodedStringLength.length + 1];\n        result[0] = (byte) ((offset + 0x37) + encodedStringLength.length);\n        System.arraycopy(encodedStringLength, 0, result, 1, encodedStringLength.length);\n        System.arraycopy(\n                bytesValue, 0, result, encodedStringLength.length + 1, bytesValue.length);\n        return result;\n    }\n}",
        "import_statements": [
            "import org.consenlabs.tokencore.foundation.utils.ByteUtil;",
            "import java.util.Arrays;",
            "import java.util.List;"
        ],
        "reference_api": [
            "toMinimalByteArray",
            "arraycopy"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "toMinimalByteArray",
                "code": "private static byte[] toMinimalByteArray(int value) {\n        byte[] encoded = toByteArray(value);\n\n        for (int i = 0; i < encoded.length; i++) {\n            if (encoded[i] != 0) {\n                return Arrays.copyOfRange(encoded, i, encoded.length);\n            }\n        }\n\n        return new byte[]{ };\n    }"
            }
        ],
        "third_party": [
            "arraycopy"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public static Identity createIdentity(String name, String password, String passwordHit, String network, String segWit)",
        "start_line": "94",
        "end_line": "105",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/wallet/Identity.java",
        "docstring": "The function createIdentity creates a new Identity object with the provided parameters.\\nIt generates a list of random mnemonic codes using MnemonicUtil.randomMnemonicCodes().\\nIt then creates a Metadata object and sets its name, password hint, source, network, and segWit attributes.\\nAn Identity object is created using the Metadata object, the mnemonic codes, and the password.\\nThis new Identity object is assigned to the static variable currentIdentity and returned.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "c0b5affe3df5",
        "ground_truth": "public static Identity createIdentity(String name, String password, String passwordHit, String network, String segWit) {\n  List<String> mnemonicCodes = MnemonicUtil.randomMnemonicCodes();\n  Metadata metadata = new Metadata();\n  metadata.setName(name);\n  metadata.setPasswordHint(passwordHit);\n  metadata.setSource(Metadata.FROM_NEW_IDENTITY);\n  metadata.setNetwork(network);\n  metadata.setSegWit(segWit);\n  Identity identity = new Identity(metadata, mnemonicCodes, password);\n  currentIdentity = identity;\n  return identity;\n}",
        "import_statements": [
            "import com.fasterxml.jackson.annotation.JsonInclude;",
            "import com.fasterxml.jackson.databind.DeserializationFeature;",
            "import com.fasterxml.jackson.databind.MapperFeature;",
            "import com.fasterxml.jackson.databind.ObjectMapper;",
            "import org.bitcoinj.core.ECKey;",
            "import org.bitcoinj.core.Utils;",
            "import org.bitcoinj.core.VarInt;",
            "import org.consenlabs.tokencore.foundation.crypto.AES;",
            "import org.consenlabs.tokencore.foundation.crypto.Crypto;",
            "import org.consenlabs.tokencore.foundation.crypto.Hash;",
            "import org.consenlabs.tokencore.foundation.crypto.Multihash;",
            "import org.consenlabs.tokencore.foundation.utils.ByteUtil;",
            "import org.consenlabs.tokencore.foundation.utils.MnemonicUtil;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import org.consenlabs.tokencore.wallet.keystore.EOSKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.HDMnemonicKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.IMTKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.IdentityKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.V3MnemonicKeystore;",
            "import org.consenlabs.tokencore.wallet.model.BIP44Util;",
            "import org.consenlabs.tokencore.wallet.model.ChainType;",
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.Metadata;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.wallet.transaction.EthereumSign;",
            "import java.io.File;",
            "import java.io.IOException;",
            "import java.math.BigInteger;",
            "import java.nio.charset.Charset;",
            "import java.security.SignatureException;",
            "import java.util.ArrayList;",
            "import java.util.Arrays;",
            "import java.util.List;",
            "import java.util.Locale;"
        ],
        "reference_api": [
            "setSegWit",
            "setNetwork",
            "setSource",
            "setPasswordHint",
            "setName",
            "randomMnemonicCodes"
        ],
        "repo_defined_api_with_code": [],
        "third_party": [
            "setSegWit",
            "setNetwork",
            "setSource",
            "setPasswordHint",
            "setName",
            "randomMnemonicCodes"
        ]
    },
    {
        "subclass": "EOS",
        "owner/repo": "consenlabs/token-core-android",
        "function_declaration": "public List<Wallet> deriveWallets(List<String> chainTypes, String password)",
        "start_line": "155",
        "end_line": "179",
        "file_path": "app/src/main/java/org/consenlabs/tokencore/wallet/Identity.java",
        "docstring": "The deriveWallets function generates a list of Wallet objects for specified blockchain types using a given password.\\nIt first exports the identity to obtain a mnemonic phrase and splits it into individual words.\\nFor each chain type in the input list, it derives the corresponding wallet using the appropriate method for Bitcoin, Ethereum, or EOS based on the chain type.\\nIf the chain type is unsupported, it throws an exception.\\nEach derived wallet is added to an internal collection and also to a list that is returned by the function.",
        "language": "Java",
        "created_time": "",
        "commit_sha": "",
        "instance_id": "20ebc9ef21ad",
        "ground_truth": "public List<Wallet> deriveWallets(List<String> chainTypes, String password) {\n  List<Wallet> wallets = new ArrayList<>();\n  String mnemonic = exportIdentity(password);\n  List<String> mnemonics = Arrays.asList(mnemonic.split(\" \"));\n  for (String chainType : chainTypes) {\n    Wallet wallet;\n    switch (chainType) {\n      case ChainType.BITCOIN:\n        wallet = deriveBitcoinWallet(mnemonics, password, this.getMetadata().getSegWit());\n        break;\n      case ChainType.ETHEREUM:\n        wallet = deriveEthereumWallet(mnemonics, password);\n        break;\n      case ChainType.EOS:\n        wallet = deriveEOSWallet(mnemonics, password);\n        break;\n        default:\n          throw new TokenException(String.format(\"Doesn't support deriving %s wallet\", chainType));\n    }\n    addWallet(wallet);\n    wallets.add(wallet);\n  }\n  return wallets;\n}",
        "import_statements": [
            "import com.fasterxml.jackson.annotation.JsonInclude;",
            "import com.fasterxml.jackson.databind.DeserializationFeature;",
            "import com.fasterxml.jackson.databind.MapperFeature;",
            "import com.fasterxml.jackson.databind.ObjectMapper;",
            "import org.bitcoinj.core.ECKey;",
            "import org.bitcoinj.core.Utils;",
            "import org.bitcoinj.core.VarInt;",
            "import org.consenlabs.tokencore.foundation.crypto.AES;",
            "import org.consenlabs.tokencore.foundation.crypto.Crypto;",
            "import org.consenlabs.tokencore.foundation.crypto.Hash;",
            "import org.consenlabs.tokencore.foundation.crypto.Multihash;",
            "import org.consenlabs.tokencore.foundation.utils.ByteUtil;",
            "import org.consenlabs.tokencore.foundation.utils.MnemonicUtil;",
            "import org.consenlabs.tokencore.foundation.utils.NumericUtil;",
            "import org.consenlabs.tokencore.wallet.keystore.EOSKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.HDMnemonicKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.IMTKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.IdentityKeystore;",
            "import org.consenlabs.tokencore.wallet.keystore.V3MnemonicKeystore;",
            "import org.consenlabs.tokencore.wallet.model.BIP44Util;",
            "import org.consenlabs.tokencore.wallet.model.ChainType;",
            "import org.consenlabs.tokencore.wallet.model.Messages;",
            "import org.consenlabs.tokencore.wallet.model.Metadata;",
            "import org.consenlabs.tokencore.wallet.model.TokenException;",
            "import org.consenlabs.tokencore.wallet.transaction.EthereumSign;",
            "import java.io.File;",
            "import java.io.IOException;",
            "import java.math.BigInteger;",
            "import java.nio.charset.Charset;",
            "import java.security.SignatureException;",
            "import java.util.ArrayList;",
            "import java.util.Arrays;",
            "import java.util.List;",
            "import java.util.Locale;"
        ],
        "reference_api": [
            "deriveEOSWallet",
            "format",
            "addWallet",
            "split",
            "exportIdentity",
            "getSegWit",
            "getMetadata",
            "asList",
            "add",
            "deriveBitcoinWallet",
            "deriveEthereumWallet"
        ],
        "repo_defined_api_with_code": [
            {
                "name": "deriveEOSWallet",
                "code": "private Wallet deriveEOSWallet(List<String> mnemonics, String password) {\n    Metadata metadata = new Metadata();\n    metadata.setChainType(ChainType.EOS);\n    metadata.setPasswordHint(this.getMetadata().getPasswordHint());\n    metadata.setSource(this.getMetadata().getSource());\n    metadata.setName(\"EOS\");\n    IMTKeystore keystore = EOSKeystore.create(metadata, password, \"\", mnemonics, BIP44Util.EOS_LEDGER, null);\n    return WalletManager.createWallet(keystore);\n  }"
            },
            {
                "name": "addWallet",
                "code": "public void addWallet(Wallet wallet) {\n    this.keystore.getWalletIDs().add(wallet.getId());\n    this.wallets.add(wallet);\n    flush();\n  }"
            },
            {
                "name": "exportIdentity",
                "code": "public String exportIdentity(String password) {\n    return this.keystore.decryptMnemonic(password);\n  }"
            },
            {
                "name": "getMetadata",
                "code": "public Metadata getMetadata() {\n    return keystore.getMetadata();\n  }"
            },
            {
                "name": "deriveBitcoinWallet",
                "code": "private Wallet deriveBitcoinWallet(List<String> mnemonicCodes, String password, String segWit) {\n    Metadata walletMetadata = new Metadata();\n    walletMetadata.setChainType(ChainType.BITCOIN);\n    walletMetadata.setPasswordHint(this.getMetadata().getPasswordHint());\n    walletMetadata.setSource(this.getMetadata().getSource());\n    walletMetadata.setNetwork(this.getMetadata().getNetwork());\n    walletMetadata.setName(\"BTC\");\n    walletMetadata.setSegWit(segWit);\n    String path;\n    if (Metadata.P2WPKH.equals(segWit)) {\n      path =  this.getMetadata().isMainNet() ? BIP44Util.BITCOIN_SEGWIT_MAIN_PATH : BIP44Util.BITCOIN_SEGWIT_TESTNET_PATH;\n    } else {\n      path = this.getMetadata().isMainNet() ? BIP44Util.BITCOIN_MAINNET_PATH : BIP44Util.BITCOIN_TESTNET_PATH;\n    }\n\n    IMTKeystore keystore = HDMnemonicKeystore.create(walletMetadata, password, mnemonicCodes, path);\n    return WalletManager.createWallet(keystore);\n  }"
            },
            {
                "name": "deriveEthereumWallet",
                "code": "private Wallet deriveEthereumWallet(List<String> mnemonics, String password) {\n    Metadata walletMetadata = new Metadata();\n    walletMetadata.setChainType(ChainType.ETHEREUM);\n    walletMetadata.setPasswordHint(this.getMetadata().getPasswordHint());\n    walletMetadata.setSource(this.getMetadata().getSource());\n    walletMetadata.setName(\"ETH\");\n    IMTKeystore keystore = V3MnemonicKeystore.create(walletMetadata, password, mnemonics, BIP44Util.ETHEREUM_PATH);\n    return WalletManager.createWallet(keystore);\n  }"
            }
        ],
        "third_party": [
            "getSegWit",
            "asList",
            "add"
        ]
    }
]