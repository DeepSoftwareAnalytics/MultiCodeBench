{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    # Check if a cached model is available and valid\n    cache_path = self.cache_path / f'{self.model_name}.pt'\n    if cache_path.exists() and torch.load(cache_path).get('model_name') == self.model_name:\n        print(f'Loading cached model from {cache_path}')\n        model = torch.load(cache_path, map_location='cpu')['model']\n        model.eval()\n        model.half() if half_attention else model.float()\n        model.to(self.device)\n        model.half() if half_attention else model.float()\n        model.to(self.device)\n        return model\n\n    # Load the model from the specified path\n    model = self.load_model_from_path(half_attention)\n\n    # Cache the loaded model for future use\n    if self.cache_path.exists():\n        torch.save({'model_name': self.model_name, 'model': model}, cache_path)\n        print(f'Cached model saved to {cache_path}')\n\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.86042332144464}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.model_path.endswith(\".safetensors\"):\n        if self.model_path.startswith(\"http\"):\n            model_path = self.model_path\n        else:\n            model_path = self.model_path.replace(\"models\", \"models_cache\")\n        if os.path.exists(model_path):\n            model = torch.load(model_path, map_location=\"cpu\")\n            print(f\"Loaded model from cache: {model_path}\")\n        else:\n            model = torch.hub.load_state_dict_from_url(\n                self.model_path, map_location=\"cpu\"\n            )\n            print(f\"Loaded model from url: {self.model_path}\")\n            torch.save(model, model_path)\n            print(f\"Saved model to cache: {model_path}\")\n    else:\n        model = torch.load(self.model_path, map_location=\"cpu\")\n        print(f\"Loaded model from path: {self.model_path}\")\n\n    if \"state_dict\" in model:\n        model = model[\"state_dict\"]\n\n    if \"global_step\" in model:\n        del model[\"global_step\"]\n\n    model = model.float()\n    model.eval()\n\n    if half_attention:\n        model.half()\n\n    if self.device == \"cuda\":\n        model.to(torch.device(\"cuda\"))\n\n    model_config = OmegaConf.load(self.config)\n    model_config.model.params.attention_implementation = \"torch_fused_add_norm\"\n    model_config.model.params.attention_dropout = 0.0\n    model_config.model.params.attention_softmax_in_fp32 = True\n    model_config.model.params.attention_query_channels = None\n    model_config.model.params.attention_key_channels = None\n    model_config.model.params.attention_head_channels = None\n    model_config.model.params.attention_out_ch", "CodeBleu_score": 39.00160927478725}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.cache_models:\n        if self.model_cache_path.exists():\n            try:\n                model_cache = torch.load(self.model_cache_path)\n                if model_cache['config'] == self.model_config_path:\n                    self.logger.info(f\"Loading model from cache: {self.model_cache_path}\")\n                    model = model_cache['model']\n                    if half_attention:\n                        model.half()\n                    model.eval()\n                    model.to(self.device)\n                    return {'model': model}\n            except Exception as e:\n                self.logger.warning(f\"Error loading model from cache: {e}\")\n\n    self.logger.info(f\"Loading model from path: {self.model_path}\")\n    model = self.load_model_from_path(self.model_path, half_attention)\n    model.eval()\n    model.to(self.device)\n\n    if self.cache_models:\n        self.logger.info(f\"Caching model: {self.model_cache_path}\")\n        torch.save({'model': model, 'config': self.model_config_path}, self.model_cache_path)\n\n    return {'model': model}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.45082825119293}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    # Initialize sampler\n    sampler = DDIMSampler(model)\n    print(f\"eta: {eta}, steps: {steps}\")\n\n    # Sample from the model\n    batch_size = shape[0]\n    samples, intermediates = sampler.sample(\n        S=steps,\n        batch_size=batch_size,\n        shape=shape,\n        conditioning=cond,\n        eta=eta,\n        callback=callback,\n        normals_sequence=normals_sequence,\n        mask=mask,\n        x0=x0,\n        quantize_x0=quantize_x0,\n        temperature=temperature,\n        score_corrector=score_corrector,\n        corrector_kwargs=corrector_kwargs,\n        x_T=x_t,\n    )\n\n    # Return samples and intermediates\n    return samples, intermediates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.63325454405312}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    print(f'sampling {batch_size * steps} steps for {batch_size} samples')\n    model.to(device)\n    eta = model.num_timesteps / steps\n    print(f'eta = {eta}')\n    sampler = DDIMSampler(model)\n    return sampler.sample(\n        S=steps,\n        batch_size=batch_size,\n        shape=shape,\n        conditioning=cond,\n        eta=eta,\n        callback=callback,\n        normals_sequence=normals_sequence,\n        mask=mask,\n        x0=x0,\n        quantize_x0=quantize_x0,\n        temperature=temperature,\n        score_corrector=score_corrector,\n        corrector_kwargs=corrector_kwargs,\n        x_T=x_t,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.4646405093411}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n\n    # Initialize the sampler with the model and extract the batch size from the shape parameter.\n    sampler = DDIMSampler(model)\n    batch_size = shape[0]\n    print(f'eta: {eta}, steps: {steps}')\n\n    # Call the sample method of the DDIMSampler instance, passing several parameters.\n    # The parameters include steps, batch size, shape, conditioning, eta, and other optional arguments.\n    # The function returns the generated samples and intermediate values.\n    return sampler.sample(\n        S=steps,\n        batch_size=batch_size,\n        shape=shape,\n        conditioning=cond,\n        eta=eta,\n        callback=callback,\n        normals_sequence=normals_sequence,\n        mask=mask,\n        x0=x0,\n        quantize_x0=quantize_x0,\n        temperature=temperature,\n        score_corrector=score_corrector,\n        corrector_kwargs=corrector_kwargs,\n        x_T=x_t,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.36489103304615}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = \"EMA\"\n    self.ema_weights = self.weights\n    self.weights = self.ema_weights\n    if self.verbose:\n        print(f\"{context} weights activated\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.196430134176154}, {"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema_enabled:\n        return\n    if context is None:\n        context = self.context\n    self.ema_enabled = True\n    if context is not None:\n        context.print_status(\"Switching to EMA weights\")\n    self.ema_weights = self.model.get_weights()\n    self.model.set_weights(self.ema_weights)\n    if context is not None:\n        context.print_status(\"Switched to EMA weights\")\n    yield\n    if context is not None:\n        context.print_status(\"Restoring original weights\")\n    self.model.set_weights(self.original_weights)\n    if context is not None:\n        context.print_status(\"Restored original weights\")\n\n", "CodeBleu_score": 40.55990440206864}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        if context:\n            context.print_verbose(\"Using EMA weights\")\n        self.ema_model.eval()\n        self.model.eval()\n        with torch.no_grad():\n            for param_ema, param in zip(self.ema_model.parameters(), self.model.parameters()):\n                param_ema.copy_(param)\n        if context:\n            context.print_verbose(\"EMA weights are now active\")\n    else:\n        if context:\n            context.print_verbose(\"EMA weights are not active\")\n\n", "CodeBleu_score": 45.07952990356622}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    keys = list(sd.keys())\n    for k in keys:\n        if k.startswith(\"model.\"):\n            sd.pop(k)\n    missing, unexpected = self.load_state_dict(sd, strict=False)\n    if len(missing) > 0 and ignore_keys is None:\n        raise RuntimeError(\n            \"Missing keys in state_dict: {}\".format(\", \".join(missing))\n        )\n    if len(unexpected) > 0:\n        print(\"Unexpected keys in state_dict: {}\".format(\", \".join(unexpected)))\n    if ignore_keys is not None:\n        for k in ignore_keys:\n            if k in sd:\n                sd.pop(k)\n        self.load_state_dict(sd, strict=False)\n    return sd\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.316466067967774}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    sd = {k.startswith(\"model.\"): k: v for k, v in sd.items()}\n    if ignore_keys is not None:\n        sd = {k: v for k, v in sd.items() if k not in ignore_keys}\n    self.load_state_dict(sd, strict=False)\n    missing_keys = []\n    unexpected_keys = []\n    for k, v in self.state_dict().items():\n        if k not in sd:\n            missing_keys.append(k)\n        elif v.shape != sd[k].shape:\n            unexpected_keys.append(k)\n    if len(missing_keys) > 0:\n        print(\"missing keys: {}\".format(missing_keys))\n    if len(unexpected_keys) > 0:\n        print(\"unexpected keys: {}\".format(unexpected_keys))\n    return", "CodeBleu_score": 42.04440948559629}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    sd = {k.startswith(\"module.\"): k.split(\"module.\", 1)[1]: v for k, v in sd.items()}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"diffusion_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n    sd = {k: v for k, v in sd.items() if not k.startswith(\"clip_model.\")}\n", "CodeBleu_score": 18.16228017995466}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, diff, _ = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, diff, quant.argmax(dim=1)\n    else:\n        return dec, diff\n\n", "CodeBleu_score": 47.36647066506015}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, diff, _ = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, diff, quant.argmax(dim=1)\n    return dec, diff\n\n", "CodeBleu_score": 51.11803920600423}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, diff, _ = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, diff, quant.permute(0, 2, 3, 1).contiguous(), quant\n    else:\n        return dec, diff\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.843586704698524}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(1)\n    if len(x.shape) == 2:\n        x = x.unsqueeze(0).unsqueeze(0)\n    if len(x.shape) == 1:\n        x = x.unsqueeze(0).unsqueeze(0).unsqueeze(0)\n    if x.shape[1] == 1:\n        x = x.expand(-1, 3, -1, -1)\n    if self.resize_data:\n        x = F.interpolate(x, size=(self.resize_h, self.resize_w), mode='bicubic', align_corners=True)\n    x = x.permute(0, 3, 2, 1).contiguous().float()\n    if self.resize_data:\n        x = x[0:1]\n    return x.detach()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.71712262363443}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(1)\n    x = x.permute(0, 3, 1, 2)\n    x = x.float()\n    if self.batch_resize:\n        x = F.interpolate(x, size=(int(self.h * self.scale_range[0] + self.h * self.scale_range[1] * (self.step / self.n_steps)), int(self.w * self.scale_range[0] + self.w * self.scale_range[1] * (self.step / self.n_steps))), mode='bicubic')\n    x = x.contiguous()\n    x = x.detach()\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.09911094473334}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(1)\n    if len(x.shape) == 4:\n        x = x.permute(0, 3, 1, 2)\n    x = F.interpolate(x, size=(self.img_size, self.img_size), mode='bicubic', align_corners=False)\n    if self.batch_size is not None:\n        if self.training:\n            if self.batch_size_range is not None:\n                batch_size = self.batch_size + np.random.randint(self.batch_size_range)\n            else:\n                batch_size = self.batch_size\n            x = x[:batch_size]\n    x = x.contiguous().float()\n    x = x.detach()\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.3492251128773}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, \"image\")\n    y = self.get_input(batch, \"label\")\n    x_hat = self(x)\n    if self.loss == \"autoencoding\":\n        loss = self.autoencoding_loss(x_hat, x)\n    elif self.loss == \"discriminator\":\n        loss = self.discriminator_loss(x, x_hat, y)\n    else:\n        raise ValueError(f\"Invalid loss type: {self.loss}\")\n    self.log_dict({\"train_loss\": loss})\n    return loss", "CodeBleu_score": 18.630628396158617}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, \"image\")\n    y_pred = self.forward(x)\n    if optimizer_idx == 0:\n        loss = self.autoencoder_loss(y_pred, x)\n        self.log(\"train/autoencoder_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n    else:\n        loss = self.discriminator_loss(y_pred, x)\n        self.log(\"train/discriminator_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n        return loss\n\n", "CodeBleu_score": 24.782026603075284}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, \"input\")\n    x_rec = self.get_input(batch, \"target\")\n    y_hat = self(x)\n    y_hat_rec = self(y_hat)\n    if optimizer_idx == 0:\n        loss = self.loss(y_hat_rec, x_rec)\n    else:\n        loss = self.loss(y_hat, x)\n    self.log_dict({\"loss\": loss, \"lr\": self.get_last_layer().detach().abs().mean()})\n    return loss\n\n", "CodeBleu_score": 21.35207207422898}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    if self.global_step % self.log_interval == 0:\n        x = self.get_input(batch, self.image_key)\n        if self.ema_scope:\n            with torch.no_grad():\n                y_ema = self.ema_model(x)\n                if self.ema_model.ema_scope == \"model\":\n                    y_ema = y_ema.ema_model(x)\n                if self.ema_model.ema_scope == \"model_and_input\":\n                    y_ema = y_ema.ema_model(y_ema.ema_input)\n        if not only_inputs:\n            y = self.model(x)\n            if self.ema_scope:\n                y_ema = self.ema_model(x)\n                if self.ema_model.ema_scope == \"model\":\n                    y_ema = y_ema.ema_model(x)\n                if self.ema_model.ema_scope == \"model_and_input\":\n                    y_ema = y_ema.ema_model(y_ema.ema_input)\n            if plot_ema:\n                y_ema = y_ema.detach()\n            if self.image_key == \"segmentation\":\n                y = self.to_rgb(y)\n                y_ema = self.to_rgb(y_ema)\n            if self.image_key == \"segmentation\":\n                y = self.to_rgb(y)\n                y_ema = self.to_rgb(y_ema)\n            if self.image_key == \"segmentation\":\n                y = self.to_rgb(y)\n                y_ema = self.to_rgb(y_ema)\n            if self.image_key == \"segmentation\":\n                y = self.to_rgb(y)\n                y_ema = self.to_rgb(y_ema)\n            if self.image_key == \"segmentation\":\n                y = self.to_rgb(y)\n                y_ema = self.to_rgb(y_ema)\n            if self.image_key == \"segmentation\":", "CodeBleu_score": 31.687438777570957}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    if not self.log_images:\n        return\n    if self.ema_scope is not None and not plot_ema:\n        return\n    if self.ema_scope is not None and plot_ema:\n        ema_model = self.ema_model\n        if ema_model is None:\n            return\n    if only_inputs:\n        return self.log_inputs(batch, **kwargs)\n    x = self.get_input(batch, self.image_key)\n    if self.ema_scope is not None and plot_ema:\n        with torch.no_grad():\n            ema_model.eval()\n            ema_model.to(x.device)\n            z, _, _ = ema_model.encode(x)\n            x_rec = ema_model.decode(z)\n            x_rec = x_rec.clamp(-1., 1.)\n    else:\n        z, _, _ = self.encode(x)\n        x_rec = self.decode(z)\n        x_rec = x_rec.clamp(-1., 1.)\n    x = x.clamp(-1., 1.)\n    if self.ema_scope is not None and plot_ema:\n        x_rec = x_rec.detach()\n    if x.shape[1] > 3:\n        x = self.to_rgb(x)\n        x_rec = self.to_rgb(x_rec)\n    if self.ema_scope is not None and plot_ema:\n        x_rec = x_rec.detach()\n    if self.ema_scope is not None and plot_ema:\n        with torch.no_grad():\n            ema_model.train()\n    self.logger.experiment.add_images(f\"{self.ema_scope}/{self.image_key}\", x, self.global_step, dataformats=\"NCHW\")\n    self.logger.experiment.add_images(f\"{self.ema_scope}/{self.image_key}_rec\", x_rec, self.global_step, dataformats=\"NCHW\")\n\n", "CodeBleu_score": 36.74451329961156}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x = self.get_input(batch, self.image_key)\n    if not only_inputs:\n        with torch.no_grad():\n            z = self.encode(x)\n            if plot_ema:\n                x_recon = self.ema_reconstruction(z)\n                x_recon = self.to_rgb(x_recon)\n                x_recon = self.ema_scope(x_recon)\n                self.ema_reconstruction.update_moving_average(self.ema_scope.ema_model.state_dict())\n            else:\n                x_recon = self.decode(z)\n                x_recon = self.to_rgb(x_recon)\n        self.logger.experiment.add_image(\"reconstruction\", make_grid(x_recon, nrow=self.num_samples), self.global_step)\n    x = self.to_rgb(x)\n    self.logger.experiment.add_image(\"input\", make_grid(x, nrow=self.num_samples), self.global_step)\n\n", "CodeBleu_score": 34.13872507581049}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise NotImplementedError(f\"Unknown loss type: {self.loss_type}\")\n\n", "CodeBleu_score": 34.7862885893028}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.10958011683423}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise NotImplementedError\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.16912388958236}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.training:\n        self.model.train()\n    else:\n        self.model.eval()\n\n    if self.cond_stage_model.training:\n        self.cond_stage_model.train()\n    else:\n        self.cond_stage_model.eval()\n\n    if self.cond_stage_model.parameterization == 'none':\n        c = None\n\n    # Sample time steps for each sample in the batch\n    if self.training:\n        shape = (x.shape[0],) + (1,) * (x.ndim - 1)\n        t = torch.randint(0, self.num_timesteps, shape, device=x.device).long()\n    else:\n        t = torch.full((x.shape[0],), self.num_timesteps - 1, dtype=torch.long, device=x.device)\n\n    # If the model has a forward function, use it\n    if hasattr(self.model, 'forward'):\n        x_in = self.model.forward(x, t, c)\n    else:\n        x_in = self.model(x, t, c)\n\n    # Compute the loss\n    loss, loss_dict = self.p_losses(x_in, t)\n\n    # If the model has a backward function, use it\n    if hasattr(self.model, 'backward'):\n        x_recon = self.model.backward(x_in, t, c)\n    else:\n        x_recon = self.model(x_in, t, c)\n\n    # Compute the VLB loss\n    if self.vlb_weight > 0:\n        vlb_loss, vlb_loss_dict = self.vlb_losses(x_recon, x, t)\n        loss += self.vlb_weight * vlb_loss\n        loss_dict.update(vlb_loss_dict)\n\n    # Compute the VLB loss\n    if self.vlb_weight > 0:\n        vlb_loss, vlb_loss_dict = self.vlb_losses(x", "CodeBleu_score": 39.16921489936942}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.cond_stage_model is not None:\n        c = self.get_learned_conditioning(c)\n\n    if self.cond_stage_model is None or self.cond_stage_forward is None:\n        assert x.shape[0] == c.shape[0]\n        x_in = x\n    else:\n        x_in = self.cond_stage_model.get_input(x, c)\n\n    if self.model_type == 'mddpm':\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device)\n        return self.mddpm_losses(x_in, t, c, *args, **kwargs)\n    elif self.model_type == 'ddpm':\n        return self.ddpm_losses(x_in, *args, **kwargs)\n    else:\n        raise NotImplementedError(f\"model_type {self.model_type} not yet supported\")\n\n", "CodeBleu_score": 46.1804091254202}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    batch_size = x.shape[0]\n    t = torch.randint(0, self.num_timesteps, (batch_size,), device=x.device)\n    c = self.get_learned_conditioning(c)\n    x_t = self.q_sample(x_start=x, t=t, noise=None)\n    model_output = self.model(x_t, t, c)\n    loss, loss_dict = self.p_losses(x_start=x, t=t, model_output=model_output)\n    return loss, loss_dict\n\n", "CodeBleu_score": 24.100772530558835}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    if self.codebook_dim == self.num_codebook_vecs:\n        codebook_indices = indices\n    else:\n        codebook_indices = self.unmap_to_all(indices)\n    z_q = self.embedding(codebook_indices)\n    if self.codebook_dim > self.num_codebook_vecs:\n        z_q = z_q[..., : self.num_codebook_vecs]\n    z_q = z_q.view(*shape)\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.80665996639825}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    if self.re_embed > self.used.shape[0]:  # extra token\n        indices[indices >= self.used.shape[0]] = 0  # simply set to zero\n    z_q = self.embedding(indices)\n    if self.remap_to_all:\n        z_q = self.unmap_to_all(indices)\n    if shape is not None:\n        z_q = z_q.view(shape)\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.439566403747236}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    indices = indices.reshape(-1)\n    if self.re_embed > self.used.shape[0]:  # extra token\n        indices[indices >= self.used.shape[0]] = 0  # simply set to zero\n    z_q = self.embedding.weight[indices]\n    z_q = z_q.view(shape)\n    z_q = z_q.permute(0, 3, 1, 2)\n    return z_q.contiguous()", "CodeBleu_score": 45.49528052495567}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        if factor > 0:\n            max_factor = factor\n        else:\n            max_factor = dimension\n        for m in range(1, max_factor + 1):\n            if dimension % m == 0:\n                n = dimension // m\n                if n <= m:\n                    return m, n\n        return 1, dimension\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.974852989953675}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if dimension == 1:\n        return 1, 1\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    if factor > 0:\n        return 1, dimension\n    m = n = dimension\n    while m * n != dimension:\n        m -= 1\n        n = dimension // m\n    return m, n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.88551303182694}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    if factor < 0:\n        m, n = 1, dimension\n        for i in range(2, int(dimension**0.5)+1):\n            if dimension % i == 0:\n                m, n = i, dimension // i\n                break\n        for i in range(2, int(dimension**0.5)+1):\n            if dimension % i == 0:\n                if i <= m:\n                    m, n = i, dimension // i\n                if m + n > factor:\n                    break\n        return m, n\n    return 1, dimension\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.51385338909772}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    # Ensure all tensors are on the same device and have the same data type\n    updown = updown.to(orig_weight.device).to(orig_weight.dtype)\n    orig_weight = orig_weight.to(updown.device).to(updown.dtype)\n\n    # Transpose and reshape the updown tensor\n    updown = updown.transpose(0, 1)\n    updown = updown.reshape(updown.shape[0], -1)\n\n    # Merge the updown and orig_weight tensors along the second dimension\n    merged_scale1 = torch.cat([updown, orig_weight], dim=1)\n\n    # Normalize the merged_scale1 tensor along the second dimension\n    norm = torch.norm(merged_scale1, dim=1, keepdim=True)\n    normed_merged_scale1 = merged_scale1 / norm\n\n    # Scale the normed_merged_scale1 tensor by the predefined scale factor\n    scale_factor = 0.2\n    scaled_normed_merged_scale1 = normed_merged_scale1 * scale_factor\n\n    # Calculate the final adjusted weight by subtracting the original weight from the scaled and normalized combined weight\n    adjusted_weight = scaled_normed_merged_scale1[:, :orig_weight.shape[1]] - orig_weight\n\n    return adjusted_weight", "CodeBleu_score": 33.351350198281494}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    self.updown.to(orig_weight.device)\n    self.updown.to(orig_weight.dtype)\n    self.orig_weight.to(orig_weight.device)\n    self.orig_weight.to(orig_weight.dtype)\n    self.transpose = self.updown.transpose(1, 0)\n    self.to = self.transpose.to(orig_weight.device)\n    self.to = self.transpose.to(orig_weight.dtype)\n    self.reshape = self.to.reshape(self.orig_weight.shape)\n    self.merged_scale1 = self.reshape + self.orig_weight\n    self.transpose = self.merged_scale1.transpose(1, 0)\n    self.to = self.transpose.to(orig_weight.device)\n    self.to = self.transpose.to(orig_weight.dtype)\n    self.reshape = self.to.reshape(self.orig_weight.shape)\n    self.norm = self.reshape / torch.norm(self.reshape)\n    self.scale_factor = self.norm * self.scale\n    self.scale_factor.to(orig_weight.device)\n    self.scale_factor.to(orig_weight.dtype)\n    self.subtract = self.scale_factor - self.orig_weight\n    self.subtract.to(orig_weight.device)\n    self.subtract.to(orig_weight.dtype)\n    return self.subtract\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.12836462938913}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    # Make sure all tensors are on the same device and have the same data type\n    updown = updown.to(orig_weight.device).to(orig_weight.dtype)\n    orig_weight = orig_weight.to(updown.device).to(updown.dtype)\n\n    # Combine the input weight and original weight\n    combined_weight = updown + orig_weight\n\n    # Normalize the combined weight\n    normalized_weight = combined_weight / torch.norm(combined_weight)\n\n    # Scale the normalized weight using a predefined scale factor\n    scaled_weight = self.scale_factor * normalized_weight\n\n    # Calculate the final adjusted weight by subtracting the original weight from the scaled and normalized combined weight\n    adjusted_weight = scaled_weight - orig_weight\n\n    return adjusted_weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.54751294983462}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    # Match the device/dtype\n    orig_weight = orig_weight.to(updown.dtype)\n    updown = updown.to(orig_weight.device)\n\n    # Apply bias\n    if ex_bias is not None:\n        updown += ex_bias\n\n    # Reshape updown\n    if updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n    else:\n        updown = updown.reshape(output_shape)\n\n    # Apply additional bias\n    if self.additional_bias is not None:\n        updown += self.additional_bias * self.multiplier\n\n    # Apply scaling factor\n    if self.scale is not None:\n        updown *= self.scale\n\n    # Apply weight decomposition\n    if self.dora_scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown, ex_bias\n\n", "CodeBleu_score": 55.49454981507525}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        ex_bias = ex_bias.to(orig_weight.dtype)\n        updown = updown + ex_bias\n\n    if self.bias is not None:\n        updown = updown + self.bias\n\n    if self.scale is not None:\n        updown = updown * self.scale\n\n    if self.dim is not None and self.alpha is not None:\n        updown = updown * self.alpha / self.dim\n\n    if self.apply_decompose:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    if updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n    else:\n        updown = updown.reshape(output_shape)\n\n    return updown, ex_bias\n\n", "CodeBleu_score": 57.41988582523293}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        updown = updown + ex_bias\n\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n    else:\n        updown = updown.reshape(output_shape)\n\n    if self.bias_multiplier is not None:\n        updown = updown * self.bias_multiplier\n\n    if self.scale is not None:\n        updown = updown * self.scale\n\n    if self.apply_weight_decompose:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown, updown\n\n", "CodeBleu_score": 52.22097574565419}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n    orig_weight = orig_weight.to(self.weight.device)\n    ex_bias = None\n    if self.bias is not None:\n        ex_bias = self.bias.to(self.weight.device)\n\n    if self.dora_scale is not None:\n        orig_weight = self.apply_weight_decompose(orig_weight, self.weight)\n\n    updown, ex_bias = self.finalize_updown(self.weight.to(orig_weight.device), orig_weight, self.weight.shape, ex_bias)\n\n    if self.dora_scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    if self.bias is not None:\n        ex_bias = ex_bias.to(self.weight.device)\n\n    return updown, ex_bias\n\n", "CodeBleu_score": 45.292953037461956}, {"code": "def calc_updown(self, orig_weight)\n\t\n    weight = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    bias = self.bias.to(orig_weight.device, dtype=orig_weight.dtype) if self.bias is not None else None\n\n    if self.dora_scale is not None:\n        weight = self.apply_weight_decompose(weight, orig_weight)\n\n    if self.dora_scale is not None and self.bias is not None:\n        bias = bias * self.multiplier()\n\n    return self.finalize_updown(weight, orig_weight, bias)\n\n", "CodeBleu_score": 35.55188986413301}, {"code": "def calc_updown(self, orig_weight)\n\t\n    if self.dora_scale is not None:\n        orig_weight = self.apply_weight_decompose(orig_weight, orig_weight)\n\n    updown = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    ex_bias = None\n\n    if self.bias is not None:\n        ex_bias = self.bias.to(orig_weight.device, dtype=orig_weight.dtype)\n\n    if self.dora_scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return self.finalize_updown(updown, orig_weight, self.weight.shape, ex_bias)", "CodeBleu_score": 46.63501691940426}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = torch.cuda.memory_allocated()\n    if networks_in_memory > devices.torch_gc:\n        print(f\"Purging networks from memory. Networks in memory: {networks_in_memory}\")\n        while networks_in_memory > devices.torch_gc:\n            networks_in_memory = torch.cuda.memory_allocated()\n            for obj in gc.get_objects():\n                try:\n                    if torch.is_tensor(obj) or (hasattr(obj, 'data') and torch.is_tensor(obj.data)):\n                        if obj.is_cuda:\n                            del obj\n                            gc.collect()\n                            networks_in_memory = torch.cuda.memory_allocated()\n                except Exception as e:\n                    print(e)\n                    pass\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n    gc.collect()\n    torch.cuda.empty_cache()\n   ", "CodeBleu_score": 33.28505075218505}, {"code": "def purge_networks_from_memory()\n\t\n    while len(networks_in_memory) > devices.torch_gc:\n        networks_in_memory.pop()\n        gc.collect()", "CodeBleu_score": 15.901917572357574}, {"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    if len(networks_in_memory) > devices.torch_gc:\n        networks_in_memory.pop()\n        gc.collect()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.988134968273936}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"backup_weights\"):\n        self.weight.data = self.backup_weights\n        del self.backup_weights\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"backup_projection_weights\"):\n            self.projection_weights.data = self.backup_projection_weights\n            del self.backup_projection_weights\n        if hasattr(self, \"backup_projection_bias\"):\n            self.projection_bias.data = self.backup_projection_bias\n            del self.backup_projection_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if hasattr(self, \"backup_bias\"):\n        self.bias.data = self.backup_bias\n        del self.backup_bias\n    if", "CodeBleu_score": 30.114596268450768}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"backup_weight\"):\n        self.weight = copy_(self.backup_weight)\n    if hasattr(self, \"backup_bias\"):\n        self.bias = copy_(self.backup_bias)\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"backup_projection_weight\"):\n            self.projection_weight = copy_(self.backup_projection_weight)\n        if hasattr(self, \"backup_projection_bias\"):\n            self.projection_bias = copy_(self.backup_projection_bias)\n    if hasattr(self, \"backup_bias\") and self.backup_bias is None:\n        self.bias = None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.82801871468754}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, 'bias_backup'):\n        if self.bias_backup is not None:\n            self.bias = self.bias_backup\n            del self.bias_backup\n        else:\n            self.bias = None\n    if hasattr(self, 'weight_backup'):\n        self.weight = self.weight_backup\n        del self.weight_backup\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, 'in_proj_backup'):\n            self.in_proj_weight = self.in_proj_backup\n            del self.in_proj_backup\n        if hasattr(self, 'out_proj_backup'):\n            self.out_proj.weight = self.out_proj_backup\n            del self.out_proj_backup\n        if hasattr(self, 'in_proj_bias_backup'):\n            self.in_proj_bias = self.in_proj_bias_backup\n            del self.in_proj_bias_backup\n        if hasattr(self, 'out_proj_bias_backup'):\n            self.out_proj.bias = self.out_proj_bias_backup\n            del self.out_proj_bias_backup", "CodeBleu_score": 38.85251172822037}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(org_module.loaded_networks) == 0:\n        return original_forward(input)\n    else:\n        input = input.to(devices.cond_cast_unet(org_module))\n        network_restore_weights_from_backup(org_module)\n        network_reset_cached_weight(org_module)\n        output = original_forward(input)\n        for network in org_module.loaded_networks:\n            if network.layer_name == org_module.name:\n                output = network.forward(output)\n        return output\n\n", "CodeBleu_score": 40.26885490102528}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(devices.loaded_networks) == 0:\n        return original_forward(input)\n    else:\n        input = devices.cond_cast_unet(input)\n        network_reset_cached_weight(org_module)\n        output = original_forward(input)\n        for net in devices.loaded_networks:\n            if net.name in org_module.network_current_names:\n                output = net.apply_network(output)\n        return output\n\n", "CodeBleu_score": 32.68030428469202}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(network_list) == 0:\n        return original_forward(org_module, input)\n    else:\n        input = devices.cond_cast_unet(input)\n        network_reset_cached_weight(org_module)\n        output = original_forward(org_module, input)\n        for network in network_list:\n            if network.layer_name == org_module.name:\n                output = network.forward(output)\n        return output\n\n", "CodeBleu_score": 40.43525764882766}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n    return [\n        param\n        for layer in self.layers\n        for name, param in layer.named_parameters()\n        if param.requires_grad\n    ]\n\n", "CodeBleu_score": 17.75766075121087}, {"code": "def trainables(self)\n\t\n    return [p for p in self.parameters() if p.requires_grad]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 6.452447410697191}, {"code": "def trainables(self)\n\t\n    return [p for p in self.parameters() if p.requires_grad]", "CodeBleu_score": 6.452447410697191}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    # Check for already loaded hypernetworks\n    already_loaded = []\n    for name in names:\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            already_loaded.append(hypernetwork)\n\n    # Clear the current list of loaded hypernetworks\n    clear()\n\n    # Load or retrieve each hypernetwork by name, setting its multiplier if provided\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            hypernetwork.set_multiplier(multiplier)\n            hypernetworks.append(hypernetwork)\n\n    # Append each loaded hypernetwork to the shared list\n    for hypernetwork in already_loaded:\n        hypernetworks.append(hypernetwork)\n\n", "CodeBleu_score": 38.78526063251445}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    if multipliers is None:\n        multipliers = [1.0] * len(names)\n\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            hypernetwork.set_multiplier(multiplier)\n            already_loaded.append(hypernetwork)\n\n", "CodeBleu_score": 23.85472641357708}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    loaded = []\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is None:\n            continue\n\n        hypernetwork.set_multiplier(multiplier)\n        loaded.append(hypernetwork)\n\n    already_loaded.set(loaded)\n\n", "CodeBleu_score": 29.000711123533307}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k, context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v", "CodeBleu_score": 69.49488199289185}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k, context_v = context, context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer=layer)\n    return context_k, context_v", "CodeBleu_score": 57.435688315169486}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k, context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v\n\n\n", "CodeBleu_score": 69.49488199289185}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    # x: [batch_size, channels, height, width]\n    # context: [batch_size, context_channels, context_height, context_width]\n    # mask: [batch_size, height, width]\n    # kwargs: dict\n    # return: [batch_size, channels, height, width]\n    assert x.dim() == 4, \"x must be a 4D tensor\"\n    assert context.dim() == 4, \"context must be a 4D tensor\"\n    assert mask is None or mask.dim() == 3, \"mask must be a 3D tensor or None\"\n    assert \"hypernetworks\" in kwargs, \"hypernetworks must be specified\"\n    assert isinstance(kwargs[\"hypernetworks\"], list), \"hypernetworks must be a list\"\n    assert len(kwargs[\"hypernetworks\"]) > 0, \"hypernetworks must not be empty\"\n    assert all(isinstance(hypernetwork, Hypernetwork) for hypernetwork in kwargs[\"hypernetworks\"]), \"hypernetworks must be a list of Hypernetwork objects\"\n    assert \"layer\" in kwargs, \"layer must be specified\"\n    assert isinstance(kwargs[\"layer\"], int), \"layer must be an integer\"\n    assert kwargs[\"layer\"] >= 0, \"layer must be non-negative\"\n\n    batch_size, channels, height, width = x.shape\n    context_channels, context_height, context_width = context.shape[1:]\n    assert context_channels == channels, \"context and x must have the same number of channels\"\n\n    # Project x and context to query, key, and value\n    query = self.to_q(x)\n    key = self.to_k(context)\n    value = self.to_v(context)\n\n    # Apply hypernetworks to context\n    context_k, context_v = self.apply_hypernetworks(kwargs[\"hypernetworks\"], context, kwargs[\"layer\"])\n\n    # Reshape query, key, and value for multi-head attention\n    query = query.reshape(batch_size, height, width, self.heads, self.head_channels).permute", "CodeBleu_score": 26.1021220417209}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n\n    # Project x and context to query, key, and value\n    query = self.to_q(x)\n    key = self.to_k(context)\n    value = self.to_v(context)\n\n    # Apply hypernetworks to context\n    context_k, context_v = self.apply_hypernetworks(self.hypernetworks, context, layer=self)\n\n    # Reshape tensors for multi-head attention\n    query = query.view(query.shape[0], query.shape[1], self.heads, self.head_features).transpose(1, 2)\n    key = key.view(key.shape[0], key.shape[1], self.heads, self.head_features).transpose(1, 2)\n    value = value.view(value.shape[0], value.shape[1], self.heads, self.head_features).transpose(1, 2)\n\n    context_k = context_k.view(context_k.shape[0], context_k.shape[1], self.heads, self.head_features).transpose(1, 2)\n    context_v = context_v.view(context_v.shape[0], context_v.shape[1], self.heads, self.head_features).transpose(1, 2)\n\n    # Calculate scaled dot-product attention\n    attn = (query @ key.transpose(-2, -1)) * self.scale\n\n    if mask is not None:\n        attn = attn.masked_fill_(mask == 0, -1e9)\n\n    attn = attn.softmax(dim=-1)\n\n    # Compute the final attention output\n    attn_output = attn @ value\n    attn_output = attn_output.transpose(1, 2).contiguous().view(attn_output.shape[0], attn_output.shape[1], -1)\n\n    # Reshape back to original shape\n    attn_output = self.to_out(attn_output)\n\n    return att", "CodeBleu_score": 38.05424014842955}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if context is None:\n        context = x\n    if mask is None:\n        mask = torch.ones(x.shape[:2], dtype=torch.bool, device=x.device)\n    if mask.shape[1] != x.shape[1]:\n        raise ValueError(\"The mask has incorrect dimensions.\")\n    if mask.dtype != torch.bool:\n        raise ValueError(\"The mask should be a boolean tensor.\")\n    if mask.shape[0] != x.shape[0]:\n        raise ValueError(\"The batch size of the mask and the input tensor should be the same.\")\n    if mask.shape[1] != x.shape[1]:\n        raise ValueError(\"The sequence length of the mask and the input tensor should be the same.\")\n    if mask.shape[0] != context.shape[0]:\n        raise ValueError(\"The batch size of the mask and the context tensor should be the same.\")\n    if mask.shape[1] != context.shape[1]:\n        raise ValueError(\"The sequence length of the mask and the context tensor should be the same.\")\n    if mask.device != x.device:\n        raise ValueError(\"The mask and the input tensor should be on the same device.\")\n    if mask.device != context.device:\n        raise ValueError(\"The mask and the context tensor should be on the same device.\")\n    if mask.dtype != x.dtype:\n        raise ValueError(\"The mask and the input tensor should have the same data type.\")\n    if mask.dtype != context.dtype:\n        raise ValueError(\"The mask and the context tensor should have the same data type.\")\n    if mask.shape[0] != context.shape[0]:\n        raise ValueError(\"The batch size of the mask and the context tensor should be the same.\")\n    if mask.shape[1] != context.shape[1]:\n        raise ValueError(\"The sequence length of the mask and the context tensor should be the same.\")\n    if mask.device != context.device:\n        raise ValueError(\"The mask and the context tensor should be on the same device.\")\n    if mask.dtype != context.dtype:\n        raise ValueError(\"", "CodeBleu_score": 15.384962112710246}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    try:\n        original_checkpoint = hypernetwork.sd_checkpoint\n        original_checkpoint_name = hypernetwork.sd_checkpoint_name\n        original_name = hypernetwork.name\n        hypernetwork.sd_checkpoint = checkpoint\n        hypernetwork.sd_checkpoint_name = hypernetwork_name\n        hypernetwork.name = filename\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.sd_checkpoint = original_checkpoint\n        hypernetwork.sd_checkpoint_name = original_checkpoint_name\n        hypernetwork.name = original_name\n        raise e\n    finally:\n        hypernetwork.sd_checkpoint = original_checkpoint\n        hypernetwork.sd_checkpoint_name = original_checkpoint_name\n        hypernetwork.name = original_name\n\n", "CodeBleu_score": 43.12120816906479}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    original_checkpoint = hypernetwork.sd_checkpoint\n    original_checkpoint_name = hypernetwork.sd_checkpoint_name\n    original_name = hypernetwork.name\n    original_layer_structure = hypernetwork.layer_structure\n    original_activation_func = hypernetwork.activation_func\n    original_add_layer_norm = hypernetwork.add_layer_norm\n    original_weight_init = hypernetwork.weight_init\n    original_activate_output = hypernetwork.activate_output\n    original_use_dropout = hypernetwork.use_dropout\n    original_dropout_structure = hypernetwork.dropout_structure\n    original_last_layer_dropout = hypernetwork.last_layer_dropout\n    original_optional_info = hypernetwork.optional_info\n\n    hypernetwork.sd_checkpoint = checkpoint\n    hypernetwork.sd_checkpoint_name = hypernetwork_name\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.layer_structure = hypernetwork.layer_structure\n    hypernetwork.activation_func = hypernetwork.activation_func\n    hypernetwork.add_layer_norm = hypernetwork.add_layer_norm\n    hypernetwork.weight_init = hypernetwork.weight_init\n    hypernetwork.activate_output = hypernetwork.activate_output\n    hypernetwork.use_dropout = hypernetwork.use_dropout\n    hypernetwork.dropout_structure = hypernetwork.dropout_structure\n    hypernetwork.last_layer_dropout = hypernetwork.last_layer_dropout\n    hypernetwork.optional_info = hypernetwork.optional_info\n\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.sd_checkpoint = original_checkpoint\n        hypernetwork.sd_checkpoint_name = original_checkpoint_name\n        hypernetwork.name = original_name\n        hypernetwork.layer_structure = original_layer_structure\n        hypernetwork.activation_func = original_activation_func\n        hypernetwork.add_layer_norm = original_add_layer_norm\n        hypernetwork.weight_init = original_weight_init\n        hypernetwork.activate_", "CodeBleu_score": 33.33200697320729}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n\n    try:\n        original_checkpoint = hypernetwork.sd_checkpoint\n        original_checkpoint_name = hypernetwork.sd_checkpoint_name\n        original_layer_structure = hypernetwork.layer_structure\n        original_activation_func = hypernetwork.activation_func\n        original_add_layer_norm = hypernetwork.add_layer_norm\n        original_weight_init = hypernetwork.weight_init\n        original_activate_output = hypernetwork.activate_output\n        original_use_dropout = hypernetwork.use_dropout\n        original_dropout_structure = hypernetwork.dropout_structure\n        original_last_layer_dropout = hypernetwork.last_layer_dropout\n        original_optional_info = hypernetwork.optional_info\n\n        hypernetwork.sd_checkpoint = checkpoint\n        hypernetwork.sd_checkpoint_name = hypernetwork_name\n        hypernetwork.layer_structure = hypernetwork.layer_structure\n        hypernetwork.activation_func = hypernetwork.activation_func\n        hypernetwork.add_layer_norm = hypernetwork.add_layer_norm\n        hypernetwork.weight_init = hypernetwork.weight_init\n        hypernetwork.activate_output = hypernetwork.activate_output\n        hypernetwork.use_dropout = hypernetwork.use_dropout\n        hypernetwork.dropout_structure = hypernetwork.dropout_structure\n        hypernetwork.last_layer_dropout = hypernetwork.last_layer_dropout\n        hypernetwork.optional_info = hypernetwork.optional_info\n\n        hypernetwork.save(filename)\n\n        hypernetwork.sd_checkpoint = original_checkpoint\n        hypernetwork.sd_checkpoint_name = original_checkpoint_name\n        hypernetwork.layer_structure = original_layer_structure\n        hypernetwork.activation_func = original_activation_func\n        hypernetwork.add_layer_norm = original_add_layer_norm\n        hypernetwork.weight_init = original_weight_init\n        hypernetwork.activate_output = original_activate_output\n        hypernetwork.use_dropout = original_use_dropout\n        hypernetwork.dropout_structure = original_", "CodeBleu_score": 37.527109356732126}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.ema_enabled = False\n        self.ema_scope_context = context\n        self.ema_scope_start_step = self.global_step\n        self.ema_scope_start_step_name = self.step_name\n        self.ema_scope_start_step_time = time.time()\n        self.ema_scope_start_step_time_str = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file_for_log = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file_for_log_for_log = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file_for_log_for_log_for_log = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file_for_log_for_log_for_log_for_log = time.strftime(\"%Y-%m-%d_%H-%M-%S\", time.localtime())\n        self.ema_scope_start_step_time_str_for_log_file_for_log_for_log_for_log_for_log_for_log", "CodeBleu_score": 16.33567242437488}, {"code": "def ema_scope(self, context=None)\n\t\n    self.ema_enabled = self.ema_enabled and self.ema_enabled()\n    if self.ema_enabled:\n        if self.ema_log:\n            self.ema_log(self.ema_enabled)\n        self.ema_store()\n        self.ema_copy_to()\n    if context is not None:\n        with context:\n            yield\n    if self.ema_enabled:\n        self.ema_restore()\n        if self.ema_log:\n            self.ema_log(self.ema_enabled)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.883115702967295}, {"code": "def ema_scope(self, context=None)\n\t\n    if not self.ema_enabled:\n        return\n    if context is None:\n        context = {}\n    if \"ema_enabled\" not in context:\n        context[\"ema_enabled\"] = self.ema_enabled\n    self.ema_enabled = False\n    self.ema_restore()\n    self.ema_enabled = context[\"ema_enabled\"]\n", "CodeBleu_score": 28.172449199262395}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    assert model_output.shape == x.shape\n    model_variance, model_log_variance = self.model_variance(x, t=t)\n    assert model_variance.shape == tuple(x.shape[0:1]) + (1,)\n\n    if clip_denoised:\n        x_recon = self.x_recon(x, t)\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n    else:\n        model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x, x_t=x, t=t)\n    assert model_mean.shape == x.shape\n    assert posterior_variance.shape == x.shape\n\n    return model_mean, posterior_variance, posterior_log_variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.43293232588977}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    if self.model_var_type in ['learned', 'learned_range']:\n        learned_variance = self.get_learned_variance(x, t, model_output)\n        model_variance, model_log_variance = learned_variance\n    else:\n        model_variance, model_log_variance = (\n            self.get_model_variance(x, t, model_output, self.model_var_type)\n        )\n    q_mean, _, q_log_variance = self.q_posterior(x_start=x, x_t=model_output, t=t)\n    if self.model_var_type in ['fixedlarge', 'fixedsmall']:\n        assert model_variance.max() <= 1.0\n    model_variance, model_log_variance = model_variance.to(x.dtype), model_log_variance.to(x.dtype)\n    if clip_denoised:\n        x_recon = self.x_recon.clamp_(-1.0, 1.0)\n    else:\n        x_recon = model_output\n    return q_mean, model_variance, model_log_variance, q_log_variance, x_recon\n\n", "CodeBleu_score": 42.90041688234258}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_mean, _, model_log_variance = self.model(x, t)\n    assert model_mean.shape == x.shape\n    nonzero_mask = (t != 0).type(x.dtype)\n    posterior_variance = extract_into_tensor(1. - extract_into_tensor(self.posterior_mean_coef2, t, x.shape), t, x.shape) * nonzero_mask\n    # Account for the pre-conditioning\n    posterior_log_variance_clipped = torch.max(model_log_variance, self.posterior_log_variance_clipped)\n    posterior_variance = extract_into_tensor(torch.exp(posterior_log_variance_clipped), t, x.shape)\n    assert (posterior_variance > 0).all(), f\"variance is non-positive despite check for >0\"\n\n    # Sample from the model\n    noise = torch.randn_like(x)\n    x_recon = self.predict_start_from_noise(x, t=t, noise=noise)\n    if clip_denoised:\n        x_recon = x_recon.clamp(-1., 1.)\n\n    # Calculate the model's mean and variance\n    model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n    assert (model_mean.shape == x_recon.shape)\n    return model_mean, posterior_variance, posterior_log_variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.94282836924455}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean(torch.pow(pred - target, 2))\n        else:\n            return torch.pow(pred - target, 2)\n    else:\n        raise NotImplementedError('Unknown loss type: {}'.format(self.loss_type))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.79656686393121}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == \"l1\":\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == \"l2\":\n        if mean:\n            return torch.mean(torch.pow(pred - target, 2))\n        else:\n            return torch.pow(pred - target, 2)\n    else:\n        raise NotImplementedError(f\"Unknown loss type: {self.loss_type}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.14994834687571}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    loss_type = self.loss_type\n    if loss_type == 'l1':\n        return self._l1_loss(pred, target, mean)\n    elif loss_type == 'l2':\n        return self._l2_loss(pred, target, mean)\n    else:\n        raise NotImplementedError('Unknown loss type: {}'.format(loss_type))\n\n\n", "CodeBleu_score": 22.99272589273541}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device, dtype=torch.long)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    return (0.5 * mean.pow(2).sum(dim=[1, 2, 3]) * 32 * 32 + 0.5 * log_variance.sum(dim=[1, 2, 3])).mean()\n\n", "CodeBleu_score": 37.455739162157585}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.ones((batch_size,), device=x_start.device, dtype=torch.long)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    return normal_kl(mean, log_variance).mean() / np.log(2.0)\n\n", "CodeBleu_score": 27.79414798633264}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.ones((batch_size,), device=x_start.device, dtype=torch.long)\n    mean, log_variance = self.q_mean_variance(x_start, t)\n    return normal_kl(mean, log_variance) / np.log(2.0)\n\n", "CodeBleu_score": 27.469946803147714}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"cache\")\n    cache = diskcache.Cache(\n        directory=os.path.join(cache_dir, subsection),\n        size_limit=4 * 1024 * 1024 * 1024,\n        disk_min_file_size=256 * 1024,\n    )\n    return cache\n\n\n\n\n", "CodeBleu_score": 54.540003455581896}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        path=f\"{CACHE_DIR}/{subsection}\",\n        size_limit=4 * 1024 * 1024 * 1024,\n        eviction_policy=\"least-recently-used\",\n        eviction_ttl=10,\n        disk_min_file_size=256 * 1024,\n    )\n\n\n\n\n", "CodeBleu_score": 52.11961870558691}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_path = f\"cache/{subsection}\"\n    cache = diskcache.Cache(\n        cache_path,\n        size_limit=4e9,\n        eviction_policy=\"least-recently-used\",\n        eviction_ttl=60 * 60 * 24 * 7,\n        disk_min_file_size=256e3,\n    )\n    return cache\n\n", "CodeBleu_score": 48.28038337014225}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    if subsection not in caches:\n        with cache_lock:\n            if subsection not in caches:\n                if not os.path.exists(cache_dir):\n                    os.makedirs(cache_dir)\n                if not isfile(cache_filename):\n                    convert_old_cached_data()\n                caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 43.111127042786386}, {"code": "def cache(subsection)\n\t\n    global caches\n    cache_obj = caches.get(subsection)\n    if cache_obj is None:\n        with cache_lock:\n            if not os.path.exists(cache_dir):\n                os.makedirs(cache_dir)\n            if not isfile(cache_filename):\n                convert_old_cached_data()\n            cache_obj = caches.get(subsection)\n            if cache_obj is None:\n                cache_obj = make_cache(subsection)\n                caches[subsection] = cache_obj\n    return cache_obj\n\n", "CodeBleu_score": 60.67200699900977}, {"code": "def cache(subsection)\n\t\n    cache_obj = caches.get(subsection)\n    if cache_obj is None:\n        with cache_lock:\n            if not os.path.exists(cache_dir):\n                os.mkdir(cache_dir)\n            if not isfile(cache_filename):\n                convert_old_cached_data()\n            cache_obj = caches.get(subsection)\n            if cache_obj is None:\n                cache_obj = make_cache(subsection)\n                caches[subsection] = cache_obj\n    return cache_obj", "CodeBleu_score": 65.16089936373541}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    if cache_obj.get(title):\n        if mtime > cache_obj.get(title).get('mtime'):\n            cache_obj.delete(title)\n\n    if not cache_obj.get(title):\n        data = func()\n        cache_obj.set(title, {'mtime': mtime, 'data': data})\n        dump_cache()\n        return data\n\n    return cache_obj.get(title).get('data')", "CodeBleu_score": 26.55377277243459}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.stat(filename).st_mtime\n    if cache_obj.get(title) and cache_obj.getmtime(title) >= mtime:\n        cache_obj.delete(title)\n\n    if not cache_obj.get(title):\n        data = func()\n        cache_obj.set(title, data, mtime=mtime)\n        dump_cache()\n        return data\n\n    return cache_obj.get(title)\n\n", "CodeBleu_score": 21.34861974262815}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    entry = cache_obj.get(title)\n    if entry:\n        if mtime > entry.mtime:\n            cache_obj.delete(title)\n            entry = None\n\n    if not entry:\n        data = func()\n        cache_obj.set(title, (data, mtime))\n        dump_cache()\n        return data\n\n    return entry.value[0]\n\n", "CodeBleu_score": 29.854813622108068}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n\n    for line in message.splitlines():\n        print(\"***\", line, file=sys.stderr)\n\n    if exc_info:\n        print(\n            \"---\",\n            textwrap.indent(traceback.format_exc(), \"    \"),\n            file=sys.stderr,\n            sep=\"", "CodeBleu_score": 62.05096265225585}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n\n    for line in message.splitlines():\n        print(f\"*** {line}\", file=sys.stderr)\n\n    if exc_info:\n        traceback.print_exc()\n        print(\"---\", file=sys.stderr)\n\n", "CodeBleu_score": 51.2005400155899}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    for line in message.splitlines():\n        print(\"***\", line, file=sys.stderr)\n    if exc_info:\n        print(\"---\", file=sys.stderr)\n        print(textwrap.indent(traceback.format_exc(), \"    \"), file=sys.stderr)\n\n", "CodeBleu_score": 74.20523584662352}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_extracted, positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    negative_extracted, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if positive_extracted and negative_extracted:\n        return True, positive_prompt, negative_prompt\n\n    return False, prompt, negative_prompt\n\n", "CodeBleu_score": 55.19615277225692}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    if style.prompt == \"\":\n        return False, prompt, negative_prompt\n\n    if style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt_extracted, positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n\n    negative_prompt_extracted, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if positive_prompt_extracted and negative_prompt_extracted:\n        return True, positive_prompt, negative_prompt\n\n    return False, prompt, negative_prompt\n\n", "CodeBleu_score": 61.38141538394643}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt_extracted, positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    negative_prompt_extracted, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if positive_prompt_extracted and negative_prompt_extracted:\n        return True, positive_prompt, negative_prompt\n\n    return False, prompt, negative_prompt\n\n", "CodeBleu_score": 55.40077488541585}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n    \n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    \n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.20475781398312}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be set to True\")\n    change_in_dBFS = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (change_in_dBFS < 0 and increase_only) or (change_in_dBFS > 0 and decrease_only):\n        return wav\n    return wav * 10 ** (change_in_dBFS / 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 79.67088006612117}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be True.\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (dBFS_change < 0 and increase_only) or (dBFS_change > 0 and decrease_only):\n        return wav\n    return wav * 10 ** (dBFS_change / 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 86.43951469229563}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase_only and decrease_only cannot be True\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if dBFS_change < 0 and increase_only or dBFS_change > 0 and decrease_only:\n        return wav\n    return wav * 10 ** (dBFS_change / 20)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 70.56018036598772}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath)['model_state'])\n    _model.eval()\n    print('Loaded model from step {}.'.format(torch.load(weights_fpath)['step']))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.83990449926981}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    _model = SpeakerEncoder(device)\n    _model.load_state_dict(torch.load(weights_fpath)[\"model_state\"])\n    _model.eval()\n    print(f\"Loaded model from {weights_fpath} | Training step: {torch.load(weights_fpath)['step']}\")\n\n    return _model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.42471368162723}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath)['model_state'])\n    _model.eval()\n    print('Loaded encoder \"%s\" trained to step %d' % (weights_fpath.name, _model._step))\n    return _model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.13433720701604}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded. Call load_model() first.\")\n    \n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    embeds = _model.forward(frames_batch).detach().cpu().numpy()\n    return embeds\n\n", "CodeBleu_score": 74.39687215759756}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model not loaded\")\n\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    embeds = _model.forward(frames_batch).detach().cpu().numpy()\n\n    return embeds\n\n", "CodeBleu_score": 69.54748106382162}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception('Model is not loaded. Call load_model(model_path) first.')\n    \n    frames_batch = torch.from_numpy(frames_batch)\n    frames_batch = frames_batch.to(_device)\n    \n    embeds = _model.forward(frames_batch).detach().cpu().numpy()\n    \n    return embeds\n\n", "CodeBleu_score": 66.97358938558922}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 <= min_pad_coverage <= 1, 'min_pad_coverage must be between 0 and 1'\n    assert 0 <= overlap <= 1, 'overlap must be between 0 and 1'\n    assert partial_utterance_n_frames > 0, 'partial_utterance_n_frames must be strictly positive'\n\n    samples_per_frame = int(np.round(hparams.sample_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil(n_samples / samples_per_frame))\n    frame_step = int(np.round(samples_per_frame * (1 - overlap)))\n\n    wav_slices, mel_slices = [], []\n    for i in range(0, n_frames, frame_step):\n        mel_start = i\n        wav_start = mel_start * samples_per_frame\n        wav_end = min(wav_start + partial_utterance_n_frames * samples_per_frame, n_samples)\n        mel_end = wav_end + partial_utterance_n_frames * samples_per_frame - wav_start\n\n        wav_slices.append(slice(wav_start, wav_end))\n        mel_slices.append(slice(mel_start, mel_end))\n\n    # Evaluate padding\n    covers = [wav_end - wav_start >= partial_utterance_n_frames * hparams.sample_rate for wav_start, wav_end in\n              wav_slices[:-1]]\n    mel_covers = [mel_end - mel_start >= partial_utterance_n_frames for mel_start, mel_end in mel_slices[:-1]]\n    mel_covers[-1] = mel_covers[-1] and mel_covers[-2]\n    covers[-1] = covers[-1] or mel_covers[-1]\n\n    for i, (c, mc) in enumerate(zip(covers[:-1], mel_covers[:-1])):\n        assert c", "CodeBleu_score": 39.08724793302413}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n\n    assert 0 <= overlap <= 1, 'Invalid value encountered in argument \\'overlap\\''\n    assert 0 <= min_pad_coverage <= 1, 'Invalid value encountered in argument \\'min_pad_coverage\\''\n\n    # Compute how many frames will result in `partial_utterance_n_frames` if\n    # each frame has `frame_shift` duration.\n    frame_shift = (1 / sr) * partial_utterance_n_frames\n    frame_length = frame_shift * (1 - overlap)\n\n    # Number of frames that will result in `partial_utterance_n_frames` assuming\n    # each frame has `frame_length` duration\n    n_frames_total = int(np.ceil(n_samples / frame_length))\n    frame_step = int(np.ceil(frame_length / frame_shift))\n\n    wav_slices, mel_slices = [], []\n    for i in range(n_frames_total):\n        start_frame = i * frame_step\n        end_frame = min(n_samples, start_frame + partial_utterance_n_frames)\n\n        wav_slices.append(slice(start_frame, end_frame))\n        mel_slices.append(slice(0, partial_utterance_n_frames))\n\n    # Ensure that we have at least min_pad_coverage % coverage\n    # If we don't, repeat the last partial utterance until we hit min_pad_coverage %\n    last_wav_slice = wav_slices[-1]\n    coverage = (last_wav_slice.stop - last_wav_slice.start) / partial_utterance_n_frames\n    while coverage < min_pad_coverage and len(wav_slices) > 1:\n        wav_slices = wav_slices[:-1]\n        mel_slices = mel_slices[:-1]\n\n        last_wav_slice = wav_slices[-1]\n        coverage = (last_wav_slice.stop - last_wav_slice.start)", "CodeBleu_score": 40.216327526882566}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 <= overlap <= 1, 'Invalid value encountered in argument \\'overlap\\'. Must be a floating point value between 0 and 1'\n    assert 0 <= min_pad_coverage <= 1, 'Invalid value encountered in argument \\'min_pad_coverage\\'. Must be a floating point value between 0 and 1'\n    assert partial_utterance_n_frames > 0, 'Invalid value encountered in argument \\'partial_utterance_n_frames\\'. Must be a positive integer'\n\n    # Compute the number of frames and step size from partial utterance n_frames\n    frames_per_step = int(np.round(partial_utterance_n_frames * (1 - overlap)))\n    n_frames_per_segment = partial_utterance_n_frames\n    expected_n_frames_per_segment = frames_per_step\n    assert frames_per_step >= 1, 'Invalid value encountered in variable \\'frames_per_step\\'. Must be an integer value greater than zero'\n    assert expected_n_frames_per_segment >= 1, 'Invalid value encountered in variable \\'expected_n_frames_per_segment\\'. Must be an integer value greater than zero'\n\n    # Compute the number of steps and the length of the last incomplete partial utterance\n    n_steps, res = divmod(n_samples, frames_per_step)\n    if res > 0:\n        n_padding = expected_n_frames_per_segment - res\n    else:\n        n_padding = 0\n\n    # Check if it is necessary to pad the last partial utterance\n    assert 0 <= n_padding < expected_n_frames_per_segment, 'Incompatible values encountered: n_padding={} n_frames_per_segment={} frames_per_step={}'.format(\n        n_padding, expected_n_frames_per_segment, frames_per_step)\n\n    # If too much padding is needed, return the empty-pad version of the input\n    if n_padding > (expected_n_frames_per_segment - min_pad_coverage * expected_n_frames_per_segment):\n        return [],", "CodeBleu_score": 20.594027951364076}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    im = ax.imshow(embed, cmap=plt.cm.hot_r)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    sm = cm.ScalarMappable(cmap=plt.cm.hot_r, norm=plt.Normalize(vmin=color_range[0], vmax=color_range[1]))\n    sm.set_array([])\n    plt.colorbar(sm)\n    return im\n\n", "CodeBleu_score": 59.16748322390827}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    sm = cm.ScalarMappable(cmap=cm.get_cmap('jet'))\n    sm.set_clim(color_range[0], color_range[1])\n    ax.imshow(embed, cmap=sm.cmap)\n    cbar = plt.colorbar(sm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.535164395090185}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    im = ax.imshow(embed, cmap=plt.cm.hot)\n    divider = make_axes_locatable(ax)\n    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n    plt.colorbar(im, cax=cax)\n    plt.clim(color_range[0], color_range[1])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    return ax", "CodeBleu_score": 58.95425696577495}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    # Determine number of speakers per batch and number of utterances per speaker\n    num_speakers = embeds.shape[0]\n    num_utts_per_speaker = embeds.shape[1]\n\n    # Initialize similarity matrix and mask matrix\n    sim_mat = torch.zeros((num_speakers, num_speakers), device=embeds.device)\n    mask = torch.ones((num_speakers, num_speakers), device=embeds.device)\n    mask = torch.triu(mask, diagonal=1)\n\n    # Compute centroids\n    centroids_incl = torch.zeros((num_speakers, embeds.shape[2]), device=embeds.device)\n    centroids_excl = torch.zeros((num_speakers, embeds.shape[2]), device=embeds.device)\n    for i in range(num_speakers):\n        centroids_incl[i] = torch.mean(embeds[i], dim=0)\n        centroids_excl[i] = torch.mean(torch.cat([embeds[i][:, j] for j in range(num_utts_per_speaker) if j != i], dim=0), dim=0)\n    centroids_incl = centroids_incl / torch.norm(centroids_incl, dim=1, keepdim=True)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=1, keepdim=True)\n\n    # Compute similarity scores\n    for i in range(num_speakers):\n        sim_incl = torch.norm(centroids_incl[i] - centroids_incl, dim=1)\n        sim_excl = torch.norm(centroids_excl[i] - centroids_excl, dim=1)\n        sim_mat[i] = sim_incl * sim_excl\n\n    # Scale and bias similarity matrix\n    sim_mat = sim_mat / torch.max(sim_mat)\n    sim_mat", "CodeBleu_score": 33.914658426848874}, {"code": "def similarity_matrix(self, embeds)\n\t\n    batch_size = embeds.shape[0]\n    num_speakers = batch_size // self.utterances_per_speaker\n    centroids_incl = torch.zeros((num_speakers, self.embed_dim), device=embeds.device)\n    centroids_excl = torch.zeros((num_speakers, self.embed_dim), device=embeds.device)\n    mask = torch.eye(num_speakers, device=embeds.device)\n    similarity_matrix = torch.zeros((num_speakers, num_speakers), device=embeds.device)\n    for i in range(num_speakers):\n        speaker_embeds = embeds[i * self.utterances_per_speaker:(i + 1) * self.utterances_per_speaker]\n        centroids_incl[i] = torch.mean(speaker_embeds, dim=0)\n        centroids_incl[i] /= torch.norm(centroids_incl[i])\n        centroids_excl[i] = torch.mean(speaker_embeds[~mask[i]], dim=0)\n        centroids_excl[i] /= torch.norm(centroids_excl[i])\n        similarity_matrix[i] = torch.sum(centroids_incl[i] * centroids_excl, dim=1)\n    similarity_matrix = similarity_matrix / torch.sum(similarity_matrix, dim=1, keepdim=True)\n    similarity_matrix = similarity_matrix * self.scale + self.bias\n    return similarity_matrix\n\n", "CodeBleu_score": 34.959411032960546}, {"code": "def similarity_matrix(self, embeds)\n\t\n    # determine number of speakers per batch and number of utterances per speaker\n    n_speakers = embeds.shape[0]\n    n_utterances = embeds.shape[1]\n\n    # initialize similarity matrix with zeros on specified device\n    similarity_matrix = torch.zeros((n_speakers, n_speakers), device=self.device)\n\n    # initialize mask matrix to exclude self-similarity\n    mask = torch.eye(n_speakers, device=self.device)\n\n    # compute centroids\n    centroids_incl = torch.zeros((n_speakers, embeds.shape[2]), device=self.device)\n    centroids_excl = torch.zeros((n_speakers, embeds.shape[2]), device=self.device)\n    for i in range(n_speakers):\n        centroids_incl[i] = torch.mean(embeds[i], dim=0)\n        centroids_excl[i] = torch.mean(torch.cat([embeds[i, :i], embeds[i, i+1:]], dim=0), dim=0)\n\n    # compute similarity scores for each speaker\n    for i in range(n_speakers):\n        # compute similarity scores using centroids_incl\n        similarity_matrix[i] = torch.norm(centroids_incl[i] - centroids_incl, dim=1)\n\n        # compute similarity scores using centroids_excl\n        similarity_matrix[i] += torch.norm(centroids_excl[i] - centroids_excl, dim=1)\n\n        # exclude self-similarity\n        similarity_matrix[i] -= torch.diag(similarity_matrix[i])\n\n    # scale and bias similarity matrix\n    similarity_matrix = similarity_matrix / torch.max(similarity_matrix)\n    similarity_matrix = similarity_matrix * 2 - 1\n\n    return similarity_matrix\n\n", "CodeBleu_score": 30.740616149506128}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker, -1)\n    labels = torch.from_numpy(np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)).long().to(self.loss_device)\n    # Compute loss\n    loss = self.loss_fn(sim_matrix, labels)\n    # Compute EER\n    with torch.no_grad():\n        preds = torch.argmax(sim_matrix, dim=1)\n        preds = torch.reshape(preds, (speakers_per_batch, utterances_per_speaker))\n        preds = torch.transpose(preds, 0, 1)\n        preds = torch.reshape(preds, (-1, 1))\n        labels = torch.reshape(labels, (-1, 1))\n        fpr, tpr, thresholds = roc_curve(labels.flatten(), preds.flatten(), pos_label=speakers_per_batch)\n        fnr = 1 - tpr\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n        thresh = interp1d(fpr, thresholds)(eer)\n        eer = fnr[np.argmin(np.absolute((fnr - fpr) - eer))]\n        eer = torch.from_numpy(np.array([eer])).float().to(self.loss_device)\n    return loss, eer\n\n", "CodeBleu_score": 59.11447147445307}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker, -1)\n    \n    # Generate labels\n    labels = np.zeros(shape=(speakers_per_batch, utterances_per_speaker, speakers_per_batch))\n    for i in range(speakers_per_batch):\n        for j in range(utterances_per_speaker):\n            labels[i, j, i] = 1\n            if i + 1 < speakers_per_batch:\n                labels[i, j, i + 1:] = 1\n    labels = labels.reshape(speakers_per_batch * utterances_per_speaker, -1)\n    \n    # Calculate loss\n    loss = self.loss_fn(sim_matrix, labels)\n    \n    # Calculate EER\n    with torch.no_grad():\n        preds = torch.argmax(sim_matrix, dim=1)\n        preds = preds.flatten()\n        labels = labels.flatten()\n        fpr, tpr, thresholds = roc_curve(labels.cpu(), preds.cpu(), pos_label=1)\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n        \n    return loss, eer\n\n", "CodeBleu_score": 54.225510069178576}, {"code": "def loss(self, embeds)\n\t\n    # Determine the number of speakers and utterances per speaker from the shape of the input embeddings\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n\n    # Compute the similarity matrix\n    sim_matrix = self.similarity_matrix(embeds)\n\n    # Reshape the similarity matrix to be (speakers_per_batch * utterances_per_speaker, speakers_per_batch)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker, -1)\n\n    # Generate ground truth labels\n    gt_labels = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    gt_labels = torch.from_numpy(gt_labels).to(self.loss_device)\n\n    # Compute the loss using the ground truth labels and the similarity matrix\n    loss = self.loss_fn(sim_matrix, gt_labels)\n\n    # Compute the EER without backpropagation\n    with torch.no_grad():\n        preds = torch.argmax(sim_matrix, dim=1)\n        preds = inv_argmax(preds)\n        fpr, tpr, thresholds = roc_curve(gt_labels.cpu().numpy(), preds.cpu().numpy(), pos_label=1)\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n\n    return loss, eer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.35036165396389}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    if self.log_params:\n        # import parameter configurations\n        import config\n\n        # create string\n        params_str = \"\"\n\n        # iterate through model parameters\n        for key, value in self.model.named_parameters():\n            # add name and value to string\n            params_str += f\"{key}: {value}", "CodeBleu_score": 5.710436633906182}, {"code": "def log_params(self)\n\t\n    import inspect\n    import textwrap\n\n    if self.config[\"log_params\"]:\n        import pprint\n        from rich.console import Console\n        from rich.panel import Panel\n\n        console = Console()\n\n        # Get the model and data parameters\n        model_params = inspect.signature(self.model).parameters\n        data_params = inspect.signature(self.data).parameters\n\n        # Create a formatted string with the model and data parameters\n        params_str = \"Model Parameters:", "CodeBleu_score": 16.222387025077317}, {"code": "def log_params(self)\n\t\n    if self.log_params:\n        import inspect\n        import textwrap\n        import numpy as np\n        import pandas as pd\n        import matplotlib.pyplot as plt\n        import seaborn as sns\n        import matplotlib.ticker as ticker\n        import matplotlib.colors as colors\n        from matplotlib.colors import ListedColormap\n        from matplotlib.colors import LinearSegmentedColormap\n        from matplotlib.colors import BoundaryNorm\n        from matplotlib.patches import Rectangle\n        from matplotlib.patches import Ellipse\n        from matplotlib.patches import Polygon\n        from matplotlib.patches import Circle\n        from matplotlib.patches import Arrow\n        from matplotlib.patches import Arc\n        from matplotlib.patches import PathPatch\n        from matplotlib.patches import ConnectionPatch\n        from matplotlib.patches import Wedge\n        from matplotlib.patches import FancyArrowPatch\n        from matplotlib.patches import FancyArrowPatch\n        from matplotlib.patches import Patch\n        from matplotlib.patches import PathPatch\n        from matplotlib.patches import Polygon\n        from matplotlib.patches import Rectangle\n        from matplotlib.patches import Ellipse\n        from matplotlib.patches import ArrowStyle\n        from matplotlib.patches import Arrow\n        from matplotlib.patches import Circle\n        from matplotlib.patches import Wedge\n        from matplotlib.patches import FancyArrowPatch\n        from matplotlib.patches import ConnectionPatch\n        from matplotlib.patches import PathPatch\n        from matplotlib.patches import Polygon\n        from matplotlib.patches import Rectangle\n        from matplotlib.patches import Ellipse\n        from matplotlib.patches import ArrowStyle\n        from matplotlib.patches import Arrow\n        from matplotlib.patches import Circle\n        from matplotlib.patches import Wedge\n        from matplot", "CodeBleu_score": 8.295390276831792}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    # Limit the number of speakers\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n\n    # Flatten embeddings and compute speaker colors\n    embeds = np.concatenate(embeds)\n    speaker_ids = np.repeat(np.arange(len(embeds)), utterances_per_speaker)\n    colors = self.get_colors(speaker_ids)\n\n    # Compute projections\n    reducer = umap.UMAP()\n    projections = reducer.fit_transform(embeds)\n\n    # Plot projections\n    plt.clf()\n    plt.scatter(projections[:, 0], projections[:, 1], c=colors)\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title(f'Speaker embeddings at step {step}')\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.96123224046264}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    # Limit the number of speakers\n    speakers = embeds.keys()\n    if len(speakers) > max_speakers:\n        speakers = speakers[:max_speakers]\n    # Flatten the embeddings\n    flattened_embeds = np.array([embeds[speaker].flatten() for speaker in speakers])\n    # Assign colors based on speaker identity\n    colors = np.array([self.speaker_to_color[speaker] for speaker in speakers])\n    # Reduce the dimensionality of the embeddings using UMAP\n    reducer = umap.UMAP()\n    projections = reducer.fit_transform(flattened_embeds)\n    # Plot the projections\n    plt.scatter(projections[:, 0], projections[:, 1], c=colors, s=100)\n    # Set the aspect ratio to be equal\n    set_aspect('equal')\n    # Add a title to the plot\n    plt.title(f'Speaker Embeddings (Step {step})')\n    # Clear the current figure\n    plt.clf()\n    # If specified, save the plot to a file\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n\n", "CodeBleu_score": 41.66784701900242}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    # Reduce dimensionality of embeddings\n    reducer = umap.UMAP(n_components=2)\n    embeds = reducer.fit_transform(embeds)\n    # Get the unique speaker ids and the number of utterances per speaker\n    speaker_ids = np.unique(utterances_per_speaker[:, 0])\n    num_utterances = np.unique(utterances_per_speaker[:, 1], return_counts=True)[1]\n    # Limit the number of speakers to plot\n    if len(speaker_ids) > max_speakers:\n        speaker_ids = speaker_ids[:max_speakers]\n    # Flatten the embeddings\n    embeds_flat = embeds[utterances_per_speaker[:, 0].argsort()]\n    # Assign colors based on speaker identity\n    colors = np.repeat(speaker_ids, num_utterances)\n    # Plot the embeddings\n    plt.scatter(embeds_flat[:, 0], embeds_flat[:, 1], c=colors, cmap='hsv', s=0.1)\n    # Set the plot title\n    plt.title(f'Step: {step}')\n    # Update the plot if enabled\n    if self.update_plot:\n        plt.pause(0.01)\n    # Clear the plot\n    plt.clf()\n    # Save the plot if a path is specified\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n\n\n\n\n", "CodeBleu_score": 38.990671688430425}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    x_size = x.size()\n    speaker_embedding_size = speaker_embedding.size()\n\n    # Determine the appropriate dimension index for the speaker embedding\n    if len(x_size) == 3:\n        speaker_embedding_dim_index = 2\n    elif len(x_size) == 4:\n        speaker_embedding_dim_index = 3\n    else:\n        raise ValueError(\"Input tensor must be 3D or 4D\")\n\n    # Repeat the speaker embedding to match the length of the input text\n    speaker_embedding = speaker_embedding.repeat_interleave(x_size[speaker_embedding_dim_index], dim=speaker_embedding_dim_index)\n\n    # Reshape and transpose the speaker embedding\n    speaker_embedding = speaker_embedding.reshape(speaker_embedding_size[0], speaker_embedding_size[1], -1)\n    speaker_embedding = speaker_embedding.transpose(1, speaker_embedding_dim_index)\n\n    # Concatenate the speaker embedding with the input tensor\n    x = torch.cat([x, speaker_embedding], dim=speaker_embedding_dim_index)\n\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.313740816183653}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    x_size = x.size()\n    speaker_embedding_size = speaker_embedding.size()\n\n    # Determine the appropriate dimension index for the speaker embedding\n    speaker_embedding_dim = speaker_embedding.dim()\n    speaker_embedding_index = speaker_embedding_dim - 1\n\n    # Repeat the speaker embedding to match the length of the input text\n    speaker_embedding = speaker_embedding.repeat_interleave(x_size[speaker_embedding_index], dim=speaker_embedding_index)\n\n    # Reshape and transpose the speaker embedding\n    speaker_embedding = speaker_embedding.reshape(x_size[:speaker_embedding_index] + speaker_embedding_size)\n    speaker_embedding = speaker_embedding.transpose(0, speaker_embedding_index)\n\n    # Concatenate the speaker embedding with the input tensor along the last dimension\n    x = torch.cat((x, speaker_embedding), dim=-1)\n\n    return x\n\n\n\n\n", "CodeBleu_score": 31.092261091597152}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    x_size = x.size()\n    speaker_embedding_size = speaker_embedding.size()\n\n    # Determine the appropriate dimension index for the speaker embedding\n    if x_size[-1] == speaker_embedding_size[-1]:\n        # If the last dimension of the input tensor matches the speaker embedding,\n        # use the last dimension as the speaker embedding dimension\n        speaker_embedding_dim = -1\n    elif x_size[-2] == speaker_embedding_size[-1]:\n        # If the second-to-last dimension of the input tensor matches the speaker embedding,\n        # use the second-to-last dimension as the speaker embedding dimension\n        speaker_embedding_dim = -2\n    else:\n        # If the dimensions do not match, raise an error\n        raise ValueError(\n            \"The last dimension of the input tensor must match the speaker embedding.\"\n        )\n\n    # Repeat the speaker embedding to match the length of the input text\n    speaker_embedding = speaker_embedding.repeat_interleave(\n        x_size[speaker_embedding_dim], dim=speaker_embedding_dim\n    )\n\n    # Reshape and transpose the speaker embedding\n    speaker_embedding = speaker_embedding.reshape(\n        *x_size[:speaker_embedding_dim], -1, *x_size[speaker_embedding_dim + 1 :]\n    )\n    speaker_embedding = speaker_embedding.transpose(\n        speaker_embedding_dim, speaker_embedding_dim + 1\n    )\n\n    # Concatenate the speaker embedding with the input tensor along the last dimension\n    x = torch.cat([x, speaker_embedding], dim=-1)\n\n    return x", "CodeBleu_score": 15.104624732452635}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters.device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    cumulative_attn_weights = torch.zeros(batch_size, seq_len, device=device)\n    attention = torch.zeros(batch_size, seq_len, device=device)\n    return cumulative_attn_weights, attention\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.246967669205283}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len = encoder_seq_proj.size()\n    self.cum_attn = torch.zeros(batch_size, seq_len, device=device)\n    self.attn = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.557161475133555}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters().device\n    batch_size, seq_len = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(batch_size, seq_len, device=device)\n    self.attention = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n", "CodeBleu_score": 28.41362016100933}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))\n\n", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))\n\n", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))\n\n", "CodeBleu_score": 93.4714524643972}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    if _curly_re.match(text):\n        sequence += _arpabet_to_sequence(text)\n    else:\n        sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 30.00734039387863}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    # Check for curly braces and treat their contents as ARPAbet:\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _clean_text(text, cleaner_names)\n            break\n        sequence += _clean_text(m.group(1), cleaner_names)\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n    # Append EOS token\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n", "CodeBleu_score": 64.29867132323726}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    if _curly_re.match(text):\n        sequence += _arpabet_to_sequence(text)\n    else:\n        sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 30.00734039387863}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        if symbol_id in _arpabet:\n            result += _arpabet[symbol_id] + ' '\n        else:\n            result += _symbol_to_id[symbol_id] + ' '\n    result = result.strip()\n    return result\n\n", "CodeBleu_score": 38.786491724355876}, {"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        if symbol_id in ARPABET_TO_ID:\n            symbol = ARPABET_TO_ID[symbol_id]\n            if symbol == ' ':\n                result += '|'\n            elif symbol == '':\n                result += ' '\n            else:\n                result += symbol\n        else:\n            result += '{%s}' % symbol_id\n    # Ensure that ARPAbet is separated from the symbols surrounding it.\n    result = result.replace('}{', ' } { ')\n    return result\n\n", "CodeBleu_score": 38.961775139273655}, {"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        if symbol_id in _arpabet:\n            result += _arpabet[symbol_id] + ' '\n        else:\n            result += _symbol_to_id[symbol_id] + ' '\n    result = result.strip()\n    result = re.sub(r'\\{', '{ ', result)\n    result = re.sub(r'\\}', ' }', result)\n    result = re.sub(r'\\s+', ' ', result)\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.53822466102683}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Verify encoder model path exists and is readable\n    if not encoder_model_fpath.exists() or not encoder_model_fpath.is_file():\n        raise Exception(\"Encoder model not found: {}\".format(encoder_model_fpath))\n\n    # Create output directory for embeddings\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    if not embed_dir.exists():\n        embed_dir.mkdir(parents=True, exist_ok=True)\n\n    # Get a list of all embedding sub-directories\n    embedding_subdirs = [x for x in embed_dir.iterdir() if x.is_dir()]\n\n    # Get a list of all embedding sub-directories that should be processed\n    embedding_subdirs = [x for x in embedding_subdirs if not x.joinpath(\"embedding.pt\").exists()]\n\n    # Create a multiprocessing pool and process each sub-directory using the pool\n    with Pool(n_processes) as p:\n        list(\n            tqdm(\n                p.imap(\n                    partial(\n                        _process_embedding_subdir,\n                        encoder_model_fpath=encoder_model_fpath,\n                    ),\n                    embedding_subdirs,\n                ),\n                total=len(embedding_subdirs),\n                desc=\"Creating embeddings\",\n            )\n        )\n\n", "CodeBleu_score": 35.94021843455959}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Verify encoder model path exists and is readable\n    if not encoder_model_fpath.exists() or not encoder_model_fpath.is_file():\n        raise FileNotFoundError(\"Encoder model file not found: {}\".format(encoder_model_fpath))\n    # Create output directory for embeddings\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n    # Get a list of all embedding files\n    embedding_files = [f.name for f in embed_dir.glob(\"*.npy\")]\n    # Get a list of all metadata files\n    metadata_files = [f.name for f in synthesizer_root.joinpath(\"METADATA\").glob(\"*.txt\")]\n    # Get a list of all audio files\n    audio_files = [f.name for f in synthesizer_root.joinpath(\"AUDIO\").glob(\"*.wav\")]\n    # Get a list of all embedding files that are missing an audio file\n    missing_audio_files = [f for f in embedding_files if f.rsplit(\".\", 2)[0] + \".wav\" not in audio_files]\n    # Get a list of all embedding files that are missing a metadata file\n    missing_metadata_files = [f for f in embedding_files if f.rsplit(\".\", 2)[0] + \".txt\" not in metadata_files]\n    # Get a list of all audio files that are missing a metadata file\n    missing_metadata_audio_files = [f.rsplit(\".\", 2)[0] + \".wav\" for f in missing_metadata_files]\n    # Get a list of all audio files that are missing an embedding file\n    missing_embedding_audio_files = [f for f in missing_metadata_audio_files if f + \".npy\" not in embedding_files]\n    # Get a list of all metadata files that are missing an embedding file\n    missing_embedding_metadata_files = [f.rsplit(\".\", 2)[0] + \".txt\" for f in missing_embedding_audio_files]\n    # Get a list of all metadata files that are missing an audio file\n    missing_", "CodeBleu_score": 40.36438499419952}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check if the encoder model file exists\n    if not encoder_model_fpath.exists():\n        raise Exception(\"Encoder model file does not exist: {}\".format(encoder_model_fpath))\n\n    # Check if the metadata file exists\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    if not metadata_fpath.exists():\n        raise Exception(\"Metadata file does not exist: {}\".format(metadata_fpath))\n\n    # Create output directories for embeddings\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    if not embed_dir.exists():\n        embed_dir.mkdir(parents=True)\n\n    # Create a list of file paths for embedding\n    wav_dir = synthesizer_root.joinpath(\"wavs\")\n    if not wav_dir.exists():\n        raise Exception(\"Wav files directory does not exist: {}\".format(wav_dir))\n    wav_fpaths = list(wav_dir.glob(\"*.wav\"))\n    if len(wav_fpaths) == 0:\n        raise Exception(\"No wav files found in: {}\".format(wav_dir))\n\n    # Create a metadata file for embedding\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    if not metadata_fpath.exists():\n        raise Exception(\"Metadata file does not exist: {}\".format(metadata_fpath))\n\n    # Load the encoder\n    print(\"Loading the encoder...\")\n    encoder = load_encoder(encoder_model_fpath)\n\n    # Create a pool of workers\n    pool = Pool(n_processes)\n    # Create a function to be mapped over\n    create_embedding_worker = partial(\n        create_embedding,\n        encoder=encoder,\n        synthesizer_root=synthesizer_root,\n        embed_dir=embed_dir,\n        metadata_fpath=metadata_fpath,\n    )\n    # Map the function to the list of wav file paths\n    list(\n        tqdm(\n            pool.imap(create_embedding_worker, wav_f", "CodeBleu_score": 39.41117372759616}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"attention_{sample_num}\"))\n\n    # Save predicted mel spectrogram\n    mel_prediction = mel_prediction.detach().cpu().numpy()\n    mel_prediction = mel_prediction.reshape(1, mel_prediction.shape[0], mel_prediction.shape[1])\n    mel_prediction = np.squeeze(mel_prediction, axis=0)\n    audio.inv_mel_spectrogram(mel_prediction, mel_output_dir.joinpath(f\"mel_{sample_num}.wav\"))\n\n    # Save reconstructed waveform\n    audio.save_wav(mel_prediction, wav_dir.joinpath(f\"wav_{sample_num}.wav\"))\n\n    # Generate and save mel spectrogram comparison plot\n    plot_spectrogram(mel_prediction, plot_dir.joinpath(f\"mel_{sample_num}\"),\n                     title=f\"{hparams.model} - Step: {step} - Loss: {loss:.4f}\",\n                     target_spectrogram=target_spectrogram,\n                     max_len=hparams.max_iters)\n\n    # Print input sequence\n    print(f\"", "CodeBleu_score": 23.777652539198613}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"{sample_num}_attention_{step}\"))\n\n    # Save predicted mel spectrogram\n    mel_prediction = mel_prediction.data.cpu().numpy()\n    np.save(mel_output_dir.joinpath(f\"{sample_num}_mel_prediction_{step}.npy\"), mel_prediction)\n\n    # Save reconstructed waveform\n    audio.save_wav(mel_prediction, wav_dir.joinpath(f\"{sample_num}_mel_prediction_{step}.wav\"), sr=hparams.sampling_rate)\n\n    # Plot predicted and target mel spectrograms\n    title = f\"{hparams.model_type} {time_string()} Step: {step} Loss: {loss:.5f}\"\n    plot_spectrogram(mel_prediction, plot_dir.joinpath(f\"{sample_num}_mel_prediction_{step}.png\"), title=title, split_title=True, target_spectrogram=target_spectrogram)\n\n    # Print input sequence\n    input_seq = input_seq.data.cpu().numpy()\n    input_seq = sequence_to_text(input_seq)\n    print(f\"Step: {step}, Input: {input_seq}\")\n\n", "CodeBleu_score": 25.441482980870937}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"{sample_num}-{step}-attention\"))\n\n    # Save predicted mel spectrogram\n    plot_spectrogram(mel_prediction.detach().cpu().numpy(), mel_output_dir.joinpath(f\"{sample_num}-{step}-mel-prediction\"))\n\n    # Save reconstructed waveform\n    audio.save_wav(mel_prediction, wav_dir.joinpath(f\"{sample_num}-{step}-reconstructed.wav\"), hparams)\n\n    # Plot predicted vs target mel spectrogram\n    plot_spectrogram(target_spectrogram.detach().cpu().numpy(), plot_dir.joinpath(f\"{sample_num}-{step}-mel-target\"),\n                     title=f\"{time_string()} step {step} loss {loss:.4f}\", split_title=True,\n                     target_spectrogram=target_spectrogram.detach().cpu().numpy(), auto_aspect=True)\n\n    # Print input sequence\n    print(f\"", "CodeBleu_score": 22.68013359261162}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    num_trainable_params = sum(p.size for p in self.parameters() if p.requires_grad)\n    print(f\"The model has {num_trainable_params / 1000000:.3f} million trainable parameters\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 16.131954812023277}, {"code": "def num_params(self)\n\t\n    num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    num_params = num_params / 1000000\n    print(f\"The model has {num_params:.3f} million trainable parameters\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 17.947000730130704}, {"code": "def num_params(self)\n\t\n    num_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f\"The model has {num_params / 1e6:.3f}M trainable parameters\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 14.098628722566042}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        x = torch.cat((torch.zeros(x.size(0), pad, x.size(2)).type_as(x), x, torch.zeros(x.size(0), pad, x.size(2)).type_as(x)), dim=1)\n    elif side == 'before':\n        x = torch.cat((torch.zeros(x.size(0), pad, x.size(2)).type_as(x), x), dim=1)\n    elif side == 'after':\n        x = torch.cat((x, torch.zeros(x.size(0), pad, x.size(2)).type_as(x)), dim=1)\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.846536059666896}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        new_size = x.size(0) + pad * 2\n    elif side == 'before':\n        new_size = x.size(0) + pad\n    elif side == 'after':\n        new_size = x.size(0) + pad\n    else:\n        raise ValueError('Invalid side argument. Must be either \"before\", \"after\", or \"both\".')\n    if x.is_cuda:\n        padded_x = torch.zeros(new_size, x.size(1), x.size(2), device=x.device)\n    else:\n        padded_x = torch.zeros(new_size, x.size(1), x.size(2))\n    if side == 'both':\n        padded_x[pad:pad + x.size(0)] = x\n    elif side == 'before':\n        padded_x[pad:] = x\n    elif side == 'after':\n        padded_x[:x.size(0)] = x\n    return padded_x\n\n", "CodeBleu_score": 33.179208551802645}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    # x is a tensor of shape (batch_size, channels, time)\n    # pad is a tuple of two integers (left, right)\n    # side is a string indicating the side of the tensor to pad ('before', 'after', or 'both')\n    # if side is 'both', the tensor is padded on both sides\n    # if side is 'before', the tensor is padded on the left side\n    # if side is 'after', the tensor is padded on the right side\n    # if side is not one of these, the function returns None\n    if side not in ['before', 'after', 'both']:\n        return None\n    if side == 'both':\n        pad = (pad[0] + pad[1], pad[0] + pad[1])\n    elif side == 'before':\n        pad = (pad[0], 0)\n    elif side == 'after':\n        pad = (0, pad[1])\n    # calculate the new size of the tensor after padding\n    new_size = (x.size(0), x.size(1), x.size(2) + pad[0] + pad[1])\n    # create a new tensor filled with zeros on either the CPU or GPU, depending on availability\n    padded_x = torch.zeros(new_size, dtype=x.dtype, device=x.device)\n    # place the original tensor into this new padded tensor according to the specified side\n    if side == 'before':\n        padded_x[:, :, pad[0]:pad[0] + x.size(2)] = x\n    elif side == 'after':\n        padded_x[:, :, pad[1]:pad[1] + x.size(2)] = x\n    else:\n        padded_x[:, :, pad[0]:pad[0] + x.size(2)] = x\n    return padded_x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.07053839415328}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(1,1,1)\n    ax.imshow(attn, cmap='jet', alpha=0.5)\n    ax.set_xticks(range(attn.shape[1]))\n    ax.set_yticks(range(attn.shape[0]))\n    ax.set_xticklabels(range(attn.shape[1]))\n    ax.set_yticklabels(range(attn.shape[0]))\n    ax.set_xlabel('Head')\n    ax.set_ylabel('Layer')\n    ax.set_title('Attention')\n    plt.savefig(path + '.png')\n    plt.close()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.53932651970601}, {"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    plt.imshow(attn, cmap='Blues', alpha=0.5, interpolation='nearest')\n    plt.savefig(path + '.png')\n    plt.close(fig)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.82756990082421}, {"code": "def save_attention(attn, path)\n\t\n    plt.close()\n    fig = plt.figure(figsize=(15, 15))\n    plt.imshow(attn, cmap='Blues', interpolation='nearest')\n    plt.savefig(path, bbox_inches='tight')\n    plt.close()\n\n", "CodeBleu_score": 38.815608042018724}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    # Create a dictionary with the image name, prediction, and confidence\n    data = {\n        \"image_name\": image_name,\n        \"prediction\": prediction,\n        \"confidence\": confidence\n    }\n\n    # Open the CSV file in append mode, creating it if it doesn't exist\n    with open(\"predictions.csv\", \"a\", newline=\"\") as csv_file:\n        # Create a CSV writer object\n        writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n\n        # If the file is new, write the header\n        if not csv_file.tell():\n            writer.writeheader()\n\n        # Write the data as a new row\n        writer.writerow(data)", "CodeBleu_score": 54.46366795304605}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'image_name': image_name, 'prediction': prediction, 'confidence': confidence}\n    with open('predictions.csv', 'a', newline='') as csv_file:\n        fieldnames = ['image_name', 'prediction', 'confidence']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        if csv_file.tell() == 0:\n            writer.writeheader()\n        writer.writerow(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.583666263918154}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    # Create a dictionary with the image name, prediction, and confidence\n    data = {\"image_name\": image_name, \"prediction\": prediction, \"confidence\": confidence}\n    # Open the CSV file in append mode\n    with open(\"predictions.csv\", \"a\", newline=\"\") as csv_file:\n        # Create a CSV writer\n        writer = csv.DictWriter(csv_file, fieldnames=[\"image_name\", \"prediction\", \"confidence\"])\n        # Write the header if the file is new\n        if not csv_path.is_file():\n            writer.writeheader()\n        # Write the data as a new row\n        writer.writerow(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.384615405138376}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} exporting {file}\")  # print to console\n    with torch.no_grad():\n        if isinstance(im, torch.Tensor):  # single image\n            im = im.half() if model.fp16 else im.float()  # fp16 to fp32\n            im = im[None]  # expand for batch dim\n        elif isinstance(im, list):  # multiple images\n            im = torch.stack([img.half() if model.fp16 else img.float() for img in im])\n        else:\n            raise Exception(f\"Export Error: {type(im)}\")\n\n        # Warmup\n        if model.jit or optimize:\n            _ = model(im)\n            torch.cuda.empty_cache()\n\n        # TorchScript tracing and export\n        with torch.jit.optimized_execution(True):\n            with torch.jit.autograd_graph():\n                trace_model = torch.jit.trace(model.model, im)\n        trace_model.save(file)\n        LOGGER.info(f\"{prefix} optimized model saved as {file}\")\n\n        # Print model\n        model_info(trace_model, verbose=False)\n\n        # Print JIT graph\n        LOGGER.info(f\"{prefix} JIT graph saved as {file.with_suffix('.jit.txt')}\")\n        jit_graph = str(torch.jit.script(model.model, im))\n        with open(file.with_suffix(\".jit.txt\"), \"w\") as f:\n            f.write(jit_graph)\n\n        # Print optimized graph\n        if optimize:\n            LOGGER.info(f\"{prefix} optimized model saved as {file.with_suffix('.opt.txt')}\")\n            opt_graph = _save_for_lite_interpreter(trace_model)\n            with open(file.with_suffix(\".opt.txt\"), \"w\") as f:\n                f.write(opt_graph)\n\n        return file\n\n", "CodeBleu_score": 35.75620842620584}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} exporting {file}\")  # print to console\n    model.eval()  # set model to inference mode\n\n    # Trace model\n    y = torch.jit.trace(model, im)  # trace model\n    LOGGER.info(f\"{prefix} traced {file}\")\n\n    # Save\n    if optimize:\n        try:  # optimize for mobile\n            from torch.utils.mobile_optimizer import optimize_for_mobile\n\n            y = optimize_for_mobile(y)\n            LOGGER.info(f\"{prefix} optimized {file}\")\n        except Exception as e:\n            LOGGER.info(f\"{prefix} optimize failed: {e}\")\n\n    # Save torchscript model\n    ts = y.eval()\n    ts.save(file)\n    LOGGER.info(f\"{prefix} saved {file}\")\n    return file\n\n", "CodeBleu_score": 34.845503038900816}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} exporting {file}\")  # print to console\n    ts = torch.jit.trace(model.model, im)  # trace model\n    ts.save(file)  # save TorchScript model\n    _save_for_lite_interpreter(model, file)  # export for mobile\n    return file, None\n\n", "CodeBleu_score": 23.588791572906963}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"{prefix} exporting {file}\")\n        file = Path(file).with_suffix(\".mlmodel\")\n        traced_model = torch.jit.trace(model, im)\n        ct_model = ct.convert(traced_model, inputs=[ct.ImageType(name=\"image\", shape=im.shape)])\n        if nms:\n            ct_model = ct.models.utils.convert_neural_network_graph(\n                ct_model._spec,\n                neural_network=ct.models.neural_network.NeuralNetwork(\n                    classifier_config=ct.ClassifierConfig(\n                        class_labels=model.names,\n                        predicted_feature_name=\"classLabel\",\n                        predicted_probabilities_output_name=\"classProbability\",\n                    ),\n                    description=\"YOLOv5\",\n                ),\n            )\n        if int8:\n            ct_model = quantize_weights(ct_model, int8=int8)\n        if half:\n            ct_model = quantize_weights(ct_model, half=half)\n        ct_model.save(file)\n        LOGGER.info(f\"{prefix} export success: {file}\")\n        return file, ct_model\n    except Exception as e:\n        LOGGER.info(f\"{prefix} export failure: {e}\")\n\n", "CodeBleu_score": 44.1365094390655}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    # Check requirements\n    check_requirements([\"coremltools\"], prefix=prefix)\n\n    # Log start\n    LOGGER.info(f\"{prefix} Exporting {file}\")\n\n    # Set file suffix\n    file = Path(file).with_suffix(\".mlmodel\")\n\n    # Wrap model with iOSModel for NMS support\n    if nms:\n        model = iOSModel(model)\n\n    # Trace model\n    traced_model = trace(im, model, int8=int8, half=half)\n\n    # Convert to CoreML\n    ct_model = convert(traced_model)\n\n    # Apply quantization\n    if int8 or half:\n        ct_model = quantize_weights(ct_model)\n\n    # Save CoreML model\n    ct_model.save(file)\n\n    return file, ct_model\n\n", "CodeBleu_score": 22.55782168567802}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n    except ImportError:\n        raise ImportError(\"Install coremltools with `pip install coremltools`\")\n    LOGGER.info(f\"{prefix} Exporting {file}\")\n    file = Path(file)\n    file.with_suffix(\".mlmodel\")\n    traced_model = torch.jit.trace(model, im)\n    ct_model = ct.convert(\n        traced_model,\n        inputs=[ct.TensorType(shape=im.shape)]\n    )\n    if nms:\n        ct_model = iOSModel(ct_model)\n    if int8:\n        ct_model.convert_image_input_dtype = ct.ImageType.UINT8\n    if half:\n        ct_model.convert_precision = ct.float16\n    ct_model.save(file)\n    return file, ct_model\n\n", "CodeBleu_score": 32.47734309549282}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for _ in range(individual_length):\n        individual.append(random.uniform(input_ranges[0], input_ranges[1]))\n    return individual\n\n", "CodeBleu_score": 39.41234669340793}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.630972577458174}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule == \"discrete\":\n        return torch.log(self.alphas[t])\n    elif self.schedule == \"linear\":\n        return torch.log(self.alphas[t]) - self.log_alpha_fn(t)\n    elif self.schedule == \"cosine\":\n        return torch.log(self.alphas[t]) - self.log_alpha_fn(t)\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 28.05881762808185}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == \"discrete\":\n        return torch.log(self.alpha_bar[t])\n    elif self.schedule_type == \"linear\":\n        return self.log_alpha_fn(t)\n    elif self.schedule_type == \"cosine\":\n        return self.log_alpha_fn(t)\n    else:\n        raise ValueError(f\"Schedule type {self.schedule_type} not recognized.\")\n\n", "CodeBleu_score": 23.452051346386828}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule == \"discrete\":\n        return self.log_alpha_fn(t)\n    elif self.schedule == \"linear\":\n        return self.log_alpha_fn(t) - self.log_alpha_fn(self.T)\n    elif self.schedule == \"cosine\":\n        return self.log_alpha_fn(t) - self.log_alpha_fn(self.T) + self.log_alpha_0\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 30.034074811354916}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.linear_schedule:\n        beta = self.beta_t[0]\n        beta_t = torch.arange(1, self.T + 1, device=lamb.device)\n        beta_t = beta_t.unsqueeze(0).expand(lamb.shape[0], -1)\n        beta_t = beta_t * beta\n        t = (torch.sqrt(1 + 4 * beta_t * (2 * self.T + 1 - beta_t)) - 1) / (2 * beta_t)\n        t = torch.clamp(t, 0, self.T)\n    elif self.discrete_schedule:\n        log_alpha = torch.cumsum(self.log_alpha_t, dim=1)\n        t = interpolate_fn(lamb, self.lamb_t, log_alpha)\n        t = torch.clamp(t, 0, self.T)\n    else:\n        lamb = torch.clamp(lamb, -1, 0)\n        t = torch.acos(torch.sqrt(1 - lamb ** 2)) / self.log_alpha_t\n        t = torch.clamp(t, 0, self.T)\n    return t\n\n", "CodeBleu_score": 31.759554951409147}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"cosine\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad_log\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad_log_linear\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad_log_linear_beta\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad_log_linear_beta_v2\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) / self.beta\n        return t\n    elif self.schedule == \"quad_log_linear_beta_v3\":\n        # t = (1 - np.exp(-lamb * self.beta)) / self.beta\n        t = (1 - torch.exp(-lamb * self.beta)) /", "CodeBleu_score": 22.451251962703083}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        return self.T - torch.log(1 - torch.exp(lamb)) / self.beta\n    elif self.schedule == \"quad\":\n        return self.T - torch.log(1 - torch.exp(lamb)) / (2 * self.beta)\n    elif self.schedule == \"sqrt\":\n        return self.T - torch.log(1 - torch.exp(lamb)) / (2 * torch.sqrt(self.beta))\n    elif self.schedule == \"none\":\n        return lamb\n    elif self.schedule == \"cosine\":\n        return torch.arccos(torch.sqrt(1 - torch.exp(-2 * lamb))) / (2 * torch.pi) * self.T\n    elif self.schedule == \"discrete\":\n        return interpolate_fn(lamb, self.log_alpha, self.t_fn)\n    else:\n        raise NotImplementedError(f\"Schedule {self.schedule} not implemented.\")\n\n", "CodeBleu_score": 23.302023724270313}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    if model.model_type == \"DDPM\":\n        t_expanded = expand_dims(t_continuous, x.dim())\n        epsilon = model(x, t_expanded)\n        alpha = noise_schedule.marginal_alpha(t_continuous)\n        alpha_expanded = expand_dims(alpha, x.dim())\n        epsilon = alpha_expanded * epsilon\n        return epsilon\n    elif model.model_type == \"DDIM\":\n        t_expanded = expand_dims(t_continuous, x.dim())\n        epsilon = model(x, t_expanded)\n        alpha = noise_schedule.marginal_alpha(t_continuous)\n        sigma = noise_schedule.marginal_std(t_continuous)\n        alpha_expanded = expand_dims(alpha, x.dim())\n        sigma_expanded = expand_dims(sigma, x.dim())\n        epsilon = alpha_expanded * epsilon + sigma_expanded * torch.randn_like(x)\n        return epsilon\n    elif model.model_type == \"DDPM2\":\n        t_expanded = expand_dims(t_continuous, x.dim())\n        epsilon = model(x, t_expanded)\n        alpha = noise_schedule.marginal_alpha(t_continuous)\n        sigma = noise_schedule.marginal_std(t_continuous)\n        alpha_expanded = expand_dims(alpha, x.dim())\n        sigma_expanded = expand_dims(sigma, x.dim())\n        epsilon = alpha_expanded * epsilon + sigma_expanded * torch.randn_like(x)\n        return epsilon\n    elif model.model_type == \"DDIM2\":\n        t_expanded = expand_dims(t_continuous, x.dim())\n        epsilon = model(x, t_expanded)\n        alpha = noise_schedule.marginal_alpha(t_continuous)\n        sigma = noise_schedule.marginal_std(t_continu", "CodeBleu_score": 35.45524403359134}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, x.dim)\n    if model_type == 'ddpm':\n        noise_pred = model(x, t_continuous)\n    elif model_type == 'ddim':\n        noise_pred = model(x, t_continuous, cond)\n    else:\n        raise ValueError('Model type not recognized.')\n    return noise_pred\n\n", "CodeBleu_score": 10.7064725319092}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    if cond is not None:\n        x = torch.cat([x, cond], dim=1)\n    t_continuous = get_model_input_time(x, t_continuous)\n    if model.model_type == \"DDPM\":\n        noise = model(x, t_continuous)\n        return noise\n    elif model.model_type == \"DDIM\":\n        alpha_t = noise_schedule.marginal_alpha(t_continuous)\n        alpha_t_prev = noise_schedule.marginal_alpha(t_continuous - 1)\n        sigma_t = noise_schedule.marginal_std(t_continuous)\n        sigma_t_prev = noise_schedule.marginal_std(t_continuous - 1)\n        noise = model(x, t_continuous)\n        return (alpha_t_prev * (x - sigma_t_prev * noise) / sigma_t / alpha_t_prev).squeeze()\n    elif model.model_type == \"DDPM2\":\n        alpha_t = noise_schedule.marginal_alpha(t_continuous)\n        alpha_t_prev = noise_schedule.marginal_alpha(t_continuous - 1)\n        sigma_t = noise_schedule.marginal_std(t_continuous)\n        sigma_t_prev = noise_schedule.marginal_std(t_continuous - 1)\n        noise = model(x, t_continuous)\n        return (alpha_t_prev * (x - sigma_t_prev * noise) / sigma_t / alpha_t_prev).squeeze()\n    elif model.model_type == \"DDPM3\":\n        alpha_t = noise_schedule.marginal_alpha(t_continuous)\n        alpha_t_prev = noise_schedule.marginal_alpha(t_continuous - 1)\n        sigma_t = noise_schedule.marginal_std(t_continuous)\n        sigma_t_prev = noise_schedule.marginal_std(", "CodeBleu_score": 32.571152784661464}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.t\n    x0_abs = torch.abs(x0)\n    x0_abs_reshaped = expand_dims(x0_abs, x0_abs.dim())\n    q_t = torch.quantile(x0_abs_reshaped, t, dim=0)\n    q_t = q_t.to(x0.device)\n    s = torch.maximum(x0_abs, q_t)\n    x0_clamped = torch.clamp(x0, -s, s)\n    x0_scaled = x0_clamped / s\n    return x0_scaled\n\n", "CodeBleu_score": 43.47295264438576}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    x0 = x0.reshape(x0.shape[0], -1)\n    x0_abs = torch.abs(x0)\n    q = torch.quantile(x0_abs, self.quantile, dim=1)\n    q = expand_dims(q, x0.dim())\n    q = torch.maximum(q, self.min_val)\n    q = torch.ones_like(q) * self.max_val\n    q = torch.minimum(q, self.min_val)\n    x0 = torch.clamp(x0, -q, q)\n    x0 = x0 * self.scale\n    return x0\n\n", "CodeBleu_score": 30.75743203818776}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    x0 = x0.reshape(x0.shape[0], -1)\n    x0_abs_quantile = torch.quantile(torch.abs(x0), 0.999, dim=1)\n    x0_abs_quantile = expand_dims(x0_abs_quantile, x0.dim())\n    x0 = torch.maximum(x0, -x0_abs_quantile)\n    x0 = torch.minimum(x0, x0_abs_quantile)\n    x0 = x0 / x0_abs_quantile\n    x0 = torch.clamp(x0, -1.0, 1.0)\n    return x0 * self.dynamic_thresholding_scale\n\n", "CodeBleu_score": 19.389004052876114}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t\n    # Calculate the threshold value based on the dynamic thresholding ratio and maximum threshold value\n    threshold = self.dynamic_thresholding_ratio * torch.max(torch.abs(x))\n    # Clamp the input tensor values within the threshold\n    x_clamped = torch.clamp(x, -threshold, threshold)\n    # Normalize the clamped values and return the processed tensor\n    return x_clamped / threshold\n\n", "CodeBleu_score": 11.314216290643476}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    # Apply dynamic thresholding\n    threshold = self.dynamic_thresholding_fn(x, t)\n    x_thresholded = torch.clamp(x, min=-threshold, max=threshold)\n\n    # Normalize the thresholded values\n    x_normalized = x_thresholded / threshold\n\n    return x_normalized\n\n", "CodeBleu_score": 5.267286807883749}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    threshold = torch.clamp(self.threshold_fn(x, t), 0., self.max_threshold)\n    x = x + torch.quantile(torch.abs(x), self.dynamic_thresholding_ratio) * threshold\n    x = torch.clamp(x, -threshold, threshold)\n    x = x / (1. - threshold)\n    return x\n", "CodeBleu_score": 15.28354486182807}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    input_scaled = input / sigma_in\n    pred = model(input_scaled)\n    pred_scaled = pred * sigma_in\n    return pred_scaled\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 19.531800636310745}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    scaled_input = input / sigma_in\n    output = model(scaled_input, **kwargs)\n    adjusted_output = output * sigma_in\n    return adjusted_output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.431093949484577}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(sigma_in.size(0), -1)\n    scaled_input = input / sigma_in\n    pred = model(scaled_input, **kwargs)\n    return pred * sigma_in\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.588627715762552}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone()\n        taus.requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        log_alpha.backward(torch.ones_like(log_alpha))\n        taus_grad = taus.grad\n        integrand = taus_grad * alpha\n    return integrand\n\n", "CodeBleu_score": 45.998728111116215}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone()\n        taus.requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        log_alpha.backward(torch.ones_like(log_alpha))\n        integrand = log_alpha * taus.grad\n    return integrand\n\n", "CodeBleu_score": 43.09931558760894}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        log_alpha.backward(torch.ones_like(log_alpha))\n        taus_grad = taus.grad\n        integrand = taus_grad * alpha\n    return integrand\n\n", "CodeBleu_score": 42.14635404701197}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if disable is None:\n        disable = False\n    if callback is None:\n        callback = lambda x, i, t: None\n    if isinstance(sigmas, torch.Tensor):\n        sigmas = sigmas.tolist()\n    extra_args_fn = lambda t: extra_args[int(t)] if isinstance(extra_args, dict) else lambda: extra_args\n    x = x.to(dtype=torch.float32)\n    for i, sigma in enumerate(sigmas):\n        sigma_prev = sigmas[i - 1] if i else 1\n        sigma_down, sigma_up = get_ancestral_step(sigma_prev, sigma, eta)\n        model_fn = lambda x: model(x, sigma_down, **extra_args_fn(sigma_down))\n        denoised = utils.noise_like(x)\n        denoised = samplers.sample_euler(model_fn, x, sigma_up, denoised)\n        x = x + to_d(x, sigma, denoised)\n        callback(x, i, sigma)\n    if s_noise:\n        x = samplers.add_noise(x, s_noise)\n    return x\n\n", "CodeBleu_score": 35.59057701527602}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n    if not disable:\n        disable = utils.make_progbar(len(sigmas))\n    for i, sigma in enumerate(sigmas):\n        if not disable:\n            disable.update(i)\n        if callback:\n            callback({'x': x, 'i': i, 'sigma': sigma, **extra_args})\n        sigma_from = sigmas[i - 1] if i > 0 else 0\n        sigma_to = sigmas[i]\n        sigma_down, sigma_up = get_ancestral_step(sigma_from, sigma_to, eta=eta)\n        x = x + to_d(x, sigma, model(x, sigma_down, **extra_args)) * sigma_up\n        if s_noise:\n            x = x + s_noise * noise_sampler(sigma, sigma_to)\n    return x\n\n", "CodeBleu_score": 43.99302568446267}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    x = x.to(dtype=torch.float32)\n    extra_args = model.prepare_extra_args(x, extra_args)\n    sigma_from = sigmas[0]\n    sigma_to = sigmas[1]\n    sigma_down, sigma_up = get_ancestral_step(sigma_from, sigma_to, eta=eta)\n    sigma_up = sigma_up * s_noise\n    if callback:\n        callback(0, x, sigma_from, sigma_to, sigma_up, sigma_down)\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_from = sigmas[i]\n        sigma_to = sigmas[i + 1]\n        sigma_down, sigma_up = get_ancestral_step(sigma_from, sigma_to, eta=eta)\n        sigma_up = sigma_up * s_noise\n        denoised = model(x, sigma_from, **extra_args)\n        x = x + to_d(x, sigma_from, denoised) * sigma_down + noise_sampler(x) * sigma_up\n        if callback:\n            callback(i, x, sigma_from, sigma_to, sigma_up, sigma_down)\n    denoised = model(x, sigma_to, **extra_args)\n    x = x + to_d(x, sigma_to, denoised) * sigma_down\n    if callback:\n        callback(len(sigmas) - 1, x, sigma_from, sigma_to, sigma_up, sigma_down)\n    return x\n\n", "CodeBleu_score": 41.757751523252814}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if j > i:\n        raise ValueError(\"j must be less than or equal to i\")\n    if j == i:\n        return 1\n    if j == i - 1:\n        return t[i] - t[i-1]\n    if j == i - 2:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2])\n    if j == i - 3:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2]) * (t[i] - t[i-3])\n    if j == i - 4:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2]) * (t[i] - t[i-3]) * (t[i] - t[i-4])\n    if j == i - 5:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2]) * (t[i] - t[i-3]) * (t[i] - t[i-4]) * (t[i] - t[i-5])\n    if j == i - 6:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2]) * (t[i] - t[i-3]) * (t[i] - t[i-4]) * (t[i] - t[i-5]) * (t[i] - t[i-6])\n    if j == i - 7:\n        return (t[i] - t[i-1]) * (t[i] - t[i-2]) * (t[i] - t[i-3]) * (t[i] - t[i-4]) * (t[i] - t[i-5]) * (t[i] - t[i-6]) * (t[i] - t[i-7])\n    if j == i - 8:\n        return (t[i] - t[i-1]) * (t[i", "CodeBleu_score": 16.59489380314274}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order > 2*i:\n        raise ValueError(\"Order too high for step index.\")\n    def product_term(k):\n        if k == j:\n            return 0\n        elif k < j:\n            return (t[i+1] - t[k+1]) / (t[i] - t[k])\n        else:\n            return (t[i+1] - t[k]) / (t[i] - t[k-1])\n    return sum(product_term(k) for k in range(order))\n\n\n\n\n", "CodeBleu_score": 30.520094095548473}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order > j:\n        raise ValueError(\"Order too high for step index.\")\n    def product_term(k):\n        if k == j:\n            return 1\n        else:\n            return (t[i+1] - t[k]) / (t[i] - t[k])\n    return integrate.quad(product_term, i, j)[0]\n\n", "CodeBleu_score": 25.301240438506355}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n\n    if extra_args is None:\n        extra_args = {}\n\n    x = x.to(model.device)\n    sigmas = sigmas.to(model.device)\n    sigma_min = sigmas[0]\n    sigma_max = sigmas[-1]\n\n    if sigma_min == 0:\n        x = model(x, sigmas, **extra_args)\n    else:\n        x = model(x, sigmas, **extra_args)\n\n    if callback is not None:\n        callback(0, x)\n\n    for i in trange(len(sigmas) - 1, disable=disable):\n        sigma_next = sigmas[i + 1]\n        sigma_prev = sigmas[i]\n\n        if sigma_next == 0:\n            x = model(x, sigmas[i:i + 1], **extra_args)\n        else:\n            noise = noise_sampler(sigma_prev, sigma_next)\n            x = model(x, sigmas[i:i + 2], noise=noise, **extra_args)\n\n        if callback is not None:\n            callback(i + 1, x)\n\n        if sigma_next > sigma_min:\n            x = x / (noise_scaling(sigma_prev, sigma_next) ** 0.5)\n\n    return x\n\n", "CodeBleu_score": 42.366662080595965}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if sigmas[0] != 0:\n        raise ValueError(f\"sigmas[0] must be 0, got {sigmas[0]}\")\n    if sigmas[-1] != 0:\n        raise ValueError(f\"sigmas[-1] must be 0, got {sigmas[-1]}\")\n    sigmas = sigmas[1:-1]\n    if disable is None:\n        disable = len(sigmas) <= trange.SUPPRESS_PROGRESS_BAR\n    for i, sigma in enumerate(tqdm(sigmas, desc=\"Sampling\", disable=disable)):\n        sigma_next = sigmas[min(i + 1, len(sigmas) - 1)]\n        x = model(x, sigma, **extra_args)\n        noise = noise_sampler(x, sigma, sigma_next)\n        if sigma_next > 0:\n            noise = noise * (sigma_next ** noise_scaling)\n        x = x + noise\n        if callback is not None:\n            callback(x, i)\n    return x\n\n", "CodeBleu_score": 37.44396608797098}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = lambda i, x: None\n\n    x = x.to(next(model.parameters()).device)\n    x_init = x.clone()\n    sigmas = torch.as_tensor(sigmas, device=x.device)\n    noise_scaling = sigmas.gt(1e-3).float().mean().item()\n\n    for i, sigma in tqdm(enumerate(sigmas), total=len(sigmas), disable=disable):\n        callback(i, x)\n        x = model(x, sigma=sigma, **extra_args)\n        if sigma.gt(1e-3):\n            noise = noise_sampler(x, sigma, sigmas[i + 1])\n            x = x + noise * (sigma ** noise_scaling)\n\n    return x\n\n", "CodeBleu_score": 39.00690619114629}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t\n    num_dims_to_append = target_dims - x.ndim\n    if num_dims_to_append < 0:\n        raise ValueError(f\"Target dimensions ({target_dims}) must be greater than or equal to the current number of dimensions ({x.ndim})\")\n    for _ in range(num_dims_to_append):\n        x = x.unsqueeze(-1)\n    if x.device.type == 'mps':\n        return x.detach().clone()\n    else:\n        return x\n", "CodeBleu_score": 36.30100259233036}, {"code": "def append_dims(x, target_dims)\n\t\n    num_dims_to_append = target_dims - x.ndim\n    if num_dims_to_append < 0:\n        raise ValueError(f\"Target dimensions ({target_dims}) cannot be fewer than the current dimensions ({x.ndim}).\")\n    x = x.expand(*(x.shape + (1,) * num_dims_to_append))\n    if x.device.type == 'mps':\n        x = x.detach().clone()\n    return x\n\n", "CodeBleu_score": 46.63109340720403}, {"code": "def append_dims(x, target_dims)\n\t\n    num_dims_to_append = target_dims - x.ndim\n    if num_dims_to_append < 0:\n        raise ValueError(f\"Target dimensions ({target_dims}) must be greater than or equal to the current number of dimensions ({x.ndim})\")\n    if x.device.type == 'mps':\n        x = x.detach().clone()\n    return x.expand(*(x.shape + (1,) * num_dims_to_append))\n\n", "CodeBleu_score": 40.50853318879754}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with urlopen(url) as response, path.open('wb') as out_file:\n            shutil.copyfileobj(response, out_file)\n    if digest and not check_sha256(path, digest):\n        raise OSError(f'{path} has an invalid SHA-256 hash')\n    return path\n", "CodeBleu_score": 33.304860253855615}, {"code": "def download_file(path, url, digest=None)\n\t\n    path = Path(path)\n    if path.exists():\n        return path\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with urlopen(url) as f:\n        with path.open('wb') as out:\n            shutil.copyfileobj(f, out)\n    if digest:\n        with path.open('rb') as f:\n            if hashlib.sha256(f.read()).hexdigest() != digest:\n                raise OSError(f'{path} has incorrect SHA-256 hash')\n    return path\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.281740386873196}, {"code": "def download_file(path, url, digest=None)\n\t\n    if path.exists():\n        return path\n    path.parent.mkdir(parents=True, exist_ok=True)\n    with urlopen(url) as f:\n        with open(path, 'wb') as out:\n            shutil.copyfileobj(f, out)\n    if digest is not None:\n        with open(path, 'rb') as f:\n            file_digest = hashlib.sha256(f.read()).hexdigest()\n        if file_digest != digest:\n            raise OSError(f'SHA-256 digest mismatch for {path}')\n    return path\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.908536155070244}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    model.train = mode\n    for module in model.modules():\n        module.train = mode\n\n", "CodeBleu_score": 19.92784786800984}, {"code": "def train_mode(model, mode=True)\n\t\n    # save the current training modes\n    training_modes = [module.training for module in model.modules()]\n    # set the mode\n    model.train(mode)\n    try:\n        yield model\n    finally:\n        # restore the original training modes\n        for module, mode in zip(model.modules(), training_modes):\n            module.train(mode)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.73491796742438}, {"code": "def train_mode(model, mode=True)\n\t\n    if model.training:\n        model.train()\n    else:\n        model.eval()\n    return model\n\n", "CodeBleu_score": 15.876809929130822}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Check if the averaged model has the same parameters and buffers as the current model\n    assert averaged_model.state_dict().keys() == model.state_dict().keys()\n    assert averaged_model.buffers().keys() == model.buffers().keys()\n\n    # Get the current model's parameters and buffers\n    model_params = model.state_dict()\n    model_buffers = model.buffers()\n\n    # Get the averaged model's parameters and buffers\n    averaged_params = averaged_model.state_dict()\n    averaged_buffers = averaged_model.buffers()\n\n    # Update the averaged model's parameters and buffers using the current model's parameters and buffers\n    for key in averaged_params.keys():\n        averaged_params[key] = decay * averaged_params[key] + (1 - decay) * model_params[key]\n    for key in averaged_buffers.keys():\n        averaged_buffers[key] = decay * averaged_buffers[key] + (1 - decay) * model_buffers[key]\n\n    # Copy the current model's buffers to the averaged model\n    averaged_model.load_state_dict(model_params)\n    averaged_model.load_buffers(model_buffers)\n\n    return averaged_model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.72390453373372}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    # Update the parameters of the averaged model\n    for param, averaged_param in zip(model.parameters(), averaged_model.parameters()):\n        averaged_param.data.mul_(decay).add_(param.data, alpha=1 - decay)\n    # Update the buffers of the averaged model\n    for buffer, averaged_buffer in zip(model.buffers(), averaged_model.buffers()):\n        averaged_buffer.data.copy_(buffer.data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.081729232085518}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    averaged_params = dict(averaged_model.named_parameters())\n    model_params = dict(model.named_parameters())\n    # ensure all parameters are present in both models\n    for name in averaged_params:\n        if name not in model_params:\n            model_params[name] = averaged_params[name]\n    for name in model_params:\n        if name not in averaged_params:\n            averaged_params[name] = model_params[name]\n    # update model params\n    for name, param in model_params.items():\n        averaged_params[name].data.mul_(decay).add_(param.data, alpha=1 - decay)\n    # update model buffers\n    averaged_buffers = dict(averaged_model.named_buffers())\n    model_buffers = dict(model.named_buffers())\n    # ensure all buffers are present in both models\n    for name in averaged_buffers:\n        if name not in model_buffers:\n            model_buffers[name] = averaged_buffers[name]\n    for name in model_buffers:\n        if name not in averaged_buffers:\n            averaged_buffers[name] = model_buffers[name]\n    # update model buffers\n    for name, buffer in model_buffers.items():\n        averaged_buffers[name].data.copy_(buffer.data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 52.88905804348727}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    min_value_log = min_value.log()\n    max_value_log = max_value.log()\n    u = torch.rand(shape, device=device, dtype=dtype)\n    u = u * (max_value_log - min_value_log) + min_value_log\n    u = u.logit()\n    u = u * scale + loc\n    u = u.exp()\n    return u\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.98874766670073}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    min_cdf = min_value.log().sub(1).neg().logit().mul(scale).add(loc)\n    max_cdf = max_value.log().sub(1).neg().logit().mul(scale).add(loc)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    u = u * (max_cdf - min_cdf).add_(min_cdf)\n    x = u.logit().mul(scale).add(loc)\n    x = x.exp()\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.68630268418304}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    u = u * (max_value.log() - min_value.log()) + min_value.log()\n    u = u.logit()\n    u = u * scale + loc\n    return u.exp()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.78885284954988}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return Activation1d(nn.ELU(inplace=True)) if antialias else nn.ELU(inplace=True)\n    if activation == \"snake\":\n        return Activation1d(SnakeBeta(channels)) if antialias else SnakeBeta(channels)\n    if activation == \"none\":\n        return Activation1d(nn.Identity()) if antialias else nn.Identity()\n    raise ValueError(f\"Unknown activation type: {activation}\")", "CodeBleu_score": 43.83824558019267}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return Activation1d(nn.ELU(inplace=True), antialias=antialias)\n    elif activation == \"snake\":\n        return Activation1d(SnakeBeta(channels), antialias=antialias)\n    elif activation == \"none\":\n        return Activation1d(nn.Identity(), antialias=antialias)\n    else:\n        raise ValueError(f\"Unknown activation type: {activation}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.88001973824004}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    if activation == \"snake\":\n        return SnakeBeta(channels=channels)\n    if activation == \"none\":\n        return nn.Identity()\n    if antialias:\n        return Activation1d(get_activation(activation, antialias=False, channels=channels))\n    raise ValueError(f\"Invalid activation: {activation}\")", "CodeBleu_score": 40.464051548192266}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if t.dtype in (torch.float16, torch.bfloat16):\n        t = t.float()\n    t_unrotated = t[..., :, :]\n    t_rot, freqs = rotate_half(t), rotate_half(freqs)\n    pe = torch.einsum('... i , ... j -> ... i j', t_rot, freqs)\n    t_rot = torch.cat((t_rot[..., :, -1:], t_rot[..., :, :-1]), dim = -1)\n    t_rot = torch.sin(pe) * scale + t_rot\n    t_rot = torch.cat((t_rot[..., -1:, :], t_rot[..., :-1, :]), dim = -2)\n    return torch.cat((t_rot, t_unrotated), dim = -1)\n\n", "CodeBleu_score": 36.77751543796963}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if t.dtype in (torch.float16, torch.bfloat16):\n        t = t.float()\n    t_unrotated = t[..., ::2]\n    t_rotated = t[..., 1::2]\n    t_rotated = rearrange(t_rotated, '... (j d) -> ... j d', j = 2)\n    t_rotated = t_rotated * scale\n    t_rotated = t_rotated * freqs.cos()\n    t_rotated = torch.stack((-t_rotated[..., 1], t_rotated[..., 0]), dim = -1)\n    t_rotated = t_rotated.type_as(t)\n    t = torch.cat((t_unrotated, t_rotated), dim = -1)\n    return t\n\n", "CodeBleu_score": 34.2289051374691}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    t2 = t[:, None, :] * freqs[None, :, None]\n    t2 = torch.cat((t2.sin(), t2.cos()), dim = -1)\n    t = torch.cat((t, t2), dim = -1)\n    t = t.to(torch.float32)\n    return t\n\n", "CodeBleu_score": 17.259785975645777}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    codebook = self.codebook\n    idx_flattened = idx.view(-1)\n    embedding_shape = list(idx.shape)\n    embedding_shape[dim] = codebook.shape[0]\n    embedding_flattened = torch.index_select(codebook, dim=0, index=idx_flattened)\n    embedding = embedding_flattened.view(embedding_shape)\n    return embedding\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.90018424380059}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    codebook = self.codebook[idx]\n    if dim != -1:\n        codebook = codebook.movedim(-1, dim)\n    return codebook\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.4639083125685}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    embed = self.codebook[idx]\n    if dim != -1:\n        embed = embed.movedim(-1, dim)\n    return embed", "CodeBleu_score": 37.164775129568426}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t\n    h = self.in_block(x)\n    for i, block in enumerate(self.down_blocks):\n        h = block(h)\n        if i < len(self.down_blocks) - 1:\n            h = self.res_blocks[i](h)\n\n    if quantize:\n        quant = self.quantize(h)\n        return quant\n\n    return h\n\n", "CodeBleu_score": 37.01312705689322}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    x = self.down_blocks(x)\n    if quantize:\n        x, (vq_loss, commit_loss), indices = self.forward(x)\n        return x, (vq_loss, commit_loss), indices\n    else:\n        return x\n\n", "CodeBleu_score": 40.734406896766686}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    if quantize:\n        x, (vq_loss, commit_loss), indices = self.forward(x)\n        return x, indices, vq_loss, commit_loss\n    else:\n        x = self.forward(x, get_losses=False)\n        return x\n\n", "CodeBleu_score": 35.46257786731176}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if not self.enabled:\n        return context\n    if context is None:\n        context = self.no_context()\n    self.store(context.parameters())\n    self.copy_to(context)\n    if self.log_switch:\n        self.logpy.info(\"EMA weights applied\")\n    return context\n\n", "CodeBleu_score": 35.70221715835841}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = self.parameters()\n    self.store(context)\n    self.copy_to(self.model)\n    if self.log:\n        logpy.info(f\"Switching to EMA weights\")\n    return self\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.55556842304336}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        return self\n    else:\n        with context:\n            self.store(self.parameters())\n            self.copy_to(self.model)\n            self.restore(self.parameters())\n            return self\n\n", "CodeBleu_score": 26.40522602514521}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + gate_msa * attn\n    x = self.norm1(x)\n    x = self.modulate(x, shift_mlp, scale_mlp)\n    x = self.gate_mlp(gate_mlp, x)\n    x = self.norm2(x)\n    return x\n\n", "CodeBleu_score": 42.29113273252014}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn @ gate_msa\n    x = self.norm1(x)\n    x = self.modulate(x, shift_mlp, scale_mlp)\n    x = self.gate_mlp(x, gate_mlp)\n    x = self.norm2(x)\n    return x\n\n", "CodeBleu_score": 41.645149417134476}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm1(x)\n    x = self.modulate(x, shift_mlp, scale_mlp)\n    x = self.gate_mlp(x, gate_mlp)\n    x = self.norm2(x)\n    return x\n\n", "CodeBleu_score": 41.8094057125589}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat((qkv_context[0], qkv_x[0]), dim=1)\n    k = torch.cat((qkv_context[1], qkv_x[1]), dim=1)\n    v = torch.cat((qkv_context[2], qkv_x[2]), dim=1)\n    c = optimized_attention(qkv, c.num_heads)\n    context, x = torch.split(c, (context.shape[1], x.shape[1]), dim=1)\n    context = context_block.post_attention(context)\n    x = x_block.post_attention(x)\n    return context, x\n\n", "CodeBleu_score": 20.195040412779342}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat([qkv_context[0], qkv_x[0]], dim=1)\n    kv = torch.cat([qkv_context[1], qkv_x[1]], dim=1)\n    v = torch.cat([qkv_context[2], qkv_x[2]], dim=1)\n    attention_results = optimized_attention(qkv, c.num_heads)\n    context_attention, x_attention = torch.split(attention_results, context.shape[1], dim=1)\n    context_attention = context_block.post_attention(context_attention)\n    x_attention = x_block.post_attention(x_attention)\n    return context_attention, x_attention\n\n", "CodeBleu_score": 18.350266197856733}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv = context_block.pre_attention(context)\n    context_intermediates = qkv[2]\n    qkv = x_block.pre_attention(x)\n    x_intermediates = qkv[2]\n    qkv = torch.cat([qkv[0], qkv[1], context_intermediates], dim=-1)\n    qkv = optimized_attention(qkv, c.num_heads)\n    context, x = torch.split(qkv, [context.shape[1], x.shape[1]], dim=1)\n    context = context_block.post_attention(context)\n    x = x_block.post_attention(x)\n    return context, x\n\n", "CodeBleu_score": 20.3001370027385}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, \"Timesteps must be a one-dimensional tensor\"\n    timesteps = timesteps.float()\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps.float()[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n    if embedding_dim % 2 == 1:\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\n", "CodeBleu_score": 77.84164508141403}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, \"Timesteps must be a one-dimensional tensor\"\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32, device=timesteps.device) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=-1)\n    if embedding_dim % 2 == 1:\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\n", "CodeBleu_score": 71.60244107912649}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1, 'Timesteps input to get_timestep_embedding() must be a one-dimensional tensor of N integers!'\n    # Embed the timestep values\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None].float() * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    # Embed the timestep values\n    if embedding_dim % 2 == 1:\n        emb = torch.cat([emb, torch.zeros_like(emb[:, :1])], dim=1)\n    return emb\n\n\n\n", "CodeBleu_score": 70.80338619839324}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n    try:\n        q = q.reshape(q.shape[0], q.shape[1], -1).transpose(1, 2)\n        k = k.reshape(k.shape[0], k.shape[1], -1).transpose(1, 2)\n        v = v.reshape(v.shape[0], v.shape[1], -1).transpose(1, 2)\n\n        r1 = torch.bmm(q, k)\n        r1 = torch.nn.functional.softmax(r1, dim=2).permute(0,2,1)\n        r1 = torch.bmm(v, r1)\n\n        return r1.reshape(q.shape[0], q.shape[2], q.shape[1])\n    except model_management.OOM_EXCEPTION as e:\n        logging.warning(\"out of memory error, falling back to slice attention\")\n        return slice_attention(q, k, v)\n\n", "CodeBleu_score": 35.552398882507156}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], -1)\n    k = k.view(k.shape[0], k.shape[1], -1)\n    v = v.view(v.shape[0], v.shape[1], -1)\n\n    q = q.transpose(1, 2)\n    k = k.transpose(1, 2)\n    v = v.transpose(1, 2)\n\n    try:\n        return torch.nn.functional.softmax(torch.bmm(q, k) / math.sqrt(q.shape[-1]), dim=2) @ v\n    except RuntimeError as e:\n        if \"out of memory\" in str(e):\n            logging.warning(\"out of memory error, using slice attention as a fallback\")\n            return slice_attention(q, k, v).transpose(1, 2).reshape(q.shape)\n        else:\n            raise e\n\n", "CodeBleu_score": 25.621407162753012}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(*q.shape[:2], -1).transpose(1, 2)\n    k = k.view(*k.shape[:2], -1).transpose(1, 2)\n    v = v.view(*v.shape[:2], -1).transpose(1, 2)\n\n    try:\n        return scaled_dot_product_attention(q, k, v)\n    except model_management.OOM_EXCEPTION:\n        return slice_attention(q, k, v).transpose(1, 2).reshape(*q.shape)\n\n", "CodeBleu_score": 14.53163962390523}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if control:\n            control.pop()\n        if name in h:\n            try:\n                h[name] = control\n            except:\n                logging.warning(format(\"Could not apply control {0} to {1}.\", control, name))\n    return h\n\n", "CodeBleu_score": 36.134403694172626}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name in control:\n        control_value = control.pop(name)\n        try:\n            h.add_control(control_value)\n        except Exception as e:\n            logging.warning(\"Failed to add control %s to %s: %s\", control_value, name, e)\n    return h\n\n", "CodeBleu_score": 37.79628515442276}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if control:\n            control = control.pop()\n            try:\n                h.add(control, name)\n            except Exception:\n                logging.warning('Unable to add control {} to {}'.format(control, name))\n    return h\n\n", "CodeBleu_score": 40.79077785030599}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # convert indices to one-hot encodings\n    min_encodings = torch.zeros(indices.shape[0], self.n_embed, device=indices.device)\n    min_encodings.scatter_(1, indices.view(-1, 1), 1)\n\n    # get quantized latent vectors\n    z_q = torch.matmul(min_encodings, self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n    else:\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.59062991531717}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape specifying (B, H, W, C)\n    # indices specifying (B, H, W)\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings, device=indices.device)\n    min_encodings.scatter_(-1, indices[:, None], 1)\n    min_encodings = min_encodings.view(indices.shape[0], -1)\n    z_q = torch.matmul(min_encodings, self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2)\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 52.848750374463236}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # convert indices to one-hot encodings\n    min_encodings = torch.zeros(indices.shape[0], self.codebook_size, device=indices.device)\n    min_encodings.scatter_(-1, indices.unsqueeze(-1), 1)\n    min_encodings = min_encodings.view(-1, self.codebook_size)\n    # get quantized latent vectors\n    z_q = torch.matmul(min_encodings, self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.325994094193085}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    noise = torch.randn(4, 4).to(self.device)\n    self.noises.append(noise)\n    for i in range(3, self.log_size + 3):\n        factor = 2 ** i\n        noise = torch.randn(factor, factor).to(self.device)\n        self.noises.append(noise)\n        self.noises.append(noise)\n    return self.noises", "CodeBleu_score": 34.18471522316551}, {"code": "def make_noise(self)\n\t\n    noise = torch.randn(4, 4).to(self.device)\n    self.noises = [noise]\n    for i in range(3, self.log_size + 1):\n        factor = 2 ** (i - 2)\n        for _ in range(2):\n            noise = torch.nn.functional.interpolate(noise, scale_factor=2, mode=\"nearest\")\n            self.noises.append(noise)\n    return self.noises\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.8056229684118}, {"code": "def make_noise(self)\n\t\n    noise = torch.randn(4, 4, device=self.device)\n    self.noises.append(noise)\n    for i in range(3, self.log_size + 1):\n        factor = 2 ** i\n        for _ in range(2):\n            noise = torch.randn(factor, factor, device=self.device)\n            self.noises.append(noise)\n    return self.noises\n\n\n\n\n", "CodeBleu_score": 43.80819954264691}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    mean_latent = torch.randn((num_latent, self.latent_dim))\n    mean_latent = self.style_mlp(mean_latent)\n    mean_latent = mean_latent.mean(0)\n    return mean_latent\n\n", "CodeBleu_score": 21.585852283174304}, {"code": "def mean_latent(self, num_latent)\n\t\n    mean_latent = torch.randn(num_latent, self.style_dim, device=self.device)\n    mean_latent = self.style_mlp(mean_latent)\n    mean_latent = torch.mean(mean_latent, dim=0, keepdim=True)\n    return mean_latent\n", "CodeBleu_score": 28.876665889765174}, {"code": "def mean_latent(self, num_latent)\n\t\n    mean_latent = torch.randn(num_latent, self.latent_dim).to(self.device)\n    mean_latent = self.style_mlp(mean_latent)\n    mean_latent = torch.mean(mean_latent, dim=0)\n    return mean_latent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.44022982806169}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=(3,))\n    img = img + jitter\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 55.745156131729466}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.randint(-shift, shift, 3)\n    img = img + jitter\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 53.10781336022655}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=3)\n    img = img + jitter\n    img = np.clip(img, 0, 1)\n    return img\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.63164026013943}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'lm_3d' in data:\n        self.lm_3d = data['lm_3d']\n    if 'lm_68' in data:\n        self.lm_68 = data['lm_68']\n    if 'lm_29' in data:\n        self.lm_29 = data['lm_29']\n    if 'lm_17' in data:\n        self.lm_17 = data['lm_17']\n    if 'lm_19' in data:\n        self.lm_19 = data['lm_19']\n    if 'lm_25' in data:\n        self.lm_25 = data['lm_25']\n    if 'lm_49' in data:\n        self.lm_49 = data['lm_49']\n    if 'lm_64' in data:\n        self.lm_64 = data['lm_64']\n    if 'lm_68_hand' in data:\n        self.lm_68_hand = data['lm_68_hand']\n    if 'lm_42' in data:\n        self.lm_42 = data['lm_42']\n    if 'lm_48' in data:\n        self.lm_48 = data['lm_48']\n    if 'lm_55' in data:\n        self.lm_55 = data['lm_55']\n    if 'lm_81' in data:\n        self.lm_81 = data['lm_81']\n    if 'lm_92' in data:\n        self.lm_92 = data['lm_92']\n    if 'lm_102' in data:\n        self.lm_102 = data['lm_102']\n    if 'lm_112' in data:\n        self.lm_112 = data['lm_112']\n    if 'lm_150' in data:\n        self.lm_15", "CodeBleu_score": 31.83796505911595}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'l_eye' in data:\n        self.l_eye = data['l_eye']\n    if 'r_eye' in data:\n        self.r_eye = data['r_eye']\n    if 'mouth' in data:\n        self.mouth = data['mouth']\n\n\n\n\n", "CodeBleu_score": 43.5686635004068}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'l_eye' in data:\n        self.l_eye = data['l_eye']\n    if 'r_eye' in data:\n        self.r_eye = data['r_eye']\n    if 'mouth' in data:\n        self.mouth = data['mouth']\n\n\n\n\n", "CodeBleu_score": 43.5686635004068}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    # Start with the ground truth image\n    img_pyramid = [self.img_gt]\n    # Iteratively downscale the image using bilinear interpolation\n    for i in range(self.n_pyramid_levels - 1):\n        # Downscale the image using bilinear interpolation\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return img_pyramid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.96821102984295}, {"code": "def construct_img_pyramid(self)\n\t\n    # construct image pyramid\n    pyramid_gt = [self.gt]\n    for i in range(self.num_scales):\n        F.interpolate(pyramid_gt[i], scale_factor=0.5, mode='bilinear', align_corners=False)\n        pyramid_gt.insert(0, F.interpolate(pyramid_gt[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return pyramid_gt", "CodeBleu_score": 33.975616420164584}, {"code": "def construct_img_pyramid(self)\n\t\n    # Initialize the image pyramid list\n    img_pyramid = []\n    # Insert the ground truth image at the beginning of the pyramid list\n    img_pyramid.insert(0, self.img_gt)\n    # Iteratively downscale the ground truth image using bilinear interpolation\n    for i in range(self.num_levels - 1):\n        # Downscale the ground truth image using bilinear interpolation\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    # Return the constructed image pyramid\n    return img_pyramid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.815913370133018}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n\n\n\n", "CodeBleu_score": 11.730051474060335}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n\n\n\n", "CodeBleu_score": 11.730051474060335}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_ema_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)\n\n\n\n\n", "CodeBleu_score": 16.45872278370166}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except OSError as e:\n            print(f\"Error deleting {item_path}: {e.strerror}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.36606153643174}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error deleting {item_path}: {e}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.87178235116543}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error deleting {item_path}: {e}\")\n", "CodeBleu_score": 48.87178235116543}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.memory):\n        sample_size = len(self.memory)\n    return random.sample(self.memory, sample_size)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.782246025742744}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if len(self.memory) < sample_size:\n        sample_size = len(self.memory)\n    batch = random.sample(self.memory, sample_size)\n    self.memory = [x for x in self.memory if x not in batch]\n    return batch\n\n", "CodeBleu_score": 59.1280921182031}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if len(self.memory) < sample_size:\n        sample_size = len(self.memory)\n    experiences = random.sample(self.memory, k=sample_size)\n    self.memory = [e for e in self.memory if e not in experiences]\n    return experiences\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.961452607397355}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = {}\n    for config_name, config in self.all_configs.items():\n        flattened_ds_config[config_name] = flatten(config)\n    flattened_ds_config = dict(sorted(flattened_ds_config.items()))\n    feature_val = list(flattened_ds_config.values())\n    feature_val = np.array(feature_val)\n    # Get the cost model prediction\n    predict = self.cost_model.predict(feature_val)\n    # Sort the predictions in descending order\n    sorted_indices = np.argsort(predict)[::-1]\n    return sorted_indices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.45368866474972}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_ds_config()\n    feature_val = []\n    configs = []\n    for config in flattened_ds_config.items():\n        configs.append(config[0])\n        feature_val.append(config[1])\n    feature_val = np.array(feature_val)\n    feature_val = feature_val.astype(np.float)\n    # predict the cost of each configuration\n    predictions = self.cost_model.predict(feature_val)\n    # sort the predictions in descending order\n    sorted_indices = np.argsort(predictions)[::-1]\n    # return the indices of the top configurations\n    return sorted_indices[:self.top_configs_num]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.805242619306796}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_ds_config()\n    feature_val = []\n    configs = []\n    for config in self.all_configs:\n        configs.append(config)\n        feature_val.append(self.flatten_config(config, flattened_ds_config))\n    feature_val = np.array(feature_val)\n    if self.metric == \"cost\":\n        predictions = self.cost_model.predict(feature_val)\n    elif self.metric == \"runtime\":\n        predictions = self.runtime_model.predict(feature_val)\n    else:\n        raise ValueError(\"Invalid metric\")\n    top_configs = np.argsort(predictions)\n    return top_configs\n\n\n\n\n", "CodeBleu_score": 29.07437915467272}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        subprocess.Popen(self.optimal_cmd, shell=True)\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(f\"Successfully executed command: {self.optimal_cmd}\")\n    else:\n        logger.info(\"No optimal command found. Autotuning did not find an optimal configuration.\")\n\n\n\n\n", "CodeBleu_score": 54.99497728995376}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(f\"Running command: {self.optimal_cmd}\")\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(f\"Command {self.optimal_cmd} executed successfully.\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 55.724011146623035}, {"code": "def run_after_tuning(self)\n\t\n    # Run the command after tuning if an optimal command is found\n    if self.optimal_cmd:\n        logger.info(\"Running command after tuning: %s\", self.optimal_cmd)\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command after tuning completed successfully\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration\")", "CodeBleu_score": 51.498537670489796}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    # Set the experiment's master port and result directory\n    exp[\"master_port\"] = self.master_port\n    exp[\"result_dir\"] = self.result_dir\n\n    # Update user arguments based on argument mappings\n    user_args = exp[\"user_args\"]\n    for arg_mapping in exp[\"arg_mappings\"]:\n        # Get the value of the argument from the reservations\n        value = get_val_by_key(reservations, arg_mapping[\"reservation_key\"])\n        if value is None:\n            # If the value is not found in the reservations, raise an error\n            raise ValueError(f\"Value for {arg_mapping['reservation_key']} not found in reservations\")\n        # Replace the argument in the user arguments with the value\n        user_args[user_args.index(arg_mapping[\"arg\"])] = value\n\n    # Create a new thread to run the experiment\n    t = threading.Thread(target=self.run_experiment, args=(exp[\"script\"], user_args))\n\n    # Start the thread\n    t.start()\n\n    # Store the running experiment details with a timestamp\n    self.running_experiments[time.time()] = {\n        \"exp\": exp,\n        \"thread\": t,\n        \"reservations\": reservations\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.548195241884667}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.logger.info(f\"Starting experiment {exp['name']}\")\n    self.logger.info(f\"Experiment config: {exp}\")\n    self.logger.info(f\"Reservations: {reservations}\")\n\n    # Set master port\n    exp[\"master_port\"] = self.get_available_port()\n    exp[\"result_dir\"] = os.path.join(self.result_dir, exp[\"name\"])\n    if not os.path.exists(exp[\"result_dir\"]):\n        os.makedirs(exp[\"result_dir\"])\n\n    # Update user arguments\n    for arg in exp[\"user_args\"]:\n        if arg[\"type\"] == \"mapped\":\n            arg[\"value\"] = self.get_val_by_key(arg[\"mapping\"], exp[\"name\"])\n        elif arg[\"type\"] == \"reservation\":\n            arg[\"value\"] = self.get_val_by_key(arg[\"mapping\"], reservations)\n\n    # Start experiment\n    thread = threading.Thread(target=self.start_experiment, args=(exp,))\n    thread.start()\n\n    # Store running experiment details\n    self.running_experiments[exp[\"name\"]] = {\n        \"exp\": exp,\n        \"thread\": thread,\n        \"timestamp\": time.time(),\n    }\n\n", "CodeBleu_score": 31.54144691856036}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp[\"master_port\"] = self.master_port\n    exp[\"result_dir\"] = self.result_dir\n    user_args = []\n    for arg in exp[\"args\"]:\n        if \"mapping\" in arg:\n            arg[\"value\"] = get_val_by_key(reservations, arg[\"mapping\"])\n        user_args.append(arg[\"value\"])\n    t = threading.Thread(target=self.run_experiment, args=(exp[\"script\"], user_args))\n    t.start()\n    self.running_experiments[t] = {\"exp\": exp, \"start_time\": time.time()}\n\n", "CodeBleu_score": 20.143171183307647}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        message = f\"{message} [rank: {dist.get_rank()}]\"\n    if self.logger is not None:\n        self.logger.debug(message)\n    if ranks is not None and dist.get_rank() in ranks:\n        if path is None:\n            path = self.outfile\n        with open(path, \"a\") as outfile:\n            json.dump(message, outfile)\n            outfile.write(\"", "CodeBleu_score": 30.743450620385314}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized() and ranks is not None:\n        if ranks:\n            message = f\"Rank {dist.get_rank()}: {message}\"\n        else:\n            message = f\"Rank {dist.get_rank()}: {message}\"\n    if self.log_to_file:\n        if path is None:\n            path = self.log_file_path\n        with open(path, \"a\") as outfile:\n            json.dump(message, outfile)\n            outfile.write(\"", "CodeBleu_score": 30.46600488971396}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    # Check if distributed training is initialized\n    if dist.is_initialized():\n        # Set logging permissions based on rank\n        if ranks is not None:\n            if dist.get_rank() not in ranks:\n                return\n        # Add rank to message\n        message = f\"Rank {dist.get_rank()}: {message}\"\n    # Append message to file in JSON format\n    with open(path, \"a\") as outfile:\n        json.dump(message, outfile)\n        outfile.write(\"", "CodeBleu_score": 26.556369558226677}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self.layer_files:\n        raise ValueError(f\"No layer files found for layer index {layer_index}\")\n    if layer_index >= len(self.layer_files):\n        raise ValueError(f\"Layer index {layer_index} is out of range\")\n    layer_files = self.layer_files[layer_index]\n    if not layer_files:\n        raise ValueError(f\"No layer files found for layer index {layer_index}\")\n    tp_degree = self.tp_degree\n    if tp_degree <= 1:\n        raise ValueError(\"TP degree must be greater than 1\")\n    prefix = self.get_layer_prefix(layer_index)\n    partition_files = self.partition_data(layer_files, tp_degree, prefix)\n    return {i: partition_files[i] for i in range(tp_degree)}\n\n", "CodeBleu_score": 33.43967036823322}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self.layer_files:\n        raise ValueError(\"No layer files found.\")\n    if layer_index >= len(self.layer_files):\n        raise ValueError(\"Invalid layer index.\")\n\n    layer_files = self.layer_files[layer_index]\n    tp_degree = self.tp_degree\n\n    tp_layer_map = {}\n    for i in range(len(layer_files)):\n        file_list = get_files_with_prefix(layer_files[i], \"tp_\")\n        partitioned_files = partition_data(file_list, tp_degree)\n        tp_layer_map[i] = partitioned_files\n\n    return tp_layer_map\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.95336792371303}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self.has_layer_files(layer_index):\n        raise ValueError(f\"Layer {layer_index} does not have any layer files.\")\n    if layer_index >= self.num_layers:\n        raise ValueError(f\"Layer {layer_index} does not exist.\")\n    prefix = f\"layer_{layer_index}\"\n    files = self.get_files_with_prefix(prefix)\n    if not files:\n        raise ValueError(f\"No layer files found for layer {layer_index}.\")\n    tp_degree = self.tp_degree\n    partition_data = self.partition_data(files, tp_degree)\n    return {i: files for i, files in enumerate(partition_data)}\n\n", "CodeBleu_score": 33.29054082185715}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    return {\n        \"system\": platform.system(),\n        \"architecture\": platform.architecture(),\n        \"version\": platform.version(),\n        \"processor\": platform.processor(),\n        \"python_version\": platform.python_version(),\n    }\n\n", "CodeBleu_score": 83.32106207916141}, {"code": "def system_info()\n\t\n    return {\n        \"system\": platform.system(),\n        \"architecture\": platform.architecture(),\n        \"version\": platform.version(),\n        \"processor\": platform.processor(),\n        \"python_version\": platform.python_version(),\n    }\n\n", "CodeBleu_score": 83.32106207916141}, {"code": "def system_info()\n\t\n    system_info = {\n        'os': platform.system(),\n        'architecture': platform.architecture(),\n        'version': platform.version(),\n        'processor': platform.processor(),\n        'python_version': platform.python_version()\n    }\n    return system_info\n\n", "CodeBleu_score": 51.10568937508009}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    if device_count == 0:\n        return \"No CUDA device found\"\n    device_names = [torch.cuda.get_device_name(i) for i in range(device_count)]\n    device_availability = [torch.cuda.is_available() for i in range(device_count)]\n    cuda_version = torch.version.cuda\n    return {\"device_names\": device_names, \"device_availability\": device_availability, \"cuda_version\": cuda_version}\n", "CodeBleu_score": 48.53546664468947}, {"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    device_name = [torch.cuda.get_device_name(i) for i in range(device_count)]\n    is_available = torch.cuda.is_available()\n    version = torch.version.cuda\n    return device_name, is_available, version\n\n", "CodeBleu_score": 41.57792154359108}, {"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    device_name = torch.cuda.get_device_name()\n    is_available = torch.cuda.is_available()\n    cuda_version = torch.version.cuda\n    return device_name, device_count, is_available, cuda_version\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.590865846685553}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping:\n            class_id = item[\"class_id\"]\n            class_name = class_id_to_class_name_mapping[class_id]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"count\": 0, \"correct\": 0}\n            class_acc_dict[class_name][\"count\"] += 1\n            if torch.argmax(embedding) == 0:\n                class_acc_dict[class_name][\"correct\"] += 1\n    for class_name, class_acc in class_acc_dict.items():\n        print(f\"Class {class_name} accuracy: {class_acc['correct'] / class_acc['count']}\")\n    print(f\"Average accuracy: {sum([class_acc['correct'] for class_acc in class_acc_dict.values()]) / sum([class_acc['count'] for class_acc in class_acc_dict.values()])}\")\n\n\n\n\n", "CodeBleu_score": 28.189566542690443}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name_mapping = encoder_manager.config.class_id_to_class_name_mapping\n    class_acc_dict = {}\n    for item in tqdm(dataset_items, desc=\"Computing encoder accuracy\"):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping is not None:\n            class_id = item[\"class_id\"]\n            true_class_name = class_id_to_class_name_mapping[class_id]\n        else:\n            true_class_name = item[\"class_name\"]\n        if embedding is not None:\n            if encoder_manager.config.use_classifier:\n                predicted_class_name = encoder_manager.classifier.predict_class_name(embedding)\n            else:\n                predicted_class_name = encoder_manager.classifier.predict_class_name(embedding)\n            if true_class_name == predicted_class_name:\n                if true_class_name in class_acc_dict:\n                    class_acc_dict[true_class_name] += 1\n                else:\n                    class_acc_dict[true_class_name] = 1\n    total_samples = sum(class_acc_dict.values())\n    for class_name, num_samples in class_acc_dict.items():\n        accuracy = num_samples / total_samples\n        print(f\"Class: {class_name}, Accuracy: {accuracy:.4f}\")\n    avg_accuracy = sum([accuracy for accuracy in class_acc_dict.values()]) / len(class_acc_dict)\n    print(f\"Average accuracy: {avg_accuracy:.4f}\")\n\n\n\n\n", "CodeBleu_score": 38.26331355536907}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config['class_name_key']\n    class_id_to_class_name_mapping = encoder_manager.config.get('class_id_to_class_name_mapping', None)\n    class_acc_dict = {}\n    for item in tqdm(dataset_items, desc='Computing encoder accuracy'):\n        audio_file = item[class_name_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if class_id_to_class_name_mapping:\n            class_id = item['class_id']\n            class_name = class_id_to_class_name_mapping[class_id]\n        else:\n            class_name = item[class_name_key]\n        if class_name not in class_acc_dict:\n            class_acc_dict[class_name] = {'correct': 0, 'total': 0}\n        if embedding is not None:\n            prediction = encoder_manager.predict_class_from_embedding(embedding)\n            if prediction == class_name:\n                class_acc_dict[class_name]['correct'] += 1\n            class_acc_dict[class_name]['total'] += 1\n    for class_name, class_acc in class_acc_dict.items():\n        class_acc['accuracy'] = class_acc['correct'] / class_acc['total']\n        print(f\"Class: {class_name}, Accuracy: {class_acc['accuracy']:.4f}\")\n    avg_acc = sum([class_acc_dict[class_name]['accuracy'] for class_name in class_acc_dict]) / len(class_acc_dict)\n    print(f\"Average accuracy: {avg_acc:.4f}\")\n", "CodeBleu_score": 36.81972459071397}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # adjust the path\n    out_path = audio_path.replace(args.input_dir, args.output_dir)\n    # if the file already exists and force is not specified, return the output path and a False flag\n    if exists(out_path) and not args.force:\n        return out_path, False\n    # create the necessary directory structure\n    mkdir(pathlib.Path(out_path).parent)\n    # remove silence from the audio using specified parameters\n    out_path, is_speech = remove_silence(\n        model_and_utils, audio_path, out_path, vad_sample_rate=8000, trim_just_beginning_and_end=True, use_cuda=False\n    )\n    return out_path, is_speech\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.47881096803012}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # get the model and utils functions\n    model, get_speech_timestamps, _, collect_chunks = get_model_and_utils()\n\n    # create the output path\n    out_path = audio_path.replace(args.input_dir, args.output_dir)\n\n    # if the output path already exists and force is not specified, return the output path and False flag\n    if os.path.exists(out_path) and not args.force:\n        print(f\"> The file {out_path} already exists, skipping...\")\n        return out_path, False\n\n    # create the necessary directory structure\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n    # remove silence from the audio using specified parameters\n    out_path, is_speech = remove_silence(\n        model_and_utils=(model, get_speech_timestamps, None, collect_chunks),\n        audio_path=audio_path,\n        out_path=out_path,\n        vad_sample_rate=args.vad_sample_rate,\n        trim_just_beginning_and_end=args.trim_just_beginning_and_end,\n        use_cuda=args.use_cuda,\n    )\n\n    return out_path, is_speech\n\n\n", "CodeBleu_score": 49.382075850229214}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # get the VAD model and utils functions\n    model, get_speech_timestamps, _, collect_chunks = model_and_utils\n\n    # read ground truth wav and resample the audio for the VAD\n    try:\n        wav, gt_sample_rate = read_audio(audio_path)\n    except:\n        print(f\"> \u2757 Failed to read {audio_path}\")\n        return None, False\n\n    # if needed, resample the audio for the VAD model\n    if gt_sample_rate != vad_sample_rate:\n        wav_vad = resample_wav(wav, gt_sample_rate, vad_sample_rate)\n    else:\n        wav_vad = wav\n\n    if use_cuda:\n        wav_vad = wav_vad.cuda()\n\n    # get speech timestamps from full audio file\n    speech_timestamps = get_speech_timestamps(wav_vad, model, sampling_rate=vad_sample_rate, window_size_samples=768)\n\n    # map the current speech_timestamps to the sample rate of the ground truth audio\n    new_speech_timestamps = map_timestamps_to_new_sr(\n        vad_sample_rate, gt_sample_rate, speech_timestamps, trim_just_beginning_and_end\n    )\n\n    # if have speech timestamps else save the wav\n    if new_speech_timestamps:\n        wav = collect_chunks(new_speech_timestamps, wav)\n        is_speech = True\n    else:\n        print(f\"> The file {audio_path} probably does not have speech please check it !!\")\n        is_speech = False\n\n    # save\n    torchaudio.save(out_path, wav[None, :], gt_sample_rate)\n    return out_path, is_speech\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.851790793661724}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    # If an output directory is provided, copy the input directory to the output directory\n    if output_dir is not None:\n        shutil.copytree(input_dir, output_dir)\n        input_dir = output_dir\n\n    # Get a list of all audio files in the input directory\n    audio_files = glob.glob(os.path.join(input_dir, \"**\", \"*.\" + file_ext), recursive=True)\n\n    # Create a progress bar for the resampling process\n    with tqdm(total=len(audio_files), desc=\"Resampling audio files\") as pbar:\n        # Use a multiprocessing pool to resample the audio files in parallel\n        with Pool(n_jobs) as p:\n            # Resample each audio file in parallel and update the progress bar\n            for _ in p.imap_unordered(partial(resample_file, output_sr=output_sr, output_dir=output_dir), audio_files):\n                pbar.update()\n\n    # Print a completion message\n    print(\"Resampling complete\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.038679297511095}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    else:\n        shutil.copytree(input_dir, output_dir)\n    audio_files = glob.glob(os.path.join(output_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(audio_files)) as pbar:\n            for _ in p.imap_unordered(partial(resample_file, output_sr=output_sr, pbar=pbar), audio_files):\n                pass\n    print(f\"Completed resampling {len(audio_files)} files to {output_sr} Hz\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.11903668821884}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    else:\n        copytree(input_dir, output_dir)\n    audio_files = [file for file in glob.glob(f\"{output_dir}/**/*.{file_ext}\", recursive=True)]\n    print(f\"Found {len(audio_files)} audio files.\")\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(audio_files)) as pbar:\n            for _ in p.imap_unordered(resample_file, audio_files):\n                pbar.update()\n    print(\"Done.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.07062124004246}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n\n    model.eval()\n    loss = 0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(-1, 1, 28, 28)\n            labels = labels.view(-1)\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n\n            outputs = model(inputs)\n            loss += criterion(outputs, labels)\n\n            if i == len(data_loader) - 1:\n                # get embeddings from last batch\n                embeddings = outputs.detach().cpu().numpy()\n                num_classes_in_batch = labels.shape[0] // 10\n                fig = plot_embeddings(embeddings, num_classes_in_batch)\n                dashboard_logger.eval_figures[\"umap\"] = fig\n\n    loss /= len(data_loader)\n    dashboard_logger.eval_stats[\"loss\"].append(loss.item())\n    print(\n        \"Evaluation Loss at step {}: {}\".format(global_step, dashboard_logger.eval_stats[\"loss\"][-1])\n    )\n    return loss\n\n", "CodeBleu_score": 35.302357292107075}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n\n    model.eval()\n\n    # initialize loss\n    eval_loss = 0.0\n\n    # iterate over batches\n    for batch_idx, (inputs, labels) in enumerate(data_loader):\n\n        # reshape inputs and labels to group samples of each class\n        inputs = inputs.view(-1, 1, 28, 28)\n        labels = labels.view(-1)\n\n        # dispatch data to GPU if available\n        if torch.cuda.is_available():\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n\n        # forward pass\n        with torch.no_grad():\n            outputs = model(inputs)\n\n        # calculate loss\n        loss = criterion(outputs, labels)\n\n        # update loss\n        eval_loss += loss.item()\n\n    # compute average loss\n    eval_loss /= len(data_loader)\n\n    # log evaluation statistics\n    dashboard_logger.eval_stats(\n        \"eval_loss\", eval_loss, step=global_step, data_type=\"scalar\"\n    )\n\n    # generate and log UMAP plot of the embeddings from the last batch\n    embeddings = outputs.detach().cpu().numpy()\n    num_classes_in_batch = len(labels.unique())\n    fig = plot_embeddings(embeddings, num_classes_in_batch)\n    dashboard_logger.eval_figures(\n        \"umap\", fig, step=global_step, data_type=\"image\", overwrite=True\n    )\n\n    # return average loss\n    return eval_loss\n\n", "CodeBleu_score": 36.01309238784304}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n\n    model.eval()\n\n    eval_loss = 0\n    num_utter_per_class = 0\n    num_classes_in_batch = 0\n    embeddings = None\n\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(inputs.shape[0], -1)\n            labels = labels.view(labels.shape[0])\n\n            if torch.cuda.is_available():\n                inputs = inputs.cuda()\n                labels = labels.cuda()\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n\n            eval_loss += loss.item()\n\n            if i == len(data_loader) - 1:\n                num_utter_per_class = inputs.shape[0] // labels.shape[0]\n                num_classes_in_batch = labels.shape[0]\n                embeddings = outputs.detach().cpu().numpy()\n\n    eval_loss /= len(data_loader)\n    eval_stats = {\n        \"loss\": eval_loss,\n        \"num_utter_per_class\": num_utter_per_class,\n        \"num_classes_in_batch\": num_classes_in_batch,\n    }\n    dashboard_logger.eval_stats(eval_stats, global_step)\n\n    if embeddings is not None:\n        eval_figures = {\"umap\": plot_embeddings(embeddings, num_classes_in_batch)}\n        dashboard_logger.eval_figures(eval_figures, global_step)\n\n    return eval_loss\n\n", "CodeBleu_score": 43.44497462137532}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_name = to_camel(model_name)\n    if model_name == \"xtts\":\n        try:\n            config_module = find_module(\n                \"xtts.config\",\n                config_name,\n            )\n            return config_module\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\n                f\"Could not find config for model {model_name} in xtts.config\"\n            )\n    else:\n        for path in [\"configs\", \"xtts.configs\"]:\n            try:\n                config_module = find_module(\n                    path,\n                    config_name,\n                )\n                return config_module\n            except ModuleNotFoundError:\n                pass\n        raise ModuleNotFoundError(\n            f\"Could not find config for model {model_name} in {path}\"\n        )\n\n", "CodeBleu_score": 32.0082575750589}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    try:\n        config_name = to_camel(model_name) + \"Config\"\n        if model_name == \"xtts\":\n            from src.models.xtts.config import XTTSConfig\n            return XTTSConfig()\n        else:\n            config_class = find_module(\"src.models\", model_name)\n            return config_class()\n    except ModuleNotFoundError as e:\n        raise ModuleNotFoundError(f\"Module {model_name} not found.\") from e\n\n", "CodeBleu_score": 33.11522925125527}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    class_name = to_camel(model_name)\n    if model_name == \"xtts\":\n        try:\n            config_class = find_module(\"xtts.config\", class_name)\n        except ModuleNotFoundError:\n            config_class = find_module(\"config\", class_name)\n    else:\n        try:\n            config_class = find_module(\"config\", class_name)\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\n                f\"Configuration class for model {model_name} not found.\"\n            )\n    return config_class\n\n", "CodeBleu_score": 31.01150070617295}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    _, ext = splitext(config_path)\n    if ext == \".json\":\n        config_dict = read_json_with_comments(config_path)\n    elif ext == \".yml\" or ext == \".yaml\":\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as f:\n            config_dict = yaml.safe_load(f)\n    else:\n        raise ValueError(f\"Unknown config file type: {ext}\")\n\n    # process model name\n    model_name = _process_model_name(config_dict)\n\n    # register config\n    config_class = register_config(model_name)\n\n    # create config instance\n    config = config_class()\n\n    # populate config with dict\n    config.from_dict(config_dict)\n\n    return config\n\n", "CodeBleu_score": 49.649269496663806}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    ext = splitext(config_path)[1]\n    if ext == \".yml\" or ext == \".yaml\":\n        config_dict = read_json_with_comments(config_path)\n    elif ext == \".json\":\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as f:\n            config_dict = json.load(f)\n    else:\n        raise ValueError(f\" [!] Unknown extension: {ext}\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 48.73564633178001}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = read_json_with_comments(config_path)\n    if config_dict is None:\n        raise ValueError(f\" [!] Failed to load config file: {config_path}\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config\n\n", "CodeBleu_score": 27.290456152034437}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                yield os.path.join(rootDir, filename)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 69.2724299215846}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image, based on the file extension\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath\n\n", "CodeBleu_score": 78.86579842171658}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 78.86579842171658}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    # Clear GPU cache\n    clear_gpu_cache()\n\n    # Check if required paths are provided\n    if xtts_checkpoint is None:\n        return \"Error: XTTS checkpoint path is not provided.\"\n    if xtts_config is None:\n        return \"Error: XTTS config path is not provided.\"\n    if xtts_vocab is None:\n        return \"Error: XTTS vocab path is not provided.\"\n\n    # Load configuration\n    config = XttsConfig.load_json(xtts_config)\n\n    # Initialize XTTS model\n    model = Xtts(config)\n\n    # Load model checkpoint and vocabulary\n    model.load_checkpoint(\n        config,\n        checkpoint_path=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n        eval=True,\n        strict=True,\n    )\n\n    # Move model to GPU if available\n    if torch.cuda.is_available():\n        model.cuda()\n\n    # Print loading progress\n    print(\"Loading XTTS model...\")\n\n    # Return success message\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 51.79586521150983}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Please provide all required paths: xtts_checkpoint, xtts_config, xtts_vocab\"\n    config = XttsConfig.load_json(xtts_config)\n    XTTS_MODEL = Xtts.init_from_config(config)\n    XTTS_MODEL.load_checkpoint(\n        config,\n        checkpoint_dir=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n        eval=True,\n        strict=True,\n    )\n    if torch.cuda.is_available():\n        XTTS_MODEL = XTTS_MODEL.cuda()\n    print(\"Loading model from checkpoint: \", xtts_checkpoint)\n    print(\"Loading config from: \", xtts_config)\n    print(\"Loading vocab from: \", xtts_vocab)\n    return \"Model loaded successfully\"\n\n", "CodeBleu_score": 47.58687723938989}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n\n    if not xtts_checkpoint:\n        return \"Please provide a valid XTTS checkpoint path.\"\n    if not xtts_config:\n        return \"Please provide a valid XTTS config path.\"\n    if not xtts_vocab:\n        return \"Please provide a valid XTTS vocab path.\"\n\n    config = XttsConfig.load_json(xtts_config)\n    model = Xtts.init_from_config(config)\n\n    model.load_checkpoint(\n        config,\n        checkpoint_path=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n    )\n\n    if torch.cuda.is_available():\n        model.cuda()\n\n    print(\"Successfully loaded XTTS model from checkpoint.\")\n    return \"Successfully loaded XTTS model from checkpoint.\"\n\n", "CodeBleu_score": 53.73018375416704}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    # Adjust number of frames based on hop length\n    num_frames = int(num_frames / self.hop_length)\n    # Compute number of frames that can be extracted from the input\n    num_frames = min(num_frames, x.shape[1] - self.frame_length + 1)\n    # Compute offset positions for evaluation\n    offsets = np.linspace(0, num_frames - self.frame_length, num_eval, dtype=int)\n    # Extract frames at these offsets\n    frames = x[:, offsets]\n    # Concatenate frames into a batch\n    frames_batch = []\n    for i in range(num_eval):\n        frames_batch.append(frames[:, i])\n    frames_batch = torch.stack(frames_batch)\n    # Perform inference to obtain embeddings\n    embeddings = self.inference(frames_batch)\n    # Compute mean of embeddings\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n    # Normalize embeddings with L2 norm\n    if l2_norm:\n        embeddings = embeddings / torch.norm(embeddings)\n    return embeddings\n\n", "CodeBleu_score": 39.08234641763039}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n\n    # Adjust the number of frames based on the hop length if using torch specifications\n    if self.specs == \"torch\":\n        num_frames = num_frames // self.hop_length\n\n    # Ensure the number of frames does not exceed the input length\n    num_frames = min(num_frames, x.shape[0])\n\n    # Calculate offset positions for evaluation\n    offsets = np.linspace(0, x.shape[0] - num_frames, num=num_eval, dtype=int)\n\n    # Extract frames at these offsets and concatenate them into a batch\n    frames_batch = []\n    for offset in offsets:\n        frames_batch.append(x[offset:offset + num_frames])\n    frames_batch = torch.cat(frames_batch)\n\n    # Perform inference to obtain embeddings\n    embeddings = self.inference(frames_batch)\n\n    # Compute the mean of the embeddings and return the result, optionally normalizing them with L2 norm\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n        if l2_norm:\n            embeddings = embeddings / torch.norm(embeddings)\n    return embeddings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.17304515451598}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    x = x.unsqueeze(0)\n    x = x.to(self.device)\n\n    if self.spec_type == \"torch\":\n        num_frames = int(num_frames * self.hop_length)\n        num_frames = min(num_frames, x.shape[-1])\n        num_frames = max(num_frames, 1)\n        num_eval = min(num_eval, num_frames)\n\n        offsets = np.linspace(0, num_frames - num_eval, num_eval)\n        offsets = np.round(offsets).astype(int)\n        frames_batch = []\n        for offset in offsets:\n            frames = x[:, :, offset : offset + num_eval]\n            frames_batch.append(frames)\n        frames_batch = torch.cat(frames_batch, dim=0)\n\n        with torch.no_grad():\n            embeddings = self.inference(frames_batch)\n\n        if return_mean:\n            embeddings = torch.mean(embeddings, dim=0)\n            if l2_norm:\n                embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=0)\n\n        return embeddings\n\n    elif self.spec_type == \"librosa\":\n        num_frames = int(num_frames * self.hop_length)\n        num_frames = min(num_frames, x.shape[-1])\n        num_frames = max(num_frames, 1)\n        num_eval = min(num_eval, num_frames)\n\n        offsets = np.linspace(0, num_frames - num_eval, num_eval)\n        offsets = np.round(offsets).astype(int)\n        frames_batch = []\n        for offset in offsets:\n            frames = x[:, offset : offset + num_eval]\n            frames_batch.append(frames)\n        frames_batch = np.stack(frames_batch, axis=0)\n\n        with torch.no_grad():\n            embeddings = self.inference(torch.from_numpy(", "CodeBleu_score": 43.422652570577405}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(\n                self.inplanes,\n                planes * block.expansion,\n                kernel_size=1,\n                stride=stride,\n                bias=False,\n            ),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 80.88513077165933}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 85.47050566601277}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 85.47050566601277}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances = np.array([len(embeddings[embeddings[:, -1] == i]) for i in range(num_classes_in_batch)])\n\n    # Limit the number of classes to 10 if necessary\n    if num_classes_in_batch > 10:\n        num_classes_in_batch = 10\n\n    # UMAP transforms the embeddings\n    umap_transform = umap.UMAP(n_components=2, n_neighbors=5, min_dist=0.1, metric='euclidean').fit_transform(embeddings[:, :-1])\n\n    # Create a scatter plot with colors representing different classes\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.scatter(umap_transform[:, 0], umap_transform[:, 1], c=embeddings[:, -1], cmap='tab10', s=5)\n\n    # Set the aspect ratio of the plot to be equal\n    set_aspect('equal', 'datalim')\n\n    # Add a colorbar to the plot\n    plt.colorbar(boundaries=np.arange(num_classes_in_batch + 1) - 0.5).set_ticks(np.arange(num_classes_in_batch))\n\n    # Add a title to the plot\n    plt.title('UMAP projection')\n\n    # Adjust the layout of the plot\n    plt.tight_layout()\n\n    # Save the plot as \"umap\"\n    plt.savefig('umap.png')\n\n    # Return the plot as a figure\n    return fig\n\n", "CodeBleu_score": 45.19487738006694}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = np.unique(num_classes_in_batch, return_counts=True)[1]\n    # Limit the number of classes to 10 if necessary\n    num_classes = min(len(num_utterances_per_class), 10)\n    # UMAP transform the embeddings\n    umap_embeddings = umap.UMAP(n_components=2).fit_transform(embeddings)\n    # Create a scatter plot with colors representing different classes\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.scatter(umap_embeddings[:, 0], umap_embeddings[:, 1], c=num_classes_in_batch, cmap='tab10')\n    # Set the aspect ratio of the plot to be equal\n    set_aspect(ax)\n    # Add a title to the plot\n    plt.title(\"UMAP projection\")\n    # Save the plot as \"umap\"\n    plt.savefig(\"umap.png\")\n    # Return the figure\n    return fig\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.15501549970962}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate number of utterances per class\n    num_utterances_per_class = np.unique(embeddings[:, -1], return_counts=True)[1]\n    # Limit number of classes to 10 if necessary\n    num_classes_in_batch = min(num_classes_in_batch, 10)\n    # UMAP transforms the embeddings\n    umap_transform = umap.UMAP()\n    embeddings_transformed = umap_transform.fit_transform(embeddings[:, :-1])\n    # Create a scatter plot with colors representing different classes\n    fig = plt.figure(figsize=(10, 10))\n    ax = fig.add_subplot(111)\n    ax.scatter(embeddings_transformed[:, 0], embeddings_transformed[:, 1], c=embeddings[:, -1], cmap='tab10', s=num_utterances_per_class * 1000 / num_classes_in_batch)\n    # Set aspect ratio to be equal\n    set_aspect('equal', 'datalim')\n    # Add title and save plot\n    plt.title(\"UMAP projection\")\n    plt.savefig(\"umap.png\")\n    # Return figure\n    return fig", "CodeBleu_score": 27.1752448602958}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, utts in enumerate(dvecs):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n        for utt, dvec in enumerate(utts):\n            cs_row = []\n            for centroid in new_centroids:\n                cos_sim = torch.mm(dvec.unsqueeze(0), centroid.unsqueeze(0).transpose(0, 1))\n                cos_sim = torch.clamp(cos_sim, min=-1, max=1)\n                cs_row.append(cos_sim)\n            cos_sim_matrix.append(torch.cat(cs_row))\n    return torch.stack(cos_sim_matrix)\n\n", "CodeBleu_score": 41.72045578569799}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr in range(len(dvecs)):\n        cs_row = []\n        for utt in range(len(dvecs[spkr])):\n            new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n            dvecs[spkr, utt] = dvecs[spkr, utt] / torch.norm(dvecs[spkr, utt])\n            new_centroids = new_centroids / torch.norm(new_centroids, dim=1).unsqueeze(1)\n            cos_sim = torch.mm(dvecs[spkr, utt].unsqueeze(0), new_centroids.transpose(0, 1))\n            cos_sim = torch.clamp(cos_sim, min=1e-6)\n            cs_row.append(cos_sim)\n        cos_sim_matrix.append(torch.cat(cs_row, dim=1))\n    return torch.stack(cos_sim_matrix)\n\n", "CodeBleu_score": 49.456847489130354}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr in range(self.num_speakers):\n        cs_row = []\n        for utt in range(self.num_utterances):\n            new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n            cos_sim = torch.mm(\n                dvecs[spkr, utt].unsqueeze(0), new_centroids.transpose(0, 1)\n            )\n            cos_sim = torch.clamp(cos_sim, min=0)\n            cs_row.append(cos_sim)\n        cos_sim_matrix.append(torch.cat(cs_row, 0))\n    return torch.stack(cos_sim_matrix)\n\n", "CodeBleu_score": 44.785736485660266}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for i in range(dvecs.shape[0]):\n        dvec = dvecs[i]\n        cos_sim_row = cos_sim_matrix[i]\n        loss = -F.log_softmax(cos_sim_row, dim=-1)[dvec]\n        losses.append(loss)\n    return torch.stack(losses)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.45019320499706}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    # Get the number of embeddings\n    num_embeddings = dvecs.shape[0]\n    # Create an empty list to store the losses for each embedding\n    losses = []\n    # Iterate over the embeddings\n    for i in range(num_embeddings):\n        # Compute the negative log softmax of the cosine similarity matrix for the current embedding\n        loss = -F.log_softmax(cos_sim_matrix[i], dim=0)\n        # Add the loss to the list of losses\n        losses.append(loss)\n    # Stack the losses into a tensor\n    losses = torch.stack(losses)\n    # Return the final stacked tensor of losses\n    return losses\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.25530758369461}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for dvec in dvecs:\n        log_softmax = F.log_softmax(cos_sim_matrix, dim=1)\n        loss = -log_softmax[dvec.idx, dvec.label]\n        losses.append(loss)\n    return torch.stack(losses)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.702504201106937}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(len(dvecs)):\n        # Sigmoid of cosine similarity matrix\n        sigmoid_cos_sim_matrix = torch.sigmoid(cos_sim_matrix[i])\n        # Exclude the current centroid\n        sigmoid_cos_sim_matrix[i] = 0\n        # Compute the contrast loss\n        contrast_loss = torch.max(sigmoid_cos_sim_matrix)\n        # Append the contrast loss to the loss row\n        L_row.append(contrast_loss)\n    # Stack the loss row into a tensor\n    L_row = torch.stack(L_row)\n    return L_row\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.75143393888071}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(self.n_embeddings):\n        cos_sim_matrix_row = cos_sim_matrix[i]\n        cos_sim_matrix_row_exclude_current_centroid = torch.cat(\n            (cos_sim_matrix_row[0:i], cos_sim_matrix_row[i + 1 :])\n        )\n        cos_sim_matrix_row_exclude_current_centroid = torch.sigmoid(\n            cos_sim_matrix_row_exclude_current_centroid\n        )\n        loss_row = torch.max(\n            torch.zeros_like(cos_sim_matrix_row_exclude_current_centroid),\n            self.margin - cos_sim_matrix_row[i]\n            + cos_sim_matrix_row_exclude_current_centroid,\n        )\n        L_row.append(loss_row)\n    return torch.stack(L_row)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.37501674520678}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(dvecs.shape[0]):\n        # sigmoid of the cosine similarity matrix for the current embedding\n        sigmoid = torch.sigmoid(cos_sim_matrix[i])\n        # exclude the current centroid\n        sigmoid = torch.cat((sigmoid[:i], sigmoid[i+1:]), dim=0)\n        # compute the contrast loss\n        loss = torch.max(torch.tensor(0.0), 1 - sigmoid)\n        # append the loss to the row\n        L_row.append(loss)\n    # stack the losses for each row into a tensor\n    L = torch.stack(L_row)\n    return L\n\n", "CodeBleu_score": 32.5205155705674}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    # check if input is valid\n    assert (\n        x.size(0) > 1\n    ), \"The batch size should be greater than 1, but it is {}\".format(x.size(0))\n    assert (\n        x.size(1) > 1\n    ), \"The number of utterances per speaker should be greater than 1, but it is {}\".format(\n        x.size(1)\n    )\n    assert (\n        x.size(2) > 0\n    ), \"The number of embedding dimensions should be greater than 0, but it is {}\".format(\n        x.size(2)\n    )\n    # calculate the centroids\n    centroids = self.calc_centroids(x)\n    # calculate the cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n    # calculate the similarity matrix\n    sim_matrix = self.calc_sim_matrix(cos_sim_matrix)\n    # calculate the embedding loss\n    loss = self.calc_embed_loss(sim_matrix)\n    # return the mean loss\n    return torch.mean(loss)\n\n", "CodeBleu_score": 37.09638301034924}, {"code": "def forward(self, x, _label=None)\n\t\n    # ensure input has at least 2 utterances per speaker\n    assert (\n        x.size(1) >= 2\n    ), \"Input must have at least 2 utterances per speaker, but it has {}\".format(x.size(1))\n\n    # compute centroids\n    centroids = self.calc_centroids(x)\n\n    # compute cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n\n    # scale and shift the cosine similarity matrix\n    cos_sim_matrix = self.scale_shift(cos_sim_matrix)\n\n    # calculate the embedding loss\n    embed_loss = self.embed_loss(cos_sim_matrix)\n\n    return embed_loss.mean()\n\n", "CodeBleu_score": 46.64913594528559}, {"code": "def forward(self, x, _label=None)\n\t\n    # Check if input is valid\n    if x.size(0) < 2:\n        raise ValueError(\"The input should have at least two utterances per speaker.\")\n\n    # Calculate centroids\n    centroids = self.calc_centroids(x)\n\n    # Calculate cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n\n    # Calculate loss\n    cos_sim_matrix = cos_sim_matrix.view(cos_sim_matrix.size(0), -1)\n    cos_sim_matrix = self.scale_shift(cos_sim_matrix)\n    cos_sim_matrix = torch.clamp(cos_sim_matrix, 1e-6)\n    cos_sim_matrix = torch.log(cos_sim_matrix)\n    embed_loss = self.embed_loss(cos_sim_matrix)\n    embed_loss = torch.mean(embed_loss)\n\n    return embed_loss\n\n", "CodeBleu_score": 40.07518289044917}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for voice_dir in [VoiceDir.VOICES, *extra_voice_dirs]:\n        for subdir in os.listdir(voice_dir):\n            if not os.path.isdir(os.path.join(voice_dir, subdir)):\n                continue\n            files = []\n            for file in glob.glob(os.path.join(voice_dir, subdir, \"*.npz\")):\n                files.append(file)\n            if not files:\n                for file in glob.glob(os.path.join(voice_dir, subdir, \"*.wav\")):\n                    files.append(file)\n                for file in glob.glob(os.path.join(voice_dir, subdir, \"*.mp3\")):\n                    files.append(file)\n            voices[subdir] = files\n    return voices\n\n", "CodeBleu_score": 31.833197336426476}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voice_dirs = [\n        os.path.join(os.path.dirname(__file__), \"voices\"),\n        os.path.join(os.path.dirname(__file__), \"voices_extra\"),\n    ]\n    voice_dirs.extend(extra_voice_dirs)\n\n    voices = {}\n    for voice_dir in voice_dirs:\n        for subdir, _, files in os.walk(voice_dir):\n            if files:\n                voices[subdir] = [\n                    os.path.join(subdir, f)\n                    for f in files\n                    if f.endswith(\".npz\")\n                    or f.endswith(\".wav\")\n                    or f.endswith(\".mp3\")\n                ]\n\n    return voices\n\n", "CodeBleu_score": 32.37028495899674}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    # Get the path to the current directory\n    current_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Get a list of all directories in the current directory\n    dirs = [d for d in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, d))]\n\n    # Add the extra directories to the list\n    dirs.extend(extra_voice_dirs)\n\n    # Initialize an empty dictionary to store the file paths\n    voices = {}\n\n    # Iterate through each directory\n    for dir in dirs:\n        # Get the path to the directory\n        dir_path = os.path.join(current_dir, dir)\n\n        # Get a list of all files in the directory\n        files = os.listdir(dir_path)\n\n        # Initialize an empty list to store the file paths\n        file_paths = []\n\n        # Iterate through each file\n        for file in files:\n            # Get the path to the file\n            file_path = os.path.join(dir_path, file)\n\n            # Check if the file is a .npz file\n            if file.endswith(\".npz\"):\n                # Add the file path to the list\n                file_paths.append(file_path)\n\n            # Check if the file is a .wav or .mp3 file\n            elif file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                # Add the file path to the list\n                file_paths.append(file_path)\n\n        # Add the list of file paths to the dictionary\n        voices[dir] = file_paths\n\n    # Return the dictionary of file paths\n    return voices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.719779941253982}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n    audio_path = paths[0]\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with .npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n    audio_path = paths[0]\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, seq_len, _ = pos_score.size()\n    zeros = torch.zeros((batch_size, seq_len, 1), device=pos_score.device)\n    padded_pos_score = torch.cat([pos_score, zeros], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, seq_len + 1, seq_len)\n    pos_score = padded_pos_score[:, :seq_len, :seq_len]\n    return pos_score\n", "CodeBleu_score": 39.240332372538106}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_len, _ = pos_score.size()\n    zeros = torch.zeros((batch_size, num_heads, seq_len, 1), device=pos_score.device)\n    padded_pos_score = torch.cat([pos_score, zeros], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_len + 1, seq_len)\n    pos_score = padded_pos_score[:, :, :seq_len, :seq_len]\n    return pos_score\n\n\n\n\n", "CodeBleu_score": 46.44070510031974}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, seq_len, _ = pos_score.size()\n    zeros = torch.zeros((batch_size, 1), device=pos_score.device, dtype=pos_score.dtype)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=1)[:, :-1]\n    padded_pos_score = padded_pos_score.view(batch_size, seq_len + 1, seq_len)\n    pos_score = padded_pos_score[:, :seq_len, :seq_len]\n    return pos_score\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.40838613785751}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(self.num_layers):\n        context = self.conv[i](context)\n        context = F.relu(context)\n        context = self.dropout(context)\n        context_embedded.append(context)\n    context_embedded = torch.cat(context_embedded, dim=1)\n    context_embedded = pad_sequence(context_embedded, padding_value=0)\n    context_embedded = context_embedded.transpose(0, 1)\n    context_embedded = pack_padded_sequence(context_embedded, lens, batch_first=True)\n    return context_embedded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.39234356098167}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(self.num_layers):\n        context = self.convs[i](context)\n        context = F.relu(context)\n        context = self.dropout(context)\n        context_embedded.append(context)\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = context_embedded.permute(1, 0, 2, 3)\n    context_embedded = context_embedded[torch.arange(context_embedded.size(0)), lens - 1]\n    context_embedded = context_embedded.unsqueeze(1)\n    return context_embedded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.144840562327104}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(self.num_layers):\n        context = self.conv[i](context)\n        context = F.relu(context)\n        context = self.dropout(context)\n        context_embedded.append(context)\n\n    context_embedded = [context_embedded[i][:, :, :lens[i]] for i in range(self.num_layers)]\n    context_embedded = torch.stack(context_embedded, dim=0)\n    context_embedded = context_embedded.transpose(0, 1)\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    return context_embedded\n\n\n\n\n", "CodeBleu_score": 36.97763736434667}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = torch.sort(lens, descending=True)\n    context_sorted = context.index_select(0, indices)\n    packed_context = pack_padded_sequence(context_sorted, lens_sorted.long(), batch_first=True)\n    packed_result = fn(packed_context)\n    result_sorted, _ = pad_packed_sequence(packed_result, batch_first=True)\n    result = result_sorted.index_select(0, indices)\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 14.74917673107608}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = torch.sort(lens, descending=True)\n    context_sorted = context[indices]\n    packed_context_sorted = pack_padded_sequence(context_sorted, lens_sorted.cpu(), batch_first=True)\n    packed_output = fn(packed_context_sorted)\n    output, _ = pad_packed_sequence(packed_output, batch_first=True)\n    output = output[indices]\n    return output", "CodeBleu_score": 13.822455008259862}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, lens_idx = torch.sort(lens, descending=True)\n    context = context[lens_idx]\n    context = pack_padded_sequence(context, lens_sorted)\n    context = fn(context)\n    context, _ = pad_packed_sequence(context)\n    context = context[torch.argsort(lens_idx)]\n    return context\n", "CodeBleu_score": 15.547292549735579}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 70.15353357610886}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', '')\n    torch_name = torch_name.replace('senet_', '')\n    torch_name = torch_name.replace('inceptionv3', 'inception')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 45.656074508058715}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    mx_name = mx_name.lower()\n    if mx_name.startswith('se_'):\n        mx_name = mx_name.replace('se_', 'squeezenext_')\n    if mx_name.startswith('senet_'):\n        mx_name = mx_name.replace('senet_', 'se_')\n    if mx_name.startswith('inceptionv3'):\n        mx_name = mx_name.replace('inceptionv3', 'inception')\n    return 'gluon_' + mx_name\n", "CodeBleu_score": 47.5609824140113}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', '')\n    torch_name = torch_name.replace('senet_', '')\n    torch_name = torch_name.replace('inceptionv3', 'inception')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 45.656074508058715}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self.num_samples\n    if self.repeats > 1:\n        num_samples = num_samples * self.repeats\n    if self.num_workers > 0:\n        num_samples = math.ceil(num_samples / self.num_workers)\n    if self.batch_size > 0:\n        num_samples = max(num_samples, self.batch_size)\n    return num_samples", "CodeBleu_score": 32.13032893883222}, {"code": "def _num_samples_per_worker(self)\n\t\n    if self.repeats > 1:\n        # If training or multiple replicas are used, round up the number of samples\n        num_samples_per_worker = math.ceil(self.num_samples / self.repeats)\n    else:\n        # If no repeats or batch size is specified, use the total number of samples\n        num_samples_per_worker = self.num_samples\n\n    if self.batch_size is not None:\n        # If a batch size is specified, adjust the number of samples to be a multiple of the batch size\n        num_samples_per_worker = (num_samples_per_worker + self.batch_size - 1) // self.batch_size * self.batch_size\n\n    return num_samples_per_worker\n\n", "CodeBleu_score": 34.762285713202246}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples_per_worker = (self.repeats * self.num_samples) // self.num_workers\n    if self.batch_size is not None:\n        num_samples_per_worker = (num_samples_per_worker + self.batch_size - 1) // self.batch_size * self.batch_size\n    return num_samples_per_worker\n\n", "CodeBleu_score": 25.675495258244197}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is not None:\n        types = set(types)\n    if class_to_idx is not None:\n        res = [(os.path.join(dp, f), class_to_idx[name.split(\"_\")[0]])\n               for dp, dn, filenames in os.walk(folder) for f in filenames\n               if ((not leaf_name_only or os.path.split(dp)[-1] == f) and\n                   (types is None or f.lower().endswith(types)))]\n    else:\n        res = [(os.path.join(dp, f), os.path.basename(dp))\n               for dp, dn, filenames in os.walk(folder) for f in filenames\n               if ((not leaf_name_only or os.path.split(dp)[-1] == f) and\n                   (types is None or f.lower().endswith(types)))]\n    if sort:\n        res.sort(key=lambda r: r[0])\n    if class_to_idx is None:\n        folders = set([r[1] for r in res])\n        mapping = {k: v for v, k in enumerate(sorted(folders))}\n        res = [(r[0], mapping[r[1]]) for r in res]\n    return res, mapping\n\n", "CodeBleu_score": 37.78128955227028}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is not None:\n        types = set(types)\n    img_names = []\n    # Iterate over all files in the folder and its subfolders\n    for root, _, fnames in sorted(os.walk(folder)):\n        for fname in sorted(fnames):\n            # Check if the file matches the specified types\n            is_valid = False\n            if types is None:\n                is_valid = True\n            elif fname.lower().endswith(get_img_extensions()):\n                is_valid = True\n            if is_valid:\n                target = os.path.join(root, fname)\n                img_names.append(target)\n\n    if class_to_idx is None:\n        # Build an index mapping labels to indices\n        labels = set()\n        for img_name in img_names:\n            label = os.path.relpath(img_name, folder)\n            if leaf_name_only:\n                label = label.replace(\"\\\\\", \"/\")\n                label = os.path.splitext(os.path.basename(label))[0]\n            labels.add(label)\n        labels = sorted(labels, key=natural_key)\n        # Backward compatibility\n        if len(labels) == 0:\n            raise FileNotFoundError(\"Dataset folder does not contain any valid file ({}). Supported extensions are: {}\".format(folder, \",\".join(IMG_EXTENSIONS)))\n        class_to_idx = {cls_name: idx for idx, cls_name in enumerate(labels)}\n    # Replace the image paths with their corresponding indices\n    img_targets = [class_to_idx[os.path.relpath(img_name, folder)] for img_name in img_names]\n    if sort:\n        img_names = list(sorted(img_names))\n        img_targets = list(sorted(img_targets))\n    return img_names, img_targets, class_to_idx\n\n", "CodeBleu_score": 41.01598153983446}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if class_to_idx is None:\n        classes, class_to_idx = find_classes(folder)\n    elif not class_to_idx:\n        raise ValueError(\"'class_to_index' must have at least one entry to collect any samples.\")\n\n    labels = []\n    filenames = []\n    for root, subdirs, files in os.walk(folder, topdown=True):\n        rel_path = os.path.relpath(root, folder) if (root != folder) else ''\n        label = os.path.basename(rel_path) if leaf_name_only else rel_path\n        for f in files:\n            base, ext = os.path.splitext(f)\n            if types is not None:\n                ext = ext.lower()\n                if ext not in types:\n                    continue\n\n            filenames.append(os.path.join(root, f))\n            labels.append(label)\n\n    if sort:\n        filenames, labels = zip(*sorted(\n            zip(filenames, labels), key=lambda f: natural_key(f[0])))\n\n    return filenames, labels, class_to_idx\n\n", "CodeBleu_score": 50.67067625459335}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        return worker_info.seed\n    return wds.utils.pytorch_worker_seed()", "CodeBleu_score": 66.80150511570375}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        # favour the seed already created for pytorch dataloader workers if it exists\n        return worker_info.seed\n    # fallback to wds rank based seed\n    return wds.utils.pytorch_worker_seed()\n\n\n", "CodeBleu_score": 66.80150511570375}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        # favour the seed already created for pytorch dataloader workers if it exists\n        return worker_info.seed\n    # fallback to wds rank based seed\n    return wds.utils.pytorch_worker_seed()", "CodeBleu_score": 66.80150511570375}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode in (\"L\", \"RGB\"):\n        lut = []\n        for i in range(256):\n            lut.append(255 if i < thresh else min(255, i + add))\n        img = img.point(lut * (1 if img.mode == \"L\" else 3))\n    return img\n\n\n\n\n", "CodeBleu_score": 44.486670223638825}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    mode = img.mode\n    if mode == \"L\":\n        lut = [i + add if i < thresh else i for i in range(256)]\n        img = img.point(lut)\n    elif mode == \"RGB\":\n        lut = [(i[0] + add if i[0] < thresh else i[0], i[1] + add if i[1] < thresh else i[1], i[2] + add if i[2] < thresh else i[2]) for i in range(256)]\n        img = img.point(lut)\n    else:\n        raise ValueError(\"Unsupported image mode: {}\".format(mode))\n    return img\n\n", "CodeBleu_score": 35.36436953173823}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    lut = [i + add if i < thresh else i for i in range(256)]\n    return img.point(lut, mode=img.mode)\n\n", "CodeBleu_score": 14.484358405348424}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names = []\n    transform_weights = []\n    for transform_name, transform_weight in transforms.items():\n        transform_names.append(transform_name)\n        transform_weights.append(transform_weight)\n    transform_weights = np.array(transform_weights) / np.sum(transform_weights)\n    return transform_names, transform_weights\n\n", "CodeBleu_score": 30.005642881420535}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names = []\n    transform_probs = []\n    for transform_name, transform_prob in transforms.items():\n        transform_names.append(transform_name)\n        transform_probs.append(transform_prob)\n    transform_probs = np.array(transform_probs)\n    transform_probs = transform_probs / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n", "CodeBleu_score": 36.305334776284084}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_probs = zip(*transforms.items())\n    transform_probs = np.array(transform_probs) / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n", "CodeBleu_score": 30.110471671460658}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size, dtype=np.uint8)\n    for w in mixing_weights:\n        for op in m:\n            img = op(img)\n        mixed += img * w\n    mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, m)\n", "CodeBleu_score": 26.79047689882339}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros((img.size[1], img.size[0], len(mixing_weights)))\n    for i, w in enumerate(mixing_weights):\n        mixed[:, :, i] = np.clip(\n            np.sum([op(img, choice(self.ops)(img, m)) for _ in range(m)], axis=0), 0, 255\n        )\n    mixed = mixed.astype(\"uint8\")\n    return Image.blend(img, Image.fromarray(mixed), m / (m + 1))", "CodeBleu_score": 25.29077394112979}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size)\n    for i in range(len(mixing_weights)):\n        mixed += mixing_weights[i] * np.asarray(\n            self.random_transform(img, m, img.getbands())\n        )\n    mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    return Image.blend(img, Image.fromarray(mixed), m)\n\n", "CodeBleu_score": 24.526332469343444}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = tuple(repeat(x, n))\n    elif len(x) != n:\n        _logger.warning(f'The length of x is {len(x)}, which is not equal to n={n}. Calculating the mean of x and repeating it n times.')\n        x = tuple(repeat(np.mean(x), n))\n    assert len(x) == n, f'The length of x is {len(x)}, which is not equal to n={n}.'\n    return x", "CodeBleu_score": 53.85137017198134}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = repeat(x, n)\n    elif len(x) != n:\n        _logger.warning(\n            f\"The length of x ({len(x)}) is not equal to the number of channels ({n}). Calculating the mean of x and repeating it {n} times.\"\n        )\n        x = repeat(np.mean(x), n)\n    assert len(x) == n, \"The length of x does not match the number of channels.\"\n    return x", "CodeBleu_score": 42.89194220283952}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = tuple(repeat(x, n))\n    elif len(x) != n:\n        _logger.warning(f\"Input x has length {len(x)}, which does not match the required number of channels n={n}. Calculating the mean of x and repeating it n times.\")\n        x = tuple(repeat(np.mean(x), n))\n    assert len(x) == n\n    return x", "CodeBleu_score": 53.72781887235608}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if worker_info.id != worker_id:\n        raise RuntimeError(f\"Worker {worker_id} is not initialized.\")\n    if worker_seeding == 'all':\n        seed = worker_info.seed\n        random.seed(seed)\n        torch.manual_seed(seed)\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, Callable):\n        worker_seeding(worker_id)\n    elif isinstance(worker_seeding, str):\n        if worker_seeding == 'all':\n            seed = worker_info.seed\n            np.random.seed(seed)\n        else:\n            raise ValueError(f\"Invalid worker_seeding value: {worker_seeding}\")\n    else:\n        raise ValueError(f\"Invalid worker_seeding type: {type(worker_seeding)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.356616312009855}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if worker_seeding == 'all':\n        worker_seed = worker_info.seed\n        random.seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        if isinstance(worker_seed, int):\n            seed(worker_seed)\n        else:\n            seed()\n    elif callable(worker_seeding):\n        worker_seed = worker_seeding(worker_id)\n        random.seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        if isinstance(worker_seed, int):\n            seed(worker_seed)\n        else:\n            seed()\n    elif isinstance(worker_seeding, int):\n        seed(worker_seeding)\n    else:\n        raise ValueError(f'Invalid worker_seeding {worker_seeding}')\n\n", "CodeBleu_score": 42.878161310068144}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if worker_seeding == 'all':\n        seed = worker_info.seed\n        if seed is not None:\n            random.seed(seed)\n            torch.manual_seed(seed)\n            if isinstance(seed, int):\n                seed = int(seed)\n            np.random.seed(seed)\n    elif callable(worker_seeding):\n        worker_seeding(worker_id)\n    elif worker_seeding == 'none':\n        pass\n    else:\n        raise ValueError(\"worker_seeding should be either 'all', 'none', or a callable function\")", "CodeBleu_score": 42.95274888176574}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image_shape = extract_jpeg_shape(image_bytes)\n    padded_center_crop_size = tf.cast(\n        (image_size / (image_size + PADDING)) * tf.cast(image_shape, tf.float32),\n        tf.int32)\n    offset_height = ((image_shape[0] - padded_center_crop_size[0]) + 1) // 2\n    offset_width = ((image_shape[1] - padded_center_crop_size[1]) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size[0], padded_center_crop_size[1]])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, resize_method)\n    return image\n", "CodeBleu_score": 44.55909296211071}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    # Decode the image bytes and get the shape of the image.\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    image_shape = tf.shape(image)\n    # Calculate the padded center crop size.\n    image_height = image_shape[0]\n    image_width = image_shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_height / (image_width / image_size + PADDING)) + PADDING) / 2,\n        tf.int32)\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    # Crop the image to the padded center.\n    cropped_image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, padded_center_crop_size,\n        padded_center_crop_size)\n    # Resize the cropped image to the given size.\n    resized_image = tf.image.resize(\n        cropped_image, [image_size, image_size], method=resize_method)\n    return resized_image\n\n\n\n\n", "CodeBleu_score": 42.869611661993915}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + PADDING)) *\n         tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32\n    )\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width,\n                            padded_center_crop_size, padded_center_crop_size])\n    image = tf.io.decode_and_crop_jpeg(\n        image_bytes, crop_window, channels=3)\n    return tf.image.resize(image, [image_size, image_size], method=resize_method)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.0961595828367}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    if use_bfloat16:\n        image = convert_image_dtype(image, dtype=tf.bfloat16)\n    else:\n        image = convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n", "CodeBleu_score": 41.47321051264014}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    dtype = tf.bfloat16 if use_bfloat16 else tf.float32\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, dtype=dtype)\n    return image\n\n", "CodeBleu_score": 35.23658812400277}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, dtype=(tf.bfloat16 if use_bfloat16 else tf.float32))\n    return image\n\n", "CodeBleu_score": 40.123615115475936}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    if use_bfloat16:\n        image = tf.image.convert_image_dtype(image, tf.bfloat16)\n    return image", "CodeBleu_score": 26.38176860643111}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = convert_image_dtype(image, use_bfloat16)\n    return image\n\n", "CodeBleu_score": 27.393980058725326}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    if use_bfloat16:\n        image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16)\n    else:\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n", "CodeBleu_score": 37.1332712943295}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    predictions = self.predict_loop(model, eval_dataloader)\n    self.save_predictions(predictions, output_file)\n    results = self.compute_metrics(predictions)\n    return results\n\n\n\n\n", "CodeBleu_score": 58.479873612401626}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    output_file = f\"{output_file}.csv\"\n    self.predict_loop(model, eval_dataloader, output_file)\n    self.compute_metrics(output_file)\n    return self.results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.89155830676491}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n\n    # Run the prediction loop\n    self.predict_loop(model, eval_dataloader, output_file)\n\n    # Compute evaluation metrics\n    metrics = self.compute_metrics(output_file)\n\n    return metrics\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.53821607873047}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(\n        f\"rank1: {rank1:.4f} | rank5: {rank5:.4f} | miou: {miou:.4f}\"\n    )", "CodeBleu_score": 33.1547150849467}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics[\"rank1\"]\n    rank5 = metrics[\"rank5\"]\n    miou = metrics[\"miou\"]\n    print(f\"Rank1: {rank1:.4f}\")\n    print(f\"Rank5: {rank5:.4f}\")\n    print(f\"Miou: {miou:.4f}\")", "CodeBleu_score": 33.028353372410514}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    print(f\"rank1: {metrics['rank1']:.4f}\")\n    print(f\"rank5: {metrics['rank5']:.4f}\")\n    print(f\"miou: {metrics['miou']:.4f}\")", "CodeBleu_score": 19.35767220162048}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment in segments:\n        ranks = []\n        ious = []\n        for gt in data:\n            ranks.append(self._rank(segment, gt))\n            ious.append(self._iou(segment, gt))\n        average_ranks.append(np.sum(np.sort(ranks)[:5]) / 5)\n        average_iou.append(np.mean(np.array(ious)))\n    rank1 = len([x for x in average_ranks if x == 1]) / len(average_ranks)\n    rank5 = len([x for x in average_ranks if x <= 5]) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 40.76225321347572}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment in segments:\n        ious = []\n        ranks = []\n        for gt in data:\n            ious.append(self._iou(segment, gt))\n            ranks.append(self._rank(segment, gt))\n        average_iou.append(np.mean(np.sort(np.array(ious))[-self.top_k:]))\n        average_ranks.append(np.mean(np.sort(np.array(ranks))[-self.top_k:]))\n    rank1 = np.mean(np.array(average_ranks) == 1)\n    rank5 = np.mean(np.array(average_ranks) <= 5)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 37.81401668784123}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment in segments:\n        ranks = []\n        ious = []\n        for gt in data:\n            ranks.append(self._rank(segment, gt))\n            ious.append(self._iou(segment, gt))\n        average_ranks.append(np.mean(np.sort(ranks)[:5]))\n        average_iou.append(np.mean(ious))\n    rank1 = np.sum(np.array(average_ranks) == 1) / len(average_ranks)\n    rank5 = np.sum(np.array(average_ranks) <= 5) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou\n\n", "CodeBleu_score": 43.87200965258489}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.to_ctx(0))\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            outputs = model(**self.to_ctx(batch))\n        outputs.update(batch)\n        self.finalize(outputs)\n        scores.append(outputs)\n    return scores\n\n", "CodeBleu_score": 42.669546743413676}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.to_ctx(model, ctx=0))\n    for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n        batch = self.to_ctx(batch, ctx=0)\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        outputs = self.process_outputs(outputs)\n        scores.extend(outputs[\"scores\"])\n    self.finalize(output_file)\n    return scores\n\n", "CodeBleu_score": 43.1574828809896}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(self.to_ctx(0))\n    for batch in eval_dataloader:\n        batch = self.to_ctx(batch)\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        outputs = self.process_outputs(outputs)\n        scores.extend(outputs)\n    if output_file is not None:\n        self.finalize(output_file)\n    return scores\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.79224064408572}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2, \"There should be exactly two sets of scores\"\n    full_scores = np.concatenate(scores, axis=0)\n    self.full_scores = None\n    return np.matmul(full_scores[0], full_scores[1].T)", "CodeBleu_score": 35.4725941469013}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    scores = [np.concatenate(s, axis=0) for s in scores]\n    self.full_scores = None\n    return np.matmul(scores[0], scores[1].T)", "CodeBleu_score": 37.07696065880246}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    assert len(scores[0]) == len(scores[1])\n    full_scores = np.concatenate([scores[0], scores[1]], axis=0)\n    self.full_scores = full_scores\n    return np.matmul(scores[0], scores[1].T)", "CodeBleu_score": 44.74716996216338}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0)\n    Y_true = torch.cat(Y_true, dim=0)\n    Y_pred = Y_pred.cpu().detach().numpy()\n    Y_true = Y_true.cpu().detach().numpy()\n    errors = np.where(Y_pred != Y_true)[0]\n    print(f\"{len(errors)} errors found.\")\n    if len(errors) > 0:\n        print(\"Sample of errors:\")\n        print(errors[:10])\n    if output_file is not None:\n        with open(output_file, \"wb\") as f:\n            pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, f)\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.1714485522901}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0).cpu().numpy()\n    Y_true = torch.cat(Y_true, dim=0).cpu().numpy()\n\n    if output_file is not None:\n        with open(output_file, 'wb') as f:\n            pickle.dump({'Y_pred': Y_pred, 'Y_true': Y_true}, f)\n\n    errors = Y_pred != Y_true\n    if np.any(errors):\n        print(\"Prediction errors:\")\n        for i in range(len(errors)):\n            if errors[i]:\n                print(\"Sample {}:\".format(i))\n                print(\"Predicted: {}\".format(Y_pred[i]))\n                print(\"True: {}\".format(Y_true[i]))\n                print()\n\n    return {'Y_pred': Y_pred, 'Y_true': Y_true}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.70449135940943}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred, dim=0)\n    Y_true = torch.cat(Y_true, dim=0)\n    Y_pred = Y_pred.cpu().detach().numpy()\n    Y_true = Y_true.cpu().detach().numpy()\n\n    # check for prediction errors\n    error_indices = np.where(Y_pred != Y_true)[0]\n    if len(error_indices) > 0:\n        print(\"Prediction errors found:\")\n        for i in error_indices[:10]:\n            print(f\"Sample {i}: Predicted {Y_pred[i]}, True {Y_true[i]}\")\n    else:\n        print(\"No prediction errors found.\")\n\n    # save predictions and true labels as a pickle file\n    if output_file is not None:\n        with open(output_file, \"wb\") as f:\n            pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, f)\n\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.335195526370526}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = utils.item(sum(log.get_loss() for log in logging_outputs))\n    sample_size_sum = utils.item(sum(log.get_sample_size() for log in logging_outputs))\n    metrics.log_scalar('loss', loss_sum / sample_size_sum, sample_size_sum, round=3)\n\n\n\n\n", "CodeBleu_score": 37.62125391379916}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    metrics.log_scalar(\n        \"loss\",\n        sum(log.get_loss() for log in logging_outputs) / len(logging_outputs),\n        round=3,\n    )\n    if len(logging_outputs) > 0 and \"nll_loss\" in logging_outputs[0]:\n        metrics.log_scalar(\n            \"nll_loss\",\n            sum(log.get(\"nll_loss\") for log in logging_outputs) / len(logging_outputs),\n            round=3,\n        )\n        metrics.log_derived(\n            \"ppl\", lambda meters: utils.get_perplexity(meters[\"nll_loss\"].avg)\n        )\n    else:\n        metrics.log_derived(\n            \"ppl\", lambda meters: utils.get_perplexity(meters[\"loss\"].avg)\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.478359970367162}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get_loss() for log in logging_outputs)\n    sample_size_sum = sum(log.get_sample_size() for log in logging_outputs)\n\n    metrics.log_scalar('loss', loss_sum / sample_size_sum, sample_size_sum, round=3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.110367599591}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    # If attention mask is not provided, create it using cmasks and vmasks.\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n\n    # Create token type IDs by concatenating zeros for visual tokens and ones for text tokens.\n    token_type_ids = torch.cat(\n        [\n            torch.zeros(\n                (cmasks.size(0), cmasks.size(1)),\n                dtype=torch.long,\n                device=cmasks.device,\n            ),\n            torch.ones(\n                (vmasks.size(0), vmasks.size(1)),\n                dtype=torch.long,\n                device=vmasks.device,\n            ),\n        ],\n        dim=1,\n    )\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 76.50996011404094}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n    if self.last_iso_layer == 0:\n        token_type_ids = torch.cat(\n            [\n                torch.zeros(cmasks.size(0), cmasks.size(1), device=cmasks.device),\n                torch.ones(vmasks.size(0), vmasks.size(1), device=vmasks.device),\n            ],\n            dim=1,\n        )\n    else:\n        token_type_ids = torch.zeros(\n            cmasks.size(0),\n            cmasks.size(1) + vmasks.size(1),\n            device=cmasks.device,\n        )\n        token_type_ids[:, : cmasks.size(1)] = 0\n        token_type_ids[:, cmasks.size(1) :] = 1\n    return attention_mask, token_type_ids\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.12006292017007}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n    token_type_ids = torch.cat(\n        [torch.zeros_like(vmasks), torch.ones_like(cmasks)], dim=1\n    )\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 35.59766362655816}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.ones_like(input_ids)\n    if token_type_ids is None:\n        token_type_ids = torch.zeros_like(input_ids)\n\n    # adjust sequence length to match combined length of input_ids and input_video_embeds\n    input_ids = input_ids[:, :-input_video_embeds.shape[1]]\n    attention_mask = attention_mask[:, :-input_video_embeds.shape[1]]\n    token_type_ids = token_type_ids[:, :-input_video_embeds.shape[1]]\n\n    # modify attention_mask and token_type_ids to fit the new sequence length\n    attention_mask = torch.cat([attention_mask, torch.ones_like(input_video_embeds)], dim=1)\n    token_type_ids = torch.cat([token_type_ids, torch.ones_like(input_video_embeds)], dim=1)\n\n    # concatenate input_ids and input_video_embeds\n    input_ids = torch.cat([input_ids, input_video_embeds], dim=1)\n\n    return {\n        \"input_ids\": input_ids,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.3605517133318}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.ones_like(input_ids)\n    if token_type_ids is None:\n        token_type_ids = torch.zeros_like(input_ids)\n\n    # Adjust sequence length to match the combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    if attention_mask.size(1) != combined_length:\n        attention_mask = torch.cat([attention_mask, torch.zeros_like(input_ids)], dim=1)\n    if token_type_ids.size(1) != combined_length:\n        token_type_ids = torch.cat([token_type_ids, torch.zeros_like(input_ids)], dim=1)\n\n    # Modify the attention_mask and token_type_ids to fit the new sequence length\n    attention_mask[:, input_ids.size(1):] = 0\n    token_type_ids[:, input_ids.size(1):] = 1\n\n    # Return the updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs,\n    }", "CodeBleu_score": 46.42820812563176}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    input_ids = input_ids.to(self.device)\n    input_video_embeds = input_video_embeds.to(self.device)\n    if attention_mask is not None:\n        attention_mask = attention_mask.to(self.device)\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids.to(self.device)\n\n    # adjust sequence length to match combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    if attention_mask is not None:\n        attention_mask = attention_mask[:, :combined_length]\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids[:, :combined_length]\n\n    # modify attention_mask and token_type_ids to fit the new sequence length\n    input_ids = input_ids[:, -combined_length:]\n    input_video_embeds = input_video_embeds[:, -combined_length:]\n\n    # return a dictionary containing the updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 56.83749377493328}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    pipeline_cfg = cfg.copy()\n    if 'meta_keys' in pipeline_cfg[0]:\n        pipeline_cfg[0]['meta_keys'].remove('img_id')\n    load_img_idx = self._get_transform_idx(pipeline_cfg, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise ValueError('LoadImageFromFile is not found in the pipeline')\n    pipeline_cfg[load_img_idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(pipeline_cfg)\n\n", "CodeBleu_score": 42.63277301423769}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    pipeline_cfg = cfg['pipeline']\n    if 'img_id' in pipeline_cfg[0]['meta_keys']:\n        pipeline_cfg[0]['meta_keys'].remove('img_id')\n    idx = self._get_transform_idx(pipeline_cfg, 'LoadImageFromFile')\n    if idx == -1:\n        raise ValueError('LoadImageFromFile transform not found in pipeline')\n    pipeline_cfg[idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(pipeline_cfg)\n\n\n", "CodeBleu_score": 36.67511822669788}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    # remove 'img_id' from meta_keys\n    if 'meta_keys' in cfg.pipeline[0]:\n        cfg.pipeline[0]['meta_keys'].remove('img_id')\n    # find LoadImageFromFile transform\n    load_img_idx = self._get_transform_idx(cfg.pipeline, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise ValueError('LoadImageFromFile transform not found in pipeline')\n    # update transform type to InferencerLoader\n    cfg.pipeline[load_img_idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(cfg.pipeline)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.52210811333409}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 37.27664845802001}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    if isinstance(inputs, (list, tuple)):\n        inputs = list(inputs)\n    else:\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 37.85253664330324}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, (str, Path)):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n\n", "CodeBleu_score": 34.972391316166274}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and (\"img\" in input or \"img_path\" in input):\n            img = input[\"img\"] if \"img\" in input else cv2.imread(input[\"img_path\"])\n            chunk_data.append(self.pipeline(img))\n        else:\n            chunk_data.append(input)\n        if len(chunk_data) >= chunk_size:\n            yield chunk_data\n            chunk_data = []\n    if len(chunk_data) > 0:\n        yield chunk_data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 34.18260417110481}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and 'img' in input:\n            img = input['img']\n            if self.pipeline is not None:\n                img = self.pipeline(img)\n            chunk_data.append(img)\n        elif isinstance(input, dict) and 'img_path' in input:\n            img_path = input['img_path']\n            img = cv2.imread(img_path)\n            if self.pipeline is not None:\n                img = self.pipeline(img)\n            chunk_data.append(img)\n        else:\n            raise ValueError(\"Invalid input format. Expected a dictionary with either an 'img' or 'img_path' key.\")\n\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n\n    if len(chunk_data) > 0:\n        yield chunk_data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.57804920851033}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for i, input in enumerate(inputs):\n        if i % chunk_size == 0:\n            if chunk_data:\n                yield chunk_data\n                chunk_data = []\n        if isinstance(input, dict):\n            if \"img\" in input:\n                input = input[\"img\"]\n            elif \"img_path\" in input:\n                input = input[\"img_path\"]\n        chunk_data.append(self.pipeline(input))\n    if chunk_data:\n        yield chunk_data\n\n", "CodeBleu_score": 34.94018710835261}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    if pred_out_dir != '' and return_datasamples:\n        warnings.warn('Saving datasamples is not supported when '\n                      'return_datasamples is True.')\n\n    if pred_out_dir != '' and not no_save_pred:\n        os.makedirs(osp.join(pred_out_dir, 'preds'), exist_ok=True)\n\n    if pred_out_dir != '' and not no_save_pred:\n        os.makedirs(osp.join(pred_out_dir, 'visualizations'), exist_ok=True)\n\n    results = []\n\n    for data_sample in preds:\n        if return_datasamples:\n            results.append(data_sample)\n        else:\n            results.append(self.pred2dict(data_sample, pred_out_dir))\n\n    if visualization is not None:\n        if pred_out_dir != '' and not no_save_pred:\n            for idx, vis in enumerate(visualization):\n                mmcv.imwrite(vis,\n                             osp.join(pred_out_dir, 'visualizations',\n                                      f'{idx}.png'))\n        results[0]['visualization'] = visualization\n\n    if print_result:\n        print_result_dict = results[0]\n        for key in print_result_dict:\n            if isinstance(print_result_dict[key], list):\n                print_result_dict[key] = [\n                    f'{len(print_result_dict[key])} elements'\n                ]\n            elif isinstance(print_result_dict[key], np.ndarray):\n                print_result_dict[key] = f'{print_result_dict[key].shape}'\n        print(f'{print_result_dict}')\n\n    return results\n\n", "CodeBleu_score": 42.57901918151625}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n    if pred_out_dir == '' and not no_save_pred:\n        pred_out_dir = osp.join(self.work_dir, 'preds')\n        if not osp.exists(pred_out_dir):\n            os.makedirs(pred_out_dir)\n\n    if return_datasamples and pred_out_dir != '':\n        warnings.warn('Saving datasamples is not supported.')\n\n    results = []\n    for data_sample in preds:\n        if visualization is not None:\n            img = visualization[data_sample.index].copy()\n            if 'pred_instances' in data_sample:\n                pred_instances = data_sample.pred_instances\n                if 'bboxes' in pred_instances:\n                    bboxes = pred_instances.bboxes\n                    labels = pred_instances.labels\n                    colors = [\n                        np.random.randint(0, 255, size=3)\n                        for _ in range(len(labels))\n                    ]\n                    colors = np.array(colors)\n                    colors = colors[labels]\n                    colors = colors.tolist()\n                    bbox_labels = [\n                        f'{self.model.dataset_meta[\"classes\"][label]}'\n                        for label in labels\n                    ]\n                    img = draw_bboxes(\n                        img,\n                        bboxes,\n                        colors=colors,\n                        labels=bbox_labels,\n                        show_score=False)\n                if 'masks' in pred_instances:\n                    masks = pred_instances.masks\n                    img = draw_masks(img, masks)\n            if 'pred_panoptic_seg' in data_sample:\n                pan = data_sample.pred_panoptic_seg.sem_seg.cpu().numpy()[0]\n                pan[pan % INSTANCE_OFFSET == len(\n                    self.model.dataset_meta['classes'])] = VOID\n                pan = id2rgb(pan).astype(np.uint8)\n                img = draw_seg(img, pan)\n            results.", "CodeBleu_score": 34.93025916284915}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    results = []\n    if pred_out_dir != '' and return_datasamples:\n        warnings.warn(\n            'Saving datasamples is not supported when return_datasamples is '\n            'True.')\n    if pred_out_dir != '':\n        mmengine.mkdir_or_exist(osp.join(pred_out_dir, 'preds'))\n\n    for i, data_sample in enumerate(preds):\n        result = self.pred2dict(data_sample, pred_out_dir)\n        if visualization is not None:\n            vis_img = visualization[i]\n            if isinstance(vis_img, np.ndarray):\n                vis_img = Image.fromarray(vis_img)\n            vis_img = mmcv.bgr2rgb(vis_img)\n            vis_img = Image.fromarray(vis_img)\n            vis_img.save(osp.join(pred_out_dir, 'vis',\n                                  f'{i}_vis.jpg'))\n        results.append(result)\n\n    if print_result:\n        self.print_result(results, no_save_pred)\n\n    if return_datasamples:\n        return preds\n    else:\n        return results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.956828780967236}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Get the dataset pipeline from the configuration\n    dataset_pipeline = cfg.dataset.pipeline\n\n    # Copy the first transform in the dataset pipeline\n    resize_transform = deepcopy(dataset_pipeline[0])\n\n    # Modify the copied transform to include only the 'Resize' transform\n    resize_transform.type = \"Resize\"\n\n    # Copy the last transform in the pipeline\n    last_transform = deepcopy(dataset_pipeline[-1])\n\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose([resize_transform, last_transform])\n\n    # Return the constructed test pipeline\n    return test_pipeline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.768002712329412}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    first_transform = copy.deepcopy(cfg.dataset.pipeline[0])\n    # Modify the first transform to include only the 'Resize' transform\n    first_transform.type = 'Resize'\n    # Copy the last transform in the pipeline\n    last_transform = copy.deepcopy(cfg.dataset.pipeline[-1])\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose([first_transform, last_transform])\n    return test_pipeline", "CodeBleu_score": 24.509754054935645}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Create a copy of the first transform in the dataset pipeline\n    resize_transform = copy.deepcopy(cfg.dataset.pipeline[0])\n\n    # Modify the copy to include only the 'Resize' transform\n    resize_transform.type = \"Resize\"\n    resize_transform.img_scale = (1333, 800)\n    resize_transform.multiscale_mode = \"range\"\n    resize_transform.keep_ratio = True\n    resize_transform.flip = False\n    resize_transform.flip_direction = \"horizontal\"\n    resize_transform.pad_val = dict(img=[114, 114, 114])\n    resize_transform.pad_to_square = False\n    resize_transform.pad_to_multiple = 1\n    resize_transform.pad_to_square_scale = 1333\n    resize_transform.scale_factor = 1.0\n    resize_transform.scale = None\n    resize_transform.img_norm_cfg = dict(mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n    resize_transform.bbox_clip_border = True\n    resize_transform.filter_empty_gt = True\n    resize_transform.add_gt_as_proposals = False\n    resize_transform.proposal_file = None\n    resize_transform.load_proposals = False\n    resize_transform.with_bbox = True\n    resize_transform.with_label = True\n    resize_transform.with_mask = False\n    resize_transform.with_seg = False\n    resize_transform.with_keypoints = False\n    resize_transform.with_dynamic_scale = None\n    resize_transform.ratio_range = (0.8, 1.2)\n    resize_transform.max_multiscale_num = 1\n    resize_transform.rescale = True\n    resize_transform.multiscale_range = None\n    resize_transform.auto_type", "CodeBleu_score": 13.228876015425717}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    img = img.astype(np.float32)\n    img /= 255.\n    img = img.transpose(2, 0, 1)\n    img = torch.from_numpy(img).unsqueeze(0)\n    data = dict(img=img, frame_id=frame_id, img_shape=img.shape,\n                ori_shape=img.shape, pad_shape=img.shape,\n                img_id=0, video_len=video_len)\n    test_pipeline = build_test_pipeline(model.cfg)\n    data = test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data)\n    if model.cfg.get('test_cfg', None) is not None:\n        data = model.test_cfg.test_pipeline(data", "CodeBleu_score": 23.218570161638542}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    img = img.astype(np.float32)\n    img = mmcv.imnormalize(img, None, model.cfg.data.test.img_norm_cfg)\n    img = torch.from_numpy(img).to(model.cfg.device)\n    img = img.unsqueeze(0)\n    data_dict = dict(\n        img=img,\n        frame_id=torch.LongTensor([frame_id]),\n        ori_shape=img.shape,\n        img_id=torch.LongTensor([0]),\n        video_len=torch.LongTensor([video_len]))\n    data_dict = model.test_step(data_dict)\n    return data_dict\n\n", "CodeBleu_score": 23.51894087091703}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    data = dict(\n        img=img,\n        frame_id=frame_id,\n        ori_shape=img.shape,\n        img_id=0,\n        video_len=video_len)\n\n    # prepare test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n    data = test_pipeline(data)\n\n    # ensure no unsupported modules like RoIPool are used\n    if model.device == 'cpu':\n        model.cfg.model.test_cfg.rcnn.rpn_head.type = 'RPNHead'\n        model.cfg.model.test_cfg.rcnn.rpn_head.num_convs = 0\n        model.cfg.model.test_cfg.rcnn.rpn_head.num_fcs = 0\n        model.cfg.model.test_cfg.rcnn.rpn_head.with_avg_pool = False\n        model.cfg.model.test_cfg.rcnn.rpn_head.with_max_pool = False\n        model.cfg.model.test_cfg.rcnn.rpn_head.with_cls_and_reg = True\n\n    # forward\n    with torch.no_grad():\n        result = model.test_step(data)\n\n    return result\n\n", "CodeBleu_score": 32.354962415395136}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n    return tokens_a, tokens_b\n\n", "CodeBleu_score": 76.0410609673484}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 77.02217016729102}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n\n\n\n", "CodeBleu_score": 77.02217016729102}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == '':\n        return None\n    activation_string = activation_string.lower()\n    if activation_string == 'sigmoid':\n        return Sigmoid()\n    elif activation_string == 'tanh':\n        return Tanh()\n    elif activation_string == 'relu':\n        return ReLU()\n    elif activation_string == 'leakyrelu':\n        return LeakyReLU()\n    elif activation_string == 'softmax':\n        return Softmax()\n    elif activation_string == 'linear':\n        return Linear()\n    elif activation_string == 'none':\n        return None\n    else:\n        raise ValueError('Activation function {} not supported.'.format(activation_string))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.151325230136415}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == \"\":\n        return None\n    activation_string = activation_string.lower()\n    if activation_string == \"relu\":\n        return nn.ReLU()\n    if activation_string == \"leakyrelu\":\n        return nn.LeakyReLU()\n    if activation_string == \"sigmoid\":\n        return nn.Sigmoid()\n    if activation_string == \"tanh\":\n        return nn.Tanh()\n    if activation_string == \"softmax\":\n        return nn.Softmax()\n    if activation_string == \"softplus\":\n        return nn.Softplus()\n    if activation_string == \"elu\":\n        return nn.ELU()\n    if activation_string == \"selu\":\n        return nn.SELU()\n    if activation_string == \"glu\":\n        return nn.GLU()\n    if activation_string == \"gelu\":\n        return nn.GELU()\n    if activation_string == \"softmax2d\":\n        return nn.Softmax2d()\n    if activation_string == \"logsigmoid\":\n        return nn.LogSigmoid()\n    if activation_string == \"hardsigmoid\":\n        return nn.Hardsigmoid()\n    if activation_string == \"hardswish\":\n        return nn.Hardswish()\n    if activation_string == \"mish\":\n        return nn.Mish()\n    if activation_string == \"softshrink\":\n        return nn.Softshrink()\n    if activation_string == \"softsign\":\n        return nn.Softsign()\n    if activation_string == \"tanhshrink\":\n        return nn.Tanhshrink()\n    if activation_string == \"logsoftmax\":\n        return nn.LogSoftmax()\n    if activation_string == \"softmin\":\n        return nn.Softmin()\n    if activation_string == \"prelu\":\n        return nn.PReLU()\n    if activation_string", "CodeBleu_score": 39.39773443327811}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if not activation_string:\n        return None\n    activations = {\n        \"relu\": tf.nn.relu,\n        \"relu6\": tf.nn.relu6,\n        \"elu\": tf.nn.elu,\n        \"selu\": tf.nn.selu,\n        \"swish\": tf.nn.swish,\n        \"gelu\": tf.nn.gelu,\n        \"tanh\": tf.nn.tanh,\n        \"sigmoid\": tf.nn.sigmoid,\n        \"softmax\": tf.nn.softmax,\n        \"softplus\": tf.nn.softplus,\n        \"softsign\": tf.nn.softsign,\n        \"mish\": tf.nn.mish,\n        \"hard_sigmoid\": tf.keras.activations.hard_sigmoid,\n        \"linear\": tf.keras.activations.linear,\n    }\n    activation_string = activation_string.lower()\n    if activation_string in activations:\n        return activations[activation_string]\n    else:\n        raise ValueError(\"Unsupported activation: \" + activation_string)\n\n\n\n\n", "CodeBleu_score": 50.451765865461226}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output", "CodeBleu_score": 87.51451468041077}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=3)\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_shape[1]]), tf.float32)\n\n    return to_mask\n\n", "CodeBleu_score": 30.713696702306592}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=2)\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    return to_mask\n\n", "CodeBleu_score": 35.12310622029974}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=3)\n    proj_shape = get_shape_list(to_mask, expected_rank=2)\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n    to_seq_length = proj_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    return to_mask\n\n", "CodeBleu_score": 32.82522607262268}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(\n        input_tensor,\n        [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.674656467999775}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(\n        input_tensor,\n        [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.674656467999775}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    input_tensor = tf.reshape(input_tensor,\n                              [batch_size, seq_length, num_attention_heads, width])\n    input_tensor = tf.transpose(input_tensor, [0, 2, 1, 3])\n    return input_tensor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.676170406078924}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    input_tensor.get_shape().assert_has_rank(2)\n    if input_tensor.get_shape().ndims == 2:\n        return input_tensor\n    else:\n        width = input_tensor.get_shape()[-1]\n        return tf.reshape(input_tensor, [-1, width])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.41945213001172}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    shape = input_tensor.get_shape().as_list()\n    if len(shape) < 2:\n        raise ValueError(\"The input tensor must have at least 2 dimensions.\")\n    elif len(shape) == 2:\n        return input_tensor\n    else:\n        width = shape[-1]\n        return tf.reshape(input_tensor, [-1, width])", "CodeBleu_score": 37.97534390324567}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    # Check the rank of the input tensor\n    rank = tf.rank(input_tensor)\n    if rank < 2:\n        raise ValueError(\"Input tensor must have rank at least 2.\")\n    # If the tensor is already rank 2, return it as is\n    if rank == 2:\n        return input_tensor\n    # Otherwise, reshape the tensor to have a shape of [-1, width]\n    width = tf.shape(input_tensor)[-1]\n    return tf.reshape(input_tensor, [-1, width])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.66719816435517}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    with open(os.path.join(data_dir, \"train.tsv\"), \"r\", encoding=\"utf-8\") as f:\n        reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n        for line_num, line in enumerate(reader):\n            if line_num == 0:\n                continue\n            guid = line[0]\n            text_a = line[1]\n            text_b = line[2]\n            label = line[-1]\n            if label == \"contradictory\":\n                label = \"contradiction\"\n            examples.append(\n                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label)\n            )\n    return examples\n\n", "CodeBleu_score": 39.30939144146676}, {"code": "def get_train_examples(self, data_dir)\n\t\n    lines = self._read_tsv(os.path.join(data_dir, \"train.tsv\"))\n    examples = []\n    for (i, line) in enumerate(lines):\n        if i == 0:\n            continue\n        guid = \"train-%d\" % (i)\n        text_a = tokenization.convert_to_unicode(line[1])\n        text_b = tokenization.convert_to_unicode(line[2])\n        label = tokenization.convert_to_unicode(line[3])\n        if label == \"contradictory\":\n            label = \"contradiction\"\n        examples.append(\n            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n    return examples\n\n", "CodeBleu_score": 47.72171875737854}, {"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    with open(os.path.join(data_dir, \"train.tsv\"), \"r\", encoding=\"utf-8\") as f:\n        reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n        for line_num, line in enumerate(reader):\n            if line_num == 0:\n                continue\n            guid = line[0]\n            text_a = line[1]\n            text_b = line[2]\n            label = line[-1]\n            if label == \"contradictory\":\n                label = \"contradiction\"\n            examples.append(\n                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label)\n            )\n    return examples\n\n", "CodeBleu_score": 39.30939144146676}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=1, output_type=tf.int32)\n    mask = tf.cast(is_real_example, dtype=tf.float32)\n    mean_loss = tf.reduce_sum(per_example_loss * mask) / tf.reduce_sum(mask)\n    accuracy = tf.reduce_sum(tf.cast(tf.equal(predictions, label_ids), dtype=tf.float32) * mask) / tf.reduce_sum(mask)\n    return {\n        'accuracy': accuracy,\n        'loss': mean_loss\n    }", "CodeBleu_score": 31.11116792447429}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    mask = tf.cast(is_real_example, dtype=tf.float32)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, label_ids), dtype=tf.float32) * mask)\n    mean_loss = tf.reduce_mean(per_example_loss * mask)\n    return {\n        \"accuracy\": accuracy,\n        \"mean_loss\": mean_loss,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.54459714682924}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.reduce_mean(tf.cast(tf.equal(predictions, label_ids), tf.float32))\n    mean_loss = tf.reduce_mean(per_example_loss * tf.cast(is_real_example, tf.float32))\n    return {\"accuracy\": accuracy, \"loss\": mean_loss}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.552425412450706}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    label_map = {}\n    for (i, label) in enumerate(label_list):\n        label_map[label] = i\n\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list, max_seq_length,\n                                         tokenizer)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 77.3878003864133}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list, max_seq_length,\n                                         tokenizer)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 83.23437047467984}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list, max_seq_length, tokenizer)\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 83.7190303398675}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"next_sentence\"):\n        output_weights = tf.get_variable(\n            \"output_weights\",\n            shape=[bert_config.hidden_size, 2],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits)\n\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 78.72948297114822}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/next_sentence\"):\n        output_weights = modeling.get_model_variable(\n            \"output_weights\",\n            shape=[bert_config.hidden_size, 2],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = modeling.get_model_variable(\n            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits)\n\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 72.19678054102965}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    output_weights = tf.get_variable(\n        \"output_weights\",\n        shape=[bert_config.hidden_size, bert_config.vocab_size],\n        initializer=modeling.create_initializer(bert_config.initializer_range),\n    )\n    output_bias = tf.get_variable(\n        \"output_bias\",\n        shape=[bert_config.vocab_size],\n        initializer=tf.zeros_initializer(),\n    )\n\n    with tf.variable_scope(\"loss\"):\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = log_softmax(logits, axis=-1)\n\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=bert_config.vocab_size, dtype=tf.float32)\n\n        per_example_loss = -tf.reduce_sum(log_probs * one_hot_labels, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n\n    return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 63.17314524245313}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1]\n    )\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.05015129505788}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    # sequence_tensor: [batch_size, seq_length, embedding_size]\n    # positions: [batch_size, seq_length]\n    # output: [batch_size, seq_length, embedding_size]\n    # Get the shape of the input sequence tensor.\n    seq_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = seq_shape[0]\n    seq_length = seq_shape[1]\n    width = seq_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(flat_offsets + positions, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 49.71570018415025}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    flattened_offsets = tf.range(tf.shape(sequence_tensor)[0]) * tf.shape(sequence_tensor)[1]\n    flattened_positions = tf.reshape(flattened_offsets + positions, [-1])\n    output_tensor = tf.gather(tf.reshape(sequence_tensor, [-1]), flattened_positions)\n    return output_tensor\n\n", "CodeBleu_score": 23.56234311877772}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 71.32095143473128}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    example = tf.io.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 64.19488911111898}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 71.32095143473128}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text.\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Find the start position of the first token of the answer.\n    for (i, token) in enumerate(doc_tokens):\n        if token == orig_answer_tokens[0]:\n            start = i\n            break\n\n    # Find the end position of the last token of the answer.\n    num_tokens = len(orig_answer_tokens)\n    for (i, token) in enumerate(doc_tokens):\n        if token == orig_answer_tokens[num_tokens - 1]:\n            end = (i + 1)\n            break\n\n    # If the answer is not within the context, return the original\n    # span.\n    if start >= len(doc_tokens) or end >= len(doc_tokens) or start < 0 or end < 0:\n        return (input_start, input_end)\n\n    # If the answer is within the context, find the split position\n    # between the start and end token.\n    while (start < len(doc_tokens) and end < len(doc_tokens) and\n           doc_tokens[start] == orig_answer_tokens[0] and\n           doc_tokens[end] == orig_answer_tokens[num_tokens - 1]):\n        start += 1\n        end -= 1\n\n    # Determine if the answer is out of context.\n    if start >= len(doc_tokens) or end < 0:\n        return (input_start, input_end)\n\n    # Return the new span.\n    return (start, end)\n\n", "CodeBleu_score": 26.320996282672514}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Find the start and end positions of the original answer text within the input span\n    orig_start_position = None\n    orig_end_position = None\n    for (i, token) in enumerate(doc_tokens):\n        token = token.strip()\n        if i == input_start:\n            orig_start_position = i\n        if i == input_end:\n            orig_end_position = i + 1\n        if token == orig_answer_tokens[0]:\n            if doc_tokens[i + 1:] == orig_answer_tokens[1:]:\n                orig_start_position = i\n                orig_end_position = i + len(orig_answer_tokens)\n                break\n    if orig_start_position == None or orig_end_position == None:\n        return (input_start, input_end)\n\n    # Find the best start and end positions within the input span\n    best_start_position = None\n    best_end_position = None\n    for (start_position, end_position) in _get_best_start_end_positions(\n            doc_tokens, orig_start_position, orig_end_position, tokenizer):\n        if start_position == None or end_position == None:\n            continue\n        if best_start_position == None or (\n                end_position - start_position\n        ) > (best_end_position - best_start_position):\n            best_start_position = start_position\n            best_end_position = end_position\n\n    return (best_start_position, best_end_position)\n\n", "CodeBleu_score": 23.722280825646152}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # Tokenize the original answer text\n    orig_answer_tokens = tokenizer.tokenize(orig_answer_text)\n\n    # Check if the original answer text is a substring of the input text\n    if \"\".join(orig_answer_tokens) not in \"\".join(doc_tokens[input_start:input_end + 1]):\n        return (input_start, input_end)\n\n    # Find the start and end positions of the original answer text within the input text\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(new_start, input_end + 1):\n            if doc_tokens[new_start:new_end + 1] == orig_answer_tokens:\n                return (new_start, new_end)\n\n    # If no match is found, return the original input start and end positions\n    return (input_start, input_end)\n\n", "CodeBleu_score": 41.6399147678003}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = -1000000\n    best_span_index = -1\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = (num_left_context + num_right_context) / span.length\n        if score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n", "CodeBleu_score": 61.95352641747203}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = -1000000\n    best_span_index = -1\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = ((-1 * num_left_context) + (-1 * num_right_context))\n        if score > best_score:\n            best_score = score\n            best_span_index = span_index\n    if best_span_index == cur_span_index:\n        return True\n    else:\n        return False\n", "CodeBleu_score": 58.661522083237706}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = -1000000\n    best_span_index = -1\n    for (span_index, span) in enumerate(doc_spans):\n        end = span.start + span.length - 1\n        if position < span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - span.start\n        num_right_context = end - position\n        score = ((-1.0 * num_left_context) * 0.05) - ((-1.0 * num_right_context) * 0.05) + (0.1 * span.length)\n        if score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n", "CodeBleu_score": 61.931048024185785}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 65.86707343330198}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 65.86707343330198}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with tf.gfile.GFile(vocab_file, \"r\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 74.17973775756064}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\n\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\n\n\n", "CodeBleu_score": 79.63749907165396}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens", "CodeBleu_score": 88.10762355418231}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    for token in tokens:\n        if token in self.vocab:\n            split_tokens.append(token)\n        else:\n            split_tokens.extend(self.wordpiece_tokenizer.tokenize(token))\n    return split_tokens", "CodeBleu_score": 39.8370770275309}, {"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens\n\n", "CodeBleu_score": 88.10762355418231}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        audio_data = self.load(path, offset, duration, sample_rate, dtype)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.813596670790584}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading audio from {path} with offset {offset}s and duration {duration}s\")\n        audio = self.load(path, offset=offset, duration=duration, sample_rate=sample_rate, dtype=dtype)\n        return audio, False\n    except Exception as e:\n        logger.exception(f\"Error loading audio from {path}: {e}\")\n        return -1.0, True\n\n\n\n\n", "CodeBleu_score": 35.47316610922317}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        audio_data = self.load(path, offset, duration, sample_rate, dtype)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(f\"Failed to load audio from {path}\")\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.696426767018675}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if n_channels < 1:\n        raise ValueError(f\"n_channels must be greater than 0, got {n_channels}\")\n\n    def trim_channels(waveform: tf.Tensor) -> tf.Tensor:\n        \"\"\"Trims the waveform to the desired number of channels.\"\"\"\n        return waveform[:, :n_channels]\n\n    def tile_channels(waveform: tf.Tensor) -> tf.Tensor:\n        \"\"\"Tiles the waveform to increase the channels and then trims it.\"\"\"\n        waveform = tf.tile(waveform, [1, n_channels // tf.shape(waveform)[-1] + 1])\n        return trim_channels(waveform)\n\n    return tf.cond(\n        tf.shape(waveform)[-1] >= n_channels,\n        lambda: trim_channels(waveform),\n        lambda: tile_channels(waveform),\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.750763963475904}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    n_channels = tf.cast(n_channels, tf.int32)\n    waveform_shape = tf.shape(waveform)\n    n_channels_waveform = waveform_shape[-1]\n    n_channels_waveform = tf.cast(n_channels_waveform, tf.int32)\n    waveform_shape_cond = tf.cond(\n        n_channels_waveform > n_channels,\n        lambda: waveform_shape[:-1] + [n_channels],\n        lambda: waveform_shape[:-1] + [n_channels_waveform],\n    )\n    waveform_cond = tf.cond(\n        n_channels_waveform > n_channels,\n        lambda: waveform[..., :n_channels],\n        lambda: waveform,\n    )\n    waveform_tile = tf.tile(waveform_cond, [1] * (len(waveform_shape_cond) - 1) + [n_channels // n_channels_waveform])\n    waveform_tile_shape = tf.shape(waveform_tile)\n    waveform_tile_shape = tf.cast(waveform_tile_shape, tf.int32)\n    waveform_tile_shape_cond = tf.cond(\n        waveform_tile_shape[-1] > n_channels,\n        lambda: waveform_tile_shape[:-1] + [n_channels],\n        lambda: waveform_tile_shape,\n    )\n    waveform_tile_cond = tf.cond(\n        waveform_tile_shape[-1] > n_channels,\n        lambda: waveform_tile[..., :n_channels],\n        lambda: waveform_tile,\n    )\n    return waveform_tile_cond\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.46498794476844}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    waveform_shape = tf.shape(waveform)\n    waveform_rank = tf.rank(waveform)\n    waveform_channels = waveform_shape[waveform_rank - 1]\n    waveform_channels_cond = tf.less_equal(waveform_channels, n_channels)\n\n    waveform_channels_cond_true = tf.cond(\n        waveform_channels_cond,\n        lambda: waveform,\n        lambda: tf.tile(waveform, [1] * (waveform_rank - 1) + [n_channels // waveform_channels]),\n    )\n\n    waveform_channels_cond_false = tf.cond(\n        waveform_channels_cond,\n        lambda: waveform[:, :, :n_channels],\n        lambda: waveform,\n    )\n\n    return tf.cond(\n        waveform_channels_cond,\n        lambda: waveform_channels_cond_true,\n        lambda: waveform_channels_cond_false,\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.66171458163254}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return from_float32_to_uint8(\n        tf.clip_by_value(\n            gain_to_db(spectrogram, **kwargs),\n            -db_range,\n            tf.reduce_max(gain_to_db(spectrogram, **kwargs)),\n        )\n    )", "CodeBleu_score": 36.49846820712798}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    # Convert to dB\n    spectrogram = gain_to_db(spectrogram)\n\n    # Find maximum dB value\n    max_db = tf.reduce_max(spectrogram)\n\n    # Clip dB spectrogram to specified range below maximum dB value\n    spectrogram = tf.clip_by_value(spectrogram, max_db - db_range, max_db)\n\n    # Convert from float32 to uint8\n    spectrogram = from_float32_to_uint8(spectrogram)\n\n    return spectrogram\n\n", "CodeBleu_score": 42.99594715620483}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    spectrogram_db = gain_to_db(spectrogram)\n    max_db = tf.reduce_max(spectrogram_db)\n    clipped_db = tf.clip_by_value(spectrogram_db, max_db - db_range, max_db)\n    return from_float32_to_uint8(clipped_db)", "CodeBleu_score": 37.78707961860311}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window = tf.pow(tf.signal.hann_window(frame_length, dtype=tf.float32), window_exponent)\n    stfts = tf.signal.stft(waveform, frame_length, frame_step, window, pad_end=True)\n    spectrogram = tf.abs(stfts)\n    spectrogram = tf.transpose(spectrogram, perm=[1, 2, 0])\n    spectrogram = tf.pow(spectrogram, spec_exponent)\n    return spectrogram\n\n", "CodeBleu_score": 38.464221988640865}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window_length = int(2 ** (window_exponent + frame_length.bit_length() - 1))\n    window = hann_window(window_length)\n    stfts = stft(\n        tf.squeeze(waveform),\n        frame_length=frame_length,\n        frame_step=frame_step,\n        window_fn=lambda x: tf.pow(window, x),\n    )\n    spectrogram = tf.abs(stfts)\n    spectrogram = tf.transpose(spectrogram, perm=[1, 0, 2])\n    return tf.pow(spectrogram, spec_exponent)", "CodeBleu_score": 38.96550779189314}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n\n    # Apply Hann window function to the waveform tensor\n    window_fn = tf.signal.hann_window(frame_length, dtype=waveform.dtype)\n    window_fn = tf.pow(window_fn, window_exponent)\n    waveform = waveform * window_fn\n\n    # Compute STFT of the waveform tensor\n    stfts = tf.signal.stft(\n        waveform, frame_length=frame_length, frame_step=frame_step, fft_length=frame_length\n    )\n\n    # Transpose the STFT tensor\n    stfts = tf.transpose(stfts, perm=[1, 2, 0])\n\n    # Compute spectrogram tensor\n    spectrograms = tf.abs(stfts)\n\n    # Raise the spectrogram tensor to the specified exponent\n    spectrograms = tf.pow(spectrograms, spec_exponent)\n\n    return spectrograms\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.30579688350802}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the new time dimension\n    new_time = tf.cast(tf.shape(spectrogram)[1], tf.float32) * factor\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [tf.cast(new_time, tf.int32)], method=method\n    )\n    # Adjust the resized spectrogram to the original dimensions by cropping or padding\n    resized_spectrogram = tf.image.resize_with_crop_or_pad(\n        resized_spectrogram, tf.shape(spectrogram)[1], tf.shape(spectrogram)[2]\n    )\n    return resized_spectrogram\n\n", "CodeBleu_score": 40.78074628636168}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    if factor == 1.0:\n        return spectrogram\n    original_time_dim = tf.shape(spectrogram)[0]\n    new_time_dim = tf.cast(original_time_dim * factor, tf.int32)\n    spectrogram = tf.image.resize(\n        spectrogram,\n        [new_time_dim, tf.shape(spectrogram)[1]],\n        method=method,\n    )\n    if new_time_dim > original_time_dim:\n        spectrogram = tf.image.resize_with_crop_or_pad(\n            spectrogram, original_time_dim, tf.shape(spectrogram)[1]\n        )\n    else:\n        spectrogram = tf.image.resize_with_pad(\n            spectrogram, original_time_dim, tf.shape(spectrogram)[1]\n        )\n    return spectrogram\n\n", "CodeBleu_score": 45.65043039252233}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the new time dimension\n    new_time = tf.cast(tf.shape(spectrogram)[0], tf.float32) * factor\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        (tf.cast(new_time, tf.int32), tf.shape(spectrogram)[1]),\n        method=method,\n    )\n\n    # Adjust the resized spectrogram to the original dimensions by cropping or padding\n    if new_time > tf.shape(spectrogram)[0]:\n        # Crop the spectrogram to the original dimensions\n        start_time = tf.cast(\n            (new_time - tf.shape(spectrogram)[0]) / 2, tf.int32\n        )\n        resized_spectrogram = resized_spectrogram[\n            start_time : start_time + tf.shape(spectrogram)[0]\n        ]\n    else:\n        # Pad the spectrogram to the original dimensions\n        start_time = tf.cast(\n            (tf.shape(spectrogram)[0] - new_time) / 2, tf.int32\n        )\n        resized_spectrogram = tf.pad(\n            resized_spectrogram,\n            [[start_time, tf.shape(spectrogram)[0] - new_time - start_time]],\n        )\n\n    return resized_spectrogram\n\n", "CodeBleu_score": 40.17344198654342}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = 2 ** (semitone_shift / 12)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=(\n            tf.cast(tf.shape(spectrogram)[0], tf.float32) * resizing_factor,\n            tf.cast(tf.shape(spectrogram)[1], tf.float32),\n        ),\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=tf.constant(\n            [[0, tf.maximum(0, tf.cast(tf.shape(spectrogram)[0], tf.int32) - tf.shape(resized_spectrogram)[0])], [0, 0]]\n        ),\n        mode=\"CONSTANT\",\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 33.6580064839502}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = tf.pow(2.0, semitone_shift / 12.0)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=(tf.shape(spectrogram)[0], tf.cast(tf.shape(spectrogram)[1] * resizing_factor, tf.int32)),\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=tf.constant([[0, 0], [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]]]),\n        mode=\"CONSTANT\",\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 31.90720872633569}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = 2 ** (semitone_shift / 12)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        [\n            tf.cast(tf.shape(spectrogram)[0], tf.int32),\n            tf.cast(tf.shape(spectrogram)[1] * resizing_factor, tf.int32),\n        ],\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[0, 0], [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]]],\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 34.6749116313066}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return nn.ReLU()\n    elif conv_activation == \"ELU\":\n        return nn.ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"Invalid activation function: {conv_activation}\")\n", "CodeBleu_score": 42.38926490878458}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return nn.ReLU()\n    elif conv_activation == \"ELU\":\n        return nn.ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"Invalid activation layer: {conv_activation}\")\n", "CodeBleu_score": 42.407692662611204}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params.get(\"conv_activation\") == \"ReLU\":\n        return nn.ReLU()\n    elif params.get(\"conv_activation\") == \"ELU\":\n        return nn.ELU()\n    elif params.get(\"conv_activation\") == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(\n            f\"Invalid value for 'conv_activation': {params.get('conv_activation')}\"\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.51800011319977}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(\n            input_tensor,\n            output_name=f\"logit_mask_{instrument}\",\n            params=params,\n            output_mask_logit=True,\n        )\n        logit_mask_list.append(logit_mask)\n    logit_mask_stack = tf.stack(logit_mask_list, axis=-1)\n    softmax_mask = Softmax(axis=-1)(logit_mask_stack)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = Multiply(name=f\"output_{instrument}\")(\n            [input_tensor, softmax_mask[:, :, :, i]]\n        )\n    return output_dict\n\n", "CodeBleu_score": 42.55692994061834}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logging.info(\"Apply softmax unet\")\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(\n            input_tensor,\n            output_name=instrument,\n            params=params,\n            output_mask_logit=True,\n        )\n        logit_mask_list.append(logit_mask)\n    logit_mask_tensor = tf.stack(logit_mask_list, axis=-1)\n    softmax_mask = Softmax(axis=-1)(logit_mask_tensor)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = Multiply(name=instrument)(\n            [input_tensor, softmax_mask[:, :, :, i : i + 1]]\n        )\n    return output_dict\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.918346563832344}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    # Apply the unet to each instrument.\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(input_tensor, output_name=instrument, params=params)\n        logit_mask_list.append(logit_mask)\n    # Softmax over axis=-1.\n    softmax = Softmax(axis=-1)\n    softmax_mask_list = [softmax(logit_mask) for logit_mask in logit_mask_list]\n    # Create the output dictionary.\n    output_dict = {}\n    for instrument, softmax_mask in zip(instruments, softmax_mask_list):\n        output_dict[instrument] = Multiply()([input_tensor, softmax_mask])\n    return output_dict\n\n", "CodeBleu_score": 32.314232517219224}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as f:\n        while True:\n            data = f.read(BUFFER_SIZE)\n            if not data:\n                break\n            sha256.update(data)\n    return sha256.hexdigest()\n", "CodeBleu_score": 36.17208331449207}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as f:\n        while True:\n            data = f.read(1024)\n            if not data:\n                break\n            sha256.update(data)\n    return sha256.hexdigest()\n", "CodeBleu_score": 39.06315299249312}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for chunk in iter(lambda: f.read(4096), b''):\n            sha256.update(chunk)\n    return sha256.hexdigest()", "CodeBleu_score": 57.841685548191435}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.26778551956617}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.418427243737774}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.418427243737774}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join((self._host, self._repository, self.RELEASE_PATH, self._release, self.MODEL_INDEX))\n    response: httpx.Response = httpx.get(url)\n    response.raise_for_status()\n    index: Dict = response.json()\n    if name not in index:\n        raise ValueError(f\"No model for {name}\")\n    model: Dict = index[name]\n    url: str = \"/\".join((self._host, self._repository, self.RELEASE_PATH, self._release, model[\"path\"]))\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.stream(\"GET\", url, headers={\"Accept-Encoding\": \"gzip\"}) as response:\n        response.raise_for_status()\n        with NamedTemporaryFile(delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n        checksum: str = compute_file_checksum(stream.name)\n        if checksum != model[\"checksum\"]:\n            raise ValueError(f\"Invalid checksum for {name}\")\n        logger.info(f\"Extracting {name}\")\n        tarfile.open(stream.name, \"r:gz\").extractall(path)\n        os.unlink(stream.name)\n        logger.info(f\"Extracted {name}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.45542642133418}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODELS_INDEX,\n            name,\n        )\n    )\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.stream(\"GET\", url) as response:\n        response.raise_for_status()\n        with NamedTemporaryFile(delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n        checksum: str = self.checksum(name)\n        if checksum != compute_file_checksum(stream.name):\n            raise IOError(f\"Invalid checksum for {name}\")\n        logger.info(f\"Extracting {name} to {path}\")\n        tar.extractall(path)\n        os.unlink(stream.name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.6851995893348}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_INDEX,\n        )\n    )\n    response: httpx.Response = httpx.get(url)\n    response.raise_for_status()\n    index: Dict = response.json()\n    if name not in index:\n        raise ValueError(f\"No model for {name}\")\n    url: str = index[name]\n    logger.info(f\"Downloading {name} from {url}\")\n    with httpx.Client() as client:\n        response: httpx.Response = client.stream(url)\n        response.raise_for_status()\n        with NamedTemporaryFile(mode=\"wb\", delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n    checksum: str = self.checksum(name)\n    if checksum != compute_file_checksum(stream.name):\n        raise ValueError(f\"Checksum mismatch for {name}\")\n    logger.info(f\"Extracting {name} to {path}\")\n    tar.extractall(path)\n    os.unlink(stream.name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.33593493642519}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embed://\"):\n        name = descriptor[len(\"embed://\") :]\n        try:\n            return json.load(loader.open_text(f\"spleeter.config.{name}\"))\n        except FileNotFoundError as e:\n            raise SpleeterError(f\"Unable to find embedded configuration: {name}\") from e\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"Unable to find configuration file: {descriptor}\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)", "CodeBleu_score": 45.68979122184273}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith('embed://'):\n        name = descriptor.split('//')[1]\n        if not loader.is_resource(name):\n            raise SpleeterError(f'Embedded configuration \"{name}\" not found')\n        return json.load(loader.open_text(name))\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f'Configuration file \"{descriptor}\" not found')\n    with open(descriptor) as f:\n        return json.load(f)", "CodeBleu_score": 50.01508608505104}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embed://\"):\n        name = descriptor[len(\"embed://\") :]\n        loader = pkg_resources.get_loader(\"spleeter\")\n        if not loader.is_resource(name):\n            raise SpleeterError(\"Embedded configuration not found: {}\".format(name))\n        return json.load(loader.open_text(name))\n    if not os.path.isfile(descriptor):\n        raise SpleeterError(\"Configuration file not found: {}\".format(descriptor))\n    with open(descriptor, \"r\") as f:\n        return json.load(f)", "CodeBleu_score": 45.33645611845061}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError\n    concat_tensor = tf.concat(list(tensor_dict.values()), axis=concat_axis)\n    processed_tensor = func(concat_tensor)\n    split_tensor_list = tf.split(processed_tensor, len(tensor_dict), axis=concat_axis)\n    return {k: v for k, v in zip(tensor_dict.keys(), split_tensor_list)}\n\n", "CodeBleu_score": 32.965874474628066}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\n            \"Concatenation axis must be either 0 or 1, got {}\".format(concat_axis)\n        )\n    tensor_list = list(tensor_dict.values())\n    if concat_axis == 0:\n        concatenated = tf.concat(tensor_list, axis=concat_axis)\n        processed = func(concatenated)\n        split_indices = [tf.shape(tensor_list[0])[0]]\n        for i in range(1, len(tensor_list)):\n            split_indices.append(split_indices[-1] + tf.shape(tensor_list[i])[0])\n        split_indices = tf.constant(split_indices, dtype=tf.int64)\n        split_tensors = tf.split(processed, split_indices, axis=0)\n        return dict(zip(tensor_dict.keys(), split_tensors))\n    else:\n        concatenated = tf.concat(tensor_list, axis=concat_axis)\n        processed = func(concatenated)\n        split_indices = [tf.shape(tensor_list[0])[1]]\n        for i in range(1, len(tensor_list)):\n            split_indices.append(split_indices[-1] + tf.shape(tensor_list[i])[1])\n        split_indices = tf.constant(split_indices, dtype=tf.int64)\n        split_tensors = tf.split(processed, split_indices, axis=1)\n        return dict(zip(tensor_dict.keys(), split_tensors))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.27047220632772}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError\n    if concat_axis == 0:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=0)\n        output_tensor = func(concat_tensor)\n        output_dict = {}\n        for i, key in enumerate(tensor_dict.keys()):\n            output_dict[key] = output_tensor[\n                i * tf.shape(tensor_dict[key])[0] : (i + 1)\n                * tf.shape(tensor_dict[key])[0]\n            ]\n    elif concat_axis == 1:\n        concat_tensor = tf.concat(list(tensor_dict.values()), axis=1)\n        output_tensor = func(concat_tensor)\n        output_dict = {}\n        for i, key in enumerate(tensor_dict.keys()):\n            output_dict[key] = output_tensor[\n                :, i * tf.shape(tensor_dict[key])[1] : (i + 1) * tf.shape(tensor_dict[key])[1]\n            ]\n    return output_dict", "CodeBleu_score": 48.0851297647245}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n\n    # Compute the minimum and maximum values of the tensor\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n\n    # Scale the tensor values to the uint8 range (0-255)\n    scaled_tensor = (tensor - min_value) / (max_value - min_value) * 255\n    scaled_tensor = tf.cast(scaled_tensor, tf.uint8)\n\n    # Create a dictionary containing the scaled uint8 tensor, the original minimum value, and the original maximum value\n    result_dict = {\n        tensor_key: scaled_tensor,\n        min_key: min_value,\n        max_key: max_value,\n    }\n\n    return result_dict\n\n", "CodeBleu_score": 48.86038211785424}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    # Get the minimum and maximum values of the tensor\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n\n    # Scale the tensor values to the uint8 range (0-255)\n    scaled_tensor = tf.cast(\n        tf.math.round(\n            tf.cast(tensor, tf.float32)\n            * (255 / (max_value - min_value))\n            - (min_value * (255 / (max_value - min_value)))\n        ),\n        tf.uint8,\n    )\n\n    return {tensor_key: scaled_tensor, min_key: min_value, max_key: max_value}\n\n", "CodeBleu_score": 41.93805861124657}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n\n    tensor_min = tf.reduce_min(tensor)\n    tensor_max = tf.reduce_max(tensor)\n    tensor_scaled = (tensor - tensor_min) / (tensor_max - tensor_min)\n    tensor_scaled = tf.cast(tensor_scaled * 255, tf.uint8)\n    return {tensor_key: tensor_scaled, min_key: tensor_min, max_key: tensor_max}\n\n", "CodeBleu_score": 59.089017428818835}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = segment_len - tf.floormod(tf.shape(tensor)[0], segment_len)\n    # Pad the tensor with zeros\n    padded_tensor = tf.pad(tensor, [[0, padding], [0, 0]])\n    # Reshape the padded tensor into a new tensor with the specified segment length\n    reshaped_tensor = tf.reshape(padded_tensor, [-1, segment_len, tf.shape(tensor)[1]])\n    return reshaped_tensor\n", "CodeBleu_score": 26.53013606560693}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = segment_len - tf.floormod(tf.shape(tensor)[0], segment_len)\n    # Pad the tensor with zeros\n    padded_tensor = tf.pad(tensor, [[0, padding], [0, 0]])\n    # Reshape the padded tensor into a new tensor with the specified segment length\n    return tf.reshape(padded_tensor, [-1, segment_len, tf.shape(tensor)[1]])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.149795796554418}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = segment_len - tf.shape(tensor)[-1] % segment_len\n    # Pad the tensor with zeros\n    padded_tensor = tf.pad(tensor, [[0, 0], [0, padding]])\n    # Reshape the padded tensor into a new tensor with the specified segment length\n    reshaped_tensor = tf.reshape(padded_tensor, [-1, segment_len])\n    return reshaped_tensor\n\n", "CodeBleu_score": 21.625871097521166}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    num_extra_rows = F - frame_length\n\n    # Create an extension of zeros\n    zeros = tf.zeros((num_extra_rows, instr_spec.shape[1]))\n\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    padded_spec = tf.concat([instr_spec, zeros], axis=0)\n\n    # Reshape the extended spectrogram by merging the first two dimensions\n    reshaped_spec = tf.reshape(padded_spec, (-1, F))\n\n    return reshaped_spec\n\n", "CodeBleu_score": 13.003350826964125}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    num_extra_rows = frame_length - tf.shape(instr_spec)[0] % frame_length\n\n    # Create an extension of zeros\n    zeros = tf.zeros((num_extra_rows, tf.shape(instr_spec)[1]), dtype=tf.float32)\n\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    extended_spec = tf.concat([instr_spec, zeros], axis=0)\n\n    # Reshape the extended spectrogram by merging the first two dimensions\n    processed_spec = tf.reshape(extended_spec, (-1, F))\n\n    return processed_spec\n\n\n\n\n", "CodeBleu_score": 20.204631333855797}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    num_extra_rows = frame_length - tf.shape(instr_spec)[0] % frame_length\n    # Create an extension of zeros with the same number of columns as the input spectrogram\n    extension = tf.zeros([num_extra_rows, tf.shape(instr_spec)[1]], dtype=tf.float32)\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    extended_spec = tf.concat([instr_spec, extension], axis=0)\n    # Reshape the extended spectrogram by merging the first two dimensions\n    reshaped_spec = tf.reshape(extended_spec, [-1, F])\n    return reshaped_spec\n\n\n\n\n", "CodeBleu_score": 21.96337496999331}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(df.values)", "CodeBleu_score": 29.79569440659192}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(df.values)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.79569440659192}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path)\n    return tf.data.Dataset.from_tensor_slices(df)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 17.232156492595102}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], length))\n    return result\n\n", "CodeBleu_score": 38.26213886106719}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, target_dim in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], target_dim))\n    return result\n\n", "CodeBleu_score": 38.82182699963245}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for dim, length in enumerate(target_shape):\n        result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[dim], length))\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.05893262328507}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params,\n        audio_adapter,\n        chunk_duration=audio_params.get(\"chunk_duration\", 11.88),\n        random_seed=audio_params.get(\"random_seed\", 1234),\n    )\n    return builder.build(\n        train_csv_path,\n        batch_size=audio_params.get(\"batch_size\", 8),\n        shuffle=True,\n        convert_to_uint=True,\n        random_data_augmentation=audio_params.get(\"random_data_augmentation\", False),\n        random_time_crop=audio_params.get(\"random_time_crop\", True),\n        infinite_generator=True,\n        cache_directory=audio_params.get(\"cache_directory\", None),\n        wait_for_cache=False,\n        num_parallel_calls=audio_params.get(\"num_parallel_calls\", 4),\n        n_chunks_per_song=audio_params.get(\"n_chunks_per_song\", 2),\n    )\n\n", "CodeBleu_score": 51.93465289520369}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        chunk_duration=audio_params.get(\"chunk_duration\"),\n        random_seed=audio_params.get(\"random_seed\"),\n    )\n    train_csv_path = audio_params.get(\"train_csv_path\")\n    cache_directory = audio_params.get(\"cache_directory\")\n    batch_size = audio_params.get(\"batch_size\")\n    n_chunks_per_song = audio_params.get(\"n_chunks_per_song\")\n    random_data_augmentation = audio_params.get(\"random_data_augmentation\")\n    random_time_crop = audio_params.get(\"random_time_crop\")\n    return builder.build(\n        csv_path=train_csv_path,\n        batch_size=batch_size,\n        convert_to_uint=True,\n        random_data_augmentation=random_data_augmentation,\n        random_time_crop=random_time_crop,\n        infinite_generator=True,\n        cache_directory=cache_directory,\n        wait_for_cache=False,\n        num_parallel_calls=4,\n        n_chunks_per_song=n_chunks_per_song,\n    )", "CodeBleu_score": 38.36924005734069}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    # Initialize dataset builder\n    builder = DatasetBuilder(\n        chunk_duration=audio_params[\"chunk_duration\"],\n        random_seed=audio_params[\"random_seed\"],\n    )\n    # Add instruments\n    builder.add_instrument(\n        instrument_name=\"vocals\",\n        instrument_type=\"vocals\",\n        audio_adapter=audio_adapter,\n    )\n    builder.add_instrument(\n        instrument_name=\"mix\", instrument_type=\"mix\", audio_adapter=audio_adapter\n    )\n    # Build dataset\n    dataset = builder.build(\n        csv_path=audio_path + \"train.csv\",\n        batch_size=audio_params[\"batch_size\"],\n        n_chunks_per_song=audio_params[\"n_chunks_per_song\"],\n        random_data_augmentation=audio_params[\"random_data_augmentation\"],\n        cache_directory=audio_path + \"cache\",\n        wait_for_cache=False,\n    )\n    return dataset\n\n", "CodeBleu_score": 37.83269344963698}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if self.instrument_dataset_builders is None:\n        self.instrument_dataset_builders = [\n            InstrumentDatasetBuilder(\n                instrument=instrument,\n                instrument_dataset_builder_id=instrument.instrument_dataset_builder_id,\n                instrument_dataset_builder_type=instrument.instrument_dataset_builder_type,\n                instrument_dataset_builder_params=instrument.instrument_dataset_builder_params,\n            )\n            for instrument in self.instruments\n        ]\n    for instrument_dataset_builder in self.instrument_dataset_builders:\n        yield instrument_dataset_builder", "CodeBleu_score": 28.74190414498064}, {"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = []\n        for instrument in self.instrument_names:\n            self._instrument_builders.append(InstrumentDatasetBuilder(instrument))\n\n    for builder in self._instrument_builders:\n        yield builder", "CodeBleu_score": 60.28822298591824}, {"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = []\n        for instrument in self.instruments:\n            builder = InstrumentDatasetBuilder(self, instrument)\n            self._instrument_builders.append(builder)\n    for builder in self._instrument_builders:\n        yield builder", "CodeBleu_score": 65.53709562932993}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset", "CodeBleu_score": 93.65648279369884}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n\n    # Load the model directory using a ModelProvider\n    model_dir = ModelProvider.default().get(params[\"model\"])\n\n    # Update the parameters with the model directory\n    params[\"model_dir\"] = model_dir\n\n    # Set up the session configuration to limit GPU memory usage\n    config = ConfigProto()\n    config.gpu_options.allow_growth = True\n\n    # Create a RunConfig with this session configuration\n    run_config = RunConfig(session_config=config)\n\n    # Initialize and return a TensorFlow estimator using the specified model function, model directory, parameters, and configuration\n    return tf.estimator.Estimator(\n        model_fn=model_function,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=run_config,\n    )\n\n", "CodeBleu_score": 34.21587695324186}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default.get_model_dir(params[\"model_name\"])\n    params[\"model_dir\"] = model_dir\n    params[\"MWF\"] = MWF\n    session_config = ConfigProto()\n    session_config.gpu_options.allow_growth = True\n    session_config.gpu_options.per_process_gpu_memory_fraction = 0.6\n    run_config = RunConfig(session_config=session_config)\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=run_config,\n    )\n    return estimator", "CodeBleu_score": 47.14607340119582}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.get(params[\"model_dir\"])\n    params[\"model_dir\"] = model_dir\n    params[\"batch_size\"] = int(params[\"batch_size\"])\n    params[\"epochs\"] = int(params[\"epochs\"])\n    params[\"learning_rate\"] = float(params[\"learning_rate\"])\n    params[\"dropout_rate\"] = float(params[\"dropout_rate\"])\n    params[\"momentum\"] = float(params[\"momentum\"])\n    params[\"weight_decay\"] = float(params[\"weight_decay\"])\n    params[\"image_size\"] = int(params[\"image_size\"])\n    params[\"num_classes\"] = int(params[\"num_classes\"])\n    params[\"num_channels\"] = int(params[\"num_channels\"])\n    params[\"num_filters\"] = int(params[\"num_filters\"])\n    params[\"num_layers\"] = int(params[\"num_layers\"])\n    params[\"num_units\"] = int(params[\"num_units\"])\n    params[\"num_residual_blocks\"] = int(params[\"num_residual_blocks\"])\n    params[\"num_residual_layers\"] = int(params[\"num_residual_layers\"])\n    params[\"num_residual_units\"] = int(params[\"num_residual_units\"])\n    params[\"num_residual_filters\"] = int(params[\"num_residual_filters\"])\n    params[\"num_residual_channels\"] = int(params[\"num_residual_channels\"])\n    params[\"num_residual_layers_per_block\"] = int(params[\"num_residual_layers_per_block\"])\n    params[\"num_residual_units_per_block\"] = int(params[\"num_residual_units_per_block\"])\n    params[\"num_residual_filters_per_block\"] = int(params[\"num_residual_filters_per_block\"])\n    params[\"num_residual_channels_per_block\"] = int(params[\"num_residual_channels_per_block", "CodeBleu_score": 16.898982221625907}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    to_stereo = audio_descriptor.to_stereo\n    if to_stereo:\n        waveform = audio_descriptor.to_stereo(waveform)\n\n    self.update_data(waveform)\n    prediction = next(self._get_prediction_generator())\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 47.27812568612435}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    to_stereo = audio_descriptor.to_stereo()\n    if to_stereo:\n        waveform = audio_descriptor.to_stereo(waveform)\n    update_data(waveform, audio_descriptor)\n    prediction = next(self._get_prediction_generator())\n    prediction.pop(\"audio_id\")\n    return prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.53176689739175}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    update_data(self, {\"waveform\": waveform, \"audio_descriptor\": audio_descriptor})\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.79224525233276}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n    else:\n        assert config.BACKBONE in [\"resnet50\", \"resnet101\"], \"Backbone '{}' not supported.\".format(config.BACKBONE)\n        return {\n            \"resnet50\":  [\n                math.ceil(image_shape[0] / 4),\n                math.ceil(image_shape[1] / 4),\n                math.ceil(image_shape[0] / 16),\n                math.ceil(image_shape[1] / 16),\n            ],\n            \"resnet101\": [\n                math.ceil(image_shape[0] / 4),\n                math.ceil(image_shape[1] / 4),\n                math.ceil(image_shape[0] / 32),\n                math.ceil(image_shape[1] / 32),\n            ],\n        }[config.BACKBONE]\n\n", "CodeBleu_score": 44.71836086823685}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n\n    if config.BACKBONE == \"resnet50\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    elif config.BACKBONE == \"resnet101\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    else:\n        raise ValueError(\n            \"Backbone '{}' not supported. Only supports ResNet50 and ResNet101\".format(\n                config.BACKBONE\n            )\n        )\n\n", "CodeBleu_score": 38.6988707654111}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape, config)\n    if config.BACKBONE == \"resnet50\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    elif config.BACKBONE == \"resnet101\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] / 32), math.ceil(image_shape[1] / 32)),\n        }\n    elif config.BACKBONE == \"resnet101\":\n        return {\n            \"res2\": (math.ceil(image_shape[0] / 4), math.ceil(image_shape[1] / 4)),\n            \"res3\": (math.ceil(image_shape[0] / 8), math.ceil(image_shape[1] / 8)),\n            \"res4\": (math.ceil(image_shape[0] / 16), math.ceil(image_shape[1] / 16)),\n            \"res5\": (math.ceil(image_shape[0] /", "CodeBleu_score": 35.589129499528894}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Convert to 2d tensor\n    boxes = tf.reshape(boxes, [-1, 4])\n    window = tf.reshape(window, [1, 4])\n    boxes = tf.to_float(boxes)\n    window = tf.to_float(window)\n    # Clip coordinates\n    boxes[..., 0] = tf.maximum(tf.minimum(boxes[..., 0], window[..., 2]), window[..., 0])\n    boxes[..., 1] = tf.maximum(tf.minimum(boxes[..., 1], window[..., 3]), window[..., 1])\n    boxes[..., 2] = tf.maximum(tf.minimum(boxes[..., 2], window[..., 2]), window[..., 0])\n    boxes[..., 3] = tf.maximum(tf.minimum(boxes[..., 3], window[..., 3]), window[..., 1])\n    # Convert back to a 1d tensor\n    boxes = tf.reshape(boxes, [-1])\n    return boxes\n\n", "CodeBleu_score": 13.27611199621338}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Convert to 4D (coords, 1) representation for TF slice op\n    shape = tf.shape(boxes)\n    boxes = tf.reshape(boxes, [-1, 4])\n    window = tf.reshape(window, [1, 4])\n    boxes = tf.concat([\n        tf.maximum(boxes[:, 0:1], window[0, 0:1]),\n        tf.maximum(boxes[:, 1:2], window[0, 1:2]),\n        tf.minimum(boxes[:, 2:3], window[0, 2:3]),\n        tf.minimum(boxes[:, 3:4], window[0, 3:4])\n    ], 1)\n    return tf.reshape(boxes, shape)\n\n", "CodeBleu_score": 17.95812544210637}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Each window is [y1, x1, y2, x2]\n    # boxes is [N, (y1, x1, y2, x2)]\n    wy1, wx1, wy2, wx2 = tf.unstack(window, axis=0)\n    y1, x1, y2, x2 = tf.unstack(boxes, axis=1)\n    y1 = tf.maximum(tf.minimum(y1, wy2), wy1)\n    x1 = tf.maximum(tf.minimum(x1, wx2), wx1)\n    y2 = tf.maximum(tf.minimum(y2, wy2), wy1)\n    x2 = tf.maximum(tf.minimum(x2, wx2), wx1)\n    clipped = tf.stack([y1, x1, y2, x2], axis=1)\n    clipped.set_shape((clipped.shape[0], 4))\n    return clipped\n\n", "CodeBleu_score": 50.02132066815535}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Classification scores\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n\n    # Reshape to (batch, num_anchors, 2)\n    rpn_class_logits = tf.reshape(x, (tf.shape(x)[0], -1, 2))\n\n    # Softmax activation\n    rpn_class = KL.Activation('softmax', name='rpn_class')(rpn_class_logits)\n\n    # Bounding box refinement deltas\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n\n    # Reshape to (batch, num_anchors, 4)\n    rpn_bbox = tf.reshape(x, (tf.shape(x)[0], -1, 4))\n\n    # Scale bounding box deltas by the anchors' stride\n    rpn_bbox = rpn_bbox * anchor_stride\n\n    return rpn_class_logits, rpn_class, rpn_bbox\n\n\n\n\n", "CodeBleu_score": 50.99520357350874}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # shared convolutional layer\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # class scores\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n    rpn_class_logits = tf.reshape(x, tf.shape(x)[0:-1] + (2, anchors_per_location))\n    rpn_class_probs = KL.Activation('softmax', name='rpn_class_xxx')(rpn_class_logits)\n\n    # bounding box predictions\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n    rpn_bbox_pred = tf.reshape(x, tf.shape(x)[0:-1] + (4, anchors_per_location))\n\n    # reshape for final output\n    rpn_class_probs = tf.reshape(rpn_class_probs, (tf.shape(rpn_class_probs)[0], -1, 2))\n    rpn_bbox_pred = tf.reshape(rpn_bbox_pred, (tf.shape(rpn_bbox_pred)[0], -1, 4))\n\n    return rpn_class_logits, rpn_class_probs, rpn_bbox_pred\n\n\n\n\n", "CodeBleu_score": 51.743638230703425}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', kernel_initializer='normal', name='rpn_conv_shared')(feature_map)\n\n    # Classification scores\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_class_raw')(shared)\n    rpn_class_logits = tf.reshape(x, [-1, 2, anchors_per_location])\n    rpn_class_logits = tf.transpose(rpn_class_logits, [0, 2, 1])\n    rpn_class_probs = KL.Activation('softmax', name='rpn_class_xxx')(rpn_class_logits)\n\n    # Bounding box predictions\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', kernel_initializer='zero', name='rpn_bbox_pred')(shared)\n    rpn_bbox_pred = tf.reshape(x, [-1, 4, anchors_per_location])\n    rpn_bbox_pred = tf.transpose(rpn_bbox_pred, [0, 2, 1])\n\n    # Reshape to get the class and bbox predictions\n    rpn_class_probs = tf.reshape(rpn_class_probs, [-1, 2])\n    rpn_bbox_pred = tf.reshape(rpn_bbox_pred, [-1, 4])\n\n    # Generate proposals\n    rpn_proposals = proposals(rpn_bbox_pred, rpn_class_probs, feature_map, anchors_per_location, anchor_stride)\n\n    return [rpn_class_logits, rpn_class_probs, rpn_bbox_pred,", "CodeBleu_score": 48.46894082818597}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    absolute_difference = K.abs(y_true - y_pred)\n    squared_difference = K.square(absolute_difference)\n    loss = K.less(absolute_difference, 1.0) * 0.5 * squared_difference + (\n        K.greater_equal(absolute_difference, 1.0)\n    ) * (absolute_difference - 0.5)\n    return K.mean(loss)", "CodeBleu_score": 25.381827828396265}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    absolute_difference = K.abs(y_true - y_pred)\n    loss = K.less(absolute_difference, 1)\n    square_loss = 0.5 * K.square(absolute_difference)\n    linear_loss = absolute_difference - 0.5\n    return K.sum(K.switch(loss, square_loss, linear_loss))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.34438481386825}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    # Calculate the absolute difference between true and predicted values\n    diff = K.abs(y_true - y_pred)\n    # Create a mask for values less than one\n    less_one = K.cast(K.less(diff, 1.0), 'float32')\n    # Calculate the squared difference for small values\n    small_diff_squared = less_one * K.square(diff)\n    # Calculate the linear difference for large values\n    large_diff_linear = 1 - less_one\n    # Combine the squared and linear differences\n    loss = small_diff_squared + large_diff_linear * diff\n    # Return the mean of the loss\n    return K.mean(loss)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.0267279157985}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    # Reset the TensorFlow graph\n    tf.reset_default_graph()\n    \n    # Define the input layer\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    \n    # Define the first convolutional layer\n    conv1 = KL.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_layer)\n    \n    # Define the second convolutional layer\n    conv2 = KL.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(conv1)\n    \n    # Define the max-pooling layer\n    max_pool = KL.MaxPooling2D(pool_size=(2, 2))(conv2)\n    \n    # Flatten the output of the max-pooling layer\n    flatten = KL.Flatten()(max_pool)\n    \n    # Define the dense layer with ReLU activation\n    dense1 = KL.Dense(units=128, activation='relu')(flatten)\n    \n    # Define the output layer with softmax activation\n    output_layer = KL.Dense(units=num_classes, activation='softmax')(dense1)\n    \n    # Define the model\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n    \n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.5577689259712}, {"code": "def build_model(x_train, num_classes)\n\t\n    # Reset the TensorFlow graph\n    tf.reset_default_graph()\n\n    # Define the input layer\n    input_layer = KL.Input(shape=x_train.shape[1:])\n\n    # Define the first convolutional layer with ReLU activation\n    conv1 = KL.Conv2D(32, (3, 3), activation='relu')(input_layer)\n\n    # Define the second convolutional layer with ReLU activation\n    conv2 = KL.Conv2D(64, (3, 3), activation='relu')(conv1)\n\n    # Define the max-pooling layer\n    pool = KL.MaxPooling2D(pool_size=(2, 2))(conv2)\n\n    # Flatten the output of the max-pooling layer\n    flatten = KL.Flatten()(pool)\n\n    # Define the first dense layer with ReLU activation\n    dense1 = KL.Dense(128, activation='relu')(flatten)\n\n    # Define the second dense layer with softmax activation for classification\n    output_layer = KL.Dense(num_classes, activation='softmax')(dense1)\n\n    # Define the model\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n\n    # Compile the model\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\n    return model", "CodeBleu_score": 32.87503085085036}, {"code": "def build_model(x_train, num_classes)\n\t\n    # Reset the TensorFlow graph\n    tf.reset_default_graph()\n\n    # Define the input layer\n    input_layer = KL.Input(shape=x_train.shape[1:])\n\n    # Define the convolutional layers\n    conv_layer1 = KL.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_layer)\n    conv_layer2 = KL.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(conv_layer1)\n\n    # Define the max-pooling layer\n    max_pool_layer = KL.MaxPooling2D(pool_size=(2, 2))(conv_layer2)\n\n    # Flatten the output of the max-pooling layer\n    flatten_layer = KL.Flatten()(max_pool_layer)\n\n    # Define the dense layers\n    dense_layer1 = KL.Dense(units=128, activation='relu')(flatten_layer)\n    dense_layer2 = KL.Dense(units=num_classes, activation='softmax')(dense_layer1)\n\n    # Define the model\n    model = KM.Model(inputs=input_layer, outputs=dense_layer2)\n\n    # Compile the model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.22511336697677}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    bboxes = []\n    for i in range(mask.shape[0]):\n        h, w = np.where(mask[i])\n        if len(h) == 0:\n            bboxes.append(np.zeros((4,), dtype=np.int32))\n        else:\n            bbox = np.array([np.min(h), np.min(w), np.max(h), np.max(w)], dtype=np.int32)\n            bboxes.append(bbox)\n    return np.array(bboxes)\n\n", "CodeBleu_score": 19.87569306900036}, {"code": "def extract_bboxes(mask)\n\t\n    # Initialize an array to store bounding boxes for each mask layer\n    boxes = np.zeros([mask.shape[0], 4], dtype=np.int32)\n\n    # Loop through each mask layer\n    for i in range(mask.shape[0]):\n        # Calculate the horizontal and vertical indices where the mask is present\n        horiz_indices = np.where(np.any(mask[i], axis=0))\n        vert_indices = np.where(np.any(mask[i], axis=1))\n\n        # Determine the coordinates of the bounding box based on these indices\n        x1 = np.min(horiz_indices)\n        x2 = np.max(horiz_indices)\n        y1 = np.min(vert_indices)\n        y2 = np.max(vert_indices)\n\n        # Store the bounding box coordinates in the array\n        boxes[i] = [x1, y1, x2, y2]\n\n    # If no mask is present, set the bounding box to zeros\n    if np.max(mask) == 0:\n        boxes = np.zeros([mask.shape[0], 4], dtype=np.int32)\n\n    return boxes\n\n\n", "CodeBleu_score": 32.416842253222846}, {"code": "def extract_bboxes(mask)\n\t\n    # Initialize an array to store bounding boxes for each mask layer\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n\n    # Loop through each mask layer\n    for i in range(mask.shape[-1]):\n        # Get the mask for the current layer\n        m = mask[:, :, i]\n\n        # Get the horizontal and vertical indices where the mask is present\n        horz_inds = np.any(m, axis=0)\n        vert_inds = np.any(m, axis=1)\n\n        # Determine the coordinates of the bounding box\n        if np.any(horz_inds) and np.any(vert_inds):\n            ymin, ymax = np.where(vert_inds)[0][[0, -1]]\n            xmin, xmax = np.where(horz_inds)[0][[0, -1]]\n            boxes[i] = [xmin, ymin, xmax, ymax]\n\n    return boxes.astype(np.int32)\n\n", "CodeBleu_score": 41.309149953402006}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    # Calculate intersections\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    # Calculate unions\n    union = box_area + boxes_area[:] - intersection[:]\n    # Compute IoU\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n\n    # Calculate the intersection areas between the box and each box in the array\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n\n    # Calculate the union areas using the provided box areas and the intersection areas\n    union = box_area + boxes_area[:] - intersection[:]\n\n    # Compute the IoU values by dividing the intersection areas by the union areas\n    iou = intersection / union\n\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If either box is empty, return empty result\n    if boxes1.shape[0] == 0 or boxes2.shape[0] == 0:\n        return np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    # Compute intersections\n    ixmin = np.maximum(boxes1[:, 1], boxes2[:, 1])\n    iymin = np.maximum(boxes1[:, 0], boxes2[:, 0])\n    ixmax = np.minimum(boxes1[:, 3], boxes2[:, 3])\n    iymax = np.minimum(boxes1[:, 2], boxes2[:, 2])\n    iw = np.maximum(ixmax - ixmin, 0.)\n    ih = np.maximum(iymax - iymin, 0.)\n    inters = iw * ih\n    # Calculate the areas\n    areas1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    areas2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n    unions = areas1[:, None] + areas2 - inters\n    overlaps = inters / unions\n    return overlaps\n\n", "CodeBleu_score": 52.63268436781195}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If either box is empty, return empty result\n    if boxes1.shape[0] == 0 or boxes2.shape[0] == 0:\n        return np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    # Compute intersections\n    ixmin = np.maximum(boxes1[:, 1], boxes2[:, 1])\n    iymin = np.maximum(boxes1[:, 0], boxes2[:, 0])\n    ixmax = np.minimum(boxes1[:, 3], boxes2[:, 3])\n    iymax = np.minimum(boxes1[:, 2], boxes2[:, 2])\n    iw = np.maximum(ixmax - ixmin, 0.)\n    ih = np.maximum(iymax - iymin, 0.)\n    inters = iw * ih\n    # Calculate the areas\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n    # Compute overlaps\n    overlaps = inters / (area1[:, np.newaxis] + area2 - inters)\n    return overlaps\n\n", "CodeBleu_score": 55.776167730204854}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If either box is empty, return empty result\n    if boxes1.shape[0] == 0 or boxes2.shape[0] == 0:\n        return np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    # Compute intersections\n    ixmin = np.maximum(boxes1[:, 1], boxes2[:, 1])\n    iymin = np.maximum(boxes1[:, 0], boxes2[:, 0])\n    ixmax = np.minimum(boxes1[:, 3], boxes2[:, 3])\n    iymax = np.minimum(boxes1[:, 2], boxes2[:, 2])\n    iw = np.maximum(ixmax - ixmin + 1., 0.)\n    ih = np.maximum(iymax - iymin + 1., 0.)\n    inters = iw * ih\n    # Compute unions\n    uni = ((boxes1[:, 2] - boxes1[:, 0] + 1.) * (boxes1[:, 3] - boxes1[:, 1] + 1.) +\n           (boxes2[:, 2] - boxes2[:, 0] + 1.) * (boxes2[:, 3] - boxes2[:, 1] + 1.) -\n           inters)\n    overlaps = inters / uni\n    return overlaps\n\n", "CodeBleu_score": 41.646925716787585}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = skimage.io.imread(image_path)\n    if image.ndim != 3:\n        image = skimage.color.gray2rgb(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 83.29790966526292}, {"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id][\"path\"]\n    image = skimage.io.imread(image_path)\n    image = skimage.color.rgb2gray(image)\n    image = skimage.color.gray2rgb(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 72.39838911990343}, {"code": "def load_image(self, image_id):\n\t\n    image = Image.open(self.image_info[image_id]['path'])\n    image = image.convert('RGB')\n    image = np.array(image)\n    if image.shape[2] == 4:\n        image = image[:, :, :3]\n    return image\n\n", "CodeBleu_score": 53.39920464201523}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    rows = len(images) // cols + 1\n    plt.figure(figsize=(14, 14 * rows // cols))\n    i = 1\n    for image, title in zip(images, titles):\n        plt.subplot(rows, cols, i)\n        plt.title(title)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.axis('off')\n        i += 1\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 55.300029799490304}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    if titles is None:\n        titles = [None] * len(images)\n\n    rows = len(images) // cols + 1\n    plt.figure(figsize=(14, 14 * rows // cols))\n    i = 1\n    for image, title in zip(images, titles):\n        plt.subplot(rows, cols, i)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        if title:\n            plt.title(title, fontsize=9)\n        plt.axis('off')\n        i += 1\n\n    plt.show()\n\n", "CodeBleu_score": 70.00554701557158}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    rows = int(len(images) / cols)\n    for i, image in enumerate(images):\n        plt.subplot(rows, cols, i + 1)\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        if titles:\n            plt.title(titles[i])\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.556252269520044}]}
