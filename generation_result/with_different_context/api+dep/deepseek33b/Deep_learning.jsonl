{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.model_cache is not None:\n        if os.path.exists(self.model_cache):\n            try:\n                self.model = torch.load(self.model_cache, map_location=\"cpu\")\n                self.model.eval()\n                if half_attention:\n                    self.model.half()\n                self.model.to(self.device, memory_format=torch.channels_last)\n                print(\"Loaded model from cache.\")\n                return {\"state_dict\": self.model.state_dict()}\n            except Exception as e:\n                print(f\"Error loading model from cache: {e}\")\n\n    if self.model_path is not None:\n        if self.model_path.endswith(\".safetensors\"):\n            with safe_open(self.model_path, framework=\"pt\") as f:\n                self.model = f.state_dict()\n        else:\n            self.model = torch.load(self.model_path, map_location=\"cpu\")\n\n        self.model.eval()\n        if half_attention:\n            self.model.half()\n        self.model.to(self.device, memory_format=torch.channels_last)\n\n        if self.model_cache is not None:\n            try:\n                torch.save(self.model, self.model_cache)\n            except Exception as e:\n                print(f\"Error caching model: {e}\")\n\n    if self.model_config is not None:\n        config = OmegaConf.load(self.model_config)\n        self.model = instantiate_from_config(config.model)\n        self.model.load_state_dict(load_file(self.model_path, model_dir=self.model_dir))\n        self.model.eval()\n        if half_attention:\n            self.model.half()\n        self.model.to(self.device, memory_format=torch.channels_last)\n\n    return {\"state_dict\": self.model.state_dict()}\n\n", "CodeBleu_score": 36.1390901020548}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.model_path is not None:\n        if self.model_path.startswith(\"http\"):\n            if self.model_path.endswith(\".safetensors\"):\n                from safetensors.torch import load_file\n\n                model_state = load_file(self.model_path, device=\"cpu\")\n            else:\n                model_state = torch.load(self.model_path, map_location=\"cpu\")\n        else:\n            if self.model_path.endswith(\".safetensors\"):\n                from safetensors.torch import load_file\n\n                model_state = load_file(self.model_path, device=\"cpu\")\n            else:\n                model_state = torch.load(self.model_path, map_location=\"cpu\")\n    else:\n        if self.config_path.endswith(\".yaml\"):\n            config = OmegaConf.load(self.config_path)\n        else:\n            config = OmegaConf.load(self.config_path + \".yaml\")\n        if config.model.target == \"ldm.models.diffusion.ddpm.LatentDiffusion\":\n            model_state = instantiate_from_config(config.model)\n        else:\n            model_state = instantiate_from_config(config.model)\n            model_state.load_state_dict(config.model.state_dict)\n    model_state = model_state.half() if half_attention else model_state\n    model_state.eval()\n    model_state = model_state.to(self.device)\n    if self.cache_path is not None:\n        if self.cache_path.endswith(\".safetensors\"):\n            from safetensors.torch import save_file\n\n            save_file(model_state.state_dict(), self.cache_path)\n        else:\n            torch.save(model_state.state_dict(), self.cache_path)\n    return {\"model\": model_state}\n\n", "CodeBleu_score": 37.74244153162861}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    model_path = self.model_path\n    config_path = self.config_path\n\n    if model_path is None:\n        raise ValueError(\"model_path is None\")\n    if config_path is None:\n        raise ValueError(\"config_path is None\")\n\n    if not os.path.exists(model_path):\n        raise ValueError(f\"model_path does not exist: {model_path}\")\n    if not os.path.exists(config_path):\n        raise ValueError(f\"config_path does not exist: {config_path}\")\n\n    model_name = os.path.splitext(os.path.basename(model_path))[0]\n    cache_path = os.path.join(self.cache_dir, f\"{model_name}.pt\")\n\n    if os.path.exists(cache_path):\n        cache_time = os.path.getmtime(cache_path)\n        model_time = os.path.getmtime(model_path)\n        if cache_time > model_time:\n            print(f\"Loading model from cache: {cache_path}\")\n            model = torch.load(cache_path)\n            return {\"model\": model}\n\n    print(f\"Loading model from {model_path}\")\n    if model_path.endswith(\".safetensors\"):\n        from safetensors.torch import load_file\n\n        pl_sd = load_file(model_path, device=\"cpu\")\n    else:\n        pl_sd = torch.load(model_path, map_location=\"cpu\")\n    if \"global_step\" in pl_sd:\n        print(f\"Global Step: {pl_sd['global_step']}\")\n    sd = pl_sd[\"state_dict\"]\n    model = instantiate_from_config(OmegaConf.load(config_path))\n    m, u = model.load_state_dict(sd, strict=False)\n    if len(m) > 0:\n        print(\"missing keys:\")\n        print(m)\n    if len(u) > 0:\n        print(\"unexpected", "CodeBleu_score": 42.49288344849461}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    ddim = DDIMSampler(model)\n    bs = shape[0]\n    print(f\"Beginning sampling with eta {eta} and {steps} steps\")\n    samples, intermediates = ddim.sample(steps, batch_size=bs, shape=shape,\n                                         conditioning=cond, eta=eta, callback=callback,\n                                         normals_sequence=normals_sequence, mask=mask, x0=x0,\n                                         quantize_x0=quantize_x0, temperature=temperature,\n                                         score_corrector=score_corrector, corrector_kwargs=corrector_kwargs,\n                                         x_t=x_t)\n    return samples, intermediates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 66.37522788115012}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    # Make sure the shapes tuples are consistent.\n    shape, cond = (shape, cond)\n    sampler = DDIMSampler(model)\n    bs = shape[0]\n    print(f'Data shape: {shape}')\n    print(f'Minibatch size: {bs}')\n    print(f'Steps: {steps}')\n    print(f'Eta: {eta}')\n    samples, intermediates = sampler.sample(steps, bs, shape, cond, eta, callback=callback,\n                                             normals_sequence=normals_sequence, mask=mask, x0=x0,\n                                             quantize_x0=quantize_x0, temperature=temperature,\n                                             score_corrector=score_corrector, corrector_kwargs=corrector_kwargs,\n                                             x_t=x_t)\n    return samples, intermediates\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.862585113900856}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    ddim = DDIMSampler(model)\n    bs = shape[0]\n    print(f\"Beginning sampling with eta {eta} and {steps} steps\")\n    return ddim.sample(steps, bs, shape,\n                       conditioning=cond,\n                       eta=eta,\n                       callback=callback,\n                       normals_sequence=normals_sequence,\n                       mask=mask,\n                       x0=x0,\n                       quantize_x0=quantize_x0,\n                       temperature=temperature,\n                       score_corrector=score_corrector,\n                       corrector_kwargs=corrector_kwargs,\n                       x_t=x_t)\n\n", "CodeBleu_score": 47.60282022166377}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_weights is None:\n        self.ema_weights = self.parameters\n    else:\n        if context is not None:\n            print(f\"{context} - Switching to EMA weights\")\n        for ema_w, model_w in zip(self.ema_weights, self.parameters):\n            ema_w.copy_(model_w.data)\n\n    yield\n\n    if self.ema_weights is not None:\n        if context is not None:\n            print(f\"{context} - Restoring model weights\")\n        for ema_w, model_w in zip(self.ema_weights, self.parameters):\n            if ema_w.requires_grad:\n                model_w.copy_(ema_w.data)", "CodeBleu_score": 50.1146953906335}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.store()\n        self.copy_to()\n        if context:\n            print(f\"{context}: Switched to EMA weights - {self.ema_decay}\")\n    yield\n    if self.ema_enabled:\n        self.restore()\n        if context:\n            print(f\"{context}: Restored original weights\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.18394736172055}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_weights is None:\n        return\n    if self.ema_weights.is_initialized:\n        if context is not None:\n            print(f\"{context} - Switching to EMA weights\")\n        self.ema_weights.swap_weights()\n        yield\n        if context is not None:\n            print(f\"{context} - Restoring original weights\")\n        self.ema_weights.swap_weights()\n    else:\n        yield\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.4470005207986}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    if len(sd.keys()) == 0:\n        sd = {k: v for k, v in sd.items() if k[0] != \".\"}\n    if ignore_keys is not None:\n        sd = {k: v for k, v in sd.items() if k not in ignore_keys}\n    self.load_state_dict(sd)\n    print(\"Loaded state_dict from [{}]\".format(path))\n    if len(ignore_keys) > 0:\n        print(\"*** WARNING: LOADING STATE DICT WITH IGNORE KEYS ***\")\n        print(\"Keys: {}\".format(ignore_keys))\n    missing_keys, unexpected_keys = self.load_state_dict(sd, strict=False)\n    if len(missing_keys) > 0:\n        print(\"Keys missing in the checkpoint: {}\".format(missing_keys))\n    if len(unexpected_keys) > 0:\n        print(\"Keys in the checkpoint but not in the model: {}\".format(unexpected_keys))", "CodeBleu_score": 37.56460952167557}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    if ignore_keys is None:\n        ignore_keys = []\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    keys = list(sd.keys())\n    for k in keys:\n        for ik in ignore_keys:\n            if k.startswith(ik):\n                print(\"Deleting key {} from state_dict.\".format(k))\n                del sd[k]\n    missing_keys, unexpected_keys = self.load_state_dict(sd, strict=False)\n    print(\"missing_keys: {}\".format(missing_keys))\n    print(\"unexpected_keys: {}\".format(unexpected_keys))\n    if len(missing_keys) > 0:\n        print(\"Weights of {} not initialized from pretrained model: {}\".format(type(self).__name__, missing_keys))\n    if len(unexpected_keys) > 0:\n        print(\"Weights from pretrained model not used in {}: {}\".format(type(self).__name__, unexpected_keys))\n\n", "CodeBleu_score": 60.866186555390776}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    sd = torch.load(path, map_location=\"cpu\")[\"state_dict\"]\n    if len(sd.keys()) == 0:\n        sd = {k: v for k, v in sd.items() if k[0] != \".\"}\n        sd = {k[1:]: v for k, v in sd.items() if k[0] == \".\"}\n    if ignore_keys is not None:\n        ignore_keys = ignore_keys + [\".mask_token\"]\n        for k in ignore_keys:\n            sd.pop(k, None)\n    self.load_state_dict(sd, strict=False)\n    print(f\"Loaded state_dict from [{path}]\")\n    return self\n\n", "CodeBleu_score": 30.252922811900557}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, emb_loss, info, torch.argmax(dec, dim=1)\n    return dec, emb_loss, info\n\n\n\n", "CodeBleu_score": 39.80633072480277}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, diff, _ = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, diff, torch.argmax(quant, dim=1)\n    return dec, diff\n\n\n", "CodeBleu_score": 50.2573765675113}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, emb_loss, info, torch.argmax(dec, dim=1)\n    return dec, emb_loss, info\n\n", "CodeBleu_score": 39.80633072480277}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    x = batch[self.key]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    elif len(x.shape) == 2:\n        x = x.unsqueeze(-1).unsqueeze(-1)\n\n    # permute to NCHW\n    x = x.permute(0, 3, 1, 2)\n\n    # adjust for downsampling\n    if self.downsample_f > 1:\n        x = F.interpolate(x, scale_factor=self.downsample_f, mode=\"bicubic\")\n\n    # adjust for batch size\n    if self.batch_size_f > 1:\n        # adjust number of channels\n        n_ch = round(np.clip(self.batch_size_f, 0, 1) * x.shape[1])\n        if isinstance(self.batch_size_f, int):\n            n_ch = self.batch_size_f\n        x = x[:, :n_ch]\n\n        # adjust spatial size\n        s = round(np.clip(self.batch_size_f, 0, 1) * x.shape[2])\n        if isinstance(self.batch_size_f, int):\n            s = self.batch_size_f\n        s = min(s, x.shape[2])\n        if s > 0:\n            x = F.interpolate(x, (s, s), mode=\"bicubic\")\n\n    # adjust for timesteps\n    if self.timesteps_f > 1:\n        # adjust number of timesteps\n        n_t = round(np.clip(self.timesteps_f, 0, 1) * x.shape[0])\n        if isinstance(self.timesteps_f, int):\n            n_t = self.timesteps_f\n        x = x[:n_t]\n\n        # adjust spatial size\n        s = round(np.clip(self.timesteps_f, 0, 1) * x.shape[2])\n        if isinstance(self.timesteps", "CodeBleu_score": 43.7571205323747}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[self.key]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    elif len(x.shape) == 2:\n        x = x.unsqueeze(-1).unsqueeze(-1)\n\n    # permute to NCHW\n    x = x.permute(0, 3, 1, 2)\n\n    # adjust for lower-res views\n    if self.batch_resizing:\n        training_step_ratio = min(self.step / self.max_steps, 1)\n        tmp_res = int(\n            np.round(\n                self.res\n                * (self.res_range[0] + training_step_ratio * (self.res_range[1] - self.res_range[0]))\n            )\n        )\n        x = F.interpolate(x, (tmp_res, tmp_res), mode=\"bicubic\", align_corners=False)\n\n    x = x.contiguous().float()\n\n    return x\n\n", "CodeBleu_score": 49.08996588859408}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[self.key]\n    if len(x.shape) == 3:\n        x = x[..., None]\n    elif len(x.shape) == 2:\n        x = x.unsqueeze(-1).unsqueeze(-1)\n\n    # permute to NCHW\n    x = x.permute(0, 3, 1, 2)\n\n    # adjust for resizing\n    if self.resize_enabled:\n        input_lowres = F.interpolate(x, self.shape, mode=\"bicubic\", align_corners=False)\n        shape = [x.shape[0], 3, x.shape[2], x.shape[3]]\n        noise = torch.randn(*shape, device=x.device)\n        t = (\n            np.arange(self.num_train_steps + 1)\n            / self.num_train_steps\n            * (self.train_step / (self.num_train_steps - 1) * 2)\n        )\n        t = torch.tensor(t, device=x.device).float()\n        t = t.unsqueeze(0).unsqueeze(-1).unsqueeze(-1).unsqueeze(-1)\n        noise = noise * t.sqrt()\n        x = torch.cat([noise, input_lowres], dim=1)\n    else:\n        x = x.contiguous().float()\n\n    return x.detach()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.1682570467952}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, self.image_key)\n    xrec, qloss = self.get_input_tuple(self.autoencoder, x)\n    if optimizer_idx == 0:\n        # autoencode\n        aeloss, log_dict_ae = self.ae_loss(x, xrec, qloss)\n        self.log_dict(log_dict_ae)\n        return aeloss\n    if optimizer_idx == 1:\n        # update discriminator\n        dis_loss = self.loss(x, xrec, qloss, dis_weight=self.discriminator_weight,\n                             conditional=self.conditional, split_mode=self.split_mode)\n        return dis_loss\n\n", "CodeBleu_score": 30.76231617105374}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, self.image_key)\n    xrec, qloss = self.forward(x, return_preds=True)\n    aeloss, log_dict_ae = self.loss(qloss, x, xrec, optimizer_idx, self.global_step,\n                                    last_layer=self.get_last_layer(), split=\"train\")\n\n    if optimizer_idx == 0:\n        # autoencode\n        logs = {\"loss\": aeloss}\n        logs.update(log_dict_ae)\n        self.log(\"train/total_loss\", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n        return logs\n\n    if optimizer_idx == 1:\n        # discriminator\n        dis_loss, log_dict_dis = self.loss(qloss, x, xrec, optimizer_idx, self.global_step,\n                                            last_layer=self.get_last_layer(), split=\"train\")\n        logs = {\"disc_loss\": dis_loss}\n        logs.update(log_dict_dis)\n        return logs\n\n    if optimizer_idx == 2:\n        # predictor\n        predictor_loss, log_dict_predictor = self.loss(qloss, x, xrec, optimizer_idx, self.global_step,\n                                                      last_layer=self.get_last_layer(), split=\"train\")\n        logs = {\"predictor_loss\": predictor_loss}\n        logs.update(log_dict_predictor)\n        return logs\n\n", "CodeBleu_score": 54.47319295883724}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t\n    x = self.get_input(batch, self.image_key)\n    xrec, posterior = self.p_sample_loop(x)\n    if optimizer_idx == 0:\n        # autoencode\n        aeloss, log_dict_ae = self.ae_loss(x, xrec, posterior)\n        self.log(\"aeloss\", aeloss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n        return aeloss\n    if optimizer_idx == 1:\n        # update discriminator\n        dis_loss = self.loss(x, xrec, posterior, optimizer_idx, self.global_step,\n                             last_layer=self.get_last_layer(), split=\"train\")\n        self.log(\"dis_loss\", dis_loss, prog_bar=True, logger=True, on_step=True, on_epoch=True)\n        return dis_loss\n\n", "CodeBleu_score": 48.73293086020433}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    inputs = self.get_input(batch, self.image_key).to(self.device)\n    reconstructions = self.ema_scope(self.ema_model)(inputs)\n    if only_inputs:\n        images = [wandb.Image(self.postprocess(inputs))]\n    else:\n        images = [wandb.Image(self.postprocess(inputs)), wandb.Image(self.postprocess(reconstructions))]\n    if plot_ema and self.ema_model is not None:\n        with self.ema_scope(self.ema_model):\n            ema_reconstructions = self.ema_model(inputs)\n            images.append(wandb.Image(self.postprocess(ema_reconstructions)))\n    if self.image_key == \"segmentation\":\n        images = [self.to_rgb(x) for x in images]\n    return wandb.log({\"images\": images}, **kwargs)\n\n", "CodeBleu_score": 33.0255669420808}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    if self.ema_scope is not None:\n        with self.ema_scope:\n            self.model.eval()\n            with torch.no_grad():\n                if only_inputs:\n                    x = self.get_input(batch, self.image_key)\n                    xrec, _ = self.model.encode_to_model(x)\n                else:\n                    x, xrec = self.get_input_pairs(batch, self.image_key)\n                if self.model.cond_stage_key == \"segmentation\":\n                    xrec = self.to_rgb(xrec)\n                if plot_ema:\n                    xrec_ema, _ = self.model.encode_to_model(x)\n                    if self.model.cond_stage_key == \"segmentation\":\n                        xrec_ema = self.to_rgb(xrec_ema)\n                if only_inputs:\n                    return x, xrec\n                else:\n                    return x, xrec, xrec_ema\n    else:\n        self.model.eval()\n        with torch.no_grad():\n            if only_inputs:\n                x = self.get_input(batch, self.image_key)\n                xrec, _ = self.model.encode_to_model(x)\n            else:\n                x, xrec = self.get_input_pairs(batch, self.image_key)\n            if self.model.cond_stage_key == \"segmentation\":\n                xrec = self.to_rgb(xrec)\n            if only_inputs:\n                return x, xrec\n            else:\n                return x, xrec, None\n\n", "CodeBleu_score": 34.61761926096918}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t\n    x = self.get_input(batch, self.image_key)\n    if only_inputs:\n        return x\n    if x.shape[1] > 3:\n        x = self.to_rgb(x)\n    with self.ema_scope():\n        recon = self(x)\n        if x.shape[1] > 3:\n            recon = self.to_rgb(recon)\n        if plot_ema:\n            with self.ema_scope(0.5):\n                recon_ema = self(x)\n                if x.shape[1] > 3:\n                    recon_ema = self.to_rgb(recon_ema)\n    images = torch.stack([x, recon, recon_ema], dim=1).flatten(0,1)\n    grid = make_grid(images, nrow=x.shape[0])\n    self.log_image(key=\"samples\", images=[grid], caption=[f\"steps: {self.global_step}\"], **kwargs)\n    return grid\n\n", "CodeBleu_score": 48.44352898761727}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('Loss type {} is not recognized.'.format(self.loss_type))\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.99764152796587}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('loss type [%s] is not found' % self.loss_type)\n    return loss\n\n\n", "CodeBleu_score": 55.82990729915077}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    else:\n        raise NotImplementedError('Loss type {} is not recognized.'.format(self.loss_type))\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.99764152796587}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, c, *spatial = x.shape\n    x = x.to(memory_format=torch.contiguous_format)  # more efficient for the forward pass\n    t = torch.randint(0, self.num_timesteps, (b,), device=x.device).long()\n\n    if self.cond_stage_model is not None:\n        c = self.get_learned_conditioning(c)\n        x = self.cond_stage_model(x, c, t)\n\n    if self.use_timesteps:\n        x = self.time_embed(timesteps=t, embedding_dim=self.time_embed_dim)(x)\n\n    if self.use_class_cond:\n        assert c is not None\n        x = x + self.class_embed(c)\n\n    if self.use_scale_shift_norm:\n        out = self.out(self.norm_out(x))\n    else:\n        out = self.out(x)\n\n    if self.output_scale != 1:\n        out = out * self.output_scale\n\n    return out\n\n", "CodeBleu_score": 50.39136108584502}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, *_, device = *x.shape, x.device\n    t = torch.randint(0, self.num_timesteps, (b,), device=device).long()\n\n    if self.cond_stage_trainable:\n        c = self.get_learned_conditioning(c)\n\n    if self.cond_stage_model is not None:\n        c = self.cond_stage_model(c)\n\n    if self.cond_stage_key == 'text':\n        x, c = self.maybe_adjust_for_cond_stage(x, c)\n\n    if self.cond_stage_key == 'image':\n        c, x = self.maybe_adjust_for_cond_stage(c, x)\n\n    if self.cond_stage_key == 'hybrid':\n        c, x = self.maybe_adjust_for_cond_stage(c, x)\n\n    if self.cond_stage_key == 'audio':\n        c, x = self.maybe_adjust_for_cond_stage(c, x)\n\n    return self.p_losses(x, t, c)\n\n", "CodeBleu_score": 44.05860484219251}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    b, c, *spatial = x.shape\n    x = x.to(memory_format=torch.contiguous_format)\n\n    if self.cond_stage_model is not None:\n        c = self.get_learned_conditioning(c)\n\n    if self.use_timesteps:\n        t = torch.randint(0, self.num_timesteps, (b,), device=x.device).long()\n    else:\n        t = None\n\n    return self.p_losses(x, t, *args, **kwargs)\n\n\n", "CodeBleu_score": 42.20830677015673}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape spec [batch, height, width, channel]\n    if self.remap_used is not None:\n        indices = self.unmap_to_used(indices)\n    if self.permuter is not None:\n        indices = self.permuter(indices)\n    bhwc = [indices.shape[0], *shape]\n    indices = indices.reshape(-1)\n    z = self.embedding(indices)\n    z = z.view(bhwc)\n    z = z.permute(0, 3, 1, 2).contiguous()\n    return z\n\n\n", "CodeBleu_score": 60.819868711333555}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape spec [batch, height, width, channel]\n    if self.remap_used is not None:\n        indices = self.unmap_to_used(indices)\n    if self.permuter is not None:\n        indices = self.permuter(indices)\n    bhwc = [indices.shape[0], *shape]\n    # print(\"bhwc: \", bhwc)\n    # print(\"indices: \", indices.shape)\n    # print(\"indices: \", indices)\n    # print(\"self.embedding: \", self.embedding.shape)\n    # print(\"self.embedding: \", self.embedding)\n    # print(\"self.embedding.view: \", self.embedding.view([self.used.shape[0], -1]).shape)\n    # print(\"self.embedding.view: \", self.embedding.view([self.used.shape[0], -1]))\n    # print(\"indices.view: \", indices.view([-1]).shape)\n    # print(\"indices.view: \", indices.view([-1]))\n    # print(\"self.embedding.view(self.used.shape[0], -1).index_select(1, indices.view([-1])): \", self.embedding.view([self.used.shape[0], -1]).index_select(1, indices.view([-1])))\n    # print(\"self.embedding.view(self.used.shape[0], -1).index_select(1, indices.view([-1])).shape: \", self.embedding.view([self.used.shape[0], -1]).index_select(1, indices.view([-1])).shape)\n    # print(\"self.embedding.view(self.used.shape[0], -1).index_select(1, indices.view([-1])).view(bhwc): \", self.embedding.view([self.used.shape[0], -1]).index_select(1, indices.view([-1])).view(bhwc))\n    # print(\"self.embedding.view(self.used.shape[0], -1", "CodeBleu_score": 34.05663732543667}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # shape spec [batch, height, width, channel]\n    if self.remap_used is not None:\n        indices = self.unmap_to_used(indices)\n    if self.remap_to_used is not None:\n        indices = self.map_to_used(indices)\n    # get quantized latent vectors\n    z_q = self.embedding(indices)\n\n    if shape is not None:\n        z_q = z_q.view(shape)\n        # reshape back to match original input shape\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n    return z_q\n\n\n", "CodeBleu_score": 65.58823755530308}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        m = int(dimension**0.5)\n        while dimension % m != 0 and m > 1:\n            m -= 1\n        n = dimension // m\n        while n > factor > 0:\n            m += 1\n            n -= 1\n        return m, n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.407073338284306}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        if factor > 0:\n            print(f\"Factor {factor} does not divide {dimension}\")\n        m = dimension\n        n = 1\n        for i in range(1, dimension):\n            if dimension % i == 0:\n                if i <= dimension // i:\n                    m = i\n                    n = dimension // i\n                else:\n                    break\n        if factor > 0:\n            if m > factor:\n                m = factor\n                n = dimension // m\n        return m, n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.2855692032288}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n\n    if factor > 0 and dimension % factor == 0:\n        return factor, dimension // factor\n    else:\n        if factor > 0:\n            print(f\"Warning: The factor {factor} does not divide the dimension {dimension}.\")\n        m = dimension\n        n = 1\n        min_sum = m + n\n        for i in range(2, int(dimension**0.5) + 1):\n            if dimension % i == 0:\n                j = dimension // i\n                if i <= j and (factor <= 0 or i <= factor) and (factor <= 0 or j <= factor):\n                    if i + j < min_sum:\n                        min_sum = i + j\n                        m = i\n                        n = j\n        return m, n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.490257699592874}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown = updown.to(orig_weight.device)\n    orig_weight = orig_weight.to(updown.device)\n    transpose = updown.transpose(0, 1)\n    to = transpose.to(orig_weight.device)\n    reshape = to.reshape(-1, to.shape[-1])\n    merged_scale1 = reshape * self.scale1\n    norm = torch.norm(merged_scale1, dim=-1)\n    to = norm.to(orig_weight.device)\n    reshape = to.reshape(reshape.shape[0], reshape.shape[1])\n    merged_scale1 = reshape.to(updown.device)\n    norm = merged_scale1 / torch.norm(merged_scale1, dim=-1, keepdim=True)\n    to = norm.to(orig_weight.device)\n    reshape = to.reshape(reshape.shape[0], reshape.shape[1])\n    merged_scale1 = reshape.to(updown.device)\n    norm = merged_scale1 * self.scale2\n    to = norm.to(orig_weight.device)\n    reshape = to.reshape(transpose.shape[0], transpose.shape[1])\n    merged_scale1 = reshape.to(updown.device)\n    norm = merged_scale1.transpose(0, 1)\n    to = norm.to(orig_weight.device)\n    reshape = to.reshape(orig_weight.shape[0], orig_weight.shape[1])\n    merged_scale1 = reshape.to(updown.device)\n    norm = merged_scale1 - orig_weight\n    return norm", "CodeBleu_score": 42.842579323970945}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    # Check if the input weight and original weight are on the same device\n    if updown.device != orig_weight.device:\n        # If not, move the input weight to the same device as the original weight\n        updown = updown.to(orig_weight.device)\n    # Check if the input weight and original weight have the same data type\n    if updown.dtype != orig_weight.dtype:\n        # If not, cast the input weight to the same data type as the original weight\n        updown = updown.to(orig_weight.dtype)\n    # Transpose the input weight\n    updown = updown.transpose(0, 1)\n    # Reshape the input weight\n    updown = updown.reshape(updown.shape[0], -1)\n    # Transpose the original weight\n    orig_weight = orig_weight.transpose(0, 1)\n    # Reshape the original weight\n    orig_weight = orig_weight.reshape(orig_weight.shape[0], -1)\n    # Merge the input weight and original weight\n    merged_scale1 = torch.cat([orig_weight, updown], dim=0)\n    # Normalize the merged weight\n    merged_scale1 = merged_scale1 / torch.norm(merged_scale1, dim=1, keepdim=True)\n    # Scale the merged weight\n    merged_scale1 = merged_scale1 * self.scale\n    # Subtract the original weight from the scaled merged weight\n    final = merged_scale1 - orig_weight\n    # Return the final adjusted weight\n    return final\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.852583345255916}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    if updown.device != orig_weight.device:\n        updown = updown.to(orig_weight.device)\n    if orig_weight.device != self.scale1.device:\n        orig_weight = orig_weight.to(self.scale1.device)\n    if updown.dtype != orig_weight.dtype:\n        updown = updown.to(orig_weight.dtype)\n    if orig_weight.dtype != self.scale1.dtype:\n        orig_weight = orig_weight.to(self.scale1.dtype)\n    updown = updown.transpose(1, 0)\n    orig_weight = orig_weight.transpose(1, 0)\n    updown = updown.reshape(updown.shape[0], -1)\n    orig_weight = orig_weight.reshape(orig_weight.shape[0], -1)\n    merged_scale1 = self.scale1.transpose(1, 0).reshape(self.scale1.shape[0], -1)\n    norm = torch.norm(merged_scale1, dim=1)\n    norm = norm.reshape(norm.shape[0], 1)\n    merged_scale1 = merged_scale1 / norm\n    merged_scale1 = merged_scale1.transpose(1, 0)\n    merged_scale1 = merged_scale1.reshape(merged_scale1.shape[0], self.scale1.shape[1], self.scale1.shape[2], self.scale1.shape[3])\n    merged_scale1 = merged_scale1.transpose(1, 0)\n    norm = norm.transpose(1, 0)\n    norm = norm.reshape(norm.shape[0], 1)\n    merged_weight = torch.matmul(updown, merged_scale1)\n    merged_weight = merged_weight / norm\n    merged_weight = merged_weight.transpose(1, 0)\n    merged_weight = merged_weight.reshape(merged_weight.shape[0], self.scale1.shape[1], self.scale", "CodeBleu_score": 40.7479606164965}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    updown = updown + ex_bias\n    updown = updown.reshape(output_shape)\n    if updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if ex_bias is not None:\n        ex_bias = ex_bias * self.multiplier\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n    return updown, ex_bias\n\n", "CodeBleu_score": 46.38679992685118}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    if ex_bias is not None:\n        updown = updown + ex_bias\n    updown = updown.reshape(output_shape)\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if self.additional_bias is not None:\n        self.additional_bias = self.additional_bias * self.multiplier()\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n    return updown, self.additional_bias", "CodeBleu_score": 50.408571627868795}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t\n    updown = updown + ex_bias\n    updown = updown.reshape(output_shape)\n\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n\n    if ex_bias is not None:\n        ex_bias = ex_bias * self.multiplier\n\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown, ex_bias\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.43856098997228}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n    updown = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    if self.bias is not None:\n        ex_bias = self.bias.to(orig_weight.device, dtype=orig_weight.dtype)\n    else:\n        ex_bias = None\n    output_shape = self.output_shape\n    updown, ex_bias = self.finalize_updown(updown, orig_weight, output_shape, ex_bias)\n    return updown, ex_bias\n\n", "CodeBleu_score": 51.038453304249465}, {"code": "def calc_updown(self, orig_weight)\n\t\n    curr_weight = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    curr_bias = self.bias.to(orig_weight.device, dtype=orig_weight.dtype) if self.bias is not None else None\n    updown, ex_bias = self.finalize_updown(curr_weight, orig_weight, curr_weight.shape, curr_bias)\n    return updown, ex_bias\n\n", "CodeBleu_score": 37.351627847088}, {"code": "def calc_updown(self, orig_weight)\n\t\n    updown = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    ex_bias = self.bias.to(orig_weight.device, dtype=orig_weight.dtype) if self.bias is not None else None\n    output_shape = self.output_shape\n    return self.finalize_updown(updown, orig_weight, output_shape, ex_bias)\n\n", "CodeBleu_score": 42.646039364814676}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    # Get the number of networks in memory\n    networks_in_memory = torch.cuda.memory_allocated() / 1024**2\n\n    # Calculate the number of networks to remove\n    num_networks_to_remove = networks_in_memory - MAX_NETWORKS_IN_MEMORY\n\n    # Remove networks from memory until the count is within the limit\n    for _ in range(num_networks_to_remove):\n        if len(networks_in_memory) > 0:\n            next(iter(networks_in_memory.values())).cpu()\n            networks_in_memory.popitem()\n\n    # Trigger garbage collection to free up memory\n    torch.cuda.empty_cache()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.684038396396176}, {"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = []\n    max_networks_in_memory = 10\n\n    while len(networks_in_memory) > max_networks_in_memory:\n        networks_in_memory.pop()\n        torch.cuda.empty_cache()\n\n", "CodeBleu_score": 37.90482031425036}, {"code": "def purge_networks_from_memory()\n\t\n    networks_in_memory = []\n    torch.cuda.empty_cache()\n    while True:\n        if len(networks_in_memory) > MAX_NETWORKS_IN_MEMORY:\n            networks_in_memory.pop(0)\n            torch.cuda.empty_cache()\n        else:\n            break\n\n", "CodeBleu_score": 28.835191936602577}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, '_backup_weights'):\n        self.weight = copy_(self._backup_weights)\n    if hasattr(self, '_backup_bias'):\n        self.bias = copy_(self._backup_bias)\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, '_backup_proj_weights'):\n            self.out_proj.weight = copy_(self._backup_proj_weights)\n        if hasattr(self, '_backup_proj_bias'):\n            self.out_proj.bias = copy_(self._backup_proj_bias)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.345360185738585}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 12.326435246995993}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, \"weight_backup\"):\n        self.weight = self.weight_backup\n        del self.weight_backup\n    if hasattr(self, \"bias_backup\"):\n        self.bias = self.bias_backup\n        del self.bias_backup\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, \"proj_weight_backup\"):\n            self.proj_weight = self.proj_weight_backup\n            del self.proj_weight_backup\n        if hasattr(self, \"proj_bias_backup\"):\n            self.proj_bias = self.proj_bias_backup\n            del self.proj_bias_backup\n\n", "CodeBleu_score": 32.60433130794998}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(networks) == 0:\n        return original_forward(input)\n\n    devices.cond_cast_unet(input)\n\n    for network in networks:\n        if network.is_in_sd_module(org_module):\n            input = network.forward(input)\n\n    return input\n\n", "CodeBleu_score": 18.859176610905397}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if not hasattr(org_module, \"network_weights_backup\"):\n        return original_forward(input)\n    if org_module.network_weights_backup is None:\n        return original_forward(input)\n    input = input.to(devices.device)\n    org_module.network_restore_weights_from_backup()\n    output = original_forward(input)\n    for net in networks.networks:\n        if net.name == org_module.network_current_names:\n            output = net(output)\n    return output\n\n", "CodeBleu_score": 33.36539939696341}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if len(networks) == 0:\n        return original_forward(input)\n\n    devices.cond_cast_unet(input)\n    for network in networks:\n        if network.module_name == org_module.name:\n            network.network_restore_weights_from_backup()\n            network.network_reset_cached_weight()\n\n    result = original_forward(input)\n    for network in networks:\n        if network.module_name == org_module.name:\n            result = network.original_forward(result, input)\n    return result\n\n", "CodeBleu_score": 33.79248494700684}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n    trainable_params = []\n    for name, param in self.named_parameters():\n        if param.requires_grad:\n            if \"weight\" in name:\n                trainable_params.append(param)\n    return trainable_params\n\n", "CodeBleu_score": 25.512584975147863}, {"code": "def trainables(self)\n\t\n    trainable_params = []\n    for name, param in self.named_parameters():\n        if param.requires_grad:\n            trainable_params.append(name)\n    return trainable_params", "CodeBleu_score": 24.56611578065764}, {"code": "def trainables(self)\n\t\n    trainable_params = []\n    for name, param in self.named_parameters():\n        if param.requires_grad:\n            if isinstance(param, torch.nn.Linear) or isinstance(param, torch.nn.LayerNorm):\n                trainable_params.append((name, param))\n    return trainable_params\n\n", "CodeBleu_score": 28.25758726628964}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    clear()\n\n    for i, name in enumerate(names):\n        hypernetwork = load_hypernetwork(name)\n\n        if hypernetwork is None:\n            continue\n\n        if multipliers is not None:\n            hypernetwork.set_multiplier(multipliers[i])\n\n        already_loaded.append(hypernetwork)\n\n    return already_loaded\n\n", "CodeBleu_score": 31.333150266421107}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    clear()\n    for name in names:\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            if multipliers is not None:\n                hypernetwork.set_multiplier(multipliers[name])\n            already_loaded.append(hypernetwork)\n    shared.hypernetworks_loaded.extend(already_loaded)\n\n", "CodeBleu_score": 18.42488333143829}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    already_loaded = []\n    clear()\n    for name, multiplier in zip(names, multipliers or []):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            hypernetwork.set_multiplier(multiplier)\n            already_loaded.append(hypernetwork)\n    for hypernetwork in already_loaded:\n        append(hypernetwork)\n\n", "CodeBleu_score": 25.14482283070737}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer=layer)\n    return context_k, context_v\n\n\n", "CodeBleu_score": 65.82264135585403}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer=layer)\n    return context_k, context_v\n\n", "CodeBleu_score": 65.82264135585403}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer=layer)\n\n    return context_k, context_v\n\n", "CodeBleu_score": 65.82264135585403}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if self.use_scalenorm:\n        x = self.norm(x)\n    if self.use_scalenorm:\n        context = self.norm(context)\n    b, c, h, w = x.shape\n    q = self.to_q(x)\n    context_k, context_v = apply_hypernetworks(self.hypernetworks, context)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q, k, v = map(lambda t: rearrange(t, 'b d n -> b n d'), (q, k, v))\n    q = q * self.scale\n    sim = einsum('b i d, b j d -> b i j', q, k)\n    if exists(self.sim_scale):\n        sim = sim * self.sim_scale\n    if exists(mask):\n        mask = rearrange(mask, 'b j -> b 1 j')\n        max_neg_value = -torch.finfo(sim.dtype).max\n        mask = repeat(mask, 'b j -> (b h) () j', h=self.heads)\n        sim = sim.masked_fill_(~mask, max_neg_value)\n    if self.use_flash_attention:\n        sim = sim.to(memory_format=torch.channels_last)\n        attn = sim.softmax(dim=-1).to(memory_format=torch.contiguous_format)\n    else:\n        attn = sim.softmax(dim=-1)\n    out = einsum('b i j, b j d -> b i d', attn, v)\n    out = rearrange(out, 'b n d -> b d n')\n    out = self.to_out(out)\n    return out\n\n", "CodeBleu_score": 58.949696237760165}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    q = self.to_q(x)\n    context = default(context, x)\n    k = self.to_k(context) * self.scale\n    v = self.to_v(context)\n    context_k, context_v = apply_hypernetworks(self.hypernetworks, context, layer=self)\n    k = k + context_k\n    v = v + context_v\n    q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h=self.heads), (q, k, v))\n    sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n    if exists(mask):\n        mask = repeat(mask, 'b j -> (b h) () j', h=self.heads)\n        sim = sim.masked_fill_(~mask, -torch.finfo(sim.dtype).max)\n\n    attn = sim.softmax(dim=-1)\n    out = einsum('b i j, b j d -> b i d', attn, v)\n    out = rearrange(out, '(b h) n d -> b n (h d)', h=self.heads)\n    return self.to_out(out)\n\n", "CodeBleu_score": 66.08445586679524}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    self.to_q = self.to_q(x)\n    self.to_k = self.to_k(context) if context is not None else self.to_k(x)\n    self.to_v = self.to_v(context) if context is not None else self.to_v(x)\n    b, t, e = self.to_q.shape\n    c, h = self.to_k.shape\n    q = self.to_q.reshape(b, t, self.heads, e // self.heads).permute(0, 2, 1, 3)\n    k = self.to_k.reshape(c, h, self.heads, e // self.heads).permute(0, 2, 3, 1)\n    v = self.to_v.reshape(c, h, self.heads, e // self.heads).permute(0, 2, 1, 3)\n    q = q * (e ** (-0.5))\n    context_k, context_v = apply_hypernetworks(self.hypernetworks, context)\n    context_k = context_k.reshape(c, h, self.heads, e // self.heads).permute(0, 2, 3, 1)\n    context_v = context_v.reshape(c, h, self.heads, e // self.heads).permute(0, 2, 1, 3)\n    k = torch.cat((k, context_k), dim=-1)\n    v = torch.cat((v, context_v), dim=-1)\n    dots = einsum(\"b h i d, b h j d -> b h i j\", q, k)\n    if mask is not None:\n        dots.masked_fill_(mask, -torch.finfo(dots.dtype).max)\n    attn = dots.softmax(dim=-1)\n    out = einsum(\"b h i j, b h j d -> b h i d\", attn, v)\n    out = out", "CodeBleu_score": 30.658299173408977}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    try:\n        old_hypernetwork_name = hypernetwork.name\n        old_filename = hypernetwork.filename\n        old_sd_checkpoint_name = hypernetwork.sd_checkpoint_name\n        old_sd_checkpoint = hypernetwork.sd_checkpoint\n        old_activate_output = hypernetwork.activate_output\n        old_use_dropout = hypernetwork.use_dropout\n        old_dropout_structure = hypernetwork.dropout_structure\n        old_last_layer_dropout = hypernetwork.last_layer_dropout\n        old_optional_info = hypernetwork.optional_info\n\n        hypernetwork.name = hypernetwork_name\n        hypernetwork.filename = filename\n        hypernetwork.sd_checkpoint_name = checkpoint.sd_model_checkpoint\n        hypernetwork.sd_checkpoint = checkpoint.sd_model\n        hypernetwork.activate_output = checkpoint.activate_output\n        hypernetwork.use_dropout = checkpoint.use_dropout\n        hypernetwork.dropout_structure = checkpoint.dropout_structure\n        hypernetwork.last_layer_dropout = checkpoint.last_layer_dropout\n        hypernetwork.optional_info = checkpoint.optional_info\n\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.name = old_hypernetwork_name\n        hypernetwork.filename = old_filename\n        hypernetwork.sd_checkpoint_name = old_sd_checkpoint_name\n        hypernetwork.sd_checkpoint = old_sd_checkpoint\n        hypernetwork.activate_output = old_activate_output\n        hypernetwork.use_dropout = old_use_dropout\n        hypernetwork.dropout_structure = old_dropout_structure\n        hypernetwork.last_layer_dropout = old_last_layer_dropout\n        hypernetwork.optional_info = old_optional_info\n        raise e\n\n", "CodeBleu_score": 41.58295007181578}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    if hypernetwork is None:\n        return\n\n    old_checkpoint = hypernetwork.checkpoint\n    old_name = hypernetwork.name\n    old_filename = hypernetwork.filename\n    old_layers = hypernetwork.layers\n    old_step = hypernetwork.step\n    old_sd_checkpoint = hypernetwork.sd_checkpoint\n    old_sd_checkpoint_name = hypernetwork.sd_checkpoint_name\n    old_activation_func = hypernetwork.activation_func\n    old_add_layer_norm = hypernetwork.add_layer_norm\n    old_weight_init = hypernetwork.weight_init\n    old_activate_output = hypernetwork.activate_output\n    old_use_dropout = hypernetwork.use_dropout\n    old_dropout_structure = hypernetwork.dropout_structure\n    old_last_layer_dropout = hypernetwork.last_layer_dropout\n    old_optional_info = hypernetwork.optional_info\n\n    try:\n        hypernetwork.checkpoint = checkpoint\n        hypernetwork.name = hypernetwork_name\n        hypernetwork.filename = filename\n        hypernetwork.layers = {}\n        hypernetwork.step = 0\n        hypernetwork.sd_checkpoint = None\n        hypernetwork.sd_checkpoint_name = None\n        hypernetwork.activation_func = None\n        hypernetwork.add_layer_norm = False\n        hypernetwork.weight_init = None\n        hypernetwork.activate_output = False\n        hypernetwork.use_dropout = False\n        hypernetwork.dropout_structure = None\n        hypernetwork.last_layer_dropout = False\n        hypernetwork.optional_info = None\n\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.checkpoint = old_checkpoint\n        hypernetwork.name = old_name\n        hypernetwork.filename = old_filename\n        hypernetwork.layers = old_layers\n        hypernetwork.step = old_step\n        hypernetwork.sd_checkpoint = old_sd_checkpoint\n        hypernetwork.sd_checkpoint_name = old_sd_checkpoint_name\n        hypernetwork.activation_func = old_activation", "CodeBleu_score": 35.80581336281507}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    if hypernetwork is None:\n        return\n\n    if shared.opts.save_optimizer_state:\n        optimizer_state_dict = hypernetwork.optimizer_state_dict\n    else:\n        optimizer_state_dict = None\n\n    original_name = hypernetwork.name\n    original_step = hypernetwork.step\n    original_checkpoint_info = hypernetwork.checkpoint_info\n    original_layer_structure = hypernetwork.layer_structure\n    original_activation_func = hypernetwork.activation_func\n    original_add_layer_norm = hypernetwork.add_layer_norm\n    original_weight_init = hypernetwork.weight_init\n    original_sd_checkpoint = hypernetwork.sd_checkpoint\n    original_sd_checkpoint_name = hypernetwork.sd_checkpoint_name\n    original_activate_output = hypernetwork.activate_output\n    original_use_dropout = hypernetwork.use_dropout\n    original_dropout_structure = hypernetwork.dropout_structure\n    original_last_layer_dropout = hypernetwork.last_layer_dropout\n    original_optional_info = hypernetwork.optional_info\n\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.step = checkpoint['step']\n    hypernetwork.checkpoint_info = checkpoint['checkpoint_info']\n    hypernetwork.layer_structure = checkpoint['layer_structure']\n    hypernetwork.activation_func = checkpoint['activation_func']\n    hypernetwork.add_layer_norm = checkpoint['add_layer_norm']\n    hypernetwork.weight_init = checkpoint['weight_init']\n    hypernetwork.sd_checkpoint = checkpoint['sd_checkpoint']\n    hypernetwork.sd_checkpoint_name = checkpoint['sd_checkpoint_name']\n    hypernetwork.activate_output = checkpoint['activate_output']\n    hypernetwork.use_dropout = checkpoint['use_dropout']\n    hypernetwork.dropout_structure = checkpoint['dropout_structure']\n    hypernetwork.last_layer_dropout = checkpoint['last_layer_dropout']\n    hypernetwork.optional_info =", "CodeBleu_score": 30.963702180238457}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = {}\n    if self.ema_weights is None:\n        return\n    if \"ema_scope_context\" in context:\n        return\n    context[\"ema_scope_context\"] = True\n    old_params = self.state_dict()\n    self.load_state_dict(self.ema_weights)\n    if self.ema_log_weights:\n        print(\"Using EMA weights\")\n    yield\n    self.load_state_dict(old_params)\n    if self.ema_log_weights:\n        print(\"Restored original weights\")", "CodeBleu_score": 30.78814831540546}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = {}\n    if self.ema_enabled:\n        if \"ema_weights\" not in context:\n            context[\"ema_weights\"] = self.get_parameters()\n        self.set_parameters(self.ema_weights)\n        if self.ema_log:\n            print(\"Switching to EMA weights\")\n    yield\n    if self.ema_enabled:\n        self.set_parameters(context[\"ema_weights\"])\n        if self.ema_log:\n            print(\"Restoring original weights\")\n\n\n", "CodeBleu_score": 37.498981217890645}, {"code": "def ema_scope(self, context=None)\n\t\n    # Get the current weights\n    original_weights = self.parameters()\n\n    # Copy EMA weights to the model\n    self.copy_to(self.ema_scope(context))\n\n    # Log the action if specified\n    if self.ema_scope(context):\n        print(f\"Switching to EMA weights for {context}.\")\n\n    # Execute the code block\n    yield\n\n    # Restore the original weights\n    self.load_state_dict(original_weights)\n\n    # Log the restoration if specified\n    if self.ema_scope(context):\n        print(f\"Restored original weights for {context}.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.0015458706415}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    if x.shape[1] == self.ch:\n        x_recon = self.predict_start_from_noise(x, t=t, noise=self.model(x, t))\n    else:\n        x_recon = self.predict_start_from_noise(x, t=t, noise=self.model(x, t)[:, :3])\n\n    if clip_denoised:\n        x_recon.clamp_(-1., 1.)\n\n    model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n    return model_mean, posterior_variance, posterior_log_variance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 64.57191668593097}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    # Get model output\n    model_output = self.model(x, t)\n\n    # Reconstruct input from model output\n    if self.model_var_type in ['learned', 'learned_range']:\n        x_recon = self.predict_start_from_noise(x, t=t, noise=model_output)\n    else:\n        x_recon = self.predict_start_from_noise(x, t=t, noise=torch.zeros_like(x))\n\n    # Clip input if specified\n    if clip_denoised:\n        x_recon.clamp_(-1., 1.)\n\n    # Calculate model mean and posterior variance\n    model_mean, posterior_variance, posterior_log_variance = self.q_posterior(x_start=x_recon, x_t=x, t=t)\n\n    return model_mean, posterior_variance, posterior_log_variance\n\n\n", "CodeBleu_score": 65.5943934245782}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    model_output = self.model(x, t)\n    if self.model_var_type in [ModelVarType.LEARNED, ModelVarType.LEARNED_RANGE]:\n        B, C = x.shape[:2]\n        assert model_output.shape == (B, C * 2, *x.shape[2:])\n        model_output, model_var_values = torch.split(model_output, C, dim=1)\n        if self.model_var_type == ModelVarType.LEARNED:\n            model_log_variance = model_var_values\n            model_variance = torch.exp(model_log_variance)\n        else:\n            min_log = _extract_into_tensor(self.posterior_log_variance_clipped, t, x.shape)\n            max_log = _extract_into_tensor(np.log(self.betas), t, x.shape)\n            # The model_var_values is [-1, 1]\n            frac = (model_var_values + 1) / 2\n            model_log_variance = frac * max_log + (1 - frac) * min_log\n            model_variance = torch.exp(model_log_variance)\n    else:\n        model_variance, model_log_variance = {\n            # for fixedlarge, we set the initial (log-)variance like so to get a better decoder log likelihood.\n            ModelVarType.FIXED_LARGE: (\n                np.append(self.posterior_variance[1], self.posterior_variance[1:]),\n                np.append(self.posterior_log_variance_clipped[1], self.posterior_log_variance_clipped[1:]),\n            ),\n            ModelVarType.FIXED_SMALL: (\n                self.posterior_variance,\n                self.posterior_log_variance_clipped,\n            ),\n        }[self.model_var_type]\n        model_variance = extract_into_tensor(model_variance, t, x.shape)\n        model", "CodeBleu_score": 29.124523930862168}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.048577405959875}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError('loss type [%s] is not found' % self.loss_type)\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.697585323888276}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='none')\n        if mean:\n            loss = loss.mean()\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='none')\n        if not mean:\n            loss = loss.sum()\n    else:\n        raise NotImplementedError(self.loss_type)\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.86968263770287}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    prior_kl = normal_kl(mean, log_variance, self.prior_mean, self.prior_log_variance)\n    prior_kl = prior_kl / math.log(2.0)\n    return torch.mean(prior_kl)\n\n", "CodeBleu_score": 48.65706636226553}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    return normal_kl(mean, log_variance) / np.log(2.0)\n\n", "CodeBleu_score": 40.03755979624126}, {"code": "def _prior_bpd(self, x_start)\n\t\n    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_timesteps - 1] * batch_size, device=x_start.device)\n    mean, _, log_variance = self.q_mean_variance(x_start, t)\n    prior_kl = normal_kl(mean, log_variance, self.prior_mean, self.prior_log_variance)\n    prior_kl = prior_kl / np.log(2.0)\n    return torch.mean(prior_kl)\n\n", "CodeBleu_score": 49.287658315211566}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"cache\")\n    cache_path = os.path.join(cache_dir, subsection)\n    cache = diskcache.Cache(cache_path, size_limit=4 * 1024 * 1024 * 1024, minimum_file_size=256 * 1024)\n    return cache\n\n", "CodeBleu_score": 50.736604405085586}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_path = os.path.join(CACHE_DIR, subsection)\n    cache = diskcache.Cache(cache_path, size_limit=4 * 1024 ** 3)\n    cache.settings[\"sqlite_min_file_size\"] = 256 * 1024\n    return cache\n\n", "CodeBleu_score": 48.95634206933705}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(\n        path=os.path.join(\n            os.path.expanduser(\"~\"),\n            \".cache\",\n            \"jupyter-cache\",\n            \"jupyter-cache\",\n            subsection,\n        ),\n        size_limit=4 * 1024 * 1024 * 1024,\n        sqlite_min_file_size=256 * 1024,\n    )\n\n", "CodeBleu_score": 54.732535707292925}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    cache_obj = caches.get(subsection)\n    if cache_obj is None:\n        with cache_lock:\n            if not os.path.exists(cache_dir):\n                os.makedirs(cache_dir)\n            if not isfile(cache_filename):\n                convert_old_cached_data()\n\n            cache_obj = caches.get(subsection)\n            if cache_obj is None:\n                cache_obj = make_cache(subsection)\n                caches[subsection] = cache_obj\n\n    return cache_obj\n\n", "CodeBleu_score": 65.03435690001642}, {"code": "def cache(subsection)\n\t\n    cache_obj = caches.get(subsection)\n    if cache_obj is not None:\n        return cache_obj\n\n    with cache_lock:\n        cache_obj = caches.get(subsection)\n        if cache_obj is not None:\n            return cache_obj\n\n        if not os.path.isdir(cache_dir):\n            os.mkdir(cache_dir)\n\n        if not isfile(cache_filename):\n            convert_old_cached_data()\n\n        cache_obj = caches.get(subsection)\n        if cache_obj is None:\n            cache_obj = make_cache(subsection)\n            caches[subsection] = cache_obj\n\n        return cache_obj\n\n", "CodeBleu_score": 61.77251844731347}, {"code": "def cache(subsection)\n\t\n    cache_obj = caches.get(subsection)\n    if cache_obj is not None:\n        return cache_obj\n\n    with cache_lock:\n        cache_obj = caches.get(subsection)\n        if cache_obj is not None:\n            return cache_obj\n\n        if not os.path.isdir(cache_dir):\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if not isfile(cache_filename):\n            convert_old_cached_data()\n\n        cache_obj = caches.get(subsection)\n        if cache_obj is None:\n            cache_obj = make_cache(subsection)\n            caches[subsection] = cache_obj\n\n        return cache_obj\n\n", "CodeBleu_score": 59.97189469776348}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n    cache_obj = cache(subsection)\n    mtime = getmtime(filename)\n    entry = cache_obj.get(title)\n    if entry:\n        cached_mtime = entry.get(\"mtime\")\n        if mtime > cached_mtime:\n            cache_obj.invalidate(title)\n            entry = None\n\n    if not entry:\n        data = func()\n        entry = {\"data\": data, \"mtime\": mtime}\n        cache_obj.set(title, entry)\n        dump_cache()\n\n    return entry[\"data\"]\n\n", "CodeBleu_score": 42.03060373749224}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    entry = cache_obj.get(title)\n    if entry:\n        if mtime > entry.get(\"mtime\", 0):\n            cache_obj.delete(title)\n            entry = None\n    if not entry:\n        entry = func()\n        entry[\"mtime\"] = mtime\n        cache_obj.set(title, entry)\n        dump_cache()\n    return entry\n\n", "CodeBleu_score": 34.821574550622586}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    entry = cache_obj.get(title)\n    if entry:\n        cached_mtime = entry.get(\"mtime\", 0)\n        if mtime > cached_mtime:\n            cache_obj.invalidate(title)\n            entry = None\n\n    if not entry:\n        data = func()\n        entry = {\"mtime\": mtime, \"data\": data}\n        cache_obj.set(title, entry)\n        dump_cache()\n\n    return entry[\"data\"]\n\n", "CodeBleu_score": 47.64706486914353}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n\n    for line in message.splitlines():\n        print(f\"*** {line}\", file=sys.stderr)\n\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"), file=sys.stderr)\n        print(\"---\", file=sys.stderr)\n\n", "CodeBleu_score": 70.73041784590174}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n\n    for line in message.splitlines():\n        print(\"***\", line)\n\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"))\n        print(\"---\")\n\n", "CodeBleu_score": 50.57568606908429}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n\n    record_exception()\n\n    for line in message.splitlines():\n        print(f\"*** {line}\", file=sys.stderr)\n\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"), file=sys.stderr)\n        print(\"---\", file=sys.stderr)\n\n", "CodeBleu_score": 70.73041784590174}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if not style.prompt and not style.negative_prompt:\n        return False, prompt, negative_prompt\n\n    extracted_positive = False\n    extracted_negative = False\n\n    if style.prompt:\n        extracted_positive, prompt = extract_style_text_from_prompt(style.prompt, prompt)\n\n    if style.negative_prompt:\n        extracted_negative, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not extracted_positive or not extracted_negative:\n        return False, prompt, negative_prompt\n\n    return True, prompt, negative_prompt\n\n", "CodeBleu_score": 70.73710244802945}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == '' and style.negative_prompt == '':\n        return False, prompt, negative_prompt\n\n    extracted_positive = False\n    extracted_negative = False\n\n    if style.prompt != '':\n        extracted_positive, prompt = extract_style_text_from_prompt(style.prompt, prompt)\n\n    if style.negative_prompt != '':\n        extracted_negative, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not extracted_positive or not extracted_negative:\n        return False, prompt, negative_prompt\n\n    return True, prompt, negative_prompt\n\n", "CodeBleu_score": 65.85519160915467}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if not style.prompt and not style.negative_prompt:\n        return False, prompt, negative_prompt\n\n    extracted_positive = False\n    extracted_negative = False\n\n    if style.prompt:\n        extracted_positive, prompt = extract_style_text_from_prompt(style.prompt, prompt)\n\n    if style.negative_prompt:\n        extracted_negative, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not extracted_positive or not extracted_negative:\n        return False, prompt, negative_prompt\n\n    return True, prompt, negative_prompt\n\n", "CodeBleu_score": 70.73710244802945}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n\n", "CodeBleu_score": 4.226190476190476}, {"code": "def random_partial(self, count, n_frames)\n\t\n\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 4.226190476190476}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (dBFS_change < 0) and increase_only:\n        return wav\n    if (dBFS_change > 0) and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n", "CodeBleu_score": 84.8381782725433}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    wav = wav.astype(np.float32)\n    rms = np.sqrt(np.mean(wav ** 2))\n    wave_dBFS = 20 * np.log10(rms)\n    dBFS_change = target_dBFS - wave_dBFS\n    if dBFS_change < 0 and increase_only or dBFS_change > 0 and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 69.45748438117528}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"Both increase only and decrease only are set\")\n    dBFS_change = target_dBFS - 10 * np.log10(np.mean(wav ** 2))\n    if (dBFS_change < 0) and increase_only:\n        return wav\n    if (dBFS_change > 0) and decrease_only:\n        return wav\n    return wav * (10 ** (dBFS_change / 20))\n\n\n\n\n", "CodeBleu_score": 84.8381782725433}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n", "CodeBleu_score": 79.69439499666903}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n", "CodeBleu_score": 78.14487612654162}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n\n    if device is None:\n        _device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    elif isinstance(device, str):\n        _device = torch.device(device)\n    else:\n        _device = device\n\n    _model = SpeakerEncoder(_device, torch.device(\"cpu\"))\n    checkpoint = torch.load(weights_fpath, map_location=\"cpu\")\n    _model.load_state_dict(checkpoint[\"model_state\"])\n    _model.eval()\n    print(\"Loaded encoder \\\"%s\\\" trained to step %d\" % (weights_fpath, checkpoint[\"step\"]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 78.14487612654162}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model was not loaded.\")\n    \n    frames = torch.from_numpy(frames_batch).to(_device)\n    embeds = _model.forward(frames).detach().cpu().numpy()\n    \n    return embeds", "CodeBleu_score": 78.34812081832051}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model was not loaded. Call load_model() before inference.\")\n\n    frames = torch.from_numpy(frames_batch).to(_device)\n    embed = _model.forward(frames).detach().cpu().numpy()\n\n    return embed\n\n\n", "CodeBleu_score": 95.0256034169634}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"Model was not loaded.\")\n    \n    frames = torch.from_numpy(frames_batch).to(_device)\n    embed = _model.forward(frames).detach().cpu().numpy()\n    \n    return embed\n\n", "CodeBleu_score": 83.27192644053888}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    # Compute the slices\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    # Evaluate whether extra padding is warranted or not\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 97.67006232562707}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n\n\n\n\n", "CodeBleu_score": 97.67006232562707}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 < overlap < 1\n    assert 0 < min_pad_coverage < 1\n    samples_per_frame = int((sampling_rate * mel_window_step / 1000))\n    n_frames = int(np.ceil((n_samples + 1) / samples_per_frame))\n    frame_step = max(int(np.round(partial_utterance_n_frames * (1 - overlap))), 1)\n    wav_slices, mel_slices = [], []\n    steps = max(1, n_frames - partial_utterance_n_frames + frame_step + 1)\n    for i in range(0, steps, frame_step):\n        mel_range = np.array([i, i + partial_utterance_n_frames])\n        wav_range = mel_range * samples_per_frame\n        mel_slices.append(slice(*mel_range))\n        wav_slices.append(slice(*wav_range))\n    last_wav_range = wav_slices[-1]\n    coverage = (n_samples - last_wav_range.start) / (last_wav_range.stop - last_wav_range.start)\n    if coverage < min_pad_coverage and len(mel_slices) > 1:\n        mel_slices = mel_slices[:-1]\n        wav_slices = wav_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 97.67006232562707}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        shape = (height, -1)\n    embed = embed.reshape(shape)\n    cmap = cm.ScalarMappable(cmap=\"bwr\")\n    cmap.set_clim(color_range[0], color_range[1])\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    ax.imshow(embed, cmap=cmap.cmap)\n    plt.colorbar(cmap)\n\n\n", "CodeBleu_score": 56.85197803535237}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        shape = (height, -1)\n\n    embed = embed.reshape(shape)\n\n    cmap = cm.get_cmap()\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(im, ax=ax)\n\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n\n    sm = cm.ScalarMappable(cmap=cmap)\n    sm.set_clim(color_range[0], color_range[1])\n\n", "CodeBleu_score": 66.30437067213425}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n\n    if shape is None:\n        height = int(np.sqrt(embed.shape[0]))\n        embed = embed.reshape(height, -1)\n\n    cmap = cm.get_cmap()\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(im, ax=ax)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    sm = cm.ScalarMappable(cmap=cmap)\n    sm.set_clim(color_range[0], color_range[1])\n\n", "CodeBleu_score": 59.37315687070631}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    num_speakers_per_batch, num_utts_per_speaker = embeds.shape[:2]\n    # embeds: (num_speakers_per_batch, num_utts_per_speaker, embedding_size)\n    # centroids_incl: (num_speakers_per_batch, 1, embedding_size)\n    centroids_incl = torch.mean(embeds, dim=1, keepdim=True)\n    centroids_incl = centroids_incl / (torch.norm(centroids_incl, 2, 2, True))\n    # centroids_excl: (num_speakers_per_batch, num_utts_per_speaker, embedding_size)\n    centroids_excl = torch.sum(embeds, dim=1, keepdim=True) - embeds\n    centroids_excl /= (num_utts_per_speaker - 1)\n    centroids_excl = centroids_excl / (torch.norm(centroids_excl, 2, 2, True))\n    # sim_matrix: (num_speakers_per_batch, num_utts_per_speaker, num_utts_per_speaker)\n    # mask_matrix: (num_speakers_per_batch, num_utts_per_speaker, num_utts_per_speaker)\n    sim_matrix = torch.zeros(num_speakers_per_batch, num_utts_per_speaker, num_utts_per_speaker).to(embeds.device)\n    mask_matrix = 1 - torch.eye(num_utts_per_speaker).unsqueeze(0).expand(num_speakers_per_batch, -1, -1).to(embeds.device)\n    for j in range(num_speakers_per_batch):\n        mask = mask_matrix[j].view((num_utts_per_speaker * num_utts_per_speaker, 1))\n        mask = mask.expand((num_utts_per_speaker", "CodeBleu_score": 41.27762311551324}, {"code": "def similarity_matrix(self, embeds)\n\t\n\n    speakers_per_batch, utterances_per_speaker = embeds.shape\n    embeds_flat = embeds.view(speakers_per_batch * utterances_per_speaker, -1)\n    centroids_incl = torch.mean(embeds, dim=1, keepdim=True)\n    centroids_excl = torch.mean(embeds[(torch.arange(speakers_per_batch), torch.arange(utterances_per_speaker))], dim=1, keepdim=True)\n    centroids_incl = centroids_incl / (torch.norm(centroids_incl, dim=2, keepdim=True) + 1e-5)\n    centroids_excl = centroids_excl / (torch.norm(centroids_excl, dim=2, keepdim=True) + 1e-5)\n    sim_matrix = torch.zeros(speakers_per_batch, utterances_per_speaker, speakers_per_batch).to(embeds.device)\n    mask_matrix = 1 - torch.eye(speakers_per_batch, dtype=torch.bool, device=embeds.device)\n    mask_matrix = mask_matrix.repeat(1, utterances_per_speaker)\n    mask_matrix = mask_matrix.view(speakers_per_batch, utterances_per_speaker, speakers_per_batch)\n    sim_matrix[mask_matrix] = torch.sum(embeds_flat * centroids_incl, dim=2)\n    sim_matrix = sim_matrix * self.similarity_weight + self.similarity_bias\n    return sim_matrix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.90251316163353}, {"code": "def similarity_matrix(self, embeds)\n\t\n    # Get the number of speakers in batch, n_utterances per speaker\n    n_speakers = self.n_speakers\n    n_utterances = self.n_utterances\n\n    # Get the centroids (mu) and the centroids without self-utterance\n    centroids_incl = torch.mean(embeds, 1, keepdim=True)\n    centroids_excl = torch.mean(embeds, 1, keepdim=True)\n    centroids_excl = centroids_excl.clone().view(embeds.shape[0], 1, embeds.shape[2]).repeat(1, embeds.shape[1], 1)\n    centroids_excl = torch.sum(embeds, dim=1, keepdim=True) - centroids_excl\n    centroids_excl = centroids_excl / (embeds.shape[1] - 1)\n\n    # Equalize the temperature of denominator\n    centroids_incl = centroids_incl / torch.norm(centroids_incl, dim=2, keepdim=True)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=2, keepdim=True)\n\n    # Calculate similarities\n    # sim_matrix = torch.zeros([speakers_per_batch, utterances_per_speaker, speakers_per_batch]).to(self.loss_device)\n    sim_matrix = torch.zeros([n_speakers, n_utterances, n_speakers]).to(self.loss_device)\n    # loop through every possible speaker\n    for i in range(n_speakers):\n        # Calculate the cosine similarity\n        centroids_incl_i = centroids_incl[i].expand(n_utterances, -1)\n        centroids_excl_i = centroids_excl[i].expand(n_utterances, -1)\n        embeds_i = embeds[i]\n        # Shape (n_utterances, n_speakers)", "CodeBleu_score": 22.475794464250658}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n\n    # Similarity matrix. The columns correspond to utterances of a speaker and the rows are\n    # the speaker embeddings.\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((speakers_per_batch * utterances_per_speaker,\n                                     speakers_per_batch))\n\n    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    ground_truth = torch.from_numpy(ground_truth).long().to(self.loss_device)\n\n    loss = self.loss_fn(sim_matrix, ground_truth)\n\n    with torch.no_grad():\n        # EER\n        inv_argmax = lambda i: np.eye(1, speakers_per_batch, i, dtype=np.int)[0]\n        labels = np.array([inv_argmax(i) for i in ground_truth])\n        preds = sim_matrix.detach().cpu().numpy()\n\n        # Snippet from https://yangcha.github.io/EER-ROC/\n        fpr, tpr, thresholds = roc_curve(labels.flatten(), preds.flatten())\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n\n    return loss, eer\n\n", "CodeBleu_score": 84.66948127008673}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n\n    # Similarity matrix. The columns correspond to utterances of a speaker and the rows are\n    # the speaker embeddings.\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((speakers_per_batch * utterances_per_speaker,\n                                     speakers_per_batch))\n\n    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    ground_truth = torch.from_numpy(ground_truth).long().to(self.loss_device)\n\n    # Compute the loss\n    loss = self.loss_fn(sim_matrix, ground_truth)\n\n    # EER\n    with torch.no_grad():\n        inv_argmax = lambda i: np.eye(1, speakers_per_batch, i, dtype=np.int)[0]\n        labels = inv_argmax(ground_truth)\n\n        # Snippet from https://yangcha.github.io/EER-ROC/\n        fpr, tpr, thresholds = roc_curve(labels.flatten(), sim_matrix.flatten())\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n\n    return loss, eer\n\n", "CodeBleu_score": 72.30604807640006}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n\n    # Similarity matrix\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape((speakers_per_batch * utterances_per_speaker,\n                                     speakers_per_batch))\n\n    # Ground truth\n    ground_truth = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    ground_truth = torch.from_numpy(ground_truth).long().to(self.loss_device)\n\n    # Calculating loss\n    loss = self.loss_fn(sim_matrix, ground_truth)\n\n    # EER\n    with torch.no_grad():\n        inv_argmax = lambda i: np.eye(1, speakers_per_batch, i, dtype=np.int)[0]\n        labels = inv_argmax(ground_truth)\n\n        # Snippet from https://yangcha.github.io/EER-ROC/\n        fpr, tpr, thresholds = roc_curve(labels.flatten(), sim_matrix.flatten())\n        eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n\n    return loss, eer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 72.30604807640006}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    import yaml\n    from IPython.display import display\n    from yaml import Loader\n\n    # Import parameter configurations\n    with open(self.config_path, \"r\") as file:\n        params = yaml.load(file, Loader=Loader)\n\n    # Initialize an empty string for model and data parameters\n    model_params = \"\"\n    data_params = \"\"\n\n    # Iterate through model parameters\n    for key, value in self.model.named_parameters():\n        model_params += f\"{key}: {value.shape}", "CodeBleu_score": 15.241693365884496}, {"code": "def log_params(self)\n\t\n    param_str = \"\"\n    for attr in dir(self):\n        if not attr.startswith(\"__\"):\n            value = getattr(self, attr)\n            param_str += f\"{attr}: {value}", "CodeBleu_score": 13.418908432954677}, {"code": "def log_params(self)\n\t\n    import importlib\n    import torch\n    import numpy as np\n    import torch.nn as nn\n    import torch.nn.functional as F\n    import torch.optim as optim\n    import torch.utils.data as data\n    import torchvision.transforms as transforms\n    import torchvision.datasets as datasets\n    import torchvision.models as models\n    import torchvision.utils as utils\n    import torchvision.ops as ops\n    import torchvision.io as io\n    import torchvision.transforms.functional as TF\n    import torchvision.models.detection as detection\n    import torchvision.models.segmentation as segmentation\n    import torchvision.models.video as video\n    import torchvision.models.optical_flow as optical_flow\n    import torchvision.models.quantization as quantization\n    import torchvision.models.mobilenet as mobilenet\n    import torchvision.models.shufflenetv2 as shufflenetv2\n    import torchvision.models.squeezenet as squeezenet\n    import torchvision.models.detection.faster_rcnn as faster_rcnn\n    import torchvision.models.detection.backbone_utils as backbone_utils\n    import torchvision.models.detection.retinanet as retinanet\n    import torchvision.models.detection.ssd as ssd\n    import torchvision.models.detection.transform as transform\n    import torchvision.models.detection.mask_rcnn as mask_rcnn\n    import torchvision.models.detection.keypoint_rcnn as keypoint_rcnn\n    import torchvision.models.detection.generalized_rcnn as generalized_rcnn\n    import torchvision.models.detection.rpn as rpn\n    import torchvision.models.detection.faster_rcnn as faster_rcnn\n    import torchvision.models.detection.retinanet as retinanet\n    import torchvision.models.detection.ssd as ssd\n    import", "CodeBleu_score": 9.436394403142835}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if not self.config.visdom:\n        return\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n\n    embeds = np.array(embeds).reshape(len(embeds), -1)\n    n_speakers = len(embeds)\n    utterances_per_speaker = np.array([len(u) for u in utterances_per_speaker])\n    utterances_per_speaker = utterances_per_speaker / np.sum(utterances_per_speaker)\n    colors = [plt.cm.Spectral(i / float(n_speakers)) for i in range(n_speakers)]\n\n    z = reducer.fit_transform(embeds)\n    plt.figure(figsize=(7, 7))\n    plt.scatter(z[:, 0], z[:, 1], marker=\"o\", s=120, c=colors, alpha=0.5)\n    area = np.pi * (15 * np.array(utterances_per_speaker)) ** 2\n    plt.scatter(z[:, 0], z[:, 1], marker=\"o\", s=area, c=colors, alpha=0.5)\n\n    for i, speaker in enumerate(self.data_loader.dataset.speakers):\n        plt.annotate(speaker, xy=(z[i, 0], z[i, 1]))\n    if not self.config.visdom:\n        plt.savefig(os.path.join(self.config.output_path, \"umap.pdf\"))\n        plt.clf()\n    else:\n        self.vis.matplot(plt, win=\"umap\")\n\n    plt.clf()\n\n", "CodeBleu_score": 41.69533519771}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    embeds = embeds[:max_speakers * utterances_per_speaker]\n    labels = np.repeat(np.arange(max_speakers), utterances_per_speaker)\n    reducer = umap.UMAP(n_neighbors=5, min_dist=0.1, metric=\"cosine\")\n    embeds = reducer.fit_transform(embeds)\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=labels)\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.title(\"UMAP projection (step %d)\" % step)\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()\n    plt.clf()\n\n", "CodeBleu_score": 47.29551674927558}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n\n    embeds_flat = np.concatenate(embeds, 0)\n    utterances_per_speaker = np.array([i for i, n in enumerate(utterances_per_speaker) for _ in range(n)])\n\n    reducer = umap.UMAP()\n    reducer.fit(embeds_flat)\n    embeds_proj = reducer.fit_transform(embeds_flat)\n\n    plt.clf()\n    plt.scatter(embeds_proj[:, 0], embeds_proj[:, 1], s=1, c=utterances_per_speaker)\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title(f'UMAP projection (step {step})')\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()\n\n\n\n", "CodeBleu_score": 45.975621179009195}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    B, T, C = x.size()\n    # Determine the appropriate dimension index for the speaker embedding\n    if self.use_c_in_mod:\n        C = C + speaker_embedding.size()[1]\n    else:\n        T = T\n    # Repeat the speaker embedding to match the length of the input text\n    e = speaker_embedding.repeat_interleave(T, dim=1)\n    # Reshape and transpose the speaker embedding\n    e = e.reshape(B, T, -1)\n    e = e.transpose(1, 2)\n    # Concatenate the speaker embedding with the input tensor along the last dimension\n    x = torch.cat([x, e], dim=-1)\n    return x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.84876497308456}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    se_size = speaker_embedding.size()\n    se_dim_index = -1\n    for i in range(len(se_size)):\n        if se_size[i] != x_size[i]:\n            se_dim_index = i\n            break\n    se_expand_size = [-1] * len(x_size)\n    se_expand_size[se_dim_index] = se_size[se_dim_index]\n    speaker_embedding = speaker_embedding.repeat_interleave(\n        x_size[se_dim_index], dim=se_dim_index\n    )\n    speaker_embedding = speaker_embedding.reshape(se_expand_size)\n    speaker_embedding = speaker_embedding.transpose(se_dim_index, -1)\n    x = torch.cat([x, speaker_embedding], dim=-1)\n    return x\n\n", "CodeBleu_score": 30.982607830340847}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    # Save the dimensions of the input tensor as human-readable names\n    B, T, C = x.size()\n    # Determine the appropriate dimension index for the speaker embedding\n    speaker_embedding_dim = 2\n    # Repeat the speaker embedding to match the length of the input text\n    e = speaker_embedding.repeat_interleave(T, speaker_embedding_dim)\n    # Reshape the speaker embedding to match the dimensions of the input tensor\n    e = e.reshape(B, T, C)\n    # Transpose the speaker embedding to match the dimensions of the input tensor\n    e = e.transpose(1, -1)\n    # Concatenate the speaker embedding with the input tensor along the last dimension\n    x = torch.cat([x, e], dim=-1)\n    # Return the result\n    return x", "CodeBleu_score": 28.281725041185602}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(batch_size, seq_len, device=device)\n    self.attention = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.378509579655223}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(batch_size, seq_len, device=device)\n    self.attention = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.378509579655223}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    batch_size, seq_len, _ = encoder_seq_proj.size()\n    self.cumulative = torch.zeros(batch_size, seq_len, device=device)\n    self.attention = torch.zeros(batch_size, seq_len, device=device)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.378509579655223}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\"model_state\": self.state_dict(), \"optimizer_state\": optimizer.state_dict()}, str(path))\n    else:\n        torch.save({\"model_state\": self.state_dict()}, str(path))\n\n", "CodeBleu_score": 69.9144528494304}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\"model_state\": self.state_dict(), \"optimizer_state\": optimizer.state_dict()}, str(path))\n    else:\n        torch.save({\"model_state\": self.state_dict()}, str(path))\n\n", "CodeBleu_score": 69.9144528494304}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    # Check for curly braces and treat their contents as ARPAbet:\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n            break\n        sequence += _symbols_to_sequence(_clean_text(m.group(1), cleaner_names))\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n    # Append EOS token\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 81.53469377232976}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n            break\n        sequence += _symbols_to_sequence(_clean_text(m.group(1), cleaner_names))\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 81.53469377232976}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n\n    # Check for curly braces and treat their contents as ARPAbet:\n    while len(text):\n        m = _curly_re.match(text)\n        if not m:\n            sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n            break\n        sequence += _symbols_to_sequence(_clean_text(m.group(1), cleaner_names))\n        sequence += _arpabet_to_sequence(m.group(2))\n        text = m.group(3)\n\n    # Append EOS token\n    sequence.append(_symbol_to_id[\"~\"])\n    return sequence\n\n", "CodeBleu_score": 81.53469377232976}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        if symbol_id in _id_to_symbol:\n            s = _id_to_symbol[symbol_id]\n            # Enclose ARPAbet back in curly braces\n            if len(s) > 1 and s[0] == \"@\":\n                s = \"{%s}\" % s[1:]\n            result += s\n    result = result.replace(\"}{\", \" \")\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 75.68261457265015}, {"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        s = _id_to_symbol[symbol_id]\n        # Enclose ARPAbet back in curly braces\n        if len(s) > 1 and s[0] == \"@\":\n            s = \"{%s}\" % s[1:]\n        result += s\n    result = result.replace(\"}{\", \" \")\n    return result\n\n\n\n\n", "CodeBleu_score": 63.14667573832047}, {"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol_id in sequence:\n        if symbol_id in symbols_lib.id_to_text:\n            s = symbols_lib.id_to_text[symbol_id]\n            # Enclose ARPAbet back with curly braces\n            if len(s) > 1 and s[0] == \"@\":\n                s = \"{\" + s[1:]\n            if len(s) > 1 and s[-1] == \"@\":\n                s = s[:-1] + \"}\"\n            result += s\n    result = result.replace(\"}{\", \" \")\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 63.867696350217216}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Verify the existence of required directories and files\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    assert wav_dir.exists()\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n    \n    # Read the metadata file and prepare file paths for audio and embeddings\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n    \n    # Create a multiprocessing pool to process the audio files in parallel\n    with Pool(n_processes) as pool:\n        # Create a progress bar to track the processing progress\n        with tqdm(total=len(fpaths)) as pbar:\n            # Process the audio files in parallel and generate embeddings\n            for _ in pool.imap(partial(process_utterance, encoder_model_fpath=encoder_model_fpath, pbar=pbar), fpaths):\n                pass\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 71.43957914323413}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    assert wav_dir.exists() and wav_dir.is_dir()\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n\n    func = partial(embed_utterance, encoder_model_fpath=encoder_model_fpath)\n    job = Pool(n_processes).imap(func, fpaths)\n    list(tqdm(job, \"Embedding\", len(metadata), unit=\"utterances\"))", "CodeBleu_score": 90.66361481775263}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    wav_dir = synthesizer_root.joinpath(\"audio\")\n    metadata_fpath = synthesizer_root.joinpath(\"train.txt\")\n    assert wav_dir.exists() and metadata_fpath.exists()\n    embed_dir = synthesizer_root.joinpath(\"embeds\")\n    embed_dir.mkdir(exist_ok=True)\n\n    with metadata_fpath.open(\"r\") as metadata_file:\n        metadata = [line.split(\"|\") for line in metadata_file]\n        fpaths = [(wav_dir.joinpath(m[0]), embed_dir.joinpath(m[2])) for m in metadata]\n\n    func = partial(embed_utterance, encoder_model_fpath=encoder_model_fpath)\n    job = Pool(n_processes).imap(func, fpaths)\n    list(tqdm(job, \"Embedding\", len(fpaths), unit=\"utterances\"))", "CodeBleu_score": 90.41200959557108}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"attention_step_{step}_sample_{sample_num}.png\"))\n\n    # Save predicted mel spectrogram\n    np.save(mel_output_dir.joinpath(f\"mel_pred_{step}_sample_{sample_num}\"), mel_prediction)\n\n    # Save reconstructed waveform\n    audio.save_wav(wav_dir.joinpath(f\"wav_pred_{step}_sample_{sample_num}.wav\"), audio.inv_mel_spectrogram(mel_prediction, hparams))\n\n    # Generate and save plot comparing predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction, plot_dir.joinpath(f\"mel_pred_{step}_sample_{sample_num}.png\"),\n                     title=f\"{hparams.builder} {time_string()} Step {step} Sample {sample_num} Loss {loss:.2f}\",\n                     target_spectrogram=target_spectrogram)\n\n    # Print input sequence at current step\n    print(f\"{sequence_to_text(input_seq)}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.078791682727648}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"att-step{step}.png\"))\n\n    # Save predicted mel spectrogram\n    np.save(mel_output_dir.joinpath(f\"mel-{sample_num}.npy\"), mel_prediction.detach().cpu().numpy(), allow_pickle=False)\n\n    # Save reconstructed waveform\n    audio.save_wav(wav_dir.joinpath(f\"{sample_num}_recon_{time_string()}.wav\"), audio.inv_mel_spectrogram(mel_prediction.detach().cpu().numpy().T, hparams))\n\n    # Save plot comparing predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction.detach().cpu().numpy().T, plot_dir.joinpath(f\"mel-prediction-{sample_num}.png\"),\n                     title=f\"{hparams.builder} {time_string()} Step {step} Loss {loss}\",\n                     target_spectrogram=target_spectrogram.detach().cpu().numpy())\n\n    # Print input sequence at current step\n    print(\"Input:", "CodeBleu_score": 21.97452409430301}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"att-{sample_num}.png\"))\n\n    # Save predicted mel spectrogram\n    np.save(mel_output_dir.joinpath(f\"mel-{sample_num}.npy\"), mel_prediction)\n    audio.save_wav(wav_dir.joinpath(f\"pred_{sample_num}.wav\"),\n                   audio.inv_mel_spectrogram(mel_prediction.T, hparams), hparams)\n\n    # Save reconstructed waveform\n    audio.save_wav(wav_dir.joinpath(f\"gt_{sample_num}.wav\"),\n                   audio.inv_mel_spectrogram(target_spectrogram.T, hparams), hparams)\n\n    # Save a plot comparing the predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction,\n                     plot_dir.joinpath(f\"mel_pred_{step}_{time_string()}_{loss:.2f}.png\"),\n                     title=f\"{hparams.builder} Step {step} Loss {loss:.2f}\",\n                     target_spectrogram=target_spectrogram)\n\n    # Print the input sequence at the current step\n    print(f\"Input: {sequence_to_text(input_seq)}\")", "CodeBleu_score": 26.34572849721284}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print('Trainable parameters: {}M'.format(round(params/1000000, 3)))\n\n", "CodeBleu_score": 38.29350089872728}, {"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print('Trainable parameters: {} Million'.format(round(params/1e6, 3)))\n\n\n", "CodeBleu_score": 38.25085355063219}, {"code": "def num_params(self)\n\t\n    model_parameters = filter(lambda p: p.requires_grad, self.parameters())\n    params = sum([np.prod(p.size()) for p in model_parameters])\n    print(\"Trainable parameters: {} Million\".format(round(params/1000000, 3)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.656674167032065}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if pad > 0:\n        if side == 'before':\n            new_size = (x.shape[0] + pad, x.shape[1], x.shape[2])\n            fill_tensor = torch.zeros(new_size)\n            fill_tensor[pad:, :, :] = x\n        elif side == 'after':\n            new_size = (x.shape[0] + pad, x.shape[1], x.shape[2])\n            fill_tensor = torch.zeros(new_size)\n            fill_tensor[:-pad, :, :] = x\n        elif side == 'both':\n            new_size = (x.shape[0] + 2 * pad, x.shape[1], x.shape[2])\n            fill_tensor = torch.zeros(new_size)\n            fill_tensor[pad:-pad, :, :] = x\n        else:\n            raise ValueError(\"side must be one of 'before', 'after', or 'both'\")\n        if x.is_cuda:\n            fill_tensor = fill_tensor.cuda()\n        return fill_tensor\n    else:\n        return x\n\n", "CodeBleu_score": 32.906968573827825}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        new_size = x.size(0) + pad * 2\n    elif side == 'after':\n        new_size = x.size(0) + pad\n    elif side == 'before':\n        new_size = x.size(0) + pad\n    else:\n        raise ValueError(\"side must be either 'before', 'after', or 'both'\")\n\n    if x.ndim == 2:\n        new_shape = (new_size, x.size(1))\n    else:\n        raise ValueError(\"x must be a 2D tensor\")\n\n    if x.is_cuda:\n        new_tensor = torch.cuda.FloatTensor(*new_shape).fill_(0)\n    else:\n        new_tensor = torch.FloatTensor(*new_shape).fill_(0)\n\n    if side == 'both':\n        new_tensor[pad:pad + x.size(0), :] = x\n    elif side == 'after':\n        new_tensor[pad:pad + x.size(0), :] = x\n    elif side == 'before':\n        new_tensor[:x.size(0), :] = x\n    else:\n        raise ValueError(\"side must be either 'before', 'after', or 'both'\")\n\n    return new_tensor\n\n\n\n\n", "CodeBleu_score": 30.31243788785001}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    # Calculate the new size of the tensor after padding\n    new_size = x.size(0) + pad * 2\n\n    # Create a new tensor filled with zeros on either the CPU or GPU\n    if x.is_cuda:\n        # If the original tensor is on the GPU, create a new tensor on the GPU\n        new_x = torch.zeros((new_size, x.size(1)), device=x.device)\n    else:\n        # If the original tensor is on the CPU, create a new tensor on the CPU\n        new_x = torch.zeros((new_size, x.size(1)))\n\n    # Place the original tensor into the new padded tensor according to the specified side\n    if side == 'before':\n        # Place the original tensor after the padding\n        new_x[pad:, :] = x\n    elif side == 'after':\n        # Place the original tensor before the padding\n        new_x[:x.size(0), :] = x\n    else:\n        # Place the original tensor on both sides of the padding\n        new_x[pad:pad + x.size(0), :] = x\n\n    return new_x", "CodeBleu_score": 33.31348262246481}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n    plt.close()\n    fig = plt.figure(figsize=(12, 6))\n    plt.imshow(attn.T, interpolation='nearest', aspect='auto')\n    fig.savefig(f'{path}.png', bbox_inches='tight')\n    plt.close(fig)", "CodeBleu_score": 59.24589167006521}, {"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(12, 6))\n    plt.imshow(attn.T, interpolation='nearest', aspect='auto')\n    fig.savefig(f'{path}.png', bbox_inches='tight')\n    plt.close(fig)", "CodeBleu_score": 62.46286889331226}, {"code": "def save_attention(attn, path)\n\t\n    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    plt.imshow(attn, aspect='auto', origin='lower', interpolation='none')\n    fig.savefig(path + \".png\")\n    plt.close(fig)", "CodeBleu_score": 46.77214876408195}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'image_name': image_name, 'prediction': prediction, 'confidence': confidence}\n    csv_path = Path('predictions.csv')\n    if not csv_path.is_file():\n        with open(csv_path, 'w') as f:\n            writer = csv.DictWriter(f, fieldnames=data.keys())\n            writer.writeheader()\n    with open(csv_path, 'a') as f:\n        writer = csv.DictWriter(f, fieldnames=data.keys())\n        writer.writerow(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.444416932458836}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {'Image Name': image_name, 'Prediction': prediction, 'Confidence': confidence}\n    with open('predictions.csv', mode='a', newline='') as file:\n        writer = csv.DictWriter(file, fieldnames=data.keys())\n        if file.tell() == 0:\n            writer.writeheader()\n        writer.writerow(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.12212472043244}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    # Create a dictionary with the image name, prediction, and confidence\n    data = {'Image Name': image_name, 'Prediction': prediction, 'Confidence': confidence}\n\n    # Open the CSV file in append mode\n    with open('predictions.csv', mode='a', newline='') as csv_file:\n        # Create a CSV writer object\n        writer = csv.DictWriter(csv_file, fieldnames=['Image Name', 'Prediction', 'Confidence'])\n\n        # Write the header if the file is new\n        if csv_file.tell() == 0:\n            writer.writeheader()\n\n        # Write the data as a new row\n        writer.writerow(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.212237685459925}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        LOGGER.info(f\"", "CodeBleu_score": 9.912281340461456}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        LOGGER.info(f\"", "CodeBleu_score": 9.912281340461456}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    try:\n        import torch\n\n        LOGGER.info(f\"", "CodeBleu_score": 10.027696614025022}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"{prefix} starting export with coremltools {ct.__version__}...\")\n        f = file.with_suffix(\".mlmodel\")  # filename\n        model.eval()\n        for k, m in model.named_modules():\n            if isinstance(m, Detect):  # export Detect() layer\n                m.export = True\n                m.model[-1].export = True  # Detect() layer export\n            _ = m.info[:4]  # for TFLite, CoreML\n            if m.info[-1] == \"auto\" and x.dtype == torch.float16:  # prefer FP16\n                m.half()\n        model.model[-1].export = True  # set Detect() layer export\n        y = model(im)  # dry run\n        if int8:\n            LOGGER.info(f\"{prefix} quantizing weights to int8...\")\n            ct.utils.misc_util.set_quantization_precision_weight(model.cpu(), nn.int8)\n        if half:\n            LOGGER.info(f\"{prefix} converting model to FP16...\")\n            model.half()\n        LOGGER.info(f\"{prefix} running CoreML export with coremltools {ct.__version__}...\")\n        model = ct.convert(\n            model,\n            inputs=[ct.ImageType(name=\"images\", shape=im.shape, scale=1 / 255.0, bias=[0, 0, 0])],\n        )\n        if nms:  # add NMS\n            model = ct.models.neural_network.NeuralNetwork.deserialize(model.serialize())\n            model = quantize_weights(model, nbits=16)\n            add_nms_to_coreml_model(model)\n        if int8 and not half:\n            LOGGER.info(f\"{prefix} quantizing weights to int8...\")\n            model = quantize_weights(model, nbits=8)\n        LOGGER.info(f\"{", "CodeBleu_score": 42.5341912094188}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"{prefix} starting export with coremltools {ct.__version__}...\")\n        f = file.with_suffix(\".mlmodel\")  # file name\n        model.eval()  # CoreML export\n        for k, m in model.named_modules():\n            if isinstance(m, Detect):  # export Detect() layer\n                m.inplace = False\n                m.dynamic = False  # ONNX export property\n                m.export = True  # ONNX export property\n        model.model[-1].export = True  # set Detect() layer export=True\n        y = model(im)  # dry run\n        if int8:\n            LOGGER.info(f\"{prefix} Quantizing with int8 precision\")\n            ct.convert(\n                model,\n                inputs=[ct.ImageType(name=\"images\", shape=im.shape, scale=1 / 255.0, bias=[0, 0, 0])],\n                outputs=[ct.ImageType(name=\"output\", shape=y.shape, scale=1 / 255.0, bias=[0, 0, 0])],\n            )\n        else:\n            LOGGER.info(f\"{prefix} Converting with float32 precision\")\n            ct.convert(\n                model,\n                inputs=[ct.ImageType(name=\"images\", shape=im.shape)],\n            )\n        mlmodel = ct.models.model.MLModel(f)\n        if nms:  # add NMS to model output\n            from coremltools.models.neural_network import NeuralNetworkBuilder\n\n            nms_spec = ct.models.neural_network.NeuralNetwork.nms(\n                config=[\n                    ct.models.neural_network.NMS.NmsConfig(\n                        \"confidence\",  # conf\n                        iou_threshold=0.35,\n                        confidence_threshold=0.35,\n                    )\n                ],\n                input_names=[\"raw_confidence\", \"raw_coordinates", "CodeBleu_score": 35.155638474610825}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t\n    try:\n        import coremltools as ct\n\n        LOGGER.info(f\"{prefix} starting export with coremltools {ct.__version__}...\")\n        assert prefix.endswith(\" \")\n        f = file.with_suffix(\".mlmodel\")  # file name\n        model.eval()  # CoreML export\n        for k, m in model.named_modules():\n            if isinstance(m, Detect):  # export Detect() layer\n                m.inplace = False\n                m.onnx_dynamic = False  # force PyTorch JIT\n                m.export = True  # CoreML export\n        model = model.model[-1]  # Detect()\n        im = im.astype(np.float16) if half else im.astype(np.float32)  # CoreML model\n        model = ct.convert(model, inputs=[ct.ImageType(\"input\", shape=im.shape)])\n        if nms:  # CoreML NMS model wrap\n            model = ct.models.MLModel(model.get_spec())\n            model = ct.models.neural_network.quantization_utils.quantize_weights(model, nbits=16)\n            model = ct.models.neural_network.NeuralNetwork.compile(model, compute_units=compute_units(),\n                                                                  use_coreml_api_2=True)\n            model = ct.models.MLModel(model.get_spec())\n            iOSModel = ct.models.neural_network.NeuralNetwork.compile(model, compute_units=compute_units(),\n                                                                     use_coreml_api_2=True)\n            model = ct.models.neural_network.pruning_utils.prune_weights(iOSModel, \"Constant\")\n            model = ct.models.MLModel(model.get_spec())\n            model.user_defined_metadata[\"com.apple.coreml.md.app\"].username = \"Apple Inc.\"\n            model.user_defined_metadata[\"com.apple.coreml.md.app\"].shortDescription = \"YOLOv5\"\n           ", "CodeBleu_score": 41.30990422831542}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.630972577458174}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    log_alpha_t = None\n    if self.schedule == \"discrete\":\n        log_alpha_t = log_alpha_fn(t)\n    elif self.schedule == \"linear\":\n        log_alpha_t = log_alpha_fn(t)\n        log_alpha_t = torch.log(log_alpha_t)\n        log_alpha_t = log_alpha_t.reshape(1, -1)\n        log_alpha_t = log_alpha_t.repeat(self.num_timesteps, 1)\n        log_alpha_t = torch.transpose(log_alpha_t, 0, 1)\n        log_alpha_t = log_alpha_t.reshape(-1)\n    elif self.schedule == \"cosine\":\n        log_alpha_t = log_alpha_fn(t)\n        log_alpha_t = torch.log(log_alpha_t)\n        log_alpha_t = log_alpha_t.reshape(1, -1)\n        log_alpha_t = log_alpha_t.repeat(self.num_timesteps, 1)\n        log_alpha_t = torch.transpose(log_alpha_t, 0, 1)\n        log_alpha_t = log_alpha_t.reshape(-1)\n        log_alpha_t = interpolate_fn(log_alpha_t, self.t, self.log_alpha)\n    return log_alpha_t\n\n", "CodeBleu_score": 36.52648312305221}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == \"discrete\":\n        log_alpha_t = interpolate_fn(t, self.discrete_time_steps, self.log_alpha_discrete)\n    elif self.schedule_type == \"linear\":\n        log_alpha_t = self.log_alpha_0 + t * (self.log_alpha_1 - self.log_alpha_0)\n    elif self.schedule_type == \"cosine\":\n        log_alpha_t = self.log_alpha_0 - torch.cos(\n            (t + self.cosine_s) / (1 + self.cosine_s) * torch.pi * 0.5\n        ) ** 2 * (self.log_alpha_0 - self.log_alpha_1)\n    else:\n        raise ValueError(f\"schedule_type {self.schedule_type} is not valid.\")\n    return log_alpha_t\n\n", "CodeBleu_score": 42.33073580407426}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    log_alpha = self.log_alpha_fn(t)\n    if self.schedule_type == \"discrete\":\n        return log_alpha\n    elif self.schedule_type == \"linear\":\n        return log_alpha - torch.log(self.t_max - t) - torch.log(t)\n    elif self.schedule_type == \"cosine\":\n        log_alpha_0 = self.log_alpha_fn(torch.tensor(0.0, device=t.device))\n        log_alpha_1 = self.log_alpha_fn(torch.tensor(1.0, device=t.device))\n        return log_alpha - torch.log(torch.cos(torch.acos(torch.exp(log_alpha_0)) * (1 - t / self.t_max) + torch.acos(torch.exp(log_alpha_1)) * (t / self.t_max))) - torch.log(1 - t / self.t_max)\n    else:\n        raise ValueError(f\"Invalid schedule type: {self.schedule_type}\")\n\n", "CodeBleu_score": 38.442619800194166}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        t = (torch.exp(self.beta_0) - lamb) / (torch.exp(self.beta_1) - lamb)\n        return t\n    elif self.schedule == \"quadratic\":\n        t = (torch.exp(self.beta_0) - lamb) / (torch.exp(self.beta_1) - lamb)\n        return t ** 2\n    elif self.schedule == \"sigmoid\":\n        t = (torch.exp(self.beta_0) - lamb) / (torch.exp(self.beta_1) - lamb)\n        return 1 / (1 + torch.exp(-self.beta_2 * t))\n    elif self.schedule == \"vp\":\n        t = (torch.exp(self.beta_0) - lamb) / (torch.exp(self.beta_1) - lamb)\n        return 1 - torch.exp(-t)\n    elif self.schedule == \"discrete\":\n        log_alpha = interpolate_fn(lamb, self.log_alpha_t, self.log_alpha)\n        return torch.log(torch.cosh(log_alpha / 2) / torch.sinh(log_alpha / 2))\n    else:\n        log_alpha = interpolate_fn(lamb, self.log_alpha_t, self.log_alpha)\n        return torch.log(torch.cos(log_alpha) / torch.sin(log_alpha))\n\n", "CodeBleu_score": 30.642688121115558}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        return (torch.sqrt(self.beta_start - lamb * self.beta_end) - torch.sqrt(self.beta_end)) / (\n            torch.sqrt(self.beta_start) - torch.sqrt(self.beta_end)\n        )\n    elif self.schedule == \"quadratic\":\n        return (torch.sqrt(self.beta_start - lamb * self.beta_end) - torch.sqrt(self.beta_end)) ** 2 / (\n            torch.sqrt(self.beta_start) - torch.sqrt(self.beta_end)\n        ) ** 2\n    elif self.schedule == \"sigmoid\":\n        return torch.log(lamb / (1.0 - lamb) + torch.sqrt(self.beta_start * (1.0 - lamb) / lamb)) / np.log(\n            self.beta_start / self.beta_end\n        )\n    elif self.schedule == \"step\":\n        return 1.0 - torch.exp(-lamb * self.beta_end)\n    elif self.schedule == \"vp\":\n        return 1.0 - torch.exp(-lamb * self.beta_end)\n    elif self.schedule == \"vp-linear\":\n        return 1.0 - torch.exp(-lamb * self.beta_end)\n    elif self.schedule == \"vp-spaced\":\n        return 1.0 - torch.exp(-lamb * self.beta_end)\n    elif self.schedule == \"discrete\":\n        log_alpha = torch.log(self.alpha)\n        log_alpha_cumprod = torch.cumsum(log_alpha, dim=1)\n        log_alpha_cumprod_prev = torch.cat([torch.zeros_like(log_alpha_cumprod[:, :1]), log_alpha_cumprod[:, :-1]], dim=1)\n        log_alpha_cumprod_prev = torch.log(torch.exp(log_alpha_cumprod_", "CodeBleu_score": 27.09782544733309}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"quadratic\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"sigmoid\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"cosine\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"log_snr\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"log_snr_continuous\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"vp_sde\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"vp_sde_continuous\":\n        return self.t_fn(lamb)\n    elif self.schedule == \"discrete\":\n        log_alpha = self.log_alpha\n        log_alpha = torch.flip(log_alpha, dims=(0,))\n        log_alpha_cum = torch.cumsum(log_alpha, dim=0)\n        log_alpha_cum = torch.flip(log_alpha_cum, dims=(0,))\n        log_alpha_cum = log_alpha_cum - log_alpha_cum.mean()\n        log_alpha_cum = log_alpha_cum.reshape(1, -1)\n        t = interpolate_fn(lamb, log_alpha_cum, torch.linspace(0, 1, log_alpha.shape[0] + 1, device=lamb.device))\n        return t\n    elif self.schedule == \"log_snr_discrete\":\n        log_alpha = self.log_alpha\n        log_alpha = torch.flip(log_alpha, dims=(0,))\n        log_alpha_cum = torch.cumsum(log_alpha, dim=0)\n        log_alpha_cum = torch.flip(log_alpha_cum, dims=(0,", "CodeBleu_score": 30.558806774586117}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    if cond is None:\n        cond = torch.zeros_like(x)\n    t_continuous = expand_dims(t_continuous, x.dim())\n    if model_type == \"noise\":\n        x_recon = model(x, t_continuous)\n    elif model_type == \"score\":\n        x_recon = model(x, t_continuous) / noise_schedule.marginal_std(t_continuous)\n    elif model_type == \"hybrid\":\n        x_recon = model(x, t_continuous)\n        x_recon = x_recon + noise_schedule.marginal_std(t_continuous) * cond\n    else:\n        raise ValueError(f\"Invalid model type: {model_type}\")\n    return x_recon\n\n", "CodeBleu_score": 29.837848802252616}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, x.dim())\n    if cond is not None:\n        cond = expand_dims(cond, x.dim())\n    if model_type == 'noise':\n        noise_pred = model(x, t_continuous, cond=cond)\n    elif model_type == 'score':\n        x_repeated = x.repeat([noise_schedule.num_noise_levels, 1, 1, 1])\n        t_continuous_repeated = t_continuous.repeat([noise_schedule.num_noise_levels, 1])\n        noise_pred = model(x_repeated, t_continuous_repeated, cond=cond)\n        noise_pred = noise_pred.view(\n            noise_schedule.num_noise_levels, x.shape[0], *x.shape[1:])\n        noise_pred = noise_pred.mean(dim=0) * \\\n            (len(noise_schedule.sigmas) / noise_schedule.sigmas[-1]) ** 2\n    elif model_type == 'hybrid':\n        x_repeated = x.repeat([noise_schedule.num_noise_levels, 1, 1, 1])\n        t_continuous_repeated = t_continuous.repeat([noise_schedule.num_noise_levels, 1])\n        noise_pred = model(x_repeated, t_continuous_repeated, cond=cond)\n        noise_pred = noise_pred.view(\n            noise_schedule.num_noise_levels, x.shape[0], *x.shape[1:])\n        noise_pred = noise_pred.mean(dim=0)\n    else:\n        raise ValueError(f'Model type {model_type} is not supported.')\n    return noise_pred\n\n", "CodeBleu_score": 32.83492464336952}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t\n    t_continuous = expand_dims(t_continuous, x.dim())\n    if cond is None:\n        model_output = model(x, t_continuous)\n    else:\n        model_output = model(x, t_continuous, cond)\n    if model_output.shape[1] == x.shape[1] * 2:\n        model_output, model_var_values = torch.split(model_output, x.shape[1], dim=1)\n        if model_var_type == \"fixedlarge\":\n            model_log_var = model_var_values\n            model_var = torch.exp(model_log_var)\n        elif model_var_type == \"fixedsmall\":\n            model_log_var = torch.log(noise_schedule.marginal_std(t_continuous) ** 2 + model_var_values)\n            model_var = torch.exp(model_log_var)\n        else:\n            raise NotImplementedError()\n        pred_x0 = model_output\n        if clip_denoised:\n            pred_x0 = torch.clamp(pred_x0, -1., 1.)\n        return pred_x0, model_var\n    else:\n        pred_x0 = model_output\n        if clip_denoised:\n            pred_x0 = torch.clamp(pred_x0, -1., 1.)\n        return pred_x0\n\n", "CodeBleu_score": 34.82943634095788}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.threshold\n    x0_abs = torch.abs(x0)\n    x0_abs_flat = x0_abs.flatten()\n    x0_abs_flat_sorted = torch.sort(x0_abs_flat)[0]\n    x0_abs_flat_sorted_quantile = torch.quantile(x0_abs_flat_sorted, t)\n    x0_abs_flat_sorted_quantile_expanded = expand_dims(x0_abs_flat_sorted_quantile, x0.dim())\n    x0_abs_flat_sorted_quantile_expanded = torch.maximum(x0_abs_flat_sorted_quantile_expanded, torch.ones_like(x0_abs_flat_sorted_quantile_expanded))\n    x0_abs_flat_sorted_quantile_expanded = torch.clamp(x0_abs_flat_sorted_quantile_expanded, min=1e-8)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.device)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.dtype)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.shape)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.dtype)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.dtype)\n    x0_abs_flat_sorted_quantile_expanded = x0_abs_flat_sorted_quantile_expanded.to(x0.dtype)\n    x0_", "CodeBleu_score": 33.55219819930538}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.t\n    x0_abs = torch.abs(x0)\n    x0_abs_flatten = x0_abs.reshape(-1)\n    x0_abs_flatten_quantile = torch.quantile(x0_abs_flatten, t)\n    scale_factor = expand_dims(x0_abs_flatten_quantile, x0.dim())\n    x0_clamped = torch.clamp(x0, -scale_factor, scale_factor)\n    x0_clamped_scaled = x0_clamped / scale_factor\n    return x0_clamped_scaled\n\n", "CodeBleu_score": 34.35062100855628}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t\n    if t is None:\n        t = self.threshold\n    x0 = x0.reshape(x0.shape[0], -1)\n    q = torch.quantile(torch.abs(x0), t, dim=1)\n    q = expand_dims(q, x0.dim())\n    x0 = torch.maximum(q, torch.abs(x0)) * torch.sign(x0)\n    x0 = torch.clamp(x0 / q, 0, 1)\n    return x0.reshape(x0.shape[0], *self.input_shape)\n\n", "CodeBleu_score": 42.56326201661089}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t\n    # Calculate the threshold value based on the dynamic thresholding ratio and maximum threshold value\n    threshold = self.dynamic_thresholding_ratio * self.max_threshold\n    # Clamp the input tensor values within the threshold\n    clamped_x = torch.clamp(x, -threshold, threshold)\n    # Normalize the clamped values\n    normalized_x = clamped_x / threshold\n    return normalized_x\n", "CodeBleu_score": 10.642025771800453}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    if self.dynamic_thresholding:\n        threshold = self.dynamic_threshold_ratio * self.max_threshold\n        x = torch.clamp(x, min=-threshold, max=threshold)\n        x = x / threshold\n    return x\n\n", "CodeBleu_score": 11.923137878217092}, {"code": "def data_prediction_fn(self, x, t)\n\t\n    # Dynamic thresholding ratio\n    ratio = self.dynamic_thresholding_ratio\n    # Maximum threshold value\n    max_threshold = self.max_threshold\n    # Calculate the threshold value based on the dynamic thresholding ratio and maximum threshold value\n    threshold = max_threshold * ratio\n    # Clamp the input tensor values within the threshold\n    x = torch.clamp(x, -threshold, threshold)\n    # Normalize the clamped values\n    x = x / threshold\n    return x\n", "CodeBleu_score": 11.27534075019268}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.size())\n    scaled_input = input * sigma_in\n    prediction = model(scaled_input, **kwargs)\n    return prediction * sigma_in\n\n", "CodeBleu_score": 24.571184819098928}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape[0], 1, 1, 1)\n    scaled_input = input / sigma_in\n    adjusted_prediction = model(scaled_input, sigma_in, **kwargs) * sigma_in\n    return adjusted_prediction\n\n", "CodeBleu_score": 27.932988891106085}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    scaled_input = input / sigma_in\n    prediction = model(scaled_input, **kwargs)\n    return prediction * sigma_in\n\n", "CodeBleu_score": 20.62361520967098}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().detach().requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        log_alpha.backward()\n        grad_log_alpha = taus.grad\n        return grad_log_alpha * alpha\n\n", "CodeBleu_score": 39.87950321931618}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = alpha.log()\n\n    log_alpha.requires_grad_(True)\n    with torch.enable_grad():\n        log_alpha_grad = torch.autograd.grad(log_alpha.sum(), taus)[0]\n    integrand = log_alpha_grad * alpha\n    return integrand\n\n", "CodeBleu_score": 46.35290782839926}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        torch.autograd.backward(log_alpha, grad_tensors=torch.ones_like(log_alpha))\n        grad_log_alpha = taus.grad\n        integrand = alpha * grad_log_alpha\n    return integrand\n\n", "CodeBleu_score": 44.062156166058756}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    sigmas_cpu = sigmas.detach().cpu().numpy()\n    ds = []\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for sigma in trange(sigmas_cpu, disable=disable):\n        eps = noise_sampler(x)\n        sigma_scaled = sigma * s_noise\n        denoised = model(x * sigma_scaled, sigma_scaled, **extra_args)\n        d = to_d(x, sigma, denoised)\n        ds.append(d)\n        if len(ds) >= 4:\n            d_prime = (1 / 8) * (55 * ds[-1] - 59 * ds[-2] + 37 * ds[-3] - 9 * ds[-4])\n            sigma_down, sigma_up = get_ancestral_step(sigmas_cpu[sigmas_cpu.tolist().index(sigma) - 3], sigmas_cpu[sigmas_cpu.tolist().index(sigma)], eta=eta)\n            x = x + d_prime * utils.append_dims(sigma_down, x.ndim)\n        x = x + d * utils.append_dims(sigma, x.ndim)\n        x = x + eps * utils.append_dims(sigma_up, x.ndim)\n        if callback is not None:\n            callback({'x': x, 'i': sigmas_cpu.tolist().index(sigma), 'sigma': sigma, 'sigma_hat': sigma, 'denoised': denoised})\n    return x\n\n", "CodeBleu_score": 42.64106734625951}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = lambda x, y, sigma: x\n    disable = disable if disable is not None else lambda x: False\n    for sigma in trange(len(sigmas) - 1, disable=disable(\"sampling\")):\n        if eta:\n            sigma_down, sigma_up = get_ancestral_step(sigmas[sigma], sigmas[sigma + 1], eta)\n            if sigma_up != 0:\n                x = x + noise_sampler(x, sigma_up) * s_noise\n        denoised = model(x, sigma_in=s_in * sigmas[sigma], **extra_args)\n        d = to_d(x, sigmas[sigma], denoised)\n        if sigma_down != 0:\n            x = x + noise_sampler(x, sigma_down) * s_noise\n        dt = sigmas[sigma + 1] - sigma_down\n        x = x + d * dt\n        x = callback(x, sigma, sigma_down, sigma_up)\n    x = x + noise_sampler(x, sigmas[0]) * s_noise\n    return x\n\n", "CodeBleu_score": 50.610622863316564}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    sigmas_forward = torch.cat([sigmas, s_in])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = lambda data: None\n    model_fn = lambda x, sigma, **kwargs: model(x, sigma, **kwargs)\n    all_samples = []\n    for i in trange(len(sigmas), disable=disable):\n        callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas_forward[i], 'model': model})\n        sigma_down, sigma_up = get_ancestral_step(sigmas[i], sigmas_forward[i], eta)\n        if sigma_down > 0:\n            x = x + noise_sampler(x, sigma_down)\n        denoised = model_fn(x, sigmas_forward[i], **extra_args)\n        d = to_d(x, sigmas[i], denoised)\n        if sigma_down > 0:\n            d = d + noise_sampler(x, sigma_down)\n        dt = sigma_down - sigmas[i]\n        if sigmas[i] == sigmas_forward[i]:\n            # Euler method\n            x = x + d * dt\n        else:\n            # Heun's method\n            x_2 = x + d * dt\n            denoised_2 = model_fn(x_2, sigmas_forward[i], **extra_args)\n            d_2 = to_d(x_2, sigmas[i], denoised_2)\n            if sigma_down > 0:\n                d_2 = d_2 + noise_sampler(x_2, sigma_down)\n            x = x + (d + d_2) / 2 * dt\n        x = x + noise_sampler(x, sigma_up)\n        all", "CodeBleu_score": 50.25244617603421}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order < i:\n        raise ValueError(\"Order of integration must be less than or equal to the number of steps.\")\n    def product_term(t):\n        prod = 1\n        for m in range(i, order+1):\n            if m != j:\n                prod *= (t - m)\n        return prod\n    integral, _ = quad(product_term, i, i+1)\n    return integral\n\n", "CodeBleu_score": 28.834968494341073}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product_term(t_):\n        result = 1\n        for k in range(order):\n            if k == j:\n                continue\n            result *= (t_ - t[i + k]) / (t[i + j] - t[i + k])\n        return result\n\n    if j >= order:\n        raise ValueError(\"Order is too high for the step index.\")\n\n    return integrate(product_term, t[i], t[i + 1])\n\n", "CodeBleu_score": 55.22970481645785}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n\n    def product_term(t_):\n        product = 1\n        for k in range(order):\n            if k != j:\n                product *= (t - t_[k]) / (t_[i] - t_[k])\n        return product\n\n    if i < j:\n        raise ValueError(\"The step index i must be greater than or equal to j.\")\n    elif i > order:\n        raise ValueError(\n            \"The step index i must be less than or equal to the order of the method.\"\n        )\n    else:\n        t_ = np.linspace(t[i - 1], t[i], 1001)\n        return integrate.simpson(product_term(t_), t_)\n\n", "CodeBleu_score": 28.891183767989403}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for i in trange(len(sigmas) - 1, disable=disable):\n        denoised = model(x, s_in * sigmas[i], **extra_args)\n        d = to_d(x, sigmas[i], denoised)\n        dt = sigmas[i + 1] - sigmas[i]\n        x = x + d * noise_scaling(sigmas[i], sigmas[i + 1])\n        x = x + noise_sampler(sigmas[i], sigmas[i + 1]) * np.sqrt(dt)\n        if callback is not None:\n            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_next': sigmas[i + 1], 'denoised': denoised})\n    return x\n\n", "CodeBleu_score": 60.65433530100647}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_input = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for i in trange(len(sigmas) - 1, disable=disable):\n        denoised = model(x, s_input * sigmas[i], **extra_args)\n        d = to_d(x, sigmas[i], denoised)\n        if sigmas[i + 1] == 0:\n            # Euler method\n            x = x + d * sigmas[i]\n        else:\n            # Heun's method\n            x_2 = x + d * sigmas[i + 1]\n            d_prime = to_d(x_2, sigmas[i + 1], denoised)\n            d_prime = (d + d_prime) / 2\n            x = x + d_prime * sigmas[i + 1]\n        if callback is not None:\n            callback({'x': x, 'i': i, 'sigma': sigmas[i], 'sigma_hat': sigmas[i], 'denoised': denoised})\n    return x\n\n", "CodeBleu_score": 59.0952394289722}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    extra_args = {} if extra_args is None else extra_args\n    s_in = x.new_ones([x.shape[0]])\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    for sigma in trange(len(sigmas), disable=disable):\n        sigma_next = sigmas[sigma]\n        sigma_next = torch.tensor(sigma_next, device=x.device)\n        sigma_next = sigma_next.item()\n        model_fn = model\n        model_kwargs = {}\n        if sigma_next == 0:\n            x = x + sigmas[sigma - 1] ** 2 * model_fn(x, sigma_next, **model_kwargs)\n        else:\n            x0_t = x\n            if sigma > 0:\n                x0_t = x0_t + noise_scaling * sigmas[sigma - 1] ** 2 * model_fn(x, sigma_next, **model_kwargs)\n            x = x0_t + sigmas[sigma] ** 2 * noise_sampler(x0_t, sigma_next)\n        if callback is not None:\n            callback({'x': x, 'i': sigma, 'sigma': sigma_next, 'sigma_hat': sigmas[sigma], 'denoising': model_fn, 'extra_args': extra_args})\n    return x\n\n", "CodeBleu_score": 47.514369786137934}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t\n    dims_to_append = target_dims - x.ndim\n    if dims_to_append < 0:\n        raise ValueError(\n            f\"target_dims must be greater than or equal to x.ndim, but got target_dims={target_dims} and x.ndim={x.ndim}\")\n    for _ in range(dims_to_append):\n        x = torch.unsqueeze(x, -1)\n    return x.detach().clone() if str(x.device) == 'mps' else x\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.04450679604833}, {"code": "def append_dims(x, target_dims)\n\t\n    dims_to_append = target_dims - x.ndim\n    if dims_to_append < 0:\n        raise ValueError(f\"Target dimensions ({target_dims}) must be greater than or equal to the current dimensions ({x.ndim}).\")\n    for _ in range(dims_to_append):\n        x = torch.unsqueeze(x, -1)\n    return x.detach().clone() if x.device.type == 'mps' else x\n\n", "CodeBleu_score": 48.41708343884045}, {"code": "def append_dims(x, target_dims)\n\t\n    dims_to_append = target_dims - x.ndim\n    if dims_to_append < 0:\n        raise ValueError(f\"target_dims must be >= x.ndim, \" f\"but got target_dims={target_dims}, x.ndim={x.ndim}\")\n    return x[(...,) + (None,) * dims_to_append].detach().clone() if x.is_mps else x[(...,) + (None,) * dims_to_append]\n\n", "CodeBleu_score": 42.17596568493979}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    path = Path(path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    if path.exists():\n        return path\n    with urlopen(url) as source, path.open(\"wb\") as target:\n        copyfileobj(source, target)\n    if digest is not None:\n        if hexdigest(path) != digest:\n            raise OSError(f\"{path} corrupted\")\n    return path\n\n", "CodeBleu_score": 36.2094313788231}, {"code": "def download_file(path, url, digest=None)\n\t\n    target = Path(path)\n    target.parent.mkdir(exist_ok=True, parents=True)\n    if not target.exists():\n        with urlopen(url) as response:\n            with target.open(\"wb\") as f:\n                shutil.copyfileobj(response, f)\n    if digest is not None:\n        if digest != hashlib.sha256(target.open(\"rb\").read()).hexdigest():\n            raise OSError(\"Downloaded file has incorrect SHA-256 hash\")\n    return target\n\n", "CodeBleu_score": 43.10650569847878}, {"code": "def download_file(path, url, digest=None)\n\t\n    path = Path(path)\n    path.parent.mkdir(exist_ok=True, parents=True)\n    if path.exists():\n        return path\n    with urlopen(url) as source, path.open(\"wb\") as target:\n        copyfileobj(source, target)\n    if digest:\n        if hashlib.sha256(path.read_bytes()).hexdigest() != digest:\n            raise OSError(f\"{url}: SHA-256 mismatch\")\n    return path\n\n", "CodeBleu_score": 32.252631492593196}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    prev_modes = []\n    for module in model.modules():\n        prev_modes.append(module.training)\n        module.train(mode)\n    yield\n    for module, mode in zip(model.modules(), prev_modes):\n        module.train(mode)\n\n", "CodeBleu_score": 37.016974025817134}, {"code": "def train_mode(model, mode=True)\n\t\n    modes = []\n    for module in model.modules():\n        modes.append(module.training)\n        module.train(mode)\n    yield\n    for module, mode in zip(model.modules(), modes):\n        module.train(mode)\n\n", "CodeBleu_score": 38.40057953024767}, {"code": "def train_mode(model, mode=True)\n\t\n    if mode:\n        model.train()\n    else:\n        model.eval()\n    return model\n\n", "CodeBleu_score": 14.524436844388436}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    model_params = dict(model.named_parameters())\n    model_buffers = dict(model.named_buffers())\n\n    averaged_params = dict(averaged_model.named_parameters())\n    averaged_buffers = dict(averaged_model.named_buffers())\n\n    for key in model_params.keys():\n        averaged_params[key].mul_(decay).add_(model_params[key], alpha=1 - decay)\n\n    for key in model_buffers.keys():\n        averaged_buffers[key].copy_(model_buffers[key])\n\n    return averaged_model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.86473342196439}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    model_params = dict(model.named_parameters())\n    model_buffers = dict(model.named_buffers())\n    averaged_params = dict(averaged_model.named_parameters())\n    averaged_buffers = dict(averaged_model.named_buffers())\n    for key in model_params.keys():\n        averaged_params[key].mul_(decay).add_(model_params[key], alpha=1 - decay)\n    for key in model_buffers.keys():\n        averaged_buffers[key].copy_(model_buffers[key])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.95820446079697}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    # The function updates an exponentially moving averaged (EMA) model with the current model's parameters.\n    # It ensures both models have matching parameters and buffers.\n    # For each parameter, it updates the averaged model using a weighted average based on the decay factor.\n    # It also copies the current model's buffers to the averaged model.\n    model_params = dict(model.named_parameters())\n    model_buffers = dict(model.named_buffers())\n    averaged_params = dict(averaged_model.named_parameters())\n    averaged_buffers = dict(averaged_model.named_buffers())\n    for key in model_params.keys():\n        averaged_params[key].mul_(decay).add_(model_params[key], alpha=1 - decay)\n    for key in model_buffers.keys():\n        averaged_buffers[key].copy_(model_buffers[key])\n\n", "CodeBleu_score": 41.95820446079697}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    return (min_value.log() - max_value.log() - torch.log(1. - u) / scale).exp()\n\n", "CodeBleu_score": 31.046076720302977}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, dtype=dtype, device=device)\n    return (max_value - min_value).log() + (min_value.log() - max_value.log() + u.log() - (-u).log()) / scale\n\n", "CodeBleu_score": 27.435571122833984}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, dtype=dtype, device=device)\n    return (min_value.log() - max_value.log() - torch.log(1 - u) / scale).exp() * scale + loc\n\n", "CodeBleu_score": 27.351145814261912}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    elif activation == \"snake\":\n        return SnakeBeta(channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Activation {activation} not supported\")\n\n", "CodeBleu_score": 39.13590132604013}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    elif activation == \"snake\":\n        return SnakeBeta(channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Activation {activation} not found\")\n\n", "CodeBleu_score": 39.069824234260636}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    elif activation == \"snake\":\n        return SnakeBeta(channels=channels, antialias=antialias)\n    elif activation == \"none\":\n        return nn.Identity()\n    else:\n        raise ValueError(f\"Activation {activation} not found\")\n\n", "CodeBleu_score": 39.25585364873555}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    t, t_unrotated = t[..., :scale], t[..., scale:]\n    t, t_unrotated = map(lambda t: t.to(torch.float32), (t, t_unrotated))\n    t, t_unrotated = map(lambda t: rearrange(t, '... d -> ... (d j)'), (t, t_unrotated))\n    t = apply_rotary_pos_emb_subset(t, freqs)\n    t = rearrange(t, '... (d j) -> ... d', j = 2)\n    return torch.cat((t, t_unrotated), dim = -1)\n\n", "CodeBleu_score": 22.82639549644182}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if t.dtype != torch.float32:\n        t = t.to(torch.float32)\n    t, t_unrotated = t[..., :freqs.shape[-1] * 2], t[..., freqs.shape[-1] * 2:]\n    t, t_unrotated = rearrange(t, '... (j d) -> ... j d', j = 2), rearrange(t_unrotated, '... d -> ... (j d)', j = 2)\n    t1, t2 = t.unbind(dim = -2)\n    t1_rot, t2_rot = rotate_half(t1), rotate_half(t2)\n    t1_rot, t2_rot = t1_rot.to(torch.float32), t2_rot.to(torch.float32)\n    t1, t2 = t1.to(torch.float32), t2.to(torch.float32)\n    freqs = freqs.to(torch.float32)\n    t1_rot = t1 * scale * torch.cos(t2_rot * freqs) + t2 * scale * torch.sin(t2_rot * freqs)\n    t2_rot = -t1 * scale * torch.sin(t2_rot * freqs) + t2 * scale * torch.cos(t2_rot * freqs)\n    t_rot = torch.cat((t1_rot, t2_rot), dim = -1)\n    t = torch.cat((t_rot, t_unrotated.to(torch.float32)), dim = -1)\n    return t\n\n", "CodeBleu_score": 37.93267685603302}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t\n    if t.dtype != torch.float32:\n        t = t.to(torch.float32)\n\n    t, t_unrotated = rearrange(t, '... (j d) -> ... j d', j = 2), rearrange(t[:, t.shape[-1] // 2:], '... (j d) -> ... j d', j = 2)\n    t, t_unrotated = t.to(torch.float32), t_unrotated.to(torch.float32)\n\n    t, t_unrotated = t.to(torch.float32), t_unrotated.to(torch.float32)\n\n    freqs = t.new_tensor(freqs).to(torch.float32)\n    freqs = freqs * scale\n\n    t_rotated = rotate_half(t) * rearrange(freqs, '... -> ... 1')\n    t_rotated = torch.cat((t_unrotated, t_rotated), dim = -2)\n    return t_rotated\n\n", "CodeBleu_score": 39.863224416546515}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook[idx].movedim(-1, dim) if dim != -1 else self.codebook[idx]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.100774432909976}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook.movedim(-1, dim)[idx]\n\n\n\n", "CodeBleu_score": 17.78526264547506}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    vq = self.codebook(idx)\n    if dim != -1:\n        vq = vq.movedim(dim, -1)\n    return vq\n\n\n\n", "CodeBleu_score": 39.740221535854374}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    for block in self.down_blocks:\n        x = block(x)\n    if quantize:\n        z_e_x = x.contiguous().view(-1, x.size(-1)) if len(x.shape) > 2 else x\n        z_q_x, indices = self.vq(z_e_x, self.codebook.weight.detach())\n        vq_loss, commit_loss = None, None\n        if self.ema_loss and self.training:\n            self._updateEMA(z_e_x.detach(), indices.detach())\n        # pick the graded embeddings after updating the codebook in order to have a more accurate commitment loss\n        z_q_x_grd = torch.index_select(self.codebook.weight, dim=0, index=indices)\n        vq_loss = (z_q_x_grd - z_e_x.detach()).pow(2).mean()\n        commit_loss = (z_e_x - z_q_x_grd.detach()).pow(2).mean()\n        z_q_x = z_q_x.view(x.shape)\n        return z_q_x, (vq_loss, commit_loss), indices.view(x.shape[:-1]), (vq_loss + commit_loss)\n    return x\n\n", "CodeBleu_score": 24.18064567880547}, {"code": "def encode(self, x, quantize=False)\n\t\n    x = self.in_block(x)\n    if quantize:\n        z_q_x, (vq_loss, commit_loss), indices = self.vq(x, self.codebook.weight.detach())\n        loss = vq_loss + commit_loss\n        return z_q_x, x, indices, loss\n    return x\n\n", "CodeBleu_score": 32.74480713011212}, {"code": "def encode(self, x, quantize=False)\n\t\n    if quantize:\n        z_e_x, (vq_loss, commit_loss), indices = self.encode(x, get_losses=True)\n        z_q_x = self.decode(indices)\n        return z_q_x, z_e_x, indices, vq_loss + commit_loss\n    else:\n        return self.encode(x, get_losses=False)\n\n", "CodeBleu_score": 43.38900440351191}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.store(self.parameters())\n        self.copy_to(self.model)\n        if context:\n            self.log.info(f\"{context} | using EMA weights\")\n    yield\n    if self.ema_enabled:\n        self.restore(self.parameters())\n        if context:\n            self.log.info(f\"{context} | restoring model parameters\")", "CodeBleu_score": 50.512771314038055}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_used:\n        self.store(self.parameters())\n        self.copy_to(self.model)\n        if context is not None:\n            self.logpy.info(f\"{context} (EMA)\")\n    yield\n    if self.ema_used:\n        self.restore(self.parameters())\n        if context is not None:\n            self.logpy.info(f\"{context} (restored)\")\n\n", "CodeBleu_score": 58.41933897571816}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is not None:\n        self.logpy.info(f\"{context} | Switch to EMA weights\")\n    self.store(self.parameters())\n    self.copy_to(self.model)\n    yield\n    self.restore(self.parameters())\n    if context is not None:\n        self.logpy.info(f\"{context} | Restore original weights\")", "CodeBleu_score": 50.07355651582126}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn * gate_msa\n    x = self.norm1(x)\n    x = modulate(x, shift_mlp, scale_mlp)\n    x = self.mlp(x) * gate_mlp.unsqueeze(1)\n    return x\n\n\n", "CodeBleu_score": 44.771509125402076}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + attn\n    x = self.norm1(x)\n    x = modulate(x, shift_mlp, scale_mlp)\n    x = self.mlp(x) * gate_mlp.unsqueeze(1)\n    x = self.norm2(x)\n    return x", "CodeBleu_score": 46.907247111050744}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    x = x + gate_msa * attn\n    x = self.norm1(x)\n    x = modulate(x, shift_mlp, scale_mlp)\n    x = self.mlp(x) * gate_mlp.unsqueeze(1)\n    return x", "CodeBleu_score": 44.864379264601986}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    # context\n    qkv_c = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n    qkv = torch.cat([qkv_c[0], qkv_x[0]], dim=1), torch.cat([qkv_c[1], qkv_x[1]], dim=1), torch.cat([qkv_c[2], qkv_x[2]], dim=1)\n    attn = optimized_attention(qkv, c)\n    attn_c, attn_x = attn[:, :context.shape[1]], attn[:, context.shape[1]:]\n    attn_c = context_block.post_attention(attn_c)\n    attn_x = x_block.post_attention(attn_x)\n    context = context + attn_c\n    x = x + attn_x\n    return context, x\n\n", "CodeBleu_score": 20.379175947733348}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    # Process context and x through their respective pre-attention blocks\n    qkv_context = context_block.pre_attention(context)\n    qkv_x = x_block.pre_attention(x)\n\n    # Concatenate qkv tensors\n    qkv = torch.cat((qkv_context, qkv_x), dim=1)\n\n    # Apply optimized attention\n    qkv = optimized_attention(qkv, c.num_heads)\n\n    # Split attention results back into context and x parts\n    qkv_context, qkv_x = qkv.chunk(2, dim=1)\n\n    # Process context and x parts through their respective post-attention blocks\n    context = context_block.post_attention(qkv_context)\n    x = x_block.post_attention(qkv_x)\n\n    return context, x\n\n", "CodeBleu_score": 12.701812826722335}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    context_qkv, context_intermediate = context_block.pre_attention(context)\n    x_qkv, x_intermediate = x_block.pre_attention(x)\n    qkv = torch.cat([context_qkv, x_qkv], dim=1)\n    attention_result = optimized_attention(qkv, c.num_heads)\n    context_result, x_result = split_qkv(attention_result, context_qkv.shape[2])\n    if context_block.pre_only:\n        context_result = context_block.post_attention(context_result)\n        x_result = x_block.post_attention(x_result)\n    else:\n        context_result = context_block.post_attention(context_result)\n        x_result = x_block.post_attention(x_result)\n    return context_result, x_result\n\n", "CodeBleu_score": 25.902161124524838}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        # zero pad\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\n", "CodeBleu_score": 77.21369170165848}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        # zero pad\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    return emb\n\n\n\n\n\n", "CodeBleu_score": 77.21369170165848}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    assert len(timesteps.shape) == 1\n    half_dim = embedding_dim // 2\n    emb = math.log(10000) / (half_dim - 1)\n    emb = torch.exp(torch.arange(half_dim, dtype=torch.float32) * -emb)\n    emb = timesteps[:, None] * emb[None, :]\n    emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n    if embedding_dim % 2 == 1:\n        # zero pad\n        emb = torch.nn.functional.pad(emb, (0, 1, 0, 0))\n    assert emb.shape == (timesteps.shape[0], embedding_dim)\n    return emb\n\n", "CodeBleu_score": 79.60681561792701}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n\n    # Reshape the tensors to prepare for attention computation\n    q = q.view(q.shape[0], q.shape[1], q.shape[2] * q.shape[3]).transpose(1, 2)\n    k = k.view(k.shape[0], k.shape[1], k.shape[2] * k.shape[3]).transpose(1, 2)\n    v = v.view(v.shape[0], v.shape[1], v.shape[2] * v.shape[3]).transpose(1, 2)\n\n    # Compute attention using PyTorch's scaled dot-product attention\n    try:\n        out = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=0.0, is_causal=False)\n    except model_management.OOM_EXCEPTION as e:\n        # If out-of-memory (OOM) exception occurs, switch to slice attention as a fallback\n        logging.warning(\"out of memory error, falling back to slice attention\")\n        out = slice_attention(q, k, v)\n\n    # Reshape the output tensor back to the original dimensions\n    out = out.transpose(1, 2).view(q.shape[0], q.shape[2], q.shape[3], v.shape[2])\n\n    return out\n\n", "CodeBleu_score": 46.28704732111312}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], q.shape[2] * q.shape[3]).transpose(1, 2)\n    k = k.view(k.shape[0], k.shape[1], k.shape[2] * k.shape[3]).transpose(1, 2)\n    v = v.view(v.shape[0], v.shape[1], v.shape[2] * v.shape[3]).transpose(1, 2)\n\n    out = scaled_dot_product_attention(q, k, v)\n    out = out.transpose(1, 2).contiguous().view(q.shape[0], q.shape[1], q.shape[2], q.shape[3])\n\n    return out\n\n", "CodeBleu_score": 24.95278192491953}, {"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.view(q.shape[0], q.shape[1], q.shape[2] * q.shape[3]).transpose(1, 2)\n    k = k.view(k.shape[0], k.shape[1], k.shape[2] * k.shape[3]).transpose(1, 2)\n    v = v.view(v.shape[0], v.shape[1], v.shape[2] * v.shape[3]).transpose(1, 2)\n\n    try:\n        out = scaled_dot_product_attention(q, k, v)\n    except model_management.OOM_EXCEPTION as e:\n        logging.warning(\"out of memory error, falling back to slice attention\")\n        out = slice_attention(q, k, v)\n\n    out = out.transpose(1, 2).contiguous()\n    out = out.view(q.shape[0], q.shape[2], q.shape[3], v.shape[2])\n\n    return out\n\n", "CodeBleu_score": 37.76204710073211}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        control_value = control.pop(0)\n        try:\n            h.add_control(control_value, name)\n        except:\n            logging.warning(f\"Control {name} {control_value} not added to gate\")\n    return h\n\n", "CodeBleu_score": 32.82712955599243}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        try:\n            control_value = control.pop(0)\n            h.add_control(control_value, name)\n        except Exception as e:\n            logging.warning(f\"Error applying control {name} with value {control_value}: {e}\")\n    return h\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.429939865929825}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        control = control.pop(0)\n        try:\n            h.add_control(control, name)\n        except:\n            logging.warning(f\"Could not add control {name} to {h}\")\n    return h\n\n", "CodeBleu_score": 32.22290996345395}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings).to(indices)\n    min_encodings.scatter_(1, indices[:, None], 1)\n\n    # get quantized latent vectors\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n\n    if shape is not None:\n        z_q = z_q.view(shape)\n        # reshape back to match original input shape\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 67.93089875771908}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.num_embeddings).to(indices)\n    min_encodings.scatter_(1, indices[:, None], 1)\n\n    # get quantized latent vectors\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n\n    if shape is not None:\n        z_q = z_q.view(shape)\n        # reshape back to match original input shape\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n\n    return z_q\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 67.93089875771908}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    min_encodings = torch.zeros(indices.shape[0], self.n_e).to(indices)\n    min_encodings.scatter_(1, indices[:,None], 1)\n    z_q = torch.matmul(min_encodings.float(), self.embedding.weight)\n    if shape is not None:\n        z_q = z_q.view(shape)\n        z_q = z_q.permute(0, 3, 1, 2).contiguous()\n    return z_q", "CodeBleu_score": 67.86977258452447}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    noises = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noises\n\n", "CodeBleu_score": 38.244827373278504}, {"code": "def make_noise(self)\n\t\n    noises = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noises\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.244827373278504}, {"code": "def make_noise(self)\n\t\n    noises = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, int(self.log_size) + 1):\n        for _ in range(2):\n            noises.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noises\n\n\n\n\n", "CodeBleu_score": 38.244827373278504}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    latent_in = torch.randn(\n        num_latent, self.style_dim, device=self.tmp_device\n    )\n    latent = self.style(latent_in).mean(0, keepdim=True)\n    return latent\n\n\n\n", "CodeBleu_score": 32.74787738960471}, {"code": "def mean_latent(self, num_latent)\n\t\n    return self.style_mlp(torch.randn(num_latent, self.style_dim)).mean(0, keepdim=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 15.65026608364388}, {"code": "def mean_latent(self, num_latent)\n\t\n    return self.style_mlp(torch.randn(num_latent, self.style_dim)).mean(0, keepdim=True)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 15.65026608364388}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    img = img.astype(np.float32)\n    shift = np.random.uniform(-shift, shift, size=3)\n    jittered_img = np.clip(img + shift, 0, 1)\n    return jittered_img\n\n", "CodeBleu_score": 28.40208186705245}, {"code": "def color_jitter(img, shift)\n\t\n    img = img.astype(np.float32)\n    shift = np.random.uniform(-shift, shift, size=(1, 1, 3))\n    img += shift\n    img = np.clip(img, 0, 1)\n    return img.astype(np.float32)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.923542024575845}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = np.random.uniform(-shift, shift, size=img.shape)\n    jittered_img = np.clip(img + jitter, 0, 1)\n    return jittered_img\n\n\n", "CodeBleu_score": 35.383522371129125}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'face' in data:\n        self.face = data['face']\n        self.leye = data['face'][:, 0:2]\n        self.reye = data['face'][:, 2:4]\n        self.mouth = data['face'][:, 4:6]\n    return", "CodeBleu_score": 44.74544304161142}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data:\n        self.gt = data['gt']\n    if 'facial_components' in data:\n        self.facial_components = data['facial_components']\n        self.left_eye = data['facial_components']['left_eye']\n        self.right_eye = data['facial_components']['right_eye']\n        self.mouth = data['facial_components']['mouth']\n\n", "CodeBleu_score": 42.08486803639654}, {"code": "def feed_data(self, data)\n\t\n    self.lq = data['lq']\n    if 'gt' in data.keys():\n        self.gt = data['gt']\n    if 'face_landmarks' in data.keys():\n        self.left_eye = data['face_landmarks'][:, 36:42]\n        self.right_eye = data['face_landmarks'][:, 42:48]\n        self.mouth = data['face_landmarks'][:, 48:68]\n\n", "CodeBleu_score": 38.7403903708952}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    # Construct the image pyramid\n    pyramid_gt = [self.gt_image]\n    for i in range(1, self.pyramid_levels):\n        pyramid_gt.insert(0, F.interpolate(pyramid_gt[0], scale_factor=0.5, mode='bilinear', align_corners=False))\n    return pyramid_gt\n\n", "CodeBleu_score": 27.345653506203053}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = []\n    img_pyramid.insert(0, self.gt_img)\n    for i in range(1, self.pyramid_levels):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode=\"bilinear\"))\n    return img_pyramid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.668267375858235}, {"code": "def construct_img_pyramid(self)\n\t\n    self.pyramid_gt = [self.gt]\n    for i in range(1, self.n_scale):\n        img = F.interpolate(self.gt, scale_factor=1.0 / (2.0 ** i), mode='bilinear', align_corners=False)\n        self.pyramid_gt.insert(0, img)\n    return self.pyramid_gt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.65138355489061}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    # Save network\n    self.save_network(epoch, current_iter)\n    # Save training state\n    self.save_training_state(epoch, current_iter)", "CodeBleu_score": 11.730051474060335}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(self.gen, 'gen', epoch, current_iter)\n    self.save_network(self.gen_ema, 'gen_ema', epoch, current_iter)\n    self.save_network(self.disc, 'disc', epoch, current_iter)\n\n    if self.facial_discriminators:\n        self.save_network(self.disc_left, 'disc_left', epoch, current_iter)\n        self.save_network(self.disc_right, 'disc_right', epoch, current_iter)\n        self.save_network(self.disc_mouth, 'disc_mouth', epoch, current_iter)\n\n    self.save_training_state(epoch, current_iter)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.541026941627464}, {"code": "def save(self, epoch, current_iter)\n\t\n    self.save_network(epoch, current_iter)\n    self.save_training_state(epoch, current_iter)", "CodeBleu_score": 11.730051474060335}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        if os.path.isfile(item_path) or os.path.islink(item_path):\n            try:\n                os.unlink(item_path)\n            except Exception as e:\n                print(f\"Failed to delete {item_path}. Reason: {e}\")\n        elif os.path.isdir(item_path):\n            try:\n                shutil.rmtree(item_path)\n            except Exception as e:\n                print(f\"Failed to delete {item_path}. Reason: {e}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.22822450764525}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path) or os.path.islink(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Failed to delete {item_path}. Reason: {e}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.3909785745615}, {"code": "def clean_folder(folder)\n\t\n    for the_file in os.listdir(folder):\n        file_path = os.path.join(folder, the_file)\n        try:\n            if os.path.isfile(file_path):\n                os.unlink(file_path)\n            elif os.path.isdir(file_path):\n                shutil.rmtree(file_path)\n            elif os.path.islink(file_path):\n                os.unlink(file_path)\n        except Exception as e:\n            print(f\"Failed to delete {file_path}. Reason: {e}\")", "CodeBleu_score": 58.267358106819735}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    if self.batch_size < len(self.memory):\n        batch_size = self.batch_size\n    else:\n        batch_size = len(self.memory)\n    batch = random.sample(self.memory, batch_size)\n    for experience in batch:\n        self.memory.remove(experience)\n    return batch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.5548234571982}, {"code": "def next_batch(self, sample_size=1)\n\t\n    batch = []\n    sample_size = min(sample_size, len(self.memory))\n    batch = random.sample(self.memory, sample_size)\n    for sample in batch:\n        self.memory.remove(sample)\n    return batch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.61241791745912}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.experiences):\n        sample_size = len(self.experiences)\n    batch = random.sample(self.experiences, sample_size)\n    self.experiences = [x for x in self.experiences if x not in batch]\n    return batch\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 72.3484173821077}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten_configs(self.all_configs)\n    feature_val = []\n    configs = []\n    for key, val in flattened_ds_config.items():\n        if isinstance(val, int) or isinstance(val, float):\n            feature_val.append(val)\n        else:\n            feature_val.append(1)\n            configs.append(key)\n    feature_val = np.array(feature_val)\n    feature_val = feature_val.reshape(1, -1)\n    estimated_costs = self.cost_model.predict(feature_val)\n    estimated_costs = estimated_costs.flatten()\n    if self.metric == \"latency\":\n        estimated_costs = 1 / estimated_costs\n    estimated_top_configs = np.argsort(estimated_costs)\n    if self.metric == \"accuracy\":\n        estimated_top_configs = estimated_top_configs[::-1]\n    return estimated_top_configs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.836023661574085}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_ds_config = self.flatten(self.all_configs)\n    feature_val = []\n    for config in flattened_ds_config:\n        configs = []\n        for key, value in config.items():\n            if isinstance(value, dict):\n                for k, v in value.items():\n                    configs.append(v)\n            else:\n                configs.append(value)\n        feature_val.append(configs)\n    feature_val = np.array(feature_val)\n    if self.metric == \"cost\":\n        estimated_top_configs = np.argsort(self.cost_model.predict(feature_val))\n    else:\n        estimated_top_configs = np.argsort(self.cost_model.predict(feature_val))[::-1]\n    return estimated_top_configs[: self.top_k]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.79898206418953}, {"code": "def find_estimated_top_configs(self)\n\t\n    flattened_configs = []\n    feature_val = []\n    for ds_config in self.all_configs:\n        flattened_ds_config = flatten(ds_config)\n        flattened_configs.append(flattened_ds_config)\n        feature_val.append([v for v in flattened_ds_config.values()])\n\n    feature_val = np.array(feature_val)\n    if self.metric == \"accuracy\":\n        cost_model = self.cost_model\n    elif self.metric == \"latency\":\n        cost_model = self.latency_model\n    else:\n        raise ValueError(\"Invalid metric\")\n\n    estimated_cost = cost_model.predict(feature_val)\n\n    if self.metric == \"accuracy\":\n        estimated_top_configs = np.argsort(estimated_cost)[::-1]\n    elif self.metric == \"latency\":\n        estimated_top_configs = np.argsort(estimated_cost)\n    else:\n        raise ValueError(\"Invalid metric\")\n\n    return estimated_top_configs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.928664888467544}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.85068910384324}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.85068910384324}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.85068910384324}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        result = subprocess.Popen(\n            self.optimal_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True\n        )\n        result.wait()\n        logger.info(f\"Autotuning finished. Command: {self.optimal_cmd}\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 56.97380710498049}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Autotuning successfully finished.\")\n    else:\n        logger.info(\"Autotuning did not find an optimal configuration.\")", "CodeBleu_score": 53.8576957995697}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\n            f\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.218059314972145}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp_id = exp[\"id\"]\n    exp_args = exp[\"args\"]\n    exp_script = exp[\"script\"]\n    user_args = exp_args[\"user_args\"]\n    # set master port and result dir\n    exp_args[\"master_port\"] = self.get_next_free_port()\n    exp_args[\"result_dir\"] = self.get_result_dir(exp_id)\n    # update user args based on argument mappings\n    user_args = self.update_user_args(user_args, exp_args[\"argument_mappings\"])\n    # start experiment in a new thread\n    t = threading.Thread(\n        target=self.start_experiment,\n        args=(exp_script, user_args, exp_args, reservations),\n    )\n    t.start()\n    # store running experiment details with timestamp\n    self.running_experiments[exp_id] = {\n        \"start_time\": time.time(),\n        \"exp_script\": exp_script,\n        \"user_args\": user_args,\n        \"exp_args\": exp_args,\n        \"reservations\": reservations,\n    }\n\n", "CodeBleu_score": 25.750658612670573}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp_id = exp[\"id\"]\n    self.set_master_port(exp_id)\n    self.set_result_dir(exp_id)\n    self.update_user_args(exp)\n    t = threading.Thread(\n        target=self.run_exp,\n        args=(exp[\"script\"], self.user_args, reservations),\n    )\n    t.start()\n    self.running_experiments[exp_id] = {\n        \"start_time\": time.time(),\n        \"thread\": t,\n        \"exp\": exp,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 18.67635818317206}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.logger.info(f\"Starting experiment {exp['name']}\")\n    exp[\"master_port\"] = self.find_free_port()\n    exp[\"result_dir\"] = os.path.join(self.result_dir, exp[\"name\"])\n    self.update_user_args(exp)\n    t = threading.Thread(target=self.run_experiment, args=(exp,))\n    t.start()\n    self.running_experiments[exp[\"name\"]] = time.time()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.02990503589323}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 3.5273972602739727}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if ranks is None:\n        ranks = [dist.get_rank()]\n    if dist.is_initialized():\n        if dist.get_rank() in ranks:\n            logger.debug(message)\n            with open(path, \"a\") as outfile:\n                json.dump(message, outfile)\n                outfile.write(\"", "CodeBleu_score": 28.693858738380346}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if ranks is None:\n        ranks = [0]\n    if self.dist.is_initialized() and self.dist.get_rank() not in ranks:\n        return\n    if self.logger is not None:\n        if ranks is not None:\n            message = f\"{message} (rank: {self.dist.get_rank()})\"\n        self.logger.debug(message)\n    if self.outfile is not None and path is not None:\n        with open(path, \"a\") as f:\n            json.dump(message, f)\n            f.write(\"", "CodeBleu_score": 29.782392645631134}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if self._layer_files_exist(layer_index):\n        assert layer_index >= 1, \"layer_index must be >= 1\"\n        tp_degree = self._tp_degrees[layer_index - 1]\n        prefix = f\"{self._prefix}_layer{layer_index}_\"\n        files = self._get_files_with_prefix(prefix)\n        partitioned_files = self._partition_data(files, tp_degree)\n        return {i: files for i, files in enumerate(partitioned_files)}\n    else:\n        return None\n", "CodeBleu_score": 36.120394992892045}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if self.layer_files is None:\n        return {}\n    if layer_index >= len(self.layer_files):\n        return {}\n    prefix = self.layer_files[layer_index].split(\".\")[0]\n    files = get_files_with_prefix(prefix)\n    if len(files) == 0:\n        return {}\n    data_map = partition_data(files, self.tp_degree)\n    return {idx: files for idx, files in enumerate(data_map)}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.804429760841685}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self._has_layer_files(layer_index):\n        raise ValueError(f\"No layer files found for layer {layer_index}\")\n\n    tp_degree = self.tp_degree\n    if tp_degree <= 0:\n        raise ValueError(\"Invalid tp_degree value. tp_degree must be a positive integer.\")\n\n    prefix = f\"{layer_index}_\"\n    files = self._get_files_with_prefix(prefix)\n    partitioned_files = self._partition_data(files, tp_degree)\n\n    tp_other_layer_map = {\n        i: partitioned_files[i] for i in range(tp_degree)\n    }\n\n    return tp_other_layer_map\n\n", "CodeBleu_score": 31.704836188438478}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    system_info = {\n        'Operating System': platform.system(),\n        'Architecture': platform.architecture()[0],\n        'Version': platform.version(),\n        'Processor': platform.processor(),\n        'Python Version': platform.python_version()\n    }\n    return system_info\n\n\n\n", "CodeBleu_score": 48.732219753859006}, {"code": "def system_info()\n\t\n    system_info = {}\n    system_info[\"Operating System\"] = platform.system()\n    system_info[\"Architecture\"] = platform.architecture()[0]\n    system_info[\"Version\"] = platform.version()\n    system_info[\"Processor\"] = platform.processor()\n    system_info[\"Python Version\"] = platform.python_version()\n    return system_info\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.153123189958094}, {"code": "def system_info()\n\t\n    system_info = {\n        \"Operating System\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version()\n    }\n    return system_info\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.39546124963006}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    import torch\n    # Check if CUDA is available\n    cuda_available = torch.cuda.is_available()\n    # Get the number of available GPUs\n    gpu_count = torch.cuda.device_count()\n    # Get the name of the current GPU\n    current_device = torch.cuda.current_device()\n    # Get the name of the current GPU\n    current_device_name = torch.cuda.get_device_name(current_device)\n    # Get the CUDA version\n    cuda_version = torch.version.cuda\n    # Print the results\n    print(\"CUDA Available:\", cuda_available)\n    print(\"Number of GPUs:\", gpu_count)\n    print(\"Current GPU:\", current_device_name)\n    print(\"CUDA Version:\", cuda_version)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.646531220364768}, {"code": "def cuda_info()\n\t\n    print(\"CUDA Version:\", torch.version.cuda)\n    print(\"Device Count:\", torch.cuda.device_count())\n    print(\"Current Device:\", torch.cuda.current_device())\n    print(\"Device Name:\", torch.cuda.get_device_name(0))\n    print(\"Device Capability:\", torch.cuda.get_device_capability(0))\n    print(\"Device Properties:\", torch.cuda.get_device_properties(0))\n    print(\"CUDA Available:\", torch.cuda.is_available())\n    print(\"CUDA Initialized:\", torch.cuda.is_initialized())\n    print(\"CUDA Memory Allocated:\", torch.cuda.memory_allocated())\n    print(\"CUDA Memory Cached:\", torch.cuda.memory_cached())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Reserved:\", torch.cuda.memory_reserved())\n    print(\"CUDA Memory Allocated Summary:\", torch.cuda.memory_allocated_stats())\n    print(\"CUDA Memory Reserved Summary:\", torch.cuda.memory_reserved_stats())\n    print(\"CUDA Memory Statistics:\", torch.cuda.memory_stats())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.cuda.memory_summary())\n    print(\"CUDA Memory Summary:\", torch.", "CodeBleu_score": 25.665777304106857}, {"code": "def cuda_info()\n\t\n    cuda_available = is_available()\n    cuda_version = get_cuda_version()\n    device_name = get_device_name(0)\n    device_count = torch.cuda.device_count()\n    device_range = range(device_count)\n    device_list = [get_device_name(i) for i in device_range]\n    return cuda_available, cuda_version, device_name, device_count, device_list\n\n", "CodeBleu_score": 25.18079528135093}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name = encoder_manager.config.class_id_to_class_name\n\n    accuracy_per_class = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        true_class_name = item[class_name_key]\n\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        embedding = torch.FloatTensor(embedding).unsqueeze(0).to(encoder_manager.device)\n\n        if encoder_manager.classifier is not None:\n            class_id = encoder_manager.classifier.predict(embedding)\n            if class_id_to_class_name is not None:\n                predicted_class_name = class_id_to_class_name[class_id]\n            else:\n                predicted_class_name = class_id\n        else:\n            predicted_class_name = None\n\n        if true_class_name not in accuracy_per_class:\n            accuracy_per_class[true_class_name] = []\n\n        if predicted_class_name is not None:\n            accuracy_per_class[true_class_name].append(\n                int(predicted_class_name == true_class_name)\n            )\n\n    print(\"Accuracy per class:\")\n    for class_name, accuracies in accuracy_per_class.items():\n        if len(accuracies) > 0:\n            accuracy = sum(accuracies) / len(accuracies)\n            print(f\"{class_name}: {accuracy:.2f}\")\n        else:\n            print(f\"{class_name}: N/A (no predictions)\")\n\n    accuracies = [\n        accuracy for accuracies in accuracy_per_class.values() for accuracy in accuracies\n    ]\n    if len(accuracies) > 0:\n        average_accuracy = sum(accuracies) / len(accuracies)\n        print(f\"Average accuracy: {average_accuracy:.", "CodeBleu_score": 39.740508598386235}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name = encoder_manager.config.class_id_to_class_name\n    total_accuracy = 0\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if encoder_manager.config.class_name_key in item:\n            class_name = item[class_name_key]\n            if class_name not in class_acc_dict:\n                class_acc_dict[class_name] = {\"correct\": 0, \"total\": 0}\n            class_acc_dict[class_name][\"total\"] += 1\n            if encoder_manager.config.class_id_to_class_name is not None:\n                class_id = item[encoder_manager.config.class_id_key]\n                class_name = class_id_to_class_name[class_id]\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class_name in class_acc_dict:\n                class_acc_dict[class_name][\"total\"] += 1\n            if class", "CodeBleu_score": 28.07227399192777}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.config.class_name_key\n    class_id_to_class_name = encoder_manager.config.class_id_to_class_name\n\n    accuracy_per_class = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[encoder_manager.config.audio_file_key]\n        class_name = item[class_name_key]\n\n        if class_id_to_class_name is not None:\n            class_name = class_id_to_class_name[class_name]\n\n        audio_embedding = encoder_manager.compute_embedding_from_clip(\n            audio_file\n        )\n        audio_embedding = torch.FloatTensor(audio_embedding).unsqueeze(0)\n\n        predicted_class_name = encoder_manager.predict_class(audio_embedding)\n\n        if class_name not in accuracy_per_class:\n            accuracy_per_class[class_name] = []\n\n        accuracy_per_class[class_name].append(\n            int(predicted_class_name == class_name)\n        )\n\n    for class_name, accuracies in accuracy_per_class.items():\n        print(\n            f\"Accuracy for class {class_name}: {sum(accuracies) / len(accuracies)}\"\n        )\n\n    print(\n        f\"Average accuracy: {sum(sum(v) for v in accuracy_per_class.values()) / sum(len(v) for v in accuracy_per_class.values())}\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.410812167599}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # adjust the output path\n    out_path = audio_path.replace(input_dir, output_dir)\n\n    # if the file already exists and force is not specified, return the output path and a False flag\n    if os.path.exists(out_path) and not force:\n        print(f\"> File {out_path} already exists. Skipping.\")\n        return out_path, False\n\n    # create the necessary directory structure\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n    # remove silence from the audio\n    out_path, is_speech = remove_silence(\n        model_and_utils,\n        audio_path,\n        out_path,\n        vad_sample_rate=vad_sample_rate,\n        trim_just_beginning_and_end=trim_just_beginning_and_end,\n        use_cuda=use_cuda,\n    )\n\n    # return the output path and a flag indicating if speech was detected\n    return out_path, is_speech\n\n\n", "CodeBleu_score": 44.886765855541945}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # adjust output path\n    output_path = audio_path.replace(INPUT_DIR, OUTPUT_DIR)\n    output_path = output_path.replace(AUDIO_EXT, OUTPUT_EXT)\n    output_path = output_path.replace(f\"{INPUT_DIR}/\", \"\")\n    output_path = join(OUTPUT_DIR, output_path)\n\n    # if already exists and force is not specified\n    if exists(output_path) and not FORCE:\n        return output_path, False\n\n    # create the necessary directory structure\n    mkdir(dirname(output_path))\n\n    # remove silence from the audio\n    output_path, is_speech = remove_silence(\n        model_and_utils, audio_path, output_path, VAD_SAMPLE_RATE, TRIM_BEGINNING_AND_END, USE_CUDA\n    )\n    return output_path, is_speech\n\n", "CodeBleu_score": 38.69079609547731}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t\n    # adjust output path\n    out_path = audio_path.replace(INPUT_DIR, OUTPUT_DIR)\n\n    # if already exists and force is not specified\n    if os.path.exists(out_path) and not force:\n        return out_path, False\n\n    # create the necessary directory structure\n    os.makedirs(os.path.dirname(out_path), exist_ok=True)\n\n    # remove silence from the audio\n    out_path, is_speech = remove_silence(\n        model_and_utils, audio_path, out_path, vad_sample_rate=8000, trim_just_beginning_and_end=True, use_cuda=False\n    )\n\n    return out_path, is_speech\n\n", "CodeBleu_score": 40.07316492073405}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is not None:\n        copytree(input_dir, output_dir, dirs_exist_ok=True)\n        input_dir = output_dir\n    files = glob.glob(os.path.join(input_dir, f\"**/*.{file_ext}\"), recursive=True)\n    pbar = tqdm(total=len(files))\n    with Pool(n_jobs) as p:\n        for _ in p.imap_unordered(\n            partial(resample_file, output_sr=output_sr, output_dir=output_dir), files\n        ):\n            pbar.update()\n    pbar.close()\n    print(\"Done\")\n\n", "CodeBleu_score": 47.22230560210397}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir:\n        shutil.copytree(input_dir, output_dir)\n        input_dir = output_dir\n\n    audio_files = glob.glob(os.path.join(input_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    with tqdm(total=len(audio_files), desc=\"Resampling audio files\") as pbar:\n        with Pool(n_jobs) as p:\n            for _ in p.imap_unordered(resample_file, [(file, output_sr, output_dir) for file in audio_files]):\n                pbar.update()\n\n    print(\"Resampling complete.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.24818687735773}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is not None:\n        copytree(input_dir, output_dir)\n        input_dir = output_dir\n\n    audio_files = glob.glob(os.path.join(input_dir, \"**\", f\"*.{file_ext}\"), recursive=True)\n    print(f\"Found {len(audio_files)} audio files.\")\n\n    with Pool(n_jobs) as p:\n        with tqdm(total=len(audio_files)) as pbar:\n            for _ in p.imap_unordered(\n                partial(\n                    resample_file,\n                    output_sr=output_sr,\n                    output_dir=output_dir,\n                ),\n                audio_files,\n            ):\n                pbar.update()\n\n    print(\"Resampling complete.\")\n\n", "CodeBleu_score": 56.10912844315135}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(\n                num_classes_in_batch, num_utter_per_class, inputs.shape[1], inputs.shape[2]\n            )\n            inputs = inputs.reshape(\n                num_classes_in_batch * num_utter_per_class, inputs.shape[2], inputs.shape[3]\n            )\n            labels = labels.view(\n                num_classes_in_batch, num_utter_per_class, labels.shape[1]\n            )\n            labels = labels.view(\n                num_classes_in_batch * num_utter_per_class, labels.shape[1]\n            )\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            if batch_idx == 0:\n                embeddings = outputs.detach().cpu().numpy()\n                fig = plot_embeddings(embeddings, num_classes_in_batch)\n                dashboard_logger.eval_figures(fig, global_step)\n\n    avg_loss = total_loss / len(data_loader)\n    dashboard_logger.eval_stats(\n        {\n            \"eval_loss\": avg_loss,\n        },\n        global_step,\n    )\n    return avg_loss\n\n", "CodeBleu_score": 40.81240128928242}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    total_loss = 0.0\n    total_embeddings = []\n    total_labels = []\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.view(\n                inputs.shape[0] * inputs.shape[1], inputs.shape[2], inputs.shape[3]\n            )\n            labels = labels.view(\n                labels.shape[0] * labels.shape[1], labels.shape[2], labels.shape[3]\n            )\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            outputs = outputs.view(\n                inputs.shape[0] // labels.shape[0],\n                labels.shape[0],\n                labels.shape[1],\n                labels.shape[2],\n            )\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            total_embeddings.append(outputs.detach().cpu())\n            total_labels.append(labels.detach().cpu())\n\n    avg_loss = total_loss / len(data_loader)\n    total_embeddings = torch.cat(total_embeddings, dim=0)\n    total_labels = torch.cat(total_labels, dim=0)\n    dashboard_logger.eval_stats(\n        global_step,\n        avg_loss,\n        total_embeddings,\n        total_labels,\n        num_classes_in_batch=total_labels.shape[0],\n    )\n    fig = plot_embeddings(total_embeddings, total_labels.shape[0])\n    dashboard_logger.eval_figures(fig, global_step)\n    return avg_loss", "CodeBleu_score": 35.23857810401852}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    for batch_idx, (inputs, labels) in enumerate(data_loader):\n        inputs = inputs.cuda()\n        labels = labels.cuda()\n        inputs = torch.transpose(inputs, 1, 2)\n        inputs = inputs.reshape(\n            inputs.shape[0] * inputs.shape[1], inputs.shape[2]\n        )  # (num_classes*num_utter, mel_spec_dim)\n        labels = labels.view(\n            -1, num_utter_per_class\n        )  # (num_classes, num_utter)\n        with torch.no_grad():\n            outputs = model(inputs)\n            loss = criterion(outputs, labels.view(-1))\n            eval_loss += loss.item()\n        if batch_idx == 0:\n            embeddings = outputs.detach().cpu().numpy()\n            fig = plot_embeddings(embeddings, num_classes_in_batch)\n            dashboard_logger.eval_figures(fig, global_step)\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(\n        {\"loss\": eval_loss, \"step\": global_step}\n    )  # log the evaluation loss\n    return eval_loss", "CodeBleu_score": 42.03592096283078}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class_name = to_camel(model_name) + \"Config\"\n    if model_name == \"xtts\":\n        from TTS.vocoder.configs.xtts_config import XTTSConfig\n\n        return XTTSConfig\n\n    try:\n        return find_module(\"TTS.vocoder.configs\", config_class_name)\n    except ModuleNotFoundError:\n        pass\n    try:\n        return find_module(\"TTS.vocoder.models\", config_class_name)\n    except ModuleNotFoundError:\n        pass\n    try:\n        return find_module(\"TTS.vocoder.layers\", config_class_name)\n    except ModuleNotFoundError:\n        pass\n    raise ModuleNotFoundError(f\" [!] Config for {model_name} could not be found.\")\n\n", "CodeBleu_score": 40.50156085341329}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class = None\n    config_name = module_name_to_class_name(model_name) + \"Config\"\n    try:\n        config_class = find_module(\"tts.configs\", config_name.lower())\n    except ModuleNotFoundError:\n        pass\n    if config_class is None:\n        raise ModuleNotFoundError(f\" [!] Config class cannot be found for {model_name}.\")\n    return config_class\n\n", "CodeBleu_score": 37.68756849992291}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class_name = to_camel(model_name) + \"Config\"\n    if model_name == \"xtts\":\n        config_class = importlib.import_module(\"TTS.vocoder.configs.xtts_config\").XTTSConfig\n        return config_class\n    else:\n        config_class = None\n        for path in config_paths:\n            try:\n                config_class = importlib.import_module(path + \".\" + config_class_name)\n                break\n            except ModuleNotFoundError:\n                pass\n        if config_class is None:\n            raise ModuleNotFoundError(f\"Config class for model {model_name} cannot be found.\")\n        return config_class\n\n", "CodeBleu_score": 47.152441548833664}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1].lower()\n    if ext == \".yaml\":\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as yaml_file:\n            config_dict = yaml.safe_load(yaml_file)\n    elif ext in {\".json\", \".json5\"}:\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise TypeError(f\" [!] Unknown config file type. Only YAML and JSON are supported. Given: {config_path}\")\n\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 54.3963747669694}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1].lower()\n    if ext == \".yaml\":\n        with fsspec.open(config_path, \"r\", encoding=\"utf-8\") as yaml_file:\n            config_dict = yaml.safe_load(yaml_file)\n    elif ext in {\".json\", \".jsonc\"}:\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise TypeError(f\" [!] Unknown config file type {ext}. Only JSON and YAML are supported.\")\n\n    # process the model name and update the version\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class.from_dict(config_dict)\n    config.model = model_name\n    return config", "CodeBleu_score": 52.42500268010346}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = {}\n    ext = splitext(config_path)[-1].lower()\n    if ext == \".yaml\":\n        config_dict.update(yaml.safe_load(open(config_path, \"r\", encoding=\"utf-8\")))\n    elif ext == \".json\":\n        config_dict.update(read_json_with_comments(config_path))\n    else:\n        raise TypeError(f\" [!] Unknown config file type {ext}\")\n\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 43.10745896121229}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath", "CodeBleu_score": 77.47690953282769}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                filePath = os.path.join(rootDir, filename)\n                yield filePath\n\n", "CodeBleu_score": 77.44616184848208}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        for filename in filenames:\n            if contains is not None and filename.find(contains) == -1:\n                continue\n            ext = filename[filename.rfind(\".\"):].lower()\n            if validExts is None or ext.endswith(validExts):\n                filePath = os.path.join(rootDir, filename)\n                yield filePath\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 77.44616184848208}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n        return \"Error: Please provide all required paths for XTTS model loading.\"\n\n    config = XttsConfig.load_json(xtts_config)\n    XTTS_MODEL = Xtts.init_from_config(config)\n    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab)\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"XTTS model loaded.\")\n    return \"XTTS model loaded.\"\n\n", "CodeBleu_score": 44.81539438075485}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: Please provide all required paths: xtts_checkpoint, xtts_config, and xtts_vocab\"\n\n    config = XttsConfig.load_json(xtts_config)\n    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab)\n\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"XTTS model loaded\")\n    return \"XTTS model loaded\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.60719655260753}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Please provide the path to the checkpoint, config, and vocab files\"\n\n    config = XttsConfig.load_json(xtts_config)\n    XTTS_MODEL.load_checkpoint(config, checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab)\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"XTTS Model Loaded\")\n    return \"XTTS Model Loaded\"\n\n", "CodeBleu_score": 45.59745522260985}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.torch_spec:\n        num_frames = int(num_frames / self.hop_length)\n    if num_frames > x.shape[0]:\n        num_frames = x.shape[0]\n    offsets = np.linspace(0, x.shape[0] - num_frames, num=num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[offset : offset + num_frames])\n    frames_batch = np.vstack(frames_batch)\n    embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n    if l2_norm:\n        embeddings = torch.nn.functional.normalize(embeddings, p=2, dim=0)\n    return embeddings\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.95191664117532}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.use_torch_spec:\n        num_frames = int(num_frames * self.hop_length / self.sample_rate)\n    num_frames = min(num_frames, x.shape[0])\n    offsets = np.linspace(0, x.shape[0] - num_frames, num=num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[offset : offset + num_frames])\n    frames_batch = np.vstack(frames_batch)\n    embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n        if l2_norm:\n            embeddings = torch.nn.functional.normalize(embeddings, dim=0)\n    return embeddings\n\n", "CodeBleu_score": 55.21767214629507}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.torch_spec:\n        num_frames = num_frames * self.hop_length\n\n    if num_frames > x.shape[1]:\n        num_frames = x.shape[1]\n\n    offsets = np.linspace(0, x.shape[1] - num_frames, num=num_eval)\n    frames_batch = []\n    for offset in offsets:\n        offset = int(offset)\n        frames_batch.append(x[:, offset : offset + num_frames])\n    frames_batch = np.vstack(frames_batch)\n    frames_batch = torch.tensor(frames_batch, dtype=torch.float32)\n    with torch.no_grad():\n        embeddings = self.model.embedding_extractor(frames_batch)\n        if return_mean:\n            embeddings = torch.mean(embeddings, dim=0, keepdim=True)\n        if l2_norm:\n            embeddings = torch.nn.functional.normalize(embeddings, dim=1, p=2)\n    return embeddings\n\n", "CodeBleu_score": 56.45081777360671}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 85.75459657510368}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 85.75459657510368}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride != 1 or self.inplanes != planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n\n", "CodeBleu_score": 85.75459657510368}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = [np.sum(num_classes_in_batch == i) for i in range(10)]\n\n    # Limit the number of classes to 10 if necessary\n    if len(num_utterances_per_class) > 10:\n        num_utterances_per_class = num_utterances_per_class[:10]\n        embeddings = embeddings[:10]\n\n    # Transform embeddings using UMAP\n    reducer = umap.UMAP()\n    umap_embeddings = reducer.fit_transform(embeddings)\n\n    # Create a scatter plot with colors representing different classes\n    fig, ax = plt.subplots(figsize=(10, 10))\n    for i in range(len(num_utterances_per_class)):\n        start = sum(num_utterances_per_class[:i])\n        end = start + num_utterances_per_class[i]\n        ax.scatter(umap_embeddings[start:end, 0], umap_embeddings[start:end, 1], label=f\"Class {i}\", s=10)\n\n    # Set plot title, adjust aspect ratio, and save the plot\n    plt.title(\"UMAP projection\")\n    ax.set_aspect('equal', 'datalim')\n    plt.savefig(\"umap\")\n\n    return fig\n\n\n\n\n", "CodeBleu_score": 40.38464691647942}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_utterances_per_class = [np.sum(num_classes_in_batch == i) for i in range(10)]\n\n    # Limit the number of classes to 10 if necessary\n    num_classes_to_plot = min(len(num_utterances_per_class), 10)\n\n    # Perform dimensionality reduction using UMAP\n    reducer = umap.UMAP()\n    reduced_embeddings = reducer.fit_transform(embeddings)\n\n    # Create a scatter plot with colors representing different classes\n    fig, ax = plt.subplots()\n    colors = plt.cm.tab10(np.arange(num_classes_to_plot) / num_classes_to_plot)\n    for i in range(num_classes_to_plot):\n        ax.scatter(reduced_embeddings[num_classes_in_batch == i, 0], reduced_embeddings[num_classes_in_batch == i, 1], color=colors[i], label=f'Class {i}')\n\n    # Set plot title and adjust aspect ratio\n    plt.title('UMAP projection')\n    ax.set_aspect('equal', 'datalim')\n\n    # Save the plot as a figure\n    plt.savefig('umap')\n\n    return fig", "CodeBleu_score": 28.009485807484268}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    num_classes = len(num_classes_in_batch)\n    if num_classes > 10:\n        num_classes = 10\n    num_utterances_per_class = [\n        sum(num_classes_in_batch[:i]) for i in range(1, num_classes + 1)\n    ]\n    labels = [\n        f\"Class {i}\" for i in range(1, num_classes + 1) for _ in range(num_utterances_per_class[i - 1])\n    ]\n    reducer = umap.UMAP()\n    embedding = reducer.fit_transform(embeddings)\n    fig, ax = plt.subplots()\n    ax.scatter(\n        embedding[:, 0], embedding[:, 1], c=np.repeat(range(num_classes), num_utterances_per_class)\n    )\n    plt.title(\"UMAP projection\")\n    ax.set_aspect(\"equal\", \"datalim\")\n    plt.savefig(\"umap\")\n    return fig\n\n", "CodeBleu_score": 41.66983159152808}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, speaker in enumerate(dvecs):\n        cos_sim_row = []\n        for utt, utterance in enumerate(speaker):\n            if self.cos_sim_type == \"cosine\":\n                new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n                # vector based cosine similarity for speed\n                cs = torch.clamp(torch.mm(utterance.unsqueeze(1).transpose(0, 1), new_centroids.transpose(0, 1)) / (torch.norm(utterance) * torch.norm(new_centroids, dim=1)), 1e-6)\n                cs_row.append(cs)\n            else:\n                raise ValueError(\"Cosine similarity type not supported yet.\")\n        cos_sim_row = torch.cat(cos_sim_row, 0)\n        cos_sim_matrix.append(cos_sim_row)\n    cos_sim_matrix = torch.stack(cos_sim_matrix, 0)\n    return cos_sim_matrix\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.75401601936413}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, speaker in enumerate(dvecs):\n        cos_sim_row = []\n        for utt, utterance in enumerate(speaker):\n            if self.oracle:\n                new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n            else:\n                new_centroids = centroids\n            # vector based cosine similarity for speed\n            cs_row = []\n            for centroid in new_centroids:\n                centroid = torch.unsqueeze(centroid, 0)\n                utterance = torch.unsqueeze(utterance, 0)\n                cos_sim = torch.nn.CosineSimilarity(dim=1, eps=1e-6)(utterance, centroid)\n                cos_sim = torch.clamp(cos_sim, 1e-7)\n                cs_row.append(cos_sim)\n            cos_sim_row.append(torch.cat(cs_row))\n        cos_sim_row = torch.stack(cos_sim_row)\n        cos_sim_matrix.append(cos_sim_row)\n    return torch.stack(cos_sim_matrix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.27746834280272}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    num_spkr, num_uttrs, dvec_dim = dvecs.shape\n    cos_sim_matrix = []\n    for spkr, speaker_dvecs in enumerate(dvecs):\n        cs_row = []\n        for uttr in range(num_uttrs):\n            # Calculate new centroids excluding the current utterance\n            new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, uttr)\n            # Calculate cosine similarity\n            speaker_dvecs = speaker_dvecs.transpose(0, 1)\n            centroids_norm = torch.norm(new_centroids, dim=1)\n            utterance_norm = torch.norm(speaker_dvecs[:, uttr], dim=0)\n            similarity = (\n                torch.mm(new_centroids, speaker_dvecs[:, uttr].unsqueeze(1))\n                / (centroids_norm * utterance_norm)\n            )\n            # Clamp the values\n            similarity = torch.clamp(similarity, 1e-7, 1 - 1e-7)\n            # Concatenate the similarity values\n            cs_row.append(similarity)\n        # Stack the similarity values for each speaker\n        cs_row = torch.cat(cs_row, 1)\n        cos_sim_matrix.append(cs_row)\n    return torch.stack(cos_sim_matrix)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.74844436677321}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    L = []\n    for j in range(N):\n        L_row = []\n        for i in range(N):\n            L_row.append(-F.log_softmax(cos_sim_matrix[j, :], 0)[i])\n        L_row = torch.stack(L_row)\n        L.append(L_row)\n    return torch.stack(L)\n\n\n\n\n", "CodeBleu_score": 60.172554912219454}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    loss = torch.empty(1, dtype=torch.float).cuda()\n    for j in range(N):\n        dvec_j = dvecs[j].repeat(N, 1)\n        input_ = torch.sum(dvec_j * dvecs, -1)\n        input_ = input_.view(1, -1)\n        target = torch.from_numpy(np.array([j for i in range(N)])).cuda()\n        loss_row = F.nll_loss(F.log_softmax(input_, -1), target)\n        loss = torch.cat((loss, loss_row.unsqueeze(0)), 0)\n    return loss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.070349919715408}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    N = dvecs.size(0)\n    L = []\n    for j in range(N):\n        L_row = []\n        for i in range(N):\n            L_row.append(-F.log_softmax(cos_sim_matrix[i], 0).squeeze(0)[j])\n        L_row = torch.stack(L_row)\n        L.append(L_row)\n    return torch.stack(L)", "CodeBleu_score": 59.703596349707375}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(dvecs.size()[0]):\n        L_row.append(\n            torch.sigmoid(\n                cos_sim_matrix[i, :]\n            ).exclude(\n                torch.tensor(i)\n            ).mean()\n        )\n    L = torch.stack(L_row)\n    return L\n\n", "CodeBleu_score": 25.071860044688677}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L = []\n    for i, dvec_A in enumerate(dvecs):\n        L_row = []\n        for j, dvec_B in enumerate(dvecs):\n            if i == j:\n                # we do not train the network on the original embeddings\n                continue\n            # L_row.append(torch.sigmoid(cos_sim_matrix[i, j]))\n            L_row.append(cos_sim_matrix[i, j])\n        L_row = torch.stack(L_row)\n        L.append(L_row)\n    return torch.stack(L)\n\n", "CodeBleu_score": 33.11656022668337}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    loss_row = []\n    for i, dvec_A in enumerate(dvecs):\n        tmp = cos_sim_matrix[i].clone()\n        tmp[i] = -float(\"inf\")\n        numerator = torch.exp(cos_sim_matrix[i, torch.argmax(tmp)]).clone()\n        denominator = torch.sum(torch.exp(tmp)).clone() + numerator\n        loss = -torch.log(numerator / denominator)\n        loss_row.append(loss)\n    loss_row = torch.stack(loss_row)\n    return loss_row\n\n", "CodeBleu_score": 29.778816392993885}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    # Reshape to (batch, seq_len, n_mels)\n    x = x.view(x.shape[0], x.shape[1], -1)\n    # Ensure at least 2 utterances per speaker\n    if x.shape[1] < 2:\n        return 0\n    # Calculate centroids\n    centroids = torch.mean(x, dim=1)\n    # Calculate the cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n    # Calculate the similarity matrix\n    sim_matrix = (\n        self.w * cos_sim_matrix + self.b\n    )  # element wise multiplication\n    L = torch.sum(\n        -F.log_softmax(sim_matrix, dim=-1) * F.softmax(sim_matrix, dim=-1), dim=-1\n    )\n    embed_loss = L.mean()\n    return embed_loss", "CodeBleu_score": 50.92412816440076}, {"code": "def forward(self, x, _label=None)\n\t\n    # Ensure inputs have at least two utterances\n    # assert x.size()[1] >= 2\n    # Get the centroids\n    centroids = self.get_centroids(x)\n    # Calculate the cosine similarity matrix\n    cs_matrix = self.calc_cosine_sim(x, centroids)\n    # Calculate the similarity matrix\n    sim_matrix = self.calc_sim_matrix(cs_matrix)\n    # Calculate the loss\n    loss = self.calc_loss(sim_matrix)\n    # Return the loss\n    return loss\n\n", "CodeBleu_score": 21.605692131955898}, {"code": "def forward(self, x, _label=None)\n\t\n    (num_speakers, num_utts_per_speaker, dvec_feats) = x.shape\n    assert num_utts_per_speaker >= 2\n    centroids = torch.mean(x, dim=1)\n    x = x.reshape(num_speakers * num_utts_per_speaker, dvec_feats)\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids).clamp(-1, 1)\n    L = self.embed_loss(cos_sim_matrix, torch.arange(num_speakers))\n    return L.mean()", "CodeBleu_score": 47.29615936098887}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    extra_voice_dirs = [os.path.join(os.path.dirname(__file__), \"voices\")] + extra_voice_dirs\n    for extra_voice_dir in extra_voice_dirs:\n        for subdir, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    if subdir not in voices:\n                        voices[subdir] = []\n                    voices[subdir].append(os.path.join(subdir, file))\n            if len(voices) == 0:\n                for file in files:\n                    if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                        if subdir not in voices:\n                            voices[subdir] = []\n                        voices[subdir].append(os.path.join(subdir, file))\n    return voices\n\n", "CodeBleu_score": 26.611341033768742}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for extra_voice_dir in extra_voice_dirs:\n        for subdir, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    if subdir not in voices:\n                        voices[subdir] = []\n                    voices[subdir].append(os.path.join(subdir, file))\n            if subdir not in voices:\n                voices[subdir] = []\n            for file in files:\n                if file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                    voices[subdir].append(os.path.join(subdir, file))\n    return voices\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.951606282120487}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\t\n    voices = {}\n    for extra_voice_dir in extra_voice_dirs:\n        extra_voices = {}\n        for root, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    if root not in extra_voices:\n                        extra_voices[root] = []\n                    extra_voices[root].append(os.path.join(root, file))\n                elif file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                    if root not in extra_voices:\n                        extra_voices[root] = []\n                    extra_voices[root].append(os.path.join(root, file))\n        voices.update(extra_voices)\n    return voices\n\n", "CodeBleu_score": 27.630104684178626}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with .npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with .npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t\n    if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with .npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.1921767598096}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score", "CodeBleu_score": 57.08735369887231}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score", "CodeBleu_score": 57.08735369887231}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, num_heads, seq_length1, seq_length2 = pos_score.size()\n    zeros = pos_score.new_zeros(batch_size, num_heads, seq_length1, 1)\n    padded_pos_score = torch.cat([zeros, pos_score], dim=-1)\n    padded_pos_score = padded_pos_score.view(\n        batch_size, num_heads, seq_length2 + 1, seq_length1)\n    pos_score = padded_pos_score[:, :, 1:].view_as(pos_score)\n    return pos_score\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.066568735137686}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    batch_size, max_len = context.size()\n    context_embedded = []\n    for i in range(batch_size):\n        context_embedded.append(self.conv(context[i, :lens[i]].transpose(0, 1)))\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = F.relu(context_embedded)\n    context_embedded = self.dropout(context_embedded)\n    return context_embedded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.28999469976413}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(context.size(0)):\n        context_embedded.append(self.conv(context[i, :lens[i]].transpose(0, 1)))\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = F.relu(context_embedded)\n    context_embedded = self.dropout(context_embedded)\n    return context_embedded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.91533135989562}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    max_len = max(lens)\n    context_embedded = []\n    for i in range(len(context)):\n        context_embedded.append(self.context_embedding(context[i][:max_len]))\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = self.dropout(context_embedded)\n    context_embedded = context_embedded.transpose(1, 2)\n    for conv in self.convs:\n        context_embedded = F.relu(conv(context_embedded))\n    return context_embedded\n\n", "CodeBleu_score": 27.623418070457273}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = lens.sort(0, descending=True)\n    inputs = pack_padded_sequence(context[indices], lens_sorted.cpu().numpy(), True)\n    outputs, _ = fn(inputs, None)\n    _, _indices = torch.sort(indices)\n    return outputs[_indices]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 7.101762049246542}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    # lens = lens.to(context.device)\n    lens_sorted, indices = torch.sort(lens, dim=0, descending=True)\n    _, indices_sorted = torch.sort(indices, dim=0)\n\n    lens_sorted = lens_sorted.long()\n    sorted_context = context.index_select(0, indices)\n    sorted_context = pack_padded_sequence(sorted_context, lens_sorted, batch_first=True)\n    sorted_context = fn(sorted_context)\n    sorted_context = pad_packed_sequence(sorted_context, batch_first=True)[0]\n    sorted_context = sorted_context.index_select(0, indices_sorted)\n    return sorted_context\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 19.629820733874524}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices = lens.sort(0, descending=True)\n    context_sorted = context[indices]\n    context_packed = pack_padded_sequence(context_sorted, lens_sorted.cpu(), batch_first=True)\n    context_sorted_packed, _ = fn(context_packed)\n    context_sorted_unpacked, _ = pad_packed_sequence(context_sorted_packed, batch_first=True)\n    context_sorted_unpacked = context_sorted_unpacked[:, :lens_sorted[0], :]\n    context_sorted_unpacked = context_sorted_unpacked.contiguous()\n    context_sorted_unpacked = context_sorted_unpacked.view(context_sorted_unpacked.size(0), context_sorted_unpacked.size(1), context_sorted_unpacked.size(2))\n    context_sorted_unpacked = context_sorted_unpacked.index_select(0, indices)\n    return context_sorted_unpacked\n\n", "CodeBleu_score": 15.54329559835761}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")", "CodeBleu_score": 70.15353357610886}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', 'se')\n    torch_name = torch_name.replace('senet_', 'senet')\n    torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    if torch_name.startswith('gluon_'):\n        return torch_name\n    return 'gluon_' + torch_name\n\n\n", "CodeBleu_score": 49.096032372035594}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    torch_name = mx_name.lower()\n    torch_name = torch_name.replace('se_', 'se')\n    torch_name = torch_name.replace('senet_', 'senet')\n    torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 50.54166478041656}, {"code": "def map_mx_to_torch_model(mx_name)\n\t\n    mx_name = mx_name.lower()\n    mx_name = mx_name.replace('se_', 'se_')\n    mx_name = mx_name.replace('senet_', 'senet_')\n    mx_name = mx_name.replace('inceptionv3', 'inception_v3')\n    return 'gluon_' + mx_name\n\n", "CodeBleu_score": 31.545253985269333}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    if self.repeats > 1:\n        return math.ceil(self.repeats * self.total_samples / self.num_replicas)\n    if self.batch_size is not None:\n        return math.ceil(self.total_samples / self.batch_size)\n    return math.ceil(self.total_samples / self.num_replicas)\n\n", "CodeBleu_score": 26.057248268937688}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples_per_worker = int(math.ceil(self.total_samples / self.num_replicas))\n    if self.repeats > 1:\n        num_samples_per_worker = max(num_samples_per_worker, self.repeats)\n    if self.batch_size > 0:\n        num_samples_per_worker = max(num_samples_per_worker, self.batch_size)\n    return num_samples_per_worker\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.214458771791}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = math.ceil(self.repeats * self.num_samples / self.num_replicas)\n    if self.train_batch_size:\n        num_samples = max(1, num_samples - num_samples % self.train_batch_size)\n    return num_samples\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 18.08066768310757}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n\n    if types is None:\n        types = IMG_EXTENSIONS\n    if class_to_idx is None:\n        # build class-to-index mapping from the found labels\n        class_to_idx = {classes: idx for idx, classes in enumerate(sorted(set(targets)))}\n    labels = [class_to_idx[target] for target in targets]\n    if sort:\n        # sort file and target lists by the natural sort order of the filenames\n        filenames = sorted(filenames, key=natural_key)\n        labels = [label for _, label in sorted(zip(filenames, labels), key=lambda x: x[0])]\n    if leaf_name_only:\n        # use basename only\n        filenames = [os.path.relpath(filename, root) for filename in filenames]\n    return filenames, labels, class_to_idx\n\n", "CodeBleu_score": 28.037807235595658}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = IMG_EXTENSIONS\n    if class_to_idx is None:\n        # build class_to_idx based on the structure of the input folder\n        classes = [d.name for d in os.scandir(folder) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n    return make_dataset(folder, class_to_idx, extensions=types, is_valid_file=None, leaf_name_only=leaf_name_only, sort=sort)\n\n", "CodeBleu_score": 18.325202428600843}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = IMG_EXTENSIONS\n    if class_to_idx is None:\n        # build class_to_idx based on the structure of the input data\n        classes = [d.name for d in os.scandir(folder) if d.is_dir()]\n        classes.sort()\n        class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n    images_and_targets = get_images_and_targets(folder, class_to_idx, types, leaf_name_only, sort)\n    return images_and_targets, class_to_idx\n\n", "CodeBleu_score": 20.251120356750025}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        # favour the seed already created for pytorch dataloader workers if it exists\n        return worker_info.seed\n    # fallback to wds rank based seed\n    return wds.utils.pytorch_worker_seed()\n\n", "CodeBleu_score": 66.80150511570375}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        # favour the seed already created for pytorch dataloader workers if it exists\n        return worker_info.seed\n    # fallback to wds rank based seed\n    return wds.utils.pytorch_worker_seed()", "CodeBleu_score": 66.80150511570375}, {"code": "def pytorch_worker_seed()\n\t\n    worker_info = get_worker_info()\n    if worker_info is not None:\n        # favour the seed already created for pytorch dataloader workers if it exists\n        return worker_info.seed\n    # fallback to wds rank based seed\n    return wds.utils.pytorch_worker_seed()\n\n", "CodeBleu_score": 66.80150511570375}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in ['L', 'RGB']:\n        return img\n    lut = []\n    for i in range(256):\n        if i < thresh:\n            lut.append(min(i + add, 255))\n        else:\n            lut.append(i)\n    return img.point(lut)\n\n", "CodeBleu_score": 40.850143090906634}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode == 'L':\n        return img.point(lambda x: x + add if x < thresh else x)\n    elif img.mode == 'RGB':\n        return ImageOps.solarize(img, thresh)\n    else:\n        return img\n\n", "CodeBleu_score": 24.5070194521949}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in [\"L\", \"RGB\"]:\n        return img\n    lut = [min(x + add, 255) if x < thresh else x for x in range(256)]\n    return img.point(lut)\n\n", "CodeBleu_score": 18.082760636053898}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transforms, probs = zip(*transforms.items())\n    probs = np.array(probs)\n    probs = probs / np.sum(probs)\n    return transforms, probs\n\n", "CodeBleu_score": 57.74878764001353}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, probabilities = zip(*transforms.items())\n    probabilities = np.array(probabilities)\n    probabilities = probabilities / np.sum(probabilities)\n    return transform_names, probabilities\n\n\n\n\n", "CodeBleu_score": 31.223593187731385}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names, transform_probs = zip(*transforms.items())\n    transform_probs = np.array(transform_probs)\n    transform_probs = transform_probs / np.sum(transform_probs)\n    return transform_names, transform_probs\n\n\n\n\n", "CodeBleu_score": 30.101588966387123}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for weight in mixing_weights:\n        mixed += weight * np.asarray(self._apply_sequence(img, m))\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    return Image.fromarray(Image.blend(img, Image.fromarray(mixed), self.blend_factor))", "CodeBleu_score": 20.655437288920094}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for weight in mixing_weights:\n        mixed += weight * self._apply_augmentations(img, m)\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, self.alpha)\n\n", "CodeBleu_score": 20.984108687795512}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros_like(img)\n    for weight in mixing_weights:\n        mixed += weight * self._apply_sequence(img, m)\n    mixed = np.clip(mixed, 0, 255).astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, self.alpha)\n", "CodeBleu_score": 20.768511107270587}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        x = (np.mean(x),) * n\n        _logger.warning('x is not a tuple/list of length {}. Adapting it by '\n                        'repeating its mean.'.format(n))\n    else:\n        assert len(x) == n\n    return x", "CodeBleu_score": 45.11632673678279}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        _logger.warning(f\"The number of channels {len(x)} does not match the required number of channels {n}. \"\n                        f\"The mean of {x} will be used for all channels.\")\n        x = tuple(np.mean(x)) * n\n    else:\n        assert len(x) == n\n    return x", "CodeBleu_score": 47.27020489902536}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = (x,) * n\n    elif len(x) != n:\n        x = (np.mean(x),) * n\n        _logger.warning(\n            \"The number of channels of the input image does not match the required number of channels. \"\n            \"The input image will be converted to a tuple of length n by repeating its mean value n times.\"\n        )\n    else:\n        assert len(x) == n\n    return x", "CodeBleu_score": 44.68364118327459}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    info = get_worker_info()\n    if info is None:\n        return\n    if isinstance(worker_seeding, str):\n        if worker_seeding == 'all':\n            seed = info.seed % (2 ** 32 - 1)\n            np.random.seed(seed)\n            random.seed(seed)\n            torch.manual_seed(seed)\n            return\n        raise ValueError(f'Invalid worker_seeding option: {worker_seeding}.')\n    if callable(worker_seeding):\n        worker_seeding(info.seed)\n        return\n    raise TypeError(f'Invalid worker_seeding type: {type(worker_seeding)}.')\n\n", "CodeBleu_score": 44.721419760488565}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    info = get_worker_info()\n    if isinstance(info, dict):\n        assert info['num_workers'] > 1, 'Single process workers are not supported'\n        worker_id = info['id']\n        if worker_seeding == 'all':\n            seed = info['seed'] % (2 ** 32 - 1)\n            random.seed(seed)\n            torch.manual_seed(seed)\n            np.random.seed(seed)\n        elif worker_seeding == 'numpy':\n            worker_seed = info['seed'] % (2 ** 32 - 1)\n            np.random.seed(worker_seed)\n        else:\n            raise ValueError(f'Invalid worker_seeding option: {worker_seeding}')\n    else:\n        assert worker_id == 0, 'Single process workers are not supported'\n        if worker_seeding == 'all':\n            seed = seeding.get_random_seed()\n            random.seed(seed)\n            torch.manual_seed(seed)\n            np.random.seed(seed)\n        elif worker_seeding == 'numpy':\n            worker_seed = seeding.get_random_seed()\n            np.random.seed(worker_seed)\n        else:\n            raise ValueError(f'Invalid worker_seeding option: {worker_seeding}')\n\n", "CodeBleu_score": 47.5486551961272}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    info = get_worker_info()\n    if isinstance(info, dict):\n        assert info['worker_id'] == worker_id\n        seed = info['seed']\n    else:\n        assert info.id == worker_id\n        seed = info.seed\n    random.seed(seed)\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    if isinstance(worker_seeding, Callable):\n        worker_seeding(seed)\n    elif worker_seeding == 'all':\n        np.random.seed(seed % (2 ** 32 - 1))\n\n", "CodeBleu_score": 56.4146949111851}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = tf.io.extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + CROP_PADDING)) * tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32)\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.io.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 56.519253333594534}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = tf.image.extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + CROP_PADDING)) * tf.cast(tf.minimum(image_height, image_width), tf.float32)), tf.int32)\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 58.97680175418283}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    shape = tf.image.extract_jpeg_shape(image_bytes)\n    image_height = shape[0]\n    image_width = shape[1]\n    padded_center_crop_size = tf.cast(\n        ((image_size / (image_size + CROP_PADDING)) *\n        tf.cast(tf.minimum(image_height, image_width), tf.float32)),\n        tf.int32,\n    )\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width,\n                            padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.decode_and_crop_jpeg(image_bytes, crop_window, channels=3)\n    image = resize(image, image_size, image_size, resize_method)\n    return image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.632001858220264}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n\n    return image\n\n", "CodeBleu_score": 42.898446301658076}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 42.898446301658076}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(\n        image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n\n    return image\n\n", "CodeBleu_score": 46.37171642737686}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    if interpolation == 'bicubic':\n        resize_method = tf.image.ResizeMethod.BICUBIC\n    elif interpolation == 'lanczos3':\n        resize_method = tf.image.ResizeMethod.LANCZOS3\n    else:\n        raise ValueError('Invalid interpolation method: {}'.format(interpolation))\n\n    image = _decode_and_center_crop(image_bytes, image_size, resize_method)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 67.00203448239368}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    resize_method = RESIZE_METHODS[interpolation]\n    image = _decode_and_center_crop(image_bytes, image_size, resize_method)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 47.735046150338704}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    resize_method = 'bicubic' if interpolation == 'bicubic' else 'area'\n    image = _decode_and_center_crop(image_bytes, image_size, resize_method)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16 if use_bfloat16 else tf.float32)\n    return image\n\n", "CodeBleu_score": 69.71189027159598}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    model.eval()\n    self.predict_loop(eval_dataloader, output_file)\n    results = self.compute_metrics(output_file)\n    return results\n\n", "CodeBleu_score": 54.476082583930484}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    if self.verbose:\n        print(\"Evaluating...\")\n    model.eval()\n    if self.verbose:\n        print(\"Running prediction loop...\")\n    predictions = self.predict_loop(model, eval_dataloader)\n    if self.verbose:\n        print(\"Saving predictions to file...\")\n    self.save_predictions(predictions, output_file)\n    if self.verbose:\n        print(\"Computing metrics...\")\n    results = self.compute_metrics(predictions)\n    if self.verbose:\n        print(\"Evaluation complete.\")\n    return results\n\n\n\n\n", "CodeBleu_score": 49.44633464767188}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    # Run prediction loop\n    predictions, labels, metrics = self.predict_loop(model, eval_dataloader, output_file)\n    # Compute evaluation metrics\n    results = self.compute_metrics(eval_pred=predictions)\n    return results\n\n\n\n\n", "CodeBleu_score": 64.95366061682685}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics['rank1']\n    rank5 = metrics['rank5']\n    miou = metrics['miou']\n    print('Rank@1: {:.4f} - Rank@5: {:.4f} - mIoU: {:.4f}'.format(rank1, rank5, miou))", "CodeBleu_score": 28.3575173663844}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics['rank1']\n    rank5 = metrics['rank5']\n    miou = metrics['miou']\n    print(f\"Rank-1: {rank1:.4f}\")\n    print(f\"Rank-5: {rank5:.4f}\")\n    print(f\"mIoU: {miou:.4f}\")\n\n", "CodeBleu_score": 23.694386153011397}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    rank1 = metrics['rank1']\n    rank5 = metrics['rank5']\n    miou = metrics['miou']\n    print('Rank@1: {:.4f}'.format(rank1))\n    print('Rank@5: {:.4f}'.format(rank5))\n    print('mIoU: {:.4f}'.format(miou))", "CodeBleu_score": 27.694462127832907}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment, datum in zip(segments, data):\n        ious = [self._iou(pred, datum['times']) for pred in segment]\n        ranks = [self._rank(segment, datum['times']) for pred in segment]\n        average_iou.append(np.mean(np.sort(ious)[-1:]))\n        average_ranks.append(np.mean(np.sort(ranks)[:1]))\n    rank1 = np.sum(np.array(average_ranks) == 1) / float(len(average_ranks))\n    rank5 = np.sum(np.array(average_ranks) <= 5) / float(len(average_ranks))\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou", "CodeBleu_score": 52.51546253004425}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment in segments:\n        ious = [self._iou(segment, data_seg) for data_seg in data]\n        ranks = [self._rank(sorted(ious, reverse=True), iou) for iou in ious]\n        average_iou.append(np.mean(ious))\n        average_ranks.append(np.mean(ranks))\n    rank1 = np.sum([1 for rank in average_ranks if rank == 1]) / len(average_ranks)\n    rank5 = np.sum([1 for rank in average_ranks if rank <= 5]) / len(average_ranks)\n    mean_iou = np.mean(average_iou)\n    return rank1, rank5, mean_iou", "CodeBleu_score": 38.94253146874653}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment in segments:\n        ious = []\n        ranks = []\n        for datum in data:\n            iou = self._iou(segment, datum)\n            ious.append(iou)\n            rank = self._rank(segment, datum)\n            ranks.append(rank)\n        average_iou.append(np.mean(np.sort(ious)[-self.top_n:]))\n        average_ranks.append(np.mean(np.sort(ranks)[:self.top_n]))\n    average_iou = np.mean(average_iou)\n    rank1 = np.sum(np.array(average_ranks) == 1) / len(average_ranks)\n    rank5 = np.sum(np.array(average_ranks) == 5) / len(average_ranks)\n    return rank1, rank5, average_iou", "CodeBleu_score": 41.478128191706496}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to_ctx(model, ctx=0)\n    for batch in eval_dataloader:\n        batch = model.to_ctx(batch, ctx=0)\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        scores.append(outputs)\n    results = self.finalize(scores)\n    if output_file:\n        self.save_results(results, output_file)\n    return results\n\n", "CodeBleu_score": 47.64507752539963}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(0)\n    for batch in eval_dataloader:\n        batch = self.to_ctx(batch, 0)\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        scores.append(outputs)\n    results = self.process_scores(scores)\n    if output_file:\n        self.finalize(output_file)\n    return results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.251657804428085}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to(0)\n    for batch in eval_dataloader:\n        batch = self.to_ctx(batch, 0)\n        with torch.no_grad():\n            outputs = model(**batch)\n        outputs.update(batch)\n        scores.extend(self.process_outputs(outputs))\n    results = self.aggregate_scores(scores)\n    if output_file is not None:\n        self.save_results(results, output_file)\n    return results\n\n", "CodeBleu_score": 44.69937582289853}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores, video_scores = scores\n    full_scores = np.concatenate([text_scores, video_scores], axis=1)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.249721682340386}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores, video_scores = scores\n    full_scores = np.concatenate((text_scores, video_scores), axis=0)\n    self.full_scores = None\n    return np.matmul(text_scores, video_scores.T)", "CodeBleu_score": 41.28234376021517}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    scores = [np.concatenate(scores[0], axis=0), np.concatenate(scores[1], axis=0)]\n    self.full_scores = None\n    return np.matmul(scores[0], scores[1].T)", "CodeBleu_score": 47.67832713039798}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    if self.error_check:\n        self.check_predictions(Y_pred, Y_true)\n    Y_pred = torch.cat(Y_pred).cpu().numpy()\n    Y_true = torch.cat(Y_true).cpu().numpy()\n    if output_file:\n        pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, open(output_file, \"wb\"))\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.0757460241023}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred)\n    Y_true = torch.cat(Y_true)\n    Y_pred = Y_pred.numpy()\n    Y_true = Y_true.numpy()\n    errors = Y_pred != Y_true\n    print(f\"Prediction errors: {errors.sum()}\")\n    if errors.sum() > 0:\n        print(\"Showing samples of prediction errors\")\n        print(\"Predicted label - True label\")\n        for i in range(len(Y_pred)):\n            if errors[i]:\n                print(f\"{Y_pred[i]} - {Y_true[i]}\")\n    result = {\"predictions\": Y_pred, \"true_labels\": Y_true}\n    if output_file is not None:\n        with open(output_file, \"wb\") as f:\n            pickle.dump(result, f)\n    return result\n\n", "CodeBleu_score": 41.14165212422524}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    if isinstance(Y_pred, torch.Tensor):\n        Y_pred = Y_pred.cpu().detach().numpy()\n    if isinstance(Y_true, torch.Tensor):\n        Y_true = Y_true.cpu().detach().numpy()\n    Y_pred = np.concatenate(Y_pred)\n    Y_true = np.concatenate(Y_true)\n\n    errors = Y_pred != Y_true\n    print(f\"Prediction errors: {errors.sum()}/{len(errors)}\")\n\n    if output_file is not None:\n        with open(output_file, \"wb\") as f:\n            pickle.dump({\"Y_pred\": Y_pred, \"Y_true\": Y_true}, f)\n\n    return {\"Y_pred\": Y_pred, \"Y_true\": Y_true}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.27653847958777}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get('loss', 0) for log in logging_outputs)\n    sample_size = sum(log.get('sample_size', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size, round=3)\n\n\n", "CodeBleu_score": 52.7910982560264}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get(\"loss\", 0) for log in logging_outputs)\n    sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n    metrics.log_scalar(\"loss\", loss_sum / sample_size, 3)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 61.41084586628428}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get(\"loss\", 0) for log in logging_outputs)\n    sample_size = sum(log.get(\"sample_size\", 0) for log in logging_outputs)\n    metrics.log_scalar(\"loss\", loss_sum / sample_size, 3)\n\n", "CodeBleu_score": 61.41084586628428}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n    token_type_ids = torch.zeros(\n        (cmasks.size(0), 1, cmasks.size(1) + vmasks.size(1)),\n        dtype=torch.long,\n        device=cmasks.device,\n    )\n    token_type_ids[:, :, cmasks.size(1) :] = 1\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 49.135254688479044}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n        if attention_mask is None:\n            attention_mask = self._mm_attention_mask(cmasks, vmasks)\n        else:\n            # the attention mask is provided by the user.\n            assert attention_mask.size(0) == cmasks.size(0), \"{}, {}, {}, {}\".format(\n                str(attention_mask.size()),\n                str(cmasks.size()),\n                str(attention_mask.size(0)),\n                str(cmasks.size(0)),\n            )\n        token_type_ids = torch.cat([torch.zeros(cmasks.size()), torch.ones(vmasks.size())], dim=-1)\n        return attention_mask, token_type_ids\n\n", "CodeBleu_score": 49.3746730953891}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n    token_type_ids = torch.cat([torch.zeros(cmasks.size()), torch.ones(vmasks.size())], dim=1)\n    return attention_mask, token_type_ids\n\n\n", "CodeBleu_score": 35.71396551947663}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.ones_like(input_ids)\n    if token_type_ids is None:\n        token_type_ids = torch.zeros_like(input_ids)\n\n    # Adjust the sequence length to match the combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    input_ids = input_ids[:, :combined_length]\n    attention_mask = attention_mask[:, :combined_length]\n    token_type_ids = token_type_ids[:, :combined_length]\n\n    # Modify the attention_mask and token_type_ids to fit the new sequence length\n    attention_mask = torch.cat((attention_mask, torch.zeros_like(input_video_embeds[:, :, 0])), dim=1)\n    token_type_ids = torch.cat((token_type_ids, torch.ones_like(input_video_embeds[:, :, 0])), dim=1)\n\n    # Return the updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.78544859502513}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # Prepare inputs\n    input_ids = input_ids.to(self.device)\n    input_video_embeds = input_video_embeds.to(self.device)\n    attention_mask = attention_mask.to(self.device)\n    token_type_ids = token_type_ids.to(self.device)\n\n    # Adjust sequence length\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    if combined_length > self.config.max_position_embeddings:\n        raise ValueError(f\"Combined input length ({combined_length}) exceeds the maximum sequence length ({self.config.max_position_embeddings}).\")\n    attention_mask = torch.cat([attention_mask, torch.zeros(attention_mask.size(0), input_video_embeds.size(1), dtype=attention_mask.dtype, device=attention_mask.device)], dim=1)\n    token_type_ids = torch.cat([token_type_ids, torch.zeros(token_type_ids.size(0), input_video_embeds.size(1), dtype=token_type_ids.dtype, device=token_type_ids.device)], dim=1)\n\n    # Update input_ids and input_video_embeds\n    input_ids = torch.cat([input_ids, torch.zeros(input_ids.size(0), input_video_embeds.size(1), dtype=input_ids.dtype, device=input_ids.device)], dim=1)\n    input_video_embeds = torch.cat([input_video_embeds, torch.zeros(input_video_embeds.size(0), input_ids.size(1) - input_video_embeds.size(1), input_video_embeds.size(2), dtype=input_video_embeds.dtype, device=input_video_embeds.device)], dim=1)\n\n    # Update model_kwargs\n    model_kwargs['input_ids'] = input_ids\n    model_kwargs['input_", "CodeBleu_score": 28.303434905773493}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n\n    # Adjust the sequence length to match the combined length of input_ids and input_video_embeds\n    sequence_length = input_ids.size(1) + input_video_embeds.size(1)\n    input_ids = self._resize_token_embeddings(input_ids, sequence_length)\n    input_video_embeds = self._resize_token_embeddings(input_video_embeds, sequence_length)\n\n    # Modify the attention_mask and token_type_ids to fit the new sequence length\n    if attention_mask is not None:\n        attention_mask = self._resize_token_embeddings(attention_mask, sequence_length)\n    if token_type_ids is not None:\n        token_type_ids = self._resize_token_embeddings(token_type_ids, sequence_length)\n\n    # Return the updated input_ids, input_video_embeds, attention_mask, and token_type_ids\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n        **model_kwargs,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.166365616488136}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    # adjust the pipeline config by removing the 'img_id' key from meta_keys\n    for transform in cfg:\n        if 'meta_keys' in transform:\n            if 'img_id' in transform['meta_keys']:\n                transform['meta_keys'].remove('img_id')\n\n    # find the index of the 'LoadImageFromFile' transform\n    idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if idx == -1:\n        raise ValueError(\n            'LoadImageFromFile transform not found in the pipeline. '\n            'Please check the pipeline configuration.')\n\n    # update the transform type to 'mmdet.InferencerLoader'\n    cfg[idx]['type'] = 'mmdet.InferencerLoader'\n\n    # return the modified pipeline configuration wrapped in a Compose object\n    return Compose(cfg)", "CodeBleu_score": 38.58339522846316}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    # Adjust the pipeline config by removing the 'img_id' key from meta_keys\n    # if present.\n    if 'meta_keys' in cfg:\n        if 'img_id' in cfg['meta_keys']:\n            cfg['meta_keys'].remove('img_id')\n    # Find the index of the 'LoadImageFromFile' transform.\n    load_idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if load_idx == -1:\n        raise ValueError(\n            'LoadImageFromFile is not found in the pipeline. '\n            'Please check the test pipeline.')\n    # Update the transform type to 'mmdet.InferencerLoader'.\n    cfg[load_idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(cfg)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.154658214876235}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t\n    # adjust the pipeline cfg\n    for transform in cfg:\n        if 'meta_keys' in transform and 'img_id' in transform['meta_keys']:\n            transform['meta_keys'].remove('img_id')\n    # find the index of LoadImageFromFile\n    idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if idx == -1:\n        raise ValueError('LoadImageFromFile is not found in the pipeline.')\n    # update the type of LoadImageFromFile\n    cfg[idx]['type'] = 'mmdet.InferencerLoader'\n    return Compose(cfg)\n\n", "CodeBleu_score": 36.051266357422875}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs, list_dir=False, list_file=True, recursive=True)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.483016150328574}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n\n", "CodeBleu_score": 37.27664845802001}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs, list_dir=False, list_file=True, recursive=True)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 43.483016150328574}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and 'img' in input:\n            input = self.pipeline(input)\n        elif isinstance(input, dict) and 'img_path' in input:\n            input = self.pipeline(input)\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n    if chunk_data:\n        yield chunk_data\n\n\n\n\n", "CodeBleu_score": 29.862104768695392}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input_ in inputs:\n        if isinstance(input_, dict):\n            if 'img' in input_:\n                data = input_\n            elif 'img_path' in input_:\n                data = dict(img_path=input_['img_path'])\n            else:\n                raise Exception(f'Invalid input: {input_}')\n        else:\n            data = dict(img=input_)\n\n        data = self.pipeline(data)\n        chunk_data.append(data)\n        if len(chunk_data) == chunk_size:\n            yield chunk_data\n            chunk_data = []\n    if chunk_data:\n        yield chunk_data\n\n", "CodeBleu_score": 40.211188867136855}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict) and \"img\" in input:\n            input = self.pipeline(input)\n        chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield copy.deepcopy(chunk_data)\n            chunk_data.clear()\n    if len(chunk_data) > 0:\n        yield copy.deepcopy(chunk_data)\n\n", "CodeBleu_score": 23.314493699071917}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n    if no_save_pred:\n        pred_out_dir = ''\n\n    if pred_out_dir != '':\n        os.makedirs(pred_out_dir, exist_ok=True)\n        os.makedirs(osp.join(pred_out_dir, 'preds'), exist_ok=True)\n\n    results = []\n    if return_datasamples:\n        warnings.warn(\n            'Saving datasamples is not supported in Panoptic Segmentation. '\n            'Please set `return_datasamples=False`.')\n\n    if isinstance(preds, list):\n        for pred in preds:\n            result = self.pred2dict(pred, pred_out_dir)\n            results.append(result)\n    else:\n        result = self.pred2dict(preds, pred_out_dir)\n        results.append(result)\n\n    if visualization is not None:\n        results.append({'visualization': visualization})\n\n    if print_result:\n        print_log(results, logger='visualization')\n\n    return results", "CodeBleu_score": 55.20929291632899}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n    if not no_save_pred and pred_out_dir == '':\n        pred_out_dir = osp.join(self.runner.work_dir, 'preds')\n        os.makedirs(pred_out_dir, exist_ok=True)\n\n    if pred_out_dir and return_datasamples:\n        warnings.warn('Saving datasamples is not supported in '\n                      '`PanopticFPN.postprocess`.')\n\n    results = []\n    for pred in preds:\n        result = self.pred2dict(pred, pred_out_dir=pred_out_dir)\n        if visualization is not None:\n            result['visualization'] = visualization\n        results.append(result)\n\n    if print_result:\n        print_log(f'Results: {results}', logger='mmdet')\n\n    if return_datasamples:\n        return preds\n    else:\n        return results", "CodeBleu_score": 53.79291464285991}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t\n\n    if visualization is not None:\n        if not isinstance(visualization, list):\n            visualization = [visualization]\n        visualization = [\n            img.cpu().numpy() for img in visualization\n        ]\n\n    results = []\n    if return_datasamples:\n        if pred_out_dir != '':\n            warnings.warn(\n                'Saving datasamples is not supported in '\n                '`return_datasamples=True` mode.')\n        return preds\n    else:\n        for pred in preds:\n            result = self.pred2dict(pred, pred_out_dir)\n            if visualization is not None:\n                result['visualization'] = visualization[0]\n            results.append(result)\n\n    if print_result:\n        self.print_results(results, logger=self.logger)\n\n    return results\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.01766589190109}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    transforms = cfg.data.test.dataset.pipeline\n    transforms[0].type = \"Resize\"\n    transforms[0].size = cfg.data.test.img_scale\n    transforms.append(copy.deepcopy(transforms[-1]))\n    transforms[-1].type = \"DefaultFormatBundle\"\n    pipeline = Compose(transforms)\n    return pipeline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.698177873915313}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    dataset_pipeline = cfg.dataset.pipeline\n    test_pipeline = dataset_pipeline.copy()\n    test_pipeline[0] = test_pipeline[0].copy()\n    test_pipeline[0].transforms = [\n        transform for transform in test_pipeline[0].transforms if transform.type == 'Resize'\n    ]\n    test_pipeline[-1] = test_pipeline[-1].copy()\n    test_pipeline[-1].transforms = [\n        transform for transform in test_pipeline[-1].transforms if transform.type != 'Resize'\n    ]\n    test_pipeline = Compose(test_pipeline)\n    return test_pipeline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.159434639646047}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    test_pipeline = copy.deepcopy(cfg.dataset.pipeline)\n    test_pipeline[0].transforms[0].type = 'Resize'\n    test_pipeline.append(copy.deepcopy(test_pipeline[-1]))\n    test_pipeline[-1].transforms[0].type = 'PackClsInputs'\n    return test_pipeline", "CodeBleu_score": 20.332004021025206}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    data = dict(\n        img=img,\n        frame_id=frame_id,\n        img_id=0,\n        img_shape=img.shape,\n        ori_shape=img.shape,\n        video_len=video_len)\n\n    # build test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n    data = test_pipeline(data)\n\n    # check if the model is on the CPU and unsupported modules are used\n    if next(model.parameters()).is_cuda is False:\n        check_model_compatibility(model, test_pipeline)\n\n    # forward the model\n    with torch.no_grad():\n        result = model.test_step(data)[0]\n\n    return result\n\n", "CodeBleu_score": 36.40686293370594}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    data = {\n        'img': img,\n        'frame_id': frame_id,\n        'img_shape': img.shape,\n        'ori_shape': img.shape,\n        'img_id': frame_id,\n        'video_len': video_len\n    }\n    # build test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n    data = test_pipeline(data)\n\n    # convert data to torch.Tensor\n    data = collate([data])\n    if next(model.parameters()).is_cuda:\n        # scatter to specified GPU\n        data = scatter(data, [device])[0]\n    elif torch.cuda.is_available():\n        warnings.warn('We still evaluate the model on CPU, however, '\n                      'it is more efficient if the GPU is used.')\n    else:\n        raise RuntimeError('No gpu device available.')\n    # forward the model\n    with torch.no_grad():\n        result = model.test_step(data)\n    return result\n\n", "CodeBleu_score": 38.24484063017067}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    data = dict(\n        img=img,\n        frame_id=frame_id,\n        img_shape=img.shape,\n        ori_shape=img.shape,\n        img_id=0,\n        img_path=None,\n        video_len=video_len)\n    # build test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n    # perform inference\n    data = test_pipeline(data)\n    # convert to torch.Tensor\n    data = collate([data])\n    if next(model.parameters()).is_cuda:\n        # scatter to specified GPU\n        data = scatter(data, [device])[0]\n    else:\n        # this is a workaround to avoid the bad-cuda-alloc error, which\n        # occurs when running mot models on CPU.\n        for m in model.modules():\n            assert not isinstance(\n                m, RoIPool\n            ), 'CPU inference with RoIPool is not supported currently.'\n        # explicitly cast to float32 to avoid Error: expected scalar type Float\n        # but found Double  # noqa E501\n        data['img'] = data['img'].type(torch.FloatTensor)\n    # We don't need gradient in test mode.\n    with torch.no_grad():\n        result = model.test_step(data, rescale=True)\n    return result\n\n", "CodeBleu_score": 55.001956120448185}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            trunc_tokens.pop()\n        else:\n            trunc_tokens.pop(0)\n\n    return tokens_a, tokens_b\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 72.75340873021591}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            trunc_tokens.pop()\n        else:\n            trunc_tokens.pop(0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 73.66999555738448}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            trunc_tokens.pop()\n        else:\n            trunc_tokens.pop(0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 73.66999555738448}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if not activation_string:\n        return None\n    act = activation_string.lower()\n    if act == \"linear\":\n        return linear\n    elif act == \"relu\":\n        return relu\n    elif act == \"sigmoid\":\n        return sigmoid\n    elif act == \"tanh\":\n        return tanh\n    elif act == \"softmax\":\n        return softmax\n    else:\n        raise ValueError(\"Unsupported activation: {}\".format(activation_string))\n\n", "CodeBleu_score": 61.321357349421035}, {"code": "def get_activation(activation_string)\n\t\n    if isinstance(activation_string, str):\n        if activation_string.lower() == \"relu\":\n            return tf.nn.relu\n        elif activation_string.lower() == \"sigmoid\":\n            return tf.nn.sigmoid\n        elif activation_string.lower() == \"softmax\":\n            return tf.nn.softmax\n        elif activation_string.lower() == \"tanh\":\n            return tf.nn.tanh\n        elif activation_string.lower() == \"selu\":\n            return tf.nn.selu\n        elif activation_string.lower() == \"elu\":\n            return tf.nn.elu\n        elif activation_string.lower() == \"exponential\":\n            return tf.nn.exponential\n        elif activation_string.lower() == \"linear\":\n            return None\n        else:\n            raise ValueError(\"Unknown activation function: {}\".format(activation_string))\n    else:\n        return activation_string\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.921768500379855}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string.lower() == 'relu':\n        return tf.keras.layers.ReLU()\n    elif activation_string.lower() == 'leakyrelu':\n        return tf.keras.layers.LeakyReLU()\n    elif activation_string.lower() == 'sigmoid':\n        return tf.keras.layers.Activation('sigmoid')\n    elif activation_string.lower() == 'tanh':\n        return tf.keras.layers.Activation('tanh')\n    elif activation_string.lower() == 'softmax':\n        return tf.keras.layers.Activation('softmax')\n    elif activation_string.lower() == 'linear':\n        return tf.keras.layers.Activation('linear')\n    elif activation_string.lower() == 'none':\n        return None\n    else:\n        raise ValueError(f\"Unknown activation function: {activation_string}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.377140093588036}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output", "CodeBleu_score": 87.51451468041077}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    # We don't assume that `from_tensor` is a mask.\n    #\n    # However, if it is a mask, then all positions where the mask is False\n    # should be ignored.\n    #\n    # Therefore, we create a mask of shape [batch_size, from_seq_length] and\n    # set the values corresponding to False values in the input mask to\n    # negative infinity.\n    #\n    # Note that the mask is not symmetrical, i.e.,\n    # `to_mask` has a shape [batch_size, 1, to_seq_length] while\n    # `from_mask` has a shape [batch_size, from_seq_length, 1].\n    to_mask = tf.cast(tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n    mask = broadcast_ones * to_mask\n\n    return mask\n\n", "CodeBleu_score": 66.52281175149255}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32\n    )\n\n    # We don't assume that `from_tensor` is a mask (although it could be).\n    #\n    # `from_tensor` might be a normal tensor, or a mask.\n    #\n    # 1. If `from_tensor` is a normal tensor, it is still a mask.\n    # Assuming the padding tokens are zero, they will be added to\n    # the attention mask. Therefore, we don't need to re-add padding.\n    #\n    # 2. If `from_tensor` is a mask -- then we use it.\n    # Since attention_mask is 1.0 for positions we want to attend and 0.0 for\n    # masked positions, this operation will create a tensor which is 0.0 for\n    # padding positions and 1.0 for non-padding positions.\n    #\n    # We don't care about the padding tokens, so we reduce\n    # across the vocabulary dimension and multiply the resulting tensor by\n    # `to_tensor`.\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32\n    )\n    mask = broadcast_ones * to_mask\n\n    return mask\n\n", "CodeBleu_score": 59.90976989090129}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n        tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    # We don't assume that `from_tensor` is a mask.\n    #\n    # However, if it is a mask, then all positions where the mask is False\n    # do not contribute to the loss.\n    #\n    # Therefore, we multiply it by a \"scale\" number to appropriately downscale\n    # the attention_scores.\n    #\n    # This is actually the exact same behavior as tf.keras.layers.AdditiveAttention\n    # and tf.keras.layers.MultiHeadAttention.\n    #\n    # (If you are using 2D attention mask, then this means that the mask is\n    # broadcasted for the batch dimension).\n    broadcast_ones = tf.ones(\n        shape=[batch_size, from_seq_length, 1], dtype=tf.float32)\n    mask = broadcast_ones * to_mask\n\n    return mask\n\n", "CodeBleu_score": 64.38636645230761}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor", "CodeBleu_score": 59.99845781533536}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is not None:\n        if input_tensor.shape.ndims < 2:\n            raise ValueError(\"Input tensor must have at least 2 dimensions, but saw shape: %s\" % input_tensor.shape)\n        if input_tensor.shape.ndims == 2:\n            return input_tensor\n        width = input_tensor.shape[-1]\n        output_tensor = tf.reshape(input_tensor, [-1, width])\n        return output_tensor\n    else:\n        raise ValueError(\"Input tensor must have a known rank, but saw shape: %s\" % input_tensor.shape)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.65396009046017}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is not None:\n        if input_tensor.shape.ndims < 2:\n            raise ValueError('Input tensor must have at least rank 2. Shape = %s' % (input_tensor.shape))\n        if input_tensor.shape.ndims == 2:\n            return input_tensor\n        batch_size = -1\n        if input_tensor.shape.ndims is not None:\n            width = input_tensor.shape.as_list()[-1]\n            return tf.reshape(input_tensor, [batch_size, width])\n        else:\n            raise ValueError('Unable to get shape of input tensor %s' % (input_tensor))\n    else:\n        raise ValueError('Unable to get shape of input tensor %s' % (input_tensor))", "CodeBleu_score": 45.021082328698704}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is not None:\n        if input_tensor.shape.ndims < 2:\n            raise ValueError(\n                \"Input tensor must have at least 2 dimensions, but saw shape: %s\"\n                % input_tensor.shape)\n        if input_tensor.shape.ndims == 2:\n            return input_tensor\n\n    width = input_tensor.shape[-1]\n    output_tensor = tf.reshape(input_tensor, [-1, width])\n    return output_tensor\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 61.29520744143188}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    return self._read_tsv(os.path.join(data_dir, \"train.tsv\"))\n", "CodeBleu_score": 2.6496837008493603}, {"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(\n        self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n", "CodeBleu_score": 6.324149162613836}, {"code": "def get_train_examples(self, data_dir)\n\t\n    return self._read_tsv(os.path.join(data_dir, \"train.tsv\"))\n", "CodeBleu_score": 2.6496837008493603}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions, weights=is_real_example)\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n", "CodeBleu_score": 50.456802985927304}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    predictions = tf.argmax(logits, axis=-1)\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions)\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n\n\n\n", "CodeBleu_score": 46.26499197673835}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Get the predictions\n    predictions = tf.argmax(logits, axis=-1)\n    # Calculate the accuracy\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predictions, weights=is_real_example\n    )\n    # Calculate the mean loss\n    mean_loss = tf.metrics.mean(values=per_example_loss, weights=is_real_example)\n    return {\"eval_accuracy\": accuracy, \"eval_loss\": mean_loss}\n\n", "CodeBleu_score": 44.27040825228}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 83.41734189253587}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 83.41734189253587}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t\n    \"\"\"Convert a set of `InputExample`s to a list of `InputFeatures`.\"\"\"\n\n    features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n\n        feature = convert_single_example(ex_index, example, label_list,\n                                        max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 83.47895387683425}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n\n    # Get the output weights and bias from the BERT configuration\n    output_weights = tf.get_variable(\n        \"output_weights\", [2, bert_config.hidden_size],\n        initializer=create_initializer(bert_config.initializer_range))\n    output_bias = tf.get_variable(\n        \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    # Compute logits through matrix multiplication and bias addition\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n\n    # Convert labels to one-hot encoding\n    labels = tf.reshape(labels, [-1])\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n    # Calculate per-example loss and mean loss\n    per_example_loss = -tf.reduce_sum(one_hot_labels * logits, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n\n    # Return mean loss, per-example loss, and log probabilities\n    return (loss, per_example_loss, logits)\n\n", "CodeBleu_score": 44.04059272926911}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\",\n            shape=[2, bert_config.hidden_size],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", shape=[2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = tf.nn.log_softmax(logits, axis=-1)\n        labels = tf.reshape(labels, [-1])\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 86.94900271179796}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n\n    # Get the output weights and bias from the bert_config\n    output_weights = tf.get_variable(\n        \"output_weights\", [2, bert_config.hidden_size],\n        initializer=modeling.create_initializer(bert_config.initializer_range))\n    output_bias = tf.get_variable(\n        \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    # Compute logits through matrix multiplication and bias addition\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n\n    # Convert labels to one-hot encoding\n    labels = tf.reshape(labels, [-1])\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n\n    # Calculate per-example loss\n    per_example_loss = -tf.reduce_sum(tf.multiply(one_hot_labels, tf.nn.log_softmax(logits)), axis=-1)\n\n    # Calculate mean loss\n    loss = tf.reduce_mean(per_example_loss)\n\n    # Return mean loss, per-example loss, and log probabilities\n    return loss, per_example_loss, logits\n\n", "CodeBleu_score": 44.70540205842111}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1]\n    )\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor, [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.34905172926283}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 57.853066637478335}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1]\n    )\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor, [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.34905172926283}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n\n    return example\n\n", "CodeBleu_score": 71.91618952996937}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n\n    return example\n\n\n\n\n", "CodeBleu_score": 71.91618952996937}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.to_int32(t)\n        example[name] = t\n    return example", "CodeBleu_score": 71.91618952996937}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_text = \" \".join(doc_tokens)\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = tok_text[new_start:(new_end + 1)]\n            if text_span == \"\":\n                continue\n            tok_answer_text = \" \".join(\n                tokenizer.tokenize(orig_answer_text))\n\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 67.32641496027833}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_text = \" \".join(doc_tokens)\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = tok_text[new_start:(new_end + 1)]\n            if text_span == \"\":\n                continue\n            tok_text_list = tokenizer.tokenize(text_span)\n            tok_text_list_trunc = tok_text_list[:-1] + \\\n                [tok_text_list[-1][-1]]\n            pos_text_list = tokenizer.tokenize(orig_answer_text)\n            if len(tok_text_list_trunc) == len(pos_text_list) and \\\n                    pos_text_list == tok_text_list_trunc:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 52.73377435150752}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_text = \" \".join(doc_tokens)\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = tok_text[new_start:(new_end + 1)]\n            if text_span == orig_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 60.717740838067954}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 65.86707343330198}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 65.86707343330198}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        while True:\n            token = convert_to_unicode(reader.readline())\n            if not token:\n                break\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 65.86707343330198}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens", "CodeBleu_score": 63.56859574727435}, {"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens\n\n", "CodeBleu_score": 88.10762355418231}, {"code": "def tokenize(self, text)\n\t\n    split_tokens = []\n    for token in self.basic_tokenizer.tokenize(text, never_split=self.all_special_tokens):\n        for sub_token in self.wordpiece_tokenizer.tokenize(token):\n            split_tokens.append(sub_token)\n    return split_tokens", "CodeBleu_score": 63.56859574727435}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading audio data from {path}\")\n        audio_data, _ = librosa.load(\n            path,\n            sr=sample_rate,\n            offset=offset,\n            duration=duration,\n            dtype=dtype,\n        )\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.51822248468123}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading from {path.numpy()}\")\n        data, _ = librosa.load(\n            path.numpy(),\n            sr=sample_rate.numpy(),\n            offset=offset.numpy(),\n            duration=duration.numpy(),\n            dtype=dtype.numpy(),\n        )\n        return data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.05606476768794}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(f\"Loading {path}\")\n        return load(path, offset, duration, sample_rate, dtype), False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 19.693836369712635}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[-1] == n_channels:\n        return waveform\n    elif waveform.shape[-1] > n_channels:\n        return waveform[..., :n_channels]\n    else:\n        n_tiles = n_channels // waveform.shape[-1]\n        waveform = tf.tile(waveform, [1, n_tiles])\n        waveform = waveform[..., :n_channels]\n        return waveform\n\n\n", "CodeBleu_score": 44.05236471688787}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[-1] >= n_channels:\n        waveform = waveform[:, :n_channels]\n    else:\n        waveform = tf.tile(waveform, [1, n_channels // waveform.shape[-1] + 1])\n        waveform = waveform[:, :n_channels]\n    return waveform\n\n", "CodeBleu_score": 48.42049129429362}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[-1] == n_channels:\n        return waveform\n    elif waveform.shape[-1] > n_channels:\n        return waveform[:, :n_channels]\n    else:\n        n_repeats = n_channels // waveform.shape[-1] + 1\n        waveform = tf.tile(waveform, [1, n_repeats])\n        return waveform[:, :n_channels]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.469457321460915}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    spectrogram_db = gain_to_db(spectrogram)\n    max_db = tf.reduce_max(spectrogram_db)\n    spectrogram_db_clipped = tf.clip_by_value(\n        spectrogram_db, 0.0, max_db - db_range\n    )\n    return from_float32_to_uint8(spectrogram_db_clipped, **kwargs)\n\n", "CodeBleu_score": 46.64128464166348}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    db_spectrogram = gain_to_db(spectrogram)\n    max_db_spectrogram = tf.reduce_max(db_spectrogram)\n    db_spectrogram = tf.clip_by_value(\n        db_spectrogram, 0.0, max_db_spectrogram - db_range\n    )\n    db_spectrogram += db_range\n    return from_float32_to_uint8(db_spectrogram, **kwargs)\n\n", "CodeBleu_score": 52.54623604499048}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    spectrogram_db = gain_to_db(spectrogram)\n    max_db = tf.reduce_max(spectrogram_db)\n    spectrogram_db_clipped = tf.clip_by_value(\n        spectrogram_db, 0.0, max_db - db_range\n    )\n    return from_float32_to_uint8(spectrogram_db_clipped, **kwargs)\n\n", "CodeBleu_score": 46.64128464166348}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n\n    # Apply the Hann window function raised to a specified exponent\n    window = tf.signal.hann_window(frame_length, periodic=True) ** window_exponent\n\n    # Perform the STFT with defined frame length and step\n    stft = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=window,\n        pad_end=False,\n    )\n\n    # Transpose the spectrogram tensor\n    spectrogram = tf.transpose(tf.abs(stft) ** spec_exponent)\n\n    return spectrogram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.817599974887976}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    # Apply a Hann window raised to a specified exponent\n    window = hann_window(frame_length, periodic=True) ** window_exponent\n\n    # Perform the STFT with defined frame length and step\n    stft = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=window,\n        pad_end=True,\n    )\n\n    # Transpose the tensor and raise the absolute value to a specified exponent\n    spectrogram = tf.transpose(tf.abs(stft) ** spec_exponent)\n\n    return spectrogram\n\n\n\n\n", "CodeBleu_score": 39.043506958309905}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n\n    # Apply the Hann window function raised to a specified exponent\n    window = hann_window(frame_length, periodic=True, dtype=waveform.dtype) ** window_exponent\n\n    # Perform the STFT with defined frame length and step\n    stfts = tf.signal.stft(\n        waveform,\n        frame_length=frame_length,\n        frame_step=frame_step,\n        fft_length=frame_length,\n        window_fn=window,\n        pad_end=True,\n    )\n\n    # Transpose the STFT tensor and take the absolute value\n    spectrograms = tf.transpose(tf.abs(stfts), [0, 2, 1])\n\n    # Raise the absolute value of the spectrogram tensor to a specified exponent\n    return spectrograms ** spec_exponent\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.99369677752657}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original shape of the spectrogram\n    original_shape = tf.shape(spectrogram)\n\n    # Calculate the new time dimension\n    new_time_dim = tf.cast(\n        tf.cast(original_shape[1], tf.float32) * factor, tf.int32\n    )\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [original_shape[0], new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions\n    # by cropping or padding\n    if factor > 1.0:\n        # Crop the resized spectrogram to the original time dimension\n        adjusted_spectrogram = resized_spectrogram[\n            :, :original_shape[1]\n        ]\n    else:\n        # Pad the resized spectrogram to the original time dimension\n        padding = tf.maximum(0, original_shape[1] - new_time_dim)\n        adjusted_spectrogram = tf.pad(\n            resized_spectrogram, [[0, 0], [0, padding]]\n        )\n\n    return adjusted_spectrogram\n\n", "CodeBleu_score": 38.60552663720414}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the new time dimension\n    new_time_dim = int(spectrogram.shape[1] * factor)\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [spectrogram.shape[0], new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions\n    if factor > 1.0:\n        # Crop the spectrogram to the original dimensions\n        cropped_spectrogram = tf.image.crop_to_bounding_box(\n            resized_spectrogram, 0, 0, spectrogram.shape[0], spectrogram.shape[1]\n        )\n        return cropped_spectrogram\n    else:\n        # Pad the spectrogram with zeros to the original dimensions\n        padded_spectrogram = tf.image.pad_to_bounding_box(\n            resized_spectrogram, 0, 0, spectrogram.shape[0], spectrogram.shape[1]\n        )\n        return padded_spectrogram\n\n", "CodeBleu_score": 32.01242334910439}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Get the original shape of the spectrogram\n    original_shape = tf.shape(spectrogram)\n\n    # Calculate the new time dimension\n    new_time_dim = tf.cast(\n        tf.cast(original_shape[1], tf.float32) / factor, tf.int32\n    )\n\n    # Resize the spectrogram using the specified interpolation method\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [original_shape[0], new_time_dim], method=method\n    )\n\n    # Adjust the resized spectrogram to the original dimensions\n    # by cropping or padding\n    if factor > 1.0:\n        # Crop the spectrogram to the original dimensions\n        adjusted_spectrogram = resized_spectrogram[\n            :, : original_shape[1]\n        ]\n    else:\n        # Pad the spectrogram to the original dimensions\n        padding = original_shape[1] - new_time_dim\n        paddings = tf.constant([[0, 0], [0, padding]])\n        adjusted_spectrogram = tf.pad(resized_spectrogram, paddings)\n\n    return adjusted_spectrogram\n\n", "CodeBleu_score": 37.07974337315893}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    factor = 2.0 ** (semitone_shift / 12.0)\n\n    # Resize the spectrogram along the frequency axis\n    resized_spectrogram = tf.image.resize(\n        spectrogram, [int(spectrogram.shape[1] * factor), spectrogram.shape[2]], method\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [\n            [0, 0],\n            [\n                int((spectrogram.shape[1] - resized_spectrogram.shape[1]) / 2),\n                int((spectrogram.shape[1] - resized_spectrogram.shape[1]) / 2),\n            ],\n            [0, 0],\n        ],\n    )\n\n    # Return the pitch-shifted spectrogram\n    return padded_spectrogram\n\n", "CodeBleu_score": 26.517593462772137}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = 2.0 ** (semitone_shift / 12.0)\n\n    # Resize the spectrogram along the frequency axis\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        [int(spectrogram.shape[1] * resizing_factor), spectrogram.shape[2]],\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [\n            [\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n                (spectrogram.shape[1] - resized_spectrogram.shape[1]) // 2,\n            ],\n            [0, 0],\n        ],\n    )\n\n    # Return the pitch-shifted spectrogram\n    return padded_spectrogram\n\n\n\n\n\n", "CodeBleu_score": 26.00929973710045}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    if semitone_shift == 0.0:\n        return spectrogram\n\n    factor = 2.0 ** (semitone_shift / 12.0)\n    new_height = int(spectrogram.shape[1] * factor)\n    spectrogram = tf.image.resize(\n        spectrogram[tf.newaxis, :, :, tf.newaxis], [new_height, spectrogram.shape[2]], method=method\n    )[0, :, :, 0]\n\n    # Pad the resized spectrogram to the original shape\n    padding_top = (spectrogram.shape[0] - new_height) // 2\n    padding_bottom = spectrogram.shape[0] - new_height - padding_top\n    spectrogram = tf.pad(spectrogram, [[padding_top, padding_bottom], [0, 0]])\n\n    return spectrogram\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.263263157304564}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ELU\":\n        return ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return LeakyReLU(negative_slope=0.2)\n    else:\n        return ReLU()\n\n", "CodeBleu_score": 49.261933733866655}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params.get(\"conv_activation\", \"ReLU\") == \"ELU\":\n        return nn.ELU(alpha=1.0, inplace=True)\n    elif params.get(\"conv_activation\", \"ReLU\") == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2, inplace=True)\n    else:\n        return nn.ReLU(inplace=True)\n\n", "CodeBleu_score": 34.517813396232135}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    conv_activation = params.get(\"conv_activation\", \"ReLU\")\n    if conv_activation == \"ReLU\":\n        return nn.ReLU()\n    elif conv_activation == \"ELU\":\n        return nn.ELU()\n    elif conv_activation == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(\n            f\"conv_activation must be either 'ReLU', 'ELU', or 'LeakyReLU', but got {conv_activation}\"\n        )\n\n\n\n", "CodeBleu_score": 42.13139483117532}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask_list.append(\n            apply_unet(input_tensor, instrument, params, output_mask_logit=True)\n        )\n    logit_masks_stack = tf.stack(logit_mask_list, axis=-1)\n    mask = Softmax(axis=-1)(logit_masks_stack)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = Multiply(name=instrument)(\n            [mask[..., i : i + 1], input_tensor]\n        )\n    return output_dict\n\n", "CodeBleu_score": 39.43446779691731}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(\n            input_tensor,\n            output_name=f\"{instrument}_spectrogram\",\n            params=params,\n            output_mask_logit=True,\n        )\n        logit_mask_list.append(logit_mask)\n    logit_masks_stack = tf.stack(logit_mask_list, axis=-1)\n    mask = Softmax(axis=-1)(logit_masks_stack)\n    mask = tf.split(mask, len(instruments), axis=-1)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = Multiply(name=f\"{instrument}_spectrogram\")(\n            [mask[i], input_tensor]\n        )\n    return output_dict\n\n", "CodeBleu_score": 45.307694925461895}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logit_mask_list = []\n    for instrument in instruments:\n        logit_mask = apply_unet(input_tensor, instrument, params)\n        logit_mask_list.append(logit_mask)\n    logit_mask = tf.stack(logit_mask_list, axis=-1)\n    mask = Softmax(axis=-1)(logit_mask)\n    output_dict = {}\n    for i, instrument in enumerate(instruments):\n        output_dict[instrument] = Multiply(name=instrument)(\n            [mask[..., i : i + 1], input_tensor]\n        )\n    return output_dict\n\n", "CodeBleu_score": 38.141413383157676}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as stream:\n        for chunk in iter(lambda: stream.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n", "CodeBleu_score": 74.81653623241759}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as stream:\n        for chunk in iter(lambda: stream.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()", "CodeBleu_score": 74.81653623241759}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as stream:\n        for chunk in iter(lambda: stream.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n\n\n\n\n", "CodeBleu_score": 74.81653623241759}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/index.json\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index.\")\n    return index[name][\"checksum\"]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.11507371475008}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/checksums.json\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"Model {name} not found in index\")\n    return index[name]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.13302740867803}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/checksum.json\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    index = response.json()\n    if name not in index:\n        raise ValueError(f\"{name} not found in index\")\n    return index[name]", "CodeBleu_score": 35.716127223738546}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_PATH,\n            f\"{name}.tar.gz\",\n        )\n    )\n    logger.info(f\"Downloading model {name} from {url}\")\n    with NamedTemporaryFile(delete=False) as temp_file:\n        with httpx.stream(\"GET\", url) as response:\n            response.raise_for_status()\n            for chunk in response.iter_raw():\n                temp_file.write(chunk)\n        checksum: str = compute_file_checksum(temp_file.name)\n        if checksum != self.checksum(name):\n            raise IOError(f\"Invalid checksum for model {name}\")\n        logger.info(f\"Extracting model {name} to {path}\")\n        with tarfile.open(temp_file.name, \"r:gz\") as tar:\n            tar.extractall(path)\n        os.unlink(temp_file.name)\n\n\n", "CodeBleu_score": 50.836119217908724}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_PATH,\n            f\"{name}.tar.gz\",\n        )\n    )\n    logger.info(f\"Downloading {name} model from {url}\")\n    with NamedTemporaryFile() as tmp_file:\n        with httpx.stream(\"GET\", url) as response:\n            response.raise_for_status()\n            with open(tmp_file.name, \"wb\") as stream:\n                for chunk in response.iter_raw():\n                    stream.write(chunk)\n        checksum: str = compute_file_checksum(tmp_file.name)\n        if checksum != self.checksum(name):\n            raise IOError(\n                f\"Checksum mismatch, expected {self.checksum(name)} but got {checksum}\"\n            )\n        logger.info(f\"Extracting {name} model to {path}\")\n        with tarfile.open(tmp_file.name, \"r:gz\") as tar:\n            tar.extractall(path)\n        os.unlink(tmp_file.name)\n\n\n", "CodeBleu_score": 52.978766252550514}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_PATH,\n            name,\n        )\n    )\n    logger.info(f\"Downloading model {name} from {url}\")\n    with httpx.stream(\"GET\", url) as response:\n        response.raise_for_status()\n        with tempfile.NamedTemporaryFile(delete=False) as stream:\n            for chunk in response.iter_raw():\n                stream.write(chunk)\n    checksum: str = compute_file_checksum(stream.name)\n    if checksum != self.checksum(name):\n        raise IOError(f\"Invalid checksum for model {name}\")\n    logger.info(f\"Validated checksum for model {name}\")\n    with tarfile.open(stream.name, \"r:gz\") as archive:\n        archive.extractall(path)\n    logger.info(f\"Extracted model {name} to {path}\")\n    os.unlink(stream.name)\n\n", "CodeBleu_score": 52.06191241261997}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor.split(\"embedded://\")[1]\n        if not loader.is_resource(name):\n            raise SpleeterError(\n                f\"No embedded configuration file found for name {name}.\"\n            )\n        with loader.open_text(name) as f:\n            return json.load(f)\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"No configuration file found for name {descriptor}.\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)\n\n\n\n\n", "CodeBleu_score": 57.0328866786415}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor[len(\"embedded://\") :]\n        if not loader.is_resource(name):\n            raise SpleeterError(\n                f\"No embedded asset found for configuration {name}\"\n            )\n        with loader.open_text(name) as f:\n            return json.load(f)\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"No such configuration file : {descriptor}\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.275566051796815}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor[len(\"embedded://\") :]\n        if not loader.is_resource(name):\n            raise SpleeterError(\n                f\"No embedded configuration file found for name {name}\"\n            )\n        with loader.open_text(name) as f:\n            return json.load(f)\n    if not os.path.exists(descriptor):\n        raise SpleeterError(f\"No configuration file found for path {descriptor}\")\n    with open(descriptor, \"r\") as f:\n        return json.load(f)", "CodeBleu_score": 51.53484237156477}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    # Check if the concatenation axis is either 0 or 1\n    if concat_axis not in [0, 1]:\n        raise ValueError(\"concat_axis must be either 0 or 1\")\n\n    # Concatenate the tensors along the specified axis\n    concat_tensor = tf.concat(list(tensor_dict.values()), axis=concat_axis)\n\n    # Apply the function to the concatenated tensor\n    processed_concat_tensor = func(concat_tensor)\n\n    # Split the processed tensor back into the original dictionary format based on the concatenation axis\n    processed_tensor_dict = {}\n    if concat_axis == 0:\n        for i, key in enumerate(tensor_dict.keys()):\n            processed_tensor_dict[key] = processed_concat_tensor[i]\n    elif concat_axis == 1:\n        start_index = 0\n        for i, key in enumerate(tensor_dict.keys()):\n            end_index = start_index + tensor_dict[key].shape[1]\n            processed_tensor_dict[key] = processed_concat_tensor[\n                :, start_index:end_index\n            ]\n            start_index = end_index\n\n    return processed_tensor_dict\n\n\n\n", "CodeBleu_score": 48.12537548906116}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(\n            \"Concatenation axis must be either 0 or 1, but got {}\".format(concat_axis)\n        )\n    concat_fn = tf.concat if concat_axis == 0 else tf.stack\n    split_fn = tf.unstack if concat_axis == 0 else tf.split\n    tensor_list = list(tensor_dict.values())\n    processed_tensor = func(concat_fn(tensor_list, axis=concat_axis))\n    processed_tensor_list = split_fn(processed_tensor, axis=concat_axis)\n    return {\n        key: tensor\n        for key, tensor in zip(tensor_dict.keys(), processed_tensor_list)\n    }\n\n", "CodeBleu_score": 40.928654700784705}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\n            \"only support concat_axis in [0, 1] for now.\"\n        )\n\n    # concat\n    tensors = tf.concat(list(tensor_dict.values()), axis=concat_axis)\n\n    # apply func\n    processed_tensors = func(tensors)\n\n    # split\n    processed_tensor_dict = {}\n    start = 0\n    for i, (k, v) in enumerate(tensor_dict.items()):\n        shape = tf.shape(v)\n        if concat_axis == 0:\n            length = shape[0]\n        else:\n            length = shape[1]\n        processed_tensor_dict[k] = processed_tensors[\n            start : start + length\n        ]\n        start += length\n    return processed_tensor_dict\n\n\n\n\n\n", "CodeBleu_score": 44.18754116722199}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n\n    scaled_tensor = tf.cast(\n        (tensor - min_value) / (max_value - min_value) * 255, tf.uint8\n    )\n\n    return {\n        tensor_key: scaled_tensor,\n        min_key: min_value,\n        max_key: max_value,\n    }\n\n", "CodeBleu_score": 44.6464839411674}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        tf.round(255 * (tensor - min_value) / (max_value - min_value)), tf.uint8\n    )\n    return {\n        tensor_key: scaled_tensor,\n        min_key: min_value,\n        max_key: max_value,\n    }\n\n\n\n", "CodeBleu_score": 44.165398593232716}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        (tensor - min_value) / (max_value - min_value) * 255, tf.uint8\n    )\n    return {tensor_key: scaled_tensor, min_key: min_value, max_key: max_value}\n\n", "CodeBleu_score": 40.74284649378469}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    padding_len = (-len(tensor)) % segment_len\n    tensor = tf.pad(tensor, [[0, padding_len]])\n    return tf.reshape(tensor, [-1, segment_len])\n\n", "CodeBleu_score": 14.714566553925328}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    original_shape = tf.shape(tensor)\n    tensor = tf.reshape(tensor, [-1])\n    pad_len = (-tf.shape(tensor)[0]) % segment_len\n    tensor = tf.pad(tensor, [[0, pad_len]])\n    return tf.reshape(tensor, [-1, segment_len])\n\n", "CodeBleu_score": 23.75914263258691}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    # Calculate the padding needed to make the tensor length a multiple of the segment length\n    padding = segment_len - tf.math.floormod(tf.shape(tensor)[0], segment_len)\n\n    # Pad the tensor with zeros to make its length a multiple of the segment length\n    padded_tensor = tf.pad(tensor, [[0, padding], [0, 0]])\n\n    # Reshape the padded tensor into segments of the specified length\n    segmented_tensor = tf.reshape(padded_tensor, [-1, segment_len, tensor.shape[1]])\n\n    return segmented_tensor\n\n", "CodeBleu_score": 27.153884998725292}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    n_frames = instr_spec.shape[1]\n    n_paddings = -n_frames % frame_length\n    padding = tf.zeros((instr_spec.shape[0], n_paddings, F))\n    padded = tf.concat((instr_spec, padding), axis=1)\n    n_frames = padded.shape[1]\n    n_segments = n_frames // frame_length\n    new_shape = (instr_spec.shape[0] * n_segments, frame_length, F)\n    reshaped = tf.reshape(padded, new_shape)\n    return reshaped\n\n", "CodeBleu_score": 19.43287256810125}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    n_extra_rows = frame_length - instr_spec.shape[0] % frame_length\n    extension = tf.zeros((n_extra_rows, instr_spec.shape[1]))\n    padded_spec = tf.concat([instr_spec, extension], axis=0)\n    n_frames = padded_spec.shape[0] // frame_length\n    reshaped_spec = tf.reshape(padded_spec, (n_frames, frame_length, F))\n    return reshaped_spec\n\n", "CodeBleu_score": 19.142892103179545}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    n_extra_rows = frame_length - (instr_spec.shape[0] % frame_length)\n    # Create an extension of zeros\n    extension = tf.zeros((n_extra_rows, instr_spec.shape[1]))\n    # Concatenate the extension to the original spectrogram along the frequency axis\n    extended_spec = tf.concat([instr_spec, extension], axis=0)\n    # Reshape the extended spectrogram by merging the first two dimensions\n    reshaped_spec = tf.reshape(extended_spec, (instr_spec.shape[0] + n_extra_rows, instr_spec.shape[1], 1))\n    return reshaped_spec\n\n", "CodeBleu_score": 21.786479475025867}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n", "CodeBleu_score": 27.127655353502654}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n", "CodeBleu_score": 27.127655353502654}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.127655353502654}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, l in enumerate(target_shape):\n        if l is not None:\n            result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], l))\n    return result\n\n", "CodeBleu_score": 40.838703431382385}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        if length is not None:\n            result = tf.logical_and(result, tf.equal(tf.shape(tensor_tf)[i], length))\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.62285958199549}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, length in enumerate(target_shape):\n        if length is not None:\n            result = tf.logical_and(\n                result, tf.equal(tf.shape(tensor_tf)[i], length)\n            )\n    return result\n\n", "CodeBleu_score": 50.49213831057382}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    train_csv = os.path.join(audio_path, \"train.csv\")\n    cache_directory = os.path.join(audio_path, \"cache\")\n    builder = DatasetBuilder(\n        audio_params,\n        audio_adapter,\n        chunk_duration=11.88,\n        random_seed=1234,\n    )\n    dataset = builder.build(\n        train_csv,\n        cache_directory=cache_directory,\n        batch_size=8,\n        n_chunks_per_song=2,\n        random_data_augmentation=True,\n        infinite_generator=True,\n        cache_directory=cache_directory,\n        wait_for_cache=True,\n    )\n    return dataset\n\n", "CodeBleu_score": 42.85024256781092}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    # Initialize the dataset builder.\n    builder = DatasetBuilder(\n        audio_params,\n        audio_adapter,\n        chunk_duration=5.0,\n        random_seed=42,\n    )\n    # Build the dataset.\n    return builder.build(\n        train_csv_path,\n        cache_directory=cache_directory,\n        batch_size=batch_size,\n        n_chunks_per_song=n_chunks_per_song,\n        random_data_augmentation=random_data_augmentation,\n        cache_in_file=cache_in_file,\n        wait_for_cache=wait_for_cache,\n    )\n\n", "CodeBleu_score": 33.945953983057436}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t\n    builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        chunk_duration=11.88,\n        random_seed=42,\n    )\n    dataset = builder.build(\n        csv_path=train_csv,\n        cache_directory=audio_path,\n        batch_size=8,\n        n_chunks_per_song=2,\n        random_data_augmentation=True,\n        wait_for_cache=True,\n    )\n    return dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.219382185634068}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = [InstrumentDatasetBuilder(self, instrument) for instrument in self.instruments()]\n    for builder in self._instrument_builders:\n        yield builder\n\n\n\n", "CodeBleu_score": 46.16264518562785}, {"code": "def instruments(self) -> Any\n\t\n    if not self._instrument_builders:\n        for instrument in self.instruments_list:\n            self._instrument_builders.append(\n                InstrumentDatasetBuilder(\n                    instrument=instrument,\n                    dataset_builder=self,\n                )\n            )\n    for instrument_builder in self._instrument_builders:\n        yield instrument_builder\n\n\n\n", "CodeBleu_score": 41.90599725270715}, {"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = [\n            InstrumentDatasetBuilder(\n                self.client,\n                self.universe,\n                self.dataset_id,\n                self.dataset_name,\n                self.dataset_type,\n                self.instrument_type,\n                self.instrument_id,\n                self.instrument_name,\n                self.instrument_dataset_id,\n                self.instrument_dataset_name,\n                self.instrument_dataset_type,\n                self.instrument_dataset_schema,\n                self.instrument_dataset_input_schema,\n                self.instrument_dataset_output_schema,\n                self.instrument_dataset_etl,\n                self.instrument_dataset_etl_input_schema,\n                self.instrument_dataset_etl_output_schema,\n                self.instrument_dataset_etl_output_table,\n                self.instrument_dataset_etl_output_table_schema,\n                self.instrument_dataset_etl_output_table_input_schema,\n                self.instrument_dataset_etl_output_table_output_schema,\n                self.instrument_dataset_etl_output_table_output_table,\n                self.instrument_dataset_etl_output_table_output_table_schema,\n                self.instrument_dataset_etl_output_table_output_table_input_schema,\n                self.instrument_dataset_etl_output_table_output_table_output_schema,\n                self.instrument_dataset_etl_output_table_output_table_output_table,\n                self.instrument_dataset_etl_output_table_output_table_output_table_schema,\n                self.instrument_dataset_etl_output_table_output_table_output_table_input_schema,\n                self.instrument_dataset_etl_output_table_output_table_output_table_output_schema,\n                self.instrument_dataset_etl_output_table_output_table_output_table_output_table,\n                self.", "CodeBleu_score": 19.772098936305756}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 93.65648279369884}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default(params[\"model_dir\"])\n    params.update(\n        {\n            \"model_dir\": model_dir,\n        }\n    )\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    config.gpu_options.per_process_gpu_memory_fraction = 0.45\n    run_config = tf.estimator.RunConfig(session_config=config)\n    return tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=model_dir,\n        params=params,\n        config=run_config,\n    )\n\n", "CodeBleu_score": 32.78168676035283}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n\n    model_dir = ModelProvider.default(params[\"model_dir\"])\n    params.update({\"model_dir\": model_dir})\n\n    session_config = tf.compat.v1.ConfigProto()\n    session_config.gpu_options.allow_growth = True\n    session_config.gpu_options.per_process_gpu_memory_fraction = 0.45\n\n    config = RunConfig(\n        model_dir=params[\"model_dir\"],\n        save_summary_steps=params[\"save_summary_steps\"],\n        save_checkpoints_steps=params[\"save_checkpoints_steps\"],\n        tf_random_seed=params[\"seed\"],\n        session_config=session_config,\n        keep_checkpoint_max=params[\"keep_checkpoint_max\"],\n        log_step_count_steps=params[\"log_step_count_steps\"],\n    )\n\n    params[\"batch_size\"] = (\n        params[\"batch_size_per_gpu\"] * params[\"num_gpus\"]\n        if MWF\n        else params[\"batch_size\"]\n    )\n\n    return tf.estimator.Estimator(\n        model_fn=model_fn, params=params, config=config, model_dir=model_dir\n    )\n\n", "CodeBleu_score": 30.608384315181098}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_dir = ModelProvider.default(params[\"model_dir\"])\n    params.update({\"model_dir\": model_dir})\n\n    session_config = tf.ConfigProto()\n    session_config.gpu_options.allow_growth = True\n    session_config.gpu_options.per_process_gpu_memory_fraction = 0.45\n\n    config = RunConfig(\n        model_dir=params[\"model_dir\"],\n        save_summary_steps=params[\"save_summary_steps\"],\n        save_checkpoints_steps=params[\"save_checkpoints_steps\"],\n        tf_random_seed=params[\"seed\"],\n        session_config=session_config,\n        keep_checkpoint_max=params[\"keep_checkpoint_max\"],\n    )\n\n    model_fn = model_fn_estimator if MWF else model_fn_estimator_not_MWF\n    return tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=config,\n    )\n\n", "CodeBleu_score": 32.39416690316491}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n        waveform = to_stereo(waveform)\n        prediction_generator = self._get_prediction_generator()\n        self._data_generator.update_data(\n            {\"waveform\": waveform, \"audio_id\": audio_descriptor.audio_id}\n        )\n        prediction = next(prediction_generator)\n        prediction.pop(\"audio_id\")\n        return prediction\n\n", "CodeBleu_score": 59.37752959634513}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n        waveform = to_stereo(waveform)\n        prediction_generator = self._get_prediction_generator()\n        self._data_generator.update_data((waveform, audio_descriptor))\n        prediction = next(prediction_generator)\n        prediction.pop(\"audio_id\")\n        return prediction\n\n", "CodeBleu_score": 49.516405931484115}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = to_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self._data_generator.update_data(\n        {\"waveform\": waveform, \"audio_id\": audio_descriptor.audio_id}\n    )\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 58.89632567145773}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n    return np.array(\n        [[int(math.ceil(image_shape[0] / stride)),\n            int(math.ceil(image_shape[1] / stride))]\n            for stride in config.BACKBONE_STRIDES])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 95.198357853076}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n    return np.array(\n        [[int(math.ceil(image_shape[0] / stride)),\n            int(math.ceil(image_shape[1] / stride))]\n         for stride in config.BACKBONE_STRIDES])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.96652467722696}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n\n    # Currently supports ResNet only\n    if config.BACKBONE in [\"resnet50\", \"resnet101\"]:\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)),\n              int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n\n    assert(\n        False,\n        \"compute_backbone_shapes not yet supported for the selected backbone\"\n    )\n\n\n\n\n", "CodeBleu_score": 81.1106915005741}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        # Split coordinates of boxes and window into separate variables w.r.t x and y.\n        win_y_min, win_x_min, win_y_max, win_x_max = tf.split(\n            value=window, num_or_size_splits=4)\n        box_ymin, box_xmin, box_ymax, box_xmax = tf.split(\n            value=boxes, num_or_size_splits=4, axis=1)\n\n        # Clip the box coordinates to be within the window's boundaries.\n        clipped_y_min = tf.maximum(tf.minimum(box_ymin, win_y_max), win_y_min)\n        clipped_x_min = tf.maximum(tf.minimum(box_xmin, win_x_max), win_x_min)\n        clipped_y_max = tf.maximum(tf.minimum(box_ymax, win_y_max), win_y_min)\n        clipped_x_max = tf.maximum(tf.minimum(box_xmax, win_x_max), win_x_min)\n\n        # Concatenate the clipped coordinates into a single tensor.\n        clipped = tf.concat([clipped_y_min, clipped_x_min,\n                             clipped_y_max, clipped_x_max], axis=1, name='concat')\n        clipped.set_shape((clipped.shape[0], 4))\n        return clipped\n\n", "CodeBleu_score": 43.65134682798785}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        # Split coordinates of boxes and window into separate variables w.r.t x and y.\n        # w.r.t stands for with respect to.\n        win_y_min, win_x_min, win_y_max, win_x_max = tf.split(axis=0, num_or_size_splits=4, value=window)\n        box_y_min, box_x_min, box_y_max, box_x_max = tf.split(axis=1, num_or_size_splits=4, value=boxes)\n\n        # Clip the window coordinates to the valid range i.e. to the image dimensions.\n        win_y_min = tf.maximum(tf.minimum(win_y_min, IMAGE_HEIGHT), 0)\n        win_x_min = tf.maximum(tf.minimum(win_x_min, IMAGE_WIDTH), 0)\n        win_y_max = tf.minimum(tf.maximum(win_y_max, 0), IMAGE_HEIGHT)\n        win_x_max = tf.minimum(tf.maximum(win_x_max, 0), IMAGE_WIDTH)\n\n        # Clip the boxes into the window.\n        clipped_y_min = tf.maximum(tf.minimum(box_y_min, win_y_max), win_y_min)\n        clipped_x_min = tf.maximum(tf.minimum(box_x_min, win_x_max), win_x_min)\n        clipped_y_max = tf.maximum(tf.minimum(box_y_max, win_y_max), win_y_min)\n        clipped_x_max = tf.maximum(tf.minimum(box_x_max, win_x_max), win_x_min)\n\n        # Concatenate the clipped coordinates to a tensor.\n        clipped = tf.concat([clipped_y_min, clipped_x_min, clipped_y", "CodeBleu_score": 35.472406558675715}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    with tf.name_scope('clip_to_window'):\n        # Split coordinates of boxes and window into separate variables w.r.t x and y\n        # you will now have 4 tensors: [boxes_x1, boxes_x2, boxes_y1, boxes_y2]\n        bx1, by1, bx2, by2 = tf.split(boxes, 4, axis=1)\n        wx1, wy1, wx2, wy2 = tf.split(window, 4)\n\n        # Clip the boxes to fit within the window\n        # Adjust the bounding box coordinates w.r.t the window boundaries\n        bx1_clipped = tf.maximum(tf.minimum(bx1, wx2), wx1)\n        by1_clipped = tf.maximum(tf.minimum(by1, wy2), wy1)\n        bx2_clipped = tf.maximum(tf.minimum(bx2, wx2), wx1)\n        by2_clipped = tf.maximum(tf.minimum(by2, wy2), wy1)\n\n        # Concatenate the clipped boxes into a single tensor\n        clipped = tf.concat([bx1_clipped, by1_clipped, bx2_clipped, by2_clipped], axis=1, name='clipped_boxes')\n        clipped.set_shape((clipped.shape[0], 4))\n        return clipped\n\n", "CodeBleu_score": 53.71546632639359}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n\n    # Apply the shared convolutional layer to the feature map\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                       strides=anchor_stride,\n                       name='rpn_conv_shared')(feature_map)\n\n    # Apply the class score convolutional layer\n    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape the class scores to match the desired output shape\n    rpn_class_logits = tf.reshape(x, [-1, 2])\n\n    # Apply the softmax activation to obtain class probabilities\n    rpn_probs = tf.nn.softmax(rpn_class_logits, axis=1)\n\n    # Apply the bounding box prediction convolutional layer\n    x = KL.Conv2D(6 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape the bounding box predictions to match the desired output shape\n    rpn_bbox = tf.reshape(x, [-1, 6])\n\n    # Return the class logits, class probabilities, and bounding box predictions\n    return rpn_class_logits, rpn_probs, rpn_bbox\n\n", "CodeBleu_score": 53.45861085490963}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                       strides=anchor_stride,\n                       name='rpn_conv_shared')(feature_map)\n\n    # Class score layer\n    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape the class score layer\n    rpn_class_logits = tf.reshape(x, [-1, 2])\n\n    # Softmax activation for class probabilities\n    rpn_probs = tf.nn.softmax(rpn_class_logits, axis=1)\n\n    # Bounding box prediction layer\n    x = KL.Conv2D(6 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape the bounding box prediction layer\n    rpn_bbox = tf.reshape(x, [-1, 6])\n\n    # Lambda layer to format the bounding box predictions\n    rpn_bbox = KL.Lambda(lambda x: x)(rpn_bbox)\n\n    return rpn_class_logits, rpn_probs, rpn_bbox\n\n", "CodeBleu_score": 56.94958107606547}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu',\n                       strides=anchor_stride,\n                       name='rpn_conv_shared')(feature_map)\n\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = KL.Conv2D(2 * anchors_per_location, (1, 1), padding='valid',\n                  activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape to [batch, anchors, 2]\n    rpn_class_logits = tf.reshape(x, [tf.shape(x)[0], -1, 2])\n\n    # Softmax on last dimension of BG/FG.\n    rpn_probs = tf.nn.softmax(rpn_class_logits, axis=-1)\n\n    # Bounding box refinement. [batch, H, W, anchors per location, depth]\n    # where depth is [x, y, log(w), log(h)]\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding=\"valid\",\n                  activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape to [batch, anchors, 4]\n    rpn_bbox = tf.reshape(x, [tf.shape(x)[0], -1, 4])\n\n    return rpn_class_logits, rpn_probs, rpn_bbox\n\n", "CodeBleu_score": 64.27293579870745}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), K.floatx())\n    loss = (1.0 - mask) * (0.5 * abs_diff**2) + mask * (abs_diff - 0.5)\n    return loss\n\n", "CodeBleu_score": 33.487004050709984}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), dtype='float32')\n    return (abs_diff ** 2) * mask + (abs_diff - 0.5) * (1.0 - mask)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.074153948424904}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), K.floatx())\n    return (mask * 0.5 * abs_diff**2) + ((1 - mask) * (abs_diff - 0.5))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.878120815624506}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    K.clear_session()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    x = KL.Conv2D(32, (3, 3), activation='relu')(input_layer)\n    x = KL.Conv2D(64, (3, 3), activation='relu')(x)\n    x = KL.MaxPooling2D(pool_size=(2, 2))(x)\n    x = KL.Flatten()(x)\n    x = KL.Dense(128, activation='relu')(x)\n    output_layer = KL.Dense(num_classes, activation='softmax')(x)\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n\n\n\n\n", "CodeBleu_score": 35.800622034035335}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    x = KL.Conv2D(32, (3, 3), activation='relu')(input_layer)\n    x = KL.Conv2D(64, (3, 3), activation='relu')(x)\n    x = KL.MaxPooling2D(pool_size=(2, 2))(x)\n    x = KL.Flatten()(x)\n    x = KL.Dense(128, activation='relu')(x)\n    x = KL.Dense(num_classes, activation='softmax')(x)\n    model = KM.Model(input_layer, x)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model", "CodeBleu_score": 36.53584371417426}, {"code": "def build_model(x_train, num_classes)\n\t\n    KTF.set_session(KTF.get_session())\n    KTF.set_learning_phase(1)\n    KTF.reset_default_graph()\n    input_shape = x_train.shape[1:]\n    model = KM.Sequential()\n    model.add(KL.Input(shape=input_shape))\n    model.add(KL.Conv2D(32, kernel_size=(3, 3), activation='relu'))\n    model.add(KL.Conv2D(64, (3, 3), activation='relu'))\n    model.add(KL.MaxPooling2D(pool_size=(2, 2)))\n    model.add(KL.Flatten())\n    model.add(KL.Dense(128, activation='relu'))\n    model.add(KL.Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n\n\n\n", "CodeBleu_score": 27.796216486734572}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            x2 += 1\n            y2 += 1\n        else:\n            x1, x2, y1, y2 = 0, 0, 0, 0\n\n        boxes[i] = np.array([y1, x1, y2, x2])\n    return boxes.astype(np.int32)\n\n\n\n\n", "CodeBleu_score": 79.8090520516883}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            boxes[i] = np.array([y1, x1, y2, x2])\n        else:\n            boxes[i] = np.zeros((4,), dtype=np.int32)\n    return boxes.astype(np.int32)\n\n", "CodeBleu_score": 66.18595577883224}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros([mask.shape[-1], 4], dtype=np.int32)\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            x2 += 1\n            y2 += 1\n        else:\n            x1, x2, y1, y2 = 0, 0, 0, 0\n        boxes[i] = np.array([y1, x1, y2, x2])\n    return boxes.astype(np.int32)\n\n\n\n\n", "CodeBleu_score": 79.8090520516883}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 58.663259083089194}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    y1 = np.maximum(box[0], boxes[:, 0])\n    y2 = np.minimum(box[2], boxes[:, 2])\n    x1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[3], boxes[:, 3])\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 58.663259083089194}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # Compute overlaps matrix which contains IoU value at i-th row and j-th column.\n    # boxes1: [N, (y1, x1, y2, x2)]\n    # boxes2: [M, (y1, x1, y2, x2)]\n    # overlaps: [N, M]\n    N = boxes1.shape[0]\n    M = boxes2.shape[0]\n    overlaps = np.zeros((N, M))\n    for n in range(N):\n        for m in range(M):\n            # Calculate the area of each box in both sets\n            box1_area = (boxes1[n, 2] - boxes1[n, 0]) * (boxes1[n, 3] - boxes1[n, 1])\n            box2_area = (boxes2[m, 2] - boxes2[m, 0]) * (boxes2[m, 3] - boxes2[m, 1])\n            # Calculate the Intersection over Union (IoU) of the two boxes\n            iou = compute_iou(boxes1[n], boxes2[m], box1_area, box2_area)\n            # Store the IoU value in the overlaps matrix\n            overlaps[n, m] = iou\n    return overlaps\n\n", "CodeBleu_score": 25.854407927179345}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # compute overlaps\n    # generate box areas\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n\n    # initialize overlap matrix\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n\n    # iterate through boxes2 and compute IoU with each box in boxes1\n    for i in range(boxes2.shape[0]):\n        overlaps[:, i] = compute_iou(boxes2[i], boxes1, area2[i], area1)\n\n    return overlaps\n\n", "CodeBleu_score": 55.70923231107078}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # compute overlaps\n    # generate boxes\n    boxes1 = np.array(boxes1)\n    boxes2 = np.array(boxes2)\n    if boxes1.ndim == 1:\n        boxes1 = boxes1[None, :]\n    if boxes2.ndim == 1:\n        boxes2 = boxes2[None, :]\n    assert boxes1.shape[1] == 4 and boxes2.shape[1] == 4,\\\n        \"Each box must have 4 elements\"\n    # compute areas of the boxes\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n    # compute overlaps to generate matrix [boxes1 count, boxes2 count]\n    # each cell contains the IoU value.\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        box2 = boxes2[i]\n        overlaps[:, i] = compute_iou(box2, boxes1, area2[i], area1)\n    return overlaps\n\n", "CodeBleu_score": 73.39960930738563}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n    info = self.image_info[image_id]\n    image = imread(info['path'])\n    # if RGBA, remove the alpha channel\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    # convert grayscale images to RGB\n    if len(image.shape) != 3 or image.shape[-1] != 3:\n        image = gray2rgb(image)\n    return image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 64.40486856707949}, {"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = imread(image_path)\n    if image.ndim == 2:\n        image = gray2rgb(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n\n\n\n", "CodeBleu_score": 66.65644176098624}, {"code": "def load_image(self, image_id):\n\t\n    image_info = self.image_info[image_id]\n    image = imread(image_info['path'])\n    if len(image.shape) != 3 or image.shape[2] != 3:\n        image = gray2rgb(image)\n    if image.shape[2] == 4:\n        image = image[:, :, :3]\n    return image", "CodeBleu_score": 52.079290755123786}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm, interpolation = interpolation)\n        a.set_title(title)\n        plt.axis('off')\n    _ = plt.show()\n\n\n\n\n\n\n", "CodeBleu_score": 37.94918631078225}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm,\n                   interpolation=interpolation)\n        a.set_title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n\n", "CodeBleu_score": 37.19908161603908}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1,n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images/float(cols)), n + 1)\n        if image.ndim == 2:\n            plt.gray()\n        plt.imshow(image, cmap = cmap, norm = norm, interpolation = interpolation)\n        a.set_title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 37.34884452383222}]}
