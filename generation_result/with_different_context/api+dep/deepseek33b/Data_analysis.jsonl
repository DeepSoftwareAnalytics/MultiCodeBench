{"instance_id": "58936b2a621b", "generation_result": [{"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 83.87646776544821}]}
{"instance_id": "83b142d9d251", "generation_result": [{"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data, label, train_size=support_ratio, random_state=42, stratify=label\n    )\n    return x_train, x_test, y_train, y_test\n\n\n\n\n", "CodeBleu_score": 70.37308698305998}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data, label, train_size=support_ratio, random_state=42, stratify=label\n    )\n    return x_train, x_test, y_train, y_test\n\n\n\n\n", "CodeBleu_score": 70.37308698305998}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}]}
{"instance_id": "5fd02b540f61", "generation_result": [{"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=100, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.988730693271556}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}]}
{"instance_id": "ad958cb31a57", "generation_result": [{"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    label = ndarrays[0]\n    means = ndarrays[1]\n    weights = ndarrays[2]\n    covariances = ndarrays[3]\n    num_samples = ndarrays[4]\n    return GMMParameters(label, means, weights, covariances, num_samples)\n\n", "CodeBleu_score": 40.08951228295815}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(ndarrays[0], ndarrays[1], ndarrays[2], ndarrays[3], ndarrays[4])\n\n", "CodeBleu_score": 28.988763610480394}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        ndarrays[0],\n        ndarrays[1],\n        ndarrays[2],\n        ndarrays[3],\n        ndarrays[4],\n    )\n\n", "CodeBleu_score": 43.55158623916156}]}
{"instance_id": "061d5a5b9d56", "generation_result": [{"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for i in range(1, len(data_paths)):\n        X_i, Y_i = load_svmlight_file(data_paths[i])\n        X_i = X_i.toarray()\n        if X_i.shape[1] != X.shape[1]:\n            raise ValueError(f\"Number of features in file {i} does not match previous files\")\n        X = np.concatenate((X, X_i), axis=0)\n        Y = np.concatenate((Y, Y_i), axis=0)\n    return X, Y", "CodeBleu_score": 41.96359173699521}, {"code": "def datafiles_fusion(data_paths):\n\t\n    # Load the first data file\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n\n    # Load and concatenate the remaining data files\n    for i in range(1, len(data_paths)):\n        X_new, Y_new = load_svmlight_file(data_paths[i])\n        X_new = X_new.toarray()\n\n        # Ensure the number of features matches the first file\n        assert X_new.shape[1] == X.shape[1]\n\n        # Concatenate the new features and labels\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n\n    return X, Y", "CodeBleu_score": 43.43354795510007}, {"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for path in data_paths[1:]:\n        X_i, Y_i = load_svmlight_file(path)\n        assert X_i.shape[1] == X.shape[1]\n        X = np.concatenate((X, X_i.toarray()), axis=0)\n        Y = np.concatenate((Y, Y_i), axis=0)\n    return X, Y\n\n", "CodeBleu_score": 36.33133940730791}]}
{"instance_id": "977d3bd5d5a3", "generation_result": [{"code": "def eval_learning(y_test, y_pred)\n\t\n    # Calculate accuracy, recall, precision, and F1 score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    # Return the calculated metrics\n    return accuracy, recall, precision, f1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.42910286151195}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 33.42910286151195}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n\n\n\n\n", "CodeBleu_score": 33.42910286151195}]}
{"instance_id": "f4c838f1f092", "generation_result": [{"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}]}
{"instance_id": "35068c779c02", "generation_result": [{"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\"\n    train_dataset_path = cfg.dataset.train_dataset_path\n    train_dataset_name = cfg.dataset.train_dataset_name\n    data, labels = load_svmlight_file(\n        os.path.join(train_dataset_path, train_dataset_name), zero_based=True\n    )\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(np.unique(labels, return_counts=True))\n    print(data.shape)\n    if train_dataset_name == \"mushrooms\":\n        labels = np.where(labels == 1, 0, 1)\n    else:\n        raise RuntimeError(\"Unknown dataset\")\n    return data_utils.TensorDataset(torch.Tensor(data), torch.Tensor(labels))\n\n", "CodeBleu_score": 34.88700734161448}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    if cfg.dataset.type != \"LIBSVM\":\n        raise RuntimeError(\"Wrong dataset type. Expected LIBSVM.\")\n    train_dataset_path = cfg.dataset.train_dataset_path\n    dataset_name = cfg.dataset.name\n    data, labels = load_svmlight_file(train_dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.float32)\n    print(\n        f\"Unique labels: {np.unique(labels, return_counts=True)}; features shape: {data.shape}\"\n    )\n    if dataset_name == \"MUSHROOMS\":\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(\"Wrong dataset name. Expected MUSHROOMS.\")\n    return TensorDataset(torch.Tensor(data), torch.Tensor(labels))\n\n", "CodeBleu_score": 44.776137389712744}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\"\n    train_dataset_path = os.path.join(cfg.dataset.path, cfg.dataset.name)\n    print(\"Loading LIBSVM dataset from\", train_dataset_path)\n    data, labels = load_svmlight_file(train_dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(\"Labels:\", np.unique(labels, return_counts=True))\n    print(\"Features shape:\", data.shape)\n    if cfg.dataset.name == \"MUSHROOMS\":\n        labels = np.where(labels == 1, 0, 1)\n    else:\n        raise RuntimeError(\n            \"Dataset name should be MUSHROOMS, not {}\".format(cfg.dataset.name)\n        )\n    return data_utils.TensorDataset(torch.Tensor(data), torch.Tensor(labels))\n\n", "CodeBleu_score": 34.02715442221857}]}
{"instance_id": "d602a96e571e", "generation_result": [{"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}]}
{"instance_id": "fcf88a773fd8", "generation_result": [{"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', dtype=None)\n\n    if isinstance(selected, six.string_types) and selected == \"all\":\n        return transform(X)\n\n    if len(selected) == 0:\n        return X\n\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n\n    if n_selected == 0:\n        # No features selected.\n        return X\n    elif n_selected == n_features:\n        # All features selected.\n        return transform(X)\n    else:\n        X_sel = transform(X[:, ind[sel]])\n        X_not_sel = X[:, ind[not_sel]]\n\n        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n            return sparse.hstack((X_sel, X_not_sel))\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 81.15779692076944}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', dtype=None)\n\n    if selected == \"all\":\n        return transform(X)\n\n    if len(selected) == 0:\n        return X\n\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n\n    if n_selected == 0:\n        # No features selected.\n        return X\n    elif n_selected == n_features:\n        # All features selected.\n        return transform(X)\n    else:\n        X_sel = transform(X[:, ind[sel]])\n        X_not_sel = X[:, ind[not_sel]]\n\n        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n            return sparse.hstack((X_sel, X_not_sel))\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 78.33126429452464}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', dtype=None)\n\n    if isinstance(selected, six.string_types) and selected == \"all\":\n        return transform(X)\n    elif len(selected) == 0:\n        return X\n    else:\n        if getattr(X, \"sparse\", False):\n            # sparse is always CSC\n            X_sel = X[:, selected].tocsc()\n            X_not_sel = X[:, np.logical_not(selected)]\n        else:\n            X_sel = X[:, selected]\n            X_not_sel = X[:, np.logical_not(selected)]\n\n        X_sel = transform(X_sel)\n        if sparse.issparse(X_sel):\n            # sparse.hstack is not happy if both arguments are sparse\n            #  so convert X_sel to an array first\n            X_sel = X_sel.toarray()\n        X_trans = np.hstack((X_sel, X_not_sel))\n\n        if getattr(X, \"sparse\", False):\n            X_trans = sparse.csr_matrix(X_trans)\n        else:\n            X_trans = np.asarray(X_trans)\n\n        if copy:\n            X_trans = X_trans.copy()\n\n        return X_trans\n\n", "CodeBleu_score": 47.18833538105296}]}
{"instance_id": "c9dfb00047d1", "generation_result": [{"code": "def _transform_new(self, X)\n\t\n\n    # Check input array\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    # Get number of samples and features\n    n_samples, n_features = X.shape\n\n    # Transform input array into integer-encoded values and generate mask for valid entries\n    X_int, X_mask = self._transform(X, handle_unknown='ignore')\n\n    # Compute number of categories for each feature\n    n_values = [cats.shape[0] for cats in self.categories_]\n\n    # Compute feature indices\n    feature_indices = np.repeat(np.arange(n_features, dtype=np.int32), n_values)\n\n    # Construct indices and indptr arrays for creating sparse matrix\n    indptr = np.zeros(n_features + 1, dtype=np.int32)\n    indices = []\n    data = []\n    for i in range(n_samples):\n        for j in range(n_features):\n            if X_mask[i, j]:\n                indptr[j + 1] += 1\n                indices.append(X_int[i, j])\n                data.append(1)\n    indptr = np.cumsum(indptr)\n    indices = np.asarray(indices, dtype=np.int32)\n    data = np.asarray(data, dtype=np.int32)\n\n    # Create sparse matrix\n    out = sparse.csr_matrix((data, indices, indptr),\n                            shape=(n_samples, np.sum(n_values)),\n                            dtype=self.dtype).astype(self.dtype)\n    if not self.sparse:\n        out = out.toarray()\n\n    return out\n\n", "CodeBleu_score": 55.683452728639715}, {"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, dtype=None)\n    n_samples, n_features = X.shape\n\n    X_int, X_mask = self._transform(X)\n\n    n_values = [cats.shape[0] for cats in self.categories_]\n    n_values = np.array([0] + n_values)\n    indices = np.cumsum(n_values)\n\n    column_indices = (X_int + indices[:-1]).ravel()\n    row_indices = np.repeat(np.arange(n_samples, dtype=np.int32), n_features)\n    mask = X_mask.ravel()\n\n    data = np.ones(n_samples * n_features, dtype=np.int8)\n\n    out = sparse.csr_matrix((data, (row_indices, column_indices)),\n                            shape=(n_samples, indices[-1]),\n                            dtype=self.dtype).tocsc()\n\n    if self.sparse:\n        out = out[:, 1:]\n    else:\n        out = out.toarray()[:, 1:]\n\n    return out", "CodeBleu_score": 36.236149039092695}, {"code": "def _transform_new(self, X)\n\t\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    _, n_features = X.shape\n    X_int = np.zeros_like(X, dtype=np.int)\n    X_mask = np.ones_like(X, dtype=np.bool)\n\n    for i in range(n_features):\n        Xi = X[:, i]\n        valid_mask = np.in1d(Xi, self.categories_[i])\n\n        if not np.all(valid_mask):\n            if self.handle_unknown == 'error':\n                diff = np.unique(X[~valid_mask, i])\n                msg = (\"Found unknown categories {0} in column {1}\"\n                       \" during transform\".format(diff, i))\n                raise ValueError(msg)\n            else:\n                # Set the problematic rows to an acceptable value and\n                # continue `The rows are marked `X_mask` and will be\n                # removed later.\n                X_mask[:, i] = valid_mask\n                Xi = Xi.copy()\n                Xi[~valid_mask] = self.categories_[i][0]\n        X_int[:, i] = self._label_encoders_[i].transform(Xi)\n\n    n_values = [cats.shape[0] for cats in self.categories_]\n    n_values = np.array([0] + n_values)\n    indices = np.cumsum(n_values)\n\n    column_indices = (X_int + indices[:-1]).ravel()\n    row_indices = np.repeat(np.arange(X.shape[0], dtype=np.int32), n_features)\n    data = np.ones(X.shape[0] * n_features, dtype=np.int8)\n\n    out = sparse.csr_", "CodeBleu_score": 49.97443571181197}]}
{"instance_id": "fcde391a8972", "generation_result": [{"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.057045198751105}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    return uniform(self.lower, self.upper)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.343095470548864}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper - self.lower)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.997576913458495}]}
{"instance_id": "5d5413adcca6", "generation_result": [{"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers:\n        self.render_header_if_needed(state, self.headers)\n    fig, axs = plt.subplots(**fig_args)\n    for ax, feature in zip(axs.ravel(), features):\n        kwargs = {**additional_kwargs, **dict(ax=ax)}\n        if self.two_way:\n            X = state.data.copy()\n            X = X[X[feature[0]].notna()]\n            X = X[X[feature[1]].notna()]\n            kwargs[\"X\"] = X\n        PartialDependenceDisplay.from_estimator(state.model, state.data, feature, **kwargs)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.939239983926115}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.render_header_if_needed():\n        self.render_header()\n    fig, axs = plt.subplots(**fig_args)\n    axs = axs.ravel()\n    if self.two_way:\n        state.data = state.data[state.data[self.features[0]].notna()]\n        state.data = state.data[state.data[self.features[1]].notna()]\n    kwargs = {**additional_kwargs, **self.predefined_kw}\n    for i, feature in enumerate(features):\n        PartialDependenceDisplay.from_estimator(\n            state.model,\n            state.data,\n            features=feature,\n            ax=axs[i],\n            **kwargs,\n        )\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.079405852555105}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers:\n        self.render_header_if_needed(state, self.headers)\n    fig, axs = plt.subplots(**fig_args)\n    for ax, f in zip(axs.ravel(), features):\n        kwargs = {**additional_kwargs, **dict(ax=ax, features=f)}\n        if self.two_way:\n            data = state.data[state.data.notna().all(axis=1)]\n            state.data = data\n        PartialDependenceDisplay.from_estimator(state.model, state.data, **kwargs)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.27333291878256}]}
{"instance_id": "db8aac29180b", "generation_result": [{"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}]}
{"instance_id": "d4eb45e6d013", "generation_result": [{"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params()\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    if self.min_samples_magnitude is None:\n        self.min_samples_magnitude = min(1, int(np.log10(len(X))))\n    if self.max_samples is None:\n        self.max_samples = len(X)\n    if self.n_jobs is None:\n        self.n_jobs = -1\n    if self.n_jobs == -1:\n        self.n_jobs = cpu_count()\n    if self.max_samples == len(X):\n        self.max_samples = None\n    if self.search_spaces is not None:\n        self.min_samples_magnitude = 0\n        self.max_samples = None\n    if self.n_jobs > 1:\n        self.n_jobs = 1\n    if self.min_samples_magnitude == 0:\n        self.min_samples_magnitude = 1\n    if self.max_samples is None:\n        self.max_samples = len(X)\n    if self.min_samples_magnitude > self.max_samples:\n        self.min_samples_magnitude = self.max_samples\n    if self.min_samples_magnitude < 1:\n        self.min_samples_magnitude = 1\n    if self.max_samples is None:\n        self.max_samples = len(X)\n    if self.max_samples < self.min_samples_magnitude:\n        self.max_samples = self.min_samples_magnitude\n    if self.max_samples > len(X):\n        self.max_samples = len(X)\n    if self.min_samples_magnitude < 1:\n        self.min_samples_magnitude = 1\n    if self.max_samples < 1:\n        self.max_samples = 1\n", "CodeBleu_score": 26.16020788606471}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params()\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    if self.min_samples_leaf is None:\n        self.min_samples_leaf = 1\n    if self.min_samples_split is None:\n        self.min_samples_split = 2\n    if self.max_depth is None:\n        self.max_depth = -1\n    if self.max_leaf_nodes is None:\n        self.max_leaf_nodes = -1\n    if self.min_child_samples is None:\n        self.min_child_samples = 20\n    if self.max_cat_to_onehot is None:\n        self.max_cat_to_onehot = 4\n    if self.max_num_to_discretize is None:\n        self.max_num_to_discretize = 10\n    if self.max_unique_ratio is None:\n        self.max_unique_ratio = 0.9\n    if self.num_classes is None:\n        self.num_classes = 2\n    if self.num_rows is None:\n        self.num_rows = X.shape[0]\n    if self.num_cols is None:\n        self.num_cols = X.shape[1]\n    if self.problem_type is None:\n        self.problem_type = BINARY\n    if self.n_jobs is None:\n        self.n_jobs = -1\n    if self.random_state is None:\n        self.random_state = 0\n    if self.num_folds is None:\n        self.num_folds = 5\n    if self.n_jobs == -1:\n        self.n_jobs = cpu_count()\n    if self.time_limit is None:\n        self.time_limit = float(\"inf\")\n    if self.search_spaces is None:\n        self.search_spaces = {}\n    if self.model_base_estimator is None:\n        self.model_base_estimator = None\n    if", "CodeBleu_score": 19.40026941443015}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    model_params = self._get_model_params()\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    min_num_estimators = self.min_num_estimators\n    if len(model_params) > 0:\n        if isinstance(model_params, dict):\n            min_num_estimators = model_params.get('n_estimators', 40)\n        elif isinstance(model_params, list):\n            min_num_estimators = model_params[0].get('n_estimators', 40)\n    min_num_estimators = max(min_num_estimators, 40)\n    if self.search_space is not None:\n        min_num_estimators = max(min_num_estimators, 40)\n    bytes_per_estimator = X.memory_usage(index=True, deep=True).sum() * num_trees_per_estimator * 1.5\n    expected_min_memory_usage = bytes_per_estimator * min_num_estimators\n    return expected_min_memory_usage", "CodeBleu_score": 42.63460894601908}]}
{"instance_id": "6923cb007f4c", "generation_result": [{"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    # Create a Counter object from the n-gram frequency data\n    ngram_counter = Counter(ngram_freq)\n\n    # Identify the top n most common n-grams\n    top_ngrams = ngram_counter.most_common(vocab_size)\n\n    # Sort the names of the top n n-grams\n    top_ngrams_sorted = sorted(top_ngrams, key=lambda x: x[0])\n\n    # Create a new vocabulary dictionary with the top n n-grams\n    vocab_dict = {ngram: idx for idx, (ngram, _) in enumerate(top_ngrams_sorted)}\n\n    # Update the vectorizer's vocabulary with the new vocabulary dictionary\n    vectorizer.vocabulary_ = vocab_dict\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.51008341342453}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    ngram_counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, count in ngram_counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    new_vocab = {ngram: idx for idx, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = new_vocab\n    return vectorizer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.944490387886226}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, count in counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    vocab = {ngram: idx for idx, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = vocab\n    return vectorizer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.12453055318999}]}
{"instance_id": "0e837b2d8088", "generation_result": [{"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = defaultdict(list)\n    skew_threshold = self.parameters['skew_threshold']\n    for feature in features:\n        skew = df[feature].skew()\n        if np.abs(skew) > skew_threshold:\n            feature_types['skewed'].append(feature)\n        else:\n            feature_types['continuous'].append(feature)\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.0593484477395}, {"code": " def _select_continuous(self, df, features)\n\t\n    continuous = []\n    skewed = []\n    skew_threshold = self.parameters.get(\"skew_threshold\", 0.95)\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skew_threshold:\n            skewed.append(feature)\n        else:\n            continuous.append(feature)\n    return {\"continuous\": continuous, \"skewed\": skewed}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.2654120965386}, {"code": " def _select_continuous(self, df, features)\n\t\n    continuous_features = []\n    skewed_features = []\n    skew_threshold = self.parameters[\"skew_threshold\"]\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skew_threshold:\n            skewed_features.append(feature)\n        else:\n            continuous_features.append(feature)\n    return {\n        \"continuous_features\": continuous_features,\n        \"skewed_features\": skewed_features,\n    }\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.35727120028761}]}
{"instance_id": "bb569c10f975", "generation_result": [{"code": "def _get_weights(dist, weights):\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 0.45454545454545453}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    if weights == \"distance\":\n        weights = np.ones_like(dist)\n        weights[dist == 0] = 0\n        weights[np.isinf(dist)] = 0\n        with np.errstate(invalid=\"ignore\"):\n            weights /= weights.sum(axis=1)[:, np.newaxis]\n        if np.any(np.isnan(weights)):\n            raise ValueError(\"nan in weights.\")\n        return weights\n    if callable(weights):\n        return weights(dist)\n    raise ValueError(\n        \"weights should be 'uniform', 'distance', or a callable function.\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.8245673309598}, {"code": "def _get_weights(dist, weights):\n\t\n\n", "CodeBleu_score": 0.45454545454545453}]}
{"instance_id": "12aaa9c78402", "generation_result": [{"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors()\n    weights = self._get_weights(distances)\n    if _y.ndim == 1:\n        _y = _y.reshape(-1, 1)\n    predictions = np.empty(_y.shape)\n    for i in range(_y.shape[0]):\n        if self.weights == \"uniform\":\n            predictions[i] = np.mean(_y[indices[i]], axis=0)\n        else:\n            predictions[i] = np.sum(_y[indices[i]] * weights[i], axis=0) / np.sum(weights[i])\n    if _y.ndim == 1:\n        predictions = predictions.flatten()\n    return predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.90000728112186}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors()\n    weights = self._get_weights(distances)\n    _y = self._y.reshape(-1, 1) if len(self._y.shape) == 1 else self._y\n    predictions = np.empty(shape=_y.shape)\n    for i in range(self._X.shape[0]):\n        if self.weights:\n            predictions[i] = np.sum(_y[indices[i]] * weights[i], axis=0) / np.sum(weights[i])\n        else:\n            predictions[i] = np.mean(_y[indices[i]], axis=0)\n    return predictions.flatten() if len(self._y.shape) == 1 else predictions\n\n", "CodeBleu_score": 29.27988715477102}, {"code": "def predict_loo(self)\n\t\n    # Compute distances and indices of k nearest neighbors\n    distances, indices = self.kneighbors()\n    # Get weights for neighbors\n    weights = self._get_weights(distances)\n    # Reshape _y to 2D array if it is 1D\n    if len(_y.shape) == 1:\n        _y = _y.reshape(-1, 1)\n    # Initialize predictions array\n    y_pred = np.empty((_y.shape[0], _y.shape[1]))\n    # Loop through each sample and make predictions\n    for i in range(_y.shape[0]):\n        # Get indices of neighbors for current sample\n        n_indices = indices[i]\n        # Get weights for neighbors\n        n_weights = weights[i]\n        # Get target values for neighbors\n        n_targets = _y[n_indices]\n        # Make predictions\n        if self.weights == \"uniform\":\n            # Unweighted predictions\n            y_pred[i] = np.mean(n_targets, axis=0)\n        else:\n            # Weighted predictions\n            y_pred[i] = np.sum(n_targets * n_weights[:, np.newaxis], axis=0) / np.sum(n_weights)\n    # Flatten predictions if original _y was 1D\n    if len(_y.shape) == 1:\n        y_pred = y_pred.flatten()\n    return y_pred", "CodeBleu_score": 41.43378812056026}]}
{"instance_id": "b316687d9e9b", "generation_result": [{"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    new_output_data = []\n    for i in range(batch_size):\n        fit_transform = IsotonicRegression(\n            quantile_list).fit_transform(input_data[i])\n        new_output_data.append(fit_transform)\n    return np.stack(new_output_data)\n\n", "CodeBleu_score": 47.15749222958486}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    # Reshape the quantile list into a one-dimensional array\n    quantile_list = np.array(quantile_list).reshape(-1)\n\n    # Determine the batch size from the input data's first dimension\n    batch_size = input_data.shape[0]\n\n    # Initialize an empty list to store the transformed data\n    new_output_data = []\n\n    # Loop over each row in the input data\n    for i in range(batch_size):\n        # Fit and transform the data using IsotonicRegression with the given quantile list\n        new_output_data.append(IsotonicRegression(quantile_list).fit_transform(input_data[i]))\n\n    # Stack the transformed data for each row into a new array and return it\n    return np.stack(new_output_data)\n\n", "CodeBleu_score": 50.01649260808596}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    # Reshape the quantile list into a one-dimensional array\n    quantile_list = np.array(quantile_list).reshape(-1)\n\n    # Determine the batch size from the input data's first dimension\n    batch_size = input_data.shape[0]\n\n    # Initialize an empty list to store the transformed data\n    new_output_data = []\n\n    # Loop through each row in the input data\n    for i in range(batch_size):\n        # Fit and transform the data using IsotonicRegression with the given quantile list\n        new_output_data.append(IsotonicRegression(quantile_list).fit_transform(input_data[i].reshape(-1, 1)))\n\n    # Stack the transformed data for each row into a new array\n    new_output_data = np.stack(new_output_data, axis=0)\n\n    # Return the new output data\n    return new_output_data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.456729518666855}]}
{"instance_id": "17566e088b4e", "generation_result": [{"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_data = vectorizer.transform(text_data)\n    return vectorizer, vectorized_data", "CodeBleu_score": 45.25213029105295}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    X = vectorizer.transform(text_data)\n    return vectorizer, X\n\n", "CodeBleu_score": 43.98226412743081}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    return vectorizer, vectorizer.transform(text_data)\n\n\n\n\n\n", "CodeBleu_score": 40.6826747095547}]}
{"instance_id": "be23c0afc2d6", "generation_result": [{"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries\n    df = df[df.ne('--').all(axis=1)]\n    \n    # Drop columns with unique values less than or equal to 1\n    df = df.drop([col for col in df.columns if df[col].nunique() <= 1], axis=1)\n    \n    # Drop columns with \"id\" in their name\n    df = df.drop([col for col in df.columns if \"id\" in col.lower()], axis=1)\n    \n    # Drop shortcut columns\n    df = df.drop(['days_to_death', 'year_of_death'], axis=1)\n    \n    # Split data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n    \n    return train_df, test_df\n\n", "CodeBleu_score": 31.013478723599796}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries\n    df = df[df.iloc[:, 1] != '--']\n    # Drop columns with unique values less than or equal to 1\n    n_unique = df.nunique()\n    cols_to_drop = [col for col in n_unique.index if n_unique[col] <= 1 or 'id' in col]\n    df.drop(cols_to_drop, axis=1, inplace=True)\n    # Drop shortcut columns\n    df.drop(['days_to_death', 'year_of_death'], axis=1, inplace=True)\n    # Split data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n    return train_df, test_df", "CodeBleu_score": 32.69580087708129}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries\n    df = df[df.ne('--').all(axis=1)]\n    # Drop columns with unique values less than or equal to 1\n    n_unique = df.nunique()\n    cols_to_drop = n_unique[n_unique <= 1].index\n    df = df.drop(cols_to_drop, axis=1)\n    # Drop columns with \"id\" in their name\n    cols_to_drop = [col for col in df.columns if 'id' in col]\n    df = df.drop(cols_to_drop, axis=1)\n    # Drop shortcut columns\n    cols_to_drop = ['days_to_death', 'year_of_death']\n    df = df.drop(cols_to_drop, axis=1)\n    # Split the data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n    return train_df, test_df\n\n\n\n\n\n", "CodeBleu_score": 30.435956663132718}]}
{"instance_id": "6a82997a8c59", "generation_result": [{"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    # Load the training and testing data\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset=dataset, make_sparse=sparse)\n\n    # Retrieve the classifier's hyperparameter search space and obtain the default configuration\n    cs = classifier.get_hyperparameter_search_space()\n    default_config = cs.get_default_configuration()\n\n    # Initialize the classifier with the default configuration and a random state\n    cls = classifier(\n        configuration=default_config, random_state=np.random.RandomState(1)\n    )\n\n    # Fit the classifier iteratively to the training data for an initial two iterations with refitting enabled\n    for i in range(2):\n        cls.iterative_fit(X_train, Y_train, n_iter=1, refit=True)\n\n    # Continue iterative fitting, doubling the number of iterations each time, until the classifier is fully fitted\n    while not cls.configuration_fully_fitted():\n        cls.iterative_fit(X_train, Y_train, n_iter=2 ** i, refit=False)\n        i += 1\n\n    # Make predictions on the test data\n    predictions = cls.predict(X_test)\n\n    # Return the predictions, true test labels, and the fitted classifier\n    return predictions, Y_test, cls\n\n", "CodeBleu_score": 43.49267950167678}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n    classifier = classifier(\n        configuration=default, random_state=1,\n    )\n\n    # make sure the hyperparameters are working so we can fit two iterations\n    # this is the most basic test\n    classifier.iterative_fit(\n        X_train, Y_train, n_iter=2, refit=True,\n    )\n\n    # Use the true test labels to stop fitting\n    n_iter = 2\n    while not classifier.configuration_fully_fitted:\n        n_iter *= 2\n        classifier.iterative_fit(\n            X_train, Y_train, n_iter=n_iter, refit=True,\n        )\n    predictions = classifier.predict(X_test)\n    return predictions, Y_test, classifier\n\n", "CodeBleu_score": 41.80030828090211}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n    classifier = classifier(configuration=default, random_state=1)\n    classifier.iterative_fit(X_train, Y_train, n_iter=2, refit=True)\n    num_iter = 4\n    while not classifier.configuration_fully_fitted:\n        classifier.iterative_fit(X_train, Y_train, n_iter=num_iter, refit=False)\n        num_iter *= 2\n\n    predictions = classifier.predict(X_test)\n    return predictions, Y_test, classifier\n\n", "CodeBleu_score": 40.98982311527607}]}
{"instance_id": "d0d8450c4c17", "generation_result": [{"code": "def _load_models(self)\n\t\n    # Load the ensemble if it is defined\n    if self._ensemble_class is not None:\n        self._ensemble = self._ensemble_class(\n            task_type=self._task,\n            backend=self._backend,\n            seed=self._seed,\n        )\n        self._logger.info(\"Loaded ensemble: {}\".format(self._ensemble.__class__.__name__))\n\n    # Load the best individual model if the ensemble is not loaded and certain evaluator output conditions and resampling strategies are met\n    if self._ensemble is None and (\n        self._evaluator is not None\n        and self._evaluator.output_constraints()\n        and self._resampling_strategy is not None\n    ):\n        self._ensemble = self._load_best_individual_model()\n\n    # If the ensemble is successfully loaded, retrieve model identifiers and load the corresponding models using the backend\n    if self._ensemble is not None:\n        model_identifiers = self._ensemble.get_identifiers_with_weights()\n        self.models_ = load_models_by_identifiers(model_identifiers, self._backend)\n        self._logger.info(\"Loaded models: {}\".format(len(self.models_)))\n\n        # If the ensemble is a cross-validation ensemble, load the cross-validated models\n        if isinstance(self._ensemble, CrossValidationEnsemble):\n            self.cv_models_ = load_cv_models_by_identifiers(\n                model_identifiers, self._backend\n            )\n            self._logger.info(\"Loaded cross-validated models: {}\".format(len(self.cv_models_)))\n        else:\n            self.cv_models_ = None\n\n    # If no ensemble is loaded, initialize empty lists for models and cross-validated models\n    else:\n        self.models_ = []\n        self.cv_models_ = None\n\n", "CodeBleu_score": 51.11376456046675}, {"code": "def _load_models(self)\n\t\n    if self.ensemble_class is not None:\n        self.ensemble = self.backend.load_ensemble(\n            self.ensemble_class, self.seed\n        )\n\n    if self.ensemble is None and self.evaluator_output_conditions():\n        self.ensemble = self._load_best_individual_model()\n\n    if self.ensemble is not None:\n        self.identifiers = self.ensemble.get_identifiers_with_weights()\n        self.models = self.backend.load_models_by_identifiers(\n            self.identifiers, self.seed\n        )\n        if self.resampling_strategy in [\"holdout-validation\", \"cv\"]:\n            self.cross_validated_models = self.backend.load_cv_models_by_identifiers(\n                self.identifiers, self.seed\n            )\n        else:\n            self.cross_validated_models = None\n    else:\n        self.models = []\n        self.cross_validated_models = None\n\n", "CodeBleu_score": 42.85985919785744}, {"code": "def _load_models(self)\n\t\n\n    if self.ensemble_ is not None:\n        self.ensemble_.load(backend=self._backend, seed=self._seed)\n\n    if (\n        self.ensemble_ is None\n        and self.evaluator_output_ is not None\n        and self.evaluator_output_.get(self.resampling_strategy) is not None\n    ):\n        self.ensemble_ = self._load_best_individual_model()\n\n    if self.ensemble_ is not None:\n        self.identifiers_ = self.ensemble_.get_identifiers_with_weights()\n        self.models_ = load_models_by_identifiers(\n            self.identifiers_,\n            backend=self._backend,\n            task=self._task,\n            metric=self._metrics,\n            seed=self._seed,\n        )\n\n        if self.resampling_strategy in [\n            \"holdout\",\n            \"holdout-iterative-fit\",\n            \"cv\",\n            \"partial-cv\",\n        ]:\n            self.models_cv_ = load_cv_models_by_identifiers(\n                self.identifiers_,\n                backend=self._backend,\n                task=self._task,\n                metric=self._metrics,\n                seed=self._seed,\n            )\n        else:\n            self.models_cv_ = None\n    else:\n        self.models_ = []\n        self.models_cv_ = []\n\n", "CodeBleu_score": 50.53908063989636}]}
{"instance_id": "ef71b1cddb50", "generation_result": [{"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    dataset = task.get_dataset()\n    X, y, categorical_indicator, _ = dataset.get_data(\n        dataset_format=\"array\", target=dataset.default_target_attribute\n    )\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    categorical_indicator = [\n        True if indicator == \"nominal\" else False for indicator in categorical_indicator\n    ]\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 28.35795771581277}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    dataset = task.get_dataset()\n    _, categorical_indicator = dataset.get_data(\n        target=dataset.default_target_attribute\n    )\n    categorical_indicator = np.array(categorical_indicator).tolist()\n    for feature_idx in range(len(categorical_indicator)):\n        if categorical_indicator[feature_idx] is None:\n            categorical_indicator[feature_idx] = False\n        else:\n            categorical_indicator[feature_idx] = True\n    unique_values = np.unique(y_train)\n    mapping = {original_value: new_value for new_value, original_value in enumerate(unique_values)}\n    y_train = np.array([mapping[x] for x in y_train])\n    y_test = np.array([mapping[x] for x in y_test])\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.305165087200834}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    train_X = X[train_indices]\n    train_y = y[train_indices]\n    test_X = X[test_indices]\n    test_y = y[test_indices]\n    dataset = task.get_dataset()\n    _, categorical = dataset.get_data(target=task.target_name)\n    categorical_indicator = []\n    for i in range(len(train_X.T)):\n        if categorical[i]:\n            le = preprocessing.LabelEncoder()\n            le.fit(train_X[:, i])\n            train_X[:, i] = le.transform(train_X[:, i])\n            test_X[:, i] = le.transform(test_X[:, i])\n            categorical_indicator.append(True)\n        else:\n            train_X[:, i] = np.array(train_X[:, i], dtype=float)\n            test_X[:, i] = np.array(test_X[:, i], dtype=float)\n            categorical_indicator.append(False)\n    label_encoder = preprocessing.LabelEncoder()\n    label_encoder.fit(train_y)\n    train_y = label_encoder.transform(train_y)\n    test_y = label_encoder.transform(test_y)\n    return train_X, train_y, test_X, test_y, categorical_indicator\n\n", "CodeBleu_score": 32.64240776273148}]}
{"instance_id": "90bd6edbcc9e", "generation_result": [{"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n    if isinstance(y, pd.Series):\n        return y.values\n    if isinstance(y, list):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, pd.DataFrame):\n        return y.values\n   ", "CodeBleu_score": 34.36346982992093}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, np.ndarray):\n        y = y\n    elif isinstance(y, list):\n        y = np.array(y)\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n        y = y.to_numpy()\n    elif isinstance(y, pd.DataFrame):\n        y = y.to_numpy()\n    elif isinstance(y, pd.Series):\n       ", "CodeBleu_score": 41.21020714328536}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n        return y.to_frame()\n    if isinstance(y, pd.DataFrame):\n        return y\n    if isinstance(y, np.ndarray):\n        return y\n    if isinstance(y, list):\n        return y\n    if isinstance(y, pd.Series):\n       ", "CodeBleu_score": 37.01775684912315}]}
{"instance_id": "5728e3d4f914", "generation_result": [{"code": "def _calculate_weights(self) -> None\n\t\n    # Count the occurrences of each ensemble member index\n    counts = Counter(self.ensemble_indices_)\n\n    # Initialize weights array with zeros\n    weights = np.zeros(len(self.input_models_))\n\n    # Calculate weights based on occurrence frequency\n    for index, count in counts.items():\n        weight = count / len(self.ensemble_indices_)\n        weights[index] = weight\n\n    # Normalize weights if their sum is less than 1\n    if np.sum(weights) < 1:\n        weights /= np.sum(weights)\n\n    # Store calculated weights in instance variable\n    self.weights_ = weights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.50704557207189}, {"code": "def _calculate_weights(self) -> None\n\t\n    counts = np.sum(self.ensemble_members, axis=0)\n    self.weights_ = np.zeros(self.n_models)\n    for i, count in enumerate(counts):\n        self.weights_[i] = count / self.n_models\n    if np.sum(self.weights_) < 1:\n        self.weights_ /= np.sum(self.weights_)\n\n", "CodeBleu_score": 21.342497623254918}, {"code": "def _calculate_weights(self) -> None\n\t\n    # count the number of occurrences of each ensemble member index\n    counts = Counter(self.ensemble_indices)\n    # initialize weights array with zeros\n    self.weights_ = np.zeros(len(self.input_models_))\n    # calculate weights for each ensemble member\n    for i, count in counts.items():\n        weight = count / len(self.ensemble_indices)\n        self.weights_[i] = weight\n    # normalize weights if their sum is less than 1\n    if np.sum(self.weights_) < 1:\n        self.weights_ /= np.sum(self.weights_)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.7497567421198}]}
{"instance_id": "4f9c4799fd8f", "generation_result": [{"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    pred_proba = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(pred_proba, axis=1), 1)\n    assert np.all((pred_proba >= 0) & (pred_proba <= 1))\n    return pred_proba\n\n\n\n", "CodeBleu_score": 34.33005425246334}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_pred_proba = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_pred_proba, axis=1), 1)\n    assert np.all((0 <= y_pred_proba) & (y_pred_proba <= 1))\n    return y_pred_proba\n\n", "CodeBleu_score": 33.212879286567976}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_pred = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_pred, axis=1), 1)\n    assert np.all(0 <= y_pred) and np.all(y_pred <= 1)\n    return y_pred\n\n", "CodeBleu_score": 31.316548449747337}]}
{"instance_id": "a9a13150aebe", "generation_result": [{"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return Ybin.dot(range(Ybin.shape[1]))\n\n", "CodeBleu_score": 27.223374943841144}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        Y = Ybin\n    else:\n        Y = np.dot(Ybin, range(Ybin.shape[1]))\n    return Y\n\n", "CodeBleu_score": 53.1489387646343}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n", "CodeBleu_score": 32.043052488809614}]}
{"instance_id": "e97d38e62f81", "generation_result": [{"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}]}
{"instance_id": "b1aaad80a9c4", "generation_result": [{"code": "def test_glm_identity_link_func()\n\t\n    # Create a sample dataset\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([2, 4, 6])\n\n    # Create a GLM model with an identity link function\n    model = utils.StatsmodelsSklearnLikeWrapper(\n        assembler.assemble(\n            Tweedie(\n                Power(\n                    ast.FeatureRef(0),\n                    ast.NumVal(1),\n                ),\n                link=ast.IdentityLink(),\n            )\n        )\n    )\n\n    # Fit the model\n    model.fit(X, y)\n\n    # Assert that the model has been fitted\n    assert model.fitted_\n\n    # Assert that the model parameters are as expected\n    assert np.allclose(model.params_, np.array([1.0, 1.0]))\n\n    # Assert that the model predictions are as expected\n    assert np.allclose(model.predict(X), np.array([2.0, 4.0, 6.0]))\n\n    # Assert that the model score is as expected\n    assert np.allclose(model.score(X, y), 1.0)\n\n    # Assert that the model summary is as expected\n    assert model.summary() == \"GLM(family=Tweedie(link=IdentityLink(), power=1.0), formula=Power(FeatureRef(0), 1.0))\"\n\n", "CodeBleu_score": 24.90803417684457}, {"code": "def test_glm_identity_link_func()\n\t\n    df = pd.DataFrame({\"A\": [1, 2, 3, 4, 5], \"B\": [2, 4, 6, 8, 10]})\n    df[\"target\"] = df[\"B\"]\n    model = Tweedie(var_power=1.0, link_power=1.0)\n    model = utils.StatsmodelsSklearnLikeWrapper(model)\n    model.fit(df[[\"A\"]], df[\"target\"])\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(model)\n    expr = assembler.assemble()\n    expected_expr = ast.BinNumExpr(\n        ast.NumVal(1.0),\n        ast.BinNumExpr(\n            ast.FeatureRef(0),\n            ast.NumVal(1.0),\n            ast.BinNumOpType.MUL,\n        ),\n        ast.BinNumOpType.ADD,\n    )\n    utils.cmp_exprs(expr, expected_expr)\n\n", "CodeBleu_score": 41.8092688805764}, {"code": "def test_glm_identity_link_func()\n\t\n    X = np.array([[1, 2], [3, 4], [5, 6]])\n    y = np.array([1, 2, 3])\n    model = utils.StatsmodelsSklearnLikeWrapper(\n        estimator=sm.GLM,\n        estimator_kwargs={\n            \"family\": sm.families.Tweedie(link=Power(1)),\n            \"link\": sm.families.links.identity(),\n        },\n    )\n    model.fit(X, y)\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(model)\n    expr = assembler.assemble()\n    expected_expr = ast.BinNumExpr(\n        ast.NumVal(1.0),\n        ast.BinNumExpr(\n            ast.FeatureRef(0),\n            ast.BinNumExpr(\n                ast.NumVal(1.0),\n                ast.BinNumExpr(\n                    ast.FeatureRef(1),\n                    ast.NumVal(1.0),\n                    ast.BinNumOpType.ADD,\n                ),\n                ast.BinNumOpType.MUL,\n            ),\n            ast.BinNumOpType.ADD,\n        ),\n        ast.BinNumOpType.ADD,\n    )\n    utils.cmp_exprs(expr, expected_expr)\n\n", "CodeBleu_score": 33.66079914659273}]}
{"instance_id": "bcab63e592d0", "generation_result": [{"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg.__name__ if isinstance(agg, Callable) else agg\n        agg_func = agg\n\n    new_col_name = f\"{col.name}_{agg_name}\"\n    return self._df.groupby(self._group_by).agg({col.name: agg_func}).rename(\n        columns={col.name: new_col_name}\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.79302275671144}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    # Handle named aggregation to avoid conflicts with column names when resetting the index\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n\n    # Construct new column name based on original column name and aggregation name\n    new_col_name = f\"{col.name}_{agg_name}\"\n\n    # Apply aggregation to grouped DataFrame and return result with new column name\n    return self.groupby(col.name).apply(agg_func).rename(new_col_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.80595766321437}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        if isinstance(agg, str):\n            agg_name = agg\n            agg_func = getattr(pd.Series, agg)\n        else:\n            agg_name = agg.__name__\n            agg_func = agg\n\n    new_col_name = f\"{col.name}_{agg_name}\"\n    return self.groupby(col.name).apply(agg_func).reset_index(name=new_col_name)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.52271464880723}]}
{"instance_id": "114d623dae7b", "generation_result": [{"code": "def _corrfunc(self, x, y, **kws)\n\t\n\n    # Calculate the correlation coefficient\n    r, p = stats.pearsonr(x, y)\n\n    # Adjust font size based on number of hue groups and correlation value\n    if 'hue' in kws.keys():\n        n_hues = len(self.hue_vals)\n        fs = (10 - n_hues) / 10\n    else:\n        fs = 1\n    fs = (abs(r) + 2) / (abs(r) + 4)\n    r = np.round(r, 2)\n\n    # Get the appropriate axis\n    ax = plt.gca()\n\n    # Annotate the axis with the correlation coefficient\n    if 'hue' in kws.keys():\n        hue_idx = list(self.hue_vals).index(kws['label'])\n        x_pos = -.1 + .8 * hue_idx / (len(self.hue_vals) - 1)\n        y_pos = 1.1\n        ax.annotate(\"r = {:.2f}\".format(r), xy=(x_pos, y_pos), xycoords=ax.transAxes,\n                    color='grey', fontsize=fs * 20, ha='center', va='center',\n                    bbox=dict(boxstyle=\"round, pad=.3\", fc=\"w\", alpha=.4))\n    else:\n        ax.annotate(\"r = {:.2f}\".format(r), xy=(1, 1), xycoords=ax.transAxes,\n                    color='grey', fontsize=fs * 20, ha='right', va='top',\n                    bbox=dict(boxstyle=\"round, pad=.3\", fc=\"w\", alpha=.4))\n\n    # Return the correlation coefficient\n    return r\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.405864723250716}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    r, p = stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\n        \"r = {:.2f}\".format(r),\n        xy=(0.1, 0.9),\n        xycoords=ax.transAxes,\n    )\n    fontsize = plt.rcParams[\"axes.labelsize\"]\n    if len(kws) > 0:\n        hue_groups = list(set(self.hue.values))\n        hue_groups.sort()\n        for i, group in enumerate(hue_groups):\n            if sum(self.hue.values == group) > 0:\n                r, p = stats.pearsonr(\n                    x[self.hue.values == group], y[self.hue.values == group]\n                )\n                if p < 0.05:\n                    if np.isfinite(r):\n                        ax.annotate(\n                            \"r = {:.2f}\".format(r),\n                            xy=(0.1, 0.9 - (i + 1) * 0.06),\n                            xycoords=ax.transAxes,\n                            fontsize=fontsize * 0.5,\n                        )\n                    else:\n                        ax.annotate(\n                            \"r = {}\".format(r),\n                            xy=(0.1, 0.9 - (i + 1) * 0.06),\n                            xycoords=ax.transAxes,\n                            fontsize=fontsize * 0.5,\n                        )\n                else:\n                    ax.annotate(\n                        \"r = {:.2f}\".format(r),\n                        xy=(0.1, 0.9 - (i + 1) * 0.06),\n                        xycoords=ax.transAxes,\n                        fontsize=fontsize * 0.5,\n                    )\n            else:\n                ax.annotate(\n                    \"r = {}\".format(r),\n                    xy=(0.1, 0.9 - (i + 1", "CodeBleu_score": 28.23134701727271}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    r, p = stats.pearsonr(x, y)\n    r_abs = abs(r)\n    ax = plt.gca()\n    if len(kws.keys()) > 0:\n        hue_groups = np.unique(kws.get(\"hue\"))\n        if hue_groups.size > 0:\n            hue_cols = kws.get(\"palette\")\n            hue_group_index = 0\n            for i, hue_group in enumerate(hue_groups):\n                hue_group_index = i\n                if hue_group_index > 0:\n                    ax.get_lines()[\n                        hue_group_index\n                    ].set_color(list(hue_cols.values())[hue_group_index])\n                x_hue = x[kws.get(\"hue\") == hue_group]\n                y_hue = y[kws.get(\"hue\") == hue_group]\n                mask = ~np.logical_or(np.isnan(x_hue), np.isnan(y_hue))\n                r, p = stats.pearsonr(x_hue[mask], y_hue[mask])\n                r_abs = abs(r)\n                ax.annotate(\n                    \"r = {:.2f}\".format(r),\n                    xy=(0.5, 0.5),\n                    xycoords=ax.transAxes,\n                    color=\"black\",\n                    va=\"center\",\n                    ha=\"center\",\n                    fontsize=np.min([15, 12 + np.ceil(10 * r_abs)]),\n                )\n    else:\n        ax.annotate(\n            \"r = {:.2f}\".format(r),\n            xy=(0.5, 0.5),\n            xycoords=ax.transAxes,\n            color=\"black\",\n            va=\"center\",\n            ha=\"center\",\n            fontsize=np.min([15, 12 + np.ceil(10 * r_abs)]),", "CodeBleu_score": 33.60642015796642}]}
{"instance_id": "4c1ade308953", "generation_result": [{"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        rounddigit = _rounddigit\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return float(f'%.{rounddigit}g' % src)\n    else:\n        raise ValueError(f\"Invalid rounding method: {method}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 74.7448318069794}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        rounddigit = 2\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return format(src, f'.{rounddigit}g')\n    else:\n        raise ValueError('Invalid method specified. Choose from \"decimal\", \"sig\", or \"format\".')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 74.22611213296798}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        rounddigit = 0\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        with decimal.localcontext() as ctx:\n            ctx.prec = rounddigit\n            return ctx.create_decimal(src)\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError(f'Invalid method: {method}')\n\n", "CodeBleu_score": 75.69148962137803}]}
{"instance_id": "a9923e678320", "generation_result": [{"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 82.531234017264}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 82.531234017264}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 82.531234017264}]}
{"instance_id": "b6106e079dc0", "generation_result": [{"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    # Combine x and y values into a DataFrame\n    df = pd.DataFrame({x_name: x, y_name: y})\n\n    # Add hue field to DataFrame if hue_data is provided\n    if hue_data is not None:\n        df[hue_name] = hue_data\n\n    # Plot scatter plot using Seaborn's scatterplot function\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=df, ax=ax, **scatter_kws)\n\n    # Set title for legend if not specified\n    if legend_kws is None or \"title\" not in legend_kws:\n        legend_kws[\"title\"] = hue_name\n\n    # Add legend to plot if legend_kws is provided\n    if legend_kws is not None:\n        ax.legend(**legend_kws)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.03570366418168}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    data = pd.DataFrame({x_name: x, y_name: y})\n    if hue_data is not None:\n        data[hue_name] = hue_data\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=data, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if \"title\" not in legend_kws:\n            legend_kws[\"title\"] = hue_name\n        ax.legend(**legend_kws)\n\n", "CodeBleu_score": 37.82299190381486}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    data = pd.DataFrame(np.stack([x, y], axis=1), columns=[x_name, y_name])\n    if hue_data is not None:\n        data[hue_name] = hue_data\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=data, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if \"title\" not in legend_kws:\n            legend_kws[\"title\"] = hue_name\n        ax.legend(**legend_kws)\n\n\n\n\n", "CodeBleu_score": 42.089740519507146}]}
{"instance_id": "257e0aa5dd4d", "generation_result": [{"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.083333333333333}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 81.66611757152214}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.083333333333333}]}
{"instance_id": "6446de2223e8", "generation_result": [{"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = ExponentialSmoothing(\n            transformed_data,\n            **kwargs,\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\n                \"pmdarima is not installed. Please install it to use AutoARIMA model.\"\n            )\n            sys.exit(1)\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = AutoARIMA(\n            transformed_data,\n            **kwargs,\n        )\n    elif self.model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data()\n        exogenous_data = self.exogenous_data\n        if exogenous_data is not None:\n            exogenous_data = exogenous_data.reindex(transformed_data.index)\n            model = SARIMAX(\n                transformed_data,\n                exogenous=exogenous_data,\n                **kwargs,\n            )\n        else:\n            model = SARIMAX(\n                transformed_data,\n                **kwargs,\n            )\n    else:\n        raise Exception(f\"Model type {self.model_type} not recognized\")\n    return model\n\n", "CodeBleu_score": 42.357031470882916}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        return ExponentialSmoothing(\n            transformed_data,\n            trend=self.trend,\n            seasonal=self.seasonal,\n            seasonal_periods=self.seasonal_periods,\n            **kwargs\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\n                \"You need to install pmdarima to use auto_arima model type. Try 'pip install pmdarima'\"\n            )\n            exit()\n        transformed_data = self._get_transformed_data(as_series=True)\n        return AutoARIMA(**kwargs)\n    elif self.model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exogenous = self.exogenous\n        if exogenous is not None:\n            exogenous = self._get_transformed_data(as_series=True)\n        return SARIMAX(\n            transformed_data,\n            exogenous=exogenous,\n            trend=self.trend,\n            seasonal=self.seasonal,\n            seasonal_periods=self.seasonal_periods,\n            **kwargs\n        )\n    else:\n        raise Exception(\"Model type not recognized\")", "CodeBleu_score": 38.555453914673635}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = ExponentialSmoothing(\n            transformed_data,\n            trend=kwargs.get(\"trend\", \"add\"),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\n                \"pmdarima is not installed. Please install it to use auto_arima model.\"\n            )\n            exit()\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = AutoARIMA(**kwargs)\n        model.fit(transformed_data)\n    elif self.model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exogenous_vars = self.exogenous_vars\n        if exogenous_vars:\n            exogenous_data = self._get_transformed_data(as_series=False)[\n                exogenous_vars\n            ]\n            model = SARIMAX(\n                transformed_data, exog=exogenous_data, **kwargs\n            )\n        else:\n            model = SARIMAX(transformed_data, **kwargs)\n    else:\n        raise Exception(\"Model type not recognized\")\n    return model\n\n", "CodeBleu_score": 45.96650963108843}]}
{"instance_id": "b2f67820e27f", "generation_result": [{"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array", "CodeBleu_score": 81.55341328072576}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array", "CodeBleu_score": 81.55341328072576}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 81.55341328072576}]}
{"instance_id": "b96f7d9bcc95", "generation_result": [{"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 0:\n        return ys\n    if x.ndim != ys[0].ndim:\n        # Calculate expected shapes for the split segments\n        split_sizes = np.array(indices_or_sections)\n        if split_sizes.size == 1:\n            # Even split\n            split_sizes = np.full(split_sizes.item(), x.shape[axis] // split_sizes.item())\n        split_sizes = np.cumsum(split_sizes)[:-1]\n        expected_shapes = [(s,) + x.shape[axis + 1:] for s in split_sizes]\n\n        # Temporary split to get expected shapes\n        temp_ys = np.split(np.empty(x.shape), indices_or_sections, axis)\n\n        # Reshape segments if necessary\n        for i, (y, expected_shape) in enumerate(zip(ys, expected_shapes)):\n            if y.shape != expected_shape:\n                ys[i] = y.reshape(expected_shape)\n    return ys\n\n\n", "CodeBleu_score": 39.2557959839168}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 0:\n        return ys\n    if len(ys) != len(indices_or_sections) + 1:\n        raise ValueError(\"Number of split segments must be equal to the number of split indices plus one.\")\n    if len(ys) != len(x.shape):\n        raise ValueError(\"Number of split segments must be equal to the number of dimensions of the input array.\")\n    if not all(isinstance(y, np.ndarray) for y in ys):\n        raise TypeError(\"All elements in the input list must be numpy arrays.\")\n    if not isinstance(x, np.ndarray):\n        raise TypeError(\"Input array x must be a numpy array.\")\n    if not isinstance(indices_or_sections, (int, list, tuple)):\n        raise TypeError(\"indices_or_sections must be an integer or a list/tuple of integers.\")\n    if not isinstance(axis, int):\n        raise TypeError(\"axis must be an integer.\")\n    if axis < 0 or axis >= len(x.shape):\n        raise ValueError(\"axis must be a valid axis of the input array.\")\n    if isinstance(indices_or_sections, int):\n        if indices_or_sections <= 0 or indices_or_sections >= x.shape[axis]:\n            raise ValueError(\"Number of splits must be a positive integer less than the number of elements along the specified axis.\")\n        indices_or_sections = np.array_split(np.arange(x.shape[axis]), indices_or_sections)\n    else:\n        indices_or_sections = np.array(indices_or_sections)\n        if np.any(indices_or_sections <= 0) or np.any(indices_or_sections >= x.shape[axis]):\n            raise ValueError(\"Split indices must be positive integers less than the number of elements along the specified axis.\")\n        indices_or_sections = np.split(np.arange(x.shape[axis]), indices_or_sections)\n    split_sizes = [len(segment) for segment in indices_or_sections]", "CodeBleu_score": 31.504925290464968}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 1:\n        return ys\n    x_shape = x.shape\n    y_shapes = [y.shape for y in ys]\n    if all(len(y_shape) == len(x_shape) for y_shape in y_shapes):\n        return ys\n    split_sizes = [y.shape[axis] for y in ys]\n    temp_x = np.empty(x_shape)\n    temp_ys = np.split(temp_x, indices_or_sections, axis)\n    expected_shapes = [tuple(s if i == axis else d for (i, d) in enumerate(y_shape)) for (y_shape, s) in zip(temp_ys, split_sizes)]\n    for (i, (y, expected_shape)) in enumerate(zip(ys, expected_shapes)):\n        if y.shape != expected_shape:\n            ys[i] = y.reshape(expected_shape)\n    return ys\n\n\n\n\n\n\n", "CodeBleu_score": 35.63502807729596}]}
{"instance_id": "cf39fb123842", "generation_result": [{"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        xp = chainer.cuda.get_array_module(*batch)\n        concat = xp.concatenate(batch, axis=0)\n        sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n        concat_dev = chainer.dataset.to_device(device, concat)\n        batch_dev = cp.split(concat_dev, sections)\n        return batch_dev\n\n", "CodeBleu_score": 86.88609731501656}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    xp = cuda.get_array_module(*batch)\n    concat = xp.concatenate(batch, axis=0)\n    sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n    concat_dev = cuda.to_gpu(concat)\n    batch_dev = cuda.cupy.split(concat_dev, sections)\n    return batch_dev\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 75.258524750886}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        xp = chainer.cuda.get_array_module(*batch)\n        concat = xp.concatenate(batch, axis=0)\n        sections = numpy.cumsum([len(x) for x in batch[:-1]], dtype=numpy.int32)\n        concat_dev = chainer.dataset.to_device(device, concat)\n        return cupy.split(concat_dev, sections)", "CodeBleu_score": 83.26608905611911}]}
{"instance_id": "845c744d897c", "generation_result": [{"code": "def make_image(trainer)\n\t\n    seed = 0\n    np.random.seed(seed)\n    n_images = 6 * 6\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config('train', False):\n        x = gen(z)\n    x = chainer.cuda.to_cpu(x.data)\n    np.random.seed()\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((6, 6, 1, H, W))\n    x = x.transpose(0, 3, 1, 4, 2)\n    if not os.path.exists('preview'):\n        os.makedirs('preview')\n    Image.fromarray(x.reshape((H * 6, W * 6))).save(preview_dir + '/image_{:0>8}.png'.format(trainer.updater.iteration))\n\n", "CodeBleu_score": 62.60380824946178}, {"code": "def make_image(trainer)\n\t\n    seed = np.random.randint(100000)\n    np.random.seed(seed)\n    n_images = 64\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n        x = gen(z)\n    x = chainer.Variable(x)\n    x = to_cpu(x.data)\n    np.random.seed()\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((n_images, 1, H, W))\n    x = x.transpose(0, 2, 3, 1)\n    preview_dir = '{}/preview'.format(args.out)\n    preview_path = preview_dir + '/image{:0>8}.png'.format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x[0, 0]).save(preview_path)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 62.32730510714768}, {"code": "def make_image(trainer)\n\t\n    np.random.seed()\n    n_images = 64\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config(\"train\", False):\n        x = gen(z)\n    x = chainer.cuda.to_cpu(x.data)\n    np.random.seed()\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((n_images, 1, H, W))\n    x = x.transpose(0, 2, 3, 1)\n    preview_dir = \"{}/preview\".format(args.out)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x[0, :, :, :]).save(\n        preview_dir + \"/image_{:0>8}.png\".format(trainer.updater.iteration)\n    )\n\n", "CodeBleu_score": 62.4932409855674}]}
{"instance_id": "fc2162d43aee", "generation_result": [{"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos <= to_pos\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.30748086205847}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    if from_dtype == to_dtype:\n        return True\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos > to_pos\n\n", "CodeBleu_score": 50.897842095091136}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    if from_dtype.kind != to_dtype.kind:\n        return False\n    if from_dtype.kind == \"f\":\n        return _typechars.find(from_dtype.char) >= _typechars.find(to_dtype.char)\n    if from_dtype.kind == \"i\":\n        return _typechars.find(from_dtype.char) <= _typechars.find(to_dtype.char)\n    if from_dtype.kind == \"u\":\n        return _typechars.find(from_dtype.char) <= _typechars.find(to_dtype.char)\n    return from_dtype == to_dtype\n\n", "CodeBleu_score": 48.63684356404695}]}
{"instance_id": "5b8e2d5e6e12", "generation_result": [{"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is None:\n        g = plt.gca()\n    elif isinstance(g, Visualizer):\n        g = g.ax\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"cannot create legend with {:,} labels and \"\n            \"{:,} colors\".format(len(labels), len(colors))\n        )\n\n    handles = [patches.Patch(color=c, label=l) for l, c in zip(labels, colors)]\n    return g.legend(handles=handles, **legend_kwargs)", "CodeBleu_score": 59.04747457662811}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is None:\n        g = plt.gca()\n    elif isinstance(g, Visualizer):\n        g = g.ax\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"Size mismatch: len(labels) != len(colors) ({} != {})\".format(\n                len(labels), len(colors)\n            )\n        )\n\n    handles = [patches.Patch(color=c, label=l) for l, c in zip(labels, colors)]\n    return g.legend(handles=handles, **legend_kwargs)", "CodeBleu_score": 58.32392570011178}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if g is not None:\n        if isinstance(g, Visualizer):\n            g = g.ax\n        elif not isinstance(g, Axes):\n            raise YellowbrickValueError(\n                \"g must be a Visualizer, None, or an Axes object\"\n            )\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"labels and colors must have the same length\"\n        )\n\n    handles = [patches.Patch(color=c, label=l) for l, c in zip(labels, colors)]\n    return g.legend(handles=handles, **legend_kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 58.60505275957537}]}
{"instance_id": "494e7f719eb6", "generation_result": [{"code": "def pcoords_time(X, y, fast=True)\n\t\n    fig, ax = plt.subplots()\n    oz = ParallelCoordinates(fast=fast)\n    start = time.time()\n    oz.fit_transform(X, y)\n    elapsed = time.time() - start\n    plt.cla()\n    plt.close()\n    return elapsed\n\n", "CodeBleu_score": 45.43923297174503}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    fig, ax = plt.subplots()\n    viz = ParallelCoordinates(fast=fast)\n    start = time.time()\n    viz.fit_transform(X, y, ax=ax)\n    end = time.time()\n    plt.clf()\n    plt.close()\n    return end - start\n\n", "CodeBleu_score": 25.118364049798835}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    fig, ax = plt.subplots()\n    viz = ParallelCoordinates(fast=fast, ax=ax)\n    start = time.time()\n    viz.fit_transform(X, y)\n    end = time.time()\n    plt.cla()\n    plt.close()\n    return end - start\n\n", "CodeBleu_score": 31.372942564891655}]}
{"instance_id": "db4143bc029f", "generation_result": [{"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the alpha transparency value from the object's attributes or defaults to 0.25\n    alpha = kwargs.get(\"alpha\", 0.25)\n\n    # For each instance, extract the feature vector and corresponding label\n    for xi, yi in zip(X, y):\n        # Determine the color based on the label\n        color = self.get_colors(yi)\n\n        # Plot the feature vector against a predefined increment sequence on the axis\n        self.ax.plot(xi, range(len(xi)), color=color, alpha=alpha)\n\n    # Return the axis object with the plotted instances\n    return self.ax\n\n", "CodeBleu_score": 32.51801804675104}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n\n    for i, (xi, yi) in enumerate(zip(X, y)):\n        self.ax.scatter(\n            xi,\n            np.ones(xi.shape) * i,\n            color=self.get_colors(yi),\n            alpha=alpha,\n            **kwargs\n        )\n\n    return self.ax\n\n", "CodeBleu_score": 30.647696343578286}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n    for i, xi in enumerate(X):\n        yi = y[i]\n        color = self.get_colors(yi)\n        self.ax.plot(xi, self.increment, c=color, alpha=alpha, **kwargs)\n    return self.ax\n\n", "CodeBleu_score": 45.35496979000763}]}
{"instance_id": "676433312ffe", "generation_result": [{"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n    X = np.c_[X, np.ones(X.shape[0])]\n    increments = [None]\n\n    for label in np.unique(y):\n        color = self.get_colors(label)[0]\n        instances = X[y == label]\n        self.ax.plot(instances, color=color, alpha=alpha, **kwargs)\n        increments.append(instances.shape[0])\n\n    return self.ax\n\n", "CodeBleu_score": 29.230690254660985}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    increments = []\n    for label in np.unique(y):\n        color = self.get_colors(label)\n        X_in_class = X[y == label, :]\n        X_in_class = np.hstack([X_in_class, np.ones((X_in_class.shape[0], 1))])\n        increments.append(None)\n        increments_separated = np.vstack(\n            [X_in_class[i, :] for i in range(X_in_class.shape[0])]\n        )\n        increments.append(increments_separated)\n    increments = np.vstack(increments)\n    self.ax.plot(\n        increments[:, 0], increments[:, 1], c=color, alpha=alpha, **kwargs\n    )\n    return self.ax\n\n\n\n", "CodeBleu_score": 44.93590865700705}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Set the alpha transparency value from the object's attributes or defaults to 0.5\n    alpha = kwargs.get(\"alpha\", self.alpha)\n\n    # Add a column of ones to X to separate the instances visually\n    X_in_class = np.hstack((X, np.ones((X.shape[0], 1))))\n\n    # Append None to the increments list to create breaks between instances\n    increments = self.increments_ + [None]\n\n    # Identify unique class labels in y\n    classes = np.unique(y)\n\n    # Iterate over the unique class labels\n    for idx, grp in enumerate(classes):\n\n        # Determine the color for the current class\n        color = self.get_colors(grp)[0]\n\n        # Select the instances of X belonging to the current class\n        instances = X_in_class[y == grp]\n\n        # Plot the instances of the current class as a single line plot with the specified color and alpha transparency\n        self.ax.plot(\n            np.vstack(instances),\n            color=color,\n            alpha=alpha,\n            label=str(grp),\n            **kwargs,\n        )\n\n    # Return the axis object with the plotted classes\n    return self.ax\n\n", "CodeBleu_score": 41.490882346362476}]}
{"instance_id": "9d297b12a673", "generation_result": [{"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n    oz = RadViz(ax=axes[0], alpha=0.8, title=\"Occupancy\")\n    oz.fit(*load_occupancy())\n    oz.finalize()\n\n    oz = Rank2D(ax=axes[1], alpha=0.8, title=\"Concrete\")\n    oz.fit(*load_concrete())\n    oz.transform(*load_concrete())\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()", "CodeBleu_score": 33.65469344486756}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    oz = RadViz(ax=axes[0], alpha=0.3)\n    oz.fit(*load_occupancy())\n    oz.finalize()\n\n    oz = Rank2D(ax=axes[1], alpha=0.3)\n    oz.fit(*load_concrete())\n    oz.transform(*load_concrete())\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()\n\n", "CodeBleu_score": 34.20277352258004}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n    oz = RadViz(ax=axes[0], alpha=0.8, title=\"Occupancy\")\n    oz.fit(*load_occupancy())\n    oz.finalize()\n\n    oz = Rank2D(ax=axes[1], alpha=0.8, title=\"Concrete\")\n    oz.fit(*load_concrete())\n    oz.transform(*load_concrete())\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n\n", "CodeBleu_score": 36.472802846732016}]}
{"instance_id": "fd1b4b9cd7ef", "generation_result": [{"code": "def regression(fname=\"regression.png\")\n\t\n    fig, axs = plt.subplots(1, 2, figsize=(18, 6))\n\n    alphas = np.logspace(-10, 10, 21)\n\n    data = load_concrete(split=True)\n\n    oz.score(\n        LassoCV(alphas=alphas),\n        data.x_train,\n        data.y_train,\n        ax=axs[0],\n        scoring=\"neg_mean_absolute_error\",\n        title=\"LassoCV\",\n    )\n\n    oz.score(\n        RidgeCV(alphas=alphas),\n        data.x_train,\n        data.y_train,\n        ax=axs[1],\n        scoring=\"neg_mean_absolute_error\",\n        title=\"RidgeCV\",\n    )\n\n    plt.tight_layout()\n\n    path = os.path.join(IMG, fname)\n    plt.savefig(path)\n\n    return path\n\n", "CodeBleu_score": 42.98120434503373}, {"code": "def regression(fname=\"regression.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-3, 3, num=100)\n\n    X_train, X_test, y_train, y_test = load_concrete(split=True)\n\n    oz = PredictionError(RidgeCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.finalize()\n\n    oz = ResidualsPlot(LassoCV(alphas=alphas))\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.finalize()\n\n    plt.tight_layout()\n    path = os.path.join(IMG, fname)\n    plt.savefig(path)\n    return path", "CodeBleu_score": 48.84872477505314}, {"code": "def regression(fname=\"regression.png\")\n\t\n    plt.figure(figsize=(18, 6))\n    alphas = np.logspace(-10, 10, 21)\n\n    plt.subplot(1, 2, 1)\n    oz.score(\n        LassoCV(alphas=alphas),\n        load_concrete(split=True),\n        plot_type=PredictionError,\n        fit_params={\"return_train_score\": True},\n    )\n\n    plt.subplot(1, 2, 2)\n    oz.score(\n        RidgeCV(alphas=alphas),\n        load_concrete(split=True),\n        plot_type=ResidualsPlot,\n        fit_params={\"return_train_score\": True},\n    )\n\n    plt.tight_layout()\n    path = os.path.join(IMG, fname)\n    plt.savefig(path)\n    return path\n\n", "CodeBleu_score": 36.45019325724519}]}
{"instance_id": "627126918f88", "generation_result": [{"code": "def classification(fname=\"classification.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n\n    # Left Axis\n    oz = ClassificationReport(\n        LogisticRegression(),\n        *load_spam(split=True),\n        labels=[\"not spam\", \"spam\"],\n        name=\"Logistic Regression\",\n        ax=axes[0],\n    )\n    oz.fit(*load_spam())\n    oz.finalize()\n\n    # Right Axis\n    oz = DiscriminationThreshold(\n        MultinomialNB(),\n        *load_spam(),\n        ax=axes[1],\n        name=\"Naive Bayes\",\n        threshold=0.5,\n    )\n    oz.fit(*load_spam())\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n\n", "CodeBleu_score": 40.140346561261225}, {"code": "def classification(fname=\"classification.png\")\n\t\n    # Create a figure and axes\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n    # Left plot: ClassificationReport for MultinomialNB\n    X_train, X_test, y_train, y_test = load_spam(split=True)\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n    oz = ClassificationReport(model, classes=[\"not spam\", \"spam\"], ax=axes[0])\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.finalize()\n\n    # Right plot: DiscriminationThreshold for LogisticRegression\n    X, y = load_spam()\n    model = LogisticRegression()\n    model.fit(X, y)\n    oz = DiscriminationThreshold(model, ax=axes[1])\n    oz.fit(X, y)\n    oz.finalize()\n\n    # Adjust layout and save the figure\n    plt.tight_layout()\n    plt.savefig(fname, dpi=300)\n\n\n", "CodeBleu_score": 43.58888844101729}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\n    # Left plot\n    oz = ClassificationReport(\n        MultinomialNB(),\n        cmap=\"coolwarm\",\n        title=\"MultinomialNB\",\n        ax=ax[0],\n    )\n    oz.fit(X_train, y_train)\n    oz.score(X_test, y_test)\n    oz.finalize()\n\n    # Right plot\n    oz = DiscriminationThreshold(LogisticRegression(), ax=ax[1])\n    oz.fit(X, y)\n    oz.finalize()\n\n    plt.tight_layout()\n    plt.savefig(fname)\n    plt.close()\n\n", "CodeBleu_score": 38.22056739225679}]}
{"instance_id": "318d3a674694", "generation_result": [{"code": "def get_color_cycle()\n\t\n    try:\n        from matplotlib import rcParams\n        colors = rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n    except (KeyError, AttributeError):\n        # If \"axes.prop_cycle\" is undefined, get the color cycle\n        # from \"axes.color_cycle\".\n        # This is a deprecated alias of \"axes.prop_cycle\" as of 1.5.0.\n        colors = rcParams[\"axes.color_cycle\"]\n    return colors\n\n", "CodeBleu_score": 36.00551543551006}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib as mpl\n        if mpl.__version__ >= '1.5.0':\n            return [x['color'] for x in mpl.rcParams['axes.prop_cycle']]\n        else:\n            return mpl.rcParams['axes.color_cycle']\n    except KeyError:\n        return mpl.rcParams['axes.color_cycle']\n\n", "CodeBleu_score": 43.48319434205053}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib as mpl\n\n        if mpl.__version__ >= \"1.5.0\":\n            from matplotlib.rcsetup import cycler\n\n            return cycler(\n                \"color\", mpl.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n            )\n        else:\n            return mpl.rcParams[\"axes.color_cycle\"]\n    except KeyError:\n        return mpl.rcParams[\"axes.color_cycle\"]\n\n", "CodeBleu_score": 32.04143129808603}]}
{"instance_id": "f3fac557334c", "generation_result": [{"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized)\n    plt.plot(self.x_normalized, self.distance, 'r')\n    plt.ylim(0, 1)\n    plt.vlines(x=self.knee, ymin=0, ymax=1, linestyles='dashed')\n    plt.yticks(np.arange(0, 1.01, 0.1))\n    plt.xticks(np.arange(0, 1.01, 0.1))\n    plt.xlabel('Normalized X')\n    plt.ylabel('Normalized Y')\n    plt.title('Normalized Curve with Knee Point')\n    plt.show()\n\n\n\n", "CodeBleu_score": 45.14567970603991}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.normalized_x, self.normalized_y)\n    plt.plot(self.distances_normalized, self.y_normalized, c=\"red\")\n    plt.ylim(0, 1)\n    plt.vlines(\n        x=self.knee,\n        ymin=0,\n        ymax=1,\n        linestyles=\"dashed\",\n        colors=\"orange\",\n        label=\" knee/elbow value: \" + str(round(self.knee, 3)),\n    )\n    plt.yticks(np.arange(0, 1.05, 0.05))\n    plt.xticks(np.arange(0, 1.05, 0.05))\n    plt.legend(loc=\"best\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.6567135306101}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.normalized_x, self.normalized_y)\n    plt.plot(self.x, self.y, \"r\")\n    plt.ylim(min(self.normalized_y) - 0.1, max(self.normalized_y) + 0.1)\n    plt.vlines(\n        self.knee,\n        min(self.normalized_y) - 0.1,\n        max(self.normalized_y) + 0.1,\n        linestyles=\"dashed\",\n    )\n    plt.yticks(np.arange(min(self.normalized_y), max(self.normalized_y) + 0.1, 0.1))\n    plt.xticks(np.arange(min(self.x), max(self.x) + 0.1, 0.1))\n    plt.xlabel(\"Points\")\n    plt.ylabel(\"Distance\")\n    plt.title(\"Knee Point\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.39346592816831}]}
{"instance_id": "b2d48aae4fce", "generation_result": [{"code": "def plot_knee(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, 'bx-')\n    plt.vlines(self.x[self.knee], plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.586332828002405}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, \"bx-\")\n    plt.vlines(self.x[self.knee], plt.ylim()[0], plt.ylim()[1], linestyles=\"dashed\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.586332828002405}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, \"bx-\")\n    plt.vlines(self.x[self.knee], plt.ylim()[0], plt.ylim()[1], linestyles=\"dashed\")\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 53.586332828002405}]}
{"instance_id": "4450ba2384c9", "generation_result": [{"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, data.shape[0] - 1))\n\n", "CodeBleu_score": 88.30161134807123}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, len(data) - 1));\n\n", "CodeBleu_score": 81.79703624972666}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, data.shape[0] - 1));\n\n", "CodeBleu_score": 89.31129533842159}]}
{"instance_id": "b09a163f3ff1", "generation_result": [{"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=pl.cm.Paired)\n    pl.xlabel('Sepal length')\n    pl.ylabel('Sepal width')\n\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n\n    pl.show()\n\n", "CodeBleu_score": 67.47269484284398}, {"code": "def plot_iris_knn()\n\t\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # Use the first two features\n    y = iris.target\n\n    # Train a kNN classifier\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    # Create a mesh grid over the feature space\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n\n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Reshape the predictions and plot the decision boundaries\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n\n    # Plot the training points\n    pl.scatter(X[:, 0], X[:, 1], c=y, edgecolor='k', cmap=pl.cm.Paired)\n    pl.xlabel('Sepal length')\n    pl.ylabel('Sepal width')\n\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n\n    pl.show()\n\n", "CodeBleu_score": 67.09832613775122}, {"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=pl.cm.Paired)\n\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=pl.cm.Paired)\n    pl.xlabel('Sepal length')\n    pl.ylabel('Sepal width')\n\n    pl.xlim(xx.min(), xx.max())\n    pl.ylim(yy.min(), yy.max())\n    pl.xticks(())\n    pl.yticks(())\n\n    pl.show()\n\n\n\n\n", "CodeBleu_score": 67.25181997508898}]}
{"instance_id": "8eaee3207c09", "generation_result": [{"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = \"k\"\n\n    ax = plt.axes()\n    ax.contour(\n        X1, X2, Z, levels, colors=colors, linestyles=linestyles\n    )\n    ax.scatter(\n        X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired, edgecolor=\"black\", s=20\n    )\n\n    ax.axis(\"tight\")\n\n", "CodeBleu_score": 62.160263174084676}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = 'k'\n\n    ax = plt.axes()\n    ax.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n\n    ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n\n    ax.axis('tight')\n\n", "CodeBleu_score": 64.71872361074236}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = \"k\"\n\n    ax = plt.axes()\n    ax.contour(\n        X1, X2, Z, levels, colors=colors, linestyles=linestyles\n    )\n    ax.scatter(\n        X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired\n    )\n\n    ax.axis(\"tight\")\n\n", "CodeBleu_score": 61.90360815077772}]}
{"instance_id": "8b54f999b4c0", "generation_result": [{"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}]}
{"instance_id": "2419013adc6e", "generation_result": [{"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")", "CodeBleu_score": 98.88171687993604}]}
{"instance_id": "e887fd2a8513", "generation_result": [{"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_string = sourcecode.split(\".\")[0]\n    object_string = sourcecode.split(\".\")[1]\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = sourcecode.split(\"tpot.\")[1].split(\".\")[0]\n        object_string = sourcecode.split(\"tpot.\")[1].split(\".\")[1]\n    try:\n        if import_string == \"tpot\":\n            imported_object = globals()[object_string]\n        else:\n            imported_object = getattr(import_module(import_string), object_string)\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        else:\n            print(\n                f\"Warning: {e} for {import_string}.{object_string}.", "CodeBleu_score": 39.21926800066393}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_string, object_string = sourcecode.split(\".\")\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = import_string.replace(\"tpot\", \"tpot.builtins\")\n    try:\n        imported_object = importlib.import_module(import_string)\n    except ImportError as e:\n        if verbose > 2:\n            raise ImportError(\n                \"Import of {0} failed: {1}\".format(sourcecode, e)\n            )\n        else:\n            warnings.warn(\n                \"Import of {0} failed: {1}.", "CodeBleu_score": 35.59021271023368}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import_string, object_string = sourcecode.split(\".\")\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = \"tpot\"\n    try:\n        imported_object = eval(\".\".join([import_string, object_string]))\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        else:\n            print(\n                \"Warning: tpot failed to import: {}. Check the module path.\".format(\n                    sourcecode\n                )\n            )\n            return None, None, None\n    return import_string, object_string, imported_object\n\n", "CodeBleu_score": 35.44961390088108}]}
{"instance_id": "5d6f629c3363", "generation_result": [{"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for name, step in pipeline_steps:\n            fit_method = getattr(step, \"fit\", None)\n            if fit_method is not None:\n                argspec = inspect.getargspec(fit_method)\n                if \"sample_weight\" in argspec.args:\n                    key = name + \"_sample_weight\"\n                    sample_weight_dict[key] = sample_weight\n    return sample_weight_dict if sample_weight_dict else None\n\n", "CodeBleu_score": 37.9229736188314}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            fit_method = getattr(step, \"fit\", None)\n            if fit_method is not None:\n                argspec = inspect.getargspec(fit_method)\n                if \"sample_weight\" in argspec.args:\n                    key = f\"{step_name}_sample_weight\"\n                    sample_weight_dict[key] = sample_weight\n    return sample_weight_dict if sample_weight_dict else None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.97787419254273}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            fit_args = inspect.getargspec(step.fit)[0]\n            if \"sample_weight\" in fit_args:\n                key = step_name + \"__sample_weight\"\n                sample_weight_dict[key] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None\n\n", "CodeBleu_score": 54.29925779847659}]}
{"instance_id": "cae17d519818", "generation_result": [{"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._optimized_pipeline:\n        raise RuntimeError(\n            \"No optimized pipeline found. You must call fit() first.\"\n        )\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._optimized_pipeline.compile(features, target)\n        self._optimized_pipeline.fit(features, target)\n\n    if self.verbosity >= 1:\n        self._pbar.write(\"\", file=self.log_file_)\n        self._pbar.write(\n            \"Best pipeline: {}\".format(self._optimized_pipeline), file=self.log_file_\n        )\n        if self.verbosity >= 2:\n            self._pbar.write(\"\", file=self.log_file_)\n\n    # Compile and fit the entire Pareto front of pipelines\n    self._pareto_front_models = [\n        pipeline.compile(features, target).fit(features, target)\n        for pipeline in self._pareto_front\n    ]\n\n", "CodeBleu_score": 33.023502811372005}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n\n    # Check if an optimized pipeline exists\n    if not self._top_pipeline:\n        raise RuntimeError(\n            \"You must fit the TPOT classifer first. \"\n            \"Use tpot.fit(X, y) to optimize the pipeline.\"\n        )\n\n    # Compile and fit the best pipeline\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._top_pipeline.fit(features, target)\n\n    # Print the best pipeline string\n    if self.verbosity >= 1:\n        print(\n            \"", "CodeBleu_score": 17.460891618718666}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if self._best_pipeline is None:\n        raise RuntimeError(\n            \"You must fit the TPOT pipeline first. \"\n            \"You can do this by calling TPOT.fit(features, target).\"\n        )\n\n    # Compile and fit the best pipeline\n    self._best_pipeline.fit(features, target)\n\n    # Print the best pipeline string\n    if self.verbosity >= 1:\n        print(\"\", file=self.log_file_)\n        print(\n            \"Best pipeline: {}", "CodeBleu_score": 13.825650316632258}]}
{"instance_id": "638683d78167", "generation_result": [{"code": "def score(self, testing_features, testing_target)\n\t\n    if self.is_optimized_ is False:\n        raise RuntimeError(\"Pipeline has not been optimized yet. Please call optimize() first.\")\n\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n\n    if self.scoring == \"accuracy\":\n        scorer = SCORERS[\"accuracy\"]\n    elif self.scoring == \"roc_auc\":\n        scorer = SCORERS[\"roc_auc\"]\n    elif self.scoring == \"f1\":\n        scorer = SCORERS[\"f1\"]\n    elif self.scoring == \"precision\":\n        scorer = SCORERS[\"precision\"]\n    elif self.scoring == \"recall\":\n        scorer = SCORERS[\"recall\"]\n    elif isinstance(self.scoring, str):\n        raise ValueError(\n            \"Scoring function {} not supported. Please use one of the following: {}\".format(\n                self.scoring, list(SCORERS.keys())\n            )\n        )\n    elif callable(self.scoring):\n        scorer = self.scoring\n    else:\n        raise ValueError(\n            \"Scoring function {} not supported. Please use one of the following: {}\".format(\n                self.scoring, list(SCORERS.keys())\n            )\n        )\n\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.06640967009847}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if self._fitted_pipeline is None:\n        raise RuntimeError(\"You must fit the pipeline before calling score\")\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n    if self.scoring is None:\n        raise ValueError(\n            \"No scoring function provided. Please provide a valid scoring function.\"\n        )\n    if isinstance(self.scoring, str):\n        if self.scoring not in SCORERS.keys():\n            raise ValueError(\n                \"Scoring function %s not available. Available options are %s\"\n                % (self.scoring, list(SCORERS.keys()))\n            )\n        scorer = SCORERS[self.scoring]\n    elif callable(self.scoring):\n        scorer = self.scoring\n    else:\n        raise ValueError(\n            \"Scoring function must be a string (name of a predefined scorer) or a callable.\"\n        )\n    return scorer(self._fitted_pipeline, testing_features, testing_target)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.392761636961325}, {"code": "def score(self, testing_features, testing_target)\n\t\n    # Check if the pipeline has been optimized\n    if not self._is_optimized:\n        raise RuntimeError(\"Cannot score pipeline because it has not been optimized\")\n\n    # Validate testing features and target\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n\n    # Get scorer\n    if isinstance(self._scoring_function, str):\n        scorer = SCORERS[self._scoring_function]\n    elif callable(self._scoring_function):\n        scorer = self._scoring_function\n    else:\n        raise RuntimeError(\"Scoring function not supported: {}\".format(self._scoring_function))\n\n    # Calculate and return score\n    return scorer(self._fitted_pipeline, testing_features, testing_target)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.29680351467056}]}
{"instance_id": "a04382560333", "generation_result": [{"code": " def _impute_values(self, features)\n\t\n        if self.verbosity > 1:\n            print(\"Imputing missing values in feature set...\", file=self.log_file_)\n\n        if not self._imputer:\n            self._imputer = SimpleImputer(strategy=\"median\")\n            self._imputer.fit(features)\n\n        return self._imputer.transform(features)\n\n", "CodeBleu_score": 73.6418739920405}, {"code": " def _impute_values(self, features)\n\t\n        if self.verbosity > 1:\n            print(\n                \"Imputing missing values in feature set using SimpleImputer...\",\n                file=self.log_file_,\n            )\n\n        if not self.imputer:\n            self.imputer = SimpleImputer(strategy=\"median\")\n            self.imputer.fit(features)\n\n        return self.imputer.transform(features)\n\n", "CodeBleu_score": 57.09782488964266}, {"code": " def _impute_values(self, features)\n\t\n        if self.verbosity > 1:\n            print(\n                \"Imputing missing values in feature set using SimpleImputer...\",\n                file=self.log_file_,\n            )\n        if not self.imputer:\n            self.imputer = SimpleImputer(strategy=\"median\")\n            self.imputer.fit(features)\n        return self.imputer.transform(features)\n\n    def _transform(self, X):\n        \"\"\"Transform the data using the fitted transformer.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The input samples.\n\n        Returns\n        -------\n        X_transformed : array-like, shape [n_samples, n_features]\n            The transformed samples.\n\n        \"\"\"\n        # Use the fitted transformer to transform the data\n        return self.transformer.transform(X)\n\n    def fit(self, X, y=None):\n        \"\"\"Fit the transformer to the data.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The input samples.\n\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API\n            requires this parameter.\n\n        Returns\n        -------\n        self : object\n            Returns self.\n\n        \"\"\"\n        # Fit the transformer to the data\n        self.transformer.fit(X, y)\n        return self\n\n    def fit_transform(self, X, y=None, **fit_params):\n        \"\"\"Fit the transformer to the data, then transform the data.\n\n        Parameters\n        ----------\n        X : array-like, shape [n_samples, n_features]\n            The input samples.\n\n        y : None\n            There is no need of a target in a transformer, yet the pipeline API\n            requires this parameter.\n\n        Returns\n        -------\n        X_transformed : array-like, shape [n_samples, n_features]\n            The transformed samples.\n\n        \"\"\"\n        # Fit the transformer to the data, then transform the data\n        self", "CodeBleu_score": 49.98327889610127}]}
{"instance_id": "0043d411c332", "generation_result": [{"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    # Generate the pipeline code string from the expression and a predefined set of operators\n    code = generate_pipeline_code(expr, operators)\n\n    # Evaluate the pipeline code string within a specific context to obtain the scikit-learn pipeline object\n    pipeline = eval(code, self.context)\n\n    # Set the pipeline's memory attribute\n    pipeline.memory = self.memory\n\n    # If a random state is specified, set the random_state parameter for each step in the pipeline\n    if self.random_state is not None:\n        set_param_recursive(pipeline, 'random_state', self.random_state)\n\n    # Return the configured scikit-learn pipeline\n    return pipeline\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.49967378619638}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    code_str = self.generate_pipeline_code(expr)\n    context = {\n        \"random_state\": self.random_state,\n        \"memory\": self.memory,\n        \"verbose\": self.verbose,\n        \"scoring\": self.scoring,\n        \"custom_scoring_functions\": self.custom_scoring_functions,\n        \"custom_transformers\": self.custom_transformers,\n        \"custom_transformers_search\": self.custom_transformers_search,\n        \"custom_transformers_search_args\": self.custom_transformers_search_args,\n        \"custom_transformers_search_kwargs\": self.custom_transformers_search_kwargs,\n        \"custom_transformers_search_n_jobs\": self.custom_transformers_search_n_jobs,\n        \"custom_transformers_search_verbose\": self.custom_transformers_search_verbose,\n        \"custom_transformers_search_random_state\": self.custom_transformers_search_random_state,\n        \"custom_transformers_search_n_iter\": self.custom_transformers_search_n_iter,\n        \"custom_transformers_search_cv\": self.custom_transformers_search_cv,\n        \"custom_transformers_search_refit\": self.custom_transformers_search_refit,\n        \"custom_transformers_search_return_train_score\": self.custom_transformers_search_return_train_score,\n        \"custom_transformers_search_error_score\": self.custom_transformers_search_error_score,\n        \"custom_transformers_search_n_splits\": self.custom_transformers_search_n_splits,\n        \"custom_transformers_search_test_size\": self.custom_transformers_search_test_size,\n        \"custom_transformers_search_train_size\": self.custom_transformers_search_train_size,\n        \"custom_transformers_search_shuffle\": self.custom_transformers_search_shuffle,\n        \"custom_transformers_search_stratify\": self.custom_transformers_search_strat", "CodeBleu_score": 13.197442388932554}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    code = self._generate_pipeline_code(expr, self.operators)\n    eval_globals = copy(self.eval_globals)\n    eval_locals = {}\n    exec(code, eval_globals, eval_locals)\n    pl = eval_locals[\"pl\"]\n    pl.memory = self.memory\n    if self.random_state is not None:\n        pl = self._set_param_recursive(pl, \"random_state\", self.random_state)\n    return pl\n\n\n\n\n", "CodeBleu_score": 40.517641948597216}]}
{"instance_id": "ca0ce462aa76", "generation_result": [{"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    primitives_per_ind = [set(ind1_prims.get_primitives(ind)) for ind in population]\n    population_str = [str(ind) for ind in population]\n    eligible_pairs = [(population_str.index(ind_str1), population_str.index(ind_str2)) for ind_str1 in population_str\n                       for ind_str2 in population_str\n                       if ind_str1 != ind_str2 and not primitives_per_ind[population_str.index(ind_str1)].isdisjoint(primitives_per_ind[population_str.index(ind_str2)])]\n    if not eligible_pairs:\n        return None, None\n    pair_index = randint(0, len(eligible_pairs) - 1)\n    return population[eligible_pairs[pair_index][0]], population[eligible_pairs[pair_index][1]]\n\n", "CodeBleu_score": 28.833144020775485}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    prims_per_ind = [set(ind1_prims(ind)) for ind in population]\n    str_per_ind = [str(ind) for ind in population]\n    eligible_pairs = [\n        (i, j)\n        for i in range(len(population))\n        for j in range(i + 1, len(population))\n        if not prims_per_ind[i].isdisjoint(prims_per_ind[j])\n        and str_per_ind[i] != str_per_ind[j]\n    ]\n    eligible_pairs += [(j, i) for i, j in eligible_pairs]\n    if not eligible_pairs:\n        return None, None\n    i, j = random.choice(eligible_pairs)\n    return population[i], population[j]\n\n", "CodeBleu_score": 31.903800320622327}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    prims_pop = [set(ind1_prims(ind)) for ind in population]\n\n    # Convert each individual to a string representation\n    str_pop = [str(ind) for ind in population]\n\n    # Identify pairs of individuals that share at least one primitive\n    # and are not identical\n    eligible_pairs = [(i, j) for i in range(len(population)) for j in range(i + 1, len(population))\n                      if not prims_pop[i].isdisjoint(prims_pop[j]) and str_pop[i] != str_pop[j]]\n\n    # Consider eligible pairs in both possible orders\n    eligible_pairs.extend([(j, i) for i, j in eligible_pairs])\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n\n    # Return the corresponding individuals from the population\n    return population[i], population[j]\n\n", "CodeBleu_score": 28.591376281930618}]}
{"instance_id": "4b03c843f506", "generation_result": [{"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    n_steps = len(steps)\n\n    if n_steps > 1:\n        formatted_steps = \",", "CodeBleu_score": 11.811891682442829}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    n_steps = len(steps)\n\n    if n_steps > 1:\n        formatted_steps = \",", "CodeBleu_score": 11.811891682442829}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n\n    if num_steps > 1:\n        formatted_steps = \",", "CodeBleu_score": 12.326043327563212}]}
{"instance_id": "e9aec2ee39a4", "generation_result": [{"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}]}
{"instance_id": "0513bf969510", "generation_result": [{"code": "def transform(self, X)\n\t\n    # Select categorical features based on a threshold\n    self.categorical_features = self.select_categorical_features(X)\n    if not self.categorical_features:\n        raise ValueError(\"No categorical features found in the input data.\")\n\n    # Apply one-hot encoding to the selected categorical features\n    X_selected = X[self.categorical_features]\n    X_transformed = self.one_hot_encoder.fit_transform(X_selected)\n\n    return X_transformed", "CodeBleu_score": 26.224376217159435}, {"code": "def transform(self, X)\n\t\n    X_selected = X.select_dtypes(include=['object'])\n    if X_selected.empty:\n        raise ValueError(\"No categorical features found in the input data.\")\n    ohe = OneHotEncoder(sparse=False)\n    ohe.fit(X_selected)\n    _X_selected = ohe.transform(X_selected)\n    return _X_selected", "CodeBleu_score": 27.10889613355877}, {"code": "def transform(self, X)\n\t\n    # Select categorical features based on a threshold\n    categorical_features = X.select_dtypes(include=['object', 'category']).columns\n    if len(categorical_features) == 0:\n        raise ValueError(\"No categorical features found in the input data.\")\n    X_selected = X[categorical_features]\n\n    # Apply one-hot encoding to the selected categorical features\n    ohe = OneHotEncoder(handle_unknown='ignore')\n    _X_selected = ohe.fit_transform(X_selected)\n\n    return _X_selected", "CodeBleu_score": 36.51868107416925}]}
{"instance_id": "5b1bcf42ca9e", "generation_result": [{"code": "def balanced_accuracy(y_true, y_pred)\n\t\n\n    # Identify all unique classes present in the true and predicted labels\n    classes = np.unique(np.concatenate((y_true, y_pred)))\n\n    # Initialize an empty list to store the class accuracies\n    all_class_accuracies = []\n\n    # Loop over each class\n    for c in classes:\n        # Identify the indices of the current class in the true and predicted labels\n        indices_true = np.where(y_true == c)[0]\n        indices_pred = np.where(y_pred == c)[0]\n\n        # Calculate the sensitivity (true positive rate) for the current class\n        sensitivity = len(np.intersect1d(indices_true, indices_pred)) / len(indices_true)\n\n        # Calculate the specificity (true negative rate) for the current class\n        if len(indices_true) > 0:\n            specificity = len(np.setdiff1d(np.arange(len(y_true)), indices_true)) / len(np.setdiff1d(np.arange(len(y_true)), indices_true))\n        else:\n            specificity = 1\n\n        # Calculate the class accuracy as the average of sensitivity and specificity\n        class_accuracy = (sensitivity + specificity) / 2\n\n        # Append the class accuracy to the list of all class accuracies\n        all_class_accuracies.append(class_accuracy)\n\n    # Return the mean of all class accuracies as the balanced accuracy\n    return np.mean(all_class_accuracies)", "CodeBleu_score": 23.562372687047468}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    # Identify all unique classes present in the true and predicted labels\n    classes = np.unique(np.concatenate((y_true, y_pred)))\n    # Initialize an empty list to store class accuracies\n    all_class_accuracies = []\n    # Loop over each class\n    for class_ in classes:\n        # Identify the true positive (TP) and true negative (TN) instances for the current class\n        TP = np.sum((y_true == class_) & (y_pred == class_))\n        TN = np.sum((y_true != class_) & (y_pred != class_))\n        # Identify the actual positive (AP) and actual negative (AN) instances for the current class\n        AP = np.sum(y_true == class_)\n        AN = np.sum(y_true != class_)\n        # Calculate the sensitivity (TPR) and specificity (TNR) for the current class\n        sensitivity = TP / AP if AP > 0 else 0\n        specificity = TN / AN if AN > 0 else 1\n        # Calculate the class accuracy as the average of sensitivity and specificity\n        class_accuracy = np.mean([sensitivity, specificity])\n        # Append the class accuracy to the list of all class accuracies\n        all_class_accuracies.append(class_accuracy)\n    # Return the mean of all class accuracies\n    return np.mean(all_class_accuracies)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.01022452774409}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n\n    classes = np.unique(y_true)\n    class_accuracies = []\n\n    for c in classes:\n        true_positives = np.sum((y_true == c) & (y_pred == c))\n        true_negatives = np.sum((y_true != c) & (y_pred != c))\n        false_positives = np.sum((y_true != c) & (y_pred == c))\n        false_negatives = np.sum((y_true == c) & (y_pred != c))\n\n        sensitivity = true_positives / (true_positives + false_negatives)\n        specificity = true_negatives / (true_negatives + false_positives)\n\n        if len(np.unique(y_true)) == 1:\n            specificity = 1\n\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n\n    return np.mean(class_accuracies)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.398548916414132}]}
{"instance_id": "19a9ad39de0a", "generation_result": [{"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    non_zero = np.count_nonzero(X, axis=1)\n    zero = X.shape[1] - non_zero\n    non_zero = non_zero.reshape(X.shape[0], 1)\n    zero = zero.reshape(X.shape[0], 1)\n    X = np.hstack((non_zero, zero, X))\n    return X\n\n", "CodeBleu_score": 16.347189872255775}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    non_zeros = np.count_nonzero(X, axis=1)\n    non_zeros = np.reshape(non_zeros, (X.shape[0], 1))\n    zeros = X.shape[1] - non_zeros\n    zeros = np.reshape(zeros, (X.shape[0], 1))\n    X_new = np.hstack((non_zeros, zeros, X))\n    return X_new\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.89537849643384}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    if self.sparse:\n        X = X.toarray()\n    if self.non_zero:\n        non_zero_count = np.count_nonzero(X, axis=1)\n        X = np.hstack((non_zero_count.reshape(-1, 1), X))\n    if self.zero:\n        zero_count = np.count_nonzero(X == 0, axis=1)\n        X = np.hstack((zero_count.reshape(-1, 1), X))\n    return X\n\n\n\n\n", "CodeBleu_score": 22.891195262958764}]}
{"instance_id": "5e8db0b5d447", "generation_result": [{"code": "def _init_pretest(self, features, target)\n\t\n    self.n_classes = len(np.unique(target))\n    self.train_size = max(self.train_size, self.n_classes)\n    pretest_X, _, pretest_y, _ = train_test_split(\n        features, target, train_size=self.train_size, random_state=self.random_state\n    )\n    if len(np.unique(pretest_y)) < self.n_classes:\n        pretest_X, pretest_y = self._safe_indexing(pretest_X, pretest_y)\n    return pretest_X, pretest_y\n", "CodeBleu_score": 21.136708109737988}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.num_classes = len(np.unique(target))\n    self.train_size = max(self.train_size, self.num_classes)\n    pretest_X, pretest_y = train_test_split(\n        features, target, train_size=self.train_size, random_state=self.random_state\n    )\n    if not np.array_equal(np.unique(pretest_y), np.arange(self.num_classes)):\n        pretest_X, pretest_y = self._safe_indexing(pretest_X, pretest_y, axis=0)\n    return pretest_X, pretest_y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.497740314098557}, {"code": "def _init_pretest(self, features, target)\n\t\n    # Calculate the number of unique target classes\n    n_classes = len(np.unique(target))\n    # Ensure the training size is at least this number\n    self.train_size = max(self.train_size, n_classes)\n    # Split the features and target into pretest_X and pretest_y with a specified random state\n    pretest_X, pretest_y = train_test_split(\n        features, target, train_size=self.train_size, random_state=self.random_state\n    )\n    # If all target classes are not included in pretest_y, adjust pretest_y to include at least one example from each class\n    if len(np.unique(pretest_y)) != n_classes:\n        unique_target_values = np.unique(target)\n        for value in unique_target_values:\n            if value not in pretest_y:\n                pretest_X = np.vstack((pretest_X, features[target == value][0]))\n                pretest_y = np.append(pretest_y, value)\n    return pretest_X, pretest_y\n\n", "CodeBleu_score": 30.832577438006968}]}
{"instance_id": "5e3d48667396", "generation_result": [{"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.dtypes.DType):\n        return dtype.as_numpy_dtype\n    return dtype\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.12379432275329}, {"code": "def _to_numpy_type(dtype)\n\t\n    if dtype is None:\n        return None\n    if isinstance(dtype, tf.DType):\n        return dtype.as_numpy_dtype\n    if isinstance(dtype, np.dtype):\n        return dtype\n    if isinstance(dtype, type):\n        return np.dtype(dtype)\n    raise TypeError(f\"Expected a TensorFlow data type or a NumPy data type, got {dtype}.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 67.12757323549779}, {"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.DType):\n        return dtype.as_numpy_dtype\n    return dtype\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.19748004987954}]}
{"instance_id": "8f1120fdd463", "generation_result": [{"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        return ds.as_numpy_iterator()\n    except AttributeError:\n        pass\n\n    if batch_size is None:\n        return map(_to_numpy, ds)\n\n    try:\n        batched_ds = ds.batch(batch_size)\n        return batched_ds.as_numpy_iterator()\n    except AttributeError:\n        return map(_to_numpy, ds)\n\n", "CodeBleu_score": 18.22782026993176}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    if batch_size is None:\n        try:\n            return ds.as_numpy_iterator()\n        except AttributeError:\n            return ds.make_one_shot_iterator().get_next()\n    else:\n        try:\n            return ds.batch(batch_size).as_numpy_iterator()\n        except AttributeError:\n            return ds.batch(batch_size).make_one_shot_iterator().get_next()\n\n", "CodeBleu_score": 13.890160375727886}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        ds = ds.batch(batch_size, drop_remainder=True)\n    except AttributeError:\n        ds = ds.batch(batch_size)\n\n    def _numpy_gen():\n        for batch in ds:\n            yield tf.nest.map_structure(_to_numpy, batch)\n\n    return tfds.as_numpy(_numpy_gen())\n\n\n", "CodeBleu_score": 17.987472199788407}]}
{"instance_id": "282271955871", "generation_result": [{"code": "def get_prng(seed)\n\t\n    if seed is None:\n        seed = np.random.randint(0, 2**32)\n    if not isinstance(seed, int):\n        raise TypeError(\"Seed must be an integer.\")\n    seed = np.asarray(seed)\n    if seed.size > 1:\n        raise ValueError(\"Seed must be a scalar.\")\n    seed = seed.reshape((1,))\n    seed = np.bitwise_and(seed, np.array([2**32 - 1]))\n    seed = np.asarray(seed, dtype=np.uint32)\n    key = np.concatenate([seed, np.array([0], dtype=np.uint32)])\n    return key\n\n", "CodeBleu_score": 37.17398059437772}, {"code": "def get_prng(seed)\n\t\n    if isinstance(seed, int):\n        seed = np.array(seed)\n    if not isinstance(seed, np.ndarray):\n        raise TypeError(\"seed must be an int or numpy.ndarray\")\n    if seed.size != 1:\n        raise ValueError(\"seed must be a scalar\")\n    seed = np.bitwise_and(seed.view(np.uint32), 0xffffffff)\n    seed = np.asarray(seed, dtype=np.uint32)\n    key = np.concatenate((seed, np.array([0], dtype=np.uint32)))\n    return key\n\n", "CodeBleu_score": 37.21586888849549}, {"code": "def get_prng(seed)\n\t\n    seed = np.asarray(seed, dtype=np.uint32)\n    assert seed.shape == ()\n    seed = np.asarray(seed, dtype=np.uint32)\n    key = np.bitwise_and(seed, 0xffffffff)\n    key = np.right_shift(key, 16)\n    subkey = np.bitwise_and(seed, 0x0000ffff)\n    return np.concatenate([key, subkey], axis=0)\n\n", "CodeBleu_score": 23.86934543042528}]}
{"instance_id": "42234dccce9a", "generation_result": [{"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pdt.DatetimeTZDtype):\n        return s.dt.tz_convert(cls.timezone)\n    elif pdt.is_datetime64_dtype(s):\n        return s.dt.tz_localize(cls.timezone)\n    elif pdt.is_numeric_dtype(s):\n        return s.apply(lambda x: pdt.to_datetime(x, unit=\"s\", utc=True)).dt.tz_localize(cls.timezone)\n    else:\n        return s.apply(lambda x: pdt.to_datetime(x, utc=True)).dt.tz_localize(cls.timezone)\n\n", "CodeBleu_score": 53.895937950991765}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pdt.DatetimeTZDtype):\n        s = s.dt.tz_convert(dtype.tz)\n    elif pdt.is_datetime64_dtype(s):\n        s = s.dt.tz_localize(dtype.tz)\n    elif pdt.is_numeric_dtype(s):\n        s = pd.to_datetime(s, unit='ms', utc=True).dt.tz_localize(dtype.tz)\n    else:\n        s = pd.to_datetime(s, utc=True).dt.tz_localize(dtype.tz)\n    return s\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 60.16314504389047}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pdt.DatetimeTZDtype):\n        return s.dt.tz_convert(cls.timezone)\n    elif pdt.is_datetime64_dtype(s):\n        return s.dt.tz_localize(cls.timezone)\n    elif pdt.is_numeric_dtype(s):\n        return pd.to_datetime(s, unit=\"s\").dt.tz_localize(cls.timezone)\n    else:\n        return pd.to_datetime(s).dt.tz_localize(cls.timezone)\n\n", "CodeBleu_score": 59.86779817018433}]}
{"instance_id": "9cee7388879b", "generation_result": [{"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz:\n        arg = arg.dt.tz_convert(\"UTC\")\n    if lower_bound.dtype.tz:\n        lower_bound = lower_bound.dt.tz_convert(\"UTC\")\n    if upper_bound.dtype.tz:\n        upper_bound = upper_bound.dt.tz_convert(\"UTC\")\n    indexer = arg.dt.hour.between(lower_bound.dt.hour, upper_bound.dt.hour)\n    return da.from_array(indexer, chunks=arg.chunksize)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.91982577514611}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is not None:\n        arg = arg.dt.tz_localize(\"UTC\")\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_localize(\"UTC\")\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_localize(\"UTC\")\n    arg = arg.dt.tz_convert(\"UTC\")\n    lower_bound = lower_bound.dt.tz_convert(\"UTC\")\n    upper_bound = upper_bound.dt.tz_convert(\"UTC\")\n    if arg.dtype.kind == \"M\":\n        arg = arg.astype(\"int64\")\n    if lower_bound.dtype.kind == \"M\":\n        lower_bound = lower_bound.astype(\"int64\")\n    if upper_bound.dtype.kind == \"M\":\n        upper_bound = upper_bound.astype(\"int64\")\n    indexer = (arg >= lower_bound) & (arg < upper_bound)\n    return da.from_array(indexer, chunks=arg.chunks)\n\n", "CodeBleu_score": 29.909808261655975}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if isinstance(arg.index, pd.DatetimeIndex):\n        if arg.index.tz is not None:\n            arg = arg.tz_convert(\"UTC\")\n        else:\n            arg = arg.tz_localize(\"UTC\")\n\n    indexer = arg.index.isin(\n        pd.date_range(lower_bound, upper_bound, freq=\"min\")\n    )\n    return da.from_array(indexer, chunks=arg.chunksize)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.389516705957558}]}
{"instance_id": "0ab1cc8ccf71", "generation_result": [{"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        value = value.to_array()\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    if like is not None:\n        if isinstance(like, tuple):\n            return asseries(cls, value, like[0])\n        elif isinstance(like, list):\n            return asseries(cls, value, like[0])\n        elif isinstance(like, dict):\n            return asseries(cls, value, list(like.values())[0])\n        else:\n            return asseries(cls, value, like)\n    return dd.from_delayed(value, meta=(None, cls), npartitions=1)\n\n", "CodeBleu_score": 35.17566655787634}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        return dd.from_array(value.to_delayed())\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    if like is not None:\n        if isinstance(like, (tuple, list)):\n            return dd.from_pandas(pd.Series(value, index=like), npartitions=1)\n        if isinstance(like, dict):\n            return dd.from_pandas(pd.Series(value, index=like.keys()), npartitions=1)\n    return dd.from_pandas(pd.Series(value), npartitions=1)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.47644729976578}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        return dd.from_array(value.to_delayed(), like=like)\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1, like=like)\n    if isinstance(value, tuple):\n        return dd.from_array(value, like=like)\n    if isinstance(value, list):\n        return dd.from_array(value, like=like)\n    if isinstance(value, dict):\n        return dd.from_array(value, like=like)\n    return dd.from_array([value], like=like)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.796550567552703}]}
{"instance_id": "926220a06a0c", "generation_result": [{"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t", "CodeBleu_score": 13.461538461538462}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k},\"\n                f\" got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 89.83741871525928}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k}.\"\n                f\" Got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 88.24580567012508}]}
{"instance_id": "95afc38c9125", "generation_result": [{"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    try:\n        classes = get_module_members(library_name)\n    except ValueError as e:\n        raise ValueError(f\"Module {library_name} not found\") from e\n\n    if estimator_name not in classes:\n        raise ValueError(\n            f\"Estimator {estimator_name} not found in {library_name}\"\n        )\n\n    if len(classes[estimator_name]) > 1:\n        logger.debug(f\"Multiple classes found for {estimator_name}: {classes[estimator_name]}\")\n        logger.warning(\"Using the first one\")\n\n    estimator_class = classes[estimator_name][0]\n\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"{estimator_class} is not a subclass of BaseEstimator\")\n\n    return estimator_class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.28857809697709}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    try:\n        classes = get_module_members(library_name)\n    except Exception as e:\n        raise ValueError(f\"Error retrieving module members for library {library_name}: {str(e)}\")\n\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} not found in module {library_name}\")\n\n    estimator_classes = [cls for name, cls in classes.items() if name == estimator_name]\n\n    if len(estimator_classes) > 1:\n        logger.debug(f\"Multiple classes found for estimator {estimator_name}: {estimator_classes}\")\n        logger.warning(f\"Multiple classes found for estimator {estimator_name}. Using the first one: {estimator_classes[0]}\")\n\n    estimator_class = estimator_classes[0]\n\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"Estimator class {estimator_class} is not a subclass of sklearn's BaseEstimator.\")\n\n    return estimator_class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.37883453415857}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n\n    if len(classes) == 0:\n        raise ValueError(f\"The library {library_name} does not have any\" \" class.\")\n\n    if estimator_name not in classes:\n        raise ValueError(\n            f\"The requested estimator {estimator_name} is not available in\"\n            f\" the library {library_name}.\"\n        )\n\n    estimator_class = classes[estimator_name]\n\n    if len(classes) > 1:\n        logger.debug(\n            \"Multiple estimators with name '{}' found: {}\".format(\n                estimator_name,\n                \", \".join([e for e in classes]),\n            )\n        )\n        logger.warning(\n            \"Using the first of multiple matching estimators: {}\".format(\n                estimator_class\n            )\n        )\n\n    if not issubclass(estimator_class, sklearn.base.BaseEstimator):\n        logger.info(\n            \"The class {} is not an sklearn estimator and will not have\"\n            \" hyperparameters tuned.\".format(estimator_class)\n        )\n\n    return estimator_class\n\n", "CodeBleu_score": 38.838167546058614}]}
{"instance_id": "9562a9cc043b", "generation_result": [{"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(join(dirname(abspath(__file__)), \"estimator_to_task_map.json\"), \"r\") as f:\n        estimator_to_task_map = json.load(f)\n    for task, postfixes in estimator_to_task_map.items():\n        if any(estimator_name.endswith(postfix) for postfix in postfixes):\n            return task\n    return \"unknown\"", "CodeBleu_score": 44.01535413033121}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(\n        join(\n            dirname(abspath(__file__)), \"estimator_to_task_map.json\"\n        ),\n        \"r\",\n    ) as f:\n        estimator_to_task_map = json.load(f)\n\n    for task, postfix in estimator_to_task_map.items():\n        if estimator_name.endswith(postfix):\n            return task\n    return \"unknown\"\n\n", "CodeBleu_score": 47.57483701191383}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(\n        join(dirname(abspath(__file__)), \"estimator_to_task_map.json\"), \"r\"\n    ) as f:\n        estimator_to_task_map = json.load(f)\n    for task, postfixes in estimator_to_task_map.items():\n        if any([estimator_name.endswith(postfix) for postfix in postfixes]):\n            return task\n    return \"unknown\"\n\n", "CodeBleu_score": 46.871550227115485}]}
{"instance_id": "2f50195d043a", "generation_result": [{"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache)\n    data = {}\n    for filename in get_filenames_by_prefix(data_cache, data_name):\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.replace(f\"{data_name}.\", \"\").split(\".\")\n        data[component] = load_data_file(\n            os.path.join(data_cache, filename), extension\n        )\n    return data\n\n", "CodeBleu_score": 46.483940585201566}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache)\n    data = {}\n    for filename in get_filenames_by_prefix(data_cache, data_name):\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.split(\".\", 1)\n        data[component] = load_data_file(os.path.join(data_cache, filename), extension)\n    return data\n\n", "CodeBleu_score": 43.16031605778219}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_cache = Path(data_cache)\n    data_filenames = get_filenames_by_prefix(data_cache, data_name)\n    data_dict = {}\n    for data_filename in data_filenames:\n        if data_filename.endswith(\".json\"):\n            continue\n        component, extension = data_filename.split(\".\")\n        data = load_data_file(data_cache / data_filename, extension)\n        data_dict[component] = data\n    return data_dict\n\n", "CodeBleu_score": 45.65306807419333}]}
{"instance_id": "e0281206029e", "generation_result": [{"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        return\n    if not url.startswith(\"http\"):\n        raise ValueError(\"Unrecognized protocol\")\n    response = requests.get(url, stream=True)\n    if response.status_code != 200:\n        raise AssertionError(f\"Failed to download (status code {response.status_code}): {url}\")\n    total = int(response.headers.get(\"content-length\"))\n    with open(filename, \"wb\") as datafile:\n        for chunk in tqdm(response.iter_content(chunk_size=max(int(total / 1000), 1024 * 1024)), total=total, unit=\"B\", unit_scale=True, unit_divisor=1024):\n            datafile.write(chunk)\n    if os.path.getsize(filename) != total:\n        raise AssertionError(\"Failed to download {}: {}\".format(url, filename))\n\n\n\n\n", "CodeBleu_score": 51.07598254338567}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(f\"Failed to download {url}: {response.status_code}\")\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        wrote = 0\n        with open(filename, \"wb\") as datafile:\n            for data in response.iter_content(block_size):\n                wrote = wrote + len(data)\n                datafile.write(data)\n        if total_size != 0 and wrote != total_size:\n            raise AssertionError(\"Only downloaded \" + str(wrote) + \" of \" + str(total_size) + \" bytes\")\n\n\n\n\n", "CodeBleu_score": 68.85021943004763}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        print(f\"File {filename} already exists.\")\n        return\n    if url.startswith(\"http\"):\n        try:\n            response = requests.get(url, stream=True)\n        except requests.exceptions.ConnectionError:\n            raise AssertionError(f\"Error downloading {url}\")\n        if response.status_code != 200:\n            raise AssertionError(f\"Error downloading {url}: status code {response.status_code}\")\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written_size = 0\n        with open(filename, \"wb\") as datafile:\n            for data in response.iter_content(block_size):\n                written_size += len(data)\n                datafile.write(data)\n        if total_size > 0 and written_size != total_size:\n            raise AssertionError(f\"Only {written_size} could be downloaded out of {total_size}\")\n\n", "CodeBleu_score": 63.79969430552329}]}
{"instance_id": "a69a71cc2fe8", "generation_result": [{"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    if data_name == \"covtype\":\n        if dataset_params.get(\"convert_to_binary\"):\n            target_labels = 2\n        else:\n            target_labels = 7\n        data_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/covtype/covtype.data.gz\"\n        raw_data_file = os.path.join(raw_data_cache, \"covtype.data\")\n        if not os.path.exists(raw_data_file):\n            download_file(data_url, raw_data_file)\n        data = pd.read_csv(raw_data_file, header=None)\n        features = data.iloc[:, 5:].to_numpy(dtype=np.float32)\n        labels = data.iloc[:, 0].to_numpy(dtype=np.int32)\n        labels = labels - 1\n        if dataset_params.get(\"convert_to_binary\"):\n            labels = np.where(labels == target_labels, 1, 0)\n        dataset = {\"features\": features, \"labels\": labels}\n        description = {\n            \"name\": \"covtype\",\n            \"n_classes\": target_labels,\n            \"length\": len(dataset[\"features\"]),\n            \"feature_names\": [f\"feature_{i}\" for i in range(features.shape[1])],\n            \"split\": {\"train_size\": 0.8, \"random_state\": 42},\n        }\n    else:\n        raise ValueError(f\"Unknown dataset: {data_name}\")\n    return dataset, description\n\n", "CodeBleu_score": 36.52775850822734}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    (x_train, y_train), (x_test, y_test) = fetch_covtype(\n        return_X_y=True, data_home=raw_data_cache\n    )\n    y_train = y_train - 1\n    y_test = y_test - 1\n    if dataset_params.get(\"binary\", False):\n        y_train = (y_train == 2).astype(int)\n        y_test = (y_test == 2).astype(int)\n    data = {\"train\": {\"x\": x_train, \"y\": y_train}, \"test\": {\"x\": x_test, \"y\": y_test}}\n    description = {\n        \"name\": data_name,\n        \"n_classes\": np.max(y_train) + 1,\n        \"length\": len(x_train),\n        \"x_shape\": np.shape(x_train),\n        \"y_shape\": np.shape(y_train),\n        \"x_train\": {\"shape\": np.shape(x_train), \"type\": x_train.dtype},\n        \"y_train\": {\"shape\": np.shape(y_train), \"type\": y_train.dtype},\n        \"x_test\": {\"shape\": np.shape(x_test), \"type\": x_test.dtype},\n        \"y_test\": {\"shape\": np.shape(y_test), \"type\": y_test.dtype},\n        \"default_split\": {\"train\": 0.8, \"test\": 0.2},\n    }\n    return data, description\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.89922717581535}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    (X, y) = fetch_covtype(return_X_y=True, data_home=raw_data_cache)\n    y = y - 1\n    if dataset_params.get(\"binary\", False):\n        y = (y == 2).astype(int)\n    dataset = {\"X\": X, \"y\": y}\n    dataset_description = {\n        \"n_classes\": len(np.unique(y)),\n        \"default_split_params\": {\n            \"train_size\": 0.8,\n            \"stratify\": y,\n        },\n    }\n    return dataset, dataset_description", "CodeBleu_score": 52.4248847528096}]}
{"instance_id": "129cbd2529ef", "generation_result": [{"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    # iteration with inner recursion\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 82.26912186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    # iteration with inner recursion\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 82.26912186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    # iteration with inner recursion\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 82.26912186632478}]}
{"instance_id": "2d38c2c60b59", "generation_result": [{"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(x >= 0, x, np.nan)\n        x = np.where(x <= 1, x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x))) * np.sign(x)\n    elif complex_mode == \"jax\":\n        return np.log(x / (1 - x))\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'split', 'magnitude', or 'jax'.\"\n        )\n\n", "CodeBleu_score": 47.62151866670631}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(x > 0, x, np.nan)\n        x = np.where(x < 1, x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    if complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x)))\n    if complex_mode == \"jax\":\n        return np.log(x / (np.ones_like(x) - x))\n    raise ValueError(\n        \"complex_mode must be one of 'split', 'magnitude', or 'jax'.\"\n    )\n\n", "CodeBleu_score": 50.45125776785825}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(x >= 0, x, np.nan)\n        x = np.where(x <= 1, x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x)))\n    elif complex_mode == \"jax\":\n        return np.log(x / (1 - x))\n    else:\n        raise ValueError(\n            f\"Unknown complex_mode {complex_mode}, choose from 'split', 'magnitude', 'jax'\"\n        )\n\n", "CodeBleu_score": 47.46106429021805}]}
{"instance_id": "205e296f8621", "generation_result": [{"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(x < -lambd, x, np.where(x > lambd, x, 0)).astype(x.dtype)\n\n", "CodeBleu_score": 38.022240999588696}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.copy(x)\n    else:\n        out = np.copy(out)\n    out = np.where(x < -lambd, x, 0)\n    out = np.where(x > lambd, out, 0)\n    return out.astype(x.dtype)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 52.71920453044295}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) > lambd, x, 0).astype(x.dtype)\n\n", "CodeBleu_score": 26.578348319387135}]}
{"instance_id": "5b133f6ebe2d", "generation_result": [{"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    result = []\n    for n in range(0, window_length):\n        temp = round(\n            sin(\n                (np.pi / 2)\n                * (\n                    sin((np.pi / window_length) * (n * 0.5)) ** 2\n                    + sin((np.pi / window_length) * (n * 0.5 + 0.5)) ** 2\n                )\n            )\n            ** 0.5,\n            8,\n        )\n        result.append(temp)\n    return np.array(result, dtype=dtype, out=out)", "CodeBleu_score": 32.4578673885568}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n\n    result = []\n    for n in range(0, window_length):\n        temp = round(\n            np.sin(\n                (np.pi / 2) * (np.sin(np.pi * (n * (1 / (window_length - 1)))) ** 2)),\n                8,\n            ),\n        )\n        result.append(temp)\n    return np.array(result, dtype=dtype, out=out)\n\n", "CodeBleu_score": 38.015661076111954}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    result = []\n    for n in range(0, window_length):\n        temp = round(\n            np.sin(\n                (np.pi / 2)\n                * (\n                    np.sin(np.pi / (window_length))\n                    * (n * 0.5 + 0.5)\n                )\n            ),\n            8,\n        )\n        result.append(temp)\n    return np.array(result, dtype=dtype, out=out)", "CodeBleu_score": 33.30921955029111}]}
{"instance_id": "473296f771a9", "generation_result": [{"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 94.57815771555306}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result\n\n", "CodeBleu_score": 94.57815771555306}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result\n\n", "CodeBleu_score": 94.57815771555306}]}
{"instance_id": "b8455221cb2a", "generation_result": [{"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret\n\n", "CodeBleu_score": 78.35765070891931}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret", "CodeBleu_score": 78.35765070891931}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret\n\n", "CodeBleu_score": 78.35765070891931}]}
{"instance_id": "f72489f434a3", "generation_result": [{"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.902523125962546}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)", "CodeBleu_score": 46.902523125962546}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not ivy.is_float_dtype(x1):\n        x1, x2 = promote_types_of_inputs(x1, x2)\n        x1 = x1.astype(ivy.default_float_dtype(as_native=True))\n    return np.copysign(x1, x2, out=out)", "CodeBleu_score": 70.06951148667954}]}
{"instance_id": "55c0d77e4dc2", "generation_result": [{"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)\n\n", "CodeBleu_score": 46.196732391005405}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    try:\n        a = a.astype(dtype)\n    except AttributeError:\n        if not isinstance(a, np.ndarray):\n            a = np.array(a, dtype=dtype)\n    return np.count_nonzero(a, axis=axis, keepdims=keepdims, out=out)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 58.52751552159934}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    try:\n        axis = tuple(axis) if isinstance(axis, list) else axis\n        return np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)\n    except ValueError:\n        if isinstance(axis, tuple) and len(axis) == 1:\n            axis = axis[0]\n        if isinstance(axis, int):\n            ret = np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)\n            if ret.shape == ():\n                ret = np.array(ret, dtype=dtype)\n            return ret\n        raise\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.871725376692304}]}
{"instance_id": "784bf7d24fc2", "generation_result": [{"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}]}
{"instance_id": "efa0a51af6bc", "generation_result": [{"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if not np.all(x):\n        return np.array(0.0, dtype=x.dtype)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 54.880187753456624}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if isinstance(x, Number):\n        x = np.asarray(x)\n    if isinstance(y, Number):\n        y = np.asarray(y)\n    x, y = promote_types_of_inputs(x, y)\n    if np.all(x == 0):\n        return np.asarray(0.0)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 58.1095195634413}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.any(x):\n        x, y = ivy.broadcast_arrays(x, y)\n        return np.multiply(x, np.log(y), out=out)\n    return ivy.zeros_like(x, dtype=promote_types_of_inputs(x, y))", "CodeBleu_score": 54.402033356809255}]}
{"instance_id": "ac1645284260", "generation_result": [{"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(\n        kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = np.transpose(x, (0, 4, 1, 2, 3))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 50.99351588085985}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(kernel, strides, dims, data_format)\n    if depth_pooling:\n        perm = [0, dims + 1] + list(range(1, dims + 1))\n        x = np.transpose(x, perm)\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 54.16701677113869}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(kernel, strides, dims, data_format)\n    if depth_pooling:\n        perm = [0, dims + 1, *range(1, dims + 1)]\n        x = np.transpose(x, perm)\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 57.641001887026654}]}
{"instance_id": "18ff0a4f7550", "generation_result": [{"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif not data_format == \"NWC\":\n            raise NotImplementedError(\n                \"Only 'NCW' and 'NWC' data formats are supported for training mode\"\n            )\n        mask = np.random.binomial(1, prob, size=x.shape)\n        res = x * mask / (1 - prob)\n        if data_format == \"NCW\":\n            res = np.transpose(res, (0, 2, 1))\n        return res\n    return x\n\n", "CodeBleu_score": 48.15474651828773}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if len(x.shape) == 3:\n            if data_format == \"NCW\":\n                x = np.transpose(x, (0, 2, 1))\n            total_size = x[0].size\n            shape = x[0].shape\n            mask = np.where(binomial(1, prob, total_size).reshape(shape) == 1, 1, 0)\n            return np.transpose(x * mask, (0, 2, 1)) if data_format == \"NCW\" else x * mask\n        else:\n            total_size = x.size\n            shape = x.shape\n            mask = np.where(binomial(1, prob, total_size).reshape(shape) == 1, 1, 0)\n            return x * mask\n    else:\n        return x\n\n", "CodeBleu_score": 40.09625974790174}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif not data_format == \"NWC\":\n            raise ivy.exceptions.IvyException(\n                \"only 'NWC' and 'NCW' supported for data_format\"\n            )\n        mask = np.random.binomial(1, prob, x.shape)\n        res = np.where(mask, x * (1.0 / (1 - prob)), np.zeros_like(x))\n        if data_format == \"NCW\":\n            res = np.transpose(res, (0, 2, 1))\n        return res\n    return x\n\n", "CodeBleu_score": 51.17197238371713}]}
{"instance_id": "0ce45eb7cbd9", "generation_result": [{"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n\n    if k < 1:\n        raise ValueError(\"k must be greater than zero.\")\n\n    if axis is None:\n        axis_size = x.size\n    else:\n        axis_size = x.shape[axis]\n\n    if k > axis_size:\n        raise ValueError(\"k must be less than or equal to the size of the specified axis.\")\n\n    if out is not None:\n        if not isinstance(out, tuple):\n            raise TypeError(\"out must be a tuple of two numpy arrays.\")\n        if len(out) != 2:\n            raise ValueError(\"out must be a tuple of two numpy arrays.\")\n        if not isinstance(out[0], np.ndarray):\n            raise TypeError(\"out must be a tuple of two numpy arrays.\")\n        if not isinstance(out[1], np.ndarray):\n            raise TypeError(\"out must be a tuple of two numpy arrays.\")\n        if out[0].shape != out[1].shape:\n            raise ValueError(\"out must be a tuple of two numpy arrays with the same shape.\")\n\n    if axis is None:\n        if largest:\n            indices = np.argpartition(x, -k, axis=None)[-k:]\n        else:\n            indices = np.argpartition(x, k - 1, axis=None)[:k]\n    else:\n        if largest:\n            indices = np.argpartition(x, -k, axis=axis)\n            indices = np.take(indices, -k, axis=axis)\n        else:\n            indices = np.argpartition(x, k - 1, axis=axis)\n            indices = np.take(indices, np.arange(k), axis=axis)\n\n    if sorted:\n        if largest:\n            values = np.take_along_axis(x, indices, axis=axis)\n            indices = np.take_along_axis(indices, indices.argsort(axis=axis), axis=axis)\n            values = np.take_along_axis(values, values.argsort(axis=axis), axis=axis)\n        else:\n            values = np.take_along_axis(x, indices, axis", "CodeBleu_score": 50.76296165454851}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return np.top_k(x, k, axis, largest, sorted, out)\n\n", "CodeBleu_score": 15.910160905600055}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    if k == 0:\n        return (np.array([]), np.array([]))\n    if k < 0:\n        raise ValueError(\"k must be a positive integer\")\n    if axis is None:\n        axis_size = x.size\n    else:\n        axis_size = x.shape[axis]\n    if k > axis_size:\n        raise ValueError(\"k must be less than or equal to the size of the specified axis\")\n    if out is None:\n        if sorted:\n            if largest:\n                indices = np.argsort(x, axis=axis)[-k:]\n            else:\n                indices = np.argsort(x, axis=axis)[:k]\n        else:\n            indices = np.arange(axis_size)\n            if largest:\n                indices = np.flip(indices)\n            indices = indices[:k]\n        values = np.take_along_axis(x, indices, axis)\n    else:\n        if sorted:\n            if largest:\n                indices = np.argsort(x, axis=axis)[-k:]\n            else:\n                indices = np.argsort(x, axis=axis)[:k]\n        else:\n            indices = np.arange(axis_size)\n            if largest:\n                indices = np.flip(indices)\n            indices = indices[:k]\n        values = np.take_along_axis(x, indices, axis)\n        np.copyto(out[0], values)\n        np.copyto(out[1], indices)\n    return values, indices\n\n", "CodeBleu_score": 44.64010600044709}]}
{"instance_id": "1424f9541998", "generation_result": [{"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.zeros_like(x)\n    if axis is None:\n        norm = np.sum(np.abs(x))\n        denorm = np.ones_like(x) * norm\n    else:\n        norm = np.sum(np.abs(x), axis=axis, keepdims=True)\n        denorm = np.divide(norm, np.abs(x) + np.finfo(x.dtype).eps)\n    return np.divide(x, denorm, out=out).astype(x.dtype)\n\n", "CodeBleu_score": 64.75953254592099}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.zeros_like(x)\n    return np.divide(x, np.reshape(np.sum(np.abs(x), axis=axis), x.shape), out=out)\n\n", "CodeBleu_score": 28.18006595089877}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.zeros_like(x)\n    denorm = np.abs(x).sum(axis=axis, keepdims=True)\n    denorm = np.divide(denorm, abs(x) + np.finfo(x.dtype).eps, out=out, where=denorm != 0)\n    return np.divide(x, denorm, out=out, where=denorm != 0)\n\n", "CodeBleu_score": 49.05432600321296}]}
{"instance_id": "4c3a386a1f05", "generation_result": [{"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}]}
{"instance_id": "271200a8b261", "generation_result": [{"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.array(x)\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 56.60266130052361}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.array(x) if not isinstance(x, np.ndarray) else x\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse", "CodeBleu_score": 56.83175639974808}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 53.67721297299843}]}
{"instance_id": "040d73b37229", "generation_result": [{"code": "def plot_medical_charts() -> None\n\t\n    # Set plotting style\n    sns.set(style=\"white\")\n\n    # Create figure with subplots\n    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axes[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axes[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(axes[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axes[1, 1], data)\n\n    # Adjust layout\n    fig.subplots_adjust(hspace=0.4)\n\n    # Export figure\n    export_figure(fig, \"medical_charts\")\n\n", "CodeBleu_score": 27.867769066426902}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    sns.set(style=\"darkgrid\")\n\n    # Create figure with subplots\n    fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axs[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axs[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(axs[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axs[1, 1], data)\n\n    # Adjust layout\n    fig.subplots_adjust(hspace=0.3)\n\n    # Export figure\n    export_figure(fig, \"medical_charts\")\n\n", "CodeBleu_score": 28.484141120975497}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    sns.set(style=\"whitegrid\")\n\n    # Create figure and subplots\n    fig, axs = plt.subplots(2, 2, figsize=(12, 10))\n\n    # Plot\n    plot_monthly_vomit(axs[0, 0], data)\n    plot_days_between_vomit(axs[0, 1], data)\n    plot_daycare_days(axs[1, 0], data)\n    plot_doctor_visit_monthly(axs[1, 1], data)\n\n    # Adjust layout\n    fig.subplots_adjust(hspace=0.4)\n\n    # Export\n    export_figure(fig, \"medical_charts\")\n\n", "CodeBleu_score": 28.032735133855823}]}
{"instance_id": "7061f4d0c3fc", "generation_result": [{"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    data = parse_raw_data(\n        pd.read_csv(\"data/feedings.csv\"), [\"Start Timestamp\", \"End Timestamp\"]\n    )\n\n    # Set up plot with dark grid style\n    sns.set_style(\"darkgrid\")\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = (\n        data.loc[data[\"Type\"] == \"Solid\", \"day_number\"].iloc[-1]\n        - data.loc[data[\"Type\"] == \"Solid\", \"day_number\"].iloc[0]\n    )\n\n    # Create scatter plot of feeding times, using red for bottle feedings and blue for solid feedings\n    fig_ax = plt.subplots(figsize=(10, 6))\n    fig_ax.scatter(\n        data.loc[data[\"Type\"] == \"Solid\", \"timestamp_hour\"] - offset,\n        data.loc[data[\"Type\"] == \"Solid\", \"day_number\"],\n        color=\"blue\",\n        label=\"Solid\",\n    )\n    fig_ax.scatter(\n        data.loc[data[\"Type\"] == \"Bottle\", \"timestamp_hour\"] - offset,\n        data.loc[data[\"Type\"] == \"Bottle\", \"day_number\"],\n        color=\"red\",\n        label=\"Bottle\",\n    )\n\n    # Add legend to distinguish between the two\n    plt.legend()\n\n    # Calculate end date for the plot\n    end_date = get_end_date(data.loc[data[\"Type\"] == \"Solid\", \"day_number\"], first_year_only=True)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    format_24h_week_plot_horizontal(fig_ax, end_date, offset)\n\n    # Export figure\n    export_figure(fig_ax, \"feeding_24h_viz\")\n\n", "CodeBleu_score": 27.676448724006637}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    bottle_data, solid_data = parse_raw_data(\n        data=get_raw_data(filename=\"feeding_data\"), key=[\"Bottle\", \"Solid\"]\n    )\n\n    # Set up plot with dark grid style\n    sns.set_style(\"darkgrid\")\n    fig_ax = plt.subplots(figsize=(10, 5))\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = (\n        solid_data.iloc[0][\"Date\"] - pd.to_datetime(\"2022-01-01\")\n    ).days / 365\n\n    # Create scatter plot of feeding times\n    fig_ax.scatter(\n        bottle_data[\"timestamp_hour\"],\n        bottle_data[\"day_number\"],\n        color=\"red\",\n        label=\"Bottle\",\n        marker=\".\",\n        s=100,\n    )\n    fig_ax.scatter(\n        solid_data[\"timestamp_hour\"],\n        solid_data[\"day_number\"] + offset,\n        color=\"blue\",\n        label=\"Solid\",\n        marker=\".\",\n        s=100,\n    )\n\n    # Add legend to distinguish between the two\n    plt.legend(\n        loc=\"upper center\",\n        bbox_to_anchor=(0.5, 1.1),\n        ncol=2,\n        fancybox=True,\n        shadow=True,\n        fontsize=15,\n    )\n\n    # Calculate end date for plot\n    end_date = get_end_date(data=solid_data, first_year_only=False)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    format_24h_week_plot_horizontal(\n        fig_ax=fig_ax,\n        end_date=end_date,\n        offset=offset,\n        first_year_only=False,\n    )\n\n    # Export figure\n    export_figure(fig_ax=fig_ax, filename=", "CodeBleu_score": 30.166674634198188}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n\n    # Import and extract feeding data\n    data = parse_raw_data(\n        pd.read_csv(\n            \"data/raw_data/feeding_data_2022.csv\",\n            parse_dates=[\"Date\"],\n            date_parser=lambda x: pd.to_datetime(x, format=\"%Y-%m-%d\"),\n        ),\n        key=[\"Date\"],\n    )\n\n    # Set up plot with dark grid style\n    sns.set_style(\"darkgrid\")\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = (\n        data[data[\"Solid or bottle\"] == \"Solid\"]\n        .iloc[-1][\"Date\"]\n        .to_pydatetime()\n        .date()\n        - datetime.date(2021, 11, 10)\n    ).days\n\n    # Create figure and axis objects\n    fig, ax = plt.subplots(figsize=(10, 5))\n\n    # Create scatter plot of feeding times\n    ax.scatter(\n        data[data[\"Solid or bottle\"] == \"Bottle\"][\"timestamp_hour\"],\n        data[data[\"Solid or bottle\"] == \"Bottle\"][\"day_number\"] - offset,\n        c=\"red\",\n        label=\"Bottle\",\n    )\n    ax.scatter(\n        data[data[\"Solid or bottle\"] == \"Solid\"][\"timestamp_hour\"],\n        data[data[\"Solid or bottle\"] == \"Solid\"][\"day_number\"] - offset,\n        c=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend to distinguish between the two\n    ax.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date(data[data[\"Solid or bottle\"] == \"Solid\"], first_year_only=True)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    format_24h_week_plot_horizontal(fig, ax, end_date)\n\n    # Export figure\n    export_figure", "CodeBleu_score": 29.14205732903804}]}
{"instance_id": "6c1ffa63d122", "generation_result": [{"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'Target Counts - {task.name}')\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.22675192528337}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'{task.name} counts')\n    ax.set_ylabel('Count')\n    ax.set_xlabel('Target')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.73848168610428}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'{task.name} target counts')\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.350494964120976}]}
{"instance_id": "2f81a906bad5", "generation_result": [{"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb(f) for f in figure], axis=0)\n    else:\n        figure.canvas.draw()\n        w, h = figure.canvas.get_width_height()\n        buf = np.frombuffer(figure.canvas.buffer_rgba(), dtype=np.uint8)\n        buf.shape = (w, h, 4)\n        return np.moveaxis(buf, 2, 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.211920178306396}, {"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb(f) for f in figure])\n    figure.canvas.draw()\n    data = np.frombuffer(figure.canvas.buffer_rgba(), dtype=np.uint8)\n    w, h = figure.canvas.get_width_height()\n    image_hwc = data.reshape([h, w, 4])[:, :, :3]\n    plt.close(figure)\n    return np.moveaxis(image_hwc, source=2, destination=0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.010952485076054}, {"code": "def render_to_rgb(figure)\n\t\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb(f) for f in figure], axis=0)\n\n    figure.canvas.draw()\n    width, height = figure.canvas.get_width_height()\n    buffer = figure.canvas.buffer_rgba()\n    image = np.frombuffer(buffer, dtype=np.uint8).reshape(height, width, 4)\n    image = image[:, :, :3]\n    plt.close(figure)\n    return np.moveaxis(image, 2, 0)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.83053178378686}]}
{"instance_id": "c3037b01569c", "generation_result": [{"code": "def beholder_pytorch()\n\t\n    import beholder_lib\n    import torch\n    import time\n\n    beholder = beholder_lib.Beholder(\"logs\")\n\n    for i in range(1000):\n        tensors_and_names = [\n            beholder_lib.tensor_and_name(\n                torch.randn(1, 3, 128, 128),\n                \"random_tensor_\" + str(i),\n            )\n            for i in range(2)\n        ]\n        frame = int(torch.randint(0, 1000, (1,)).item())\n        beholder.update(tensors_and_names, frame)\n        time.sleep(0.1)\n        print(i)\n\n", "CodeBleu_score": 33.20137857557415}, {"code": "def beholder_pytorch()\n\t\n    beholder = beholder_lib.Beholder(\"logs/beholder_pytorch\")\n    for i in range(1000):\n        tensors = [\n            tensor_and_name(randn(3, 256, 256), \"image\"),\n            tensor_and_name(randn(1, 3, 256, 256), \"mask\"),\n        ]\n        beholder.update(tensors, frame=str(i))\n        time.sleep(0.01)\n        print(i)\n\n", "CodeBleu_score": 24.334510663428173}, {"code": "def beholder_pytorch()\n\t\n    logdir = \"./logs/pytorch\"\n    beholder = beholder_lib.Beholder(logdir)\n    for i in range(1000):\n        tensors_and_names = [\n            tensor_and_name(randn(100, 100), \"random_tensor_\" + str(i))\n            for i in range(2)\n        ]\n        frame = randn(100, 100)\n        beholder.update(tensors_and_names, frame)\n        time.sleep(0.1)\n        print(i)\n\n", "CodeBleu_score": 35.05303351263058}]}
{"instance_id": "cd57b5de8a88", "generation_result": [{"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    tensor_data = np.fromiter(tensor_data, np.float32)\n    tensor_data = np.vsplit(tensor_data, num_thresholds)\n    thresholds = [i / num_thresholds for i in range(num_thresholds)]\n    tp, fp, tn, fn, precision, recall = [\n        np.reshape(tensor, (num_thresholds, -1)).tolist() for tensor in tensor_data\n    ]\n    pr_data = {\n        \"true_positive\": tp,\n        \"false_positive\": fp,\n        \"true_negative\": tn,\n        \"false_negative\": fn,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"thresholds\": thresholds,\n    }\n    self.log_asset_data(pr_data, tag, step=step)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.28701450153495}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    tensor_data = np.array(tensor_data).reshape(len(tensor_data) // num_thresholds, num_thresholds)\n    thresholds = [i / num_thresholds for i in range(num_thresholds)]\n    TP, FP, TN, FN, precision, recall = np.vsplit(tensor_data, 6)\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"TP\": TP.flatten().tolist(),\n        \"FP\": FP.flatten().tolist(),\n        \"TN\": TN.flatten().tolist(),\n        \"FN\": FN.flatten().tolist(),\n        \"precision\": precision.flatten().tolist(),\n        \"recall\": recall.flatten().tolist(),\n    }\n    self.log_asset_data(pr_data, tag, step)\n\n", "CodeBleu_score": 33.39445789511324}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    tensor_data = np.fromiter(tensor_data, np.float32)\n    tensor_data = tensor_data.reshape(\n        -1, num_thresholds, 5)\n    thresholds = [i / num_thresholds for i in range(num_thresholds)]\n    TP, FP, TN, FN, precision, recall = np.vsplit(tensor_data, 6)\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"TP\": TP.flatten().tolist(),\n        \"FP\": FP.flatten().tolist(),\n        \"TN\": TN.flatten().tolist(),\n        \"FN\": FN.flatten().tolist(),\n        \"precision\": precision.flatten().tolist(),\n        \"recall\": recall.flatten().tolist(),\n    }\n    self.log_asset_data(pr_data, tag, step)\n\n", "CodeBleu_score": 33.98693464564337}]}
{"instance_id": "7c4ea9beecc9", "generation_result": [{"code": "def load_mnist(images, labels, num)\n\t\n    f_images = gzip.open(images, 'rb')\n    f_labels = gzip.open(labels, 'rb')\n\n    # Skip the header bytes\n    f_images.read(16)\n    f_labels.read(8)\n\n    # Read the data\n    data = []\n    target = []\n    for i in range(num):\n        # Read the image data\n        image = np.frombuffer(f_images.read(784), dtype=np.uint8).reshape(28, 28)\n        data.append(image)\n\n        # Read the label data\n        label = ord(f_labels.read(1))\n        target.append(label)\n\n    # Convert the data and target to NumPy arrays\n    data = np.array(data)\n    target = np.array(target)\n\n    return data, target\n", "CodeBleu_score": 38.183760988210615}, {"code": "def load_mnist(images, labels, num)\n\t\n    with gzip.open(labels, 'rb') as f_labels:\n        f_labels.read(8)\n        buf = f_labels.read(1 * num)\n        labels = np.frombuffer(buf, dtype=np.uint8).astype(np.int64)\n\n    with gzip.open(images, 'rb') as f_images:\n        f_images.read(16)\n        buf = f_images.read(28 * 28 * num)\n        data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n        data = data.reshape(num, 784)\n\n    return data, labels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.7085513107898}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = np.zeros((num, 784), dtype=np.uint8)\n    target = np.zeros((num,), dtype=np.uint8)\n\n    with gzip.open(images, 'r') as f_images:\n        f_images.read(16)\n        for i in range(num):\n            for j in range(784):\n                data[i, j] = ord(f_images.read(1))\n\n    with gzip.open(labels, 'r') as f_labels:\n        f_labels.read(8)\n        for i in range(num):\n            target[i] = ord(f_labels.read(1))\n\n    return data, target\n\n", "CodeBleu_score": 49.48498583516335}]}
{"instance_id": "bf4f1c828b25", "generation_result": [{"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.cardinality = {}\n    self.min_max = {}\n    self.unique_values = {}\n    self.data_type = {}\n    self.data_type[\"quantitative\"] = list(\n        ldf.data.select_dtypes(include=[is_integer_dtype, is_float_dtype])\n    )\n    self.data_type[\"temporal\"] = list(ldf.data.select_dtypes(include=[\"datetime\"]))\n    self.length = len(ldf)\n    for attribute in ldf.columns:\n        uniq = list(ldf.data[attribute].unique())\n        self.unique_values[attribute] = uniq\n        self.cardinality[attribute] = len(uniq)\n        if ldf.data[attribute].dtype.name != \"category\":\n            if isinstance(uniq[0], datetime):\n                uniq = [str(val) for val in uniq]\n            sorted_uniq = sorted(uniq)\n            self.min_max[attribute] = (sorted_uniq[0], sorted_uniq[-1])\n        if not ldf.data.index.is_integer():\n            self.unique_values[\"index\"] = list(ldf.data.index.unique())\n            self.cardinality[\"index\"] = len(ldf.data.index.unique())\n\n\n\n\n", "CodeBleu_score": 36.75537390650877}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max = {}\n    self.cardinality = {}\n    self.len = len(ldf)\n    for attr in ldf.columns:\n        self.unique_values[attr] = list(ldf[attr].unique())\n        self.cardinality[attr] = len(ldf[attr].unique())\n        if pd.api.types.is_numeric_dtype(ldf.data_type[attr]):\n            self.min_max[attr] = (ldf[attr].min(), ldf[attr].max())\n    if not pd.api.types.is_integer_dtype(ldf.data_type[ldf.index.name or \"index\"]):\n        self.unique_values[ldf.index.name or \"index\"] = list(\n            ldf[ldf.index.name or \"index\"].astype(str).unique()\n        )\n        self.cardinality[ldf.index.name or \"index\"] = len(\n            ldf[ldf.index.name or \"index\"].astype(str).unique()\n        )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.345869698414404}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.cardinality = {}\n    self.min_max = {}\n    self.unique_values = {}\n    self.len = len(ldf)\n    if not ldf.index.is_integer():\n        self.unique_values[\"Lux Index\"] = list(ldf.index.values)\n        self.cardinality[\"Lux Index\"] = len(ldf.index.unique())\n    for attribute in ldf.columns:\n        col = ldf[attribute]\n        self.unique_values[attribute] = list(col.unique())\n        self.cardinality[attribute] = len(ldf.unique_values[attribute])\n        if isinstance(col, pd.DatetimeTZDtype) or is_datetime_series(col):\n            self.min_max[attribute] = (\n                str(col.min()),\n                str(col.max()),\n            )\n        elif is_integer_dtype(col):\n            self.min_max[attribute] = (col.min(), col.max())\n        elif is_float_dtype(col):\n            self.min_max[attribute] = (col.min(), col.max())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.046679911104626}]}
{"instance_id": "3e6fc3d2f47c", "generation_result": [{"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = tbl.preview_query.format(tbl.table_name, preview_size)\n    df = pd.read_sql(preview_query, tbl.sql_conn)\n    return df\n\n", "CodeBleu_score": 22.634623154268304}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = tbl.preview_query.format(tbl.name, preview_size)\n    df = pd.read_sql(preview_query, lux_conn)\n    return df", "CodeBleu_score": 21.485835151694772}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = tbl.preview_query.format(tbl.name, preview_size)\n    df = pd.read_sql(preview_query, sql_connection)\n    return df\n\n", "CodeBleu_score": 22.29289945867983}]}
{"instance_id": "b3dee87be4b8", "generation_result": [{"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if tbl.sampled is not None:\n        return\n    if lux.config.sampling.flag:\n        if lux.config.sampling.start:\n            start = lux.config.sampling.start\n        else:\n            start = random.randint(0, tbl.length - 1)\n        if lux.config.sampling.cap:\n            cap = min(tbl.length, start + lux.config.sampling.cap)\n        else:\n            cap = tbl.length\n        if start > cap:\n            start, cap = cap, start\n        if lux.config.sampling.frac:\n            limit = int((cap - start) * lux.config.sampling.frac)\n        else:\n            limit = tbl.length\n        if limit == 0:\n            limit = 1\n        query = tbl.query.format(limit=limit, offset=start)\n        tbl._sampled = pandas.read_sql(query, lux.config.SQLConnection)\n    else:\n        tbl._sampled = pandas.read_sql(tbl.query, lux.config.SQLConnection)\n\n", "CodeBleu_score": 33.03830653945279}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if lux.config.sampling.SAMPLE_FLAG:\n        if tbl.table_len is None:\n            tbl.table_len = len(tbl.df)\n        if tbl.table_len > lux.config.sampling.SAMPLE_CAP:\n            tbl.table_len = lux.config.sampling.SAMPLE_CAP\n        limit = int(tbl.table_len * lux.config.sampling.SAMPLE_FRAC)\n        if limit < lux.config.sampling.SAMPLE_START:\n            limit = lux.config.sampling.SAMPLE_START\n        tbl._sampled = execute_sql(\n            f\"SELECT * FROM {tbl.table_name} LIMIT {limit}\", tbl.table_name\n        )\n\n", "CodeBleu_score": 25.944447337173205}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if tbl.sampled:\n        return\n    sample_flag = lux.config.sampling.sample_flag\n    sample_start = lux.config.sampling.sample_start\n    sample_cap = lux.config.sampling.sample_cap\n    sample_frac = lux.config.sampling.sample_frac\n    if sample_flag:\n        tbl.length = len(tbl.unique_values)\n        limit = sample_cap if sample_cap else int(tbl.length * sample_frac)\n        if limit <= sample_cap:\n            sample_query = f\"SELECT * FROM {tbl.table_name} LIMIT {limit}\"\n            tbl._sampled = pd.read_sql_query(sample_query, lux.config.SQLconnection)\n        else:\n            sample_query = f\"SELECT * FROM {tbl.table_name} LIMIT {sample_cap}\"\n            tbl._sampled = pd.read_sql_query(sample_query, lux.config.SQLconnection)\n\n", "CodeBleu_score": 29.603256659778804}]}
{"instance_id": "485253b1088a", "generation_result": [{"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    # Override default text settings with provided parameters\n    params = override_params(DEFAULT_TEXT_PARAMS, params)\n\n    # Extract text, x, and y values from parameters\n    text = params.pop(\"text\")\n    x = params.pop(\"x\")\n    y = params.pop(\"y\")\n\n    # Get background bounds\n    xmin, xmax, ymin, ymax = background.get_bounds()\n\n    # Interpolate x and y values to fit within background bounds\n    x = np.interp(x, [0, 1], [xmin, xmax])\n    y = np.interp(y, [0, 1], [ymin, ymax])\n\n    # Draw text at calculated position with remaining parameters\n    plt.text(x, y, text, **params)\n\n", "CodeBleu_score": 18.221124653047422}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    params = override_params(\n        default_dict=DEFAULT_TEXT_PARAMS,\n        new_dict=params\n    )\n\n    text = params.pop('text')\n    x = params.pop('x')\n    y = params.pop('y')\n\n    x_bounds = background.bounds[0]\n    y_bounds = background.bounds[1]\n\n    x = np.interp(x, [0, 1], [x_bounds[0], x_bounds[1]])\n    y = np.interp(y, [0, 1], [y_bounds[0], y_bounds[1]])\n\n    plt.text(x, y, text, **params)\n\n", "CodeBleu_score": 18.820108196352024}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    # Override default text settings with provided parameters\n    text_params = override_params(default_params[\"text\"], params)\n\n    # Extract text, x, and y values\n    text = text_params.pop(\"text\")\n    x = text_params.pop(\"x\")\n    y = text_params.pop(\"y\")\n\n    # Get background bounds\n    x_min, y_min, x_max, y_max = background.bounds\n\n    # Interpolate x and y values to fit within background bounds\n    x = np.interp(x, [0, 1], [x_min, x_max])\n    y = np.interp(y, [0, 1], [y_min, y_max])\n\n    # Draw text at calculated position with remaining parameters\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 18.343698667630363}]}
{"instance_id": "5f70a88b6b72", "generation_result": [{"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format:\n        return datetime_format\n    deltas = [ dates[i+1] - dates[i] for i in range( len( dates ) - 1 ) ]\n    avg = sum( deltas, timedelta( 0 ) ) / len( deltas )\n    if avg < timedelta( days=0.33 ):\n        if dates[-1].day != dates[0].day:\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        if dates[-1].year != dates[0].year:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n", "CodeBleu_score": 34.38883609153695}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    deltas = np.diff(mdates.date2num(dates))\n    if len(deltas) == 0:\n        return '%Y-%b-%d'\n    average_delta = np.average(deltas)\n    if average_delta < 0.33:\n        if dates[-1] > dates[0] + datetime.timedelta(days=1):\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    if dates[-1] > dates[0] + datetime.timedelta(days=1):\n        return '%Y-%b-%d'\n    else:\n        return '%b %d'\n\n\n\n", "CodeBleu_score": 39.89527322888149}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n\n    # get the average number of days between consecutive dates\n    deltas = np.diff(mdates.date2num(dates))\n    average_delta = np.mean(deltas)\n\n    # if the data is intraday\n    if average_delta < 0.33:\n        # if the data spans multiple days\n        if dates[-1] - dates[0] > datetime.timedelta(days=1):\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n\n    # if the data is daily or less frequent\n    else:\n        # if the data spans multiple years\n        if dates[-1] - dates[0] > datetime.timedelta(days=365):\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.08713275003286}]}
{"instance_id": "f9589bf4666d", "generation_result": [{"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if not _is_uint8_rgb_or_rgba(c):\n        c = mcolors.to_rgba(c, alpha)\n    if _is_uint8_rgb_or_rgba(c):\n        if c[0] > 1 or c[1] > 1 or c[2] > 1:\n            c = tuple(np.array(c) / 255.0)\n        if len(c) == 3:\n            c = c + (1.0,)\n        if alpha is not None:\n            c = c[0:3] + (alpha,)\n    return c\n\n", "CodeBleu_score": 31.3059952576599}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        c = tuple(c / 255.0)\n    if alpha is None:\n        return mcolors.to_rgba(c)\n    else:\n        return mcolors.to_rgba(c, alpha)\n\n", "CodeBleu_score": 23.875852073599535}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 3:\n            c = tuple(np.array(c) / 255.0)\n        elif len(c) == 4:\n            c = tuple(np.array(c[0:3]) / 255.0) + (c[3],)\n        c = mcolors.to_rgba(c)\n    else:\n        c = mcolors.to_rgba(c, alpha)\n    return c\n\n", "CodeBleu_score": 34.539244109420856}]}
{"instance_id": "4202e378ab0b", "generation_result": [{"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist", "CodeBleu_score": 91.4910089123845}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 91.4910089123845}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n", "CodeBleu_score": 91.4910089123845}]}
{"instance_id": "3e2b6dfe4753", "generation_result": [{"code": "def _adjust_figsize(fig,config)\n\t\n    if not fig:\n        return\n    if not \"figsize\" in config:\n        ratio = config[\"figratio\"]\n        figsize = (config[\"figwidth\"] / config[\"figwidth_inch\"],\n                   config[\"figheight\"] / config[\"figheight_inch\"])\n        if figsize[0] / figsize[1] > ratio[0] / ratio[1]:\n            figsize = (figsize[0], figsize[0] * ratio[1] / ratio[0])\n        else:\n            figsize = (figsize[1] * ratio[0] / ratio[1], figsize[1])\n        fig.set_size_inches(figsize)\n    else:\n        fig.set_size_inches(config[\"figsize\"])\n\n\n\n", "CodeBleu_score": 34.04074893506068}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if 'figsize' not in config:\n        figratio = config['figratio']\n        figsize = fig.get_size_inches()\n        figsize = (figsize[0],figsize[0]*figratio)\n        if figsize[0] < 3 or figsize[1] < 3:\n            figsize = (6,6*figratio)\n        fig.set_size_inches(*figsize)\n    else:\n        fig.set_size_inches(*config['figsize'])\n\n\n\n", "CodeBleu_score": 31.032074748939937}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if 'figsize' not in config:\n        ratio = config['figratio']\n        figsize = _figsize_from_ratio(ratio)\n        fig.set_size_inches(figsize)\n        return\n    figsize = config['figsize']\n    fig.set_size_inches(figsize)\n\n", "CodeBleu_score": 24.12097416403708}]}
{"instance_id": "986e5804b941", "generation_result": [{"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.8871118525845847}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.8871118525845847}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.8871118525845847}]}
{"instance_id": "5308e20f3c90", "generation_result": [{"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    # Get the kernel height and width from the input tensor's shape\n    kernel_h, kernel_w = opnode.inputs[0].shape[2:]\n    # Get the number of input channels from the input tensor's shape\n    in_channels = opnode.inputs[0].shape[1]\n    # Calculate the total number of output elements\n    total_output_elements = np.prod(outputs[0].shape)\n    # Check if the operation includes a bias term\n    if len(opnode.inputs) == 3:\n        # If so, compute the FLOPs by multiplying the total number of output elements by the number of input channels and the kernel size,\n        # and adding the bias\n        return total_output_elements * (in_channels * kernel_h * kernel_w + 1)\n    else:\n        # Otherwise, compute the FLOPs by multiplying the total number of output elements by the number of input channels and the kernel size\n        return total_output_elements * in_channels * kernel_h * kernel_w\n\n", "CodeBleu_score": 24.877155883962853}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#L105\n    # https://github.com/microsoft/onnxconverter-common/blob/master/onnxconverter_common/onnx_ops.py#", "CodeBleu_score": 3.553921568627451}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    if len(inputs[0].shape) == 4:\n        n, c, h, w = inputs[0].shape\n    else:\n        n, c, h, w = 1, inputs[0].shape[0], inputs[0].shape[1], inputs[0].shape[2]\n    if len(outputs[0].shape) == 4:\n        n, c, h, w = outputs[0].shape\n    else:\n        n, c, h, w = 1, outputs[0].shape[0], outputs[0].shape[1], outputs[0].shape[2]\n    groups = opnode.groups\n    in_channels = inputs[0].shape[1]\n    out_channels, kernel_h, kernel_w = opnode.kernel_shape\n    out_h, out_w = outputs[0].shape[2], outputs[0].shape[3]\n    kernel_ops = kernel_h * kernel_w * (in_channels / groups)\n    bias_ops = 1 if opnode.bias is not None else 0\n    params = out_channels * kernel_ops + bias_ops\n    flops = n * out_h * out_w * params\n    return flops\n\n", "CodeBleu_score": 31.3706824495951}]}
{"instance_id": "70811d3cf578", "generation_result": [{"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    ir_type_factory = _dtype_to_ir_type[mge_dtype]\n    return ir_type_factory()\n\n", "CodeBleu_score": 30.077334114358223}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype]()\n\n", "CodeBleu_score": 20.149569944707952}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)\n\n\n\n", "CodeBleu_score": 21.40981359960167}]}
{"instance_id": "a108c9ba2c22", "generation_result": [{"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(dtype=x.dtype.canonicalize_dtype())\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = np.packbits(x, axis=None, bitorder=\"little\")\n    if x.dtype == np.bfloat16:\n        x = x.view(np.int16)\n    x = np.ascontiguousarray(x)\n    dense_elements_attr = hlo.DenseElementsAttr.get(x, type=ir_type)\n    return hlo.ConstantOp(dense_elements_attr).results\n\n", "CodeBleu_score": 49.60903930674159}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype))\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.uint8)\n    elif x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    dense_attr = hlo.DenseElementsAttr.get(x, type=ir_type)\n    return hlo.ConstantOp(dense_attr).results\n\n", "CodeBleu_score": 42.353076817349624}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.copy()\n        x.dtype = x.dtype.canonicalize_dtype()\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if ir_type.is_bool():\n        x = x.astype(np.uint8)\n    elif ir_type.is_bfloat16():\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    dense_elements_attr = ir.DenseElementsAttr.get(x.shape, ir_type, x)\n    return hlo.ConstantOp(dense_elements_attr).results\n\n", "CodeBleu_score": 40.5680610385727}]}
{"instance_id": "3345fe4d008b", "generation_result": [{"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.size == 0:\n        return _numpy_array_constant(val, canonicalize_types)\n    zero_stride_axes = tuple(i for i, s in enumerate(val.strides) if s == 0)\n    non_zero_stride_axes = tuple(i for i, s in enumerate(val.strides) if s != 0)\n    if len(zero_stride_axes) != 0:\n        val = np.broadcast_to(val, (1,) * len(val.shape))\n        if canonicalize_types:\n            val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n        return (\n            hlo.BroadcastInDimOp(\n                _numpy_array_constant(val, canonicalize_types)[0],\n                shape=val.shape,\n                broadcast_dimensions=non_zero_stride_axes,\n            ).result,\n        )\n    return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 36.526444767632974}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.size == 0:\n        return (hlo.ConstantOp(ir.DenseElementsAttr.get(val, type=mge_dtype_to_ir_type(val.dtype))).result,)\n    if val.ndim == 0:\n        return (hlo.ConstantOp(ir.DenseElementsAttr.get(val, type=mge_dtype_to_ir_type(val.dtype))).result,)\n    zero_stride_axes = tuple(i for i, s in enumerate(val.strides) if s == 0)\n    non_zero_stride_axes = tuple(i for i, s in enumerate(val.strides) if s != 0)\n    if len(zero_stride_axes) == 0:\n        return _numpy_array_constant(val, canonicalize_types)\n    if len(non_zero_stride_axes) == 0:\n        return (hlo.ConstantOp(ir.DenseElementsAttr.get(val, type=mge_dtype_to_ir_type(val.dtype))).result,)\n    val = np.broadcast_to(val, val.shape)\n    if canonicalize_types:\n        val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n    val = val.reshape(val.shape[0], *val.shape[1:])\n    return (hlo.BroadcastInDimOp(val, shape=val.shape, broadcast_dimensions=non_zero_stride_axes).result,)\n\n", "CodeBleu_score": 38.53577361279837}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if np.any(val.strides == 0) and val.size != 0:\n        # Collapse zero-stride axes.\n        zero_stride_axes = tuple(i for i, stride in enumerate(val.strides) if stride == 0)\n        non_zero_stride_axes = tuple(\n            i for i, stride in enumerate(val.strides) if stride != 0\n        )\n        collapsed_val = np.squeeze(val, zero_stride_axes)\n        if canonicalize_types:\n            collapsed_val = np.asarray(\n                collapsed_val, dtype.canonicalize_dtype(collapsed_val.dtype)\n            )\n        # Broadcast collapsed_val to the original shape.\n        broadcast_op = hlo.BroadcastInDimOp(\n            _numpy_array_constant(collapsed_val, canonicalize_types)[0],\n            shape=val.shape, broadcast_dimensions=non_zero_stride_axes,\n        )\n        return (broadcast_op.result,)\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 44.60201066956163}]}
{"instance_id": "91b298678351", "generation_result": [{"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    bits = np.packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        if xs[0]:\n            bits = np.full(1, -128, dtype=np.int8)\n        else:\n            bits = np.full(1, 0, dtype=np.int8)\n    return ir.DenseElementsAttr.get(\n        np.array(bits, dtype=np.int8),\n        type=ir.IntegerType.get_signless(1),\n        shape=ir.ArrayAttr.get([len(xs)], context=ir.ArrayAttr),\n    )\n", "CodeBleu_score": 45.49335479301014}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed = np.packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        packed = np.array([packed[0]], dtype=np.uint8)\n    return ir.DenseElementsAttr.get(\n        np.array(packed, dtype=np.uint8), type=ir.IntegerType.get_signless(1)\n    ).reshape((len(xs),))\n\n", "CodeBleu_score": 48.49924982396473}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    bits = packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        bits = np.full_like(bits, xs[0])\n    return ir.DenseElementsAttr.get(\n        np.array(bits, dtype=np.uint8),\n        type=ir.IntegerType.get_signless(1),\n        shape=(len(xs),),\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.173379128444104}]}
{"instance_id": "06ebabf1e0ff", "generation_result": [{"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n\n    var_in = ctx.vars_in[0]\n    var_out = ctx.vars_out[0]\n\n    if var_in.bound_data is not None:\n        var_in.set_value(var_in.bound_data)\n        var_out.set_value(var_in.bound_data)\n\n    assert var_in.shape == var_out.shape\n\n    if var_in.bound_data is not None:\n        data = np.asarray(var_in.bound_data, dtype=var_out.dtype)\n    elif var_out.bound_data is not None:\n        data = np.asarray(var_out.bound_data, dtype=var_out.dtype)\n    else:\n        assert False, \"Only tensor creation from constants is supported\"\n\n    return HLOTensor(data)\n\n", "CodeBleu_score": 67.68258383623431}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n\n    if input_var.bound_data is not None:\n        ctx.module.set_value(input_var.name, input_var.bound_data)\n        ctx.module.set_value(output_var.name, input_var.bound_data)\n\n    assert input_var.shape == output_var.shape\n\n    if input_var.bound_data is not None:\n        output_var.bound_data = np.asarray(\n            input_var.bound_data, dtype=output_var.dtype\n        )\n    elif output_var.bound_data is not None:\n        input_var.bound_data = np.asarray(\n            output_var.bound_data, dtype=input_var.dtype\n        )\n    else:\n        raise AssertionError(\n            \"Only tensor creation from constants is supported.\"\n        )\n\n    return HLOTensor(output_var.bound_data)\n\n", "CodeBleu_score": 50.72200810712426}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n\n    var_in = ctx.vars_in[0]\n    var_out = ctx.vars_out[0]\n\n    if var_in.bound_data is not None:\n        var_in.set_value(var_in.bound_data)\n        var_out.set_value(var_in.bound_data)\n\n    assert var_in.shape == var_out.shape\n\n    if var_in.bound_data is not None:\n        data = np.asarray(var_in.bound_data, dtype=var_out.dtype)\n    elif var_out.bound_data is not None:\n        data = np.asarray(var_out.bound_data, dtype=var_out.dtype)\n    else:\n        assert False, \"only tensor creation from constants is supported\"\n\n    return HLOTensor(data)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 68.258281132367}]}
{"instance_id": "6cd750fa0c8d", "generation_result": [{"code": "def _device_put_scalar(x, device)\n\t\n    return _device_put(np.asarray(x, dtype=_scalar_type_to_dtype(x)), device)\n\n\n\n\n", "CodeBleu_score": 16.52444883139786}, {"code": "def _device_put_scalar(x, device)\n\t\n    if not isinstance(x, np.ndarray):\n        x = np.asarray(x)\n    return _device_put(x, device)\n\n\n\n\n", "CodeBleu_score": 20.22391014567732}, {"code": "def _device_put_scalar(x, device)\n\t\n    if isinstance(x, Number):\n        x = np.asarray(x)\n    if not isinstance(x, np.ndarray):\n        raise TypeError(f\"x must be a scalar or numpy array, got {type(x)}\")\n    if x.ndim != 0:\n        raise ValueError(f\"x must be a scalar, got {x.ndim} dimensions\")\n    x = _convert_scalar_type_to_dtype(x)\n    return _device_put(x, device)\n\n", "CodeBleu_score": 33.86005424196338}]}
{"instance_id": "140de7c2b6a8", "generation_result": [{"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    assert isinstance(lhs_shape[0], int)\n    assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n\n\n\n", "CodeBleu_score": 50.94043049654204}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list)), \"lhs_shape is not tuple or list\"\n    assert isinstance(rhs_shape, (tuple, list)), \"rhs_shape is not tuple or list\"\n    if not lhs_shape and not rhs_shape:\n        return True\n    if lhs_shape and rhs_shape:\n        assert isinstance(lhs_shape[0], int), \"lhs_shape[0] is not int\"\n        assert isinstance(rhs_shape[0], int), \"rhs_shape[0] is not int\"\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.75774377710926}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) != 0:\n        assert isinstance(lhs_shape[0], int)\n    if len(rhs_shape) != 0:\n        assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 56.235710775644456}]}
{"instance_id": "55d0c71a259b", "generation_result": [{"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n    training_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_metadata = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    test_metadata[\"target\"] = list(test_metadata[\"target\"])\n    return training_set, test_set, training_metadata, test_metadata\n\n", "CodeBleu_score": 28.893607592553934}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes.pop(\"target\")\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes[\"target\"] = \"int8\"\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 52.13860737002026}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n\n    training_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_metadata = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n\n    return (training_set, test_set, training_metadata, test_metadata)\n\n", "CodeBleu_score": 25.535993170564907}]}
{"instance_id": "9e5e02cd73e0", "generation_result": [{"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    fig, ax = plt.subplots(figsize=(8, 2))\n    ax.set_axis_off()\n    ax.pcolormesh(np.linspace(0, 1, 256).reshape(1, -1), cmap=cmap)\n\n\n\n", "CodeBleu_score": 31.19346086676297}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    fig, ax = plt.subplots(figsize=(10, 1))\n    ax.set_axis_off()\n    ax.set_aspect('equal')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    X = np.linspace(0, 1, 256).reshape(1, -1)\n    ax.pcolormesh(X, cmap=cmap)\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 49.43001195549159}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    fig, ax = plt.subplots(figsize=(6, 1), subplot_kw=dict(xticks=[], yticks=[]))\n    ax.set_axis_off()\n    ax.pcolormesh(np.linspace(0, 1, 256).reshape(1, -1), cmap=cmap)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.085014255763}]}
{"instance_id": "ad0781b5cc38", "generation_result": [{"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return xdata, ydata\n    if obj.get_transform() != obj.axes.transData:\n        points = np.array([xdata, ydata]).T\n        transformed_points = obj.get_transform().transform(points)\n        return transformed_points[:, 0], transformed_points[:, 1]\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 59.96470020788149}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return xdata, ydata\n    if obj.get_transform() != obj.axes.transData:\n        points = np.array([xdata, ydata]).T\n        return obj.transData.inverted().transform(points).T\n    else:\n        return xdata, ydata\n\n\n\n", "CodeBleu_score": 52.78956061088501}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        points = np.array(xdata, ydata)\n        transData = obj.axes.transData\n        points = transData.transform(points)\n        points = obj.get_transform().inverted().transform(points)\n        return points[:, 0], points[:, 1]\n    else:\n        return xdata, ydata\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 64.257898749743}]}
{"instance_id": "bf776cadef8d", "generation_result": [{"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n\n    if data2 is not None:\n        if not pd.api.types.is_list_like(data2):\n            data2 = self._df[data2]\n    return self._module.kdeplot(data, data2=data2, *args, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 78.95861998202267}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n\n", "CodeBleu_score": 6.737749546279492}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 6.737749546279492}]}
{"instance_id": "fb44964174d9", "generation_result": [{"code": "def plot_most_used_words(df)\n\t\n    df['text'] = df['text'].str.replace('programa', 'programar')\n    df = df[df['text'].str.isalpha() & (df['text'].str.len() > 1)]\n    stop_words = set(stopwords.words('spanish'))\n    df = df[~df['text'].isin(stop_words)]\n    word_counts = df['text'].value_counts()[:20]\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=word_counts.values, y=word_counts.index, palette='deep')\n    plt.xlabel('Frequency')\n    plt.ylabel('Word')\n    plt.title('Most Frequent Words')\n    plt.savefig('most_frequent_words.png')\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 39.300875248216286}, {"code": "def plot_most_used_words(df)\n\t\n    df[\"text\"] = df[\"text\"].apply(lambda x: x.replace(\"programa\", \"programar\"))\n    words = df[\"text\"].str.split().explode()\n    words = words[words.str.isalpha() & (words.str.len() > 1) & ~words.isin(stopwords)]\n    word_counts = words.value_counts()[:20]\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x=word_counts.values, y=word_counts.index, palette=\"deep\")\n    plt.title(\"Most Used Words\")\n    plt.xlabel(\"Count\")\n    plt.ylabel(\"Word\")\n    plt.savefig(\"most_used_words.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.25045044827438}, {"code": "def plot_most_used_words(df)\n\t\n    df['token'] = df['token'].str.replace('programa', 'programar')\n    df = df[(df['token'].str.isalpha()) & (df['token'].str.len() > 1)]\n    df = df[~df['token'].isin(stopwords)]\n    df['token'].value_counts()[:20].plot(kind='bar', figsize=(12, 6))\n    plt.xlabel('Tokens')\n    plt.ylabel('Frequency')\n    plt.title('Most used words')\n    plt.savefig('most_used_words.png')\n\n\n", "CodeBleu_score": 31.9200913882991}]}
{"instance_id": "13414a7eb4e3", "generation_result": [{"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n\n    a = a.astype(a.dtype.name.replace(\"?\", \"\"))\n    depth = {0: (window // 2, window - window // 2 - 1), 1: (0, 0)}\n    boundary = {0: (None, np.nan), 1: (np.nan, None)}\n    ag = da.overlap.overlap(a, depth=depth[axis], boundary=boundary[axis])\n    return da.overlap.trim_internal(\n        da.map_blocks(\n            moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype\n        ),\n        depth[axis],\n    )\n\n", "CodeBleu_score": 44.01500345485101}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    a = a.astype(a.dtype.name, casting=\"safe\")\n    depth = {0: (window // 2, window // 2), 1: (0, 0)}\n    boundary = {0: \"nearest\", 1: \"none\"}\n    ag = da.overlap.overlap(a, depth=depth[axis], boundary=boundary[axis])\n    res = da.map_blocks(moving_func, ag, window, min_count=min_count, axis=axis)\n    res = da.overlap.trim_internal(res, depth[axis])\n    return res\n\n\n\n\n", "CodeBleu_score": 33.23114500979491}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    from dask.array.overlap import overlap, trim_internal\n\n    a = a.astype(a.dtype.type(a.max()))\n    depth = {0: (0, 0), 1: (0, 0)}\n    boundary = {0: \"nearest\", 1: \"nearest\"}\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    res = da.map_blocks(\n        moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype\n    )\n    res = trim_internal(res, depth[axis])\n    return res\n\n", "CodeBleu_score": 47.28488796452945}]}
{"instance_id": "68ce25d325d4", "generation_result": [{"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    lhs = da.from_array(lhs, chunks=(chunksize, chunksize))\n    rhs = da.from_array(rhs, chunks=(chunksize,))\n\n    if skipna:\n        if rhs.ndim == 1:\n            rhs = rhs.reshape(-1, 1)\n        coeffs, residuals, rank, s = lstsq(lhs, rhs, rcond)\n    else:\n        coeffs, residuals, rank, s = lstsq(lhs, rhs, rcond)\n\n    return coeffs, residuals\n\n", "CodeBleu_score": 19.351249018365728}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    lhs, rhs = da.broadcast_arrays(lhs, rhs)\n    if skipna:\n        if rhs.ndim == 1:\n            rhs = rhs.reshape((-1, 1))\n        rhs = da.apply_along_axis(\n            lambda x: np.polynomial.polynomial.polyfit(\n                np.arange(len(x)), x, 1, w=~np.isnan(x)\n            ),\n            0,\n            rhs,\n        )\n    else:\n        rhs = da.from_array(rhs)\n    lhs = da.from_array(lhs)\n    c, resids, rank, s = da.linalg.lstsq(lhs, rhs, rcond=rcond)\n    return c, resids\n\n", "CodeBleu_score": 24.961549475413292}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    lhs, rhs = da.broadcast_arrays(lhs, rhs, chunks='auto')\n\n    if skipna:\n        if lhs.ndim == 1:\n            lhs = lhs.reshape(-1, 1)\n        if rhs.ndim == 1:\n            rhs = rhs.reshape(-1, 1)\n        rhs = rhs.rechunk({1: lhs.shape[1]})\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs)\n    else:\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs)\n\n    return coeffs, residuals\n\n\n\n\n", "CodeBleu_score": 23.4101285320307}]}
{"instance_id": "c0c2c53b76e0", "generation_result": [{"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.332506203473944}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.332506203473944}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]\n\n", "CodeBleu_score": 92.04127144323292}]}
{"instance_id": "6559019d09a0", "generation_result": [{"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 93.9150977472243}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n\n", "CodeBleu_score": 21.982758620689655}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n", "CodeBleu_score": 93.9150977472243}]}
{"instance_id": "4a2801bb3851", "generation_result": [{"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        dask_args = [is_duck_dask_array(arg) for arg in args]\n        dask_kwargs = {\n            k: is_duck_dask_array(v) for k, v in kwargs.items()\n        }\n        if any(dask_args) or any(dask_kwargs.values()):\n            if isinstance(dask_module, str):\n                module = import_module(dask_module)\n            else:\n                module = dask_module\n            f = getattr(module, name)\n        else:\n            f = getattr(eager_module, name)\n        return f(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 53.451241115851765}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    f.__name__ = name\n    return f\n\n", "CodeBleu_score": 57.601020881798284}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            f = getattr(dask_module, name)\n        else:\n            f = getattr(eager_module, name)\n        return f(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 61.90389719428342}]}
{"instance_id": "eef8d746d01e", "generation_result": [{"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask_available and is_duck_dask_array(arr1) and is_duck_dask_array(arr2):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 75.89016297880904}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n\n    if arr1.shape != arr2.shape:\n        return False\n\n    try:\n        import dask\n    except ImportError:\n        return None\n\n    if is_duck_dask_array(arr1) and is_duck_dask_array(arr2):\n        return dask.tokenize(arr1) == dask.tokenize(arr2)\n\n    return None\n\n", "CodeBleu_score": 75.82231774054942}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n\n    if arr1.shape != arr2.shape:\n        return False\n\n    if dask_available and is_duck_array(arr1) and is_duck_array(arr2):\n        return tokenize(arr1) == tokenize(arr2)\n\n    return None\n\n", "CodeBleu_score": 73.36995491261618}]}
{"instance_id": "15e830ff5fcb", "generation_result": [{"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        x = da.random.RandomState(seed).standard_normal(shape, chunks=chunks)\n    else:\n        x = np.random.RandomState(seed).standard_normal(shape)\n\n    if frac_nan is not None:\n        inds = rng.choice(range(x.size), int(x.size * frac_nan), replace=False)\n        x.flat[inds] = np.nan\n\n    return x\n\n", "CodeBleu_score": 63.958301429005346}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        x = da.random.standard_normal(shape, chunks=chunks)\n    else:\n        x = np.random.standard_normal(shape)\n    if frac_nan is not None:\n        n_nans = int(np.prod(shape) * frac_nan)\n        inds = rng.choice(np.arange(x.size), size=n_nans, replace=False)\n        x.flat[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 54.66100951171071}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if frac_nan is not None:\n        assert 0 <= frac_nan <= 1\n    if chunks is not None:\n        x = da.random.RandomState(seed=seed).normal(0, 1, size=shape, chunks=chunks)\n    else:\n        x = np.random.RandomState(seed=seed).randn(*shape)\n    if frac_nan is not None:\n        inds = np.random.RandomState(seed=seed+1).choice(\n            range(x.size), int(x.size * frac_nan), replace=False)\n        x.flat[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 53.08042328451543}]}
{"instance_id": "5b57abbbe38b", "generation_result": [{"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n\n\n\n", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n\n\n\n", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 81.06081450739325}]}
{"instance_id": "592e414671e9", "generation_result": [{"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    # Validate name\n    if name not in const.allowed_financial_statements:\n        raise ValueError(\n            f\"Invalid name {name}. Allowed financial statements are {const.allowed_financial_statements}\"\n        )\n\n    # Validate timescale\n    if timescale not in const.allowed_periods:\n        raise ValueError(\n            f\"Invalid timescale {timescale}. Allowed periods are {const.allowed_periods}\"\n        )\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        logger = utils.get_yf_logger()\n        logger.error(e)\n        return pd.DataFrame()", "CodeBleu_score": 36.42634335940525}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.financial_statements:\n        raise ValueError(\n            f\"Invalid name '{name}' for financial statement. Valid names are {const.financial_statements}\"\n        )\n\n    if timescale not in const.periods:\n        raise ValueError(\n            f\"Invalid timescale '{timescale}' for financial statement. Valid timescales are {const.periods}\"\n        )\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        logger = utils.get_yf_logger()\n        logger.error(f\"Error fetching financials for '{name}' with timescale '{timescale}': {e}\")\n        return pd.DataFrame()", "CodeBleu_score": 37.42687964136714}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.fundamentals_keys:\n        raise ValueError(\n            \"Invalid financial statement name: \"\n            + name\n            + \". Valid names are: \"\n            + \", \".join(const.fundamentals_keys.keys())\n        )\n\n    if timescale not in const.period_keys:\n        raise ValueError(\n            \"Invalid timescale: \"\n            + timescale\n            + \". Valid timescales are: \"\n            + \", \".join(const.period_keys.keys())\n        )\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        get_yf_logger().error(\n            \"Error while fetching financials time series for \" + name + \": \" + str(e)\n        )\n        return pd.DataFrame()", "CodeBleu_score": 35.1719501241399}]}
{"instance_id": "af01d9bae091", "generation_result": [{"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership_details = data['ownershipDetails']\n    for owner in ownership_details:\n        self._parse_raw_values(owner)\n        del owner['maxAge']\n    df = pd.DataFrame(ownership_details)\n    if not df.empty:\n        df['reportDate'] = pd.to_datetime(df['reportDate'])\n        df = df.rename(columns={'fundName': 'fund_name', 'ownership': 'ownership_percentage', 'reportDate': 'report_date'})\n    self._mutualfund = df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.844280916102655}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data[\"fundOwnership\"]\n    for owner in ownership:\n        self._parse_raw_values(owner)\n        owner.pop(\"maxAge\")\n\n    df = pd.DataFrame(ownership)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"], format=\"%Y-%m-%d\")\n        df = df.rename(\n            columns={\n                \"fundSymbol\": \"symbol\",\n                \"orgName\": \"name\",\n                \"orgType\": \"type\",\n                \"reportTitle\": \"report_title\",\n                \"value\": \"value\",\n                \"valueChange\": \"value_change\",\n                \"shares\": \"shares\",\n                \"shareChange\": \"share_change\",\n                \"shareChangePct\": \"share_change_pct\",\n            }\n        )\n\n    self._mutualfund = df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.37467610373076}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    owners = data['fundOwnership']['ownershipList']\n    for owner in owners:\n        self._parse_raw_values(owner)\n        del owner['maxAge']\n    df = pd.DataFrame(owners)\n    if not df.empty:\n        df['reportDate'] = pd.to_datetime(df['reportDate'])\n        df.rename(columns={'reportDate': 'Date', 'organizationId': 'Fund'}, inplace=True)\n    self._mutualfund = df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 34.178978743392264}]}
{"instance_id": "2b5c6f1253db", "generation_result": [{"code": "def currency(self)\n\t\n    if self.currency:\n        return self.currency\n    metadata = self.get_history_metadata(self.ticker, proxy=self.proxy)\n    self.currency = metadata[\"currency\"]\n    return self.currency", "CodeBleu_score": 53.07472027145862}, {"code": "def currency(self)\n\t\n    if self.currency is not None:\n        return self.currency\n    metadata = self.get_history_metadata()\n    self.currency = metadata.get('currency', None)\n    return self.currency", "CodeBleu_score": 50.8834991532119}, {"code": "def currency(self)\n\t\n    if self.currency is not None:\n        return self.currency\n\n    metadata = self.get_history_metadata()\n    if \"currency\" in metadata:\n        self.currency = metadata[\"currency\"]\n    return self.currency\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.87003414121308}]}
{"instance_id": "16b80be60e3b", "generation_result": [{"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(self._proxy, [\"recommendationTrend\"])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = pd.DataFrame(self._recommendations['recommendationTrend']['trend'][0]['trend'])\n            except (KeyError, IndexError):\n                raise YFDataException(\"Could not parse data for recommendations\")\n    return self._recommendations\n\n", "CodeBleu_score": 52.11307213864607}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(self._proxy, ['recommendationTrend'])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = self._recommendations['recommendationTrend']['trend']\n            except KeyError as e:\n                raise YFDataException(f\"Could not parse data for {self._symbol}\") from e\n    return self._recommendations\n\n", "CodeBleu_score": 45.87485585572885}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(self._data.proxy, ['recommendationTrend'])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = pd.DataFrame(self._recommendations['recommendationTrend']['trend'][0]['trend'])\n            except (KeyError, IndexError):\n                raise YFDataException('No recommendations found for the given ticker.')\n    return self._recommendations\n\n", "CodeBleu_score": 53.438956475172475}]}
{"instance_id": "abaf8c2a3ecc", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n\n    # Check if the classifier has the attribute 'n_clusters'\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier does not have the 'n_clusters' attribute.\")\n\n    # Set default cluster range if not specified\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    # Create a list of tuples with cluster numbers and corresponding scores\n    scores = Parallel(n_jobs=n_jobs)(delayed(lambda i: (i, np.absolute(clf.set_params(n_clusters=i).fit(X).score(X))))(i) for i in cluster_ranges)\n\n    # Sort the scores by cluster number\n    scores = sorted(scores, key=lambda x: x[0])\n\n    # Extract cluster numbers and scores into separate lists\n    n_clusters, scores = zip(*scores)\n\n    # Create a new figure and axis if not provided\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    # Plot the scores against the number of clusters\n    ax.plot(n_clusters, scores, 'o-', color='b')\n\n    # Set the title, x-axis label, and y-axis label\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Score', fontsize=text_fontsize)\n\n    # Add a twin y-axis to show the clustering duration\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.set_ylabel('Clustering Time (seconds)', fontsize=text_fontsize)\n        ax2.tick_params(axis='y', labelsize=text_fontsize)\n        ax2.plot(n_clusters, [clf.cluster_time_ for _ in n_clusters], 'o-', color='r')\n\n", "CodeBleu_score": 50.59099547663729}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have the instance variable 'n_clusters'\")\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n    with Parallel(n_jobs=n_jobs) as parallel:\n        res = parallel(delayed(fit_and_score_cluster)(clf, X, n_clusters)\n                        for n_clusters in cluster_ranges)\n    scores, cluster_times = list(zip(*res))\n    ax.plot(cluster_ranges, scores, marker='o', color='b')\n    ax.set_ylabel('Sum of Squared Errors (SSE)', color='b',\n                  fontsize=text_fontsize)\n    ax.tick_params('y', colors='b', labelsize=text_fontsize)\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, cluster_times, marker='o', color='r')\n        ax2.set_ylabel('Clustering Duration (seconds)', color='r',\n                       fontsize=text_fontsize)\n        ax2.tick_params('y', colors='r', labelsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.grid(True)\n    return ax\n\n", "CodeBleu_score": 57.00841452506297}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have the attribute 'n_clusters'\")\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n    if show_cluster_time:\n        ax2 = ax.twinx()\n    with Parallel(n_jobs=n_jobs) as parallel:\n        clf = delayed(clf)\n        scores = parallel(\n            delayed(clf.set_params)(n_clusters=i)\n            for i in cluster_ranges\n        )\n        scores = parallel(\n            delayed(clf.fit)(X) for clf in scores\n        )\n        scores = [clf.score(X) for clf in scores]\n    ax.plot(cluster_ranges, scores, 'b*-')\n    ax.set_ylabel('Sum of Squared Errors', color='b', fontsize=text_fontsize)\n    if show_cluster_time:\n        ax2.plot(cluster_ranges, [clf.cluster_time_ for clf in scores], 'r*-')\n        ax2.set_ylabel('Cluster Time', color='r', fontsize=text_fontsize)\n    _ = ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    _ = ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n    if show_cluster_time:\n        ax2.tick_params(axis='y', which='major', labelsize=text_fontsize)\n    ax.grid(True)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.58853964454015}]}
{"instance_id": "8a90815c4ee1", "generation_result": [{"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    # clone the given clusterer\n    clf_clone = clone(clf)\n    # set the number of clusters for the cloned clusterer\n    setattr(clf_clone, \"n_clusters\", n_clusters)\n    # fit the cloned clusterer to the dataset X\n    clf_clone.fit(X)\n    # calculate the clustering score\n    score = score(X, clf_clone.labels_)\n    # record the end time\n    end_time = time.time()\n    # return the clustering score and the time taken\n    return score, end_time - start_time\n\n\n\n\n", "CodeBleu_score": 28.535361251357205}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    cloned_clf = clone(clf)\n    cloned_clf.set_params(n_clusters=n_clusters)\n    cloned_clf.fit(X)\n    run_time = time.time() - start_time\n    score = scorer(X, cloned_clf.labels_)\n    return score, run_time\n\n", "CodeBleu_score": 36.55270336481945}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    cloned_clf = clone(clf)\n    cloned_clf.set_params(n_clusters=n_clusters)\n    cloned_clf.fit(X)\n    y_pred = cloned_clf.predict(X)\n    end_time = time.time()\n    return (end_time - start_time, score(X, y_pred))\n\n", "CodeBleu_score": 26.951515874170184}]}
{"instance_id": "da40bd5dd81a", "generation_result": [{"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError(\"'{}' is not a valid clusterer instance.\".format(clf.__class__.__name__))\n    def plot_silhouette(self, X, **kwargs):\n        \"\"\"The function plot_silhouette takes a clustering object self, a dataset X, and additional keyword arguments kwargs.", "CodeBleu_score": 14.06902070854078}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('The object passed is not a valid clusterer instance.')\n\n    def plot_silhouette(self):\n        \"\"\"The function plot_silhouette takes a clustering object as an argument.", "CodeBleu_score": 8.965894348867874}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError(\"'{}' is not a valid clusterer instance.\".format(clf.__class__.__name__))\n\n    def plot_silhouette(self, X, ax=None, **kwargs):\n        \"\"\"\n        Plot the silhouette plot of the clustering results.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input data.\n        ax : matplotlib Axes, default=None\n            The target axes instance. If None, a new figure and axes is created.\n        **kwargs : dict\n            Other keyword arguments are passed to the silhouette plot function.\n\n        Returns\n        -------\n        ax : matplotlib Axes\n            The axes instance with the silhouette plot.\n        \"\"\"\n        from .plotting import plot_silhouette\n\n        return plot_silhouette(self, X, ax=ax, **kwargs)\n\n    def plot_elbow_curve(self, X, ax=None, **kwargs):\n        \"\"\"\n        Plot the elbow curve of the clustering results.\n\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            The input data.\n        ax : matplotlib Axes, default=None\n            The target axes instance. If None, a new figure and axes is created.\n        **kwargs : dict\n            Other keyword arguments are passed to the elbow curve plot function.\n\n        Returns\n        -------\n        ax : matplotlib Axes\n            The axes instance with the elbow curve plot.\n        \"\"\"\n        from .plotting import plot_elbow_curve\n\n        return plot_elbow_curve(self, X, ax=ax, **kwargs)\n\n    for method in [plot_silhouette, plot_elbow_curve]:\n        if hasattr(clf, method.__name__):\n            warnings.warn(\n                \"'{}' already has a method named '{}', which will be overridden.\".format(\n                    cl", "CodeBleu_score": 27.6412876418211}]}
{"instance_id": "b8d8ba3c0b1b", "generation_result": [{"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if title == \"Learning Curve\":\n        ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n        ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    elif title == \"Scalability of the model\":\n        ax.set_xlabel(\"Number of training examples\", fontsize=text_fontsize)\n        ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    ax.grid()\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n\n    ax.legend(loc=\"best\", fontsize=", "CodeBleu_score": 75.86942329099908}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if title == \"Learning Curve\":\n        ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n        ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    elif title == \"Scalability of the model\":\n        ax.set_xlabel(\"Number of training examples\", fontsize=text_fontsize)\n        ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=", "CodeBleu_score": 76.95831953915322}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n\n    # If no axes object is provided, create one\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    # Set the plot title and labels for the x and y axes\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n\n    # Compute the training and cross-validation scores\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    # Plot the learning curves\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax\n\n\n\n\n", "CodeBleu_score": 79.42996007047232}]}
{"instance_id": "e6e76eb35945", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have a \"\n                        \"'n_clusters' attribute. \"\n                        \"'%s' does not.\" % (clf))\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n    scores = []\n    for k in cluster_ranges:\n        clf_k = clone(clf)\n        setattr(clf_k, 'n_clusters', k)\n        clf_k.fit(X)\n        score = scorer(X, clf_k.labels_)\n        scores.append(np.absolute(score))\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.plot(cluster_ranges, scores, 'b*-')\n    ax.grid(True)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Score', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n    ax.set_title(title, fontsize=title_fontsize)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 58.245845610807955}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    if not hasattr(clf, \"n_clusters\"):\n        raise TypeError(\"The classifier passed should have a \"\n                        \"'n_clusters' attribute.\")\n\n    clfs = []\n    for i in cluster_ranges:\n        clf_ = clone(clf)\n        clf_.n_clusters = i\n        clf_.fit(X)\n        clfs.append(clf_)\n\n    scores = [np.absolute(clf_.score(X)) for clf_ in clfs]\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, scores, marker='o')\n    ax.grid(True)\n    ax.set_xlabel(\"Number of clusters\")\n    ax.set_ylabel(\"Score\")\n    ax.set_title(\"Elbow Plot\", fontsize=title_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax\n\n\n\n\n", "CodeBleu_score": 56.88513463456913}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n    if not hasattr(clf, \"n_clusters\"):\n        raise TypeError(\"The classifier should have the n_clusters parameter\")\n\n    clfs = []\n    for i in cluster_ranges:\n        clf_ = clone(clf)\n        clf_.n_clusters = i\n        clf_.fit(X)\n        clfs.append(clf_)\n\n    scores = [np.absolute(clf_.score(X)) for clf_ in clfs]\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, scores, marker='o')\n    ax.grid(True)\n\n    ax.set_xlabel('Number of clusters')\n    ax.set_ylabel('Score')\n    ax.set_title(title, fontsize=title_fontsize)\n\n    # set tick label size\n    ax.tick_params(labelsize=text_fontsize)\n    return ax", "CodeBleu_score": 54.28615196040036}]}
{"instance_id": "6f4530c8a20f", "generation_result": [{"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    X_pca = clf.transform(X)\n    ax.set_xlabel('1st principal component', fontsize=text_fontsize)\n    ax.set_ylabel('2nd principal component', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap)\n    ax.legend(np.unique(y), loc='best', fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 36.060358736948466}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    # Apply PCA transformation\n    X_pca = clf.transform(X)\n\n    # Set up the plot\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    # Plot the data points\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap, edgecolor='none', alpha=0.7, s=40)\n\n    # Add a legend\n    legend = ax.legend(*scatter.legend_elements(), loc=\"upper right\", title=\"Classes\")\n    ax.add_artist(legend)\n\n    # Label the axes with the first and second principal components\n    ax.set_xlabel('PC1')\n    ax.set_ylabel('PC2')\n\n    # Set plot title\n    plt.title(title, fontsize=title_fontsize)\n\n    # Set title font size\n    plt.title(title, fontsize=title_fontsize)\n\n    # Set x-axis label font size\n    ax.set_xlabel('PC1', fontsize=text_fontsize)\n\n    # Set y-axis label font size\n    ax.set_ylabel('PC2', fontsize=text_fontsize)\n\n    # Set tick label font size\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 43.47190084863812}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    X_pca = clf.transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.set_xlabel('1st principal component', fontsize=text_fontsize)\n    ax.set_ylabel('2nd principal component', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap)\n    ax.legend()\n    return ax\n\n", "CodeBleu_score": 29.999656616017123}]}
{"instance_id": "e7c2775d024c", "generation_result": [{"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    Y1 = np.array([uniform(0, 1) for i in range(16)])\n    Y2 = np.array([uniform(0, 1) for i in range(16)])\n\n    ax.bar(np.arange(16), Y1, color=\"0.7\", clip_path=clip1, edgecolor=\"0.3\", linewidth=0.5, zorder=10)\n    ax.bar(np.arange(16), Y2, color=\"0.7\", clip_path=clip2, edgecolor=\"0.3\", linewidth=0.5, zorder=10)\n    ax.bar(np.arange(16), Y1, color=\"tab:red\", clip_path=clip1, edgecolor=\"None\", linewidth=0.5, zorder=20)\n    ax.bar(np.arange(16), Y2, color=\"tab:red\", clip_path=clip2, edgecolor=\"None\", linewidth=0.5, zorder=20)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.0, -0.08, \"Bar plot\", transform=ax.transAxes,\n            fontsize=14, fontweight=\"bold\", va=\"top\")\n    ax.text(0.0, -0.14, r\"$\\it{ax.bar()}$\", transform=ax.transAxes,\n            fontfamily=\"monospace\", fontsize=14, va=\"top\")\n\n", "CodeBleu_score": 35.61201954731427}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    Y1 = np.arange(1, 17) + np.random.uniform(0.0, 0.5, 16)\n    Y2 = np.arange(1, 17) + np.random.uniform(0.0, 0.5, 16)\n\n    ax.bar(Y1, +np.random.uniform(0.5, 1.0, 16), facecolor='#cccccc',\n           edgecolor='white', clip_path=clip1)\n    ax.bar(Y2, +np.random.uniform(0.5, 1.0, 16), facecolor='#cccccc',\n           edgecolor='white', clip_path=clip2)\n\n    ax.bar(Y1, -np.random.uniform(0.5, 1.0, 16), facecolor='#999999',\n           edgecolor='white', clip_path=clip1)\n    ax.bar(Y2, -np.random.uniform(0.5, 1.0, 16), facecolor='#999999',\n           edgecolor='white', clip_path=clip2)\n\n    ax.bar(Y1, -np.random.uniform(0.5, 1.0, 16), facecolor='#ffaaaa',\n           edgecolor='white', clip_path=clip1)\n    ax.bar(Y2, -np.random.uniform(0.5, 1.0, 16), facecolor='#ffaaaa',\n           edgecolor='white', clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.0, 1.05, 'Bar plot', transform=ax.transAxes, size=20,\n            ha='left', va='bottom')\n    ax.text(0.0, 1.01, 'ax.bar()', transform=ax.transAxes, size=16,\n            ha='", "CodeBleu_score": 38.86805624467323}, {"code": "def barplot(ax)\n\t\n\n    clip1, clip2 = clip_path(ax)\n\n    X = np.arange(16)\n    Y1 = np.random.uniform(0.5, 1, len(X))\n    Y2 = np.random.uniform(0, 0.5, len(X))\n\n    ax.bar(X, +Y1, facecolor='#cccccc', edgecolor='white')\n    ax.bar(X, -Y2, facecolor='#999999', edgecolor='white')\n    ax.bar(X, +Y1, facecolor='#cccccc', edgecolor='white', clip_path=clip1)\n    ax.bar(X, -Y2, facecolor='#999999', edgecolor='white', clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.05, 1.05, \"Bar plot\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", color=\"black\")\n    ax.text(0.05, 1.0, \"ax.bar()\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", color=\"blue\", fontfamily=\"monospace\")\n\n", "CodeBleu_score": 39.9222801014926}]}
{"instance_id": "0ec1d146a32b", "generation_result": [{"code": "def split(n_segment)\n\t\n\n    X0 = np.arange(0, 1, 1 / n_segment)\n    X1 = np.arange(1 / n_segment, 1 + 1 / n_segment, 1 / n_segment)\n\n    return X0, X1\n\n", "CodeBleu_score": 15.361995652797928}, {"code": "def split(n_segment)\n\t\n\n    # Calculate the width of each segment\n    width = 1 / n_segment\n\n    # Calculate the padding between segments\n    pad = (1 - width * n_segment) / 2\n\n    # Determine the starting and ending positions of each segment\n    X0 = np.arange(0, 1, width) + pad\n    X1 = X0 + width\n\n    # Return the starting and ending positions of each segment\n    return X0, X1\n\n", "CodeBleu_score": 28.92572337826891}, {"code": "def split(n_segment)\n\t\n\n    # Calculate the width of each segment\n    width = width_segment(n_segment)\n\n    # Calculate the padding between segments\n    padding = padding_segment(n_segment)\n\n    # Calculate the starting positions of each segment\n    X0 = np.arange(0, n_segment, 1) * width\n\n    # Calculate the ending positions of each segment\n    X1 = X0 + width\n\n    # Return the starting and ending positions of each segment\n    return X0, X1\n\n", "CodeBleu_score": 21.386876381760352}]}
{"instance_id": "604a3e93ac0d", "generation_result": [{"code": "def pixelated_text(dpi=100)\n\t\n    # Create a figure and a canvas\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n\n    # Place the character 'a' at the center of the figure\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n\n    # Remove the axis\n    ax.axis('off')\n\n    # Draw the canvas\n    canvas.draw()\n\n    # Convert the canvas to an image array\n    image = np.frombuffer(canvas.tostring_argb(), dtype='uint8')\n    image = image.reshape(canvas.get_width_height()[::-1] + (4,))\n\n    # Adjust the color channels\n    image = np.roll(image, 1, axis=-1)\n\n    return image\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.24582534474517}, {"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.axis('off')\n    canvas.draw()\n    s, (width, height) = canvas.print_to_buffer()\n    X = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n    X = np.roll(X, 3, axis=2)\n    return X\n\n\n\n\n", "CodeBleu_score": 49.736973460468725}, {"code": "def pixelated_text(dpi=100)\n\t\n    # Create a figure and a canvas\n    fig = plt.figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n\n    # Place the character 'a' at the center of the figure\n    ax = fig.gca()\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n\n    # Remove the axis\n    ax.axis('off')\n\n    # Draw the canvas\n    canvas.draw()\n\n    # Convert the canvas to an image array\n    image = np.frombuffer(canvas.tostring_argb(), dtype='uint8')\n    image = image.reshape(canvas.get_width_height()[::-1] + (4,))\n\n    # Adjust the color channels\n    image = np.roll(image, 1, axis=-1)\n\n    return image\n\n\n\n\n", "CodeBleu_score": 54.36999818568624}]}
{"instance_id": "2a7fc7d560ea", "generation_result": [{"code": "def curve()\n\t\n    n_comp = randint(1, 10)\n    centers = uniform(0, 1, n_comp)\n    widths = normal(0.1, 0.05, n_comp)\n    scales = normal(0.5, 0.1, n_comp)\n    widths /= widths.sum()\n    scales /= scales.sum()\n    x = np.linspace(0, 1, 100)\n    y = np.zeros_like(x)\n    for c, w, s in zip(centers, widths, scales):\n        y += s * np.exp(-((x - c) / w) ** 2)\n    return x, y\n\n", "CodeBleu_score": 35.41866115119434}, {"code": "def curve()\n\t\n    n_components = np.random.randint(1, 5)\n    centers = np.random.uniform(0, 100, n_components)\n    widths = np.random.normal(5, 2, n_components)\n    scales = np.random.uniform(0.1, 1, n_components)\n    widths /= widths.sum()\n    scales /= scales.sum()\n    x = np.linspace(0, 100, 100)\n    y = np.zeros_like(x)\n    for center, width, scale in zip(centers, widths, scales):\n        y += scale * np.exp(-0.5 * ((x - center) / width) ** 2)\n    return x, y\n\n", "CodeBleu_score": 46.36552682079086}, {"code": "def curve()\n\t\n    n = randint(1, 10)\n    centers = uniform(0, 100, n)\n    widths = normal(0, 10, n)\n    scales = normal(0, 10, n)\n    widths = widths / widths.sum()\n    scales = scales / scales.sum()\n    x = np.linspace(0, 100, 1000)\n    y = np.zeros(1000)\n    for center, width, scale in zip(centers, widths, scales):\n        y += scale * np.exp(-((x - center) ** 2) / (2 * width ** 2))\n    return x, y\n\n", "CodeBleu_score": 41.40595333047001}]}
{"instance_id": "be694335ebfc", "generation_result": [{"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = np.round(np.pi / 2 / derivative * accuracy)\n    points = np.arange(-radius, radius + 1)\n    coefficients = np.linalg.inv(np.vander(points, derivative))[:, derivative]\n    return coefficients / np.math.factorial(derivative - 1), points\n\n", "CodeBleu_score": 48.13266207774567}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = np.ceil(derivative / 2)\n    points = np.arange(-radius, radius + 1)\n    inv_vander = np.linalg.inv(np.vander(points, derivative))\n    return (inv_vander[derivative - 1, :] * factorial(derivative - 1))[::-1], points\n\n", "CodeBleu_score": 45.52087132461512}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = np.ceil(derivative / 2) + accuracy\n    points = np.arange(-radius, radius + 1)\n    coefficients = np.linalg.inv(np.vander(points, derivative))\n    return coefficients / fact(derivative - 1), points\n\n", "CodeBleu_score": 52.54999773512574}]}
{"instance_id": "fa3fb47f33fa", "generation_result": [{"code": "def interpolate(X, Y, T)\n\t\n    # Calculate the distances between consecutive points\n    distances = np.sqrt(np.diff(X)**2 + np.diff(Y)**2)\n\n    # Calculate the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n\n    # Calculate the total distance\n    total_distance = cumulative_distances[-1]\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interp = np.interp(T, cumulative_distances, X)\n    Y_interp = np.interp(T, cumulative_distances, Y)\n\n    return X_interp, Y_interp, total_distance\n\n\n\n\n", "CodeBleu_score": 27.508146596275672}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute the distances between consecutive points\n    distances = np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2)\n\n    # Compute the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n\n    # Compute the total distance\n    total_distance = cumulative_distances[-1]\n\n    # Compute the interpolated X and Y coordinates\n    interpolated_X = np.interp(T, cumulative_distances, X)\n    interpolated_Y = np.interp(T, cumulative_distances, Y)\n\n    return interpolated_X, interpolated_Y, total_distance\n\n", "CodeBleu_score": 32.659219734184376}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute the distances between consecutive points\n    distances = np.sqrt(np.diff(X)**2 + np.diff(Y)**2)\n\n    # Compute the cumulative distances\n    cumulative_distances = np.cumsum(np.insert(distances, 0, 0))\n\n    # Compute the total distance\n    total_distance = cumulative_distances[-1]\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interp = np.interp(T, cumulative_distances, X)\n    Y_interp = np.interp(T, cumulative_distances, Y)\n\n    return X_interp, Y_interp, total_distance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.587784782113054}]}
{"instance_id": "870a2dad3c66", "generation_result": [{"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n", "CodeBleu_score": 73.67980821339879}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n", "CodeBleu_score": 73.67980821339879}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n", "CodeBleu_score": 73.67980821339879}]}
{"instance_id": "e1a908945acf", "generation_result": [{"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A = np.asarray(A)\n    window_len = int(sigma * 4 + 1)\n    A", "CodeBleu_score": 9.948329373197968}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = int(sigma) * 4 + 1\n    A = np.asarray(A)\n    window_len = int(window_len) // 2 * 2 + 1\n    B = np.empty(A.shape)\n    for idx, row in enumerate(A):\n        B[idx] = smooth1d(row, window_len)\n    BT = B.T\n    for idx, row in enumerate(BT):\n        BT[idx] = smooth1d(row, window_len)\n    return BT.T\n\n", "CodeBleu_score": 36.97131197094288}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = int(sigma) * 4 + 1\n    A = np.asarray(A)\n    window_len = int(window_len) // 2 * 2 + 1\n    A = np.transpose(A)\n    A = smooth1d(A, window_len)\n    A = np.transpose(A)\n    A = smooth1d(A, window_len)\n    A = np.transpose(A)\n    return A\n\n", "CodeBleu_score": 38.770317181085396}]}
{"instance_id": "94563c54b483", "generation_result": [{"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px = 1 / dpi * 72\n    return np.roll(padded_src, (int(ox / px), int(oy / px)), axis=(0, 1))\n\n", "CodeBleu_score": 23.130591485413643}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px = 1 / dpi\n    return np.roll(padded_src, (int(ox / px), int(oy / px)), axis=(0, 1))\n\n", "CodeBleu_score": 22.59001015750672}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px_per_inch = dpi / 72.0\n    ox = int(round(ox * px_per_inch))\n    oy = int(round(oy * px_per_inch))\n    padded_src = np.roll(padded_src, ox, axis=1)\n    padded_src = np.roll(padded_src, oy, axis=0)\n    return padded_src\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.42532996708826}]}
{"instance_id": "d71d232872fe", "generation_result": [{"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = tuple(shape)\n    width = tuple(width)\n    center = tuple(center)\n    grid = np.zeros(shape)\n    for i, w in enumerate(width):\n        grid = grid + ((np.exp(-0.5 * ((grid_coords(grid.shape, center)[i] - center[i]) / width[i]) ** 2)))\n    return grid\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.50709713831079}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = shape if isinstance(shape, tuple) else (shape,)\n    width = width if isinstance(width, tuple) else (width,)\n    center = center if isinstance(center, tuple) else (center,)\n    grid = np.mgrid[tuple(slice(-w / 2.0, w / 2.0, s) for s, w in zip(shape, width))]\n    dist = np.sum(np.square(grid - np.array(center)[:, None, None]), axis=0)\n    return np.exp(-dist / (2.0 * np.square(width)))\n\n", "CodeBleu_score": 23.743142699053163}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape, shape) if isinstance(shape, int) else shape\n    width = (width, width) if isinstance(width, float) or isinstance(width, int) else width\n    center = (center, center) if isinstance(center, float) or isinstance(center, int) else center\n    x, y = np.meshgrid(np.linspace(-1, 1, shape[0]), np.linspace(-1, 1, shape[1]))\n    d = np.sqrt(x * x + y * y)\n    g = np.exp(-(d - center[0]) ** 2 / (2 * width[0] * width[0]))\n    return g\n\n", "CodeBleu_score": 21.207235299254755}]}
{"instance_id": "7bbd08c987bc", "generation_result": [{"code": "def stimulus(position, size, intensity)\n\t\n    x = size * np.cos(position)\n    y = size * np.sin(position)\n    x -= x.mean()\n    y -= y.mean()\n    x /= x.max() - x.min()\n    y /= y.max() - y.min()\n    x, y = np.meshgrid(x, y)\n    R = (x**2 + y**2)\n    return np.exp(-R / size) * intensity\n\n", "CodeBleu_score": 25.047614168297557}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = polar2cartesian(position)\n    x, y = normalize(x, y)\n    x, y = center(x, y)\n    X, Y = np.meshgrid(x, y)\n    R = (X - size / 2) ** 2 + (Y - size / 2) ** 2\n    return np.exp(-R / (2 * size ** 2)) * intensity\n\n", "CodeBleu_score": 19.504156930992043}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = position\n    x, y = cartesian(x, y)\n    x, y = x/size, y/size\n    x, y = x-0.5, y-0.5\n    X, Y = np.meshgrid(x, y)\n    R = X**2 + Y**2\n    return np.exp(-R/intensity)\n\n", "CodeBleu_score": 12.731944125633715}]}
{"instance_id": "2b5806238d5d", "generation_result": [{"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xlabel(\"\")\n    ax.set_xlim(0, 1)\n    ax.set_xticks(np.linspace(0, 1, 11))\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n        fontdict={\"family\": \"monospace\", \"size\": 20, \"weight\": \"bold\"},\n    )\n    ax.set_title(\"Axes Demo\", fontdict={\"family\": \"serif\", \"weight\": \"bold\"})\n\n", "CodeBleu_score": 47.230471515282126}, {"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xlabel(\"\")\n    ax.set_xlim(0, 1)\n    ax.set_xticks(np.linspace(0, 1, 5))\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        fontdict={\"family\": \"monospace\", \"weight\": \"bold\", \"size\": 16},\n    )\n    ax.set_title(\n        \"Axes\",\n        family=\"serif\",\n        weight=\"light\",\n        size=16,\n    )\n    ax.set_ylim(0, 1)\n    ax.set_ylabel(\"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.33405301910617}, {"code": "def plot(ax, text)\n\t\n    ax.set_yticks([])\n    ax.set_xticks([])\n    ax.set_xlabel('x')\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_ylabel('y')\n    ax.text(0.5, 0.5, text, fontproperties='monospace',\n            horizontalalignment='center', verticalalignment='center',\n            transform=ax.transAxes, fontsize=20)\n    ax.set_title('matplotlib default settings', fontfamily='monospace',\n                 fontweight='bold')\n\n", "CodeBleu_score": 39.452917724991046}]}
{"instance_id": "0b42aac61e21", "generation_result": [{"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n\n\n\n\n", "CodeBleu_score": 61.35151560708025}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n\n", "CodeBleu_score": 61.35151560708025}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.final_estimator_.predict_cumulative_hazard_function(Xt, **kwargs)\n\n\n\n", "CodeBleu_score": 54.33774805561797}]}
{"instance_id": "c8439e4918ad", "generation_result": [{"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 66.76449005274651}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt, **kwargs)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 59.492376049259256}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)", "CodeBleu_score": 66.76449005274651}]}
{"instance_id": "216662ca7db4", "generation_result": [{"code": "def _check_success(self, results)\n\t\n    if results.solver.termination_condition == TerminationCondition.optimal:\n        pass\n    elif results.solver.termination_condition == TerminationCondition.feasible:\n        pass\n    elif results.solver.termination_condition == TerminationCondition.maxIterations:\n        warnings.warn(\"Optimization terminated because the maximum number of iterations was reached.\")\n    elif results.solver.termination_condition == TerminationCondition.infeasible:\n        raise RuntimeError(\"The problem is infeasible.\")\n    elif results.solver.termination_condition == TerminationCondition.unbounded:\n        raise RuntimeError(\"The problem is unbounded.\")\n    elif results.solver.termination_condition == TerminationCondition.internalSolverError:\n        raise RuntimeError(\"The solver encountered an internal error.\")\n    elif results.solver.termination_condition == TerminationCondition.nan:\n        raise RuntimeError(\"The solver returned an unexpected nan value.\")\n    else:\n        raise RuntimeError(f\"Unexpected termination condition: {results.solver.termination_condition}\")\n\n", "CodeBleu_score": 26.666526599738617}, {"code": "def _check_success(self, results)\n\t\n    if results.solver.status == SolverStatus.ok and results.solver.termination_condition == TerminationCondition.optimal:\n        pass\n    elif results.solver.termination_condition in [TerminationCondition.maxIterations, TerminationCondition.locallyOptimal]:\n        warnings.warn(\"Convergence problem: status: {}\".format(results.solver.termination_condition))\n    elif results.solver.status != SolverStatus.ok:\n        raise RuntimeError(\"Solver ({}) returned solver status: {}\".format(results.solver.name, results.solver.status))\n    elif results.solver.termination_condition == TerminationCondition.infeasible:\n        raise RuntimeError(\"Solver ({}) returned infeasible\".format(results.solver.name))\n    elif results.solver.termination_condition == TerminationCondition.unbounded:\n        raise RuntimeError(\"Solver ({}) returned unbounded\".format(results.solver.name))\n    elif results.solver.termination_condition == TerminationCondition.infeasibleOrUnbounded:\n        raise RuntimeError(\"Solver ({}) returned infeasible or unbounded\".format(results.solver.name))\n    elif results.solver.termination_condition == TerminationCondition.fatalError:\n        raise RuntimeError(\"Solver ({}) returned fatal error\".format(results.solver.name))\n    else:\n        raise RuntimeError(\"Solver ({}) returned unknown solver status: {}\".format(results.solver.name, results.solver.termination_condition))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.69545078716404}, {"code": "def _check_success(self, results)\n\t\n    status = results.solver.status\n    if results.solver.termination_condition == TerminationCondition.optimal:\n        logger.info(\n            \"Optimal solution found. Model status: %s\",\n            self._get_solver_status_info(status, True),\n        )\n    elif results.solver.termination_condition == TerminationCondition.feasible:\n        logger.info(\n            \"Model status: %s\", self._get_solver_status_info(status, True)\n        )\n    elif results.solver.termination_condition == TerminationCondition.maxIterations:\n        logger.warning(\n            \"Check model for infeasibilities or unboundedness.\"\n        )\n    elif results.solver.termination_condition == TerminationCondition.infeasible:\n        raise RuntimeError(\n            \"The model returned an infeasible solution. \"\n            \"The solver status is: {}\".format(\n                self._get_solver_status_info(status, False)\n            )\n        )\n    elif results.solver.termination_condition == TerminationCondition.unbounded:\n        raise RuntimeError(\n            \"The model returned an unbounded solution. \"\n            \"The solver status is: {}\".format(\n                self._get_solver_status_info(status, False)\n            )\n        )\n    elif results.solver.termination_condition == TerminationCondition.infeasibleOrUnbounded:\n        raise RuntimeError(\n            \"The model returned an infeasible or unbounded solution. \"\n            \"The solver status is: {}\".format(\n                self._get_solver_status_info(status, False)\n            )\n        )\n    elif results.solver.termination_condition == TerminationCondition.locallyOptimal:\n        logger.info(\n            \"Model status: %s\", self._get_solver_status_info(status, True)\n        )\n    elif results.solver.termination_condition == TerminationCondition.other:\n        raise RuntimeError(\n            \"The solver returned an unexpected status: {}\".format(\n                self._get_solver_status_info(status, False", "CodeBleu_score": 36.49375752533028}]}
{"instance_id": "1fe2e379fca0", "generation_result": [{"code": "def _decompose(self, P)\n\t\n    # calculate eigenvalues and eigenvectors\n    eigenvalues, eigenvectors = linalg.eigh(P)\n    # identify largest eigenvalue\n    max_eigenvalue = np.max(np.abs(eigenvalues))\n    # calculate condition number\n    condition_number = max_eigenvalue / (s.min() * P.shape[0] * np.finfo(float).eps)\n    # filter out eigenvalues below cutoff\n    not_below_cutoff = (eigenvalues >= -max_eigenvalue * np.sqrt(condition_number))\n    # normalize eigenvalues\n    eigenvalues[not_below_cutoff] /= max_eigenvalue\n    # return decomposed matrix and largest eigenvalue\n    return (eigenvectors[:, not_below_cutoff] * eigenvalues[not_below_cutoff]).T, max_eigenvalue", "CodeBleu_score": 23.000816179931853}, {"code": "def _decompose(self, P)\n\t\n    eigvals, eigvecs = linalg.eigh(P)\n    eigvals = eigvals.astype(float)\n    eigvecs = eigvecs.astype(float)\n\n    # Identify the largest eigenvalue.\n    abs_eigvals = np.abs(eigvals)\n    max_eigval = abs_eigvals.max()\n\n    # Calculate a condition number based on the largest eigenvalue, the shape of P,\n    # and machine epsilon.\n    condition_number = max_eigval / (abs_eigvals.shape[0] * np.finfo(float).eps)\n    if condition_number >= 1000:\n        warnings.warn(\n            \"The normalized Laplacian matrix is very close to singular!\"\n            \" Highly likely that eigenvector computation did not converge.\"\n        )\n\n    # Filter out eigenvalues below the cutoff.\n    not_below_cutoff = abs_eigvals > self.cutoff_\n    eigvals = eigvals[not_below_cutoff]\n    eigvecs = eigvecs[:, not_below_cutoff]\n\n    # Normalize the eigenvalues.\n    eigvals /= abs_eigvals.max()\n\n    return eigvecs.T, eigvals\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.430543378357502}, {"code": "def _decompose(self, P)\n\t\n    # Calculate eigenvalues and eigenvectors\n    evals, evecs = linalg.eigh(P)\n    # Identify largest eigenvalue\n    max_eval = np.max(evals)\n    # Calculate condition number\n    condition_number = max_eval / (np.finfo(float).eps * P.shape[0])\n    # Check if all eigenvalues are above the negative cutoff\n    not_below_cutoff = evals > -1.0 * condition_number * max_eval\n    # Filter out eigenvalues below the positive cutoff\n    evals = evals[not_below_cutoff]\n    evecs = evecs[:, not_below_cutoff]\n    # Normalize eigenvalues\n    evals = evals / np.max(evals)\n    # Return transposed decomposed matrix and largest eigenvalue\n    return evecs.T, max_eval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.6386799550758}]}
{"instance_id": "20c3f5d05d79", "generation_result": [{"code": "def _update_coef(self, coef, D)\n\t\n    self.coef_ = np.zeros(coef.shape)\n    inds = np.flatnonzero(coef)\n    self.coef_[inds] = D[inds]\n\n\n\n\n", "CodeBleu_score": 20.5087566373169}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef = np.array(coef)\n    coef[np.abs(coef) < 1e-15] = 0\n    coef[np.abs(coef) < 1e-14] = np.sign(coef[np.abs(coef) < 1e-14]) * 1e-14\n    self.coef_ = coef * D\n\n\n\n\n", "CodeBleu_score": 20.71610761134974}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef_ = coef\n    coef_[coef < self.threshold] = 0\n    coef_[coef >= self.threshold] /= D[coef >= self.threshold]\n    self.coef_ = coef_", "CodeBleu_score": 18.386228579880477}]}
{"instance_id": "37c347d00d35", "generation_result": [{"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    y_true = self._check_y(y_true)\n    if sample_weight is None:\n        sample_weight = np.ones(y_true.shape[0])\n    # y_true is a 2d array of event type and time\n    # raw_prediction is a 1d array of risk scores\n    # sample_weight is a 1d array of sample weights\n    # calculate the negative gradient of the Cox PH model using event type and time\n    # apply sample weights to the gradient\n    # return the weighted or unweighted gradient\n    # return the negative gradient\n    return -y_true[:, 0] * (y_true[:, 1] - raw_prediction) * sample_weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.26817777386518}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    y_true = y_true.astype(int)\n    event_type = y_true[:, 0]\n    event_time = y_true[:, 1]\n    gradient = np.zeros((event_type.shape[0], raw_prediction.shape[1]))\n    gradient[event_type == 1] = -event_time[:, np.newaxis] * raw_prediction[event_type == 1]\n    gradient[event_type == 0] = raw_prediction[event_type == 0]\n    if sample_weight is not None:\n        gradient *= sample_weight[:, np.newaxis]\n    return gradient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.30439254234706}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    y_true = y_true.astype(int)\n    event_type = y_true[:, 0]\n    event_time = y_true[:, 1]\n    gradient = np.zeros_like(raw_prediction)\n    gradient[event_type == 1] = -event_time[event_type == 1]\n    gradient[event_type == 0] = raw_prediction[event_type == 0]\n    if sample_weight is not None:\n        gradient *= sample_weight\n    return gradient\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.462249735939032}]}
{"instance_id": "6be432d27e52", "generation_result": [{"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values:\n        assert_all_finite(X)\n        return None\n\n    overall_sum = np.sum(X)\n    if np.isnan(overall_sum) or np.isinf(overall_sum):\n        raise ValueError(\n            f\"{estimator_name} does not support missing values when \"\n            f\"the dataset contains infinite values.\"\n        )\n    if not np.isfinite(overall_sum):\n        return None\n\n    with np.errstate(all=\"ignore\"):\n        if issparse(X):\n            missing_values_mask = np.asarray(X.sum(axis=0) == 0).ravel()\n        else:\n            missing_values_mask = np.all(X == self.missing_values_in_feature_mask, axis=0)\n        if np.any(missing_values_mask):\n            return missing_values_mask\n        return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.21361892267875}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        assert_all_finite(X)\n        return None\n    if estimator_name is None:\n        estimator_name = self.__class__.__name__\n    estimator_name = estimator_name.lower()\n    if estimator_name in (\"imputer\", \"missingindicator\"):\n        default_params = {\"missing_values\": np.nan}\n    elif estimator_name == \"simpleimputer\":\n        default_params = {\"missing_values\": np.nan, \"strategy\": \"mean\"}\n    else:\n        default_params = {}\n    estimator = self._get_estimator(estimator_name, default_params)\n    try:\n        estimator.fit(X)\n    except ValueError as e:\n        if \"Input contains NaN\" in str(e):\n            pass\n        else:\n            raise e\n    estimator_params = estimator.get_params()\n    if \"missing_values\" in estimator_params:\n        missing_values = estimator_params[\"missing_values\"]\n        if missing_values != np.nan:\n            return None\n    if \"strategy\" in estimator_params:\n        strategy = estimator_params[\"strategy\"]\n        if strategy == \"constant\":\n            return None\n    if issparse(X):\n        missing_values_mask = _any_isnan_axis0(X)\n    else:\n        with np.errstate(invalid=\"ignore\"):\n            X_sum = np.sum(X, axis=0)\n        if not np.isfinite(X_sum).all():\n            raise ValueError(\n                \"Input contains infinite values. Try setting to \"\n                \"np.nan values inf, -inf or a value too large for \"\n                \"dtype('float64').\"\n            )\n        missing_values_mask = ~np.isfinite(X_sum)\n    return missing_values_mask\n\n\n\n", "CodeBleu_score": 38.49933152874346}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        assert_all_finite(X)\n        return None\n\n    if self._get_tags()[\"allow_nan\"]:\n        # Missing values are not supported by the estimator\n        return None\n\n    # Check for missing values in the feature matrix X\n    X = np.asarray(X)\n    with np.errstate(over=\"ignore\"):\n        if np.isnan(np.sum(X)):\n            # There are missing values in the feature matrix X\n            # Compute the mask indicating which features have missing values\n            return _any_isnan_axis0(X)\n        else:\n            # No missing values in the feature matrix X\n            return None\n\n\n", "CodeBleu_score": 28.907853014529472}]}
{"instance_id": "dc5bda895a07", "generation_result": [{"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    if self.low_memory:\n        check_is_fitted(self, \"tree_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        pred = self.tree_.predict(X)\n        array = pred[..., 1]\n    else:\n        array = self.predict_survival_function(X, check_input, return_array=True)\n\n    if return_array:\n        return array\n\n    unique_times = np.unique(array)\n    return _array_to_step_function(unique_times, array)\n\n", "CodeBleu_score": 73.6884071212996}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    if self.low_memory:\n        check_is_fitted(self, \"tree_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        pred = self.tree_.predict(X)\n        array = pred[..., 1]\n    else:\n        array = self.predict_survival_function_partial(X, check_input)\n\n    if return_array:\n        return array\n\n    x = np.unique(array)\n    return _array_to_step_function(x, array)\n\n", "CodeBleu_score": 74.82435123076844}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n    pred = self.tree_.predict(X)\n    array = pred[..., 1]\n    if return_array:\n        return array\n\n    x = self.event_times_\n    return _array_to_step_function(x, array)\n\n", "CodeBleu_score": 76.75442931131822}]}
{"instance_id": "84ae915b5933", "generation_result": [{"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_array_survival(X, y)\n    if X.shape[0] < self.min_samples:\n        raise ValueError(\n            \"The minimum number of samples is %d. \"\n            \"Got %d.\" % (self.min_samples, X.shape[0])\n        )\n\n    X = X.astype(np.float64)\n    event, time = y[:, 0], y[:, 1]\n\n    # Center the feature matrix\n    X -= X.mean(0)\n\n    if self.normalize:\n        X = f_normalize(X, norm=\"l2\", axis=0)\n\n    # Sort the data in descending order based on survival time\n    order = np.argsort(-time)\n    X = np.asfortranarray(X[order])\n    event = event[order]\n    time = time[order]\n\n    return X, event, time, X.mean(0), np.sqrt(np.square(X).sum(0))\n\n\n\n\n", "CodeBleu_score": 36.044378555126485}, {"code": "def _pre_fit(self, X, y)\n\t\n\n    X, y = check_X_y(X, y, accept_sparse=True)\n    X = check_array(X, ensure_2d=True)\n\n    if X.shape[0] < self.min_samples:\n        raise ValueError(\"X must have at least %d samples.\" % self.min_samples)\n\n    X = np.asfortranarray(X, dtype=np.float64)\n    y = np.asfortranarray(y, dtype=np.float64)\n\n    event, time = y[:, 0], y[:, 1]\n\n    X_mean = X.mean(0)\n    X_std = X.std(0)\n    X_std[X_std == 0] = 1.0\n\n    if self.normalize:\n        X = (X - X_mean) / X_std\n    else:\n        X = (X - X_mean)\n\n    order = np.argsort(-time, kind=\"mergesort\")\n    X = X[order]\n    event = event[order]\n    time = time[order]\n\n    return X, event, time, X_mean, X_std\n\n", "CodeBleu_score": 38.86753961836629}, {"code": "def _pre_fit(self, X, y)\n\t\n    X = check_array_survival(X, self.allow_min_timesteps)\n    y = check_y_survival(y)\n    event, time = check_y_survival(y, allow_all_censored=True)\n    X = np.asfortranarray(X)\n    X -= X.mean(0)\n    if self.normalize:\n        X = f_normalize(X)\n    order = np.argsort(-time, kind=\"mergesort\")\n    X = X[order]\n    time = time[order]\n    event = event[order]\n    return X, event, time, X.mean(0), X.std(0)\n\n", "CodeBleu_score": 21.0366818800662}]}
{"instance_id": "c70bb013f85f", "generation_result": [{"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        n_alphas = 200\n        if self.n_alphas is not None:\n            n_alphas = self.n_alphas\n        alphas = np.logspace(-10, -2, n_alphas)\n    else:\n        alphas = np.sort(self.alphas)\n    n_alphas = len(alphas)\n    if n_alphas < 1:\n        raise ValueError(\"Invalid value for 'n_alphas': %d. \"\n                         \"The number of alphas must be greater than zero.\"\n                         % n_alphas)\n\n    if (alphas < 0).any() or (alphas > 1).any():\n        raise ValueError(\"Alpha values must be in the interval [0, 1]\")\n\n    alphas = column_or_1d(alphas)\n    alphas = alphas.astype(np.float64)\n    self.alphas_ = alphas\n    self.l1_ratio_ = self.l1_ratio\n    return self.alphas_, self.l1_ratio_\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.98543873771657}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if self.n_alphas <= 0:\n            raise ValueError(\"Invalid value for 'n_alphas': %d . The number of alphas must be > 0\" % self.n_alphas)\n        alphas = np.empty(self.n_alphas)\n        self.alphas_ = alphas\n        self.path = True\n    else:\n        alphas = column_or_1d(self.alphas).astype(np.float64)\n        alphas = check_array(alphas, ensure_2d=False)\n        check_non_negative(alphas, \"Alpha values must be non-negative\")\n        assert_all_finite(alphas)\n        self.alphas_ = alphas\n        self.path = False\n    return alphas, self.path\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.95420949153363}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        self.alphas = np.empty(self.n_alphas)\n        self.n_alphas = self.alphas.shape[0]\n        self.n_alphas_ = self.n_alphas\n        self.coefs_path_ = np.empty((self.n_alphas, self.n_features))\n        self.alphas_path_ = np.empty((self.n_alphas, self.n_features))\n        self.new_alphas = True\n    else:\n        self.alphas = column_or_1d(self.alphas)\n        self.n_alphas = self.alphas.shape[0]\n        self.new_alphas = False\n\n    if self.n_alphas < 1:\n        raise ValueError(\"Invalid number of alphas: %d\" % self.n_alphas)\n\n    if not np.all(np.isfinite(self.alphas)):\n        raise ValueError(\"All alphas must be finite\")\n\n    if not np.all(self.alphas >= 0):\n        raise ValueError(\"All alphas must be non-negative\")\n\n    return self.alphas, self.new_alphas\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 34.071342324754795}]}
{"instance_id": "7b54a0554ba4", "generation_result": [{"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(time, event)\n    unique_times, n_events, n_at_risk, _ = _compute_counts(event, time)\n    # n_events are the number of events that happened at time t\n    # n_at_risk are the number of people that are known to have survived\n    # up to time t\n    # n_events[i] / n_at_risk[i] is the probability of an event\n    # happening at time[i] given that n_at_risk[i] individuals survived\n    # up to that point.\n    # The cumulative hazard is the sum of these probabilities\n    # up to time t.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the\n    # survival function.\n    # The cumulative hazard is the negative logarithm of the", "CodeBleu_score": 34.4581266023438}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n\n    event, time = check_y_survival(event, time)\n    check_consistent_length(time, event)\n\n    # order time in ascending order\n    order = np.argsort(time, kind=\"mergesort\")\n    time = time[order]\n    event = event[order]\n\n    # uniq_times = np.unique(time)\n    # n_events = np.zeros_like(uniq_times)\n    # n_at_risk = np.zeros_like(uniq_times)\n    # n_censored = np.zeros_like(uniq_times)\n\n    # # sum up the events and censored for each unique time point\n    # for i, t in enumerate(uniq_times):\n    #     was_event = event[time == t]\n    #     n_events[i] = np.sum(was_event)\n    #     n_censored[i] = np.sum(~was_event)\n    #     if i > 0:\n    #         n_at_risk[i] = n_at_risk[i - 1] - n_censored[i - 1]\n    #     else:\n    #         n_at_risk[i] = len(time) - n_censored[i]\n\n    times, n_events, n_at_risk, n_censored = _compute_counts(event, time, order)\n\n    # estimate cumulative hazard function\n    # cum_n_events = np.cumsum(n_events)\n    # cum_n_censored = np.cumsum(n_censored)\n    # cum_hazard = cum_n_events / n_at_risk\n    cum_hazard = np.cumsum(n_events) / n_at_risk\n    return times, cum_hazard\n\n", "CodeBleu_score": 32.131317635415684}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n\n    order = np.argsort(time, kind=\"mergesort\")\n    time = time[order]\n    event = event[order]\n\n    distinct_times = np.unique(time)\n    n_samples = len(time)\n    n_events = np.zeros(n_samples, dtype=int)\n    total_n_events = np.zeros(n_samples, dtype=int)\n    n_at_risk = np.zeros(n_samples, dtype=int)\n\n    # iterate through events\n    i = 0\n    j = 0\n    while i < n_samples and j < len(distinct_times):\n        if time[i] == distinct_times[j]:\n            total_n_events[j] += event[i]\n            n_events[i] = total_n_events[j]\n            i += 1\n        else:\n            total_n_events[j] += event[i]\n            n_events[i] = total_n_events[j]\n            j += 1\n\n    n_events = np.resize(n_events, i)\n    total_n_events = np.resize(total_n_events, j)\n\n    # compute the counts of events and censored\n    uniq_times, n_events, n_at_risk, n_censored = _compute_counts(event, time, order)\n\n    # compute the estimates\n    # if the time of the first event is not 0 (and if there is at\n    # least one event), add an additional point\n    if uniq_times[0] != 0 and n_events[0] > 0:\n        uniq_times = np.r_[0, uniq_times]\n        n_events = np.r_[0, n_events]\n        n_at_risk = np.r_[n_samples, n_at_risk]\n        n_censored = np.r_[0, n_c", "CodeBleu_score": 33.858330696572736}]}
{"instance_id": "35af806300cc", "generation_result": [{"code": "def ipc_weights(event, time)\n\t\n\n    # check if all events have occurred\n    if event.all():\n        return np.ones(event.shape[0])\n\n    # calculate Kaplan-Meier estimator in reverse\n    time_rev = np.max(time) - time\n    surv_prob_rev = kaplan_meier_estimator(~event, time_rev)[1]\n\n    # find index positions of event times within unique time values\n    time_unique = np.unique(time)\n    event_idx = np.searchsorted(time_unique, time[event])\n\n    # retrieve survival probabilities at event times\n    surv_prob_at_event = surv_prob_rev[event_idx]\n\n    # ensure all retrieved probabilities are positive\n    if np.any(surv_prob_at_event <= 0):\n        raise ValueError(\"Encountered non-positive probability at an event time\")\n\n    # create weights array\n    weights = np.ones(event.shape[0])\n    weights[event] = 1.0 / surv_prob_at_event\n\n    return weights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.37815177536246}, {"code": "def ipc_weights(event, time)\n\t\n    if np.all(event):\n        return np.ones(len(event))\n\n    _, prob_survival = kaplan_meier_estimator(~event, time, reverse=True)\n    idx = np.searchsorted(np.unique(time), time[event])\n    prob_event = prob_survival[idx]\n    prob_event[prob_event == 0] = np.inf\n    weights = 1.0 / prob_event\n    return weights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.90198420792358}, {"code": "def ipc_weights(event, time)\n\t\n    if np.all(event):\n        return np.ones(len(event))\n\n    km_est = kaplan_meier_estimator(event, time, reverse=True)\n\n    # find index positions of event times within the unique time values\n    event_pos = np.searchsorted(km_est[0], time[event == 1])\n\n    # retrieve survival probabilities for event times\n    surv_prob = km_est[1][event_pos]\n\n    # ensure all retrieved probabilities are positive\n    surv_prob = np.where(surv_prob > 0, surv_prob, 1e-10)\n\n    # create weights array\n    weights = np.ones(len(event))\n    weights[event == 1] = 1 / surv_prob\n\n    return weights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.379863192025354}]}
{"instance_id": "72b19985ea11", "generation_result": [{"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame) or isinstance(dfs, modin.pandas.DataFrame) or isinstance(dfs, pl.DataFrame):\n        dfs = [dfs]\n\n    connectors = []\n    for df in dfs:\n        if isinstance(df, pd.DataFrame) or isinstance(df, modin.pandas.DataFrame):\n            connectors.append(PandasConnector(df))\n        elif isinstance(df, pl.DataFrame):\n            connectors.append(PolarsConnector(df))\n        elif isinstance(df, BaseConnector):\n            connectors.append(df)\n        else:\n            raise ValueError(\n                \"Invalid input type. Expected pd.DataFrame, modin.pandas.DataFrame, pl.DataFrame, or BaseConnector.\"\n            )\n\n    return connectors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.75152682015383}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    elif isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n    elif isinstance(dfs, list):\n        pass\n    else:\n        raise ValueError(\"Invalid input type. Expected pandas DataFrame or connector.\")\n\n    connectors = []\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            connector = PandasConnector(df)\n        elif isinstance(df, BaseConnector):\n            connector = df\n        elif isinstance(df, modin.pandas.DataFrame):\n            connector = ModinConnector(df)\n        elif isinstance(df, pl.DataFrame):\n            connector = PolarsConnector(df)\n        else:\n            raise ValueError(\"Invalid input type. Expected pandas DataFrame or connector.\")\n        connectors.append(connector)\n\n    return connectors", "CodeBleu_score": 40.171581611987094}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    if isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n    if not isinstance(dfs, list):\n        raise ValueError(\"Invalid input type. Please provide a list of dataframes or connectors.\")\n\n    connectors = []\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            connector = PandasConnector(df)\n        elif isinstance(df, modin.pandas.DataFrame):\n            connector = ModinConnector(df)\n        elif isinstance(df, pl.DataFrame):\n            connector = PolarsConnector(df)\n        elif isinstance(df, BaseConnector):\n            connector = df\n        else:\n            raise ValueError(f\"Invalid dataframe type: {type(df)}\")\n        connectors.append(connector)\n\n    return connectors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.34289065856992}]}
{"instance_id": "cf22fb696e90", "generation_result": [{"code": "def execute(self) -> pd.DataFrame\n\t\n    cached = self._cached()\n    if cached is not None:\n        return pd.read_parquet(cached)\n\n    cached = self._cached(include_additional_filters=True)\n    if cached is not None:\n        return pd.read_parquet(cached)\n\n    if isinstance(self._instance, pd.DataFrame):\n        return self._instance\n\n    self._instance = self._fetch_data()\n    return self._instance", "CodeBleu_score": 67.44021921187024}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    # Check if there is a cached version of the data\n    cached_path = self._cached(include_additional_filters=False)\n    if cached_path is not None:\n        return pd.read_parquet(cached_path)\n\n    cached_path = self._cached(include_additional_filters=True)\n    if cached_path is not None:\n        return pd.read_parquet(cached_path)\n\n    # If the instance variable is already a DataFrame, return it\n    if isinstance(self._data, pd.DataFrame):\n        return self._data\n\n    # Fetch the data and assign it to the instance variable\n    self._data = self._fetch_data()\n\n    # Return the fetched data as a DataFrame\n    return self._data\n\n", "CodeBleu_score": 52.426158413259486}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._cached():\n        return pd.read_parquet(self._cached())\n\n    if self._cached(include_additional_filters=True):\n        return pd.read_parquet(self._cached(include_additional_filters=True))\n\n    if isinstance(self._data, pd.DataFrame):\n        return self._data\n\n    self._data = self._fetch_data()\n    return self._data", "CodeBleu_score": 56.29267731984324}]}
{"instance_id": "21df5ecea95f", "generation_result": [{"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self.execute()\n    columns_str = \"|\".join(self._instance.columns)\n    formula_str = self._build_formula()\n    return hashlib.sha256(f\"{columns_str}{formula_str}\".encode()).hexdigest()\n\n", "CodeBleu_score": 77.04169204255827}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self.execute()\n    columns_str = \"|\".join(self._instance.columns)\n    formula_str = self.config.formula or \"\"\n    return hashlib.sha256(f\"{columns_str}{formula_str}\".encode()).hexdigest()\n\n", "CodeBleu_score": 76.06100455083963}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self.execute()\n    columns_str = \"|\".join(self._instance.columns)\n    return hashlib.sha256(\n        (columns_str + self._build_formula()).encode(\"utf-8\")\n    ).hexdigest()\n\n", "CodeBleu_score": 76.71157834883702}]}
{"instance_id": "27ee5f415000", "generation_result": [{"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, (list, dict)):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        df = FileImporter.import_from_file(df)\n    else:\n        raise ValueError(\n            f\"The input type {type(df)} is not supported. Please provide a pandas DataFrame, Series, list, dict, or a string representing a file path.\"\n        )\n    return df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.35568327634934}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        df = FileImporter.import_from_file(df)\n    else:\n        raise ValueError(\n            \"Input type not supported. Supported types are: pd.DataFrame, pd.Series, list, dict, str\"\n        )\n    return df", "CodeBleu_score": 48.571925714769705}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        df = FileImporter.import_from_file(df)\n    else:\n        raise ValueError(\"Input data type not supported.\")\n    return df", "CodeBleu_score": 45.59052798578315}]}
{"instance_id": "38f48a358606", "generation_result": [{"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}]}
{"instance_id": "8bddad2e31ca", "generation_result": [{"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    if \"name\" in extras:\n        name = extras[\"name\"]\n    else:\n        name = \"DataFrame\"\n    if \"description\" in extras:\n        description = extras[\"description\"]\n    else:\n        description = \"\"\n    csv = df.to_csv(index=False)\n    return f\"<{name} description='{description}' shape='{df.shape}'>", "CodeBleu_score": 32.80040373382466}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    if df.empty:\n        return \"\"\n\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    details = extras.get(\"details\", \"\")\n    content = df.to_csv(index=False)\n\n    xml_string = f\"<dataframe name='{name}' description='{description}' details='{details}'>", "CodeBleu_score": 33.91882392680589}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    df_name = df.name\n    df_description = df.description\n    df_dimensions = df.shape\n    df_content = df.to_csv()\n    df_details = f\"{df_dimensions[0]} rows, {df_dimensions[1]} columns\"\n    df_extras = extras\n    df_xml = f\"<DataFrame name='{df_name}' description='{df_description}' dimensions='{df_details}'>", "CodeBleu_score": 24.640261518893837}]}
{"instance_id": "5380bb60fd39", "generation_result": [{"code": "def convert_df_sql_connector_to_str\n\t\n    # Get the table name and description from the DataFrame metadata\n    table_name = df.get_name()\n    table_description = df.get_description()\n\n    # Construct the opening table tag with the table name and optional description\n    html = f\"<table name='{table_name}'>\"\n    if table_description:\n        html += f\"<description>{table_description}</description>\"\n\n    # Add the CSV representation of the DataFrame's head\n    html += df.get_head().to_csv()\n\n    # Close the table tag and return the complete HTML string\n    html += \"</table>\"\n    return html", "CodeBleu_score": 36.64171332345253}, {"code": "def convert_df_sql_connector_to_str\n\t\n    table_name = df.get_name()\n    description = df.get_description()\n    html = f\"<table name='{table_name}'>\"\n    if description:\n        html += f\"<caption>{description}</caption>\"\n    html += df.get_head().to_csv()\n    html += \"</table>\"\n    return html\n\n\n\n\n", "CodeBleu_score": 34.641850784995505}, {"code": "def convert_df_sql_connector_to_str\n\t\n    pass\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.4514239784450392e-14}]}
{"instance_id": "0afd995716c5", "generation_result": [{"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t", "CodeBleu_score": 11.79006085192698}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_data = self.convert_df_to_json(df, extras)\n    yaml_data = yaml.dump(json_data)\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return f\"<table>{yaml_data}</table>\"\n    return yaml_data", "CodeBleu_score": 65.49661404469978}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    df_json = self.convert_df_to_json(df, extras)\n    yaml_str = yaml.dump(df_json)\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return f\"<table>{yaml_str}</table>\"\n    return yaml_str\n\n", "CodeBleu_score": 66.01155589016119}]}
{"instance_id": "e2b90ebd4e5d", "generation_result": [{"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        if isinstance(self.value, (int, float)):\n            return True\n        else:\n            return False\n    elif expected_type == \"string\":\n        if isinstance(self.value, str):\n            return True\n        else:\n            return False\n    elif expected_type == \"dataframe\":\n        if isinstance(self.value, (pd.DataFrame, pd.Series)):\n            return True\n        else:\n            return False\n    elif expected_type == \"plot\":\n        if isinstance(self.value, str) and re.match(r\"^.*\\.(png|jpg|jpeg|gif)$\", self.value):\n            return True\n        elif isinstance(self.value, dict):\n            return True\n        else:\n            return False\n    else:\n        return False", "CodeBleu_score": 51.53690721339474}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self.value, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self.value, str) and re.match(\n            r\"^(file|data):\\/\\/(.+)\", self.value\n        )\n    else:\n        raise ValueError(f\"Invalid expected_type: {expected_type}\")\n\n", "CodeBleu_score": 55.39722327225532}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self.value, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self.value, str) or isinstance(self.value, dict)\n    else:\n        return False\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.95523499959072}]}
{"instance_id": "d95828fdcbcb", "generation_result": [{"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, metric=self.distance, **self.distance_params)\n        else:\n            if \"X\" in list(sig(self.distance).parameters.keys()):\n                return self.distance(X, **self.distance_params)\n            else:\n                return self.distance(X, X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.577859000507654}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(self.distance, X, **self.distance_params)\n        else:\n            sig = signature(self.distance)\n            if len(sig.parameters) == 1:\n                return self.distance(X, **self.distance_params)\n            else:\n                return self.distance(X, X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(self.distance, X, X2, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)", "CodeBleu_score": 28.676534225925714}, {"code": " def _distance(self, X, X2=None)\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.746268656716418}]}
{"instance_id": "497d73b298ee", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    # Check if X is a Series or a DataFrame\n    if isinstance(X, pd.Series):\n        # Reset the index of X\n        X_w_ix = X.reset_index(drop=True)\n        # Pivot the data to create a DataFrame with a single column\n        X_pivot = X_w_ix.pivot(columns=X_w_ix.index, values=X.name)\n        # Fill missing values with zeros\n        X_pivot_fill = X_pivot.fillna(0)\n        # Convert the pivoted DataFrame to a numpy array\n        X_np = X_pivot_fill.to_numpy()\n        # Calculate the length of each series\n        X_lengths = X_pivot_fill.notna().sum(axis=0).values\n        # Concatenate the lengths as the first column\n        X_np = np.concatenate((X_lengths.reshape(-1, 1), X_np), axis=1)\n        # Return the resulting numpy array\n        return X_np\n    elif isinstance(X, pd.DataFrame):\n        # Group the data by index and convert each group to a numpy array\n        X_np = np.array([group.to_numpy() for _, group in X.groupby(level=0)])\n        # Calculate the length of each series\n        X_lengths = X.groupby(level=0).size().values\n        # Concatenate the lengths as the first column\n        X_np = np.concatenate((X_lengths.reshape(-1, 1), X_np), axis=1)\n        # Return the resulting numpy array\n        return X_np\n    else:\n        # If X is not a Series or a DataFrame, raise a ValueError\n        raise ValueError(\"Input data X must be a pandas Series or DataFrame.\")", "CodeBleu_score": 39.63050238104847}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, np.ndarray):\n        if X.index.nlevels > 1:\n            X.index = X.index.remove_unused_levels()\n        if not X.index.is_lexsorted():\n            X = X.sort_index()\n        if isinstance(X, pd.Series):\n            X = X.to_frame()\n        if isinstance(X, pd.DataFrame):\n            if X.shape[1] > 1:\n                X_pivot = X.pivot(columns=X.columns[0])\n                X_pivot.columns = X_pivot.columns.droplevel(0)\n            else:\n                X_pivot = X\n            X_pivot = X_pivot.fillna(0)\n            X_flattened = X_pivot.to_numpy()\n            X_lengths = X_pivot.groupby(level=0).size()\n            X_flattened = np.concatenate([X_lengths.values.reshape(-1, 1), X_flattened], axis=1)\n        else:\n            X_flattened = X.to_numpy()\n    else:\n        X_flattened = X\n    return X_flattened\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.32725516551491}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, pd.DataFrame):\n        X = pd.DataFrame(X)\n    if self.equal_length:\n        if isinstance(X, pd.Series):\n            X = X.to_frame()\n        X_np = X.to_numpy()\n        X_np = X_np.reshape(X_np.shape[0], X_np.shape[1] * X_np.shape[2])\n    else:\n        X.columns = [\"dim_\" + str(x) for x in range(X.shape[1])]\n        X_w_ix = X.reset_index()\n        X_pivot = X_w_ix.pivot(\n            index=(\"index\"), columns=\"dim_0\", values=X.columns[1:]\n        )\n        X_pivot = X_pivot.fillna(0)\n        X_np = X_pivot.to_numpy()\n        series_lengths = X_w_ix.groupby(\"index\").size()\n        series_lengths = np.expand_dims(series_lengths, axis=1)\n        X_np = np.concatenate([series_lengths, X_np], axis=1)\n    return X_np", "CodeBleu_score": 38.96478011557493}]}
{"instance_id": "8798260a6f12", "generation_result": [{"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        raise TypeError(\n            f\"{obj} is not a class, please pass the class itself. Do not initialise \"\n            f\"an object and pass to is_sklearn_estimator.\"\n        )\n    return issubclass(obj, BaseEstimator) and not issubclass(obj, BaseObject)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.291972656487047}, {"code": "def is_sklearn_estimator(obj)\n\t\n    return isclass(obj) and issubclass(obj, SklearnBaseEstimator) and not issubclass(\n        obj, BaseObject\n    )\n\n", "CodeBleu_score": 14.606920579869897}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    if issubclass(obj, BaseEstimator) and not issubclass(obj, BaseObject):\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 24.266995535984936}]}
{"instance_id": "2ab2596d8520", "generation_result": [{"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        transformer_pipeline = other * self.transformer_pipeline\n        return SklearnRegressorPipeline(\n            regressor=self.regressor, transformer_pipeline=transformer_pipeline\n        )\n    return NotImplemented\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.387746350314075}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return SklearnRegressorPipeline(\n            regressor=self.regressor,\n            transformer=other * self.transformer,\n        )\n    return NotImplemented\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.87503917481588}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return SklearnRegressorPipeline(\n            self.regressor, self.transformer_pipeline * other\n        )\n    else:\n        return NotImplemented", "CodeBleu_score": 22.547556484832803}]}
{"instance_id": "5c1c6d14ca93", "generation_result": [{"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = df.columns.astype(str)\n    if df.columns.dtype == 'object':\n        return df\n    else:\n        df.columns = df.columns.astype(str)\n        return df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.60530954101816}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = df.columns.astype(str)\n    if df.columns.dtype != 'object':\n        df.columns = df.columns.astype(str)\n    return df\n\n\n\n\n", "CodeBleu_score": 50.04270967829365}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = df.columns.astype(str)\n    if not all(isinstance(col, str) for col in df.columns):\n        df.columns = df.columns.astype(str)\n    return df", "CodeBleu_score": 52.43519404087256}]}
{"instance_id": "d5e567c20361", "generation_result": [{"code": "def predict(self, X)\n\t\n\n    # Check if the model is fitted\n    check_is_fitted(self)\n\n    # Initialize the random state\n    rng = check_random_state(self.random_state)\n\n    # Obtain the predicted probabilities for each sample\n    proba = self.predict_proba(X)\n\n    # Select the indices of the maximum probability values for each sample\n    max_idx = np.argmax(proba, axis=1)\n\n    # Randomly choose one of the indices for each sample\n    max_idx = rng.choice(max_idx, size=len(max_idx))\n\n    # Map the chosen indices to the corresponding class labels\n    y_pred = self.classes_[max_idx]\n\n    return y_pred\n\n\n", "CodeBleu_score": 31.497521785113282}, {"code": "def predict(self, X)\n\t\n\n    rng = check_random_state(self.random_state)\n    proba = self.predict_proba(X)\n    random_state = check_random_state(self.random_state)\n    y_pred = [\n        self.classes_[int(rng.choice(np.flatnonzero(prob == prob.max())))]\n        for prob in proba\n    ]\n    return self.classes_.take(np.array(y_pred))\n\n\n\n\n", "CodeBleu_score": 55.466733475038055}, {"code": "def predict(self, X)\n\t\n\n    rng = check_random_state(self.random_state)\n    proba = self.predict_proba(X)\n    max_proba = proba.max(axis=1)\n    max_proba_indices = np.flatnonzero(proba == max_proba[:, np.newaxis])\n    random_max_proba_indices = rng.choice(\n        max_proba_indices, size=len(max_proba_indices), replace=True\n    )\n    y_pred = self.classes_[random_max_proba_indices % self.n_classes_]\n    return y_pred\n\n", "CodeBleu_score": 35.36628962880661}]}
{"instance_id": "210b60dffd55", "generation_result": [{"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n\n    # transform the data by applying the corresponding pca to each group and concatenating the results\n    X_transformed = np.concatenate(\n        [\n            pca.transform(X[:, group])\n            for pca, group in zip(pcas, groups)\n        ],\n        axis=1,\n    )\n\n    # replace missing values with 0\n    X_transformed = np.nan_to_num(X_transformed)\n\n    # compute class probabilities\n    y_proba = clf.predict_proba(X_transformed)\n\n    # if the number of predicted classes does not match the expected number of classes, adjust the probabilities to match the expected class structure\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba = np.concatenate(\n            (y_proba, np.zeros((y_proba.shape[0], self.n_classes_ - y_proba.shape[1]))),\n            axis=1,\n        )\n\n    return y_proba", "CodeBleu_score": 28.734032304175784}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.236467236467236}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n\n    # transform the data\n    X_transformed = []\n    for group in groups:\n        X_transformed.append(pcas[group].transform(X[:, group]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n\n    # replace missing values with 0\n    X_transformed = np.nan_to_num(X_transformed)\n\n    # predict probabilities\n    y_probas = clf.predict_proba(X_transformed)\n\n    # adjust probabilities\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas = self._adjust_probas(y_probas)\n\n    return y_probas\n\n\n", "CodeBleu_score": 31.348236874657264}]}
{"instance_id": "9436ee0860bb", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists", "CodeBleu_score": 89.06183340968327}, {"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists", "CodeBleu_score": 89.06183340968327}, {"code": "def predict_proba(self, X)\n\t\n\n", "CodeBleu_score": 0.7380952380952381}]}
{"instance_id": "d7cb1cb66840", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n\n    scitype = get_tag(self.transformers_, \"scitype:transform-output\")\n\n    if scitype == \"Primitives\":\n        Xt = convert_to(X, \"numpy3D\")\n    elif scitype == \"Series\":\n        Xt = convert_to(X, \"numpyflat\")\n    else:\n        raise TypeError(\n            f\"unexpected scitype {scitype} for transformers in this pipeline\"\n        )\n\n    return Xt\n\n", "CodeBleu_score": 40.856296028305}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    scitype = get_tag(self.transformers_, \"scitype:transform-output\")\n    if scitype == \"Primitives\":\n        return convert_to(X, \"numpy2D\", \"Series\")\n    elif scitype == \"Series\":\n        return convert_to(X, \"numpyflat\", \"Panel\")\n    else:\n        raise TypeError(\n            f\"unexpected output scitype: {scitype}, expected: Primitives or Series\"\n        )", "CodeBleu_score": 31.576580591139646}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n\n", "CodeBleu_score": 1.1151960784313726}]}
{"instance_id": "497cb75f2b4d", "generation_result": [{"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = {}\n    for key, value in estimator.get_params().items():\n        if key.endswith(\"random_state\") or key.endswith(\"seed\"):\n            value = random_state.randint(np.iinfo(np.int32).max)\n            params[key] = value\n    if params:\n        estimator.set_params(**params)\n    return estimator\n\n", "CodeBleu_score": 41.124260370353994}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = dict()\n    for key, value in estimator.get_params().items():\n        if key.endswith(\"random_state\") or key.endswith(\"seed\"):\n            params[key] = random_state.randint(np.iinfo(np.int32).max)\n    if params:\n        estimator.set_params(**params)\n    return estimator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.97678259521566}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    to_set = {}\n    for name, param in six.iteritems(estimator.get_params(deep=False)):\n        if (\n            name.endswith(\"random_state\")\n            or name.endswith(\"seed\")\n            or name in [\"random_state\", \"seed\"]\n        ):\n            to_set[name] = random_state.randint(np.iinfo(np.int32).max)\n    if to_set:\n        estimator.set_params(**to_set)\n\n", "CodeBleu_score": 51.309727110493355}]}
{"instance_id": "59ffd1d596a1", "generation_result": [{"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n\n    transformed = np.empty((n_instances, n_intervals * 3))\n\n    for i, interval in enumerate(intervals):\n        start, end = interval\n        X_slice = X[:, start:end]\n        means = np.mean(X_slice, axis=1)\n        stds = np.std(X_slice, axis=1)\n        slopes = _slope(X_slice, axis=1)\n        transformed[:, i * 3] = means\n        transformed[:, i * 3 + 1] = stds\n        transformed[:, i * 3 + 2] = slopes\n\n    return transformed.transpose()\n\n", "CodeBleu_score": 39.25558924793926}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n\n    transformed = np.empty((n_instances, 3 * n_intervals))\n\n    for i, (start, end) in enumerate(intervals):\n        sub_arr = X[:, start:end]\n        means = np.mean(sub_arr, axis=1)\n        stds = np.std(sub_arr, axis=1)\n        slopes = _slope(sub_arr.T)\n        transformed[:, 3 * i] = means\n        transformed[:, 3 * i + 1] = stds\n        transformed[:, 3 * i + 2] = slopes\n\n    return transformed.T", "CodeBleu_score": 35.74444808524281}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n    transformed = np.empty((n_instances, 3 * n_intervals))\n\n    for interval_id, interval in enumerate(intervals):\n        X_interval = X[interval]\n\n        # mean\n        X_interval_mean = np.mean(X_interval, axis=1)\n        transformed[:, 3 * interval_id] = X_interval_mean\n\n        # std dev\n        X_interval_std = np.std(X_interval, axis=1)\n        transformed[:, 3 * interval_id + 1] = X_interval_std\n\n        # slope\n        X_interval_slope = _slope(X_interval, axis=1)\n        transformed[:, 3 * interval_id + 2] = X_interval_slope\n\n    return transformed.T\n\n", "CodeBleu_score": 35.110228369567416}]}
{"instance_id": "5a01594eebfb", "generation_result": [{"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n    self.plot(plot, *args, **plot_params)\n    _apply_ax_operations(self.ax, ax_op_before)\n    self.configure(**configuration)\n    getattr(self, annotation_func)(**annotation_params)\n    _apply_ax_operations(self.ax, ax_op_after)\n    return self.get_output(**annotate_params)\n\n", "CodeBleu_score": 52.82085723098413}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n\n    # Initialize annotation and operation parameters\n    annotation_params.update({\"annotate_params\": annotate_params})\n    annotation_params.update(kwargs)\n    annotation_params.update({\"configuration\": configuration})\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    self.new_plot(plot, plot_params, *args, **kwargs)\n    _apply_ax_operations(self.ax, ax_op_before)\n\n    # Configure and annotate the plot based on provided configuration and annotation functions\n    self.configure(**configuration)\n    getattr(self, annotation_func)(**annotation_params)\n\n    # Apply post-plot axis operations\n    _apply_ax_operations(self.ax, ax_op_after)\n\n    # Return the output of the plotting process\n    return self.get_output()", "CodeBleu_score": 54.55791911200759}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n\n    self.plot(plot, plot_params, *args, **kwargs)\n    _apply_ax_operations(self.ax, ax_op_before)\n    self.configure(**configuration)\n    getattr(self, annotation_func)(**annotation_params)\n    _apply_ax_operations(self.ax, ax_op_after)\n    return self.get_output()\n\n", "CodeBleu_score": 54.293097618903595}]}
{"instance_id": "b5b17d312c74", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise NotFittedError(\"This instance is not fitted yet. Call 'fit' with appropriate arguments before using this method.\")\n    X = check_array(X)\n    if X.shape[1] != self._n_features_in:\n        raise ValueError(f\"X has {X.shape[1]} features per sample; expecting {self._n_features_in}.\")\n    scores = self.execute(X)\n    probs = self._transformer(scores)\n    return np.vstack([1 - probs, probs]).T\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.23715745730454}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise NotFittedError(\"This %(name)s instance is not fitted yet. \"\n                              \"Call 'fit' with appropriate arguments before \"\n                              \"using this method.\"\n                              % {'name': type(self).__name__})\n\n    X = check_array(X, accept_sparse='csr')\n    if X.shape[1] != self._expected_n_features:\n        raise ValueError(\"X has %d features per sample; expecting %d\"\n                         % (X.shape[1], self._expected_n_features))\n\n    scores = self.execute(X)\n    scores = np.vstack((-scores, scores)).T / 2.\n    scores = 1. / (1. + np.exp(scores))\n    return np.hstack((1 - scores, scores))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.65144009735583}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise NotFittedError(\"This %(name)s instance is not fitted yet\" % {'name': type(self).__name__})\n    X = check_array(X, accept_sparse=True)\n    if X.shape[1] != self.n_features_in_:\n        raise ValueError(\"X has %d features per sample; expecting %d\"\n                         % (X.shape[1], self.n_features_in_))\n    scores = self.execute(X)\n    scores = scores.reshape(-1, 1)\n    scores = np.hstack([-scores, scores])\n    probas = softmax(scores)\n    return probas", "CodeBleu_score": 47.047060696977674}]}
{"instance_id": "83f71c959df7", "generation_result": [{"code": "def point_mutation(self, random_state)\n\t\n\n    # Create a copy of the program\n    mutated_program = copy.deepcopy(self)\n\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    node_indices = list(range(len(mutated_program)))\n    modified_nodes = np.where(random_state.uniform(size=len(mutated_program)) < self.mutation_prob)[0]\n\n    # For each node to be mutated\n    for node_index in modified_nodes:\n        # If the node is a function\n        if isinstance(mutated_program[node_index], Function):\n            # Find a valid replacement function with the same arity\n            replacement_function = self.function_set[random_state.randint(len(self.function_set))]\n            while replacement_function.arity != mutated_program[node_index].arity:\n                replacement_function = self.function_set[random_state.randint(len(self.function_set))]\n            # Update the node\n            mutated_program[node_index] = replacement_function\n        # If the node is a terminal\n        else:\n            # Replace it with either a constant or a variable\n            if random_state.uniform() < 0.5:\n                # If the constant range is not None, replace with a constant within the range\n                if self.constant_range is not None:\n                    mutated_program[node_index] = random_state.uniform(*self.constant_range)\n                # Otherwise, replace with a constant within the range (-1, 1)\n                else:\n                    mutated_program[node_index] = random_state.uniform(-1, 1)\n            else:\n                # Replace with a variable from the feature set\n                mutated_program[node_index] = Feature(random_state.randint(self.num_features))\n\n    # Return the mutated program and the list of modified node indices\n    return mutated_program, modified_nodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.723562322049037}, {"code": "def point_mutation(self, random_state)\n\t\n\n    # Create a copy of the program\n    mutated_program = copy.deepcopy(self)\n\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    nodes_to_modify = np.where(random_state.uniform(size=len(mutated_program)) < self.mutation_probability)[0]\n\n    # For each node to be mutated\n    for node_idx in nodes_to_modify:\n        # If the node is a function\n        if isinstance(mutated_program[node_idx], Function):\n            # Find a valid replacement function with the same arity\n            replacement_function = random_state.choice(self.function_set[mutated_program[node_idx].arity])\n            # Update the node with the new function\n            mutated_program[node_idx] = replacement_function\n        # If the node is a terminal\n        else:\n            # Replace it with either a constant or a variable, ensuring valid replacement according to the defined constant range and number of features\n            if random_state.randint(0, 2) == 0:\n                # Replace with a constant\n                mutated_program[node_idx] = random_state.uniform(self.constant_range[0], self.constant_range[1])\n            else:\n                # Replace with a variable\n                mutated_program[node_idx] = random_state.randint(0, self.num_features)\n\n    # Return the mutated program and the list of modified node indices\n    return mutated_program, nodes_to_modify.tolist()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.38881682591527}, {"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    program_copy = copy.deepcopy(self)\n\n    # Identify nodes to modify\n    node_indices = np.arange(len(program_copy))\n    num_nodes = len(node_indices)\n    num_to_modify = random_state.randint(0, num_nodes)\n    node_indices_to_modify = random_state.choice(node_indices, size=num_to_modify, replace=False)\n\n    # Modify selected nodes\n    modified_nodes = []\n    for node_index in node_indices_to_modify:\n        node = program_copy[node_index]\n\n        if isinstance(node, Function):\n            # Find a valid replacement function with the same arity\n            replacement_function = self._find_valid_replacement_function(node, random_state)\n\n            if replacement_function is not None:\n                # Update the node with the new function\n                program_copy[node_index] = replacement_function\n                modified_nodes.append(node_index)\n\n        elif isinstance(node, Terminal):\n            # Replace with a constant or variable\n            if random_state.uniform() < 0.5:\n                # Replace with a constant\n                constant_value = random_state.uniform(self.constant_range[0], self.constant_range[1])\n                program_copy[node_index] = Constant(constant_value)\n            else:\n                # Replace with a variable\n                variable_index = random_state.randint(0, self.num_features)\n                program_copy[node_index] = Feature(variable_index)\n\n            modified_nodes.append(node_index)\n\n    return program_copy, modified_nodes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.95314742530786}]}
{"instance_id": "f1853251e671", "generation_result": [{"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    offset = get_offset(offset)\n\n    # Calculate Result\n    if close is not None:\n        if mamode == \"ema\":\n            MA = close.ewm(span=length, min_periods=length).mean()\n        else:\n            MA = close.rolling(length).mean()\n\n        BIAS = 100 * (close - MA) / close\n        if offset != 0:\n            BIAS = BIAS.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        BIAS.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        BIAS.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    BIAS.name = f\"BIAS_{length}\"\n    BIAS.category = \"momentum\"\n\n    return BIAS\n\n", "CodeBleu_score": 53.50299015491379}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode if isinstance(mamode, str) else \"sma\"\n    offset = get_offset(offset)\n\n    # Calculate Result\n    if close is not None:\n        if mamode == \"ema\":\n            ma = close.ewm(span=length, min_periods=length).mean()\n        elif mamode == \"sma\":\n            ma = close.rolling(length, min_periods=length).mean()\n        else:\n            ma = close.rolling(length, min_periods=length).sum() / length\n\n        bias = (close - ma) / ma\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}\"\n    bias.category = \"momentum\"\n\n    return bias", "CodeBleu_score": 58.21181408029131}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    offset = int(offset) if offset and offset != 0 else 0\n\n    # Calculate Result\n    if mamode == \"sma\":\n        ma = close.rolling(length).mean()\n    else:\n        ma = close.rolling(length).mean()\n\n    bias = (close / ma) - 1\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}_{mamode}\"\n    bias.category = \"momentum\"\n\n    return bias\n\n", "CodeBleu_score": 58.877724094235596}]}
{"instance_id": "77825be37c24", "generation_result": [{"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        url = ''\n        if broker == 'hb':\n            url = 'https://api.huobi.pro/market/history/kline?period={}&size={}&symbol={}usdt'.format(ktype, size, code)\n        elif broker == 'okx':\n            url = 'https://www.okx.com/api/v5/market/history-candles?instId={}-USDT&bar={}&limit={}'.format(code, ktype, size)\n        elif broker == 'binance':\n            url = 'https://api.binance.com/api/v3/klines?symbol={}USDT&interval={}&limit={}'.format(code, ktype, size)\n        else:\n            print('\u6682\u4e0d\u652f\u6301\u7684\u4ea4\u6613\u6240')\n            return\n        headers = {'Content-Type': 'application/json', 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.132 Safari/537.36'}\n        response = requests.get(url, headers=headers)\n        js = json.loads(response.text)\n        if broker == 'hb':\n            js = js['data']\n        elif broker == 'okx':\n            js = js['data']\n        elif broker == 'binance':\n            js = js\n        df = pd.DataFrame(js)\n        if broker == 'hb':\n            df.columns = ['id', 'open', 'close', 'high', 'low', 'amount', 'vol', 'count', 'bid', 'ask']\n            df['date'] = df['id'].apply(int2time)\n        elif broker == 'okx':\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'volume_ccy', 'volume_ccy_usd']\n        elif broker == 'binance':\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume',", "CodeBleu_score": 31.678036202876857}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        url = 'https://{0}.huobi.com/staticmarket/ticker_{1}_{2}.html'.format(\n            broker, code, ktype)\n        if broker == 'hb':\n            js = json.loads(requests.get(url).text)\n            df = pd.DataFrame(js['data'])\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n            df['date'] = df['date'].map(int2time)\n            df['date'] = pd.to_datetime(df['date'])\n            df = df.set_index('date')\n            df = df.sort_index()\n            return df\n        else:\n            return None\n    except Exception:\n        print(traceback.print_exc())\n\n\n\n\n\n", "CodeBleu_score": 34.83685039641925}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        if broker == 'hb':\n            url = 'https://api.huobi.pro/market/history/kline?period={}&size={}&symbol={}usdt'.format(ktype, size, code)\n            js = _get_data(url)\n            if 'data' in js:\n                js = js['data']\n                df = pd.DataFrame(js)\n                df.columns = ['id', 'open', 'high', 'low', 'close', 'amount', 'vol', 'count', 'bid', 'ask', 'bidSz', 'askSz', 'ts']\n                df['date'] = df['ts'].apply(int2time)\n                if ktype == '1min':\n                    df['date'] = df['date'].apply(lambda x: x[:-3])\n                elif ktype == '5min':\n                    df['date'] = df['date'].apply(lambda x: x[:-3])\n                elif ktype == '15min':\n                    df['date'] = df['date'].apply(lambda x: x[:-3])\n                elif ktype == '30min':\n                    df['date'] = df['date'].apply(lambda x: x[:-3])\n                elif ktype == '60min':\n                    df['date'] = df['date'].apply(lambda x: x[:-3])\n                elif ktype == '1day':\n                    df['date'] = df['date'].apply(lambda x: x[:-9])\n                elif ktype == '1mon':\n                    df['date'] = df['date'].apply(lambda x: x[:-9])\n                elif ktype == '1week':\n                    df['date'] = df['date'].apply(lambda x: x[:-9])\n                elif ktype == '1year':\n                    df['date'] = df['date'].apply(lambda x: x[:-9])\n                df['date'] = pd.to_datetime(df['date'])\n                return df\n            else:\n                print(js)\n                return None\n        elif broker == 'okx':\n            ktype = ktype.strip('m')\n            url = 'https://www.ok", "CodeBleu_score": 37.446382947178876}]}
{"instance_id": "c6552851da8a", "generation_result": [{"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        data = _get_data(broker, code, size)\n        if broker == 'hb':\n            ask = pd.DataFrame(data['tick']['asks'])\n            ask['timestamp'] = int2time(data['ts'] / 1000)\n            bid = pd.DataFrame(data['tick']['bids'])\n            bid['timestamp'] = int2time(data['ts'] / 1000)\n        else:\n            ask = pd.DataFrame(data['asks'])\n            ask['timestamp'] = int2time(data['timestamp'])\n            bid = pd.DataFrame(data['bids'])\n            bid['timestamp'] = int2time(data['timestamp'])\n        data = {'ask': ask, 'bid': bid}\n        df = pd.Panel(data)\n        return df\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 38.48643739428351}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        js = _get_data(f'https://api.huobi.pro/market/history/trade?symbol={code}usdt&size={size}')\n        if broker == 'hb':\n            ask = pd.DataFrame(js['tick']['asks'])\n            ask.columns = ['price', 'volume']\n            ask['timestamp'] = int2time(js['ts'] / 1000)\n            bid = pd.DataFrame(js['tick']['bids'])\n            bid.columns = ['price', 'volume']\n            bid['timestamp'] = int2time(js['ts'] / 1000)\n            data = {'ask': ask, 'bid': bid}\n            df = pd.Panel(data)\n            return df\n    except Exception:\n        print(traceback.print_exc())\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.124802663226774}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        js = _get_data(broker, code, size)\n        if broker == 'hb':\n            df_ask = pd.DataFrame(js['asks'])\n            df_ask['timestamp'] = int2time(js['timestamp'])\n            df_bid = pd.DataFrame(js['bids'])\n            df_bid['timestamp'] = int2time(js['timestamp'])\n            df_ask = df_ask.set_index('timestamp')\n            df_bid = df_bid.set_index('timestamp')\n            df_ask.columns = ['ask_' + str(i) for i in range(1, 6)]\n            df_bid.columns = ['bid_' + str(i) for i in range(1, 6)]\n            d = {'ask': df_ask, 'bid': df_bid}\n            df = pd.Panel(d)\n            return df\n        else:\n            df_ask = pd.DataFrame(js['asks'])\n            df_ask['timestamp'] = int2time(js['timestamp'] / 1000)\n            df_bid = pd.DataFrame(js['bids'])\n            df_bid['timestamp'] = int2time(js['timestamp'] / 1000)\n            df_ask = df_ask.set_index('timestamp')\n            df_bid = df_bid.set_index('timestamp')\n            df_ask.columns = ['ask_' + str(i) for i in range(1, 6)]\n            df_bid.columns = ['bid_' + str(i) for i in range(1, 6)]\n            d = {'ask': df_ask, 'bid': df_bid}\n            df = pd.Panel(d)\n            return df\n    except Exception:\n        print(traceback.print_exc())", "CodeBleu_score": 39.2288755112003}]}
{"instance_id": "8b5fee723398", "generation_result": [{"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = 'https://api.hbdm.com/market/history/trade?symbol={}{}'.format(code, broker)\n    if broker == 'hb':\n        url = 'https://api.hbdm.com/market/history/trade?symbol={}{}'.format(code, broker)\n    elif broker == 'ok':\n        url = 'https://www.okcoin.cn/api/spot/v3/instruments/{}/{}-USDT/history/candles?granularity=60&start=2013-10-01T00:00:00.000Z&end=2013-10-02T00:00:00.000Z'.format(code, code)\n    elif broker == 'chbtc':\n        url = 'https://api.chbtc.com/data/v1/kline?symbol={}_{}&type=1min&size=1000'.format(code, broker)\n    else:\n        url = 'https://api.hbdm.com/market/history/trade?symbol={}{}'.format(code, broker)\n    print(url)\n    js = _get_data(url)\n    if js is not None:\n        if broker == 'hb':\n            data = pd.DataFrame(js['data'])\n            data = data[['id', 'ts', 'data']]\n            data.columns = ['tid', 'datetime', 'data']\n            data['datetime'] = data['datetime'].apply(int2time)\n        elif broker == 'ok':\n            data = pd.DataFrame(js)\n            data = data[['candle_begin_time', 'data']]\n            data.columns = ['datetime', 'data']\n            data['datetime'] = data['datetime'].apply(int2time)\n        elif broker == 'chbtc':\n            data = pd.DataFrame(js['data'])\n            data = data[['id', 'timestamp', 'data']]\n            data.columns = ['tid', 'datetime', 'data']\n            data['datetime'] = data['datetime", "CodeBleu_score": 35.395642655012}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = 'https://api.hbdm.com/market/history/trade?symbol=%s%s&size=200' % (code, broker)\n    if broker == 'hb':\n        url = 'https://api.hbdm.com/market/history/trade?symbol=%s%s&size=200' % (code, broker)\n    elif broker == 'ok':\n        url = 'https://www.okcoin.cn/api/spot/v3/instruments/%s-USDT/trades?size=200' % code\n    elif broker == 'chbtc':\n        url = 'https://api.chbtc.com/data/v1/trades?currency=%s&since=%s' % (code, broker)\n    else:\n        return None\n    data = pd.DataFrame(_get_data(url))\n    if broker == 'hb':\n        data = data[['id', 'ts', 'data']]\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n        data['datetime'] = data['datetime'].apply(int2time)\n    elif broker == 'ok':\n        data = data[['trade_id', 'created_at', 'price', 'amount', 'side']]\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n        data['type'] = data['type'].apply(lambda x: 'sell' if x == 'sell' else 'buy')\n    elif broker == 'chbtc':\n        data = data[['date', 'price', 'amount', 'tid', 'type']]\n        data.columns = ['datetime', 'price', 'amount', 'tid', 'type']\n    data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n    return data\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.75699268839748}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    data = _get_data(broker, code)\n    if data is not None:\n        if broker == 'hb':\n            df = pd.DataFrame(data['data'])\n            df = df[['id', 'ts', 'price', 'amount', 'direction']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n        elif broker in ['ok', 'chbtc']:\n            df = pd.DataFrame(data['trades'])\n            df = df[['tid', 'date', 'price', 'amount', 'type']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n        else:\n            df = pd.DataFrame(data)\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        df['type'] = df['type'].apply(lambda x: 'buy' if x == 'bid' else 'sell')\n        return df\n", "CodeBleu_score": 53.27508631039461}]}
{"instance_id": "25e0a134c45b", "generation_result": [{"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_console(url)\n    try:\n        response = urlopen(url)\n        text = response.read()\n        text = text.decode('utf-8')\n        reg = re.compile(r'var r = (.*?);')\n        text = reg.findall(text)[0]\n        text = text.replace('null', 'None')\n        text = text.replace('true', 'True')\n        text = text.replace('false', 'False')\n        items = text.split(';')\n        count = 0\n        for i in range(len(items)):\n            if count == 0:\n                items[i] = items[i] + ':'\n            elif count == 1:\n                items[i] = items[i] + ','\n            elif count == 2:\n                items[i] = items[i] + '}'\n            count = count + 1\n        text = ''.join(items)\n        js = json.loads(text)\n        fund_df = pd.DataFrame(js['Data']['LSJZList'])\n        if fund_type == 'open':\n            fund_df.columns = ['fund_date', 'dwjz', 'ljjz', 'jzzzl', 'sgzt', 'shzt']\n        else:\n            fund_df.columns = ['fund_date', 'dwjz', 'ljjz', 'jzzzl', 'bz', 'rzdfy', 'sgzt', 'shzt']\n        fund_df.fillna(value='0', inplace=True)\n        return fund_df\n    except Exception as e:\n        print(e)", "CodeBleu_score": 46.406925603091324}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    print(urlopen)\n    print(ct._write_console)\n    print(json.loads)\n    print(read)\n    print(fund_df.fillna)\n    print(text.decode)\n    print(reg.sub)\n    print(str)\n    print(split)\n    print(text.replace)\n    print(pd.read_json)\n    print(Request)\n    print(text.split)\n    print(json.dumps)\n    print(re.compile)\n    print(pd.DataFrame)\n\n    try:\n        print(url)\n        response = urlopen(url)\n        text = response.read().decode('utf-8')\n        text = reg.sub('', text)\n        text = str(text)\n        text = text.split('=')[1]\n        text = text.replace(';', '')\n        js = json.loads(text)\n        if fund_type == 'open':\n            fund_df = pd.DataFrame(js['Data']['LSJZList'])\n            fund_df.set_index(['FSRQ'], inplace=True)\n            fund_df.rename(columns={'DWJZ': '\u5355\u4f4d\u51c0\u503c', 'LJJZ': '\u7d2f\u8ba1\u51c0\u503c', 'JZZZL': '\u51c0\u503c\u589e\u957f\u7387', 'SGZT': '\u7533\u8d2d\u72b6\u6001', 'SHZT': '\u8d4e\u56de\u72b6\u6001'}, inplace=True)\n            fund_df = fund_df.fillna(0)\n            return fund_df\n        else:\n            fund_df = pd.DataFrame(js['Data']['LSJZList'])\n            fund_df.set_index(['FSRQ'], inplace=True)\n            fund_df.rename(columns={'DWJZ': '\u5355\u4f4d\u51c0\u503c', 'LJJZ': '\u7d2f\u8ba1\u51c0\u503c', 'JZZZL': '\u51c0\u503c\u589e\u957f\u7387', 'SGZT': '\u7533\u8d2d\u72b6\u6001', 'SHZT': '\u8d4e\u56de\u72b6\u6001'}, inplace=True)\n            fund_df = fund_df.fillna(0)\n            return fund_df\n    except Exception as e:\n        print(e)\n\n\n", "CodeBleu_score": 39.182224931914504}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_console('Retrieving fund data...')\n    try:\n        response = urlopen(url)\n    except:\n        ct._write_console('Error retrieving fund data.')\n        return\n\n    text = response.read()\n    text = text.decode('utf-8')\n    reg = re.compile(r'var\\s+json\\s+=\\s+(.*?);')\n    text = reg.findall(text)[0]\n    text = text.replace('jsonpgz', 'json')\n    text = text.split('", "CodeBleu_score": 23.50303737005413}]}
{"instance_id": "401d18e122d8", "generation_result": [{"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        f = get_future_daily_cffex\n    else:\n        f = get_future_daily_cffex\n    if start == None:\n        start = today\n    else:\n        start = ct.convert_date(start)\n    if end == None:\n        end = today\n    else:\n        end = ct.convert_date(end)\n    df_list = []\n    for i in range((end - start).days + 1):\n        date = start + datetime.timedelta(days = i)\n        data = f(date, market = market.upper())\n        if len(data) > 0:\n            df_list.append(data)\n    if len(df_list) > 0:\n        return pd.concat(df_list)\n\n\n\n\n\n", "CodeBleu_score": 46.02588496307263}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        get_daily = get_cffex_daily\n    elif market == 'CZCE':\n        get_daily = get_czce_daily\n    else:\n        raise ValueError('Invalid market parameter')\n\n    if start is None:\n        start = ct.convert_date(datetime.date.today())\n    else:\n        start = ct.convert_date(start)\n\n    if end is None:\n        end = ct.convert_date(datetime.date.today())\n    else:\n        end = ct.convert_date(end)\n\n    df_list = []\n\n    for i in range((end - start).days + 1):\n        date = start + datetime.timedelta(days=i)\n        df = get_daily(date, market=market)\n        if len(df) > 0:\n            df_list.append(df)\n\n    if len(df_list) > 0:\n        return pd.concat(df_list)\n    else:\n        return None\n\n", "CodeBleu_score": 52.119659592448855}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market.upper() == 'CFFEX':\n        f = get_daily_cffex\n    else:\n        print('Market not supported')\n        return\n    start, end = ct.convert_date(start, end)\n    df_list = []\n    for date in pd.date_range(start, end, freq = 'D'):\n        data = f(date)\n        if len(data) > 0:\n            df_list.append(data)\n    return pd.concat(df_list)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.147150080885925}]}
{"instance_id": "697779825988", "generation_result": [{"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n\n    url = 'https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=f5eef3421c602c6cb7ea224104795888&targetDt=20230216'\n    for i in range(retry_count):\n        try:\n            response = urlopen(url)\n            data = json.loads(response.read())\n            df = pd.DataFrame(data['boxOfficeResult']['dailyBoxOfficeList'])\n            df.drop(['MovieImg','mId'],axis=1,inplace=True)\n            df['date'] = du.get_now('%Y%m%d')\n            if len(df) > 0:\n                return df\n        except:\n            pass\n        time.sleep(pause)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.44286719972621}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    df = None\n    for i in range(retry_count):\n        try:\n            url = 'https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=f5eef3421c602c6cb7ea224104795888&targetDt=20230228'\n            with urlopen(url) as response:\n                lines = response.read()\n                data = json.loads(lines.decode('utf-8'))\n                df = pd.DataFrame(data['boxOfficeResult']['dailyBoxOfficeList'])\n                df.drop(['MovieImg','mId'],axis=1,inplace=True)\n                df['date'] = du.get_now('%Y-%m-%d')\n                return df\n        except Exception as e:\n            print(e)\n            time.sleep(pause)\n    return df\n\n\n", "CodeBleu_score": 39.46725971169967}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n\n    url = 'https://www.kobis.or.kr/kobisopenapi/webservice/rest/boxoffice/searchDailyBoxOfficeList.json?key=f5eef3421c602c6cb7ea224104795888&targetDt=20230201'\n    for i in range(retry_count):\n        try:\n            with urlopen(url) as response:\n                lines = response.read()\n                data = json.loads(lines)\n                df = pd.DataFrame(data['boxOfficeResult']['dailyBoxOfficeList'])\n                df = df.drop(['MovieImg','mId'],axis=1)\n                df['timestamp'] = du.get_now()\n                if len(df) > 0:\n                    return df\n        except Exception as e:\n            print(e)\n            time.sleep(pause)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.18140844464377}]}
