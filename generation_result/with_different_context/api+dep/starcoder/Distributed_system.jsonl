{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    if self._orig_kazoo_connect is None:\n        self._orig_kazoo_connect = self._kazoo_client.KazooClient.connect\n    return self._orig_kazoo_connect(self, *args)\n\n", "CodeBleu_score": 47.138226404305996}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    start = time.time()\n    ret = self._orig_kazoo_connect(*args)\n    end = time.time()\n    loop_wait = self.loop_wait - 2\n    if loop_wait < 2:\n        loop_wait = 2\n    return (loop_wait * 1000, ret)\n", "CodeBleu_score": 51.57613064176804}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    orig_wait = self._loop_wait\n    self._loop_wait = max(self._loop_wait - 2, 2)\n    start = time.perf_counter()\n    ret = self._orig_kazoo_connect(*args)\n    end = time.perf_counter()\n    self._loop_wait = orig_wait\n    return (self._loop_wait * 1000, ret)\n", "CodeBleu_score": 54.240804628469895}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    if self._config is not None:\n        self._config.set_dynamic_configuration(config)\n    if config.loop_wait != self._config.loop_wait:\n        self._loop_wait = config.loop_wait\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self._loop_wait / 2.0)\n    if config.ttl != self._config.ttl:\n        if self.set_ttl(config.ttl):\n            self.restart()\n    self._config = config\n\n", "CodeBleu_score": 42.44741406682097}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, Config):\n        config = Config(config)\n    if config.retry_timeout != self._retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n    if config.ttl != self._ttl:\n        if self.set_ttl(config.ttl):\n            if self._loop_wait != config.loop_wait and isinstance(self._handler, PatroniSequentialThreadingHandler):\n                self.set_connect_timeout(config.loop_wait)\n        else:\n            self.set_retry_timeout(self._retry_timeout)\n    if config.loop_wait != self._loop_wait:\n        self._loop_wait = config.loop_wait\n        if isinstance(self._handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n\n", "CodeBleu_score": 39.12237660561115}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.config\n    if self.config != config:\n        self.config = config\n        self.set_retry_timeout(config['retry_timeout'])\n        self.set_ttl(config['ttl'])\n        if self.loop_wait != config['loop_wait'] and isinstance(self._client, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config['loop_wait'])\n\n", "CodeBleu_score": 38.09842771150276}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    self._logger.debug('Loading cluster configuration from %s', path)\n    self._logger.debug('Loading configuration')\n    config = self.get_node(path + self._CONFIG)\n    if not config:\n        raise RuntimeError('Configuration not found')\n    config = ClusterConfig.from_node(config[0])\n    self._logger.debug('Loading timeline history')\n    history = self.get_node(path + self._HISTORY)\n    if not history:\n        raise RuntimeError('Timeline history not found')\n    history = TimelineHistory.from_node(history[0])\n    self._logger.debug('Loading synchronization state')\n    sync = self.get_node(path + self._SYNC)\n    if not sync:\n        raise RuntimeError('Synchronization state not found')\n    sync = SyncState.from_node(sync[0])\n    self._logger.debug('Loading members')\n    members = self.load_members(path)\n    self._logger.debug('Loading leader')\n    leader = self.get_node(path + self._LEADER)\n    if leader:\n        leader = Leader.from_node(leader[0])\n    else:\n        leader = None\n    self._logger.debug('Loading status')\n    status = self.get_status(path, leader)\n    self._logger.debug('Loading failover')\n    failover = self.get_node(path + self._FAILOVER)\n    if failover:\n        failover = Failover.from_node(failover[0])\n    else:\n        failover = None\n    self._logger.debug('Loading failsafe configuration')\n    failsafe_config = self.get_node(path + self._FAILSAFE_CONFIG)\n    if not failsafe_config:\n        raise RuntimeError('Failsafe configuration not found')\n    failsafe_config = FailsafeConfig.from_node(failsafe_config[0])\n    return Cluster(\n        config=config,\n        history=history,\n        sync=sync,\n        members=members,\n        leader=leader,\n        status=status,\n        failover=failover,\n        failsafe_config=failsafe_config,\n    )", "CodeBleu_score": 35.205068711841065}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.initialize(self.get_node(path + self._INITIALIZE))\n    cluster.config = ClusterConfig.from_node(self.get_node(path + self._CONFIG))\n    cluster.history = TimelineHistory.from_node(self.get_node(path + self._HISTORY))\n    cluster.sync = SyncState.from_node(self.get_node(path + self._SYNC))\n    cluster.members = self.load_members(path)\n    cluster.leader = Leader.from_node(self.get_node(path + self._LEADER))\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = Failover.from_node(self.get_node(path + self._FAILOVER))\n    cluster.failsafe = FailsafeConfig.from_node(self.get_node(path + self._FAILSAFE))\n    return cluster\n", "CodeBleu_score": 14.057163614796425}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if self.get_node(path + self._INITIALIZE):\n        initialize = Initialize.from_node(self.get_node(path + self._INITIALIZE)[0])\n    else:\n        initialize = Initialize(False)\n    if self.get_node(path + self._CONFIG):\n        config = self.get_node(path + self._CONFIG)[0]\n    else:\n        config = None\n    if self.get_node(path + self._HISTORY):\n        history = self.get_node(path + self._HISTORY)[0]\n    else:\n        history = None\n    if self.get_node(path + self._SYNC):\n        sync = self.get_node(path + self._SYNC)[0]\n    else:\n        sync = None\n    if self.get_node(path + self._FAILOVER):\n        failover = self.get_node(path + self._FAILOVER)[0]\n    else:\n        failover = None\n    if self.get_node(path + self._FAILSAFE):\n        failsafe = self.get_node(path + self._FAILSAFE)[0]\n    else:\n        failsafe = None\n    if self.get_node(path + self._MEMBERS):\n        members = self.load_members(path)\n    else:\n        members = []\n    if self.get_node(path + self._LEADER):\n        leader = Leader.from_node(self.get_node(path + self._LEADER)[0])\n    else:\n        leader = None\n    if self.get_node(path + self._STATUS):\n        status = Status.from_node(self.get_node(path + self._STATUS)[0])\n    else:\n        status = None\n    if self.get_node(path + self._OPTIME):\n        optime = self.get_node(path + self._OPTIME)[0]\n    else:\n        optime = None\n    if self.get_node(path + self._LSN):\n        lsn = self.get_node(path + self._LSN)[0]\n    else:\n        lsn = None\n    if self.get_node(path + self._ROLE):\n        role = Role.from_node(self.get_node(path + self._ROLE)[0])\n    else:\n        role = None\n    if self.get_node(path + self._", "CodeBleu_score": 31.15634788948331}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, ephemeral=True)\n        return True\n    except (ConnectionLoss, SessionExpiredError, OperationTimeoutError) as e:\n        raise ZooKeeperError(e)\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Unexpected error when attempting to acquire leader lock: {e}\")\n        return False\n", "CodeBleu_score": 46.36953563060789}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, b\"\", ephemeral=True, sequence=True)\n        return True\n    except (ZooKeeperError, ConnectionClosedError) as e:\n        raise e\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Unexpected error while attempting to acquire leader lock: {e}\")\n        return False\n\n", "CodeBleu_score": 39.75784940027505}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, b\"\")\n        return True\n    except NoNodeError:\n        self.zk.ensure_path(self.leader_path)\n        return attempt_to_acquire_leader(self)\n    except (SessionExpiredError, ConnectionLoss):\n        raise ZooKeeperError(\"Unable to connect to ZooKeeper.\")\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Unexpected error when attempting to acquire leader lock: {e}\")\n        return False\n", "CodeBleu_score": 48.7506621792525}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.client_id != self.client_id:\n        logger.warning(f\"Leader session ID mismatch: {leader.client_id} != {self.client_id}\")\n        try:\n            self._delete_leader()\n        except NoNodeError:\n            logger.warning(\"Leader node not found\")\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.error(f\"Failed to delete leader node: {e}\")\n            raise ZooKeeperError from e\n\n    try:\n        self._create_leader(leader)\n    except NodeExistsError:\n        logger.warning(\"Leader node already exists\")\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(f\"Failed to create leader node: {e}\")\n        raise ZooKeeperError from e\n\n    return True\n\n", "CodeBleu_score": 40.64104922446861}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        # Check if the current client is the leader\n        if leader.session_id != self.client_id:\n            # The current client is not the leader, so we need to delete the leader ZNode\n            self.delete(leader.path)\n            self.logger.warning(\n                \"The current client is not the leader, so we need to delete the leader ZNode\"\n            )\n        # Try to create a new leader ZNode\n        self.create(leader.path, str.encode(self.client_id))\n        self.logger.info(\"Successfully created a new leader ZNode\")\n        return True\n    except NoNodeError:\n        # The leader ZNode doesn't exist, so we need to create it\n        self.create(leader.path, str.encode(self.client_id))\n        self.logger.info(\"Successfully created a new leader ZNode\")\n        return True\n    except (ConnectionClosedError, RetryFailedError):\n        # We were unable to connect to ZooKeeper, so we need to ignore the error\n        self.logger.warning(\"Unable to connect to ZooKeeper\")\n        return False\n    except Exception as e:\n        # An unexpected error occurred, so we need to raise an exception\n        self.logger.error(f\"Unexpected error occurred: {e}\")\n        raise ZooKeeperError(e)\n\n", "CodeBleu_score": 41.78225493995318}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session_id != self.client_id:\n        logger.warning(\"Leader's session ID (%s) does not match current client ID (%s)\", leader.session_id, self.client_id)\n        try:\n            self.delete(leader.path)\n        except NoNodeError:\n            pass\n        except (ConnectionClosedError, RetryFailedError) as e:\n            logger.error(\"Failed to delete leader ZNode: %s\", e)\n            raise ZooKeeperError(\"Failed to delete leader ZNode\") from e\n        else:\n            logger.info(\"Deleted leader ZNode\")\n\n    try:\n        self.create(leader.path, value=self.client_id.encode(\"utf-8\"))\n    except NodeExistsError:\n        pass\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(\"Failed to create leader ZNode: %s\", e)\n        raise ZooKeeperError(\"Failed to create leader ZNode\") from e\n    else:\n        logger.info(\"Created leader ZNode\")\n        return True\n\n", "CodeBleu_score": 51.226685500542445}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll >= self._poll_interval:\n        self._last_poll = time.time()\n        exhibitors = self._query_exhibitors(self._exhibitors)\n        if exhibitors and 'servers' in exhibitors and 'port' in exhibitors:\n            if self._exhibitors != exhibitors['servers'] or self._exhibitor_port != exhibitors['port']:\n                self._exhibitors = exhibitors['servers']\n                self._exhibitor_port = exhibitors['port']\n                self._update_zookeeper_connection_string()\n                logging.info('ZooKeeper connection string updated to %s', self._zookeeper_connection_string)\n                return True\n        else:\n            logging.warning('Invalid exhibitor response: %s', exhibitors)\n    return False", "CodeBleu_score": 36.94378157634613}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll > self._poll_interval:\n        exhibitors = self._query_exhibitors(self._exhibitors)\n        if exhibitors:\n            if 'servers' in exhibitors:\n                servers = exhibitors['servers']\n                if servers != self._servers:\n                    self._servers = servers\n                    self._update_zookeeper_connection_string()\n                    self._last_poll = time.time()\n                    return True\n    return False", "CodeBleu_score": 31.161650723745353}, {"code": "def poll(self) -> bool\n\t\n    if time.time() > self._last_poll + self._poll_interval:\n        exhibitors = self._query_exhibitors(self._exhibitors)\n        if exhibitors:\n            new_connection_string = self._create_connection_string(exhibitors)\n            if new_connection_string != self._connection_string:\n                logging.info('Exhibitor connection string updated from %s to %s', self._connection_string, new_connection_string)\n                self._connection_string = new_connection_string\n                self._last_poll = time.time()\n                return True\n    return False", "CodeBleu_score": 31.829029821253606}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\tif (zookeeperListener == null) {\nreturn;\n}\ntry {\nString group = getGroup();\nString dataId = getDataId();\nif (StringUtils.isBlank(group) || StringUtils.isBlank(dataId)) {\nreturn;\n}\nlogUnsubscribeStarted(group, dataId);\nzookeeperListener.unsubscribe(group, dataId);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}", "CodeBleu_score": 77.51107672727086}, {"code": "public void destroy(){\n\tif (zookeeperListener == null) {\nreturn;\n}\ntry {\nString group = getGroup();\nString dataId = getDataId();\nif (StringUtils.isEmpty(group) || StringUtils.isEmpty(dataId)) {\nreturn;\n}\nlogUnsubscribeStarted(group, dataId);\nzookeeperListener.unsubscribe(group, dataId);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}", "CodeBleu_score": 77.49444653296365}, {"code": "public void destroy(){\n\tif (zookeeperListener == null) {\nreturn;\n}\nString group = getGroup();\nString dataId = getDataId();\nif (StringUtils.isBlank(group) || StringUtils.isBlank(dataId)) {\nlogger.error(\"dataId or group is null, please check your configuration!\");\nreturn;\n}\nlogger.info(\"unsubscribe dataId [{}] from group [{}] started\", dataId, group);\ntry {\nzookeeperListener.unsubscribe(group, dataId);\nlogger.info(\"unsubscribe dataId [{}] from group [{}] success\", dataId, group);\n} catch (Exception e) {\nlogger.error(\"unsubscribe dataId [{}] from group [{}] failed\", dataId, group, e);\n}\n}", "CodeBleu_score": 66.70094196606101}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tMap<String, String> metadata = new HashMap<String, String>();\n\tif (server instanceof ZookeeperServer) {\n\t\tmetadata = ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn metadata;\n}", "CodeBleu_score": 48.06473123211482}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.42210315805}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.42210315805}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = \"/\" + group + \"/\" + serviceId;\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tbyte[] data = nodeCache.getCurrentData().getData();\n\t\t\tString config = new String(data, \"UTF-8\");\n\t\t\ttry {\n\t\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Failed to invoke callback\", e);\n\t\t\t}\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n\tcuratorFramework.getCuratorListenable().addListener(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 56.306726351902014}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = \"/\" + group + \"/\" + serviceId;\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = convertConfig(path);\n\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n\tcuratorFramework.getCuratorListenable().addListener(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 60.90761577532477}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\n}", "CodeBleu_score": 6.644044709338043}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList serverList = new ZookeeperServerList(config, serviceDiscovery);\n\tserverList.initWithNiwsConfig(config);\n\tserverList.setServiceId(config.getClientName());\n\tserverList.setLoadBalanceListenerExecutor(config.getScheduledExecutor());\n\treturn serverList;\n}", "CodeBleu_score": 66.19643297483589}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.81278207135417}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tIClientConfig config = DefaultClientConfigImpl.getClientConfigWithDefaultValues();\nconfig.loadProperties(\"client.properties\");\n\nString clientName = config.getClientName();\nif (StringUtils.isBlank(clientName)) {\nclientName = config.getDeploymentContext().getApplicationName();\n}\n\nif (StringUtils.isBlank(clientName)) {\nthrow new IllegalArgumentException(\"clientName must be set\");\n}\n\nconfig.setClientName(clientName);\n\nServerList<ZookeeperInstance> serverList = new ZookeeperServerList(config, serviceDiscovery);\nserverList.initWithNiwsConfig(config);\nserverList.setServiceId(clientName);\nserverList.setLoadBalanceListenerExecutor(Executors.newSingleThreadExecutor());\n\nreturn serverList;\n}", "CodeBleu_score": 55.722841488656314}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.64531523943103}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.64531523943103}, {"code": "public void register(ZookeeperRegistration registration){\n\t\n}", "CodeBleu_score": 4.935456189630512}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\t\n}", "CodeBleu_score": 3.9967210117648984}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = config.getProperty(\"group\");\n\tString dataId = config.getProperty(\"dataId\");\n\tif (group == null || dataId == null) {\n\t\tlogger.error(\"The group or dataId property is not set in the config.properties file.\");\n\t\treturn null;\n\t}\n\tlogger.info(\"Subscribing to group: \" + group + \", dataId: \" + dataId);\n\tZookeeperListener listener = new ZookeeperListener(group, dataId, globalConfig);\n\ttry {\n\t\tzookeeperOperation.subscribe(listener);\n\t\tlogger.info(\"Successfully subscribed to group: \" + group + \", dataId: \" + dataId);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error subscribing to group: \" + group + \", dataId: \" + dataId, e);\n\t\treturn null;\n\t}\n\treturn listener;\n}", "CodeBleu_score": 38.11877765632267}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig ? \"global\" : \"config\";\n\tString dataId = globalConfig ? \"global.properties\" : \"application.properties\";\n\tLOGGER.info(\"Subscribing to {} config with dataId {}\", group, dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, new ConfigListener());\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error subscribing to {} config with dataId {}\", group, dataId, e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 40.77267465557311}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\ttry {\n\t\tgroup = config.getProperty(Constants.GROUP);\n\t\tdataId = config.getProperty(Constants.DATA_ID);\n\t\tlogger.info(\"Starting to subscribe to config group: \" + group + \", dataId: \" + dataId);\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, configListener);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to subscribe to config group: \" + group + \", dataId: \" + dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 32.0044266190559}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\tif (StringUtils.isEmpty(connectString)) {\nthrow new DiscoveryException(\"Zookeeper connection string not found in environment\");\n}\n\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(retryCount, sleepTime);\nCuratorFramework cf = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(retryPolicy).build();\ncf.start();\nreturn cf;\n}", "CodeBleu_score": 24.97660252728386}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\nif (connectionString == null || connectionString.isEmpty()) {\nthrow new DiscoveryException(\"Zookeeper connection string not found in environment variable ZOOKEEPER_CONNECTION_STRING\");\n}\nint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\nint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\nCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder();\nCuratorFramework client = builder.connectString(connectionString).retryPolicy(retryPolicy).build();\nclient.start();\nreturn client;\n}", "CodeBleu_score": 39.2380435270577}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\nif (connectionString == null || connectionString.isEmpty()) {\nthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n}\nint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\nint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\nRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\nCuratorFramework cf = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(retryPolicy).build();\ncf.start();\nreturn cf;\n}", "CodeBleu_score": 38.14602525788026}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n@Bean\n@ConditionalOnProperty(prefix = \"spring.cloud.gateway\", name = \"discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic RouteLocator gatewayRouteLocator(RouteLocatorBuilder builder, ZookeeperDiscoveryClient discoveryClient) {\n\nreturn builder.routes().route(p -> p.path(\"/service-a/**\")\n.filters(f -> f.prefixPath(\"/service-a\")).uri(discoveryClient.getInstances(\"service-a\").get(0).getUri()))\n.route(p -> p.path(\"/service-b/**\")\n.filters(f -> f.prefixPath(\"/service-b\")).uri(discoveryClient.getInstances(\"service-b\").get(0).getUri()))\n.build();\n}\n}", "CodeBleu_score": 28.15867981165794}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 51.16349362353591}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 45.80543071516783}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t//        CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n//        builder.connectString(getZkHosts());\n//        builder.namespace(getNamespace());\n//        builder.retryPolicy(retryPolicy);\n//        builder.sessionTimeoutMs(getSessionTimeout());\n//        CuratorFramework client = builder.build();\n//        client.start();\n//        return client;\n//    }", "CodeBleu_score": 1.6531227316461272}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(this.getZkHosts())\n.retryPolicy(new ExponentialBackoffRetry(1000, 3))\n.namespace(this.getNamespace())\n.sessionTimeoutMs(this.getSessionTimeout())\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 47.42059763522003}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tif (this.curatorFramework != null) {\nreturn this.curatorFramework;\n}\nif (this.curatorFrameworkFactory == null) {\nthis.curatorFrameworkFactory = new DefaultCuratorFrameworkFactory();\n}\nthis.curatorFramework = this.curatorFrameworkFactory.newCuratorFramework(this.connectString, this.sessionTimeoutMs, this.namespace, this.retryPolicy);\nthis.curatorFramework.start();\nreturn this.curatorFramework;\n}", "CodeBleu_score": 25.410078540331078}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex lock = null;\n\ttry {\n\t\tlock = new InterProcessMutex(zkClient, path);\n\t\tlock.acquire();\n\t\tlocksMap.put(path, lock);\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Error while acquiring lock for path: \" + path, e);\n\t}\n}", "CodeBleu_score": 21.4378351629722}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(path)) {\nInterProcessMutex lock = locksMap.get(path);\nif (lock.isAcquiredInThisProcess()) {\nreturn;\n}\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path, e);\n}\n} else {\nInterProcessMutex lock = new InterProcessMutex(zkClient, path);\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path, e);\n}\nlocksMap.put(path, lock);\n}\n}", "CodeBleu_score": 34.308780390231796}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (path == null) {\nthrow new DistributedLockException(\"Path cannot be null\");\n}\nif (path.isEmpty()) {\nthrow new DistributedLockException(\"Path cannot be empty\");\n}\n\nInterProcessMutex lock = getLock(path);\ntry {\nif (lock.isAcquiredInThisProcess()) {\nLOGGER.debug(\"Thread {} already holds the lock for path {}\", Thread.currentThread().getName(), path);\nreturn;\n}\nLOGGER.debug(\"Attempting to acquire lock for path {}\", path);\nlock.acquire();\nLOGGER.debug(\"Successfully acquired lock for path {}\", path);\nlocksMap.put(path, lock);\n} catch (Exception e) {\nLOGGER.error(\"Exception while attempting to acquire lock for path {}\", path, e);\nthrow new DistributedLockException(\"Exception while attempting to acquire lock for path \" + path, e);\n}\n}", "CodeBleu_score": 28.499723000079037}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Config config = dtpProperties.getConfig();\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tMap<Object, Object> properties = Maps.newHashMap();\n\tif (config.getType().equals(DtpProperties.ConfigType.PROPERTIES)) {\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\t\tString nodePath = nodePath(dtpProperties);\n\t\tproperties = genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (config.getType().equals(DtpProperties.ConfigType.JSON)) {\n\t\tString nodePath = ZKPaths.makePath(ZKPaths.makePath(zookeeper.getRootNode(), zookeeper.getConfigVersion()),\n\t\t\t\tzookeeper.getNode(), config.getKey());\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\t\tString value = getVal(nodePath, curatorFramework);\n\t\ttry {\n\t\t\tproperties = ConfigHandler.parseConfig(value);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"parse zk config failed, nodePath: {}, value: {}\", nodePath, value, e);\n\t\t}\n\t}\n\treturn properties;\n}", "CodeBleu_score": 57.28039571494109}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tMap<Object, Object> properties = null;\n\tif (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.PROPERTIES)) {\n\t\tproperties = genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.JSON)) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString value = getVal(ZKPaths.makePath(nodePath, configKey), curatorFramework);\n\t\tproperties = ConfigHandler.parseConfig(value);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 55.36490246094586}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tif (dtpProperties.getConfigType() == ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath(dtpProperties), getCuratorFramework(dtpProperties));\n\t} else {\n\t\tString nodePath = nodePath(dtpProperties) + \"/\" + getConfigKey(dtpProperties);\n\t\tString value = getVal(nodePath, getCuratorFramework(dtpProperties));\n\t\treturn parseConfig(value);\n\t}\n}", "CodeBleu_score": 27.02520981057091}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t// 1. Retrieve an instance of DtpProperties\n        DtpProperties dtpProperties = getInstance(environment);\n// 2. Bind DtpProperties with the current environment\n        bindDtpProperties(environment, dtpProperties);\n// 3. Generate a properties map from DtpProperties\n        Map<Object, Object> properties = genPropertiesMap(dtpProperties);\n// 4. Check if the required property exists in the environment\n        if (!checkPropertyExist(environment)) {\n// 5. If the property does not exist, it creates a Zookeeper property source with the generated properties\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 66.28822266240799}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = DtpProperties.getInstance();\nenvironment.getPropertySources().addLast(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, dtpProperties));\n}", "CodeBleu_score": 29.330506160534302}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = getInstance(environment, DtpProperties.class);\nBinder binder = Binder.get(environment);\nbinder.bind(DtpProperties.class, dtpProperties);\nMap<Object, Object> properties = binder.bind(DtpProperties.class).get().getAllProperties();\ncheckPropertyExist(environment);\ncreateZkPropertySource(environment, properties);\n}", "CodeBleu_score": 60.837018096919195}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterInstance(configInfo).SingleInstance();\nbuilder.RegisterType<DefaultServiceRouteFactory>().As<IServiceRouteFactory>();\nbuilder.RegisterType<DefaultZookeeperClientProvider>().As<IZookeeperClientProvider>();\nbuilder.RegisterGeneric(typeof(ZooKeeperServiceRouteManager<>)).As(typeof(IServiceRouteManager<>)).SingleInstance();\nbuilder.RegisterGeneric(typeof(ZooKeeperServiceRouteManager<>)).As(typeof(IServiceRouteManager)).SingleInstance();\nbuilder.RegisterGeneric(typeof(ZooKeeperRouteSubscriber<>)).As(typeof(IRouteSubscriber)).SingleInstance();\nbuilder.RegisterGeneric(typeof(ZooKeeperRouteCache<>)).As(typeof(IRouteCache)).SingleInstance();\nbuilder.RegisterGeneric(typeof(ZooKeeperCommandExecuter<>)).As(typeof(ICommandExecuter)).SingleInstance();\nbuilder.RegisterGeneric(typeof(ZooKeeperCommandSender<>)).As(typeof(ICommandSender)).SingleInstance();\nreturn this;\n}", "CodeBleu_score": 33.8037708341885}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\n}", "CodeBleu_score": 4.679638655496093}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 4.435738909874791}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t return UseZooKeeperCommandManager(builder, configInfo, null);\n}", "CodeBleu_score": 23.843842901114794}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t builder.UseCommandManager(provider => new ZookeeperServiceCommandManager(GetConfigInfo(configInfo), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n}", "CodeBleu_score": 57.17265779888974}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 8.618059401316474}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\nCheck.NotNull(path, nameof(path));\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(Resources.Error_PathCannotBeNullOrEmpty, nameof(path));\n}\nif (provider == null && Path.IsPathRooted(path)) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\nif (provider == null) {\nthrow new ArgumentException(Resources.Error_ProviderCannotBeNull, nameof(provider));\n}\nvar source = new ZookeeperConfigurationSource {\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n};\nsource.FileProvider = provider;\nbuilder.Add(source);\nreturn builder.Build();\n}", "CodeBleu_score": 62.09330832841593}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(\"The configuration file path cannot be null or empty.\", nameof(path));\n}\nif (provider == null && !Path.IsPathRooted(path)) {\nthrow new ArgumentException(\"The configuration file path must be absolute.\", nameof(path));\n}\nif (optional && !File.Exists(path)) {\nreturn builder;\n}\nCheck.NotNull(provider, nameof(provider));\nCheck.NotNull(path, nameof(path));\nCheck.NotNull(reloadOnChange, nameof(reloadOnChange));\nif (reloadOnChange) {\nCheck.Condition(provider is PhysicalFileProvider, \"The reloadOnChange option is not supported when using a non-physical provider.\");\n}\nreturn builder.Add(new ZookeeperConfigurationSource {\nProvider = provider,\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n});\n}", "CodeBleu_score": 46.70063740394151}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (path == null) {\nthrow new ArgumentNullException(nameof(path));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(\"The path must not be empty.\", nameof(path));\n}\nif (provider == null && !Path.IsPathRooted(path)) {\nthrow new ArgumentException(\"The path must be absolute.\", nameof(path));\n}\nif (optional) {\nif (!provider.FileExists(path)) {\nreturn builder;\n}\n}\nelse {\nif (!provider.GetFileInfo(path).Exists) {\nthrow new FileNotFoundException(\"The configuration file was not found and is not optional.\", path);\n}\n}\nvar source = new ZookeeperConfigurationSource {\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange,\nFileProvider = provider\n};\nbuilder.Add(source);\nreturn builder;\n}", "CodeBleu_score": 49.83223492029185}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tforeach (var item in Address) {\n\t\t_routes.RemoveAll(s => s.Address == item.Address && s.Router == item.Router);\n\t}\n\tawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 36.47556044509802}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\n}", "CodeBleu_score": 5.252912912894922}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\n}", "CodeBleu_score": 5.252912912894922}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar oldRouteIds = await _zookeeperClientProvider.GetZooKeepers();\n\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\tforeach (var zooKeeper in _zookeeperClientProvider.GetZooKeepers()) {\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar path = $\"/{_routePath}/{deletedRouteId}\";\n\t\t\tvar addresses = await zooKeeper.Item2.getChildrenAsync(path);\n\t\t\tif (addresses.Contains(hostAddr.ToString())) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.11561397800806}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tif (routes == null || !routes.Any()) {\n\t\treturn;\n\t}\n\tstring path = _pathRoot + \"/\" + hostAddr.ToAddressString();\n\tvar addresses = routes.Select(i => i.Address).ToArray();\n\tvar oldRouteIds = await _zookeeperClientProvider.GetZooKeepers().Item2.getChildrenAsync(path);\n\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\tvar zooKeeper = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\tvar routePath = path + \"/\" + deletedRouteId;\n\t\tif (addresses.Contains(hostAddr)) {\n\t\t\tawait zooKeeper.Item2.deleteAsync(routePath);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.926501604307745}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar oldRouteIds = await _zookeeperClientProvider.GetZooKeepers().Select(zk => zk.Item2.getChildrenAsync(RoutePath)).SelectMany(t => t.Result).ToArray();\n\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\tvar zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeeperClients) {\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar path = GetRoutePath(deletedRouteId);\n\t\t\tvar addresses = await zooKeeper.Item2.getChildrenAsync(path);\n\t\t\tif (addresses.Contains(hostAddr.ToString())) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.64218177495064}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n\nvar descriptor = await DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn await CreateServiceRouteAsync(new[] { descriptor }).First();\n}", "CodeBleu_score": 26.689487779446385}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) return null;\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug\n($\"{{0}}: Retrieving service route from byte array data.\", nameof(GetRoute));\nvar descriptor = await DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn await CreateServiceRoutesAsync(new[] { descriptor }).First();\n}", "CodeBleu_score": 42.49346070770478}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug(\n$\"{nameof(GetRoute)} \u6b63\u5728\u4ece\u63d0\u4f9b\u7684\u5b57\u8282\u6570\u7ec4\u6570\u636e\u4e2d\u68c0\u7d22\u670d\u52a1\u8def\u7531\u3002\n\u5982\u679c\u542f\u7528\u4e86\u8c03\u8bd5\u65e5\u5fd7\u8bb0\u5f55\uff0c\u5219\u4f1a\u8bb0\u5f55\u8def\u7531\u6570\u636e\u3002\n\u5982\u679c\u6570\u636e\u4e3a\u7a7a\uff0c\u5219\u8fd4\u56de null\u3002\n\u5b83\u5c06\u5b57\u8282\u6570\u7ec4\u53cd\u5e8f\u5217\u5316\u4e3a ServiceRouteDescriptor \u5e76\u4f7f\u7528\u670d\u52a1\u8def\u7531\u5de5\u5382\u521b\u5efa\u5e76\u8fd4\u56de\u7b2c\u4e00\u4e2a ServiceRoute\u3002\");\n}\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 40.45100039776135}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData))\nreturn;\n\nvar newRoute = await GetRoute(newData);\nif (newRoute == null)\nreturn;\n\nvar oldRoute = await GetRoute(oldData);\nif (oldRoute == null)\nreturn;\n\n_routes = _routes.Where(i => i.ServiceDescriptor.Id != oldRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n\n//\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n\nawait _onChanged.InvokeAsync(new RouteChangedEventArgs(oldRoute, newRoute));\n}", "CodeBleu_score": 63.46537558585429}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8def\u7531\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nif (DataEquals(oldData, newData)) {\nreturn;\n}\n\nvar newRoute = await GetRoute(newData);\n\nif (newRoute == null) {\n_logger.LogWarning($\"\u65e0\u6cd5\u4ece\u914d\u7f6e\u4e2d\u89e3\u6790\u670d\u52a1\u8def\u7531\u3002\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\nreturn;\n}\n\nvar oldRoute = await GetRoute(oldData);\n\nif (oldRoute == null) {\n_logger.LogWarning($\"\u65e0\u6cd5\u4ece\u914d\u7f6e\u4e2d\u89e3\u6790\u670d\u52a1\u8def\u7531\u3002\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(oldData)}\u3002\");\nreturn;\n}\n\n//\u66f4\u65b0\u8def\u7531\u5217\u8868\u3002\n\n_routes = _routes.Where(i => i.ServiceDescriptor.Id != oldRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n\n//\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n\n_logger.LogInformation($\"\u670d\u52a1\u8def\u7531\u5df2\u66f4\u65b0\uff1a{newRoute.ServiceDescriptor.Id}\u3002\");\nOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 58.535290010415366}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.516682952259708}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar subscribersArray = subscribers.ToArray();\n\tif (subscribersArray.Length == 0) {\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u6ca1\u6709\u9700\u8981\u66f4\u65b0\u7684\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\t\treturn;\n\t}\n\n\tvar rootPath = _configInfo.SubscriberPath;\n\tif (!rootPath.EndsWith(\"/\"))\n\t\trootPath += \"/\";\n\n\tvar childrens = subscribersArray.Select(p => p.ServiceDescriptor.Id).ToArray();\n\tvar existingSubscribers = await GetSubscribers(childrens);\n\tif (existingSubscribers.Length == 0) {\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u6ca1\u6709\u9700\u8981\u66f4\u65b0\u7684\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\t\treturn;\n\t}\n\n\tforeach (var subscriber in subscribersArray) {\n\t\tvar existingSubscriber = existingSubscribers.FirstOrDefault(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id);\n\t\tif (existingSubscriber == null) {\n\t\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t\t_logger.LogInformation($\"\u6ca1\u6709\u627e\u5230\u9700\u8981\u66f4\u65b0\u7684\u8ba2\u9605\u8005\u4fe1\u606f\uff1a{subscriber.ServiceDescriptor.Id}\");\n\t\t\tcontinue;\n\t\t}\n\n\t\tsubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).Except(existingSubscriber.Address).ToArray();\n\t}\n\n\tawait base.SetSubscribersAsync(subscribersArray);\n}", "CodeBleu_score": 45.759223797639514}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar oldSubscribers = await GetSubscribers(subscribers.Select(p => p.ServiceDescriptor.Id));\nvar newSubscribers = subscribers.ToArray();\nforeach (var oldSubscriber in oldSubscribers) {\nvar newSubscriber = newSubscribers.FirstOrDefault(p => p.ServiceDescriptor.Id == oldSubscriber.ServiceDescriptor.Id);\nif (newSubscriber != null) {\nvar newAddresses = newSubscriber.Address.Concat(oldSubscriber.Address).Distinct();\noldSubscriber.Address = newAddresses.ToArray();\n}\n}\nawait base.SetSubscribersAsync(oldSubscribers);\n}", "CodeBleu_score": 49.18681578774592}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar serviceSubscribers = await GetServiceSubscribersAsync();\nforeach (var subscriber in subscribers) {\nvar oldSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\nif (oldSubscriber == null)\nserviceSubscribers.Add(subscriber);\nelse {\nvar newAddresses = subscriber.Address.Concat(oldSubscriber.Address).Except(oldSubscriber.Address);\noldSubscriber.Address = newAddresses;\n}\n}\nawait base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 51.988869365891176}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar rootPath = GetRootPath(childrens);\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in childrens) {\nvar path = string.Concat(rootPath, child);\nvar subscriber = await GetSubscriber(path);\nif (subscriber != null) {\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 35.48130596324225}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tstring rootPath = _service.Root.Path;\nList<ServiceSubscriber> subscribers = new List<ServiceSubscriber>();\nforeach (string child in childrens) {\nstring fullPath = string.Format(\"{0}/{1}\", rootPath, child);\n_logger.LogDebug(\"Getting subscriber information for node: {0}\", fullPath);\nvar subscriber = await _service.GetSubscriberAsync(fullPath);\nsubscribers.Add(subscriber);\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 34.22760326278982}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tstring rootPath = _node.NodePath;\nServiceSubscriber[] subscribers = new ServiceSubscriber[childrens.Count()];\nint index = 0;\nforeach (string child in childrens) {\nstring childPath = string.Format(\"{0}/{1}\", rootPath, child);\n_logger.LogDebug(\"Getting subscriber information for {0}...\", childPath);\nServiceSubscriber subscriber = await _node.GetSubscriberAsync(childPath);\nif (subscriber != null) {\nsubscribers[index] = subscriber;\nindex++;\n}\n}\nreturn subscribers;\n}", "CodeBleu_score": 33.307971166314545}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers != null) return;\n\tvar zooKeeper = await GetZooKeeper();\n\tvar resetEvent = zooKeeper.Item1;\n\tawait resetEvent.WaitOne();\n\tif (_subscribers != null) return;\n\tvar childrens = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\n\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u51c6\u5907\u4ece\u8282\u70b9\uff1a{_configInfo.SubscriberPath}\u4e2d\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\tvar subscribers = await GetSubscribers(childrens);\n\t_subscribers = subscribers;\n}", "CodeBleu_score": 45.99756558495112}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null) {\nreturn;\n}\n\n_logger.LogInformation(\"EnterSubscribers:\u521d\u59cb\u5316_subscribers\u5b57\u6bb5\u3002\");\nvar zooKeeper = await GetZooKeeper();\nzooKeeper.Item2.existsAsync(\n_configInfo.SubscriberPath,\nasync (rc, stat) => {\nif (rc == ZooKeeper.ErrorCode.Ok) {\nvar childrens = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug(\"EnterSubscribers:\u83b7\u53d6\u5b50\u8282\u70b9\u4fe1\u606f\u3002\");\n}\nvar subscribers = await GetSubscribers(childrens);\n_subscribers = subscribers;\n} else if (rc == ZooKeeper.ErrorCode.NoNode) {\n_logger.LogWarning(\"EnterSubscribers:\u8ba2\u9605\u8005\u8def\u5f84\u4e0d\u5b58\u5728\u3002\");\n_subscribers = new ServiceSubscriber[0];\n} else {\n_logger.LogError(\"EnterSubscribers:\u83b7\u53d6\u5b50\u8282\u70b9\u4fe1\u606f\u5931\u8d25\u3002\");\n}\n});\n}", "CodeBleu_score": 51.659542450213415}, {"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers != null)\n\t\treturn;\n\n\tvar zooKeeper = await GetZooKeeper();\n\tvar (event, _) = zooKeeper;\n\tawait event.WaitOne();\n\n\tvar childrens = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\n\tif (childrens.Length > 0) {\n\t\t_subscribers = await GetSubscribers(childrens);\n\t}\n\telse {\n\t\t_logger.LogWarning($\"\u8282\u70b9\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\u3002\");\n\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t}\n}", "CodeBleu_score": 54.391726485544964}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\ts\n            if (_logger.IsEnabled(LogLevel.Trace))\n                _logger.LogTrace($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65e7\u6570\u636e\uff1a{Encoding.UTF8.GetString(oldData)}\uff0c\u65b0\u6570\u636e\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\n            if (DataEquals(oldData, newData))\n                return;\n\n            var oldCommands = GetServiceCommands(oldData);\n            var newCommands = GetServiceCommands(newData);\n\n            if (oldCommands.Length != newCommands.Length)\n            {\n                _logger.LogWarning($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\u65f6\u670d\u52a1\u547d\u4ee4\u6570\u91cf\u4e0d\u5339\u914d\uff0c\u65e7\u6570\u636e\u670d\u52a1\u547d\u4ee4\u6570\u91cf\uff1a{oldCommands.Length}\uff0c\u65b0\u6570\u636e\u670d\u52a1\u547d\u4ee4\u6570\u91cf\uff1a{newCommands.Length}\u3002\");\n                return;\n            }\n\n            if (_logger.IsEnabled(LogLevel.Debug))\n                _logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\u65f6\u670d\u52a1\u547d\u4ee4\u6570\u91cf\u5339\u914d\uff0c\u65e7\u6570\u636e\u670d\u52a1\u547d\u4ee4\u6570\u91cf\uff1a{oldCommands.Length}\uff0c\u65b0\u6570\u636e\u670d\u52a1\u547d\u4ee4\u6570\u91cf\uff1a{newCommands.Length}\u3002\");\n\n            for (var i = 0; i < oldCommands.Length; i++)\n            {\n                var oldCommand = oldCommands[i];\n                var newCommand = newCommands[i];\n                if (oldCommand.ServiceId != newCommand.ServiceId)\n                {\n                    _logger.LogWarning($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\u65f6\u670d\u52a1\u547d\u4ee4 ID \u4e0d\u5339\u914d\uff0c\u65e7\u6570\u636e\u670d\u52a1\u547d\u4ee4 ID\uff1a{oldCommand.ServiceId}\uff0c\u65b0\u6570\u636e\u670d\u52a1\u547d\u4ee4 ID\uff1a{newCommand.ServiceId}\u3002\");\n                    return;\n                }\n\n                if (_logger.IsEnabled(LogLevel.Debug))\n                    _logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\u65f6\u670d\u52a1\u547d\u4ee4 ID \u5339\u914d\uff0c\u65e7\u6570\u636e\u670d\u52a1\u547d\u4ee4 ID\uff1a{oldCommand.ServiceId}\uff0c\u65b0\u6570\u636e\u670d\u52a1\u547d\u4ee4 ID\uff1a{newCommand.ServiceId}\u3002\");\n\n                _serviceCommands = _serviceCommands.Where(i => i.ServiceId != oldCommand.ServiceId).ToArray();\n            }\n\n            _serviceCommands = _serviceCommands.Concat(newCommands).ToArray();\n\n            OnChanged?.Invoke(newCommands, oldCommands);\n        }", "CodeBleu_score": 50.84016493980318}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.5875867509581765}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t. . . . }", "CodeBleu_score": 4.681651116799029}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t// Get the current data from the node asynchronously.\nvar getDataTask = _zooKeeperCall(zooKeeper.GetDataAsync, _action);\n// Wait for the current data to be retrieved.\nawait getDataTask;\n// Get the current data from the task.\nvar currentData = getDataTask.Result;\n// Get the new data from the event.\nvar newData = watchedEvent.get_Data;\n// Execute the action with the current and new data.\n_action(currentData, newData);\n// Update the watcher with the new data.\nawait _zooKeeperCall(zooKeeper.SetDataAsync, _watcher.SetCurrentData, newData);\n}", "CodeBleu_score": 46.13873423376387}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t// Get the current data from the node.\nbyte[] currentData = await _zooKeeperCall.GetDataAsync(_path);\n// Execute the action with the current and new data.\nawait _action(currentData, watchedEvent);\n// Update the watcher with the new data.\nawait _zooKeeperCall.SetDataAsync(_path, currentData);\n}", "CodeBleu_score": 36.92930197100888}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tvar zooKeeper = (ZooKeeper)watchedEvent.get_Keeper();\nvar zooKeeperCall = zooKeeper.Item2;\nvar watcher = (ZooKeeperWatcher)zooKeeperCall.get_Watcher();\nvar action = zooKeeperCall.get_Action();\nvar data = await zooKeeperCall.getDataAsync();\nvar newData = new ZooKeeperData(data.get_Data(), data.get_Stat());\nwatcher.SetCurrentData(newData);\nawait action(watcher, newData);\n}", "CodeBleu_score": 29.712957267237684}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.AddSingleton<IZookeeperClientProvider, DefaultZookeeperClientProvider>();\nreturn builder.ConfigureServices(services =>\n{\n    services.AddSingleton(provider => GetConfigInfo(configInfo));\n    services.AddSingleton<IHealthCheckService, DefaultHealthCheckService>();\n    services.AddSingleton<IZookeeperAddressSelector, DefaultZookeeperAddressSelector>();\n    services.AddSingleton<ILogger<DefaultZookeeperClientProvider>, DefaultZookeeperClientProvider>();\n    services.AddSingleton(provider => provider.Resolve<ILogger<DefaultZookeeperClientProvider>>());\n    services.AddSingleton(provider => provider.Resolve<IHealthCheckService>());\n    services.AddSingleton(provider => provider.Resolve<IZookeeperAddressSelector>());\n    services.AddSingleton(provider => new DefaultZookeeperClientProvider(\n        GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n        provider.Resolve<IZookeeperAddressSelector>(),\n        provider.Resolve<ILogger<DefaultZookeeperClientProvider>>()));\n    services.AddSingleton(provider => provider.Resolve<IZookeeperClientProvider>()).As<IZookeeperClientProvider>();\n    services.AddSingleton(provider => provider.Resolve<IZookeeperClientProvider>()).As<IZookeeperClientProvider>().SingleInstance;\n});\n}", "CodeBleu_score": 60.678511578619606}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\nnew DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.Resolve<IHealthCheckService>(),\nprovider.Resolve<IZookeeperAddressSelector>(),\nprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>();\nreturn builder.UseSingleInstance(typeof(IZookeeperClientProvider));\n}", "CodeBleu_score": 81.07339893701348}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\nnew DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.Resolve<IHealthCheckService>(),\nprovider.Resolve<IZookeeperAddressSelector>(),\nprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>();\nbuilder.Services.Register(provider =>\nnew DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.Resolve<IHealthCheckService>(),\nprovider.Resolve<IZookeeperAddressSelector>(),\nprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\nreturn builder;\n}", "CodeBleu_score": 84.39906596828394}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nvar serviceRoutes = routes.ToList();\n\nif (serviceRoutes.Count == 0) {\n_logger.LogInformation(\nLogLevel.Information,\n\"No MQTT service routes to set up.\"\n);\nreturn;\n}\n\nvar zooKeepers = GetZooKeepers();\nif (zooKeepers.Count == 0) {\n_logger.LogInformation(\nLogLevel.Information,\n\"No ZooKeeper clients to set up MQTT service routes.\"\n);\nreturn;\n}\n\nvar serviceRouteCount = serviceRoutes.Count;\nvar zooKeeperCount = zooKeepers.Count;\n\n_logger.LogInformation(\nLogLevel.Information,\n\"Setting up MQTT service routes for {serviceRouteCount} routes on {zooKeeperCount} ZooKeeper clients.\",\nserviceRouteCount,\nzooKeeperCount\n);\n\nvar tasks = new List<Task>();\n\nforeach (var zooKeeper in zooKeepers) {\ntasks.Add(SetRoutesAsync(zooKeeper, serviceRoutes));\n}\n\nawait Task.WhenAll(tasks);\n\n_logger.LogInformation(\nLogLevel.Information,\n\"Successfully set up MQTT service routes for {serviceRouteCount} routes on {zooKeeperCount} ZooKeeper clients.\",\nserviceRouteCount,\nzooKeeperCount\n);\n}", "CodeBleu_score": 36.3740223404324}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\nvar zooKeepers = GetZooKeepers();\nif (zooKeepers.Count == 0) {\nthrow new InvalidOperationException(\"No ZooKeeper servers specified.\");\n}\n\nvar tasks = new List<Task>();\nforeach (var zooKeeper in zooKeepers) {\ntasks.Add(SetRoutesAsync(zooKeeper, routes));\n}\n\nawait Task.WhenAll(tasks);\n}", "CodeBleu_score": 15.248556005736361}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar newRouteTopics = routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nvar deletedRouteTopic = deletedRouteTopics.FirstOrDefault();\nvar addresses = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).ToArray();\nif (addresses.Contains(hostAddr)) {\nvar zooKeeper = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zk in zooKeeper) {\nawait zk.Item2.deleteAsync(zk.Item1 + deletedRouteTopic);\n}\n}\n}", "CodeBleu_score": 45.04440472045318}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nvar zooKeeper = _zookeeperClientProvider.GetZooKeepers();\nvar addresses = zooKeeper.Item1.ToArray();\nforeach (var address in addresses) {\nvar client = zooKeeper.Item2;\nvar deletedRouteTopicsWithAddress = deletedRouteTopics.Where(p => p.Contains(hostAddr.HostAddress)).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopicsWithAddress) {\nvar routePath = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\nawait client.deleteAsync(routePath);\n}\n}\n}", "CodeBleu_score": 54.437652025589344}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeperClient in zooKeeperClients) {\nvar routePath = _zookeeperRoutesPath;\nvar oldRouteTopics = await zooKeeperClient.getChildrenAsync(routePath);\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nvar deletedRoutePath = string.Format(\"{0}/{1}\", routePath, deletedRouteTopic);\nvar addresses = await zooKeeperClient.getDataAsync(deletedRoutePath);\nif (addresses.Contains(hostAddr.ToString())) {\nawait zooKeeperClient.deleteAsync(deletedRoutePath);\n}\n}\n}\n}", "CodeBleu_score": 45.912019394727906}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t_logger.LogInformation(\"Updating service cache descriptors in Zookeeper...\");\n\nvar zooKeepers = _zooKeeperProvider.GetZooKeepers();\nvar tasks = new List<Task>();\nforeach (var zooKeeper in zooKeepers) {\ntasks.Add(SetCachesAsync(zooKeeper, cacheDescriptors));\n}\nawait Task.WhenAll(tasks);\n\n_logger.LogInformation(\"Successfully updated service cache descriptors in Zookeeper.\");\n}", "CodeBleu_score": 19.184601967729115}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (cacheDescriptors == null) {\nthrow new ArgumentNullException(nameof(cacheDescriptors));\n}\n\nif (cacheDescriptors.Count() == 0) {\nreturn;\n}\n\nvar cacheDescriptorsArray = cacheDescriptors.ToArray();\nvar cachePath = GetCachePath(cacheDescriptorsArray);\nvar zooKeeperClients = await GetZooKeepersAsync();\n\nforeach (var zooKeeperClient in zooKeeperClients) {\nawait zooKeeperClient.CreateRecursive(cachePath, null, true);\n\nforeach (var cacheDescriptor in cacheDescriptorsArray) {\nvar cacheDescriptorJson = SerializeObject(cacheDescriptor);\nvar cacheDescriptorPath = GetCacheDescriptorPath(cachePath, cacheDescriptor.Name);\nvar cacheDescriptorExists = await zooKeeperClient.ExistsAsync(cacheDescriptorPath) != null;\n\nif (cacheDescriptorExists) {\nvar cacheDescriptorJsonExists = await zooKeeperClient.ExistsAsync(cacheDescriptorPath) != null;\n\nif (cacheDescriptorJsonExists) {\nvar cacheDescriptorJsonData = await zooKeeperClient.GetDataAsync(cacheDescriptorPath);\n\nif (cacheDescriptorJsonData.DataEquals(cacheDescriptorJson)) {\ncontinue;\n}\n}\n\nawait zooKeeperClient.SetDataAsync(cacheDescriptorPath, cacheDescriptorJson);\n} else {\nawait zooKeeperClient.CreateAsync(cacheDescriptorPath, cacheDescriptorJson, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n}\n}\n}\n\n_logger.LogInformation(\n$\"Successfully updated cache descriptors for service {cachePath}.\"\n);\n}", "CodeBleu_score": 32.70023669736538}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tstring[] pathParts = path.Split(new char[] { '/' });\nstring currentPath = \"\";\nforeach (string pathPart in pathParts) {\ncurrentPath = string.Format(\"{0}/{1}\", currentPath, pathPart);\nif (await zooKeeper.Item2.existsAsync(currentPath) == null) {\n_logger.LogInformation(\"Creating Zookeeper node: {0}\", currentPath);\nawait zooKeeper.Item2.createAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}\n}", "CodeBleu_score": 41.50450854153417}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tif (zooKeeper.Item2.existsAsync(path).Result == null) {\n_logger.LogInformation(\"Creating the subdirectory {0}.\", path);\nawait CreateSubdirectory(zooKeeper, path.Substring(0, path.LastIndexOf(\"/\")));\nzooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}", "CodeBleu_score": 33.36828784284675}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tif (zooKeeper == null) throw new ArgumentNullException(nameof(zooKeeper));\nif (path == null) throw new ArgumentNullException(nameof(path));\nif (path == String.Empty) throw new ArgumentException(nameof(path));\nif (zooKeeper.Item2 == null) throw new ArgumentException(nameof(zooKeeper));\nif (zooKeeper.Item1 == null) throw new ArgumentException(nameof(zooKeeper));\n\nif (zooKeeper.Item1.WaitOne(0)) return;\n\nvar nodePath = path.TrimEnd('/');\nvar nodeNames = nodePath.Split('/');\nvar nodeNamesLength = nodeNames.Length;\nvar nodeNamesIndex = 0;\n\nwhile (nodeNamesIndex < nodeNamesLength) {\nvar nodePathPart = nodeNames[nodeNamesIndex];\nvar nodePathPartExists = await zooKeeper.Item2.existsAsync(nodePath);\n\nif (nodePathPartExists == null) {\n_logger.LogInformation(\"Creating Zookeeper node path {0}.\", nodePathPart);\n\nvar nodePathPartCreated = await zooKeeper.Item2.createAsync(nodePathPart, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\nif (nodePathPartCreated == null) {\n_logger.LogWarning(\"Failed to create Zookeeper node path {0}.\", nodePathPart);\n\nzooKeeper.Item1.Set();\nreturn;\n}\n}\n\nnodePath = nodePath.Substring(0, nodePath.Length - nodePathPart.Length - 1);\nnodeNames = nodePath.Split('/');\nnodeNamesLength = nodeNames.Length;\nnodeNamesIndex++;\n}\n\nzooKeeper.Item1.Set();\n}", "CodeBleu_score": 44.14819430734074}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.Addresses) {\nvar (connectionWait, zooKeeper) = CreateZooKeeper(ipAddress);\nawait _healthCheckService.IsHealth(ipAddress.ToHealthAddress(), connectionWait);\nresult.Add(zooKeeper);\n}\nreturn result;\n}", "CodeBleu_score": 68.68294810919761}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var ipAddress in _config.ZooKeeperAddresses) {\n\t\tvar (connectionWait, zk) = CreateZooKeeper(ipAddress);\n\t\tawait _healthCheckService.IsHealth(ipAddress, zk);\n\t\tresult.Add(new ValueTuple<ManualResetEvent, ZooKeeper>(connectionWait, zk));\n\t}\n\treturn result;\n}", "CodeBleu_score": 66.42118484374213}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n\tvar addresses = _config.ZooKeeperAddresses;\n\tforeach (var address in addresses) {\n\t\tvar (event, zk) = CreateZooKeeper(address);\n\t\tif (await _healthCheckService.IsHealth(address)) {\n\t\t\tresult.Add((event, zk));\n\t\t}\n\t}\n\treturn result;\n}", "CodeBleu_score": 71.11696582075172}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (this) {\n\t\tif (zooKeeper == null) {\n\t\t\tif (helper == null) {\n\t\t\t\thelper = new ZooKeeperHelper(connectionString, sessionTimeout, maxRetries, retryInterval, allowReadOnlyMode);\n\t\t\t}\n\t\t\tzooKeeper = helper.getZooKeeper();\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 35.953695123860065}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized(this) {\n\t\tif (zooKeeper == null) {\n\t\t\tif (connectionString == null) {\n\t\t\t\tthrow new Exception(\"ZooKeeper connection string is null\");\n\t\t\t}\n\t\t\tzooKeeper = new ZooKeeper(connectionString, sessionTimeout, this);\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 22.208176772227027}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (this) {\n\t\tif (helper == null) {\n\t\t\thelper = new Helper(this);\n\t\t}\n\t\treturn helper.getZooKeeper();\n\t}\n}", "CodeBleu_score": 17.880648018021937}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zookeeper == null) {\n\t\treturn;\n\t}\n\n\ttry {\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t// wait for shutdown\n\t\t\tLOG.info(\"Waiting for ZooKeeper client to shut down (timeout={} ms)\", waitForShutdownTimeoutMs);\n\t\t\tzookeeper.close(waitForShutdownTimeoutMs);\n\t\t} else {\n\t\t\t// shutdown immediately\n\t\t\tLOG.info(\"Closing ZooKeeper client immediately\");\n\t\t\tzookeeper.close();\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tLOG.error(\"Interrupted while waiting for ZooKeeper client to shut down\", e);\n\t\tThread.currentThread().interrupt();\n\t} finally {\n\t\tzookeeper = null;\n\t}\n}", "CodeBleu_score": 27.602227938742914}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zooKeeper != null) {\n\t\ttry {\n\t\t\tzooKeeper.register(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t} catch (Exception e) {\n\t\t\tLOG.error(\"Could not register dummy watcher to clear default watcher.\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tLOG.info(\"Waiting up to {} ms for ZooKeeper client to shut down.\", waitForShutdownTimeoutMs);\n\t\t\t\tzooKeeper.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tzooKeeper.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tLOG.error(\"Interrupted while waiting for ZooKeeper client to shut down.\", e);\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 41.48805853537684}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk != null) {\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tzk.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t} finally {\n\t\t\tzk = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 24.186809135721358}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tboolean isConnected = this.isConnected();\n\tif (isConnected) {\n\t\treturn true;\n\t}\n\tlong waitTimeMs = connectionTimeoutMs;\n\twhile (!isConnected && (waitTimeMs > 0)) {\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\ttry {\n\t\t\tthis.internalBlockUntilConnectedOrTimedOut(timeoutMs);\n\t\t} finally {\n\t\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\t\twaitTimeMs -= elapsed;\n\t\t}\n\t\tisConnected = this.isConnected();\n\t}\n\treturn isConnected;\n}", "CodeBleu_score": 29.81983566105198}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t//    checkState();\n    if (state.isConnected()) {\n        return true;\n    }\n    LOG.debug(\"Waiting for connection to {}\", state.getConnectString());\n    long startTimeMs = System.currentTimeMillis();\n    internalBlockUntilConnectedOrTimedOut();\n    long elapsed = System.currentTimeMillis() - startTimeMs;\n    LOG.debug(\"Connected to {} in {} ms\", state.getConnectString(), elapsed);\n    return state.isConnected();\n}", "CodeBleu_score": 41.93436904252449}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlong startTimeMs = System.currentTimeMillis();\n\tlong waitTimeMs = connectionTimeoutMs;\n\tboolean isConnected = false;\n\twhile (!isConnected && (waitTimeMs > 0)) {\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\ttry {\n\t\t\tisConnected = isConnected();\n\t\t\tif (isConnected) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tThread.sleep(timeoutMs);\n\t\t} finally {\n\t\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\t\twaitTimeMs -= elapsed;\n\t\t}\n\t}\n\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\tif (isConnected) {\n\t\ttracer.get().log(Level.INFO, \"Client is connected after \" + elapsed + \" ms\");\n\t} else {\n\t\ttracer.get().log(Level.WARNING, \"Client timed out after \" + elapsed + \" ms\");\n\t}\n\treturn isConnected;\n}", "CodeBleu_score": 31.54621402411565}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif (isStarted()) {\n\t\tLOG.info(\"Shutting down the service\");\n\t\tsetStarted(false);\n\t\ttry {\n\t\t\tcloseInternal(waitForShutdownTimeoutMs);\n\t\t} catch (IOException e) {\n\t\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\t\tLOG.warn(\"Interrupted while closing the service\", e);\n\t\t\t} else {\n\t\t\t\tthrow new RuntimeException(\"Could not close the service\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 39.838641710409576}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t//        log.debug(\"Closing {}\", this);\n        synchronized (this) {\n            if (isStarted()) {\n                log.info(\"Closing {}\", this);\n                setStarted(false);\n                try {\n                    doClose(waitForShutdownTimeoutMs);\n                } catch (IOException e) {\n                    if (Thread.currentThread().isInterrupted()) {\n                        log.warn(\"Interrupted while closing {}\", this, e);\n                    } else {\n                        log.error(\"Error closing {}\", this, e);\n                    }\n                }\n            }\n        }\n}", "CodeBleu_score": 40.184510530734954}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tif (isStarted()) {\n    log.info(\"Shutting down service {} with timeout {} ms\", this.getClass().getSimpleName(), waitForShutdownTimeoutMs);\n    this.started.set(false);\n    try {\n        closeInternal(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (Thread.currentThread().isInterrupted()) {\n            log.info(\"Interrupted while shutting down {}\", this.getClass().getSimpleName());\n        } else {\n            log.error(\"Error while shutting down {}\", this.getClass().getSimpleName(), e);\n        }\n    }\n}\n}", "CodeBleu_score": 45.05776963005674}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong start = System.currentTimeMillis();\n\tlong waitTime = timeout;\n\tCountDownLatch latch = new CountDownLatch(1);\n\tinternalAddConnectionStateListener(new ConnectionStateListener() {\n\t\t@Override\n\t\tpublic void onConnectionStateChanged(ConnectionState state) {\n\t\t\tif (state == ConnectionState.CONNECTED) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t}\n\t});\n\twhile (System.currentTimeMillis() - start < timeout && getState() != ConnectionState.CONNECTED) {\n\t\tlatch.await(waitTime, TimeUnit.MILLISECONDS);\n\t\twaitTime = timeout - (System.currentTimeMillis() - start);\n\t}\n\tinternalRemoveConnectionStateListener(this);\n\tif (getState() != ConnectionState.CONNECTED) {\n\t\tthrow new TimeoutException(\"Timeout waiting for connection\");\n\t}\n}", "CodeBleu_score": 31.59873168678107}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong startTime = System.currentTimeMillis();\n\tlong waitTime = connectionTimeout;\n\tCountDownLatch latch = new CountDownLatch(1);\n\tConnectionStateWatcher watcher = new ConnectionStateWatcher(latch, connectionState);\n\twatcher.start();\n\ttry {\n\t\twhile (waitTime > 0) {\n\t\t\tif (connectionState.isConnected()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tlatch.await(waitTime, TimeUnit.MILLISECONDS);\n\t\t\twaitTime = connectionTimeout - (System.currentTimeMillis() - startTime);\n\t\t}\n\t} finally {\n\t\twatcher.stop();\n\t}\n\tthrow new TimeoutException(\"Connection timed out after \" + connectionTimeout + \"ms\");\n}", "CodeBleu_score": 31.752785813632723}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong waitTime = getConnectionTimeout();\n\tCountDownLatch latch = new CountDownLatch(1);\n\tConnectionStateWatcher watcher = new ConnectionStateWatcher(latch, ConnectionState.CONNECTED);\n\tsynchronized (this) {\n\t\tif (getConnectionState() == ConnectionState.CONNECTED) {\n\t\t\treturn;\n\t\t}\n\t\taddConnectionStateListener(watcher);\n\t}\n\tlatch.await(waitTime, TimeUnit.MILLISECONDS);\n\tsynchronized (this) {\n\t\tremoveConnectionStateListener(watcher);\n\t}\n\tif (getConnectionState() != ConnectionState.CONNECTED) {\n\t\tthrow new TimeoutException(\"Connection timeout reached.\");\n\t}\n}", "CodeBleu_score": 20.898594224836167}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tString sessionId = client.getZooKeeper().getSessionId();\n\tif ( sessionId.equals(protectedId) ) {\n\t\treturn foundNode;\n\t}\n\telse {\n\t\tif ( protectedId == null ) {\n\t\t\tprotectedId = sessionId;\n\t\t\tLOGGER.info(\"Session ID changed from 0x{} to 0x{}\", Long.toHexString(0), Long.toHexString(sessionId));\n\t\t}\n\t\telse {\n\t\t\tLOGGER.info(\"Session ID changed from 0x{} to 0x{}\", Long.toHexString(protectedId), Long.toHexString(sessionId));\n\t\t\tclient.getZooKeeper().delete(foundNode, -1);\n\t\t\tprotectedId = sessionId;\n\t\t}\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 35.86049255888333}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tString sessionId = client.getZooKeeper().getSessionId();\n\tif ( sessionId.equals(protectedId) ) {\n\t\treturn foundNode;\n\t}\n\telse {\n\t\tif ( protectedId == null ) {\n\t\t\tprotectedId = sessionId;\n\t\t\tLOGGER.info(\"Session ID changed from {} to {} - this is expected during ephemeral node creation\", protectedId, sessionId);\n\t\t}\n\t\telse {\n\t\t\tLOGGER.info(\"Session ID changed from {} to {} - this is unexpected\", protectedId, sessionId);\n\t\t}\n\t\tprotectedId = sessionId;\n\t\tclient.getZooKeeper().delete(foundNode, -1);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 36.82724938164296}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode == CreateMode.EPHEMERAL) {\nif (client.getZooKeeper().getSessionId() != foundNode.getSessionId()) {\nif (client.getZooKeeper().getState() == KeeperState.CONNECTED) {\nif (foundNode.getStat() != null) {\nclient.getZooKeeper().delete(foundNode.getPath(), foundNode.getStat().getVersion());\n}\nclient.setZooKeeper(client.getZooKeeper().retry(client.getZooKeeper().getRetryPolicy()));\n}\n}\n}\nreturn foundNode.getPath();\n}", "CodeBleu_score": 24.92601380241071}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// Create the operation trace.\n\tTrace trace = new Trace(Operation.SET_ACL, path);\n\n\t// Start the trace.\n\ttrace.start();\n\n\t// Set the ACL.\n\tStat stat = zookeeper.setACL(path, aclList, -1);\n\n\t// Check if the ACL was set successfully.\n\tif (stat == null) {\n\t\t// The ACL was not set.\n\t\ttrace.fail();\n\t\tthrow new Exception(\"ACL not set: \" + path);\n\t}\n\n\t// Record the result.\n\ttrace.record(stat);\n\n\t// Commit the trace.\n\ttrace.commit();\n\n\t// Return the result.\n\treturn stat;\n}", "CodeBleu_score": 27.594377884146866}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tStat stat = new Stat();\n\ttry {\n\t\t// Start an advanced trace for the operation\n\t\tZooKeeperTrace.startAdvancedTrace(ZooKeeperTrace.ZOOKEEPER_SET_ACL_OP, path);\n\t\t// Set the ACL for the path\n\t\tstat = zooKeeper.setACL(path, aclList, -1);\n\t\t// Commit the advanced trace\n\t\tZooKeeperTrace.commitAdvancedTrace();\n\t} catch (Exception e) {\n\t\t// Rollback the advanced trace\n\t\tZooKeeperTrace.rollbackAdvancedTrace();\n\t\t// Throw the exception\n\t\tthrow e;\n\t}\n\treturn stat;\n}", "CodeBleu_score": 25.80898763889327}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// Start an advanced trace for the operation.\n\tfinal AdvancedTrace advancedTrace = new AdvancedTrace(AdvancedTraceType.ZOOKEEPER, \"setACL\", path);\n\tadvancedTrace.startTrace();\n\n\t// Create the retry loop object.\n\tfinal RetryLoop retryLoop = new RetryLoop();\n\n\t// Retry until the ACL is set successfully.\n\twhile (true) {\n\t\ttry {\n\t\t\t// Get the current ACL.\n\t\t\tfinal List<ACL> currentACL = zk.getACL(path, new Stat());\n\n\t\t\t// If the current ACL is not empty, remove all the current ACL entries.\n\t\t\tif (currentACL != null && !currentACL.isEmpty()) {\n\t\t\t\tzk.setACL(path, new ArrayList<ACL>(), -1);\n\t\t\t}\n\n\t\t\t// Set the new ACL.\n\t\t\tzk.setACL(path, aclList, -1);\n\n\t\t\t// Get the new ACL.\n\t\t\tfinal List<ACL> newACL = zk.getACL(path, new Stat());\n\n\t\t\t// If the new ACL is not empty, the ACL has been set successfully.\n\t\t\tif (newACL != null && !newACL.isEmpty()) {\n\t\t\t\t// Commit the trace.\n\t\t\t\tadvancedTrace.commitTrace();\n\n\t\t\t\t// Return the status of the operation.\n\t\t\t\treturn new Stat();\n\t\t\t}\n\t\t}\n\t\tcatch (KeeperException.NoNodeException e) {\n\t\t\t// If the node does not exist, the ACL has been set successfully.\n\t\t\tadvancedTrace.commitTrace();\n\n\t\t\t// Return the status of the operation.\n\t\t\treturn new Stat();\n\t\t}\n\t\tcatch (KeeperException e) {\n\t\t\t// If the ACL could not be set, retry the operation.\n\t\t\tadvancedTrace.setFailMessage(e.getMessage());\n\t\t\tadvancedTrace.setFailStackTrace(ExceptionUtils.getStackTrace(e));\n\t\t\tadvancedTrace.incrementFailCount();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\t// If any other exception occurs, retry the operation.\n\t\t\tadvancedTrace.setFailMessage(e.getMessage());\n\t\t\tadvancedTrace.setFailStackTrace(ExceptionUtils.getStackTrace(e));\n\t\t\tadvancedTrace.incrementFailCount();\n\t\t}\n\n\t\t// Sleep for a short time before retrying the operation.\n\t\tretryLoop.sleep();\n\t}\n}", "CodeBleu_score": 26.84169122758663}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.idCheck();\n\tthis.cache = new CuratorCache(client, membershipPath, new GroupMembershipListener(this));\n\tthis.node = PersistentNode.makePath(client, membershipPath + \"/\" + thisId, payload, CreateMode.EPHEMERAL);\n}", "CodeBleu_score": 45.1573196791512}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.memberPath = makePath(membershipPath, thisId);\n\tthis.cache = new CuratorCache(client, membershipPath, new CacheDataBuilder() {\n\t\tpublic byte[] build(ChildData data) throws Exception {\n\t\t\treturn data.getData();\n\t\t}\n\t});\n\tthis.cache.listenable().addListener(this);\n\tthis.node = PersistentNode.makePersistent(client, memberPath, payload, CreateMode.EPHEMERAL);\n\tthis.node.start();\n}", "CodeBleu_score": 42.39380944660071}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tsuper(client, membershipPath, thisId);\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath, new GroupMemberCacheListener(this));\n\tthis.cache.listenable().addListener(cacheListener);\n\tthis.persistentNode = PersistentNode.makePersistent(client, membershipPath, thisId, payload, CreateMode.EPHEMERAL);\n}", "CodeBleu_score": 39.97451776178252}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t\ttry {\n\t\tclient.create().forPath(path);\n\n\t\t// set up a watch on the node to handle future events\n\t\tclient.getChildren().usingWatcher(new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tSystem.out.println(\"Event: \" + event);\n\t\t\t}\n\t\t}).forPath(path);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 30.99833693451653}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t// create a node at the given path asynchronously\nclient.create().forPath(path, \"some data\".getBytes()).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // set up a watch on the node. This will trigger every time the node changes\n        client.getChildren().watched().forPath(path).whenComplete((children, watcherException) -> {\n            if (watcherException != null) {\n                watcherException.printStackTrace();\n            } else {\n                System.out.println(\"Children are: \" + children);\n            }\n        });\n    }\n});\n}", "CodeBleu_score": 60.01612597322622}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t// create a node at the given path with an empty payload asynchronously\nclient.create().forPath(path, new byte[0]).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // set up a watch on the node so that we get notified of changes\n        client.getChildren().watched().forPath(path).whenComplete((children, watcherException) -> {\n            if (watcherException != null) {\n                watcherException.printStackTrace();\n            } else {\n                System.out.println(\"Current children are: \" + children);\n            }\n        });\n    }\n});\n}", "CodeBleu_score": 60.063469166437}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t", "CodeBleu_score": 3.001154690052189}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t", "CodeBleu_score": 3.001154690052189}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = new ArrayList<OpResult>(multi.size());\n\tint i = 0;\n\tfor (Op op : multi) {\n\t\ttry {\n\t\t\tresults.add(op.execute());\n\t\t} catch (KeeperException e) {\n\t\t\tif (e.code() == KeeperException.Code.CONNECTIONLOSS) {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t\tif (i == 0) {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t\tresults.add(new OpResult(e.code(), null, null, null));\n\t\t}\n\t\ti++;\n\t}\n\treturn results;\n}", "CodeBleu_score": 26.103718684738077}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tSystem.out.println(\"Listing instances for all services\");\n\n// Query for all services\nList<String> names = serviceDiscovery.queryForNames();\n\n// Print the service names and their instances\nfor (String name : names) {\n    System.out.println(\"\\t\" + name + \":\");\n    List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(name);\n    for (ServiceInstance<InstanceDetails> instance : instances) {\n        outputInstance(instance);\n    }\n}\n\n// Close the ServiceDiscovery instance quietly\nserviceDiscovery.close();\n}", "CodeBleu_score": 45.651189878727884}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tSystem.out.println(\"Listing instances for all services\");\n\n// Retrieve all service names\nCollection<String> serviceNames = serviceDiscovery.queryForNames();\n\n// For each service name, retrieve all instances\nfor (String serviceName : serviceNames) {\n    Collection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n    System.out.println(\"\\tService: \" + serviceName);\n\n    // For each instance, output the instance's details\n    for (ServiceInstance<InstanceDetails> instance : instances) {\n        outputInstance(instance);\n    }\n}\n}", "CodeBleu_score": 55.09150774539868}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tSystem.out.println(\"Listing instances:\");\n\tList<String> names = serviceDiscovery.queryForNames();\n\tSystem.out.println(\"\\t\" + names.size() + \" services found\");\n\tfor (String name : names) {\n\t\tSystem.out.println(\"\\t\" + name + \":\");\n\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(name);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.74562867344881}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.remove(READY_NODE);\n\tchildren.sort();\n\treturn children;\n}", "CodeBleu_score": 15.732405714756245}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (child.equals(READY_NODE)) {\n\t\t\tcontinue;\n\t\t}\n\t\tfilteredChildren.add(child);\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 26.32590335278422}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = children.stream()\n\t\t.filter(child -> !child.equals(READY_NODE))\n\t\t.collect(Collectors.toList());\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 34.87389036529411}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t//        if (zk != null) {\n//            zk.close();\n//        }\n//        zk = new ZooKeeper(newHost, timeout, this);\n//        zk.setReadOnly(readonly);\n}", "CodeBleu_score": 4.125715113000573}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t//        if (zk != null) {\n//            zk.close();\n//        }\n//        zk = new ZooKeeper(newHost, timeout, this);\n//        if (readOnly) {\n//            zk.setReadOnlyMode();\n//        }\n}", "CodeBleu_score": 4.125715113000573}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t", "CodeBleu_score": 4.002539703279978}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\nString[] aclStrings = aclString.split(\",\");\nfor (String aclStr : aclStrings) {\nString[] parts = aclStr.split(\":\");\nif (parts.length != 3) {\noutputStream.write((\"Invalid ACL syntax: \" + aclStr).getBytes());\ncontinue;\n}\nACL acl = new ACL();\nacl.setId(new Id(parts[0], parts[1].getBytes()));\nacl.setPerms(getPermFromString(parts[2]));\naclList.add(acl);\n}\nreturn aclList;\n}", "CodeBleu_score": 26.984014813389024}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> aclList = new ArrayList<ACL>();\n\tif (aclString != null) {\n\t\tString[] acls = aclString.split(\",\");\n\t\tfor (String acl : acls) {\n\t\t\tString[] parts = acl.split(\":\");\n\t\t\tif (parts.length == 3) {\n\t\t\t\tACL newAcl = new ACL(getPermFromString(parts[2]), new Id(parts[0], parts[1]));\n\t\t\t\taclList.add(newAcl);\n\t\t\t} else {\n\t\t\t\toutputStream.write((\"Invalid ACL: \" + acl).getBytes());\n\t\t\t}\n\t\t}\n\t}\n\treturn aclList;\n}", "CodeBleu_score": 26.24603082348582}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\nString[] acls = aclString.split(\",\");\nfor (String acl : acls) {\nString[] parts = acl.split(\":\");\nif (parts.length != 3) {\noutputStream.write((\"Invalid ACL syntax: \" + acl).getBytes());\n} else {\nACL newAcl = new ACL();\nnewAcl.setId(new Id(parts[0], parts[1]));\ntry {\nnewAcl.setPerms(getPermFromString(parts[2]));\n} catch (IOException e) {\noutputStream.write((\"Invalid perms: \" + parts[2]).getBytes());\n}\naclList.add(newAcl);\n}\n}\nreturn aclList;\n}", "CodeBleu_score": 31.172165232314136}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(List.of(new ACL(ZooDefs.Perms.ALL, ZooDefs.Ids.ANYONE_ID_UNSAFE)))\n\t\t\t.build();\n\tvar connection = factory.create(params);\n\tvar client = connection.getZookeeperClient();\n\twriter.write(\"Connecting to Zookeeper instance \" + url + \" ...\n\");\n\twriter.flush();\n\tif (client.blockUntilConnectedOrTimedOut()) {\n\t\twriter.write(\"Connected to Zookeeper instance \" + url + \"!\n\");\n\t\twriter.flush();\n\t\treturn new Terminal(id, url, connection, new ZooKeeperMain(client));\n\t} else {\n\t\twriter.write(\"Connection to Zookeeper instance \" + url + \" timed out!\n\");\n\t\twriter.flush();\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 57.64861423772098}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t//        System.out.println(\"createTerminal\");\n        ZooKeeperMain zkMain = new ZooKeeperMain(id, url);\n        zkMain.connect();\n        writer.write(\"Connected to \" + url + \"\n\");\n        return new Terminal(id, url, zkMain);\n    }", "CodeBleu_score": 22.597956299687322}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tfinal CuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n\tfinal ZookeeperParams params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(ZookeeperAcl.OPEN_ACL_UNSAFE)\n\t\t\t.build();\n\tfinal ZooKeeperMain main = new ZooKeeperMain(factory.create(params));\n\twriter.write(\"Connecting to Zookeeper at \" + url + \"...\");\n\twriter.flush();\n\treturn new Terminal(id, url, main);\n}", "CodeBleu_score": 45.91779628034387}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t\n}", "CodeBleu_score": 1.0145750671711116}, {"code": "public void blockUntilConnected(){\n\t\tint retries = 0;\n\twhile (retries < 6 && !isConnected()) {\n\t\ttry {\n\t\t\tretries++;\n\t\t\tlogger.info(\"Attempting to connect to SSH tunnel (attempt \" + retries + \")...\");\n\t\t\tconnect();\n\t\t\tlogger.info(\"Successfully connected to SSH tunnel\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to connect to SSH tunnel\", e);\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel\", e);\n\t\t}\n\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tlogger.error(\"Interrupted while attempting to connect to SSH tunnel\", e);\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Interrupted while attempting to connect to SSH tunnel\", e);\n\t\t}\n\t}\n\n\tif (!isConnected()) {\n\t\tlogger.error(\"Failed to connect to SSH tunnel after 6 attempts\");\n\t\tclose();\n\t\tthrow new IllegalStateException(\"Failed to connect to SSH tunnel after 6 attempts\");\n\t}\n}", "CodeBleu_score": 40.728521968227824}, {"code": "public void blockUntilConnected(){\n\t\tint attempt = 0;\n\twhile (!isConnected() && attempt < 6) {\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IllegalStateException(e);\n\t\t}\n\t\tlog.info(\"Attempting to connect to SSH proxy server (attempt \" + attempt + \")...\");\n\t\tattempt++;\n\t}\n\n\tif (!isConnected()) {\n\t\tthrow new IllegalStateException(\"Unable to connect to SSH proxy server after 6 attempts.\");\n\t}\n}", "CodeBleu_score": 48.38541156817649}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\nzookeeperDomainService.deleteNode(serverId, pathList);\n} catch (Exception e) {\nlog.error(\"Error deleting node for serverId \" + serverId + \" and pathList \" + pathList, e);\nthrow new IllegalStateException(\"Error deleting node for serverId \" + serverId + \" and pathList \" + pathList, e);\n}\n}", "CodeBleu_score": 57.75729357332504}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOG.error(\"Error while deleting node\", e);\n\t\tthrow new IllegalStateException(\"Error while deleting node\");\n\t}\n}", "CodeBleu_score": 70.14556511748228}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"An error occurred while deleting nodes from Zookeeper\", e);\n\t\tthrow new IllegalStateException(\"An error occurred while deleting nodes from Zookeeper\", e);\n\t}\n}", "CodeBleu_score": 61.551043748321945}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\n}", "CodeBleu_score": 3.3910150352935258}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\n    ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n    zookeeperDomainService.disconnect(serverConfiguration.getId());\n    treeItemCache.remove(id);\n});\n}", "CodeBleu_score": 90.41737480458565}, {"code": "public void disconnect(String id){\n\t\n}", "CodeBleu_score": 3.3910150352935258}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"Server with ID \" + serverId + \" not found\");\n\t}\n\tif (server.getTerminal() != null) {\n\t\tthrow new IllegalArgumentException(\"Terminal already started for server with ID \" + serverId);\n\t}\n\tTerminal terminal = new Terminal(stream);\n\tserver.setTerminal(terminal);\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl);\n}", "CodeBleu_score": 31.041995962796648}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tif (serverId == null || serverId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"serverId cannot be null or empty\");\n\t}\n\tif (stream == null) {\n\t\tthrow new IllegalArgumentException(\"stream cannot be null\");\n\t}\n\tServer server = getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server with id \" + serverId + \" not found\");\n\t}\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 30.10795730640858}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tif (serverId == null || serverId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"serverId cannot be null or empty\");\n\t}\n\tif (stream == null) {\n\t\tthrow new IllegalArgumentException(\"stream cannot be null\");\n\t}\n\tServer server = getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server with ID \" + serverId + \" does not exist\");\n\t}\n\tString connectionUrl = getConnectionUrl(server);\n\tif (connectionUrl == null) {\n\t\tthrow new IllegalArgumentException(\"connection URL for server with ID \" + serverId + \" does not exist\");\n\t}\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 30.31921823571921}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\t// Get the server's ZooKeeper instance\n\t\tZooKeeper zk = zkMap.get(id);\n\t\t// Execute the command\n\t\tzk.create(command, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t} catch (KeeperException e) {\n\t\t// Log the error with the server ID and command\n\t\tlogger.error(\"Error executing command \" + command + \" on server \" + id);\n\t\t// Display an error message indicating that the command execution failed and should be retried\n\t\tSystem.out.println(\"Error executing command \" + command + \" on server \" + id + \". Please try again.\");\n\t} catch (InterruptedException e) {\n\t\tlogger.error(\"Error executing command \" + command + \" on server \" + id);\n\t\tSystem.out.println(\"Error executing command \" + command + \" on server \" + id + \". Please try again.\");\n\t}\n}", "CodeBleu_score": 32.37827021620282}, {"code": "public void executeCommand(String id, String command){\n\t\t// TODO: Implement this method\n\ttry {\n\t\tzk.command(id, command);\n\t} catch (Exception e) {\n\t\tSystem.err.println(\"Error executing command \" + command + \" on server \" + id + \": \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 47.75648258518195}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\t// Execute the given command\n\t\tzk.command(id, command);\n\t} catch (Exception e) {\n\t\t// Log the error\n\t\tSystem.err.println(\"Error executing command \" + command + \" on server \" + id);\n\t\t// Display an error message\n\t\tSystem.err.println(\"Error executing command: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 54.56562763721874}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties props = new Properties();\ntry {\nif (new File(ZOOKEEPER_CONFIG_FILE).exists()) {\nprops.load(new FileInputStream(ZOOKEEPER_CONFIG_FILE));\nlogger.info(\"Loaded zookeeper system properties from \" + ZOOKEEPER_CONFIG_FILE + \": \" + props.toString());\n} else {\nlogger.error(\"Zookeeper config file not found: \" + ZOOKEEPER_CONFIG_FILE);\n}\n} catch (IOException e) {\nlogger.error(\"Error loading zookeeper system properties from \" + ZOOKEEPER_CONFIG_FILE + \": \" + e.getMessage());\n}\nreturn props;\n}", "CodeBleu_score": 36.59667372673305}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nif (new File(ZOOKEEPER_CONFIG_FILE).exists()) {\nproperties.load(new FileInputStream(ZOOKEEPER_CONFIG_FILE));\nlogger.info(\"Loaded zookeeper system properties from \" + ZOOKEEPER_CONFIG_FILE);\n} else {\nlogger.error(ZOOKEEPER_CONFIG_FILE + \" does not exist.  Not loading zookeeper system properties\");\n}\n} catch (IOException e) {\nlogger.error(\"Error loading zookeeper system properties from \" + ZOOKEEPER_CONFIG_FILE, e);\n}\nreturn properties;\n}", "CodeBleu_score": 35.51254320089862}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tFile file = new File(ZOOKEEPER_CONFIG_FILE_PATH);\n\t\tif (file.exists()) {\n\t\t\tFileInputStream fis = new FileInputStream(file);\n\t\t\tprops.load(fis);\n\t\t\tfis.close();\n\t\t\tlog.info(\"Loaded Zookeeper system properties from file: \" + ZOOKEEPER_CONFIG_FILE_PATH);\n\t\t} else {\n\t\t\tlog.error(\"Zookeeper system properties file does not exist: \" + ZOOKEEPER_CONFIG_FILE_PATH);\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading Zookeeper system properties from file: \" + ZOOKEEPER_CONFIG_FILE_PATH, e);\n\t}\n\treturn props;\n}", "CodeBleu_score": 35.54736404764445}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tOutputStream out = new FileOutputStream(SYS_PROP_PATH);\n\t\tproperties.store(out, \"Saved by Zookeeper\");\n\t\tout.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error saving Zookeeper system properties\", e);\n\t\tNotifications.create().title(\"Error saving Zookeeper system properties\").text(\"Check the logs for more information.\").showError();\n\t}\n}", "CodeBleu_score": 27.616162135825007}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tOutputStream output = new FileOutputStream(SYS_PROP_PATH);\n\t\tproperties.store(output, null);\n\t\toutput.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error loading Zookeeper system properties\", e);\n\t\tNotifications.create().title(\"Error loading Zookeeper system properties\").text(\"Check the logs for more information.\").showError();\n\t}\n}", "CodeBleu_score": 28.575706610986806}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tproperties.store(new FileOutputStream(SYS_PROP_PATH), null);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Unable to save Zookeeper system properties\", e);\n\t\tNotifications.create().title(\"Error saving Zookeeper system properties\").text(\"Unable to save Zookeeper system properties\").showError();\n\t}\n}", "CodeBleu_score": 21.80364742355908}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t\tStringBuilder sb = new StringBuilder();\n\tBufferedReader br = null;\n\ttry {\n\t\tbr = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line = br.readLine();\n\t\twhile (line != null) {\n\t\t\tsb.append(line);\n\t\t\tline = br.readLine();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from socket\", e);\n\t} finally {\n\t\tcleanup(br);\n\t\tcleanup(client);\n\t}\n\treturn sb.toString();\n}", "CodeBleu_score": 46.88071812686344}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString inputLine;\n\t\twhile ((inputLine = in.readLine()) != null) {\n\t\t\tsb.append(inputLine);\n\t\t}\n\t\tcleanup(in);\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Could not read from socket\", e);\n\t}\n}", "CodeBleu_score": 49.58391547851478}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tStringBuilder response = new StringBuilder();\n\t\tString inputLine;\n\t\twhile ((inputLine = in.readLine()) != null) {\n\t\t\tresponse.append(inputLine);\n\t\t}\n\t\tcleanup(client);\n\t\treturn response.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from socket\", e);\n\t}\n}", "CodeBleu_score": 49.97009775163662}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tfinal CuratorFramework curatorFramework = curatorFramework(params);\n\ttry {\n\t\tcuratorFramework.start();\n\t\tif (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n\t\t\tcuratorFramework.close();\n\t\t\tthrow new ZookeeperConnectionException(\"Unable to connect to zookeeper within 5 seconds\");\n\t\t}\n\t\treturn new CuratorZookeeperConnection(curatorFramework);\n\t} catch (final Exception e) {\n\t\tcuratorFramework.close();\n\t\tthrow new ZookeeperConnectionException(\"Unable to connect to zookeeper\", e);\n\t}\n}", "CodeBleu_score": 52.771218814436885}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tfinal CuratorFramework curatorFramework = curatorFramework(params);\ncuratorFramework.start();\ntry {\n    if (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n        curatorFramework.close();\n        throw new ZookeeperConnectionException(\"Unable to connect to Zookeeper\");\n    }\n} catch (final Exception e) {\n    curatorFramework.close();\n    throw new ZookeeperConnectionException(e);\n}\nreturn new CuratorZookeeperConnection(curatorFramework);\n}", "CodeBleu_score": 52.820793425719714}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\n}", "CodeBleu_score": 3.463844142688477}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t//        if (isSync.compareAndSet(false, true)) {\n//            logger.info(\"Starting synchronization of Zookeeper nodes\");\n//            String connectionString = getCurrentConnectionString();\n//            logger.debug(\"Current Zookeeper connection string: \" + connectionString);\n//            try {\n//                treeCache = CuratorTreeCache.create(curatorFramework, connectionString, \"/\");\n//                treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n//                treeCache.start();\n//            } catch (Exception e) {\n//                logger.error(\"Error starting TreeCache\", e);\n//                close();\n//            }\n//        } else {\n//            logger.info(\"Synchronization already in progress\");\n//        }\n}", "CodeBleu_score": 2.6809899971628313}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (!isSync.compareAndSet(false, true)) {\n\t\tLOGGER.info(\"Synchronization already in progress\");\n\t\treturn;\n\t}\n\n\tLOGGER.info(\"Starting synchronization\");\n\ttry {\n\t\tString connectionString = getCurrentConnectionString();\n\t\tLOGGER.info(\"Connection string: {}\", connectionString);\n\t\ttreeCache = CuratorTreeCache.build(curatorFramework, connectionString);\n\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\ttreeCache.start();\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error while starting synchronization\", e);\n\t\tclose();\n\t}\n}", "CodeBleu_score": 43.955798299036694}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (!isSync.get()) {\n\t\tlogger.info(\"Starting synchronization with Zookeeper\");\n\t\ttry {\n\t\t\tcuratorFramework.getConnectionStateListenable().addListener(this);\n\t\t\ttreeCache = new CuratorTreeCache(curatorFramework, rootNodePath);\n\t\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\t\ttreeCache.start();\n\t\t\tisSync.set(true);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error starting synchronization with Zookeeper\", e);\n\t\t\ttreeCache.close();\n\t\t}\n\t} else {\n\t\tlogger.info(\"Synchronization with Zookeeper is already in progress\");\n\t}\n}", "CodeBleu_score": 48.75171957214104}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.getListenable().addListener(listener);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 69.20128486956945}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\n}", "CodeBleu_score": 12.867095662891915}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\ttry {\n\t\tSystem.out.println(\"Unregistering service...\");\n\t\tfor (String path : paths) {\n\t\t\tSystem.out.println(\"Deleting path: \" + path);\n\t\t\ttry {\n\t\t\t\tclient.delete().forPath(path);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.out.println(\"Error deleting path: \" + e.getMessage());\n\t\t\t}\n\t\t}\n\t\tclient.close();\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error unregistering service: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 44.16192664424556}, {"code": "public void unregisterService(){\n\t\ttry {\n\t\tSystem.out.println(\"Unregistering service\");\n\t\tSystem.out.println(\"Closing connection to Zookeeper\");\n\t\tclient.close();\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 23.212649576294442}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\ttry {\n\t\tclient.start();\n\t\tSystem.out.println(\"Connected to Zookeeper\");\n\t\tfor (String path : paths) {\n\t\t\tSystem.out.println(\"Deleting path: \" + path);\n\t\t\tclient.delete().deletingChildrenIfNeeded().forPath(path);\n\t\t}\n\t\tSystem.out.println(\"Deleted paths\");\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error deleting paths: \" + e.getMessage());\n\t} finally {\n\t\ttry {\n\t\t\tclient.close();\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Error closing client: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 41.70935473936096}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t//    client.subscribeStateChanges(listener);\n    client.subscribeStateChanges(new IZkStateListener() {\n        @Override\n        public void handleStateChanged(KeeperState state) throws Exception {\n            listener.handleStateChanged(state);\n        }\n\n        @Override\n        public void handleNewSession() throws Exception {\n            listener.handleNewSession();\n        }\n\n        @Override\n        public void handleSessionEstablishmentError(Throwable error) throws Exception {\n            listener.handleSessionEstablishmentError(error);\n        }\n    });\n}", "CodeBleu_score": 41.15400157778314}, {"code": "public void addListener(IZkStateListener listener){\n\t//    if (this.client == null) {\n        this.client = new ZkClient(this.zkServers, this.sessionTimeout, this.connectionTimeout, new ZKStringSerializer());\n        this.client.addListener(stateListener);\n        this.client.retryUntilConnected(new Callable<Boolean>() {\n            @Override\n            public Boolean call() throws Exception {\n                makeClientReady(client, null);\n                return true;\n            }\n        });\n//    }\n}", "CodeBleu_score": 24.871647519552763}, {"code": "public void addListener(IZkStateListener listener){\n\t\tCompletableFuture<ZkClient> completableFuture = new CompletableFuture<>();\n\tclient.subscribeStateChanges(new IZkStateListener() {\n\t\t@Override\n\t\tpublic void handleStateChanged(KeeperState state) throws Exception {\n\t\t\tlistener.handleStateChanged(state);\n\t\t}\n\n\t\t@Override\n\t\tpublic void handleNewSession() throws Exception {\n\t\t\tlistener.handleNewSession();\n\t\t}\n\n\t\t@Override\n\t\tpublic void handleSessionEstablishmentError(Throwable error) throws Exception {\n\t\t\tlistener.handleSessionEstablishmentError(error);\n\t\t}\n\t});\n\tclient.createPersistent(\"/test\", true);\n}", "CodeBleu_score": 20.777840809537246}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, 30000, 3, 15000, null);\n}", "CodeBleu_score": 3.410257383920392}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\nretryPolicy = new ExponentialBackoffRetry(1000, 3);\nconnectionTimeoutMs = 15 * 1000;\nclient = CuratorFrameworkFactory.newClient(serverAddr, connectionTimeoutMs, retryPolicy);\nclient.getConnectionStateListenable().addListener(this);\ntry {\nif (authority != null) {\nclient.start();\nclient.getZookeeperClient().blockUntilConnectedOrTimedOut();\nclient.getZookeeperClient().addAuthInfo(AUTH_DATA_TYPE, authority.getBytes(Charsets.UTF_8));\n} else {\nclient.start();\nclient.getZookeeperClient().blockUntilConnectedOrTimedOut();\n}\n} catch (Exception e) {\nthrow new IllegalStateException(\"Error initializing CuratorZookeeperClient\", e);\n}\n}", "CodeBleu_score": 28.90017545786188}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, new ExponentialBackoffRetry(1000, 3));\n}", "CodeBleu_score": 3.6881791898849783}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener must not be null\");\n\t}\n\tsynchronized (this.lock) {\n\t\tMap<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n\t\tif (listeners != null) {\n\t\t\tTargetChildListener targetListener = listeners.remove(listener);\n\t\t\tif (targetListener != null) {\n\t\t\t\tremoveTargetChildListener(path, targetListener);\n\t\t\t}\n\t\t\tif (listeners.isEmpty()) {\n\t\t\t\tthis.listeners.remove(path);\n\t\t\t\tif (this.listeners.isEmpty()) {\n\t\t\t\t\tthis.listeners.clear();\n\t\t\t\t\tremoveTargetChildListener(path, this.listener);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 69.41882967567123}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"Path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener must not be null\");\n\t}\n\tsynchronized (lock) {\n\t\tif (childListeners.containsKey(path)) {\n\t\t\tMap<String, ChildListener> listeners = childListeners.get(path);\n\t\t\tlisteners.remove(listener.toString());\n\t\t\tif (listeners.isEmpty()) {\n\t\t\t\tchildListeners.remove(path);\n\t\t\t\tremoveTargetChildListener(path, targetChildListeners.get(path));\n\t\t\t\ttargetChildListeners.remove(path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.88173870501143}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"Path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener must not be null\");\n\t}\n\tif (listeners.containsKey(path)) {\n\t\tlisteners.get(path).remove(listener);\n\t\tif (listeners.get(path).isEmpty()) {\n\t\t\tremoveTargetChildListener(path, targetChildListeners.get(path));\n\t\t\tlisteners.remove(path);\n\t\t\ttargetChildListeners.remove(path);\n\t\t}\n\t}\n}", "CodeBleu_score": 36.293134377085764}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tint ret = QCONF_OK;\n\tif (zh == NULL) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tstring idc_host;\n\tret = lock_ht_find(idc_ht, idc_ht_mu, zh, idc_host);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tlock_ht_delete(idc_ht, idc_ht_mu, zh);\n\tqconf_host_t host;\n\tret = lock_ht_find(host_ht, host_ht_mu, zh, host);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tlock_ht_delete(host_ht, host_ht_mu, zh);\n\tqconf_idc_t idc;\n\tret = deserialize_from_idc_host(idc_host, idc, host);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tret = zookeeper_close(zh);\n\tif (ret != ZOK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tret = zookeeper_init(idc.c_str(), watcher_func, host.c_str(), &zh, 10000, 0, 0);\n\tif (ret != ZOK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tret = init_env_for_zk(zh, idc, host);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\treturn ret;\n}", "CodeBleu_score": 44.854814749677416}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tint ret = QCONF_OK;\n\tif (!zh) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\t// Retrieve and delete the old host information\n\tchar *idc_host = NULL;\n\tif (QCONF_OK != (ret = lock_ht_find(g_idc_host_ht, g_idc_host_mu, zh, idc_host))) {\n\t\treturn ret;\n\t}\n\tlock_ht_delete(g_idc_host_ht, g_idc_host_mu, zh);\n\t// Close the old handle\n\tret = zookeeper_close(zh);\n\tif (ZOK != ret) {\n\t\tLOG_ERR(\"zookeeper_close failed, ret=%d\", ret);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\t// Deserialize the IDC and host information\n\tqconf_host_t host;\n\tif (QCONF_OK != (ret = deserialize_from_idc_host(idc_host, host))) {\n\t\tLOG_ERR(\"deserialize_from_idc_host failed, ret=%d\", ret);\n\t\treturn ret;\n\t}\n\t// Initialize a new handle with this information\n\tzh = zookeeper_init(host.c_str, watcher_callback, host.timeout, host.session_id, host.passwd, host.is_auth);\n\tif (!zh) {\n\t\tLOG_ERR(\"zookeeper_init failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\t// Initialize the environment for the new handle\n\tret = init_env_for_zk(zh);\n\tif (QCONF_OK != ret) {\n\t\tLOG_ERR(\"init_env_for_zk failed, ret=%d\", ret);\n\t\treturn ret;\n\t}\n\t// Reset the table watcher\n\tret = watcher_callback(zh, ZOO_SESSION_EVENT, NULL);\n\tif (ZOK != ret) {\n\t\tLOG_ERR(\"watcher_callback failed, ret=%d\", ret);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\treturn QCONF_OK;\n}", "CodeBleu_score": 43.24136413442703}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (!zh) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Retrieve and delete the IDC host information associated with the handle\n\tstring idc_host;\n\tif (lock_ht_find(idc_ht, idc_ht_mu, zh, idc_host) != QCONF_OK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tlock_ht_delete(idc_ht, idc_ht_mu, zh);\n\n\t// Close the old handle\n\tint ret = zookeeper_close(zh);\n\tif (ret != ZOK) {\n\t\tLOG_ERR(\"zookeeper_close failed, ret: %d\", ret);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Deserialize the IDC and host information and initialize a new ZooKeeper handle with this information\n\tret = deserialize_from_idc_host(idc_host, &zh, &idc_ht, &idc_ht_mu);\n\tif (ret != QCONF_OK) {\n\t\tLOG_ERR(\"deserialize_from_idc_host failed, ret: %d\", ret);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Initialize the environment for the new handle and reset the table watcher\n\tret = init_env_for_zk(zh);\n\tif (ret != QCONF_OK) {\n\t\tLOG_ERR(\"init_env_for_zk failed, ret: %d\", ret);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\treturn QCONF_OK;\n}", "CodeBleu_score": 32.887421510051865}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n}", "CodeBleu_score": 4.319947644130407}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n}", "CodeBleu_score": 4.319947644130407}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// TODO: check zh is connected\n\tzk_register_ephemeral(zh, idc_host, idc);\n\t// TODO: check zh is connected\n\twatch_notify_node(zh, idc_host, idc);\n}", "CodeBleu_score": 17.348584339566735}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1((username + \":\" + password).encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode()\n\n", "CodeBleu_score": 27.770588200463525}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1((username + ':' + password).encode()).digest()\n    return username + ':' + b64encode(cred_hash).decode()\n", "CodeBleu_score": 22.231972080705802}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode()\n", "CodeBleu_score": 31.764147029464663}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.processing_element.get_lock_path()\n        self.zk_client.sync(lock_path)\n        lock_value = self.zk_client.get(lock_path)[0]\n        return lock_value == self.processing_element.instance_id\n\n", "CodeBleu_score": 46.28689922978666}, {"code": "def holds_lock(self)\n\t\n    # If there is no processing element, return False\n    if self.processing_element is None:\n        return False\n    # Construct the lock path\n    lock_path = self.processing_element + '/lock'\n    # Synchronize with the Zookeeper client\n    self.zk.sync(lock_path)\n    # Retrieve the lock value\n    lock_value = self.zk.get(lock_path)[0].decode('utf-8')\n    # Return True if the lock value matches the instance ID\n    return lock_value == self.instance_id\n", "CodeBleu_score": 47.713497083094545}, {"code": "def holds_lock(self)\n\t\n    # TODO: Implement this\n    return False\n", "CodeBleu_score": 1.1580938446711797}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if not self.holds_lock():\n        return False\n    with self.client.transaction() as txn:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        txn.delete(lock_path)\n        txn.delete(self._path)\n        txn.set_data(self._processing_element_path, None)\n        self.processing_element = None\n    return True\n\n", "CodeBleu_score": 49.91312769947353}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    self.client.transaction(\n        self.client.delete, lock_path,\n        self.client.set, self.path, None\n    )\n    if self.client.retry(self.holds_lock):\n        raise RuntimeError(\"Lock was not held\")\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 50.763209142067026}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    self.client.sync(lock_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value != self.id:\n        return False\n    transaction = self.client.transaction()\n    transaction.delete(lock_path)\n    transaction.delete(self._path)\n    transaction.commit()\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 53.33453200718532}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    header, buffer, offset = None, None, None\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n        xid = header.xid\n\n        if xid == PING_XID:\n            self.logger.debug(\"Received PING\")\n            client._outstanding_ping = False\n        elif xid == AUTH_XID:\n            self.logger.debug(\"Received AUTH response\")\n            client._auth_in_progress = False\n            if header.err:\n                exc = AuthFailedError()\n                client._session_callback.set_exception(exc)\n                raise exc\n            else:\n                client._session_callback.set()\n        elif xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self._read_response(header, buffer, offset)\n    except (ConnectionClosedError, ConnectionDroppedError):\n        client._session_callback.set_exception(ConnectionDroppedError())\n        raise\n    except Exception:\n        client._session_callback.set_exception(ConnectionDroppedError())\n        raise\n\n", "CodeBleu_score": 48.00540354870259}, {"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    header, buffer, offset = await self._read_header(read_timeout)\n    xid = header.xid\n    if xid == PING_XID:\n        self.logger.debug(\"Received PING\")\n        client._outstanding_ping = False\n    elif xid == AUTH_XID:\n        client._session_callback(header, buffer, offset)\n    elif xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n", "CodeBleu_score": 35.84880967764404}, {"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except Exception as exc:\n        self.logger.exception(\"Exception during read header: %r\", exc)\n        return\n    xid = header.xid\n    if xid == PING_XID:\n        self.logger.debug(\"Received PING\")\n        self.client._outstanding_pings = False\n    elif xid == AUTH_XID:\n        if header.err == 0:\n            self.logger.debug(\"Received successful authentication\")\n            self.client._session_callback.set()\n        else:\n            self.logger.debug(\n                \"Received error during authentication: %r\", header.err\n            )\n            self.client._session_callback.set_exception(\n                AuthFailedError(header.err)\n            )\n    elif xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n", "CodeBleu_score": 46.90403803486175}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self.connect)\n        except Exception as e:\n            self.log.warning(\"Unable to connect to Zookeeper: %s\", e)\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED)\n    self.log.info(\"Zookeeper connection loop has stopped\")\n", "CodeBleu_score": 38.25174394322547}, {"code": "def zk_loop(self)\n\t\n    self.log.debug(\"Starting zk_loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self.connect)\n            self.log.debug(\"zk_loop: Connected to Zookeeper\")\n            while not self.stopped.is_set():\n                self.process(self.read_callback)\n                if self.state == KazooState.CONNECTED:\n                    self.process(self.session_callback)\n                if self.state == KazooState.LOST:\n                    self.log.warning(\"zk_loop: KazooState.LOST\")\n                    self.connection_stopped.set()\n                    self.session_callback(KazooState.LOST)\n                    break\n                self.connection_stopped.wait(self.client_timeout / 1000.0)\n        except self.handler.timeout_exception:\n            self.log.warning(\"zk_loop: Timeout exception\")\n        except self.handler.connection_exception:\n            self.log.warning(\"zk_loop: Connection exception\")\n        except Exception:\n            self.log.exception(\"zk_loop: Unhandled exception\")\n    self.log.debug(\"Exiting zk_loop\")\n", "CodeBleu_score": 40.55171376168186}, {"code": "def zk_loop(self)\n\t\n    self.log.info('Starting zk_loop')\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.log.info('Attempting to connect to Zookeeper')\n            self.retry(self.connect)\n            self.log.info('Connected to Zookeeper')\n            self.set(self.session_callback, ZOO_CONNECTED_STATE)\n            self.connection_stopped.wait()\n            self.log.info('Stopping Zookeeper connection')\n            self.close()\n            self.set(self.session_callback, ZOO_EXPIRED_SESSION_STATE)\n        except Exception as e:\n            self.log.warning('Zookeeper connection failed: %s', e)\n            time.sleep(1)\n    self.log.info('zk_loop stopped')\n", "CodeBleu_score": 45.55969840476135}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n", "CodeBleu_score": 33.6805163744097}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions.sort()\n    members.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n", "CodeBleu_score": 33.6805163744097}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n", "CodeBleu_score": 37.493399878959686}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self._best_effort_cleanup()\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self.participating = False\n\n", "CodeBleu_score": 47.04810743589421}, {"code": "def leave(self)\n\t\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self._best_effort_cleanup()\n    self.participating = False\n\n", "CodeBleu_score": 55.60550779640604}, {"code": "def leave(self)\n\t\n    if not self.participating:\n        return\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self.participating = False\n    self._best_effort_cleanup()\n\n", "CodeBleu_score": 47.80465841738501}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\t// Check if the server is running\n\tif (serverStatus() == ServerStatus.RUNNING) {\n\t\treturn new Result(Result.CODE_ERROR, \"The server is already running\");\n\t}\n\n\t// Start the server\n\ttry {\n\t\t// Start the server\n\t\tserver.start();\n\n\t\t// Return a success result\n\t\treturn new Result(Result.CODE_SUCCESS, \"The server was started successfully\");\n\t} catch (Exception e) {\n\t\t// Return an error result\n\t\treturn new Result(Result.CODE_ERROR, \"The server could not be started\", e);\n\t}\n}", "CodeBleu_score": 30.268501904783186}, {"code": "public Result start(){\n\t\t// Check if the server is already running\n\tif (statusServer() == ServerStatus.RUNNING) {\n\t\treturn new Result(Result.CODE_ERROR, \"The HDFS over FTP server is already running\");\n\t}\n\n\ttry {\n\t\t// Start the server\n\t\tserver.start();\n\t} catch (IOException e) {\n\t\treturn new Result(Result.CODE_ERROR, \"An exception occurred while starting the HDFS over FTP server: \" + e.getMessage());\n\t}\n\n\t// Return a success result\n\treturn new Result(Result.CODE_SUCCESS, \"The HDFS over FTP server was successfully started\");\n}", "CodeBleu_score": 29.819150462447563}, {"code": "public Result start(){\n\t\ttry {\n\t\tif (!isRunning()) {\n\t\t\t// Start the server\n\t\t\tif (startServer()) {\n\t\t\t\treturn new Result(Result.SUCCESS, \"HDFS over FTP server started successfully\");\n\t\t\t} else {\n\t\t\t\treturn new Result(Result.ERROR, \"HDFS over FTP server failed to start\");\n\t\t\t}\n\t\t} else {\n\t\t\treturn new Result(Result.SUCCESS, \"HDFS over FTP server is already running\");\n\t\t}\n\t} catch (Exception e) {\n\t\treturn new Result(Result.ERROR, \"HDFS over FTP server failed to start: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 27.781022407639615}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (server != null) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new Result(Result.SUCCESS, \"The FTP server has been stopped.\");\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Could not stop the FTP server.\", e);\n\t\t\treturn new Result(Result.FAILURE, \"Could not stop the FTP server.\");\n\t\t}\n\t} else {\n\t\treturn new Result(Result.FAILURE, \"The FTP server is not running.\");\n\t}\n}", "CodeBleu_score": 27.104959511609312}, {"code": "public Result stop(){\n\t\tif (serverRunning) {\n\t\ttry {\n\t\t\tserver.stopServer();\n\t\t\tserverRunning = false;\n\t\t\treturn new Result(Result.SUCCESS, \"FTP server stopped.\");\n\t\t} catch (Exception e) {\n\t\t\te.printStackTrace();\n\t\t\treturn new Result(Result.FAILURE, \"Error stopping FTP server.\");\n\t\t}\n\t} else {\n\t\treturn new Result(Result.FAILURE, \"FTP server not running.\");\n\t}\n}", "CodeBleu_score": 29.429494557456948}, {"code": "public Result stop(){\n\t\tif (serverRunning) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\tserverRunning = false;\n\t\t\treturn new Result(Result.SUCCESS, \"FTP server stopped successfully.\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error stopping FTP server.\", e);\n\t\t\treturn new Result(Result.FAILURE, \"Error stopping FTP server.\");\n\t\t}\n\t} else {\n\t\treturn new Result(Result.FAILURE, \"FTP server was not running.\");\n\t}\n}", "CodeBleu_score": 28.457297122049013}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.9295216055856}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.9295216055856}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.9295216055856}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(fullPath), conf);\n\t\tfs.mkdirs(new Path(fullPath));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 71.1803445155531}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(hdfsPath), conf);\n\t\treturn fs.mkdirs(new Path(fullPath));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 67.07838029811761}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\treturn fs.mkdirs(new Path(fullPath));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 67.321927308754}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tPath newPath = new Path(ftpFile.getParent(), ftpFile.getName());\n\t\tfs.rename(path, newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.66790899854273}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\treturn fs.rename(ftpFile.getPath(), new Path(ftpFile.getParent(), ftpFile.getName()));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 44.764264107195956}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(path.toString()), conf);\n\t\tPath newPath = new Path(ftpFile.getParent().getPath() + \"/\" + ftpFile.getName());\n\t\tfs.rename(path, newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 60.796969903372954}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\t// get the HDFS file system instance\n\t\tFileSystem fs = getDfs();\n\n\t\t// list the status of files in the directory\n\t\tFileStatus[] fileStatuses = fs.listStatus(path);\n\n\t\t// construct virtual file names based on the base directory's virtual path\n\t\tList<FtpFile> files = new ArrayList<FtpFile>(fileStatuses.length);\n\t\tfor (FileStatus fileStatus : fileStatuses) {\n\t\t\tString fileName = fileStatus.getPath().getName();\n\t\t\tfiles.add(new FtpFile(this, fileName, fileStatus));\n\t\t}\n\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 29.89083726603805}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\tfor (FileStatus file : status) {\n\t\t\tfiles.add(new FtpFile(file));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 18.658950161388947}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(path.toString()), conf);\n\t\tFileStatus[] fileStatuses = fs.listStatus(path);\n\t\tList<FtpFile> fileList = new ArrayList<FtpFile>(fileStatuses.length);\n\t\tfor (FileStatus fileStatus : fileStatuses) {\n\t\t\tFtpFile file = new FtpFile(fileStatus, path.toString());\n\t\t\tfileList.add(file);\n\t\t}\n\t\treturn Collections.unmodifiableList(fileList);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Could not list files in \" + path.toString() + \".\");\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 31.529754993602133}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\t//\n\t// Set the configuration state to true\n\t//\n\tconfigured = true;\n\n\t//\n\t// Check if the user data file exists and load its properties\n\t//\n\tFile userFile = new File(getUserDataFilePath());\n\tif (userFile.exists()) {\n\t\ttry {\n\t\t\tuserDataProp.load(new FileInputStream(userFile));\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to load user data file: \" + userFile.getAbsolutePath(),\n\t\t\t\t\te);\n\t\t}\n\t}\n\n\t//\n\t// Convert any deprecated property names\n\t//\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 41.10526066112578}, {"code": "public void configure(){\n\t\tif (configured) {\n\t\treturn;\n\t}\n\n\tconfigured = true;\n\n\tif (!userDir.exists()) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User home directory does not exist: \" + userDir);\n\t}\n\n\tString userFileName = userDir.getAbsolutePath() + File.separator\n\t\t\t+ USER_DATA_FILE;\n\n\tif (!userFileName.startsWith(userDir.getAbsolutePath())) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User home directory is not a valid path: \" + userDir);\n\t}\n\n\tFile userDataFile = new File(userFileName);\n\n\tif (!userDataFile.exists()) {\n\t\ttry {\n\t\t\tuserDataFile.createNewFile();\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to create user data file: \" + userDataFile, e);\n\t\t}\n\t}\n\n\ttry {\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data file: \" + userDataFile, e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 38.614959180350425}, {"code": "public void configure(){\n\t\tif (configured) {\n\t\treturn;\n\t}\n\n\tconfigured = true;\n\n\tif (!userDir.exists()) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User directory does not exist: \" + userDir.getAbsolutePath());\n\t}\n\n\tif (!userDir.isDirectory()) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User directory is not a directory: \" + userDir.getAbsolutePath());\n\t}\n\n\tif (!userDir.canWrite()) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User directory is not writable: \" + userDir.getAbsolutePath());\n\t}\n\n\tFile userDataFile = new File(userDir, USER_DATA_FILE_NAME);\n\n\tif (!userDataFile.exists()) {\n\t\ttry {\n\t\t\tuserDataFile.createNewFile();\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to create user data file: \" + userDataFile.getAbsolutePath(), e);\n\t\t}\n\t}\n\n\ttry {\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data file: \"\n\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 47.14078116667568}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\ttry {\n\t\tFile parent = getAbsoluteFile().getParentFile();\n\t\tif (!parent.exists()) {\n\t\t\tif (!parent.mkdirs()) {\n\t\t\t\tthrow new FtpException(\"Could not create parent directory for user data file: \" + parent.getAbsolutePath());\n\t\t\t}\n\t\t}\n\t\tFileOutputStream fos = new FileOutputStream(getAbsolutePath());\n\t\tstore(fos, null);\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Could not save user data to file: \" + getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Could not save user data to file: \" + getAbsolutePath(), e);\n\t}\n}", "CodeBleu_score": 36.46245990232522}, {"code": "private void saveUserData() throws FtpException{\n\ttry {\nString userDir = System.getProperty(\"user.home\");\nFile userFile = new File(userDir, \"user.dat\");\nFile parent = userFile.getParentFile();\nif (!parent.exists()) {\nparent.mkdirs();\n}\nFileOutputStream fos = new FileOutputStream(userFile);\nObjectOutputStream oos = new ObjectOutputStream(fos);\noos.writeObject(userData);\noos.close();\nfos.close();\n} catch (IOException e) {\nlogger.log(Level.SEVERE, \"Failed to save user data\", e);\nthrow new FtpException(\"Failed to save user data\");\n}\n}", "CodeBleu_score": 40.94393091375711}, {"code": "private void saveUserData() throws FtpException{\n\t// Check if the parent directory exists and create it if necessary\nif (!userDir.exists()) {\nif (!userDir.mkdirs()) {\nthrow new FtpException(\"Could not create directory for user data file\");\n}\n}\n\n// Attempt to write the user data to the file\ntry (FileOutputStream out = new FileOutputStream(userDataFile)) {\nout.write(userData.getBytes());\n} catch (IOException e) {\nlogger.error(\"Could not save user data to file\", e);\nthrow new FtpException(\"Could not save user data to file\");\n}\n}", "CodeBleu_score": 25.214457095734844}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}\ncatch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.58856692270341}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 79.80052682501866}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"Opening file: \" + path + \" with buffer size: \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tFSDataInputStream stream = fs.open(qualifiedPath, bufferSize);\n\tLOG.info(\"Opened file: \" + path + \" with buffer size: \" + bufferSize);\n\treturn stream;\n}", "CodeBleu_score": 25.46135922358693}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"open(path={}, bufferSize={})\", path, bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tLOG.info(\"open: qualifiedPath={}\", qualifiedPath);\n\tFSDataInputStream fsdis = fileSystem.open(qualifiedPath, bufferSize);\n\tLOG.info(\"open: fsdis={}\", fsdis);\n\treturn fsdis;\n}", "CodeBleu_score": 28.07081618300038}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"open({}, {})\", path, bufferSize);\n\tPath qualified = qualify(path);\n\tFSDataInputStream stream = fileSystem.open(qualified, bufferSize);\n\tLOG.info(\"opened {}\", qualified);\n\treturn stream;\n}", "CodeBleu_score": 25.906188733809554}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 94.24097931912301}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 94.24097931912301}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 94.24097931912301}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.619069546583695}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// Synchronize the operation\n\tsynchronized(this) {\n\t\t// Write metadata to the filer client\n\t\tif (this.metadata != null) {\n\t\t\tthis.metadata.writeMetadata(this.filerClient);\n\t\t}\n\n\t\t// Update the last flush offset\n\t\tthis.lastFlushOffset = offset;\n\n\t\t// Close the file\n\t\tif (this.file != null) {\n\t\t\tthis.file.close();\n\t\t\tthis.file = null;\n\t\t}\n\n\t\t// Reset the written bytes\n\t\tthis.writtenBytes = 0;\n\t}\n}", "CodeBleu_score": 33.18729286707353}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// Synchronize the operation.\n\tsynchronized(this) {\n\t\t// Write metadata to the filer client.\n\t\tif (this.meta != null) {\n\t\t\tthis.meta.flushToFiler();\n\t\t}\n\t\t// Update the last flush offset.\n\t\tthis.lastFlushOffset = offset;\n\t}\n}", "CodeBleu_score": 29.86544723526447}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\t// Check for errors\n\tif (lastError != null) {\n\t\tthrow lastError;\n\t}\n\n\t// Check if the buffer is empty\n\tif (bufferToWrite.remaining() == 0) {\n\t\treturn 0;\n\t}\n\n\t// Check if the queue is full\n\tif (writeOperations.size() >= writeQueueLimit) {\n\t\ttry {\n\t\t\twaitForTaskToComplete();\n\t\t} catch (IOException e) {\n\t\t\tlastError = e;\n\t\t\tthrow e;\n\t\t}\n\t}\n\n\t// Submit the write task to the completion service\n\tfinal Future<Integer> writeTask = completionService.submit(new Callable<Integer>() {\n\t\t@Override\n\t\tpublic Integer call() throws Exception {\n\t\t\treturn channel.write(bufferToWrite, writePosition);\n\t\t}\n\t});\n\n\t// Record the write operation\n\twriteOperations.add(new WriteOperation(writeTask, bufferToWrite.remaining()));\n\n\t// Return the number of bytes written\n\treturn bufferToWrite.remaining();\n}", "CodeBleu_score": 35.69967837498127}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\n// 1. Prepare the buffer for reading.\n        bufferToWrite.flip();\n\n// 2. Calculate the length of the buffer.\n        int length = bufferToWrite.remaining();\n\n// 3. Ensure the task queue is not overloaded.\n        waitForTaskToComplete();\n\n// 4. Submit the write task to the completion service.\n        final Future<Integer> writeTask = completionService.submit(new WriteTask(bufferToWrite, writePosition));\n\n// 5. Record the write operation.\n        writeOperations.add(new WriteOperation(writeTask, length));\n\n// 6. Return the number of bytes written.\n        return length;\n    }", "CodeBleu_score": 26.462829649446174}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t//        if (bufferToWrite.remaining() > maxWriteBufferSize) {\n//            throw new IllegalArgumentException(\"The maximum write buffer size is \" + maxWriteBufferSize);\n//        }\n\n        final int length = bufferToWrite.remaining();\n        final ByteBuffer bufferToWriteFlipped = bufferToWrite.duplicate();\n        bufferToWriteFlipped.flip();\n\n        final Future<Integer> writeTask = completionService.submit(new Callable<Integer>() {\n            @Override\n            public Integer call() throws Exception {\n                return channel.write(bufferToWriteFlipped, writePosition);\n            }\n        });\n\n        writeOperations.add(new WriteOperation(writeTask, length));\n\n        waitForTaskToComplete();\n\n        return length;\n    }", "CodeBleu_score": 39.380748639748596}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tFuture<TaskResult> future = completionService.poll(1, TimeUnit.SECONDS);\n\t\t\tif (future == null) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tTaskResult taskResult = future.get();\n\t\t\tif (taskResult.isSuccess()) {\n\t\t\t\treturn;\n\t\t\t} else {\n\t\t\t\tthrow new IOException(taskResult.getException());\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 28.804596333035658}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\tboolean completed = false;\n\twhile (!completed) {\n\t\ttry {\n\t\t\tcompleted = completionService.take().isDone();\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 30.901796044046627}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\twhile (!completionService.isDone()) {\n\t\t\tFuture<Integer> future = completionService.take();\n\t\t\ttry {\n\t\t\t\tfuture.get();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tthrow new IOException(e);\n\t}\n}", "CodeBleu_score": 27.14570942741187}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\tif (op.isSuccessful()) {\n\t\t\t\ttotalAppendOffset += op.getLength();\n\t\t\t} else {\n\t\t\t\tthrow new IOException(\"Write operation failed: \" + op.getException());\n\t\t\t}\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.68576542733555}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\twhile (!writeOperationQueue.isEmpty()) {\nWriteOperation writeOperation = writeOperationQueue.peek();\nif (writeOperation.isDone()) {\nwriteOperationQueue.remove();\nif (writeOperation.getException() != null) {\nthrow new IOException(\"Write operation failed\", writeOperation.getException());\n}\nappendOffset += writeOperation.getLength();\n} else {\nbreak;\n}\n}\n}", "CodeBleu_score": 29.239968779026672}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation writeOperation = writeOperationQueue.peek();\n\t\tif (writeOperation.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\ttry {\n\t\t\t\ttotalAppendOffset += writeOperation.getLength();\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 29.114820009671206}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"The user argument cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"The user's home directory cannot be null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 67.98325373491122}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User home directory cannot be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 74.98071955745469}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory is null\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 66.90391639499434}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = null;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = new Path(dir);\n\t} else {\n\t\tnewPath = new Path(workingDirectory, dir);\n\t}\n\tif (newPath.isDirectory()) {\n\t\tworkingDirectory = newPath;\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 23.33071210211505}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.charAt(0) == '/') {\n\t\t// absolute path\n\t\tPath newPath = new Path(dir);\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t} else {\n\t\t// relative path\n\t\tPath newPath = currentPath.resolve(dir);\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 16.99984225902259}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.equals(\"..\")) {\n\t\tif (this.currentPath.toString().equals(\"/\")) {\n\t\t\treturn false;\n\t\t}\n\t\tthis.currentPath = this.currentPath.getParent();\n\t\treturn true;\n\t}\n\tif (dir.startsWith(\"/\")) {\n\t\tthis.currentPath = new Path(dir);\n\t\treturn true;\n\t}\n\tthis.currentPath = new Path(this.currentPath.toString() + \"/\" + dir);\n\treturn true;\n}", "CodeBleu_score": 25.76407943144945}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.conf = conf;\n\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(ACCESS_MODE, ACCESS_MODE_DEFAULT);\n\tif (accessMode.equals(ACCESS_MODE_DEFAULT)) {\n\t\tthis.accessMode = ACCESS_MODE_DEFAULT;\n\t} else if (accessMode.equals(ACCESS_MODE_DIRECT)) {\n\t\tthis.accessMode = ACCESS_MODE_DIRECT;\n\t} else if (accessMode.equals(ACCESS_MODE_PUBLIC_URL)) {\n\t\tthis.accessMode = ACCESS_MODE_PUBLIC_URL;\n\t} else if (accessMode.equals(ACCESS_MODE_FILER_PROXY)) {\n\t\tthis.accessMode = ACCESS_MODE_FILER_PROXY;\n\t} else {\n\t\tthrow new IllegalArgumentException(\"Invalid access mode: \" + accessMode);\n\t}\n}", "CodeBleu_score": 36.64578711760462}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\nString accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\nif (accessMode.equals(\"direct\")) {\nsetAccessVolumeServerByDirect();\n} else if (accessMode.equals(\"filerProxy\")) {\nsetAccessVolumeServerByFilerProxy();\n} else {\nsetAccessVolumeServerByPublicUrl();\n}\n}", "CodeBleu_score": 38.43654220967314}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\nString accessMode = conf.get(ACCESS_MODE_KEY, ACCESS_MODE_DEFAULT);\nif (accessMode.equals(ACCESS_MODE_DEFAULT)) {\naccessMode = ACCESS_MODE_DEFAULT;\n} else if (accessMode.equals(ACCESS_MODE_DIRECT)) {\naccessMode = ACCESS_MODE_DIRECT;\n} else if (accessMode.equals(ACCESS_MODE_PUBLIC_URL)) {\naccessMode = ACCESS_MODE_PUBLIC_URL;\n} else if (accessMode.equals(ACCESS_MODE_FILER_PROXY)) {\naccessMode = ACCESS_MODE_FILER_PROXY;\n} else {\nthrow new IllegalArgumentException(\"Invalid access mode: \" + accessMode);\n}\nif (accessMode.equals(ACCESS_MODE_FILER_PROXY)) {\nsetAccessVolumeServerByFilerProxy();\n} else if (accessMode.equals(ACCESS_MODE_PUBLIC_URL)) {\nsetAccessVolumeServerByPublicUrl();\n} else {\nsetAccessVolumeServerByDirect();\n}\n}", "CodeBleu_score": 34.881994498544245}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n//        LOG.debug(\"openFileForRead: \" + path);\n\n        final SeaweedHadoopInputStream inputStream = new SeaweedHadoopInputStream(this, filerClient, statistics, path);\n\n        if (inputStream.getFileEntry() == null) {\n\n            throw new FileNotFoundException(\"File not found: \" + path);\n\n        }\n\n        return inputStream;\n\n    }", "CodeBleu_score": 55.07466190043699}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nlogger.info(\"openFileForRead: \" + path);\n\nFilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, entry, statistics, path);\n\n}", "CodeBleu_score": 71.30926543927063}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nif (statistics != null) {\n\nstatistics.incrementReadOps(1);\n\n}\n\nPath qualifiedPath = toUri(path);\n\nFilerProto.Entry entry = lookupEntry(qualifiedPath);\n\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File does not exist: \" + qualifiedPath);\n\n}\n\nif (entry.isDirectory()) {\n\nthrow new FileNotFoundException(\"Is a directory: \" + qualifiedPath);\n\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, entry, qualifiedPath, statistics);\n\n}", "CodeBleu_score": 56.45114199476422}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\tconf_ = conf;\ntry {\nlocalHostname_ = InetAddress.getLocalHost().getHostName();\n} catch (UnknownHostException e) {\nlocalHostname_ = \"localhost\";\n}\nnumThreads_ = conf.getInt(\"mapred.map.tasks\", 1);\nnumFilesPerThread_ = conf.getInt(\"mapred.map.tasks.files.per.thread\", 1);\nthreadPool_ = Executors.newFixedThreadPool(numThreads_, new ThreadFactory() {\npublic Thread newThread(Runnable r) {\nThread t = new Thread(r);\nt.setDaemon(true);\nreturn t;\n}\n});\n}", "CodeBleu_score": 59.182613472565606}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.localHostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.localHostname = \"localhost\";\n\t}\n\tthis.numThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tthis.numFiles = conf.getInt(\"mapred.map.tasks.files\", 1);\n\tthis.pool = newFixedThreadPool(this.numThreads);\n\tfor (int i = 0; i < this.numThreads; i++) {\n\t\tthis.pool.execute(new WorkerThread());\n\t}\n}", "CodeBleu_score": 34.10761608753243}, {"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\ntry {\nthis.localMachine = InetAddress.getLocalHost().getHostName();\n} catch (UnknownHostException e) {\nthis.localMachine = \"localhost\";\n}\nthis.numThreads = conf.getInt(\"mapred.map.tasks\", 1);\nthis.numFiles = conf.getInt(\"mapred.map.max.split.size\", 1);\nthis.pool = newFixedThreadPool(numThreads);\n}", "CodeBleu_score": 33.54769711962684}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 96.97284868202057}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 96.97284868202057}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 96.97284868202057}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"Context cannot be null\");\n\t}\n\tif (context.length() > 256) {\n\t\tthrow new Exception(\"Context cannot be longer than 256 characters\");\n\t}\n\tString currentContext = getCurrent();\n\tif (currentContext == null) {\n\t\tsetCurrent(context);\n\t\treturn;\n\t}\n\tif (isContextValid(currentContext)) {\n\t\tString[] currentContexts = currentContext.split(\"\\\\|\");\n\t\tfor (String currentContextItem : currentContexts) {\n\t\t\tif (currentContextItem.equals(context)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\tsetCurrent(currentContext + \"|\" + context);\n\t} else {\n\t\tsetCurrent(context);\n\t}\n}", "CodeBleu_score": 30.404673058872312}, {"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getCurrent();\n\tif (currentContext == null || !isContextValid(currentContext)) {\n\t\tsetCurrent(context);\n\t} else if (!currentContext.endsWith(context)) {\n\t\tString newContext = currentContext + \".\" + context;\n\t\tsetCurrent(newContext);\n\t}\n}", "CodeBleu_score": 20.44423538577923}, {"code": "public static void setContext(String context) throws Exception{\n\t\tString current = getCurrent();\n\tif (current == null) {\n\t\tcurrent = context;\n\t} else {\n\t\tif (isContextValid(current)) {\n\t\t\tif (!current.contains(context)) {\n\t\t\t\tcurrent = current + \" \" + context;\n\t\t\t}\n\t\t} else {\n\t\t\tcurrent = context;\n\t\t}\n\t}\n\tsetCurrent(current);\n}", "CodeBleu_score": 21.169487412856355}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t", "CodeBleu_score": 4.052206276703755}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\n}", "CodeBleu_score": 4.1687620148226046}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t", "CodeBleu_score": 4.052206276703755}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nif (libhdfs_->hdfsExists(fs, uri.to_path().c_str())) {\nhdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\nif (file == nullptr) {\nreturn LOG_STATUS(Status_HDFSError(\"Cannot open file '\" + uri.to_string() + \"' in write mode\"));\n}\nint ret = libhdfs_->hdfsFlush(fs, file);\nif (ret != 0) {\nlibhdfs_->hdfsCloseFile(fs, file);\nreturn LOG_STATUS(Status_HDFSError(\"Cannot flush file '\" + uri.to_string() + \"' to HDFS\"));\n}\nret = libhdfs_->hdfsCloseFile(fs, file);\nif (ret != 0) {\nreturn LOG_STATUS(Status_HDFSError(\"Cannot close file '\" + uri.to_string() + \"' after flushing to HDFS\"));\n}\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 50.394090025702745}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nif (!libhdfs_->hdfsExists(fs, uri.to_path().c_str())) {\n  return Status::Ok();\n}\nhdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\nif (file == nullptr) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot open file in HDFS\"));\n}\nint ret = libhdfs_->hdfsFlush(fs, file);\nif (ret != 0) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot flush file to HDFS\"));\n}\nret = libhdfs_->hdfsCloseFile(fs, file);\nif (ret != 0) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot close file in HDFS\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 47.762845141548475}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nif (libhdfs_->hdfsExists(fs, uri.to_path().c_str()) == 0) {\n  hdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot open file: \" + uri.to_string()));\n  }\n  if (libhdfs_->hdfsFlush(fs, file) != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot flush file: \" + uri.to_string()));\n  }\n  if (libhdfs_->hdfsCloseFile(fs, file) != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot close file: \" + uri.to_string()));\n  }\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 47.13762538020874}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFileInfo* info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot get file info from HDFS\"));\n  }\n  if (info->mKind != kObjectKindFile) {\n    libhdfs_->hdfsFreeFileInfo(info, 1);\n    return LOG_STATUS(Status_HDFSError(\"Cannot get file size from HDFS; \" + uri.to_string()));\n  }\n  *nbytes = static_cast<uint64_t>(info->mSize);\n  libhdfs_->hdfsFreeFileInfo(info, 1);\n  return Status::Ok();\n#else\n  return Status_NotImplemented(\"HDFS not supported\");\n#endif\n}", "CodeBleu_score": 61.72499462281272}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t", "CodeBleu_score": 3.187356454526044}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifndef NDEBUG\n  LOG_DEBUG(\"Getting file size for URI: \" + uri.to_string());\n#endif\n  hdfsFileInfo* info = nullptr;\n  RETURN_NOT_OK(libhdfs_->hdfsGetPathInfo(hdfs_, uri.to_path().c_str(), &info));\n  if (info->mKind != kObjectKindFile) {\n    LOG_ERROR(\"URI \" + uri.to_string() + \" is not a file\");\n    libhdfs_->hdfsFreeFileInfo(info, 1);\n    return LOG_STATUS(Status_HDFSError(\"URI \" + uri.to_string() + \" is not a file\"));\n  }\n  *nbytes = info->mSize;\n  libhdfs_->hdfsFreeFileInfo(info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 42.09420182416936}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfg = hbaseCfgString.split(\";\");\n\tString quorum = null;\n\tString znode = null;\n\tfor (String cfg : hbaseCfg) {\n\t\tif (cfg.startsWith(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = cfg.split(\"=\")[1];\n\t\t} else if (cfg.startsWith(\"zookeeper.znode.parent\")) {\n\t\t\tznode = cfg.split(\"=\")[1];\n\t\t}\n\t}\n\tif (quorum == null) {\n\t\tthrow new IllegalArgumentException(\"hbase.zookeeper.quorum not found in configuration string\");\n\t}\n\tif (!quorum.contains(\":\")) {\n\t\tquorum += \":2181\";\n\t}\n\tif (znode == null) {\n\t\tznode = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znode);\n}", "CodeBleu_score": 26.665210303623365}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tString zkQuorum = hbaseCfg[0].split(\":\")[0];\n\tString zkPort = hbaseCfg[0].split(\":\")[1];\n\tString zkZnodeParent = hbaseCfg[1];\n\tif (zkPort == null || zkPort.isEmpty()) {\n\t\tzkPort = \"2181\";\n\t}\n\tif (zkZnodeParent == null || zkZnodeParent.isEmpty()) {\n\t\tzkZnodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(zkQuorum + \":\" + zkPort, zkZnodeParent);\n}", "CodeBleu_score": 30.62160692270528}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (hbaseCfgString == null) {\n\t\treturn null;\n\t}\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tString hbaseQuorum = hbaseCfg[0].trim();\n\tString hbaseZnodeParent = null;\n\tif (hbaseCfg.length > 1) {\n\t\thbaseZnodeParent = hbaseCfg[1].trim();\n\t}\n\tif (hbaseQuorum.isEmpty()) {\n\t\treturn null;\n\t}\n\tif (hbaseZnodeParent == null || hbaseZnodeParent.isEmpty()) {\n\t\thbaseZnodeParent = \"/hbase\";\n\t}\n\t// ensure quorum includes port number\n\tif (!hbaseQuorum.contains(\":\")) {\n\t\thbaseQuorum += \":2181\";\n\t}\n\treturn new Pair<String, String>(hbaseQuorum, hbaseZnodeParent);\n}", "CodeBleu_score": 32.11679955513935}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tLOG.debug(\"validate hbase writer config\");\n\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\tcheckTable(conn, cfg.getNamespace(), cfg.getTableName(), cfg.isThinClient());\n\t\tPTable tableSchema = getTableSchema(conn, cfg.getNamespace() + \".\" + cfg.getTableName());\n\t\tList<String> columns = cfg.getColumns();\n\t\tfor (String column : columns) {\n\t\t\tgetColumnForColumnName(tableSchema, column);\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.CONFIG_INVALID_EXCEPTION, e);\n\t} finally {\n\t\tif (conn != null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t} catch (SQLException e) {\n\t\t\t\tLOG.warn(\"close hbase connection error\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 34.367118762728005}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tLOG.debug(\"validateConfig() begin\");\n\tConnection conn = getJdbcConnection(cfg);\n\tString namespace = cfg.getNamespace();\n\tString tableName = cfg.getTableName();\n\tboolean isThinClient = cfg.isThinClient();\n\tcheckTable(conn, namespace, tableName, isThinClient);\n\tgetTableSchema(conn, tableName);\n\tList<String> columnNames = cfg.getColumnNames();\n\tList<String> columnTypes = cfg.getColumnTypes();\n\tif (columnNames.size() != columnTypes.size()) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n\t\t\t\tString.format(\"column name and column type size not match. column name size is [%d], column type size is [%d]\",\n\t\t\t\t\t\tcolumnNames.size(), columnTypes.size()));\n\t}\n\tfor (int i = 0; i < columnNames.size(); i++) {\n\t\tString columnName = columnNames.get(i);\n\t\tString columnType = columnTypes.get(i);\n\t\tgetColumnForColumnName(conn, tableName, columnName, columnType);\n\t}\n\tLOG.debug(\"validateConfig() end\");\n}", "CodeBleu_score": 30.994140255573978}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tConnection conn = getJdbcConnection(cfg);\n\tString tableName = cfg.getTableName();\n\tString namespace = cfg.getNamespace();\n\tboolean isThinClient = cfg.isThinClient();\n\tcheckTable(conn, namespace, tableName, isThinClient);\n\tPTable table = getTableSchema(conn, tableName);\n\tList<String> columnNames = cfg.getColumn();\n\tfor (String columnName : columnNames) {\n\t\tgetColumnForColumnName(table, columnName);\n\t}\n}", "CodeBleu_score": 21.00022666949774}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\tConfiguration conf = HdfsUtil.getFileSystem().getConf();\n\t\tconf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\tUserGroupInformation.setConfiguration(conf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tLOGGER.error(\"Kerberos login failed using principal [{}] and keytab file [{}].\", kerberosPrincipal, kerberosKeytabFilePath);\n\t\t\tthrow new AsAddaxException(\"Kerberos login failed using principal [{}] and keytab file [{}].\", kerberosPrincipal, kerberosKeytabFilePath);\n\t\t}\n\t}\n}", "CodeBleu_score": 50.11220016136409}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\tlogger.info(\"Kerberos authentication is enabled. Attempting to login using principal: \" + kerberosPrincipal + \" and keytab file: \" + kerberosKeytabFilePath);\n\t\tConfiguration hadoopConfiguration = new Configuration();\n\t\thadoopConfiguration.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\thadoopConfiguration.set(\"java.security.krb5.conf\", System.getProperty(\"java.security.krb5.conf\"));\n\t\thadoopConfiguration.set(\"kerberos.keytab.file\", kerberosKeytabFilePath);\n\t\thadoopConfiguration.set(\"kerberos.principal\", kerberosPrincipal);\n\t\tUserGroupInformation.setConfiguration(hadoopConfiguration);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Kerberos login failed using principal: \" + kerberosPrincipal + \" and keytab file: \" + kerberosKeytabFilePath, e);\n\t\t\tthrow new AsAddaxException(\"Kerberos login failed using principal: \" + kerberosPrincipal + \" and keytab file: \" + kerberosKeytabFilePath, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.136137793927894}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n\t\tLOGGER.info(\"Kerberos authentication is enabled with principal: \" + kerberosPrincipal + \" and keytab: \" + kerberosKeytabFilePath);\n\t\tConfiguration hadoopConf = getConfiguration();\n\t\thadoopConf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\thadoopConf.set(\"kerberos.principal\", kerberosPrincipal);\n\t\thadoopConf.set(\"kerberos.keytab\", kerberosKeytabFilePath);\n\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tLOGGER.error(\"Kerberos login failed with principal: \" + kerberosPrincipal + \" and keytab: \" + kerberosKeytabFilePath);\n\t\t\tthrow new asAddaxException(\"Kerberos login failed with principal: \" + kerberosPrincipal + \" and keytab: \" + kerberosKeytabFilePath, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 49.94388078095646}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint numCols = rsmd.getColumnCount();\nfor (int i = 1; i <= numCols; i++) {\nString colName = rsmd.getColumnLabel(i);\nif (colName == null) {\nthrow new SQLException(\"Column name cannot be null\");\n}\nint colType = rsmd.getColumnType(i);\nif (colType == Types.NULL) {\nthrow new SQLException(\"Column type cannot be null\");\n}\nThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(colName,\nType.fromSqlTypeName(rsmd.getColumnTypeName(i)),\nrsmd.getColumnDisplaySize(i),\nrsmd.getPrecision(i),\nrsmd.getScale(i),\nrsmd.isNullable(i) == ResultSetMetaData.columnNullable);\ncolMap.put(colName, col);\n}\nreturn colMap;\n}", "CodeBleu_score": 42.85419263369124}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t", "CodeBleu_score": 3.6144534202708902}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnLabel(i);\nif (colName == null) {\nthrow new SQLException(\"Column \" + i + \" has no name\");\n}\nint colType = rsmd.getColumnType(i);\nif (colType == Types.NULL) {\nthrow new SQLException(\"Column \" + i + \" has no type\");\n}\nString colTypeName = rsmd.getColumnTypeName(i);\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName,\nType.fromSqlTypeName(colTypeName), colType));\n}\nreturn colMap;\n}", "CodeBleu_score": 41.5796076192113}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// Ensure table exists and is enabled\n\t\tcheckTable(admin, hTableName);\n\t\t// Truncate table\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t}\n\tcatch (Throwable t) {\n\t\t// Truncate table failed\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t}\n\tfinally {\n\t\tif (admin != null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.67283253369143}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t}\n\tcatch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t}\n\tfinally {\n\t\tif (admin != null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 92.72131069623914}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// ensure table exists and is enabled\n\t\tcheckTable(admin, hTableName);\n\t\t// truncate table\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t}\n\tcatch (Throwable t) {\n\t\t// truncate table failed\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t}\n\tfinally {\n\t\tif (admin != null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.67283253369143}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\n}", "CodeBleu_score": 2.1812566724741114}, {"code": "private void addSourceFileByType(String filePath){\n\t\nString specifiedFileType = this.config.getNecessaryValue(Key.FILE_TYPE, HdfsReaderErrorCode.REQUIRED_VALUE);\n\nif (checkHdfsFileType(filePath, specifiedFileType)) {\n    this.sourceFiles.add(filePath);\n}\nelse {\n    String message = String.format(\"The file type of [%s] is not configured as [%s] in the configuration file.\", filePath, specifiedFileType);\n    LOG.error(message);\n    throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT_ERROR, message);\n}\n}", "CodeBleu_score": 42.77703858442093}, {"code": "private void addSourceFileByType(String filePath){\n\t\tboolean isFileAdded = false;\n\tString specifiedFileType = this.config.getString(Key.FILE_TYPE);\n\tif (StringUtils.isEmpty(specifiedFileType)) {\n\t\tLOG.info(\"The file type is not configured, the default file type [{}] is used.\", HdfsConstant.TEXT);\n\t\tspecifiedFileType = HdfsConstant.TEXT;\n\t}\n\tif (checkHdfsFileType(filePath, specifiedFileType)) {\n\t\tLOG.info(\"Add file [{}] to the source files list.\", filePath);\n\t\tsourceFiles.add(filePath);\n\t\tisFileAdded = true;\n\t}\n\telse {\n\t\tString message = String.format(\"The file type [%s] of the file [%s] is not supported.\", specifiedFileType, filePath);\n\t\tLOG.error(message);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n\t}\n}", "CodeBleu_score": 46.07957402867828}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ntry {\n\nlogger.info(\"The sequence file reading starts, please wait a moment.\");\n\nFileSystem fileSystem = FileSystem.get(new Configuration());\n\nPath path = new Path(sourceSequenceFilePath);\n\nif (!fileSystem.exists(path)) {\n\nthrow AddaxException.asAddaxException(\n\nFrameworkErrorCode.CONFIG_ERROR,\n\nString.format(\"The path:[%s] is not exist.\", sourceSequenceFilePath));\n\n}\n\nif (!fileSystem.isFile(path)) {\n\nthrow AddaxException.asAddaxException(\n\nFrameworkErrorCode.CONFIG_ERROR,\n\nString.format(\"The path:[%s] is not a file.\", sourceSequenceFilePath));\n\n}\n\nFSDataInputStream inputStream = fileSystem.open(path);\n\nSequenceFile.Reader reader = new SequenceFile.Reader(fileSystem, path, readerSliceConfig);\n\nClass<? extends Writable> keyClass = reader.getKeyClass();\n\nClass<? extends Writable> valueClass = reader.getValueClass();\n\nlogger.info(String.format(\"The key type is:[%s], the value type is:[%s].\", keyClass.toString(), valueClass.toString()));\n\nWritable key = ReflectionUtils.newInstance(keyClass, null);\n\nWritable value = ReflectionUtils.newInstance(valueClass, null);\n\nwhile (reader.next(key, value)) {\n\nif (null != key && null != value) {\n\ntransportOneRecord(recordSender, key, value, readerSliceConfig, taskPluginCollector);\n\n} else {\n\nlogger.error(\"The record key or record value is null, please check the data source configuration.\");\n\n}\n\n}\n\nreader.close();\n\ninputStream.close();\n\nlogger.info(\"All the records have been read from the sequence file.\");\n\n} catch (Exception e) {\n\nlogger.error(\"Failed to read the sequence file, please check the data source configuration.\");\n\nthrow AddaxException.asAddaxException(FrameworkErrorCode.READ_RECORD_FAILED, e);\n\n}\n\n}", "CodeBleu_score": 43.37131063808062}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t", "CodeBleu_score": 2.382402701443833}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tPath path = new Path(filepath);\n\t\tFileSystem fs = FileSystem.get(hadoopConf);\n\t\tFSDataInputStream in = fs.open(path);\n\t\tboolean isFileType = false;\n\t\tif (specifiedFileType.equals(\"orc\")) {\n\t\t\tisFileType = isORCFile(path, fs, in);\n\t\t} else if (specifiedFileType.equals(\"rc\")) {\n\t\t\tisFileType = isRCFile(filepath, in);\n\t\t} else if (specifiedFileType.equals(\"sequence\")) {\n\t\t\tisFileType = isSequenceFile(path, in);\n\t\t} else if (specifiedFileType.equals(\"parquet\")) {\n\t\t\tisFileType = isParquetFile(path);\n\t\t} else if (specifiedFileType.equals(\"csv\")) {\n\t\t\tisFileType = isCsvFile(path, fs);\n\t\t} else if (specifiedFileType.equals(\"text\")) {\n\t\t\tisFileType = isTextFile(path, fs);\n\t\t} else {\n\t\t\tLOG.info(\"The specified file type [{}] is not supported.\", specifiedFileType);\n\t\t}\n\t\treturn isFileType;\n\t} catch (IOException e) {\n\t\tLOG.error(\"Error occurred when checking file type: [{}]\", e.getMessage());\n\t\tthrow DataXException.asDataXException(HdfsReaderErrorCode.ILLEGAL_VALUE, e.getMessage());\n\t}\n}", "CodeBleu_score": 40.5263758884502}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tPath path = new Path(filepath);\n\t\tFileSystem fs = FileSystem.get(hadoopConf);\n\t\tFSDataInputStream in = fs.open(path);\n\t\tboolean isFile = fs.isFile(path);\n\t\tif (!isFile) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"The path [%s] is not a file\", filepath));\n\t\t}\n\t\tString fileType = null;\n\t\tif (specifiedFileType.equals(\"orc\")) {\n\t\t\tif (isORCFile(path, fs, in)) {\n\t\t\t\tfileType = \"orc\";\n\t\t\t}\n\t\t}\n\t\telse if (specifiedFileType.equals(\"rc\")) {\n\t\t\tif (isRCFile(filepath, in)) {\n\t\t\t\tfileType = \"rc\";\n\t\t\t}\n\t\t}\n\t\telse if (specifiedFileType.equals(\"seq\")) {\n\t\t\tif (isSequenceFile(path, in)) {\n\t\t\t\tfileType = \"seq\";\n\t\t\t}\n\t\t}\n\t\telse if (specifiedFileType.equals(\"parquet\")) {\n\t\t\tif (isParquetFile(path)) {\n\t\t\t\tfileType = \"parquet\";\n\t\t\t}\n\t\t}\n\t\telse if (specifiedFileType.equals(\"text\")) {\n\t\t\tfileType = \"text\";\n\t\t}\n\t\telse if (specifiedFileType.equals(\"csv\")) {\n\t\t\tfileType = \"csv\";\n\t\t}\n\t\tif (fileType == null) {\n\t\t\tthrow AddaxException.asAddaxException(\n\t\t\t\t\tFrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\t\tString.format(\"The file type [%s] is not supported\", specifiedFileType));\n\t\t}\n\t\tLOG.info(\"The file [{}] is a {} file.\", filepath, fileType);\n\t\treturn true;\n\t}\n\tcatch (IOException e) {\n\t\tLOG.error(\"Failed to check the file type of the file [{}].\", filepath, e);\n\t\tthrow AddaxException.asAddaxException(FrameworkErrorCode.CONFIG_ERROR,\n\t\t\t\tString.format(\"Failed to check the file type of the file [%s]\", filepath));\n\t}\n}", "CodeBleu_score": 39.91147551287123}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection != null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(\n\t\t\t\t\t\"HBaseUtil:closeConnection():\" + e.getMessage(),\n\t\t\t\t\t\"10000000002\",\n\t\t\t\t\te);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.47241378821233}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new AddaxException(\n\t\t\t\tHBase20xSQLReaderErrorCode.CLOSE_HBASE_CONNECTION_ERROR,\n\t\t\t\tString.format(\"Failed to close hbase connection, please check if the connection is closed or invalid. Exception message: %s\", e.getMessage()), e);\n\t}\n}", "CodeBleu_score": 48.16389555896939}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection != null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(ErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 47.47810006915255}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\ttry {\n\t\tif (admin != null) {\n\t\t\tadmin.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new AddaxException(HBASE_IO_ERROR, e);\n\t}\n}", "CodeBleu_score": 45.21178069583726}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tHBase20xSQLReaderErrorCode.CLOSE_ADMIN_ERROR,\n\t\t\t\t\tString.format(\"Failed to close the HBase admin instance. message:%s\", e.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.10111448310727}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(\n\t\t\t\t\tHBase20xSQLReaderErrorCode.CLOSE_ADMIN_ERROR,\n\t\t\t\t\tString.format(\"Failed to close the HBase Admin instance. Please check if the connection to HBase is normal. Error message: %s\",\n\t\t\t\t\t\t\te.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.168244531672485}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key from the cell.\nbyte[] rowKey = CellUtil.cloneRow(cell);\n\n// Get the timestamp from the cell.\nlong timestamp = cell.getTimestamp();\n\n// Get the column family from the cell.\nbyte[] columnFamily = CellUtil.cloneFamily(cell);\n\n// Get the column qualifier from the cell.\nbyte[] columnQualifier = CellUtil.cloneQualifier(cell);\n\n// Get the column value from the cell.\nbyte[] columnValue = CellUtil.cloneValue(cell);\n\n// Get the column type from the mappings.\nString columnType = getTypeName(columnFamily, columnQualifier);\n\n// Get the column format from the mappings.\nString columnFormat = getFormat(columnFamily, columnQualifier);\n\n// Convert the row key to a string.\nString rowKeyString = convertBytesToString(rowKey);\n\n// Convert the column value to the appropriate type and format.\nObject columnValueConverted = convertBytesToAssignType(columnValue, columnType, columnFormat);\n\n// Add the row key, family, qualifier, timestamp, and column value to the record.\nrecord.addColumn(COLUMN_FAMILY_NAME, COLUMN_QUALIFIER_NAME, rowKeyString, timestamp, columnValueConverted);\n}", "CodeBleu_score": 32.0436839321012}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key from the cell.\nbyte[] rowKey = cell.getRowArray();\nrowKey = Arrays.copyOfRange(rowKey, cell.getRowOffset(), cell.getRowOffset() + cell.getRowLength());\n\n// Get the timestamp from the cell.\nlong timestamp = cell.getTimestamp();\n\n// Get the column family from the cell.\nbyte[] family = cell.getFamilyArray();\nfamily = Arrays.copyOfRange(family, cell.getFamilyOffset(), cell.getFamilyOffset() + cell.getFamilyLength());\n\n// Get the column qualifier from the cell.\nbyte[] qualifier = cell.getQualifierArray();\nqualifier = Arrays.copyOfRange(qualifier, cell.getQualifierOffset(), cell.getQualifierOffset() + cell.getQualifierLength());\n\n// Get the column value from the cell.\nbyte[] value = cell.getValueArray();\nvalue = Arrays.copyOfRange(value, cell.getValueOffset(), cell.getValueOffset() + cell.getValueLength());\n\n// Get the type and format for the row key.\nString rowKeyType = rowKeyMappings.get(family);\nString rowKeyFormat = rowKeyFormats.get(family);\n\n// Get the type and format for the column value.\nString valueType = valueMappings.get(family + \":\" + qualifier);\nString valueFormat = valueFormats.get(family + \":\" + qualifier);\n\n// Convert the row key to the appropriate type and add it as a column to the record.\nrecord.addColumn(rowKeyType, rowKeyFormat, rowKey);\n\n// Convert the column value to the appropriate type and add it as a column to the record.\nrecord.addColumn(valueType, valueFormat, value);\n\n// Add the timestamp as a column to the record.\nrecord.addColumn(\"timestamp\", \"yyyy-MM-dd HH:mm:ss\", timestamp);\n}", "CodeBleu_score": 35.85781722435482}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Extract the row key from the cell.\nbyte[] rowKey = CellUtil.cloneRow(cell);\n// Extract the timestamp from the cell.\nlong timestamp = cell.getTimestamp();\n// Extract the column family from the cell.\nbyte[] family = CellUtil.cloneFamily(cell);\n// Extract the column qualifier from the cell.\nbyte[] qualifier = CellUtil.cloneQualifier(cell);\n// Extract the column value from the cell.\nbyte[] value = CellUtil.cloneValue(cell);\n// Convert the row key to a string.\nString rowKeyString = convertBytesToAssignType(rowKey);\n// Convert the column value to a string.\nString valueString = convertBytesToAssignType(value);\n// Add the row key, family, qualifier, timestamp, and column value as columns to the record.\nrecord.addColumn(rowKeyString, family, qualifier, timestamp, valueString);\n}", "CodeBleu_score": 23.069596714748}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(Constants.START_ROWKEY);\n\tif (isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\telse {\n\t\tboolean isBinaryRowkey = getBool(configuration, Constants.IS_BINARY_ROWKEY);\n\t\treturn stringToBytes(userStartRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 55.53661584743929}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(HConstants.START_ROW);\n\tif (isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tboolean isBinaryRowkey = configuration.getBoolean(HConstants.IS_BINARY_ROWKEY, false);\n\treturn stringToBytes(userStartRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 48.55447308499324}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString rowkey = configuration.get(HConstants.START_ROW);\n\tboolean isBinaryRowkey = configuration.getBoolean(HConstants.IS_BINARY_ROWKEY, false);\n\treturn stringToBytes(rowkey, isBinaryRowkey);\n}", "CodeBleu_score": 42.73013648154634}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 49.90027917725271}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(HBaseConstants.HBASE_START_ROWKEY);\n\tbyte[] startRowkeyBytes = null;\n\tif (StringUtils.isBlank(startRowKey)) {\n\t\tstartRowkeyBytes = new byte[0];\n\t} else {\n\t\tstartRowkeyBytes = Bytes.toBytesBinary(startRowKey);\n\t}\n\treturn startRowkeyBytes;\n}", "CodeBleu_score": 47.57257124511708}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(Constants.START_ROWKEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t} else {\n\t\treturn Bytes.toBytesBinary(startRowkey);\n\t}\n}", "CodeBleu_score": 62.33083462719091}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(header -> headers.put(header.key(), new String(header.value())));\n\tthis.data = record.value();\n}", "CodeBleu_score": 51.68951253582651}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new TbQueueMsgHeaders();\nrecord.headers().forEach(header -> headers.put(header.key(), new String(header.value())));\nthis.data = record.value();\n}", "CodeBleu_score": 51.59172557367808}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new TbQueueMsgHeaders();\nfor (Header header : record.headers()) {\nthis.headers.put(header.key(), new String(header.value()));\n}\nthis.data = record.value();\n}", "CodeBleu_score": 49.78028999529353}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaSettings kafkaSettings = getKafkaSettings();\nString clientId = getServiceId() + \"-\" + TRANSPORT_NOTIFICATIONS_TOPIC;\nString topicName = getNotificationsTopic();\nlog.info(\"Create Kafka producer for transport notifications [{}] with client ID [{}].\", topicName, clientId);\nTbKafkaAdmin admin = new TbKafkaAdmin(kafkaSettings);\nTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>();\nproducer.init(kafkaSettings, clientId, admin, topicName);\nreturn producer;\n}", "CodeBleu_score": 31.10709790821895}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaSettings kafkaSettings = getKafkaSettings();\nString clientId = getServiceId() + \"-transport-notifications\";\nString defaultTopic = getNotificationsTopic();\nreturn new TbKafkaProducer<>(kafkaSettings, clientId, defaultTopic, ToTransportMsg.class);\n}", "CodeBleu_score": 24.830098134964604}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\n}", "CodeBleu_score": 5.886600204806592}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>();\nconsumerTemplate.setTopic(getNotificationsTopic());\nconsumerTemplate.setClientId(getClientId());\nconsumerTemplate.setGroupId(getGroupId());\nconsumerTemplate.setMessageDecoder(new TbProtoQueueMsgJsonDecoder<>(ToCoreNotificationMsg.class));\nconsumerTemplate.setAdmin(getAdmin());\nconsumerTemplate.setStats(getStatsService());\nreturn consumerTemplate.build();\n}", "CodeBleu_score": 24.694182366888736}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<ToCoreNotificationMsg> consumerTemplate = new TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(getNotificationsTopic());\n\tconsumerTemplate.setClientId(getClientId());\n\tconsumerTemplate.setGroupId(getGroupId());\n\tconsumerTemplate.setDecoder(new TbProtoQueueMsgJsonDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(admin);\n\tconsumerTemplate.setStats(statsService);\n\treturn consumerTemplate.create(ToCoreNotificationMsg.class);\n}", "CodeBleu_score": 24.441571950339515}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tString topic = getNotificationsTopic();\n\tString clientId = getClientId();\n\tString groupId = getGroupId();\n\tTbKafkaConsumerTemplate<ToCoreNotificationMsg> consumerTemplate = new TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(topic);\n\tconsumerTemplate.setClientId(clientId);\n\tconsumerTemplate.setGroupId(groupId);\n\tconsumerTemplate.setMessageDecoder(new TbProtoBufJsonDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(getAdmin());\n\tconsumerTemplate.setStats(getStatsService());\n\treturn consumerTemplate.create(ToCoreNotificationMsg.class);\n}", "CodeBleu_score": 26.76255190454449}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames == null || topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tunsubscribe();\n\t} else {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!topicExists(topicName)) {\n\t\t\t\tcreateTopic(topicName);\n\t\t\t}\n\t\t}\n\t\tsubscribe(topicNames);\n\t}\n}", "CodeBleu_score": 51.780692715312306}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlog.info(\"Unsubscribing consumer from all topics\");\nunsubscribe();\n} else {\n// Ensure that the topics exist before subscribing\nfor (String topicName : topicNames) {\ntry {\ncreateTopicIfNecessary(topicName);\n} catch (Exception e) {\nthrow new RuntimeException(\"Failed to create topic \" + topicName, e);\n}\n}\n// Subscribe to the topics\nlog.info(\"Subscribing consumer to topics {}\", topicNames);\nsubscribe(topicNames);\n}\n}", "CodeBleu_score": 49.47422863895577}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlogger.info(\"Unsubscribing from all topics.\");\n\t\tconsumer.unsubscribe();\n\t} else {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!topicExists(topicName)) {\n\t\t\t\tcreateTopic(topicName);\n\t\t\t}\n\t\t}\n\t\tconsumer.subscribe(topicNames);\n\t}\n}", "CodeBleu_score": 56.816998005922024}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlogger.info(\"Polling for {} ms on topic {}\", durationInMillis, topic);\n\trecords = consumer.poll(durationInMillis).records(topic);\n\tstopwatch.stop();\n\tlogger.info(\"Polled {} records in {} ms on topic {}\", records.size(), stopwatch.elapsed(TimeUnit.MILLISECONDS), topic);\n\treturn records;\n}", "CodeBleu_score": 41.802063222096265}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\t// Start the stopwatch\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\n\t// Log the topic and duration\n\tlogger.info(\"Polling Kafka topic {} for {} milliseconds\", topic, durationInMillis);\n\n\t// Poll the consumer for records\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis).records(topic);\n\n\t// Stop the stopwatch\n\tstopwatch.stop();\n\n\t// Log the total time taken\n\tlogger.info(\"Polled Kafka topic {} for {} milliseconds\", topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\n\t// If no records were found, return an empty list\n\tif (records.isEmpty()) {\n\t\tlogger.info(\"No records found in Kafka topic {}\", topic);\n\t\treturn Collections.emptyList();\n\t}\n\n\t// Otherwise, collect the records into a list and return them\n\telse {\n\t\tlogger.info(\"Found {} records in Kafka topic {}\", records.size(), topic);\n\t\treturn records;\n\t}\n}", "CodeBleu_score": 49.29440265513679}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tlong startTime = System.currentTimeMillis();\nlong endTime = startTime + durationInMillis;\nStopwatch stopwatch = Stopwatch.createStarted();\nList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\nwhile (System.currentTimeMillis() < endTime) {\nrecords.addAll(consumer.poll(Duration.ofMillis(durationInMillis)).records(topic));\n}\nstopwatch.stop();\nLOGGER.info(\"Polled {} records from topic {} in {} ms\", records.size(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\nreturn records;\n}", "CodeBleu_score": 38.65356041436846}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (initResult != null) {\n\t\tif (initResult.isSuccess()) {\n\t\t\tString topic = getTopicPattern(ctx, msg);\n\t\t\tString key = getKeyPattern(ctx, msg);\n\t\t\tif (StringUtils.isEmpty(topic)) {\n\t\t\t\tctx.tellFailure(msg, new IllegalArgumentException(\"Topic pattern is not defined!\"));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (StringUtils.isEmpty(key)) {\n\t\t\t\tctx.tellFailure(msg, new IllegalArgumentException(\"Key pattern is not defined!\"));\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tctx.getExternalCallExecutor().submit(() -> publish(ctx, msg, topic, key));\n\t\t} else {\n\t\t\tctx.tellFailure(msg, initResult.getError());\n\t\t}\n\t} else {\n\t\tctx.tellFailure(msg, new RuntimeException(\"Failed to initialize Kafka producer!\"));\n\t}\n}", "CodeBleu_score": 33.38331413512907}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (initResult.isFailure()) {\n\t\tlog.warn(\"[{}] Initialization failed! Can't process message: {}\", ctx.getSelfId(), msg);\n\t\tctx.tellFailure(msg, initResult);\n\t\treturn;\n\t}\n\tString topic = getTopicPattern();\n\tString key = getKeyPattern();\n\tif (StringUtils.isEmpty(topic) || StringUtils.isEmpty(key)) {\n\t\tlog.warn(\"[{}] Failed to process message: {}. Topic or key pattern is empty!\", ctx.getSelfId(), msg);\n\t\tctx.tellFailure(msg, new RuntimeException(\"Topic or key pattern is empty!\"));\n\t\treturn;\n\t}\n\tctx.getExternalCallExecutor().submit(() -> publish(ctx, msg, topic, key));\n}", "CodeBleu_score": 26.61106399430101}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (init) {\n\t\t\tif (ctx.isLocalMsg()) {\n\t\t\t\tlog.debug(\"[{}] Local message consumed by Kafka rule node: {}\", ctx.getSelfId(), msg.toString());\n\t\t\t}\n\t\t\tprocessPattern(ctx, msg);\n\t\t} else {\n\t\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n\t\t\tctx.tellFailure(msg, new RuntimeException(\"Failed to process message: \" + msg));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.tellFailure(msg, e);\n\t}\n}", "CodeBleu_score": 26.903710554550003}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tbyte[] keyBytes = null;\n\tbyte[] valueBytes = null;\n\tif (key != null) {\n\t\tkeyBytes = key.getBytes();\n\t}\n\tif (msg != null) {\n\t\tvalueBytes = msg.getData();\n\t}\n\tif (metadataEnabled) {\n\t\tMap<String, String> headers = getHeaders(msg);\n\t\tif (headers != null) {\n\t\t\tctx.debug(\"Adding metadata to Kafka headers\");\n\t\t\tFuture<RecordMetadata> future = producer.send(new ProducerRecord(topic, keyBytes, valueBytes, headers));\n\t\t\tfuture.addCallback(new KafkaCallback(ctx, msg, metadataEnabled));\n\t\t} else {\n\t\t\tctx.debug(\"No metadata to add to Kafka headers\");\n\t\t\tFuture<RecordMetadata> future = producer.send(new ProducerRecord(topic, keyBytes, valueBytes));\n\t\t\tfuture.addCallback(new KafkaCallback(ctx, msg, metadataEnabled));\n\t\t}\n\t} else {\n\t\tctx.debug(\"No metadata enabled, sending message directly to topic\");\n\t\tFuture<RecordMetadata> future = producer.send(new ProducerRecord(topic, keyBytes, valueBytes));\n\t\tfuture.addCallback(new KafkaCallback(ctx, msg, metadataEnabled));\n\t}\n}", "CodeBleu_score": 30.35103664193623}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t", "CodeBleu_score": 5.441118430176013}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\tif (getSelfId().equals(ctx.getOriginatorId())) {\n\t\t\tlog.warn(\"Failed to publish message from self: {}\", ctx.getSelfId());\n\t\t\treturn;\n\t\t}\n\t\tbyte[] bytes = getBytes(msg);\n\t\tif (bytes == null || bytes.length == 0) {\n\t\t\tlog.warn(\"Failed to publish empty message: {}\", ctx.getSelfId());\n\t\t\treturn;\n\t\t}\n\t\tMap<String, String> headers = getMetaData(msg);\n\t\tif (headers == null || headers.isEmpty()) {\n\t\t\tlog.debug(\"No metadata found, publishing message without headers: {}\", ctx.getSelfId());\n\t\t\tprocessRecord(ctx, msg, kafkaTemplate.send(topic, key, bytes), null);\n\t\t} else {\n\t\t\tlog.debug(\"Metadata found, publishing message with headers: {}\", ctx.getSelfId());\n\t\t\tprocessRecord(ctx, msg, kafkaTemplate.send(topic, key, headers, bytes), null);\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.debug(\"Failed to publish message: {}\", ctx.getSelfId(), e);\n\t}\n}", "CodeBleu_score": 39.97959331395406}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\tif (producer != null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nLOG.error(\"Failed to close Kafka producer: {}\", e.getMessage());\n}\n}\n}", "CodeBleu_score": 44.82136054268706}, {"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Exception while closing Kafka producer\", e);\n\t\t} finally {\n\t\t\tproducer = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 58.61553906449177}, {"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.216837460594526}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t// Create a producer template builder\nTbQueueProducerTemplate.Builder<TbProtoQueueMsg<ToRuleEngineMsg>> builder =\n        new TbQueueProducerTemplate.Builder<TbProtoQueueMsg<ToRuleEngineMsg>>();\n// Configure the template builder with the required settings\nbuilder.kafka().bootstrapServers(bootstrapServers)\n        .topic(ruleEngineTopic)\n        .keySerializer(new StringSerializer())\n        .valueSerializer(new TbProtoSerializer<ToRuleEngineMsg>())\n        .admin(adminClient)\n        .clientId(clientId);\n// Build the producer template\nTbQueueProducerTemplate<TbProtoQueueMsg<ToRuleEngineMsg>> producerTemplate = builder.build();\n// Return the configured producer\nreturn producerTemplate.getProducer();\n}", "CodeBleu_score": 37.33740799944026}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaProducerTemplate.Builder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new TbKafkaProducerTemplate.Builder<>();\n\tbuilder.kafka().bootstrapServers(kafkaBootstrapServers);\n\tbuilder.kafka().defaultTopic(ruleEngineTopic);\n\tbuilder.kafka().acks(1);\n\tbuilder.kafka().retries(0);\n\tbuilder.kafka().batchSize(16384);\n\tbuilder.kafka().lingerMs(1);\n\tbuilder.kafka().bufferMemory(33554432);\n\tbuilder.kafka().keySerializer(new StringSerializer());\n\tbuilder.kafka().valueSerializer(new TbProtoSerializer<ToRuleEngineMsg>());\n\tbuilder.admin().client(admin);\n\tbuilder.admin().topic(ruleEngineTopic);\n\tbuilder.admin().defaultTopic(ruleEngineTopic);\n\tbuilder.admin().pollInterval(pollInterval);\n\tbuilder.admin().partitionsCount(partitionsCount);\n\tbuilder.admin().replicationFactor(replicationFactor);\n\tbuilder.admin().topicConfig(topicConfig);\n\tbuilder.admin().topicName(buildTopicName(ruleEngineTopic));\n\tbuilder.admin().clientId(getClientId(ruleEngineTopic));\n\tbuilder.admin().settings(settings);\n\treturn builder.build();\n}", "CodeBleu_score": 32.679692091813386}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaProducerTemplate.Builder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new TbKafkaProducerTemplate.Builder<>();\n\tbuilder.kafka().bootstrapServers(kafkaBootstrapServers);\n\tbuilder.kafka().defaultTopic(defaultTopic);\n\tbuilder.kafka().defaultPartition(defaultPartition);\n\tbuilder.kafka().defaultKey(defaultKey);\n\tbuilder.kafka().defaultMsgKey(defaultMsgKey);\n\tbuilder.kafka().acks(kafkaAcks);\n\tbuilder.kafka().retries(kafkaRetries);\n\tbuilder.kafka().batchSize(kafkaBatchSize);\n\tbuilder.kafka().lingerMs(kafkaLingerMs);\n\tbuilder.kafka().bufferMemory(kafkaBufferMemory);\n\tbuilder.kafka().keySerializer(new StringSerializer());\n\tbuilder.kafka().valueSerializer(new TbProtoSerializer<>(ToRuleEngineMsg.class));\n\tbuilder.kafka().producerConfig(producerProps);\n\tbuilder.admin().clientId(clientId);\n\tbuilder.admin().settings(adminProps);\n\treturn builder.build();\n}", "CodeBleu_score": 33.15798598732764}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t", "CodeBleu_score": 0.6449045691040067}, {"code": "private void startLogScheduling(){\n\t\n}", "CodeBleu_score": 0.6776176710826489}, {"code": "private void startLogScheduling(){\n\t//        log.info(\"Starting periodic logging of Kafka consumer group statistics.\");\n        long kafkaResponseTimeoutMs = kafkaConsumerConfig.getKafkaResponseTimeoutMs();\n        long printIntervalMs = kafkaConsumerConfig.getPrintIntervalMs();\n        long timeoutDuration = kafkaResponseTimeoutMs + printIntervalMs;\n        ScheduledFuture<?> scheduledFuture = scheduler.scheduleWithFixedDelay(new KafkaConsumerStatsLogTask(), timeoutDuration, printIntervalMs, TimeUnit.MILLISECONDS);\n        if (scheduledFuture == null) {\n            log.warn(\"Failed to schedule Kafka consumer group statistics logging task.\");\n        }\n    }", "CodeBleu_score": 15.47752286709951}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\n\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tif (metric instanceof Counter) {\n\t\tcounterMetrics.put(getScopedName(metricName, group), (Counter) metric);\n\t} else if (metric instanceof Gauge) {\n\t\tgaugeMetrics.put(getScopedName(metricName, group), (Gauge) metric);\n\t} else if (metric instanceof Histogram) {\n\t\thistogramMetrics.put(getScopedName(metricName, group), (Histogram) metric);\n\t} else if (metric instanceof Meter) {\n\t\tmeterMetrics.put(getScopedName(metricName, group), (Meter) metric);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: \" + metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 39.725859000473164}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t// We only support Counter, Gauge, Histogram, and Meter metrics.\n\tif (metric instanceof Counter || metric instanceof Gauge || metric instanceof Histogram || metric instanceof Meter) {\n\t\t// Get the scoped name and tags from the group.\n\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\t// Add the metric and its event to the corresponding collection.\n\t\tif (metric instanceof Counter) {\n\t\t\tcounters.put(scopedName, (Counter) metric);\n\t\t\tcounterEvents.add(new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tgauges.put(scopedName, (Gauge) metric);\n\t\t\tgaugeEvents.add(new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t\t} else if (metric instanceof Histogram) {\n\t\t\thistograms.put(scopedName, (Histogram) metric);\n\t\t\thistogramEvents.add(new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t\t} else if (metric instanceof Meter) {\n\t\t\tmeters.put(scopedName, (Meter) metric);\n\t\t\tmeterEvents.add(new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t\t}\n\t} else {\n\t\t// The metric type is unknown.\n\t\tLOG.warn(\"Unknown metric type: \" + metric.getClass() + \". Ignoring metric: \" + metricName + \" in group: \" + group);\n\t}\n}", "CodeBleu_score": 46.00224226624701}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tif (metric == null) {\n\t\tthrow new IllegalArgumentException(\"Metric must not be null\");\n\t}\n\tif (metricName == null) {\n\t\tthrow new IllegalArgumentException(\"Metric name must not be null\");\n\t}\n\tif (group == null) {\n\t\tthrow new IllegalArgumentException(\"Metric group must not be null\");\n\t}\n\t// check whether the metric is already registered\n\tif (registeredMetrics.containsKey(metricName)) {\n\t\tthrow new IllegalArgumentException(\"A metric with the name \" + metricName + \" is already registered\");\n\t}\n\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\t// add the metric to the corresponding collection\n\tif (metric instanceof Counter) {\n\t\tregisteredCounters.put(scopedName, (Counter) metric);\n\t\tregisteredCounterEvents.put(scopedName, new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t} else if (metric instanceof Gauge) {\n\t\tregisteredGauges.put(scopedName, (Gauge<Object>) metric);\n\t\tregisteredGaugeEvents.put(scopedName, new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t} else if (metric instanceof Histogram) {\n\t\tregisteredHistograms.put(scopedName, (Histogram) metric);\n\t\tregisteredHistogramEvents.put(scopedName, new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t} else if (metric instanceof Meter) {\n\t\tregisteredMeters.put(scopedName, (Meter) metric);\n\t\tregisteredMeterEvents.put(scopedName, new MetricEvent(scopedName, tags, System.currentTimeMillis()));\n\t} else {\n\t\tLOG.warn(\"The metric type {} is not supported. The metric {} will not be registered.\", metric.getClass().getName(), metricName);\n\t}\n\tregisteredMetrics.put(metricName, metric);\n}", "CodeBleu_score": 41.343580162285775}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (metricEvent.getFields() != null) {\n\t\tif (value instanceof Number) {\n\t\t\tmetricEvent.getFields().put(field, value);\n\t\t} else {\n\t\t\tmetricEvent.getFields().put(field, value.toString());\n\t\t}\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tif (value instanceof Number) {\n\t\t\tfields.put(field, value);\n\t\t} else {\n\t\t\tfields.put(field, value.toString());\n\t\t}\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 57.17925424015564}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (gauge != null) {\n\t\tObject value = gauge.getValue();\n\t\tif (value != null) {\n\t\t\treturn addFields(metricEvent, field, value);\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 23.914803378372522}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (metricEvent.getFields() == null) {\n\t\tMap<String, Object> fields = new HashMap<String, Object>();\n\t\tfields.put(field, value);\n\t\tmetricEvent.setFields(fields);\n\t} else {\n\t\tmetricEvent.getFields().put(field, value);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 36.933351950522635}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString[] metricName = metricEvent.getMetricName().split(\"\\\\.\");\n\tif (metricName.length != 3) {\n\t\tthrow new IllegalArgumentException(\"Metric name must be of the form 'componentName.topicName.partitionId'.\");\n\t}\n\tString componentName = metricName[0];\n\tString topicName = metricName[1];\n\tint partitionId = Integer.parseInt(metricName[2]);\n\tString key = componentName + \".\" + topicName + \".\" + partitionId;\n\tlong currentOffset = (long) gauge.getValue();\n\tlong committedOffset = (long) gauge.getContext().get(\"committedOffset\");\n\tlong lag = currentOffset - committedOffset;\n\tlong lagTime = timestamp - (Long) gauge.getContext().get(\"lastReportTime\");\n\tif (lagTime < 0) {\n\t\tlagTime = 0;\n\t}\n\tmetricEvent.setFields(new HashMap<String, Object>() {{\n\t\tput(\"currentOffset\", currentOffset);\n\t\tput(\"committedOffset\", committedOffset);\n\t\tput(\"lag\", lag);\n\t\tput(\"lagTime\", lagTime);\n\t}});\n\tmetricEvent.setTimestamp(timestamp);\n\tif (lagTime != 0) {\n\t\tmetricEvent.getTags().put(\"lagTime\", String.valueOf(lagTime));\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 37.43325845663027}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties props = buildKafkaProps(env.getExecutionConfig().getGlobalJobParameters());\nif (time != null) {\n    Map<KafkaTopicPartition, Long> partitionOffsets = buildOffsetByTime(props, env.getExecutionConfig().getGlobalJobParameters(), time);\n    setStartFromSpecificOffsets(env, topic, partitionOffsets);\n}\nDataStreamSource<MetricEvent> source = env.addSource(new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props));\nreturn source;\n}", "CodeBleu_score": 50.06587523781049}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool globalJobParameters = getGlobalJobParameters(env);\n\tProperties kafkaProps = buildKafkaProps(globalJobParameters);\n\tMap<KafkaTopicPartition, Long> specificOffsets = buildOffsetByTime(kafkaProps, globalJobParameters, time);\n\tsetStartFromSpecificOffsets(kafkaProps, specificOffsets);\n\tFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n\tDataStreamSource<MetricEvent> kafkaSource = env.addSource(kafkaConsumer);\n\treturn kafkaSource;\n}", "CodeBleu_score": 52.480897025712345}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tProperties props = buildKafkaProps();\n\tParameterTool parameterTool = env.getConfig().getGlobalJobParameters();\n\tMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n\tsetStartFromSpecificOffsets(props, partitionOffset);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new JsonSchema(), props);\n\tDataStreamSource<MetricEvent> source = env.addSource(consumer);\n\treturn source;\n}", "CodeBleu_score": 60.85514427844202}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\t// Set the consumer group ID to the provided time\n\tprops.setProperty(\"group.id\", String.valueOf(time));\n\t// Create a KafkaConsumer using the properties\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\t// Retrieve the partition information for the specified topic\n\tList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\t// Create a map of KafkaTopicPartition to offsets\n\tMap<KafkaTopicPartition, Long> topicPartitionOffsets = new HashMap<>();\n\t// For each partition, fetch the offset for the provided time\n\tfor (PartitionInfo partition : partitions) {\n\t\ttopicPartitionOffsets.put(new KafkaTopicPartition(partition.topic(), partition.partition()),\n\t\t\t\tconsumer.offsetsForTimes(Collections.singletonMap(partition, time)).get(partition));\n\t}\n\t// Close the consumer and return the map of partition offsets\n\tconsumer.close();\n\treturn topicPartitionOffsets;\n}", "CodeBleu_score": 44.407780117894944}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\tString topic = parameterTool.getRequired(\"topic\");\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tconsumer.assign(partitionsFor(consumer, topic));\n\tMap<TopicPartition, OffsetAndTimestamp> offsetsForTimes = consumer.offsetsForTimes(Collections.singletonMap(new TopicPartition(topic, 0), time));\n\tconsumer.close();\n\tfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsetsForTimes.entrySet()) {\n\t\tpartitionOffsets.put(new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry.getValue().offset());\n\t}\n\treturn partitionOffsets;\n}", "CodeBleu_score": 40.553839310903996}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t// Set the consumer group ID using the provided time\nprops.setProperty(\"group.id\", \"buildOffsetByTime-\" + time);\n\n// Create a KafkaConsumer with the properties\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n// Retrieve partition information for the specified topic\nMap<KafkaTopicPartition, PartitionInfo> partitionInfoMap = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\n// Create a map associating each partition with the timestamp\nMap<KafkaTopicPartition, Long> partitionTimeMap = new HashMap<>();\nfor (KafkaTopicPartition partition : partitionInfoMap.keySet()) {\npartitionTimeMap.put(partition, time);\n}\n\n// Fetch offsets for the given times\nMap<KafkaTopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionTimeMap);\n\n// Close the consumer and return the map of partition offsets\nconsumer.close();\nreturn offsets;\n}", "CodeBleu_score": 45.29506509919648}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t// Configure Kafka producer properties\nProperties properties = new Properties();\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n\n// Create a KafkaProducer instance\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);\n\n// Create a MetricEvent instance\nMetricEvent metricEvent = new MetricEvent();\n\n// Populate the MetricEvent\nmetricEvent.setName(\"test_event\");\nmetricEvent.setTimestamp(System.currentTimeMillis());\nmetricEvent.setFields(new HashMap<String, Object>() {{\nput(\"field1\", 123);\nput(\"field2\", \"abc\");\n}});\nmetricEvent.setTags(new HashMap<String, String>() {{\nput(\"tag1\", \"tag1\");\nput(\"tag2\", \"tag2\");\n}});\n\n// Create a ProducerRecord instance\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"metrics\", metricEvent.toJson());\n\n// Send the record to Kafka\nproducer.send(record);\n\n// Print the sent data\nSystem.out.println(record.toString());\n\n// Flush the producer to ensure all data is sent\nproducer.flush();\n\n// Close the producer\nproducer.close();\n}", "CodeBleu_score": 42.103043046029626}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties properties = new Properties();\nproperties.put(\"bootstrap.servers\", \"localhost:9092\");\nproperties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nproperties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nProducer<String, String> producer = new KafkaProducer<String, String>(properties);\nMetricEvent metricEvent = new MetricEvent();\nmetricEvent.setName(\"test_metric\");\nmetricEvent.setTimestamp(System.currentTimeMillis());\nmetricEvent.setFields(new HashMap<String, Object>() {{\nput(\"field1\", 1);\nput(\"field2\", 2);\n}});\nmetricEvent.setTags(new HashMap<String, String>() {{\nput(\"tag1\", \"value1\");\nput(\"tag2\", \"value2\");\n}});\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test_topic\", null, metricEvent.toJson());\nproducer.send(record);\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 48.56059289184641}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\n\tprops.put(ProducerConfig.CLIENT_ID_CONFIG, \"MetricEventProducer\");\n\tprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\tprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, MetricEventSerializer.class.getName());\n\n\tKafkaProducer<String, MetricEvent> producer = new KafkaProducer<String, MetricEvent>(props);\n\n\tMetricEvent me = new MetricEvent();\n\tme.setTimestamp(System.currentTimeMillis());\n\tme.setName(\"KafkaMetricEvent\");\n\tme.setTags(new HashMap<String, String>() {{\n\t\tput(\"host\", \"localhost\");\n\t\tput(\"region\", \"us-west-2\");\n\t}});\n\tme.setFields(new HashMap<String, Double>() {{\n\t\tput(\"cpu\", 75.3);\n\t\tput(\"memory\", 85.3);\n\t}});\n\n\tProducerRecord<String, MetricEvent> data = new ProducerRecord<String, MetricEvent>(\"metrics\", me);\n\tproducer.send(data);\n\tproducer.flush();\n\tproducer.close();\n\n\tSystem.out.println(\"MetricEvent sent to Kafka\");\n\tThread.sleep(1000);\n}", "CodeBleu_score": 43.26625759910695}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (!checkLevel(event.getLevel())) {\n\t\treturn;\n\t}\n\tif (checkLogger(event.getLoggerName())) {\n\t\treturn;\n\t}\n\ttry {\n\t\tproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n\t} catch (Exception e) {\n\t\tlog.warn(\"Error sending log event to Kafka topic '{}'\", topic, e);\n\t}\n}", "CodeBleu_score": 44.721667263007284}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (event.getLevel().isMoreSpecificThan(level)) {\nreturn;\n}\n\nif (loggerFilter != null && loggerFilter.isFiltered(event.getLoggerName())) {\nreturn;\n}\n\ntry {\nproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n} catch (Exception e) {\nlog.warn(\"Error sending log event to Kafka\", e);\n}\n}", "CodeBleu_score": 42.43961908280948}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (event.getLevel().toString().equals(\"INFO\")) {\nif (!event.getLoggerName().contains(\"xxx\")) {\ntry {\nString message = subAppend(event);\nproducer.send(new ProducerRecord<String, String>(topic, message));\n} catch (Exception e) {\nlog.warn(\"Error while sending message to Kafka\", e);\n}\n}\n}\n}", "CodeBleu_score": 43.9956559528344}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method %q\", method)\n}", "CodeBleu_score": 89.26407316638922}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, v := range validTopicSuffixMethods {\n\t\tif method == v {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 80.5371172877213}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, m := range validTopicSuffixMethods {\n\t\tif m == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 78.72835933549631}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"routing tag not present in metric\")\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 58.603640220451304}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar routingKey string\n\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\troutingKey = tag\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %s not found\", k.RoutingTag)\n\t\t}\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\troutingKey = uuid.NewV4().String()\n\t} else {\n\t\troutingKey = k.RoutingKey\n\t}\n\treturn routingKey, nil\n}", "CodeBleu_score": 51.6915925098437}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tkey := k.RoutingKey\n\tif key == \"random\" {\n\t\tkey = uuid.NewV4().String()\n\t}\n\tif key == \"\" {\n\t\ttag := k.RoutingTag\n\t\tif tag != \"\" {\n\t\t\tvalue, ok := metric.GetTag(tag)\n\t\t\tif !ok {\n\t\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not present in metric %q\", tag, metric.Name())\n\t\t\t}\n\t\t\tkey = value\n\t\t}\n\t}\n\treturn key, nil\n}", "CodeBleu_score": 43.70404531668329}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(re)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regex %s: %s\", re, err)\n\t\t}\n\t\tregexps[i] = re\n\t}\n\tk.regexps = regexps\n\treturn nil\n}", "CodeBleu_score": 46.330947077894976}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tif len(k.TopicRegexps) == 0 {\n\t\treturn fmt.Errorf(\"no topic regular expressions provided\")\n\t}\n\n\tregexps := make([]*regexp.Regexp, 0, len(k.TopicRegexps))\n\tfor _, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", re, err)\n\t\t}\n\n\t\tregexps = append(regexps, r)\n\t}\n\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 48.39008322053847}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\t// Compile the regular expressions\n\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topic := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(topic)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp '%s': %s\", topic, err)\n\t\t}\n\t\tregexps[i] = re\n\t}\n\tk.regexps = regexps\n\treturn nil\n}", "CodeBleu_score": 46.98813558459031}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\nmsg := h.undelivered[track.ID]\nif msg != nil {\nmsg.session.MarkMessage(msg, telegraf.Delivered)\ndelete(h.undelivered, track.ID)\n}\nh.mu.Unlock()\nh.delivered.Done()\n}", "CodeBleu_score": 34.81780661521886}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok {\n\t\tmsg.session.MarkMessage(msg, track)\n\t\tdelete(h.undelivered, track.ID)\n\t}\n\th.mu.Unlock()\n\th.delivered.Done()\n}", "CodeBleu_score": 46.5628925729304}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\nmsg := h.undelivered[track.ID]\nif msg != nil {\nmsg.session.MarkMessage(msg, telegraf.Delivered)\ndelete(h.undelivered, track.ID)\n}\nh.mu.Unlock()\nh.sem.Done()\n}", "CodeBleu_score": 34.25737175540944}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\terr := h.Handle(ctx, msg)\n\t\t\tif err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 46.88866924979782}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tdefault:\n\t\t\t// Check for new messages from the consumer group claim.\n\t\t\tfor msg := range claim.Messages() {\n\t\t\t\terr := h.Handle(ctx, msg)\n\t\t\t\tif err != nil {\n\t\t\t\t\th.acc.AddError(err)\n\t\t\t\t}\n\t\t\t\tclaim.MarkMessage(msg, \"\")\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 54.15963768274473}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tfor {\n\t\tif session.Context().Err() != nil {\n\t\t\treturn nil\n\t\t}\n\t\tif !h.Reserve(ctx) {\n\t\t\treturn nil\n\t\t}\n\t\tfor msg := range claim.Messages() {\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\tlog.Println(\"error handling message\", err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 42.92183554534004}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t", "CodeBleu_score": 1.1892782233472832}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tif(logkafka_id.isEmpty) {\nthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n}\nif(logkafka_id.equals(\".\")) {\nthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n}\nif(logkafka_id.equals(\"..\")) {\nthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n}\nif(logkafka_id.length > 255) {\nthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n}\nif(!logkafka_id.findFirstIn(\"[a-zA-Z0-9-_.]\").isDefined) {\nthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n}\n}", "CodeBleu_score": 29.55122192888852}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id != \".\", IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id != \"..\", IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.length <= 64, IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.matches(\"\"\"[a-zA-Z0-9-_.]+\"\"\"), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 37.028062429960094}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tFuture.successful(msg).flatMap { m =>\n      system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n        case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n        case o: Output =>\n          fn(o)\n      }.recover {\n        case e: Throwable =>\n          Future.successful(-\\/(ApiError.fromThrowable(e)))\n      }\n    }\n\n}", "CodeBleu_score": 76.43355281011252}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\nval request = KMClusterCommandRequest(clusterName, PreferredReplicaLeaderElectionCommand(topics))\n\nsendClusterCommand(request) map {\n  case (result, _) => result.map(ClusterContext.apply)\n}\n  }", "CodeBleu_score": 22.70528158215393}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\nval request = KMClusterCommandRequest(clusterName, PreferredReplicaElectionCommand(topics))\n\nval result = sendRequest(request)\n\nresult.map {\n  case KMSuccess(result) =>\n    \\/-(ClusterContext(clusterName, result.clusterInfo.map(_.brokerId).toSet, result.clusterInfo.map(_.brokerId).toSet))\n  case KMError(error) =>\n    -\\/(ApiError(error))\n}\n  }", "CodeBleu_score": 21.98705601702102}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMRunPreferredLeaderElection(Set.empty)\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 49.62992638317967}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMRunPreferredLeaderElection(Set.empty[String])\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 49.69900100899948}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMRunPreferredLeaderElection(Set.empty[String])\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 49.69900100899948}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\tval results = assignments.map {\n  case (topic, partitions) =>\n    tryWithKafkaManagerActor(\n      KMClusterCommandRequest(\n        clusterName,\n        CMManualPartitionAssignments(\n          partitions.map {\n            case (partitionId, replicas) =>\n              CMAssignedPartition(topic, partitionId, replicas.map(r => ReplicaAssignment(r, r)).toSeq)\n          }\n        )\n      )\n    )\n}\n\nval result = results.map(_.result.collect {\n  case CMAssignedPartition(_, partitionId, replicas) =>\n    (partitionId, replicas.map(_.id))\n})\n\nresult.result.collect {\n  case (partitionId, replicas) =>\n    (partitionId, replicas.mkString(\",\"))\n}\n}", "CodeBleu_score": 19.538097472727088}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tList<Node> nodes = getNodes(admin, 10000);\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka nodes available.\");\n\t}\n\n\tString nodeId = nodes.get(0).idString();\n\tConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, nodeId);\n\tConfig config = admin.describeConfigs(Collections.singleton(resource)).all().get(resource);\n\tif (config.values().isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka broker configuration found.\");\n\t}\n\n\treturn config.values().get(nodeId);\n}", "CodeBleu_score": 49.12902461106233}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t// Describe the cluster to get the available nodes\nDescribeClusterResult describeClusterResult = admin.describeCluster();\nList<Node> nodes = describeClusterResult.nodes().get();\n\n// If no nodes are available, throw an exception\nif (nodes.size() == 0) {\nthrow new ConnectException(\"No nodes found in the Kafka cluster.\");\n}\n\n// Select the first node's ID and request its configuration\nString nodeId = nodes.get(0).idString();\nDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(nodeId));\n\n// If no configurations are received, throw an exception\nMap<String, Config> configMap = describeConfigsResult.all().get();\nif (configMap.size() == 0) {\nthrow new ConnectException(\"No configuration found for node \" + nodeId);\n}\n\n// Return the broker's configuration\nreturn configMap.get(nodeId);\n}", "CodeBleu_score": 41.99389261764594}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\nCollection<Node> nodes = admin.describeCluster().nodes().get(120, TimeUnit.SECONDS);\nif (nodes.size() == 0) {\nthrow new ConnectException(\"No broker available!\");\n}\nNode node = nodes.iterator().next();\nConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\nreturn admin.describeConfigs(Collections.singleton(resource)).all().get(120, TimeUnit.SECONDS).get(resource);\n} catch (Exception e) {\nthrow new ConnectException(\"Failed to retrieve Kafka broker configuration: \" + e.getMessage());\n}\n}", "CodeBleu_score": 44.33495127695056}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Config config) {\n\t\t\tfinal String schemaHistory = config.getString(ConfigOptions.KEY_SCHEMA_HISTORY);\n\t\t\tif (schemaHistory.equals(KafkaSchemaHistory.class.getName())) {\n\t\t\t\treturn validator.validate(config);\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t};\n}", "CodeBleu_score": 40.612096216791784}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Config config) {\n\t\t\tfinal String schemaHistory = config.getString(KafkaConfig.SCHEMA_REGISTRY_URL_CONFIG);\n\t\t\tif (schemaHistory != null && schemaHistory.equals(KafkaConfig.KafkaSchemaHistory.KAFKASTORE.name())) {\n\t\t\t\treturn validator.validate(config);\n\t\t\t} else {\n\t\t\t\treturn 0;\n\t\t\t}\n\t\t}\n\t};\n}", "CodeBleu_score": 36.240034446624506}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Configuration configuration) {\n\t\t\tfinal String schemaHistory = configuration.getString(ConfigOptions.SCHEMA_HISTORY_TOPIC);\n\t\t\tif (schemaHistory.equals(KafkaSchemaHistory.class.getName())) {\n\t\t\t\treturn validator.validate(configuration);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 39.704003342246295}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (topicCreationEnabled == null) {\n\t\ttopicCreationEnabled = parseBoolean(config.get(TOPIC_CREATION_ENABLE_CONFIG));\n\t\tif (topicCreationEnabled == null) {\n\t\t\ttopicCreationEnabled = Boolean.TRUE;\n\t\t}\n\n\t\tif (topicCreationEnabled) {\n\t\t\tfinal String connectVersion = getVersion();\n\t\t\tif (connectVersion != null) {\n\t\t\t\tfinal Version version = parseVersion(connectVersion);\n\t\t\t\tif (version.compareTo(MIN_TOPIC_CREATION_VERSION) < 0) {\n\t\t\t\t\tLOGGER.info(\"Topic creation is enabled but is not supported in Kafka Connect version {}. \" +\n\t\t\t\t\t\t\t\"Kafka Connect version {} or higher is required.\", connectVersion, MIN_TOPIC_CREATION_VERSION);\n\t\t\t\t\ttopicCreationEnabled = Boolean.FALSE;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn topicCreationEnabled;\n}", "CodeBleu_score": 38.014129797603644}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (topicCreationEnabled == null) {\n\t\tString kafkaConnectVersionString = getVersion();\n\t\tVersion kafkaConnectVersion = parseVersion(kafkaConnectVersionString);\n\t\tif (kafkaConnectVersion.compareTo(VERSION_2_1_0) < 0) {\n\t\t\ttopicCreationEnabled = false;\n\t\t}\n\t\telse {\n\t\t\ttopicCreationEnabled = Boolean.parseBoolean(get(config, TOPIC_CREATION_ENABLE_CONFIG, \"true\"));\n\t\t}\n\t}\n\treturn topicCreationEnabled;\n}", "CodeBleu_score": 42.13215730507369}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (topicCreationEnabled == null) {\n\t\tString kafkaConnectVersion = parseVersion(getConnectCluster().getVersion().toString()).toString();\n\t\ttopicCreationEnabled = parseBoolean(config.getOrDefault(TOPIC_CREATION_ENABLE_CONFIG, TOPIC_CREATION_ENABLE_DEFAULT));\n\t\tif (topicCreationEnabled) {\n\t\t\tlogger.info(\"Topic creation is enabled and is compatible with Kafka Connect version {}.\", kafkaConnectVersion);\n\t\t}\n\t\telse {\n\t\t\tlogger.info(\"Topic creation is disabled and is compatible with Kafka Connect version {}.\", kafkaConnectVersion);\n\t\t}\n\t}\n\treturn topicCreationEnabled;\n}", "CodeBleu_score": 37.124331484087115}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\n}", "CodeBleu_score": 3.8343025383378277}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\n}", "CodeBleu_score": 3.8343025383378277}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t// Check if the node is an object\nif (!node.isObject()) {\nthrow new IOException(\"Key must be an object\");\n}\n\n// Check if the key is a composite key\nif (config.keyFields() != null && config.keyFields().size() > 0) {\n// Extract the payload field if present\nif (node.has(PAYLOAD_FIELD)) {\nnode = node.get(PAYLOAD_FIELD);\n}\n// Read the entire node as the key\nreturn reader.readValue(node);\n}\nelse {\n// Read the value of the single key field\nString keyFieldName = config.keyField();\nif (!node.has(keyFieldName)) {\nthrow new IOException(\"Key field '\" + keyFieldName + \"' not found in message\");\n}\nreturn reader.readValue(node.get(keyFieldName));\n}\n}", "CodeBleu_score": 42.501778734477405}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (!node.isObject()) {\nthrow new IOException(String.format(\"Key must be an object, but was %s\", node.getNodeType()));\n}\nif (config.keyFields().isEmpty()) {\nreturn null;\n}\nelse if (config.keyFields().size() == 1) {\nString fieldName = config.keyFields().get(0);\nif (!node.has(fieldName)) {\nthrow new IOException(String.format(\"Key does not contain field '%s'\", fieldName));\n}\nreturn reader.readValue(node.get(fieldName));\n}\nelse {\nObjectNode key = mapper.createObjectNode();\nfor (String fieldName : config.keyFields()) {\nif (!node.has(fieldName)) {\nthrow new IOException(String.format(\"Key does not contain field '%s'\", fieldName));\n}\nkey.set(fieldName, node.get(fieldName));\n}\nreturn reader.readValue(key);\n}\n}", "CodeBleu_score": 43.75412853706382}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\nnode = node.get(PAYLOAD_FIELD);\n}\n\n// Schema + payload format\nif (node.isObject()) {\nIterator<String> fieldNames = node.fieldNames();\nwhile (fieldNames.hasNext()) {\nString fieldName = fieldNames.next();\nif (fieldName.equals(Envelope.FieldName.SOURCE) && config.asEnvelope()) {\nreturn reader.readValue(node);\n}\nif (fieldName.equals(config.sourceField())) {\nreturn reader.readValue(node.get(fieldName));\n}\n}\n}\n\n// Debezium envelope\nif (config.asEnvelope()) {\nreturn reader.readValue(node);\n}\n\n// Extracted format\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 45.420905843444835}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tif (id == null) {\nthrow new IllegalArgumentException(\"id cannot be null\");\n}\nif (prefix == null) {\nthrow new IllegalArgumentException(\"prefix cannot be null\");\n}\nif (delimiter == null) {\nthrow new IllegalArgumentException(\"delimiter cannot be null\");\n}\nString topicName = topicNameFor(id);\nif (topicName.startsWith(prefix)) {\nreturn topicName;\n}\nelse {\nString sanitizedTopicName = sanitize(topicName, prefix, delimiter);\nif (sanitizedTopicName != topicName) {\nlogger.warn(\"Topic name '\" + topicName + \"' is invalid and has been sanitized to '\" + sanitizedTopicName + \"'\");\n}\nreturn sanitizedTopicName;\n}\n}", "CodeBleu_score": 26.31742427642073}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tif (prefix == null) {\nprefix = \"\";\n}\nif (delimiter == null) {\ndelimiter = \"\";\n}\n\nString topicName = topicNameFor(id);\nif (topicName.startsWith(prefix) && topicName.endsWith(delimiter)) {\nreturn topicName;\n}\n\nStringBuilder sb = new StringBuilder(topicName);\nboolean modified = false;\nfor (int i = 0; i < sb.length(); i++) {\nchar c = sb.charAt(i);\nif (!isValidTopicNameCharacter(c)) {\nsb.setCharAt(i, replacementCharacter);\nmodified = true;\n}\n}\nif (modified) {\nwarn(\"Invalid characters were replaced in topic name \" + topicName + \".  The topic name has been sanitized to \" + sb.toString());\n}\nreturn sb.toString();\n}", "CodeBleu_score": 42.77632848396689}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tif (id == null) {\nthrow new IllegalArgumentException(\"id cannot be null\");\n}\nif (prefix == null) {\nthrow new IllegalArgumentException(\"prefix cannot be null\");\n}\nif (delimiter == null) {\nthrow new IllegalArgumentException(\"delimiter cannot be null\");\n}\n\nString topicName = topicNameFor(id);\n\nboolean modified = false;\n\nchar[] chars = topicName.toCharArray();\nfor (int i = 0; i < chars.length; i++) {\nif (!isValidTopicNameCharacter(chars[i])) {\nchars[i] = replacementCharacter;\nmodified = true;\n}\n}\n\nif (modified) {\nString sanitizedTopicName = new String(chars);\nlogger.warn(\"The topic name '\" + topicName + \"' contains invalid characters. The topic name has been sanitized to '\" + sanitizedTopicName + \"'.\");\ntopicName = sanitizedTopicName;\n}\n\nreturn topicName;\n}", "CodeBleu_score": 37.567281751659344}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 86.18283332940219}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 86.18283332940219}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 86.18283332940219}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader != null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 97.57940834905897}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader != null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.78268445597212}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader != null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.78268445597212}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\nString snapshotString = (String) source.get(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\ntry {\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n} catch (IllegalArgumentException e) {\nreturn null;\n}\n}", "CodeBleu_score": 36.33690902988952}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\n\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\n\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 26.21092239617402}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.schema().field(SNAPSHOT_KEY).schema().type().equals(Schema.Type.ENUM)) {\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString != null) {\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}\n}\nreturn null;\n}", "CodeBleu_score": 47.462216905301766}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] numbers = parts[0].split(\"-\");\n\tif (numbers.length > 1) {\n\t\treturn Optional.of(Float.parseFloat(numbers[0]));\n\t}\n\treturn Optional.of(Float.parseFloat(parts[0]));\n}", "CodeBleu_score": 53.268176191871696}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null || version.isEmpty()) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] subParts = parts[0].split(\"-\");\n\tif (subParts.length > 1) {\n\t\ttry {\n\t\t\treturn Optional.of(Float.parseFloat(subParts[0]));\n\t\t} catch (NumberFormatException e) {\n\t\t\treturn Optional.empty();\n\t\t}\n\t} else {\n\t\ttry {\n\t\t\treturn Optional.of(Float.parseFloat(parts[0]));\n\t\t} catch (NumberFormatException e) {\n\t\t\treturn Optional.empty();\n\t\t}\n\t}\n}", "CodeBleu_score": 53.72178717148206}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null || version.isEmpty()) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0].split(\"-\")[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 59.82067974410747}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 92.94612271212847}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 92.94612271212847}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.86403343743555}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n.operationName(\"deleteConnector\")\n.operationParams(Map.of(CONNECTOR_NAME, connectName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 93.24741260180726}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 96.09403183430064}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nAccessContext context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 94.35170673334919}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n}", "CodeBleu_score": 6.700678162085702}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n}", "CodeBleu_score": 6.700678162085702}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n}", "CodeBleu_score": 6.700678162085702}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(new DynamicConfigPropertiesInitializer())\n\t\t.run(args);\n}", "CodeBleu_score": 40.64046746937218}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigPropertiesInitializer());\n\treturn builder.run(args);\n}", "CodeBleu_score": 44.72881051305274}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(new DynamicConfigPropertiesInitializer())\n\t\t.run(args);\n}", "CodeBleu_score": 40.64046746937218}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn connector -> true;\n\t}\n\tfinal String searchTerm = search.toLowerCase();\n\treturn connector -> getStringsForSearch(connector).anyMatch(s -> containsIgnoreCase(s, searchTerm));\n}", "CodeBleu_score": 60.144184589209814}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\tif (search == null) {\n\t\treturn connector -> true;\n\t}\n\tfinal String searchTerm = search.toLowerCase();\n\treturn connector -> getStringsForSearch(connector).anyMatch(s -> containsIgnoreCase(s, searchTerm));\n}", "CodeBleu_score": 60.144184589209814}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\nreturn x -> true;\n}\nfinal String searchTerm = search.trim();\nif (searchTerm.isEmpty()) {\nreturn x -> true;\n}\nfinal String lowerCaseSearchTerm = searchTerm.toLowerCase();\nreturn x -> getStringsForSearch(x).anyMatch(y -> y.toLowerCase().contains(lowerCaseSearchTerm));\n}", "CodeBleu_score": 59.89168303371986}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\nMap<String, Object> result = new HashMap<String, Object>();\n\nif (propertiesMap == null) {\n  return result;\n}\n\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n  String key = entry.getKey();\n  Object value = entry.getValue();\n  String newKey = prefix == null ? key : prefix + \".\" + key;\n  if (value instanceof Map) {\n    result.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n  } else {\n    result.put(newKey, value);\n  }\n}\n\nreturn result;\n  }", "CodeBleu_score": 50.64319642335353}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedProperties;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = (prefix == null) ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattenedProperties.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattenedProperties.put(newKey, value);\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 51.0290000237301}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return null;\n//    }\n    Map<String, Object> flattened = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      String newKey = (prefix == null) ? key : prefix + \".\" + key;\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattened.put(newKey, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 53.9495147115089}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().stream().filter(c -> c.type() == ConfigDef.Type.PASSWORD).collect(Collectors.toSet());\n }", "CodeBleu_score": 59.71450423295923}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().stream().filter(configKey -> configKey.type() == ConfigDef.Type.PASSWORD).collect(Collectors.toSet());\n }", "CodeBleu_score": 60.8049594672616}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n Set<String> passwordKeys = configDef.configKeys().stream()\n .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n .collect(Collectors.toSet());\n return passwordKeys;\n }", "CodeBleu_score": 62.27628921581554}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tif (clusterDescription.getClusterFeatures().contains(ClusterFeature.AUTHORIZED_SECURITY_ENABLED)) {\nreturn adminClient.describeAcls(AclBindingFilter.ANY)\n.map(AclBindingFilter::getOperation)\n.collect(Collectors.toSet())\n.flatMap(operations -> {\nif (operations.containsAll(ImmutableSet.of(AclOperation.ALTER, AclOperation.DESCRIBE, AclOperation.ANY)) || operations.contains(AclOperation.ALL)) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n} else {\nreturn Mono.empty();\n}\n});\n} else {\nreturn Mono.empty();\n}\n}", "CodeBleu_score": 29.61699146026034}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn adminClient.describeCluster().map(cluster -> {\n\t\tif (cluster.getFeatures().contains(ClusterFeature.AUTHORIZED_SECURITY_FEATURE)) {\n\t\t\tList<String> authorizedOperations = cluster.getAuthorizedOperations();\n\t\t\tif (authorizedOperations.contains(AclOperation.ALL.name()) || authorizedOperations.contains(AclOperation.ALTER.name())) {\n\t\t\t\treturn ClusterFeature.AUTHORIZED_SECURITY_FEATURE;\n\t\t\t}\n\t\t}\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 29.39586628303461}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.just(clusterDescription.getAuthorizedOperations())\n.filter(ops -> ops.containsAll(List.of(AclOperation.ALTER, AclOperation.DESCRIBE)))\n.map(ops -> ClusterFeature.KAFKA_ACL_EDIT)\n.defaultIfEmpty(ClusterFeature.NONE);\n}", "CodeBleu_score": 26.03544303301184}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\n// If the previous range is empty, we start from the offsets from the seek operations.\nif (prevRange.isEmpty()) {\nfor (Map.Entry<TopicPartition, Long> seek : seekOperations.getOffsetsForSeek().entrySet()) {\nnextRange.put(seek.getKey(), new FromToOffset(seek.getValue(), seek.getValue()));\n}\n} else {\n// For each topic partition, we get the offsets from the previous range.\nfor (Map.Entry<TopicPartition, FromToOffset> prevRangeEntry : prevRange.entrySet()) {\nTopicPartition tp = prevRangeEntry.getKey();\nFromToOffset prevRangeOffset = prevRangeEntry.getValue();\n\n// If the previous range contains an offset for this topic partition, we use it as the starting offset.\n// Otherwise, we use the seek operation offset.\nlong startOffset = prevRangeOffset.getFrom();\nif (startOffset == OFFSET_NOT_SET) {\nstartOffset = seekOperations.getOffsetsForSeek().getOrDefault(tp, OFFSET_NOT_SET);\n}\n\n// We calculate the end offset based on the number of messages to poll.\nlong endOffset = startOffset + numRecordsPerPartition;\n\n// We adjust the end offset based on the last offset in the partition.\nlong lastOffset = offsets.get(tp).high();\nif (endOffset > lastOffset) {\nendOffset = lastOffset;\n}\n\nnextRange.put(tp, new FromToOffset(startOffset, endOffset));\n}\n}\nreturn nextRange;\n}", "CodeBleu_score": 35.28070569318216}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n// For each topic partition\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset prevOffset = entry.getValue();\n// If the previous range is empty, get the offset from the seek operations\nif (prevOffset.getFrom() == null) {\nlong offset = seekOperations.getOffset(tp);\nFromToOffset fromToOffset = new FromToOffset(offset, null);\nnextRange.put(tp, fromToOffset);\n} else {\n// Calculate the number of messages to poll\nlong toPoll = Math.min(prevOffset.getTo() - prevOffset.getFrom() + 1, pollSize);\n// Calculate the start offset\nlong startOffset = prevOffset.getFrom() + toPoll - 1;\n// Ensure the start offset is not below the beginning offset\nlong beginningOffset = beginningOffsets.get(tp);\nif (startOffset < beginningOffset) {\nstartOffset = beginningOffset;\n}\n// Calculate the end offset\nlong endOffset = Math.min(startOffset + toPoll - 1, endOffsets.get(tp));\nFromToOffset fromToOffset = new FromToOffset(startOffset, endOffset);\nnextRange.put(tp, fromToOffset);\n}\n}\nreturn nextRange;\n}", "CodeBleu_score": 31.404658343043266}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tMap<TopicPartition, Long> offsetsToReadFrom = new HashMap<>();\nif (prevRange != null && !prevRange.isEmpty()) {\n// Get the last offset of the previous range\nFromToOffset lastOffset = prevRange.lastEntry().getValue();\n// For each topic partition, get the offset to read from from the previous range\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\nlong prevOffset = fromToOffset.getTo();\nlong nextOffset = prevOffset + 1;\n// If the offset from the previous range is not the last offset of the partition,\n// add the offset to the map of offsets to read from\nif (nextOffset < lastOffset.getTo()) {\noffsetsToReadFrom.put(tp, nextOffset);\n}\n}\n} else {\n// If there is no previous range, get the offsets from the seek operations\nfor (Map.Entry<TopicPartition, Long> entry : seekOperations.getOffsets().entrySet()) {\nTopicPartition tp = entry.getKey();\nlong seekOffset = entry.getValue();\noffsetsToReadFrom.put(tp, seekOffset);\n}\n}\n// Get the number of messages to poll per partition\nint numMessagesPerPartition = Math.max(1, Math.min(numMessagesPerPoll, maxNumMessagesPerPoll));\n// For each topic partition, get the start offset and the end offset\n// of the range to poll\nTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nfor (Map.Entry<TopicPartition, Long> entry : offsetsToReadFrom.entrySet()) {\nTopicPartition tp = entry.getKey();\nlong startOffset = entry.getValue();\nlong endOffset = Math.max(startOffset, startOffset + numMessagesPerPartition - 1);\n// Ensure the end offset does not go below the beginning offset\nlong partitionSize = Math.max(0, endOffset - startOffset + 1);\nlong partitionBeginning = Math.max(0, startOffset - partitionSize);\nnextRange.put(tp, new FromToOffset(partitionBeginning, endOffset));\n}\nreturn nextRange;\n}", "CodeBleu_score": 32.07141308996836}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\n    if (configuration.getString(CK_BOOTSTRAP) == null && configuration.getString(CK_ZOOKEEPER) == null) {\n        throw new IllegalArgumentException(\"Either \" + CK_BOOTSTRAP + \" or \" + CK_ZOOKEEPER + \" must be configured in legacy mode.\");\n    }\n    doLaunchLegacy(input);\n} else {\n    doLaunchConsumer(input);\n}\n\nscheduleAtFixedRate(new Runnable() {\n    @Override\n    public void run() {\n        final long tmp = lastSecBytesReadTmp.getAndSet(0);\n        if (tmp > 0) {\n            lastSecBytesRead.set(tmp);\n        }\n    }\n}, 1, 1, TimeUnit.SECONDS);\n\nregister(Lifecycle.class);\n\nawaitRunning();\n\nLOG.info(\"Started Kafka input.\");\n}", "CodeBleu_score": 36.38381188852933}, {"code": "public void doLaunch(final MessageInput input){\n\t\nif (configuration.getBoolean(CK_LEGACY_MODE)) {\n// legacy mode is enabled, check for required settings\nif (configuration.getString(CK_ZOOKEEPER) == null) {\nthrow new IllegalArgumentException(\"Legacy mode requires setting \" + CK_ZOOKEEPER);\n}\nif (configuration.getString(CK_BOOTSTRAP) != null) {\nthrow new IllegalArgumentException(\"Legacy mode does not support setting \" + CK_BOOTSTRAP);\n}\ndoLaunchLegacy(input);\n} else {\n// legacy mode is not enabled, check for required settings\nif (configuration.getString(CK_BOOTSTRAP) == null) {\nthrow new IllegalArgumentException(\"Consumer mode requires setting \" + CK_BOOTSTRAP);\n}\nif (configuration.getString(CK_ZOOKEEPER) != null) {\nthrow new IllegalArgumentException(\"Consumer mode does not support setting \" + CK_ZOOKEEPER);\n}\ndoLaunchConsumer(input);\n}\n\n// register for lifecycle changes\nlifecycle.register(this);\n\n// schedule a task to update the last second bytes read\nscheduler.scheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 32.03615909240224}, {"code": "public void doLaunch(final MessageInput input){\n\t\tLOG.info(\"Launching message input: {}\", input.getId());\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\n\t\tif (configuration.containsKey(CK_ZOOKEEPER) && configuration.containsKey(CK_BOOTSTRAP)) {\n\t\t\tthrow new IllegalArgumentException(\"Cannot use both legacy mode and new consumer mode at the same time.\");\n\t\t}\n\n\t\tif (!configuration.containsKey(CK_ZOOKEEPER) && !configuration.containsKey(CK_BOOTSTRAP)) {\n\t\t\tthrow new IllegalArgumentException(\"Must use either legacy mode or new consumer mode.\");\n\t\t}\n\n\t\tif (configuration.containsKey(CK_ZOOKEEPER)) {\n\t\t\tLOG.info(\"Using legacy mode with ZooKeeper.\");\n\t\t} else {\n\t\t\tLOG.info(\"Using legacy mode with bootstrap servers.\");\n\t\t}\n\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tLOG.info(\"Using new consumer mode.\");\n\t\tdoLaunchConsumer(input);\n\t}\n\n\t// schedule a task to update the last second bytes read every second\n\tscheduler.scheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n\n\t// wait for the server to be running\n\tawaitRunning();\n\n\t// register for lifecycle events\n\tlifecycle.register(this);\n}", "CodeBleu_score": 38.982526612674974}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\tString customPropsString = \"\";\n\ttry {\n\t\tcustomPropsString = getString(\"custom.properties.string\");\n\t} catch (IOException e) {\n\t\terror(\"Could not load custom properties string: \" + e.getMessage());\n\t}\n\n\tProperties customProps = new Properties();\n\ttry {\n\t\tcustomProps.load(new StringReader(customPropsString));\n\t} catch (IOException e) {\n\t\terror(\"Could not load custom properties: \" + e.getMessage());\n\t}\n\n\tprops.putAll(customProps);\n}", "CodeBleu_score": 43.53847153712267}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProperties = getCustomProperties();\n\tif (customProperties != null) {\n\t\tProperties customProps = new Properties();\n\t\ttry {\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Error loading custom properties: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 42.52689725569268}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProps = System.getProperty(\"custom.properties\");\n\tif (customProps != null) {\n\t\ttry {\n\t\t\tProperties customPropsObj = new Properties();\n\t\t\tcustomPropsObj.load(new StringReader(customProps));\n\t\t\tprops.putAll(customPropsObj);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Unable to load custom properties\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.27136139530262}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\treturn;\n\t}\n\n\tfinal List<Journal.Entry> journalEntries = new ArrayList<>();\n\tfinal List<RawMessageEvent> nonNullEntries = entries.stream()\n\t\t\t.filter(Objects::nonNull).collect(Collectors.toList());\n\n\tlong totalBytes = 0;\n\tfor (RawMessageEvent entry : nonNullEntries) {\n\t\tfinal Journal.Entry journalEntry = map(entry);\n\t\tjournalEntries.add(journalEntry);\n\t\ttotalBytes += journalEntry.getRawMessage().length;\n\t}\n\n\tLOG.debug(\"Writing batch of {} entries, total bytes: {}\", journalEntries.size(), totalBytes);\n\n\twhile (true) {\n\t\ttry {\n\t\t\twriteToJournal(journalEntries);\n\t\t\tbreak;\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Failed to write batch to journal, retrying.\", e);\n\t\t\ttry {\n\t\t\t\tThread.sleep(backoff.next());\n\t\t\t} catch (InterruptedException ie) {\n\t\t\t\tLOG.debug(\"Interrupted while sleeping, exiting.\");\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t}\n\n\twrittenMessages.addAndGet(journalEntries.size());\n\twrittenBytes.addAndGet(totalBytes);\n}", "CodeBleu_score": 40.49148357955969}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\treturn;\n\t}\n\n\tlong start = System.nanoTime();\n\n\t// filter out null entries\n\tList<RawMessageEvent> nonNullEntries = entries.stream().filter(Objects::nonNull)\n\t\t\t.collect(Collectors.toList());\n\n\t// map each entry to a journal entry\n\tList<Journal.Entry> journalEntries = nonNullEntries.stream().map(this::toJournalEntry)\n\t\t\t.collect(Collectors.toList());\n\n\tlong end = System.nanoTime();\n\n\t// update metrics\n\tlong bytes = journalEntries.stream().mapToLong(Journal.Entry::size).sum();\n\tlong messages = journalEntries.size();\n\n\twrittenBytes.addAndGet(bytes);\n\twrittenMessages.addAndGet(messages);\n\n\t// write entries to journal\n\twriteToJournal(journalEntries);\n}", "CodeBleu_score": 36.27977740740273}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\tLOG.debug(\"No entries to write to journal.\");\n\t\treturn;\n\t}\n\n\tfinal List<Journal.Entry> journalEntries = entries.stream()\n\t\t\t.filter(Objects::nonNull)\n\t\t\t.map(this::mapEntry)\n\t\t\t.collect(toList());\n\n\tif (journalEntries.isEmpty()) {\n\t\tLOG.debug(\"No entries to write to journal.\");\n\t\treturn;\n\t}\n\n\ttry {\n\t\twriteToJournal(journalEntries);\n\t} catch (InterruptedException e) {\n\t\tLOG.error(\"Interrupted while writing to journal.\", e);\n\t\tThread.currentThread().interrupt();\n\t}\n}", "CodeBleu_score": 32.86963055177024}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tlong max = messages.stream().map(Message::getQueueId).filter(Objects::nonNull).max(Long::compare).orElse(0L);\n\tif (max > 0) {\n\t\tacknowledgedMessages.mark(max);\n\t\tstream.acknowledge(max);\n\t}\n}", "CodeBleu_score": 38.08888924736416}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages == null || messages.isEmpty()) {\nreturn;\n}\nlong max = -1;\nfor (Message message : messages) {\nlong msgId = message.getMessageId();\nif (msgId > max) {\nmax = msgId;\n}\n}\nif (max >= 0) {\nacknowledgedMessages.mark(max + 1);\n}\n}", "CodeBleu_score": 19.02847197027277}, {"code": "public void acknowledge(List<Message> messages){\n\tlong maxId = messages.stream()\n.map(Message::getQueueId)\n.filter(id -> id >= 0)\n.max(Long::compare)\n.orElse(-1);\nif (maxId >= 0) {\nacknowledgedMessages.mark(maxId + 1);\n}\n}", "CodeBleu_score": 36.25975848012853}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\tfinal Set<String> legacyMetricNames = new HashSet<>();\nfor (final Map.Entry<String, Metric> entry : this.getMetrics().entrySet()) {\n    if (entry.getKey().startsWith(LocalKafkaJournal.class.getName())) {\n        legacyMetricNames.add(entry.getKey());\n    }\n}\n\nfor (final Map.Entry<String, Metric> entry : this.getMetrics().entrySet()) {\n    final String metricName = entry.getKey();\n    if (legacyMetricNames.contains(metricName)) {\n        final String legacyMetricName = metricName.replace(LocalKafkaJournal.class.getName(), \"KafkaJournal\");\n        try {\n            this.getMetricRegistry().register(legacyMetricName, entry.getValue());\n        } catch (final IllegalArgumentException e) {\n            this.log.warn(\"Unable to register metric {} under legacy name {}\", metricName, legacyMetricName, e);\n        }\n    }\n}\n\n}", "CodeBleu_score": 37.40774657725054}, {"code": "private void registerLegacyMetrics(){\n\t// Register legacy metrics in the metric registry.\nfinal Map<String, Gauge<Object>> gauges = new HashMap<>();\nfinal Set<String> metricNames = LocalKafkaJournal.this.metrics.getNames();\nfor (final String metricName : metricNames) {\n    if (metricName.startsWith(LocalKafkaJournal.class.getName())) {\n        final String legacyMetricName = metricName.replace(LocalKafkaJournal.class.getName(), \"KafkaJournal\");\n        try {\n            gauges.put(legacyMetricName, (Gauge<Object>) LocalKafkaJournal.this.metrics.get(metricName));\n        } catch (Exception e) {\n            LocalKafkaJournal.this.log.warn(\"Failed to register legacy metric {} under name {}\", metricName, legacyMetricName, e);\n        }\n    }\n}\nLocalKafkaJournal.this.metrics.register(LocalKafkaJournal.class.getName(), gauges);\n}", "CodeBleu_score": 36.8119034502716}, {"code": "private void registerLegacyMetrics(){\n\t\n}", "CodeBleu_score": 1.0472453922148197}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = null;\ntry {\ntimer = metricRegistry.timer(metricName);\n} catch (IllegalArgumentException iae) {\ntimer = metricRegistry.timer(metricRegistry.getNames().get(metricRegistry.getNames().indexOf(metricName)));\n}\nreturn timer;\n}", "CodeBleu_score": 36.21743764842175}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.timer(metricRegistry.getNames().get(metricRegistry.getNames().indexOf(metricName)));\n\t}\n\treturn timer;\n}", "CodeBleu_score": 38.35006531884273}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = metricRegistry.timer(metricName);\ntry {\ntimer = metricRegistry.timer(metricName);\n} catch (IllegalArgumentException e) {\ntimer = metricRegistry.timer(metricName);\n}\nreturn timer;\n}", "CodeBleu_score": 28.53668348781807}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n    metricRegistry.register(MetricRegistry.name(name, \"Uncommitted\"), new Gauge<Long>() {\n        @Override\n        public Long getValue() {\n            long committedOffset = getCommittedOffset();\n            long logEndOffset = getLogEndOffset();\n            long uncommitted = 0;\n            if (committedOffset == KafkaLog.INVALID_COMMITTED_OFFSET) {\n                uncommitted = logEndOffset - getLogStartOffset();\n            } else {\n                uncommitted = logEndOffset - committedOffset;\n            }\n            return uncommitted;\n        }\n    });\n} catch (IllegalArgumentException e) {\n    log.warn(\"Error while registering uncommitted gauge for {}. {}\", name, e.getMessage());\n}\n}", "CodeBleu_score": 40.052934991427016}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n    metricRegistry.register(MetricRegistry.name(name, \"Uncommitted\"), new Gauge<Integer>() {\n        @Override\n        public Integer getValue() {\n            long committedOffset = getCommittedOffset();\n            if (committedOffset == -1) {\n                return (int) (getLogEndOffset() - getLogStartOffset());\n            }\n            return (int) (getLogEndOffset() - committedOffset);\n        }\n    });\n} catch (IllegalArgumentException e) {\n    logger.error(\"Failed to register gauge metric {}.{}\", name, \"Uncommitted\", e);\n}\n}", "CodeBleu_score": 42.75426067593755}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n    metricRegistry.register(name, (Gauge<Long>) () -> {\n        final long committedOffset = kafkaLog.committedOffset();\n        if (committedOffset == KafkaLog.INVALID_OFFSET) {\n            return getLogEndOffset() - getLogStartOffset();\n        }\n        return getLogEndOffset() - committedOffset;\n    });\n} catch (IllegalArgumentException e) {\n    log.warn(\"Unable to register gauge for uncommitted messages: {}\", e.getMessage());\n}\n}", "CodeBleu_score": 50.93527492869509}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlogger.debug(\"No messages to flush\");\n}\n\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages);\nlong startOffset = kafkaLog.append(messageSet);\nlong endOffset = startOffset + messageSet.sizeInBytes();\n\nlogger.debug(\"Wrote {} bytes to Kafka log beginning at offset {}\", payloadSize, startOffset);\nlogger.debug(\"Wrote {} messages to Kafka log beginning at offset {}\", messageSet.size(), startOffset);\nlogger.debug(\"Wrote {} bytes to Kafka log ending at offset {}\", messageSet.sizeInBytes(), endOffset);\n\nreturn endOffset;\n}", "CodeBleu_score": 38.21745784024698}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n    log.debug(\"No messages to flush\");\n    return lastOffset;\n}\n\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages);\nlog.debug(\"Writing {} bytes to Kafka log\", messageSet.sizeInBytes());\n\nlastOffset = kafkaLog.append(messageSet);\n\nlog.debug(\"Wrote {} messages to Kafka log at offset {}\", messages.size(), lastOffset);\nmark(messages.size());\nreturn lastOffset;\n}", "CodeBleu_score": 36.823961492304434}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to write to Kafka log\");\nreturn 0;\n}\n\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages);\nlog.debug(\"Writing {} messages to Kafka log with {} bytes\", messages.size(), messageSet.sizeInBytes());\n\nlong lastOffset = kafkaLog.append(messageSet);\nlog.debug(\"Wrote {} messages to Kafka log with last offset {}\", messages.size(), lastOffset);\n\nmark(messages.size(), payloadSize);\nreturn lastOffset;\n}", "CodeBleu_score": 37.48553914357722}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u4f4f\u5ba2\u6237\u7aefmap\uff0c\u4fdd\u8bc1\u7ebf\u7a0b\u5b89\u5168\n        synchronized (this.clientMap) {\n            List<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n// \u5173\u95ed\u5ba2\u6237\u7aef\uff0c\u8d85\u65f6\u65f6\u95f4\u4e3a30\u79d2\n            boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n            }\n// \u79fb\u9664\u5ba2\u6237\u7aef\u5217\u8868\n            this.clientMap.remove(clusterPhyId);\n        }\n    }", "CodeBleu_score": 55.17447672079775}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\n}", "CodeBleu_score": 2.823742511002327}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9a\u5ba2\u6237\u7aef\u96c6\u5408\n        synchronized (this.clientMap) {\n            List<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n            }\n\n            this.clientMap.remove(clusterPhyId);\n        }\n    }", "CodeBleu_score": 51.60941398839014}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tboolean success = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Failed to close Kafka AdminClient for cluster {}.\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 66.16269885445159}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tfor (AdminClient adminClient in adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing Kafka AdminClient for cluster ID: \" + clusterPhyId, e)\n\t\t\tsuccess = false\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 36.77867467518995}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tboolean success = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tLOG.error(\"Failed to close Kafka admin client for cluster {}: {}\", clusterPhyId, e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 57.953317916369926}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.73382833539546}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.73382833539546}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.73382833539546}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t", "CodeBleu_score": 3.2210673266230256}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTls(true);\n\trunner.setKeyStore(KEYSTORE_PATH, KEYSTORE_PASSWORD, TRUSTSTORE_PATH, TRUSTSTORE_PASSWORD);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 45.885262333364174}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner runner = new EurekaServerRunner(config);\nrunner.enableTls();\nrunner.setKeyStore(KEYSTORE_PATH, KEYSTORE_PASSWORD);\nrunner.setTrustStore(TRUSTSTORE_PATH, TRUSTSTORE_PASSWORD);\nrunner.start();\nreturn runner;\n}", "CodeBleu_score": 44.14879798629162}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tKeyTool ca = createCA();\n\tKeyTool server = createServer(ca);\n\tKeyTool client = createClient(ca);\n\tKeyTool client2 = createClient2(ca);\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveCert(client);\n\tsaveCert(client2);\n\tsaveKeyAndCert(ca);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 22.905092250118734}, {"code": "static void createCertificates() throws Exception{\n\t\tfinal KeyTool keyTool = new KeyTool();\n\tfinal KeyAndCert ca = keyTool.createCA();\n\tfinal KeyAndCert server = keyTool.sign(ca, \"server\");\n\tfinal KeyAndCert client = keyTool.sign(ca, \"client\");\n\tkeyTool.saveCert(ca);\n\tkeyTool.saveCert(server);\n\tkeyTool.saveCert(client);\n\tfinal KeyAndCert ca2 = keyTool.createCA();\n\tfinal KeyAndCert client2 = keyTool.sign(ca2, \"client2\");\n\tkeyTool.saveCert(ca2);\n\tkeyTool.saveCert(client2);\n}", "CodeBleu_score": 32.42082749984133}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyAndCert ca = createCA();\n\tKeyAndCert server = createCert(ca, \"server\");\n\tKeyAndCert client = createCert(ca, \"client\");\n\tKeyAndCert client2 = createCert(ca, \"client2\");\n\tsaveCert(ca);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 26.041192554005534}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong start = System.currentTimeMillis();\n\tlong limit = start + seconds * 1000;\n\twhile (System.currentTimeMillis() < limit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tsleep(100);\n\t}\n\tthrow new RuntimeException(\"Assertion failed\");\n}", "CodeBleu_score": 50.69434480293486}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + seconds * 1000;\n\twhile (true) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tif (System.currentTimeMillis() >= timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed\");\n\t\t}\n\t}\n}", "CodeBleu_score": 46.437653827434424}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = currentTimeMillis();\n\tlong timeLimit = startTime + seconds * 1000;\n\twhile (true) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tif (currentTimeMillis() > timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n\t\t}\n\t}\n}", "CodeBleu_score": 41.51188091670455}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 75.55908499750589}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\tbuilder.addExtension(Extension.subjectKeyIdentifier, false, createSubjectKeyId(keyPair.getPublic()));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 70.40988460947246}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\t// Add Key Usage extension\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\n\t// Add Basic Constraints extension\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 76.67971341875977}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient != null) {\n\t\treturn eurekaHttpClient;\n\t}\n\ttry {\n\t\tField registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\tmakeAccessible(registrationClientField);\n\t\tregistrationClient = (RegistrationClient) registrationClientField.get(eurekaTransport);\n\t\tField eurekaHttpClientField = registrationClient.getClass().getDeclaredField(\"eurekaHttpClient\");\n\t\tmakeAccessible(eurekaHttpClientField);\n\t\teurekaHttpClient = (EurekaHttpClient) eurekaHttpClientField.get(registrationClient);\n\t\treturn eurekaHttpClient;\n\t} catch (IllegalAccessException e) {\n\t\tLOGGER.error(\"Error accessing EurekaHttpClient\", e);\n\t\treturn null;\n\t} catch (NoSuchFieldException e) {\n\t\tLOGGER.error(\"Error accessing EurekaHttpClient\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 44.76221116273306}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = EurekaTransport.class.getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(this.eurekaTransport);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access eurekaHttpClient field\", e);\n\t\t} catch (NoSuchFieldException e) {\n\t\t\tlogger.error(\"Cannot find eurekaHttpClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 44.99999239448304}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tregistrationClient.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access EurekaHttpClient\", e);\n\t\t} catch (NoSuchFieldException e) {\n\t\t\tlogger.error(\"Cannot access EurekaHttpClient\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 50.40775320384678}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\tString vipAddress = instance.getVIPAddress();\n\t\t\tif (StringUtils.hasText(vipAddress)) {\n\t\t\t\tservices.add(vipAddress.toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 51.33459082352029}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\tString name = instance.getAppName().toLowerCase();\n\t\t\tif (!services.contains(name)) {\n\t\t\t\tservices.add(name);\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 53.64616884072009}, {"code": "public List<String> getServices(){\n\t\tApplications apps = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tfor (Application app : apps.getRegisteredApplications()) {\n\t\tfor (InstanceInfo instance : app.getInstances()) {\n\t\t\tString name = instance.getAppName();\n\t\t\tif (!services.contains(name.toLowerCase())) {\n\t\t\t\tservices.add(name.toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 50.35541440549007}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tMap<String, HealthContributor> temp = new HashMap<>();\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor healthContributor = entry.getValue();\n\t\tif (healthContributor instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) healthContributor;\n\t\t\tfor (Map.Entry<String, HealthIndicator> indicatorEntry : discoveryCompositeHealthContributor.getIndicators().entrySet()) {\n\t\t\t\tHealthIndicator healthIndicator = indicatorEntry.getValue();\n\t\t\t\tif (!(healthIndicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\ttemp.put(indicatorEntry.getKey(), healthIndicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\ttemp.put(entry.getKey(), healthContributor);\n\t\t}\n\t}\n\thealthContributors.clear();\n\thealthContributors.putAll(temp);\n}", "CodeBleu_score": 41.00469813222471}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (Map.Entry<String, HealthContributor> indicatorEntry : compositeHealthContributor.getIndicators().entrySet()) {\n\t\t\t\tif (!(indicatorEntry.getValue() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicatorEntry.getKey(), indicatorEntry.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.53558633675321}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (Map.Entry<String, HealthContributor> indicatorEntry : compositeHealthContributor.getIndicators().entrySet()) {\n\t\t\t\tif (!(indicatorEntry.getValue() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicatorEntry.getKey(), indicatorEntry.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.53558633675321}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n\tString uri = instances.get(0).getUri();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n\treturn response;\n}", "CodeBleu_score": 53.36992710282964}, {"code": "public String hello(){\n\t\t// Attempt to discover an instance of \"provider-application\"\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances found for 'provider-application'\");\n\t}\n\t// Retrieve the first instance's URI\n\tURI uri = instances.get(0).getUri();\n\t// Send a POST request to its \"/echo\" endpoint using RestTemplate\n\tMap<String, String> params = new HashMap<String, String>();\n\tparams.put(\"message\", \"Hello from consumer-application!\");\n\tString response = new RestTemplate().postForObject(uri + \"/echo\", params, String.class);\n\t// Return the response\n\treturn response;\n}", "CodeBleu_score": 57.02968103199565}, {"code": "public String hello(){\n\t\tString uri = discoveryClient.getInstances(\"provider-application\").get(0).getUri();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n}", "CodeBleu_score": 20.00305715658425}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tString url = loadBalancerClient.choose(\"provider-application\").getUri() + \"/echo\";\n\tRestTemplate restTemplate = new RestTemplate();\n\tResponseEntity<String> response = restTemplate.postForEntity(url, \"World\", String.class);\n\treturn response.getBody();\n}", "CodeBleu_score": 38.8818414020821}, {"code": "public String world(){\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\tif (serviceInstance == null) {\n\t\tthrow new RuntimeException(\"No service instance found\");\n\t}\n\tString serviceUri = String.format(\"http://%s:%d\", serviceInstance.getHost(), serviceInstance.getPort());\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(serviceUri + \"/echo\", \"Hello from Spring Cloud Netflix!\", String.class);\n}", "CodeBleu_score": 58.4376932130896}, {"code": "public String world(){\n\t\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\"No service instance found for 'provider-application'\");\n\t}\n\tString serviceUri = \"http://\" + instance.getHost() + \":\" + instance.getPort() + \"/echo\";\n\tRestTemplate restTemplate = new RestTemplate();\n\tString response = restTemplate.postForObject(serviceUri, \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 58.5441567066606}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// Your code here\n\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t} else {\n\t\tsynchronizedSet = new HashSet<Server>();\n\t\tsynchronizedSet.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, synchronizedSet);\n\t}\n\tlogger.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\treturn true;\n}", "CodeBleu_score": 52.67329985050034}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlogger.info(\"Successfully registered \" + serviceName + \" with \" + ip + \":\" + port);\n\t\treturn true;\n\t} else {\n\t\tsynchronized (serverMap) {\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t\tlogger.info(\"Successfully registered \" + serviceName + \" with \" + ip + \":\" + port);\n\t\t\treturn true;\n\t\t}\n\t}\n}", "CodeBleu_score": 45.45175412064277}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// Your code goes here\n\tif (serverMap.containsKey(serviceName)) {\n\t\tsynchronized (serverMap.get(serviceName)) {\n\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t}\n\t} else {\n\t\tsynchronized (serverMap) {\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t}\n\t}\n\tlogger.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\treturn true;\n}", "CodeBleu_score": 49.05691471449649}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serviceName == null || ip == null || port == null) {\n\t\tthrow new IllegalArgumentException(\"Arguments cannot be null\");\n\t}\n\n\tif (!serverMap.containsKey(serviceName)) {\n\t\tlog.info(\"Service \" + serviceName + \" is not registered\");\n\t\treturn false;\n\t}\n\n\tServer server = serverMap.get(serviceName).get(ip + \":\" + port);\n\tif (server == null) {\n\t\tlog.info(\"Service \" + serviceName + \" with ip \" + ip + \" and port \" + port + \" is not registered\");\n\t\treturn false;\n\t}\n\n\tserverMap.get(serviceName).remove(ip + \":\" + port);\n\tlog.info(\"Deregistered service \" + serviceName + \" with ip \" + ip + \" and port \" + port);\n\treturn true;\n}", "CodeBleu_score": 40.887985091295}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: implement\n\treturn false;\n}", "CodeBleu_score": 15.915118860340804}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> serverSet = serverMap.get(serviceName);\n\t\tfor (Server server : serverSet) {\n\t\t\tif (server.getIp().equals(ip) && server.getPort().equals(port)) {\n\t\t\t\tserverSet.remove(server);\n\t\t\t\tlogger.info(\"Deregistered server: \" + server);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\tlogger.warn(\"Failed to deregister server: \" + ip + \":\" + port + \" for service: \" + serviceName);\n\treturn false;\n}", "CodeBleu_score": 38.583538700138014}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes == null) {\n\t\treturn;\n\t}\n\tMap<String, Object> defaultAttributes = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\n\tif (defaultAttributes == null) {\n\t\treturn;\n\t}\n\tString name = (String) defaultAttributes.get(\"name\");\n\tif (StringUtils.isEmpty(name)) {\n\t\tname = metadata.getClassName();\n\t}\n\tregisterClientConfiguration(registry, name, defaultAttributes);\n\tMap<String, Object> namedAttributes = (Map<String, Object>) attributes.get(\"named\");\n\tif (namedAttributes != null) {\n\t\tfor (Map.Entry<String, Object> entry : namedAttributes.entrySet()) {\n\t\t\tMap<String, Object> configuration = (Map<String, Object>) entry.getValue();\n\t\t\tString configurationName = (String) configuration.get(\"name\");\n\t\t\tif (StringUtils.isEmpty(configurationName)) {\n\t\t\t\tconfigurationName = entry.getKey();\n\t\t\t}\n\t\t\tregisterClientConfiguration(registry, configurationName, configuration);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.23892286622649}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 4.511580463841749}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes != null) {\n\t\tMap<String, Object> clients = (Map<String, Object>) attributes.get(\"value\");\n\t\tif (clients != null) {\n\t\t\tfor (Map.Entry<String, Object> entry : clients.entrySet()) {\n\t\t\t\tString name = entry.getKey();\n\t\t\t\tObject value = entry.getValue();\n\t\t\t\tif (value instanceof Class) {\n\t\t\t\t\tClass<?> clazz = (Class<?>) value;\n\t\t\t\t\tif (clazz.isAnnotationPresent(RibbonClient.class)) {\n\t\t\t\t\t\tRibbonClient annotation = clazz.getAnnotation(RibbonClient.class);\n\t\t\t\t\t\tif (StringUtils.hasText(annotation.configuration())) {\n\t\t\t\t\t\t\tregisterClientConfiguration(registry, name, annotation.configuration());\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\telse if (value instanceof String) {\n\t\t\t\t\tregisterClientConfiguration(registry, name, value);\n\t\t\t\t}\n\t\t\t\telse if (value instanceof RibbonClientSpecification) {\n\t\t\t\t\tregisterClientConfiguration(registry, name, value);\n\t\t\t\t}\n\t\t\t\telse if (value instanceof Map) {\n\t\t\t\t\tMap<String, Object> map = (Map<String, Object>) value;\n\t\t\t\t\tif (map.containsKey(\"configuration\")) {\n\t\t\t\t\t\tregisterClientConfiguration(registry, name, map.get(\"configuration\"));\n\t\t\t\t\t}\n\t\t\t\t\telse {\n\t\t\t\t\t\tregisterClientConfiguration(registry, name, map);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 43.86150749964387}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString originalScheme = original.getScheme();\n\tString originalHost = original.getHost();\n\tint originalPort = original.getPort();\n\tString originalPath = original.getRawPath();\n\tString originalQuery = original.getRawQuery();\n\tif (originalScheme == null) {\n\t\tthrow new IllegalArgumentException(\"Original URI must have a scheme\");\n\t}\n\tif (originalHost == null) {\n\t\tthrow new IllegalArgumentException(\"Original URI must have a host\");\n\t}\n\tif (originalPort == -1) {\n\t\tthrow new IllegalArgumentException(\"Original URI must have a port\");\n\t}\n\tif (originalPath == null) {\n\t\tthrow new IllegalArgumentException(\"Original URI must have a path\");\n\t}\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"Server instance must not be null\");\n\t}\n\tString scheme = originalScheme;\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString path = originalPath;\n\tString query = originalQuery;\n\tif (host.equals(originalHost) && port == originalPort) {\n\t\treturn original;\n\t}\n\ttry {\n\t\tString newURI = new URI(scheme, null, host, port, path, query, null).toString();\n\t\treturn URI.create(newURI);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 38.81559846876739}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server must not be null\");\n\t}\n\tif (original == null) {\n\t\tthrow new IllegalArgumentException(\"original must not be null\");\n\t}\n\tString scheme = original.getScheme();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString path = original.getRawPath();\n\tString query = original.getRawQuery();\n\tStringBuilder sb = new StringBuilder();\n\tsb.append(scheme).append(\"://\").append(host).append(\":\").append(port);\n\tif (path != null) {\n\t\tsb.append(path);\n\t}\n\tif (query != null) {\n\t\tsb.append(\"?\").append(query);\n\t}\n\ttry {\n\t\treturn new URI(sb.toString());\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 52.0024993075214}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString originalURI = original.toString();\n\tString originalPath = original.getRawPath();\n\tString originalQuery = original.getRawQuery();\n\tString originalScheme = original.getScheme();\n\tif (originalQuery == null) {\n\t\toriginalQuery = \"\";\n\t}\n\tif (originalPath == null) {\n\t\toriginalPath = \"\";\n\t}\n\tif (originalScheme == null) {\n\t\toriginalScheme = \"\";\n\t}\n\tString newURI = originalScheme + \"://\" + server.getHost() + \":\" + server.getPort() + originalPath + \"?\" + originalQuery;\n\ttry {\n\t\treturn new URI(newURI);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Error reconstructing URI: \" + newURI, e);\n\t}\n}", "CodeBleu_score": 36.99429887376949}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tString serviceName = getServiceName()\n\tString serverAddr = getServerAddr()\n\tString url = serverAddr + \"/list\"\n\tString params = \"serviceName=\" + serviceName\n\tHttpClient client = new DefaultHttpClient()\n\tHttpResponse response = client.execute(new HttpGet(url + \"?\" + params))\n\tBufferedReader reader = new BufferedReader(new InputStreamReader(response.getEntity().getContent()))\n\tString line = reader.readLine()\n\tString json = \"[\" + line\n\twhile (line != null) {\n\t\tline = reader.readLine()\n\t\tif (line != null) {\n\t\t\tjson += \", \" + line\n\t\t}\n\t}\n\tjson += \"]\"\n\tList<TutuServer> servers = new ArrayList<TutuServer>()\n\ttry {\n\t\tJSONArray jsonArray = new JSONArray(json)\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject jsonObj = jsonArray.getJSONObject(i)\n\t\t\tString ip = jsonObj.getString(\"ip\")\n\t\t\tint port = jsonObj.getInt(\"port\")\n\t\t\tTutuServer server = new TutuServer(ip, port)\n\t\t\tservers.add(server)\n\t\t}\n\t} catch (JSONException e) {\n\t\te.printStackTrace()\n\t}\n\treturn servers\n}", "CodeBleu_score": 24.15827217419853}, {"code": "private List<TutuServer> getServer(){\n\t\ttry {\n\t\tURL url = new URL(getServerAddr() + \"/list?serviceName=\" + serviceName);\n\t\tHttpURLConnection connection = (HttpURLConnection) url.openConnection();\n\t\tconnection.setReadTimeout(10000);\n\t\tconnection.setConnectTimeout(15000);\n\t\tconnection.setRequestMethod(\"GET\");\n\t\tconnection.setDoInput(true);\n\t\tconnection.setDoOutput(false);\n\t\tconnection.setUseCaches(false);\n\t\tconnection.setAllowUserInteraction(false);\n\t\tconnection.setRequestProperty(\"Content-Type\", \"application/json\");\n\t\tconnection.setRequestProperty(\"Accept\", \"application/json\");\n\t\tconnection.connect();\n\t\tInputStream response = connection.getInputStream();\n\t\tBufferedReader reader = new BufferedReader(new InputStreamReader(response));\n\t\tString line;\n\t\tStringBuilder sb = new StringBuilder();\n\t\twhile ((line = reader.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\treader.close();\n\t\tresponse.close();\n\t\tString json = sb.toString();\n\t\tJSONArray servers = (JSONArray) JSONValue.parseWithException(json);\n\t\tList<TutuServer> serverList = new ArrayList<TutuServer>();\n\t\tfor (Object server : servers) {\n\t\t\tJSONObject serverObj = (JSONObject) server;\n\t\t\tString ip = (String) serverObj.get(\"ip\");\n\t\t\tint port = ((Long) serverObj.get(\"port\")).intValue();\n\t\t\tserverList.add(new TutuServer(ip, port));\n\t\t}\n\t\treturn serverList;\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn null;\n}", "CodeBleu_score": 32.095659509796135}, {"code": "private List<TutuServer> getServer(){\n\t\t// Construct the request parameters\n\tMap<String, String> params = new HashMap<String, String>();\n\tparams.put(\"serviceName\", serviceName);\n\t// Send the request to the discovery service\n\tString response = get(serverAddr + \"/list\", params);\n\t// Parse the JSON response\n\treturn parseArray(response, new TutuServer());\n}", "CodeBleu_score": 18.823770915451338}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.routes.values()) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = path.substring(path.indexOf(route.getPath()) + route.getPath().length());\n\t\t\tif (targetPath.startsWith(\"/\")) {\n\t\t\t\ttargetPath = targetPath.substring(1);\n\t\t\t}\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 43.12519810373137}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.routes.values()) {\n\t\tif (route.matches(path)) {\n\t\t\tString targetPath = route.getTargetPath();\n\t\t\tString serviceId = route.getServiceId();\n\t\t\tif (targetPath == null) {\n\t\t\t\ttargetPath = \"\";\n\t\t\t}\n\t\t\treturn new Route(path.substring(targetPath.length()), serviceId);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.6370415876929}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (Route route : routes.values()) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = route.getPath();\n\t\t\tif (targetPath.startsWith(\"**\")) {\n\t\t\t\ttargetPath = targetPath.substring(2);\n\t\t\t}\n\t\t\telse if (targetPath.startsWith(\"*\")) {\n\t\t\t\ttargetPath = targetPath.substring(1);\n\t\t\t}\n\t\t\telse if (targetPath.endsWith(\"**\")) {\n\t\t\t\ttargetPath = targetPath.substring(0, targetPath.length() - 2);\n\t\t\t}\n\t\t\telse if (targetPath.endsWith(\"*\")) {\n\t\t\t\ttargetPath = targetPath.substring(0, targetPath.length() - 1);\n\t\t\t}\n\t\t\telse {\n\t\t\t\ttargetPath = \"\";\n\t\t\t}\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 40.015617908182186}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(FeignClientsConfiguration.class.getName());\n\tif (attributes == null) {\n\t\treturn;\n\t}\n\tList<String> basePackages = new ArrayList<>();\n\tbasePackages.addAll((List<String>) attributes.get(\"basePackages\"));\n\tbasePackages.addAll((List<String>) attributes.get(\"value\"));\n\tbasePackages.addAll((List<String>) attributes.get(\"basePackageClasses\"));\n\tif (basePackages.isEmpty()) {\n\t\tbasePackages.add(ClassUtils.getPackageName(importingClassMetadata.getClassName()));\n\t}\n\tregisterBeanDefinitions(importingClassMetadata, registry, basePackages);\n}", "CodeBleu_score": 23.559475418140774}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// Get the package of the importing class\n\tString packageName = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n\t// Scan for classes with the FeignClient annotation\n\tSet<BeanDefinition> beanDefinitions = scanPackageByAnnotation(packageName, FeignClient.class);\n\t// For each annotated class, create a GenericBeanDefinition\n\tfor (BeanDefinition beanDefinition : beanDefinitions) {\n\t\t// Set the bean class to the annotated class\n\t\tbeanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\t// Set the bean class to the annotated class\n\t\tbeanDefinition.getPropertyValues().addPropertyValue(\"type\", beanDefinition.getBeanClassName());\n\t\t// Set the contextId property to the package name\n\t\tbeanDefinition.getPropertyValues().addPropertyValue(\"contextId\", packageName);\n\t\t// Register the bean definition with the BeanDefinitionRegistry using the class name as the bean name\n\t\tregistry.registerBeanDefinition(beanDefinition.getBeanClassName(), beanDefinition);\n\t}\n}", "CodeBleu_score": 36.58639931602868}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tAssert.notNull(importingClassMetadata, \"importingClassMetadata must not be null\");\n\tAssert.notNull(registry, \"registry must not be null\");\n\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(FeignClient.class.getName());\n\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false, this.environment);\n\tscanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n\tSet<BeanDefinition> candidates = new LinkedHashSet<>();\n\tString basePackage = attributes.get(\"basePackage\").toString();\n\tfor (BeanDefinition candidate : scanner.findCandidateComponents(basePackage)) {\n\t\tcandidates.add(candidate);\n\t}\n\tfor (BeanDefinition candidate : candidates) {\n\t\tString beanName = candidate.getBeanClassName();\n\t\tBeanDefinitionBuilder definitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class);\n\t\tdefinitionBuilder.addPropertyValue(\"type\", beanName);\n\t\tdefinitionBuilder.addPropertyValue(\"contextId\", beanName);\n\t\tdefinitionBuilder.addPropertyValue(\"url\", attributes.get(\"url\"));\n\t\tregistry.registerBeanDefinition(beanName, definitionBuilder.getBeanDefinition());\n\t}\n}", "CodeBleu_score": 36.55496544728787}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\tTutuDiscoveryClient tutuDiscoveryClient = new TutuDiscoveryClient(tutuDiscoveryProperties);\n\treturn tutuDiscoveryClient;\n}", "CodeBleu_score": 41.37821029346896}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
