{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect.return_value\n", "CodeBleu_score": 46.0677560104099}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    start = time.time()\n    self._orig_kazoo_connect(*args)\n    return (max(2, self.loop_wait - 2) * 1000, self._orig_kazoo_connect.return_value[1])\n", "CodeBleu_score": 46.21759295061961}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n", "CodeBleu_score": 50.2273244970304}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    self._config = config\n    self._client.set_retry_timeout(self._config.retry_timeout)\n    self._client.set_loop_wait_time(self._config.loop_wait)\n    if self._client.handler.__class__ == PatroniSequentialThreadingHandler:\n        self._client.set_connect_timeout(self._config.connect_timeout)\n    if self._client.set_ttl(self._config.ttl) and self._config.loop_wait!= self._client.handler.loop_wait_time:\n        self._client.close()\n\n", "CodeBleu_score": 40.96547421141749}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n\n    if config.retry_timeout is not None:\n        self.set_retry_timeout(config.retry_timeout)\n    if config.loop_wait is not None:\n        self.set_loop_wait(config.loop_wait)\n    if config.ttl is not None:\n        if self.set_ttl(config.ttl) and isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n    if config.ttl is None and self.set_ttl(self._client._session_timeout / 1000):\n        self.close()\n\n", "CodeBleu_score": 41.604288683829736}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_ttl(config.ttl)\n    if self.loop_wait!= config.loop_wait:\n        self.loop_wait = config.loop_wait\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n    if self.set_ttl(config.ttl) and self.loop_wait!= config.loop_wait:\n        self.close()\n\n", "CodeBleu_score": 43.11292796702465}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n    cluster.initialization = self.get_node(path + self._INITIALIZATION)\n    cluster.configuration = self.get_node(path + self._CONFIGURATION)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.sync_state = self.get_node(path + self._SYNC_STATE)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n", "CodeBleu_score": 13.488502783052231}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Check if the cluster has been initialized\n    init_node = self.get_node(path + self._INITIALIZED)\n    if not init_node:\n        raise ClusterNotInitializedError(f\"Cluster {path} has not been initialized.\")\n\n    # Check if the cluster has been configured\n    config_node = self.get_node(path + self._CONFIG)\n    if not config_node:\n        raise ClusterNotConfiguredError(f\"Cluster {path} has not been configured.\")\n\n    # Load the configuration\n    config = ClusterConfig.from_node(config_node[0])\n\n    # Load the timeline history\n    timeline_history = TimelineHistory.from_node(self.get_node(path + self._TIMELINE_HISTORY))\n\n    # Load the synchronization state\n    sync_state = SyncState.from_node(self.get_node(path + self._SYNC_STATE))\n\n    # Load the members\n    members = self.load_members(path)\n\n    # Load the leader information\n    leader_node = self.get_node(path + self._LEADER)\n    if leader_node:\n        leader = Leader.from_node(leader_node[0])\n    else:\n        leader = None\n\n    # Load the cluster status\n    status = self.get_status(path, leader)\n\n    # Load the failover state\n    failover_node = self.get_node(path + self._FAILOVER)\n    if failover_node:\n        failover = Failover.from_node(failover_node[0])\n    else:\n        failover = None\n\n    # Load the failsafe configuration\n    failsafe_node = self.get_node(path + self._FAILSAFE)\n    if failsafe_node:\n        failsafe = json.loads(failsafe_node[0])\n    else:\n        failsafe = None\n\n    # Create the cluster object\n    cluster = Cluster(\n        path,\n        config,\n        timeline_history,\n        sync_state,\n        members,\n        leader,\n        status,\n        failover,\n        failsafe,\n    )\n\n    return cluster\n", "CodeBleu_score": 34.13422829949588}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n    cluster.initialized = self.get_node(path + self._INITIALIZED)\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.sync_state = self.get_node(path + self._SYNC_STATE)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n", "CodeBleu_score": 13.25036774128225}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(\n            path=self.leader_path,\n            value=self.node_id.encode(),\n            ephemeral=True,\n            sequence=True,\n        )\n        return True\n    except ZooKeeperError as e:\n        if e.code == KeeperException.ConnectionLoss:\n            logger.error(\n                f\"Connection to ZooKeeper lost while attempting to acquire leader lock: {e}\"\n            )\n            raise e\n        elif e.code == KeeperException.OperationTimeout:\n            logger.error(\n                f\"Timeout while attempting to acquire leader lock: {e}\"\n            )\n            raise e\n        elif e.code == KeeperException.NodeExists:\n            logger.info(\n                f\"Another instance has the leader lock: {e}\"\n            )\n            return False\n        else:\n            logger.error(\n                f\"Unexpected error while attempting to acquire leader lock: {e}\"\n            )\n            raise e\n    except Exception as e:\n        if isinstance(e, NodeExistsError):\n            logger.info(\n                f\"Another instance has the leader lock: {e}\"\n            )\n            return False\n        else:\n            logger.error(\n                f\"Unexpected error while attempting to acquire leader lock: {e}\"\n            )\n            raise e\n\n", "CodeBleu_score": 38.847895265881995}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, ephemeral=True, sequence=True)\n        return True\n    except ZooKeeperError as e:\n        if e.code == KeeperException.CONNECTION_LOSS:\n            logger.error(\"Connection to ZooKeeper lost while attempting to acquire leader lock.\")\n            raise\n        elif e.code == KeeperException.SESSION_EXPIRED:\n            logger.error(\"Session expired while attempting to acquire leader lock.\")\n            raise\n        elif e.code == KeeperException.NODE_EXISTS:\n            logger.info(\"Another instance has the leader lock.\")\n            return False\n        else:\n            logger.error(f\"Unexpected ZooKeeper error while attempting to acquire leader lock: {e}\")\n            raise\n    except Exception as e:\n        if isinstance(e, NodeExistsError):\n            logger.info(\"Another instance has the leader lock.\")\n            return False\n        else:\n            logger.error(f\"Unexpected error while attempting to acquire leader lock: {e}\")\n            raise\n\n", "CodeBleu_score": 41.45108692320333}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    # Attempt to acquire a leader lock by creating an ephemeral node in ZooKeeper at a specified path.\n    # This function uses a retry mechanism to handle transient issues.\n    # If successful, it returns True.\n    # If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError.\n    # For other exceptions, it logs an error unless the exception is a NodeExistsError,\n    # indicating another instance has the lock.\n    # If the lock cannot be acquired, it logs an info message and returns False.\n    #\n    # The retry mechanism is implemented using the retry library.\n    # It retries a maximum of 10 times with a delay of 1 second between each attempt.\n    # The retry decorator is applied to the function to handle the exceptions.\n    # If the function raises a ZooKeeperError, it is raised immediately.\n    # Otherwise, it logs the exception and retries the function.\n    # If the function succeeds, it returns True.\n    # If the function fails after the maximum number of retries, it returns False.\n    #\n    # The function uses the logger.error and logger.info functions to log messages.\n    # If the function raises a ZooKeeperError, it logs an error message.\n    # If the function fails after the maximum number of retries, it logs an info message.\n    #\n    # The function uses the isinstance function to check if the exception is a NodeExistsError.\n    # If it is, it indicates another instance has the lock.\n    # Otherwise, it logs an error message and returns False.\n    #\n    # The function uses the logger.error and logger.info functions to log messages.\n    # If the function raises a ZooKeeperError, it logs an error message.\n    # If the function fails after the maximum number of retries, it logs an info message.\n    #\n    # The function uses the isinstance function to check if the exception is a NodeExistsError.\n    # If it is, it indicates another instance has the lock.\n    # Otherwise, it logs an error message and returns False.\n    @retry(stop_max_attempt_number=10, wait_fixed=1000)\n    def _attempt_to_acquire_leader():\n        try:\n            self._zk.create(\n                self._leader_path,\n                ephemeral=True,\n                sequence=True,\n                makepath=True,\n            )\n            return True\n        except ZooKeeper", "CodeBleu_score": 22.529788453684297}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id!= leader.session:\n        logger.warning(\n            \"Client ID mismatch, current: %s, leader: %s\",\n            self._client_id,\n            leader.session,\n        )\n        try:\n            self._zk.delete(self._leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        except Exception as e:\n            logger.error(\n                \"Failed to delete leader ZNode: %s\",\n                e,\n                exc_info=True,\n            )\n            return False\n    try:\n        self._zk.create(\n            self._leader_path,\n            self._client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            makepath=True,\n        )\n    except NodeExistsError:\n        pass\n    except ConnectionClosedError:\n        pass\n    except Exception as e:\n        logger.error(\n            \"Failed to create leader ZNode: %s\",\n            e,\n            exc_info=True,\n        )\n        return False\n    return True\n", "CodeBleu_score": 47.718375974794085}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id!= leader.session:\n        logger.warning(\"Client ID mismatch, deleting old leader\")\n        try:\n            self._zk.delete(self._leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError as e:\n            if e.errors[0].errno!= zookeeper.ZNONODE:\n                raise ZooKeeperError(e)\n        else:\n            try:\n                self._zk.create(self._leader_path, leader.name.encode(\"utf-8\"), ephemeral=True)\n            except ConnectionClosedError:\n                pass\n            except RetryFailedError as e:\n                if e.errors[0].errno!= zookeeper.ZNODEEXISTS:\n                    logger.error(\"Failed to create leader node: %s\", e)\n                    return False\n            else:\n                return True\n    return False", "CodeBleu_score": 49.79574686539058}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id!= leader.session:\n        logger.warning(\n            \"Leader session ID %s does not match current client ID %s\",\n            leader.session,\n            self._client_id,\n        )\n        try:\n            self._zk.delete(self._leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError as e:\n            if e.errors[0].code == KeeperException.CONNECTIONLOSS:\n                pass\n            else:\n                raise\n        else:\n            return False\n\n    try:\n        self._zk.create(\n            self._leader_path,\n            self._client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            sequence=True,\n        )\n    except NodeExistsError:\n        pass\n    except ConnectionClosedError:\n        pass\n    except Exception as e:\n        logger.error(\"Error updating leader: %s\", e)\n        return False\n    else:\n        return True\n\n", "CodeBleu_score": 42.6667007735448}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll < self._poll_interval:\n        return False\n    self._last_poll = time.time()\n    data = self._query_exhibitors(self._exhibitors)\n    if not data:\n        return False\n    if self._data_changed(data):\n        self._data = data\n        self._update_connection_string()\n        return True\n    return False", "CodeBleu_score": 22.70824338315093}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll > self._poll_interval:\n        self._last_poll = time.time()\n        data = self._query_exhibitors(self._exhibitors)\n        if data:\n            if'servers' in data:\n                # Sort servers for stable connection string\n                servers = sorted(data['servers'])\n                # Update connection string if it has changed\n                if self._servers!= servers:\n                    self._servers = servers\n                    self._connection_string = ','.join(servers)\n                    logging.info('Updated ZooKeeper connection string: %s', self._connection_string)\n                    return True\n            else:\n                logging.warning('Invalid data received from Exhibitor: %s', data)\n        else:\n            logging.warning('Failed to query Exhibitor')\n    return False", "CodeBleu_score": 37.94578133846812}, {"code": "def poll(self) -> bool\n\t\n    if time.time() > self._last_poll + self.POLL_INTERVAL:\n        self._last_poll = time.time()\n        exhibitors = self._query_exhibitors(self._exhibitors)\n        if isinstance(exhibitors, dict):\n            servers = []\n            for instance in exhibitors['instances']:\n                if instance['status'] == 'ALIVE':\n                    servers.append(instance['hostname'] + ':' + str(instance['port']))\n            servers = sorted(servers)\n            if servers!= self._servers:\n                logging.info('ZooKeeper connection string changed from %s to %s', self._servers, servers)\n                self._servers = servers\n                return True\n    return False", "CodeBleu_score": 38.86126794372256}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener!= null) {\n\t\tString group = getGroup();\n\t\tString dataId = getDataId();\n\t\tlogUnsubscribeStarted(group, dataId);\n\t\ttry {\n\t\t\tzookeeperListener.unsubscribe(group, dataId);\n\t\t} catch (Exception e) {\n\t\t\tlogUnsubscribeFailed(group, dataId, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 64.57919846577529}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 38.497174905089544}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 38.65338413283172}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zkServer = (ZookeeperServer) server;\n\t\treturn zkServer.getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 56.256399787247105}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\n// create a NodeCache for the given path\nNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\n// start the NodeCache\nnodeCache.start();\n\n// define a NodeCacheListener to handle node changes\nNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n    @Override\n    public void nodeChanged() throws Exception {\n        // convert the config and invoke the callback\n        String config = convertConfig(nodeCache.getCurrentData().getData());\n        zookeeperSubscribeCallback.onConfigChanged(config);\n    }\n};\n\n// create a ZookeeperListener with the NodeCache and NodeCacheListener\nZookeeperListener zookeeperListener = new ZookeeperListener();\nzookeeperListener.setNodeCache(nodeCache);\nzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\n// add the listener to the ZookeeperListener\nzookeeperListener.addListener(zookeeperListener);\n\n// return the ZookeeperListener instance\nreturn zookeeperListener;\n}", "CodeBleu_score": 67.1172704738785}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\nString path = \"/\" + group + \"/\" + serviceId;\n\nNodeCache nodeCache = new NodeCache(curatorFramework, path);\nnodeCache.start(true);\n\nNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n    public void nodeChanged() throws Exception {\n        String config = convertConfig(path);\n        zookeeperSubscribeCallback.onConfigChanged(config);\n    }\n};\n\nnodeCache.getListenable().addListener(nodeCacheListener);\n\nZookeeperListener zookeeperListener = new ZookeeperListener();\nzookeeperListener.setNodeCache(nodeCache);\nzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\nzookeeperListenerList.add(zookeeperListener);\n\nreturn zookeeperListener;\n}", "CodeBleu_score": 67.89541143904975}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getServicePath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start(true);\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tzookeeperSubscribeCallback.onConfigChange(convertConfig(path));\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tZookeeperListener zookeeperListener = new ZookeeperListener();\n\tzookeeperListener.setNodeCache(nodeCache);\n\tzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\tzookeeperListeners.add(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 69.2365736234131}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverListDecorator = new ZookeeperServerListDecorator(serviceDiscovery, config);\n\tserverListDecorator.setLoadBalanceListenerExecutor(config.getLoadBalanceExecutor());\n\tserverListDecorator.setServiceId(config.getClientName());\n\treturn serverListDecorator;\n}", "CodeBleu_score": 47.99503126389653}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config);\n\tserverList.setClientConfig(config);\n\tserverList.setLoadBalanceListenerExecutor(config.getLoadBalanceExecutor());\n\tserverList.setServiceId(config.getClientName());\n\treturn serverList;\n}", "CodeBleu_score": 68.09113158949036}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList zsl = new ZookeeperServerList(config, serviceDiscovery);\n\tzsl.setClientName(config.getClientName());\n\tzsl.setLoadBalanceListenerExecutor(config.getLoadBalanceListenerExecutor());\n\tzsl.setServiceId(config.getClientName());\n\treturn zsl;\n}", "CodeBleu_score": 51.32815438015719}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.79794007709059}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.79794007709059}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.79794007709059}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalGroup : localGroup\n\tString dataId = globalConfig? globalDataId : localDataId\n\tlog.info(\"Subscribing to configuration: $group/$dataId\")\n\tZookeeperListener listener = zookeeperOperation.subscribe(group, dataId, {\n\t\tlog.info(\"Configuration updated: $group/$dataId\")\n\t})\n\tif (listener == null) {\n\t\tlog.error(\"Failed to subscribe to configuration: $group/$dataId\")\n\t}\n\treturn listener\n}", "CodeBleu_score": 18.309718045813362}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalGroup : localGroup\n\tString dataId = globalConfig? globalDataId : localDataId\n\tlog.info \"Subscribing to configuration: group: $group, dataId: $dataId\"\n\ttry {\n\t\tZookeeperListener listener = zookeeperOperation.subscribe(group, dataId, new ZookeeperListener() {\n\t\t\tvoid onEvent(Event event) {\n\t\t\t\tif (event.getType() == Event.EventType.NODE_DATA_CHANGED) {\n\t\t\t\t\tlog.info \"Configuration changed: group: $group, dataId: $dataId\"\n\t\t\t\t\ttry {\n\t\t\t\t\t\tString config = zookeeperOperation.get(group, dataId)\n\t\t\t\t\t\tlog.info \"Configuration retrieved: group: $group, dataId: $dataId, config: $config\"\n\t\t\t\t\t\tupdateConfig(config)\n\t\t\t\t\t} catch (Exception e) {\n\t\t\t\t\t\tlog.error \"Failed to retrieve configuration: group: $group, dataId: $dataId\", e\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t})\n\t\treturn listener\n\t} catch (Exception e) {\n\t\tlog.error \"Failed to subscribe to configuration: group: $group, dataId: $dataId\", e\n\t}\n\treturn null\n}", "CodeBleu_score": 25.79787428604117}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? GLOBAL_GROUP : this.group\n\tString dataId = globalConfig? GLOBAL_DATA_ID : this.dataId\n\tlog.info(\"subscribeConfig: group = $group, dataId = $dataId\")\n\ttry {\n\t\tZookeeperListener listener = zookeeperOperation.subscribe(group, dataId, {\n\t\t\tif (it!= null) {\n\t\t\t\tlog.info(\"subscribeConfig: config updated, config = $it\")\n\t\t\t\tif (globalConfig) {\n\t\t\t\t\tglobalConfig = it\n\t\t\t\t} else {\n\t\t\t\t\tconfig = it\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.warn(\"subscribeConfig: config is null\")\n\t\t\t}\n\t\t})\n\t\tlog.info(\"subscribeConfig: subscription succeeded\")\n\t\treturn listener\n\t} catch (Exception e) {\n\t\tlog.error(\"subscribeConfig: subscription failed, e = $e.message\", e)\n\t\treturn null\n\t}\n}", "CodeBleu_score": 32.498278642968245}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = environment.getProperty(CONNECT_STRING_KEY);\n\tif (connectString == null || connectString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string not found.\");\n\t}\n\n\tint retryCount = environment.getProperty(RETRY_COUNT_KEY, Integer.class, DEFAULT_RETRY_COUNT);\n\tint sleepTime = environment.getProperty(SLEEP_TIME_KEY, Integer.class, DEFAULT_SLEEP_TIME);\n\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 47.6984309635285}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = environment.getProperty(\"zookeeper.connectString\");\n\tif (StringUtils.isEmpty(connectString)) {\n\t\tthrow new DiscoveryException(\"zookeeper.connectString is empty\");\n\t}\n\tint retryCount = environment.getProperty(\"zookeeper.retryCount\", Integer.class, 3);\n\tint retrySleepTime = environment.getProperty(\"zookeeper.retrySleepTime\", Integer.class, 1000);\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectString, retryPolicy);\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 42.42114128799109}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectString = environment.getProperty(CONNECT_STRING_PROPERTY);\n\tif (StringUtils.isEmpty(connectString)) {\n\t\tthrow new DiscoveryException(\"No Zookeeper connection string provided\");\n\t}\n\tint retryCount = environment.getProperty(RETRY_COUNT_PROPERTY, Integer.class, 3);\n\tint sleepMsBetweenRetries = environment.getProperty(SLEEP_MS_BETWEEN_RETRIES_PROPERTY, Integer.class, 1000);\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepMsBetweenRetries, retryCount);\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.retryPolicy(retryPolicy);\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 49.6399867956289}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t", "CodeBleu_score": 1.394537427031336}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * Bean method for creating a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 64.91734404115697}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnMissingBean(GatewayStrategyRouteZookeeperProcessor.class)\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(\n\t\t\tGatewayStrategyRouteZookeeperProcessorProperties gatewayStrategyRouteZookeeperProcessorProperties,\n\t\t\tGatewayStrategyRouteZookeeperProcessorContext gatewayStrategyRouteZookeeperProcessorContext) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(gatewayStrategyRouteZookeeperProcessorProperties,\n\t\t\t\tgatewayStrategyRouteZookeeperProcessorContext);\n\t}\n}", "CodeBleu_score": 21.623959854599995}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.sessionTimeoutMs(sessionTimeoutMs)\n\t\t\t.namespace(getNamespace())\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 39.931184369084875}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectString)\n\t\t\t.sessionTimeoutMs(sessionTimeoutMs)\n\t\t\t.namespace(namespace)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 38.543199039754306}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder()\n\t\t.connectString(connectString)\n\t\t.sessionTimeoutMs(sessionTimeoutMs)\n\t\t.namespace(namespace)\n\t\t.retryPolicy(retryPolicy);\n\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 40.324652597142865}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (locksMap.containsKey(path)) {\n\t\ttry {\n\t\t\tlocksMap.get(path).acquire();\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(e);\n\t\t}\n\t} else {\n\t\tInterProcessMutex lock = new InterProcessMutex(zkClient, path);\n\t\ttry {\n\t\t\tlock.acquire();\n\t\t\tlocksMap.put(path, lock);\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 27.859673360414643}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = locksMap.get(path);\nif (lock == null) {\nlock = new InterProcessMutex(zkClient, path);\nlocksMap.put(path, lock);\n}\ntry {\nlock.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n}\n}", "CodeBleu_score": 24.802498151160652}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex lock = locksMap.get(path);\n\tif (lock == null) {\n\t\tlock = new InterProcessMutex(client, path);\n\t\tlocksMap.put(path, lock);\n\t}\n\ttry {\n\t\tif (!lock.acquire(lockTimeout, TimeUnit.MILLISECONDS)) {\n\t\t\tthrow new DistributedLockException(\"Unable to acquire lock for path: \" + path);\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Unable to acquire lock for path: \" + path, e);\n\t}\n}", "CodeBleu_score": 22.285365754653757}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\t// Initialize a CuratorFramework instance\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\t// Determine the node path\n\tString nodePath = nodePath(dtpProperties);\n\t// If the configuration type is PROPERTIES, generate the map using genPropertiesTypeMap\n\tif (dtpProperties.getConfigType() == ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t}\n\t// If the configuration type is JSON, construct the node path with a config key, retrieve the value, and parse it into a map using ConfigHandler\n\tString configKey = dtpProperties.getConfigKey();\n\tString value = getVal(ZKPaths.makePath(nodePath, configKey), curatorFramework);\n\treturn ConfigHandler.getInstance().parseConfig(value);\n}", "CodeBleu_score": 40.00543839646908}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tif (dtpProperties.getConfigType() == DtpProperties.ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType() == DtpProperties.ConfigType.JSON) {\n\t\tString configKey = dtpProperties.getConfigKey();\n\t\tString path = ZKPaths.makePath(nodePath, configKey);\n\t\tString value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parseConfig(value);\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 46.28807227085535}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tif (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.PROPERTIES)) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.JSON)) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString path = ZKPaths.makePath(nodePath, configKey);\n\t\tString value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parseConfig(value);\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 45.17840615305494}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment);\n\tMap<Object, Object> properties = genPropertiesMap(dtpProperties);\n\tif (!checkPropertyExist(environment)) {\n\t\tcreateZkPropertySource(environment, properties);\n\t}\n}", "CodeBleu_score": 56.336298276989936}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\t// Bind DtpProperties to the environment\n\tDtpProperties dtpProperties = new DtpProperties();\n\tBinder binder = Binder.get(environment);\n\tbinder.bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n\t// Generate a properties map from DtpProperties\n\tMap<Object, Object> properties = genPropertiesMap(dtpProperties);\n\t// Check if the required property exists in the environment\n\tif (!checkPropertyExist(environment)) {\n\t\t// Create a Zookeeper property source with the generated properties\n\t\tcreateZkPropertySource(environment, properties);\n\t}\n}", "CodeBleu_score": 66.28126624555237}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = bindDtpProperties(environment);\n\tMap<Object, Object> properties = genPropertiesMap(dtpProperties);\n\tif (!checkPropertyExist(environment)) {\n\t\tcreateZkPropertySource(environment, properties);\n\t}\n}", "CodeBleu_score": 56.336298276989936}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n\tbuilder.UseRouteManager(provider => new ZooKeeperServiceRouteManager(\n\t\tprovider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>(),\n\t\tprovider.GetRequiredService<ISerializer<byte[]>>(),\n\t\tprovider.GetRequiredService<IServiceRouteFactory>(),\n\t\tprovider.GetRequiredService<ISerializer<string>>(),\n\t\tprovider.GetRequiredService<IZookeeperClientProvider>(),\n\t\tconfig));\n\treturn this;\n}", "CodeBleu_score": 61.70728554977193}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n\tbuilder.RegisterAdapter(provider => new ZooKeeperServiceRouteManager(\n\t\tprovider.GetRequiredService<ISerializer<byte[]>>(),\n\t\tprovider.GetRequiredService<ISerializer<string>>(),\n\t\tprovider.GetRequiredService<IServiceRouteFactory>(),\n\t\tprovider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>(),\n\t\tprovider.GetRequiredService<IZookeeperClientProvider>(),\n\t\tconfigInfo)).InstancePerLifetimeScope();\n\treturn this;\n}", "CodeBleu_score": 71.91938779451861}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n\nbuilder.UseRouteManager(provider => new ZookeeperServiceRouteManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<IServiceRouteFactory>(), provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo));\n\nbuilder.RegisterAdapter(provider => new ZookeeperClientProvider(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), configInfo));\n\nbuilder.RegisterAdapter(provider => new ZookeeperServiceRouteFactory(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), configInfo));\n\nbuilder.RegisterAdapter(provider => new ZookeeperSerializer());\n\nbuilder.RegisterAdapter(provider => new ZookeeperSerializer());\n\nreturn this;\n}", "CodeBleu_score": 54.192045224801454}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tisterAdapter(provider => new ZookeeperServiceCommandManager(\nprovider.GetRequiredService<ISerializer<byte[]>>(),\nprovider.GetRequiredService<ISerializer<string>>(),\nprovider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\nprovider.GetRequiredService<IServiceRouteManager>(),\nprovider.GetRequiredService<IZookeeperClientProvider>(),\nconfigInfo\n)).InstancePerLifetimeScope();\n\nreturn this;\n}", "CodeBleu_score": 55.075964143910824}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n\tbuilder.RegisterAdapter(provider => new ZookeeperServiceCommandManager(\n\t\tprovider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\n\t\tprovider.GetRequiredService<ISerializer<byte[]>>(),\n\t\tprovider.GetRequiredService<ISerializer<string>>(),\n\t\tprovider.GetRequiredService<IServiceEntryManager>(),\n\t\tprovider.GetRequiredService<IServiceRouteManager>(),\n\t\tprovider.GetRequiredService<IZookeeperClientProvider>(),\n\t\tconfigInfo\n\t)).SingleInstance();\n\treturn this;\n}", "CodeBleu_score": 59.69164922259833}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n\tbuilder.UseCommandManager(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceEntryManager>(), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo));\n\treturn this;\n}", "CodeBleu_score": 60.148291603157375}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.NotNull(path, nameof(path));\n\tif (!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException($\"The path '{path}' is not rooted.\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tbuilder.Add(source);\n\treturn builder.Build();\n}", "CodeBleu_score": 59.36299052173716}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(nameof(path));\n\t}\n\tif (provider == null) {\n\t\tif (!Path.IsPathRooted(path)) {\n\t\t\tthrow new ArgumentException(nameof(path));\n\t\t}\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 55.88935392608748}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.NotNull(path, nameof(path));\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"Path cannot be empty\", nameof(path));\n\t}\n\tif (!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\"Path must be rooted\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource() {\n\t\tFileProvider = provider,\n\t\tPath = Path.GetFileName(path),\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tbuilder.Add(source);\n\treturn builder.Build();\n}", "CodeBleu_score": 59.48438661360614}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tvar routes = await GetRoutesAsync();\n\tvar newRoutes = routes.Select(r => new ServiceRoute(r) { Address = r.Address.Except(Address) });\n\tawait SetRoutesAsync(newRoutes);\n}", "CodeBleu_score": 39.06836992592078}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tif (Address!= null) {\n\t\tvar routes = _routes.ToList();\n\t\tforeach (var route in routes) {\n\t\t\troute.Address.Except(Address);\n\t\t}\n\t\tawait SetRoutesAsync(routes);\n\t}\n}", "CodeBleu_score": 45.70009628320429}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tvar routes = _routes.ToList();\n\tforeach (var route in routes) {\n\t\tvar addresses = route.Address.Except(Address);\n\t\troute.Address = addresses.ToList();\n\t}\n\tawait base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 57.56817310046544}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\t// Construct route path\n\tvar path = $\"/{_routePath}/{hostAddr.Host}:{hostAddr.Port}\";\n\t// Get current Zookeeper clients\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\t// Compare existing routes with new routes and identify routes to be deleted\n\t\tvar deletedRouteIds = _routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.ServiceDescriptor.Id).ToArray();\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar oldRouteIds = _routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deleteRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deleteRouteId in deleteRouteIds) {\n\t\t\t// If the addresses of the routes to be deleted contain the specified hostAddr, delete the corresponding node from Zookeeper\n\t\t\tvar addresses = _routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n\t\t\tif (addresses.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(path + $\"/{deleteRouteId}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 54.13214054371998}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\t// The route path in Zookeeper is \"/routes/{serviceName}\".\n\tvar routePath = \"/routes\";\n\t// Get the current Zookeeper clients.\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\t// For each Zookeeper client, remove the routes that are not in the routes parameter.\n\tforeach (var zooKeeper in zooKeepers) {\n\t\t// Get the current routes in Zookeeper.\n\t\tvar currentRoutes = await GetRoutesAsync(zooKeeper.Item2);\n\t\t// Get the routes to be deleted.\n\t\tvar routesToBeDeleted = currentRoutes.Except(routes).ToArray();\n\t\t// For each route to be deleted, check if the address contains the specified hostAddr.\n\t\tforeach (var route in routesToBeDeleted) {\n\t\t\tif (route.Address.Contains(hostAddr)) {\n\t\t\t\t// Delete the corresponding node from Zookeeper.\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath + \"/\" + route.ServiceDescriptor.Id);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 28.929087271207578}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar path = GetRoutePath(hostAddr);\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar oldRouteIds = await zooKeeper.Item2.getChildrenAsync(path);\n\t\tvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\tvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n\t\tforeach (var deletedRouteId in deletedRouteIds) {\n\t\t\tvar address = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\n\t\t\tif (address.Contains(hostAddr.Host)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(path + \"/\" + deletedRouteId);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.49259484584554}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t_logger.LogDebug\n) {\n            if (data == null)\n            {\n                return null;\n            }\n\n            var descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n            return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n        }\n_logger.LogDebug\n)}", "CodeBleu_score": 55.47750881636567}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug(\n$\"Deserializing service route from byte array of length {data.Length}.\");\n}\n\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 50.3558595305412}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\n_logger.LogDebug(\"The GetRoute function asynchronously retrieves a ServiceRoute from the provided byte array data.\nIf logging at the Debug level is enabled, it logs the route data.\nIf the data is null, it returns null.\nIt deserializes the byte array into a ServiceRouteDescriptor and uses a service route factory to create and return the first ServiceRoute.\");\n\nif (data == null) {\n\n_logger.LogDebug(\"The GetRoute function asynchronously retrieves a ServiceRoute from the provided byte array data.\nIf logging at the Debug level is enabled, it logs the route data.\nIf the data is null, it returns null.\nIt deserializes the byte array into a ServiceRouteDescriptor and uses a service route factory to create and return the first ServiceRoute.\");\n\nreturn null;\n\n}\n\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n\n_logger.LogDebug(\"The GetRoute function asynchronously retrieves a ServiceRoute from the provided byte array data.\nIf logging at the Debug level is enabled, it logs the route data.\nIf the data is null, it returns null.\nIt deserializes the byte array into a ServiceRouteDescriptor and uses a service route factory to create and return the first ServiceRoute.\");\n\nreturn (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n\n}", "CodeBleu_score": 40.81283681309131}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\ttaEquals(oldData, newData)) {\n\t\treturn;\n\t}\n\tvar newRoute = await GetRoute(newData);\n\tvar oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\tlock (_lock) {\n\t\t_routes = _routes.Where(i => i.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id)\n\t\t\t.Concat(new[] { newRoute }).ToArray();\n\t}\n\tOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 67.66175404746782}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\taEquals(oldData, newData))\n                return;\n\n            var newRoute = await GetRoute(newData);\n            if (newRoute == null)\n                return;\n\n            var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n            if (oldRoute == null)\n                return;\n\n            lock (_routes)\n            {\n                _routes = _routes.Where(i => i.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id)\n                       .Concat(new[] { newRoute }).ToArray();\n            }\n\n            //\u89e6\u53d1\u8def\u7531\u53d8\u66f4\u4e8b\u4ef6\u3002\n            OnChanged?.Invoke(newRoute, oldRoute);\n        }", "CodeBleu_score": 77.98745512431815}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\taEquals(oldData, newData)) {\nreturn;\n}\n\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\n\nlock (_routes) {\n_routes = _routes.Where(i => i.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id)\n.Concat(new[] { newRoute }).ToArray();\n}\n\nOnChanged(new RouteChangedEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 62.48888466743987}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar serviceSubscribers = await GetSubscribersAsync();\n\tforeach (var subscriber in subscribers) {\n\t\tvar serviceSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (serviceSubscriber!= null) {\n\t\t\tserviceSubscriber.Address = subscriber.Address.Concat(serviceSubscriber.Address).Distinct().ToArray();\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 66.44779613323608}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t//\u83b7\u53d6\u73b0\u6709\u7684\u8ba2\u9605\u8005\n\tvar serviceSubscribers = await GetSubscribersAsync();\n\t//\u904d\u5386\u8ba2\u9605\u8005\n\tforeach (var subscriber in subscribers) {\n\t\t//\u83b7\u53d6\u73b0\u6709\u7684\u8ba2\u9605\u8005\n\t\tvar serviceSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\t//\u5982\u679c\u4e0d\u5b58\u5728\uff0c\u5219\u76f4\u63a5\u6dfb\u52a0\n\t\tif (serviceSubscriber == null) {\n\t\t\tserviceSubscribers = serviceSubscribers.Concat(new ServiceSubscriber[] { subscriber }).ToArray();\n\t\t\tcontinue;\n\t\t}\n\t\t//\u5408\u5e76\u5730\u5740\n\t\tserviceSubscriber.Address = serviceSubscriber.Address.Concat(subscriber.Address).Distinct().ToArray();\n\t\t//\u66ff\u6362\u73b0\u6709\u7684\u8ba2\u9605\u8005\n\t\tserviceSubscribers = serviceSubscribers.Where(p => p.ServiceDescriptor.Id!= subscriber.ServiceDescriptor.Id).Concat(new ServiceSubscriber[] { serviceSubscriber }).ToArray();\n\t}\n\t//\u8c03\u7528\u57fa\u7c7b\u7684SetSubscribersAsync\u65b9\u6cd5\n\tawait base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 63.846857500251254}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar serviceSubscribers = await base.GetSubscribersAsync();\n\tforeach (var subscriber in subscribers) {\n\t\tvar serviceSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (serviceSubscriber!= null) {\n\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t_logger.LogDebug($\"Updating subscriber address list of service {subscriber.ServiceDescriptor.Id} with new addresses {string.Join(\", \", subscriber.Address)}\");\n\n\t\t\tsubscriber.Address = subscriber.Address.Concat(serviceSubscriber.Address).Except(subscriber.Address);\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 66.50768614997713}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\n\nvar rootPath = _configuration.GetSubscribersPath();\n\n_logger.LogDebug(\"Retrieving subscribers for children {Children}\", childrens);\n\nforeach (var child in childrens) {\nvar nodePath = Path.Combine(rootPath, child);\n\n_logger.LogDebug(\"Retrieving subscribers for child {Child} with node path {NodePath}\", child, nodePath);\n\nvar subscriber = await GetSubscriber(nodePath);\n\nsubscribers.Add(subscriber);\n}\n\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 48.341612186010565}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar rootPath = _serviceSubscriberPath.Replace(\"{serviceId}\", _serviceId);\nif\n_logger.LogDebug\nchildrens.ToArray\nrootPath.EndsWith\nvar fullPath = $\"{rootPath}/{child}\";\nvar subscriber = await GetSubscriber(fullPath);\nsubscribers.Add(subscriber);\n}", "CodeBleu_score": 27.737040043147125}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar\nsubscribers = new List<ServiceSubscriber>();\nvar\nrootPath = GetRootPath(ServiceSubscriber.SubscribersPath);\nforeach (var child in childrens) {\nif\n(_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug($\"Retrieving subscribers for child {child}\");\n}\nvar\nsubscriberPath = Path.Combine(rootPath, child);\nvar\nsubscriber = await GetSubscriber(subscriberPath);\nsubscribers.Add(subscriber);\n}\nreturn\nsubscribers.ToArray();\n}", "CodeBleu_score": 41.38121639176211}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null)\n\t\treturn;\n\n\tvar zooKeeper = await _zookeeperClientProvider.GetZooKeeper();\n\tzooKeeper.Item1.WaitOne();\n\n\tvar childrens = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\n\tif (childrens.Children.Any()) {\n\t\t_subscribers = await GetSubscribers(childrens.Children);\n\t} else {\n\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t_logger.LogWarning($\"Subscriber path {_configInfo.SubscriberPath} does not exist.\");\n\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t}\n}", "CodeBleu_score": 54.278468585336235}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\tvar zooKeeper = await _zookeeperClientProvider.GetZooKeeper();\n\tzooKeeper.Item1.WaitOne();\n\tvar rootPath = _configInfo.SubscriberPath;\n\tif (!rootPath.EndsWith(\"/\")) {\n\t\trootPath += \"/\";\n\t}\n\tif (_logger.IsEnabled(LogLevel.Debug)) {\n\t\t_logger.LogDebug($\"\u51c6\u5907\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\uff0c\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u3002\");\n\t}\n\tvar children = await zooKeeper.Item2.getChildrenAsync(rootPath);\n\tif (children == null || children.Children.Count == 0) {\n\t\tif (_logger.IsEnabled(LogLevel.Warning)) {\n\t\t\t_logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u4e0d\u5b58\u5728\u3002\");\n\t\t}\n\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t\treturn;\n\t}\n\t_subscribers = await GetSubscribers(children.Children);\n}", "CodeBleu_score": 44.339782527053195}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\tvar (resetEvent, zooKeeper) = await GetZooKeeper();\n\ttry {\n\t\tawait resetEvent.WaitOneAsync();\n\t\tvar rootPath = _configInfo.SubscriberPath;\n\t\tif (!rootPath.EndsWith(\"/\")) {\n\t\t\trootPath += \"/\";\n\t\t}\n\t\tvar result = await zooKeeper.getChildrenAsync(rootPath);\n\t\tif (result.Children.Any()) {\n\t\t\t_subscribers = await GetSubscribers(result.Children);\n\t\t} else {\n\t\t\tif (_logger.IsEnabled(LogLevel.Warning)) {\n\t\t\t\t_logger.LogWarning($\"The subscriber path {rootPath} does not exist.\");\n\t\t\t}\n\t\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t\t}\n\t} finally {\n\t\tzooKeeper.close();\n\t}\n}", "CodeBleu_score": 44.91525656154148}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\the data is the same, there is no need to do anything.\nif (DataEquals(oldData, newData))\nreturn;\n// Get the old and new service commands.\nvar oldCommand = GetServiceCommand(oldData);\nvar newCommand = GetServiceCommand(newData);\n// If the service command is the same, there is no need to do anything.\nif (oldCommand!= null && newCommand!= null && oldCommand.Equals(newCommand))\nreturn;\n// Update the service commands list.\nif (oldCommand!= null)\n{\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= oldCommand.ServiceId).ToArray();\n}\nif (newCommand!= null)\n{\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n// Trigger the service command change event.\nOnChanged?.Invoke(this, new ServiceCommandChangedEventArgs(newCommand, oldCommand));\n}", "CodeBleu_score": 63.93895298120361}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\togger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"Node change, old data: {Encoding.UTF8.GetString(oldData)}, new data: {Encoding.UTF8.GetString(newData)}\");\n\tif (DataEquals(oldData, newData))\n\t\treturn;\n\tvar oldCommand = GetServiceCommand(oldData);\n\tvar newCommand = GetServiceCommand(newData);\n\tif (oldCommand!= null) {\n\t\t_commands = _commands.Where(i => i.ServiceId!= oldCommand.ServiceId).ToArray();\n\t}\n\tif (newCommand!= null) {\n\t\t_commands = _commands.Where(i => i.ServiceId!= newCommand.ServiceId)\n\t\t\t.Concat(new[] { newCommand }).ToArray();\n\t}\n\tOnChanged?.Invoke(newCommand, oldCommand);\n}", "CodeBleu_score": 62.42282072911289}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.5875867509581765}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\t// Handle NodeDataChanged events.\n\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\t// Get the current data from the node asynchronously using a ZooKeeper client.\n\t\tvar zooKeeper = await _zooKeeperCall(watchedEvent.get_Path());\n\t\tvar currentData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), this);\n\n\t\t// Execute the action with the current and new data.\n\t\tawait _action(currentData, zooKeeper.Item1);\n\n\t\t// Update the watcher with the new data.\n\t\t_watcher.SetCurrentData(currentData);\n\t}\n}", "CodeBleu_score": 24.669459066683853}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == Watcher.Event.EventType.NodeDataChanged) {\n\t\tvar zooKeeper = await _zooKeeperCall(watchedEvent.get_Path());\n\t\tvar currentData = _currentData.Value;\n\t\tvar newData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), this);\n\t\t_currentData.Value = newData;\n\t\t_action(currentData, newData);\n\t}\n}", "CodeBleu_score": 53.18541203467743}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\tvar zooKeeper = await _zooKeeperCall(watchedEvent.get_Path());\n\t\tvar currentData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), this);\n\t\t_action(currentData, zooKeeper.Item1);\n\t\tzooKeeper.Item2.setDataAsync(watchedEvent.get_Path(), zooKeeper.Item1, -1, this, null);\n\t}\n}", "CodeBleu_score": 48.82792607604488}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\trvices.Register(provider =>\n//       new DefaultZookeeperClientProvider(\n//           GetConfigInfo(configInfo),\n//        provider.Resolve<IHealthCheckService>(),\n//          provider.Resolve<IZookeeperAddressSelector>(),\n//          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\n\nbuilder.Services.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\n\nreturn builder;\n}", "CodeBleu_score": 80.45092875275017}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tvices.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance\n\n\n}", "CodeBleu_score": 69.28175256804776}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t == null)\n\t\tthrow new ArgumentNullException(nameof(builder));\n\tif (configInfo == null)\n\t\tthrow new ArgumentNullException(nameof(configInfo));\n\tvar provider = builder.Services.BuildServiceProvider();\n\tbuilder.Services.Register(provider =>\n\t\tnew DefaultZookeeperClientProvider(\n\t\t\tGetConfigInfo(configInfo),\n\t\t\tprovider.Resolve<IHealthCheckService>(),\n\t\t\tprovider.Resolve<IZookeeperAddressSelector>(),\n\t\t\tprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n\treturn builder;\n}", "CodeBleu_score": 82.60956556105836}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t}", "CodeBleu_score": 1.1662014589334855}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tvar serviceRoutes = routes.Select(x => new MqttServiceRoute(x.Id, x.Name, x.Host, x.Port, x.TlsPort, x.Protocol));\nvar zooKeepers = _provider.GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\nvar serviceRoutePath = $\"{_configuration.ZooKeeper.ServiceRoutePath}/{zooKeeper.Id}\";\n_logger.LogInformation($\"Adding service routes to {serviceRoutePath}\");\n\nvar serviceRouteData = JsonConvert.SerializeObject(serviceRoutes);\nvar serviceRouteNode = new ZooKeeperNode(serviceRoutePath, serviceRouteData);\n\nif (!await zooKeeper.ExistsAsync(serviceRoutePath)) {\nawait zooKeeper.CreateAsync(serviceRouteNode, ZooDefs.Ids.OPEN_ACL_UNSAFE);\n_logger.LogInformation($\"Created service route node: {serviceRoutePath}\");\n}\nelse {\nawait zooKeeper.SetAsync(serviceRouteNode);\n_logger.LogInformation($\"Updated service route node: {serviceRoutePath}\");\n}\n\n_logger.LogInformation($\"Added service routes to {serviceRoutePath}\");\n}\n}", "CodeBleu_score": 34.42291874382792}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routeTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar routePath = zooKeeper.Item1;\n\t\tvar addresses = zooKeeper.Item2.getChildrenAsync(routePath).Result.ToArray();\n\t\tvar deletedRouteTopics = addresses.Except(routeTopics).ToArray();\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tvar address = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n\t\t\tif (address.Equals(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteTopic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 51.87806713404477}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = $\"{_serviceRoutePath}/{hostAddr.Host}:{hostAddr.Port}\";\n\tvar zooKeepers = _zookeeperClientProvider.GetZooKeepers();\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tvar addresses = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n\t\t\tif (addresses.Contains(hostAddr)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath + \"/\" + deletedRouteTopic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 58.917369366368696}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routeTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n\tvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeeperClients) {\n\t\tvar oldRouteTopics = await zooKeeper.Item2.getChildrenAsync(ZookeeperRoutePath);\n\t\tvar deletedRouteTopics = oldRouteTopics.Except(routeTopics).ToArray();\n\t\tforeach (var deletedRouteTopic in deletedRouteTopics) {\n\t\t\tif (zooKeeper.Item1.Contains(hostAddr.Address)) {\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(ZookeeperRoutePath + \"/\" + deletedRouteTopic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 40.78195911581945}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t_logger.LogInformation(\"Setting caches in Zookeeper\");\n\nstring cachePath = _config.GetCachePath();\n\nvar zooKeepers = _zooKeeperProvider.GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\nawait zooKeeper.EnsurePathExistsAsync(cachePath);\n\nforeach (var cacheDescriptor in cacheDescriptors) {\nstring nodePath = $\"{cachePath}/{cacheDescriptor.ServiceId}\";\n\nbyte[] data = _serializer.Serialize(cacheDescriptor);\n\nif (await zooKeeper.ExistsAsync(nodePath) == null) {\nawait zooKeeper.CreateAsync(nodePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n} else {\nif (!DataEquals(nodePath, data, zooKeeper)) {\nawait zooKeeper.SetDataAsync(nodePath, data);\n}\n}\n}\n}\n\n_logger.LogInformation(\"Successfully added service caches\");\n}", "CodeBleu_score": 36.65978114345564}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\n_logger.LogInformation(\"Updating service cache descriptors in Zookeeper\");\n\n// Construct the cache path\nvar cachePath = Path.Combine(_configuration.ZookeeperPath, \"caches\");\n\n// Retrieve Zookeeper clients\nvar zooKeepers = _zookeeperProvider.GetZooKeepers();\n\n// Iterate through each Zookeeper client\nforeach (var zooKeeper in zooKeepers) {\n\n// Ensure the cache path exists\nawait zooKeeper.CreateParentPathAsync(cachePath);\n\n// Iterate through the cache descriptors\nforeach (var cacheDescriptor in cacheDescriptors) {\n\n// Serialize the descriptor\nvar cacheData = JsonConvert.SerializeObject(cacheDescriptor);\n\n// Check if the node exists\nvar nodePath = Path.Combine(cachePath, cacheDescriptor.ServiceName);\nif (await zooKeeper.ExistsAsync(nodePath) == null) {\n\n// Create the node\nawait zooKeeper.CreateAsync(nodePath, cacheData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n} else {\n\n// Update the node's data if necessary\nif (!DataEquals(nodePath, cacheData, zooKeeper)) {\nawait zooKeeper.SetDataAsync(nodePath, cacheData);\n}\n}\n}\n}\n\n// Log the successful addition of the service caches\n_logger.LogInformation(\"Successfully added service caches to Zookeeper\");\n}", "CodeBleu_score": 38.040367405797205}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation($\"CreateSubdirectory: {path}\");\nzooKeeper.Item2.existsAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, (rc, path1, ctx, stat) => {\nif (stat == null) {\n_logger.LogInformation($\"CreateSubdirectory: {path1} does not exist\");\nzooKeeper.Item1.Set();\n}\n}, null);\nzooKeeper.Item1.WaitOne();\nif (zooKeeper.Item2.existsAsync(path) == null) {\n_logger.LogInformation($\"CreateSubdirectory: {path} does not exist\");\nstring[] subDirs = path.Split(new char[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nStringBuilder sb = new StringBuilder();\nfor (int i = 0; i < subDirs.Length; i++) {\nsb.Append(\"/\");\nsb.Append(subDirs[i]);\nstring subDir = sb.ToString();\nif (zooKeeper.Item2.existsAsync(subDir) == null) {\n_logger.LogInformation($\"CreateSubdirectory: {subDir} does not exist\");\nzooKeeper.Item2.createAsync(subDir, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}\n}\n}", "CodeBleu_score": 50.27467542440801}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t", "CodeBleu_score": 6.677050525407208}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\t// Wait for the manual reset event before proceeding\n\tzooKeeper.Item1.WaitOne();\n\n\t// Check if the path already exists\n\tif (zooKeeper.Item2.existsAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, null).Result == null) {\n\t\t// Log the creation process\n\t\t_logger.LogInformation($\"Creating path: {path}\");\n\n\t\t// Split the path into subdirectories\n\t\tvar subdirectories = path.Split('/');\n\n\t\t// Create the subdirectories if they do not exist\n\t\tfor (int i = 1; i < subdirectories.Length; i++) {\n\t\t\tvar subdirectory = string.Join(\"/\", subdirectories.Take(i + 1));\n\t\t\tif (zooKeeper.Item2.existsAsync(subdirectory, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, null).Result == null) {\n\t\t\t\tzooKeeper.Item2.createAsync(subdirectory, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT).Wait();\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 44.65301493664688}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nvar healthyAddresses = await _healthCheckService.GetHealthyAddresses();\nforeach (var address in healthyAddresses) {\nvar (connectionWait, zookeeper) = CreateZooKeeper(address);\nresult.Add((connectionWait, zookeeper));\n}\nreturn result;\n}", "CodeBleu_score": 62.78958329945985}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.IpAddresses) {\nvar (connectionWait, zooKeeper) = CreateZooKeeper(ipAddress);\nif (await _healthCheckService.IsHealth(zooKeeper)) {\nresult.Add((connectionWait, zooKeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 65.87503270630305}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\n\nforeach (var ipAddress in _config.ZooKeeperAddresses)\n{\n    if (!_healthCheckService.IsHealth(ipAddress))\n    {\n        continue;\n    }\n\n    var (connectionWait, zooKeeper) = CreateZooKeeper(ipAddress);\n    await connectionWait.WaitAsync();\n    result.Add((connectionWait, zooKeeper));\n}\nreturn result;\n}", "CodeBleu_score": 65.4866353400306}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (zk == null) {\n\t\t\thelper = new Helper(this);\n\t\t\tzk = helper.getZooKeeper();\n\t\t}\n\t\treturn zk;\n\t}\n}", "CodeBleu_score": 18.694867611561207}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (helper == null) {\n\t\t\thelper = new Helper(this);\n\t\t\thelper.start();\n\t\t}\n\t}\n\treturn helper.getZooKeeper();\n}", "CodeBleu_score": 15.700814572910899}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (helper == null) {\n\t\t\thelper = new Helper(this);\n\t\t}\n\t}\n\treturn helper.getZooKeeper();\n}", "CodeBleu_score": 12.651944640697044}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\tWatcher defaultWatcher = this.zk.getDefaultWatcher();\n\t\tif (defaultWatcher!= null) {\n\t\t\tthis.zk.register(defaultWatcher);\n\t\t}\n\t\tif (waitForShutdownTimeoutMs == 0) {\n\t\t\tthis.zk.close();\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tthis.zk.close(waitForShutdownTimeoutMs);\n\t\t\t} catch (InterruptedException ie) {\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tthrow ie;\n\t\t\t}\n\t\t}\n\t\tthis.zk = null;\n\t}\n}", "CodeBleu_score": 29.1298798411674}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zk = this.getZk();\n\tif (zk!= null) {\n\t\ttry {\n\t\t\tzk.register(new Watcher() {\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t} catch (Exception e) {\n\t\t\t// ignore\n\t\t}\n\t\tif (waitForShutdownTimeoutMs == 0) {\n\t\t\tzk.close();\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 33.95451865799659}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zk = null;\n\tWatcher dummyWatcher = new Watcher() {\n\t\tpublic void process(WatchedEvent event) {\n\t\t}\n\t};\n\tsynchronized (this) {\n\t\tzk = zookeeper;\n\t\tif (zk!= null) {\n\t\t\tzookeeper = null;\n\t\t\tzk.register(dummyWatcher);\n\t\t}\n\t}\n\tif (zk!= null) {\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tzk.close();\n\t\t\t}\n\t\t} catch (InterruptedException ie) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 43.84551240877741}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlong start = System.currentTimeMillis();\n\tboolean connected = false;\n\ttry {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\tconnected = true;\n\t} finally {\n\t\tlong end = System.currentTimeMillis();\n\t\tlong duration = end - start;\n\t\tif (log.isInfoEnabled()) {\n\t\t\tlog.info(\"blockUntilConnectedOrTimedOut: \" + connected + \" in \" + duration + \"ms\");\n\t\t}\n\t\tif (tracer.get()!= null) {\n\t\t\ttracer.get().addFirst(new OperationTrace(\"blockUntilConnectedOrTimedOut\", duration, connected));\n\t\t}\n\t}\n\treturn connected;\n}", "CodeBleu_score": 40.667917115001174}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlog.info(\"blockUntilConnectedOrTimedOut\");\n\tstartAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n\tboolean connected = false;\n\ttry {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\tconnected = state.isConnected();\n\t} catch (InterruptedException e) {\n\t\tThread.currentThread().interrupt();\n\t\tthrow e;\n\t} finally {\n\t\tgetTracer().traceDone(connected);\n\t}\n\treturn connected;\n}", "CodeBleu_score": 40.3043755902951}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\ttry {\n\t\tdebug(\"blockUntilConnectedOrTimedOut\");\n\t\tstartAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n\t\tcheckState();\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\treturn isConnected();\n\t} finally {\n\t\tdebug(\"blockUntilConnectedOrTimedOut - end\");\n\t\tstartAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n\t}\n}", "CodeBleu_score": 29.055474406772497}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down\");\n\tstarted = false;\n\ttry {\n\t\tclose(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (IOException e) {\n\t\tcheckInterrupted();\n\t\tlog.error(\"Error while closing\", e);\n\t}\n}", "CodeBleu_score": 42.701243969235215}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlogger.info(\"Shutting down service\");\n\tstarted = false;\n\ttry {\n\t\tclose(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (IOException e) {\n\t\tcheckInterrupted();\n\t\tlogger.error(\"Error while closing service\", e);\n\t}\n}", "CodeBleu_score": 42.92661178890835}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif (started) {\n\t\tlogger.info(\"Shutting down service...\");\n\t\tstarted = false;\n\t\ttry {\n\t\t\tclose(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t\t} catch (IOException e) {\n\t\t\tcheckInterrupted(e);\n\t\t\tlogger.error(\"Error while shutting down service.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.432621449066055}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: implement method\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: implement this method\n\t//add code here\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: Implement method\n\t//Add code here\n}", "CodeBleu_score": 1.4820082928049525}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (createMode == CreateMode.EPHEMERAL) {\nif (client.getZooKeeper().getSessionId()!= protectedId) {\nLOG.info(\"Session {} changed for protected node {}. Deleting old node and creating new one\", client.getZooKeeper().getSessionId(), foundNode);\nclient.delete().forPath(foundNode);\nprotectedId = client.getZooKeeper().getSessionId();\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 31.35149601808064}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (createMode == CreateMode.EPHEMERAL) {\nif (client.getZooKeeper()!= null) {\nif (client.getZooKeeper().getSessionId()!= protectedId) {\nlog.warn(\"Session ID changed for protected node: {}. Deleting old node\", foundNode);\nclient.getZooKeeper().delete(foundNode, -1);\nprotectedId = client.getZooKeeper().getSessionId();\n}\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 31.88888316257471}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif ( doProtected() )\n\t{\n\t\tif (!client.getZooKeeper().getSessionId().equals(protectedId) )\n\t\t{\n\t\t\tLOG.warn( \"Session changed from {} to {}. Deleting old node {}\", protectedId, client.getZooKeeper().getSessionId(), foundNode );\n\t\t\tclient.delete().forPath( foundNode );\n\t\t\tprotectedId = client.getZooKeeper().getSessionId();\n\t\t}\n\t}\n\n\treturn foundNode;\n}", "CodeBleu_score": 31.285327858948552}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// TODO: add code here\n}", "CodeBleu_score": 8.015348925448922}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal String traceName = \"setACL\";\n\tfinal String traceId = getTraceId(traceName);\n\tfinal Trace trace = startTrace(traceId, traceName, path);\n\ttry {\n\t\tStat status = null;\n\t\tint retries = 0;\n\t\twhile (retries < 3) {\n\t\t\ttry {\n\t\t\t\tstatus = getZooKeeper().setACL(path, aclList, -1);\n\t\t\t\tbreak;\n\t\t\t} catch (KeeperException.NoNodeException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.BadVersionException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.NoAuthException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.NotEmptyException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.NodeExistsException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.SessionExpiredException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException.ConnectionLossException e) {\n\t\t\t\t// ignore\n\t\t\t} catch (KeeperException e) {\n\t\t\t\t// ignore\n\t\t\t}\n\t\t\tretries++;\n\t\t\tThread.sleep(1000);\n\t\t}\n\t\ttrace.addResult(path, status);\n\t\ttrace.commit();\n\t\treturn status;\n\t} catch (Exception e) {\n\t\ttrace.addResult(path, e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 31.038111306636146}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis(client, membershipPath, thisId, payload, null);\n}", "CodeBleu_score": 11.687543650928422}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tif (client == null) {\n\t\tthrow new IllegalArgumentException(\"client cannot be null\");\n\t}\n\tif (membershipPath == null) {\n\t\tthrow new IllegalArgumentException(\"membershipPath cannot be null\");\n\t}\n\tif (thisId == null) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null\");\n\t}\n\tif (thisId.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be empty\");\n\t}\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = CuratorCache.builder(client, membershipPath).build();\n}", "CodeBleu_score": 40.286100616507944}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\tif (thisId.indexOf('/')!= -1) {\n\t\tthrow new IllegalArgumentException(\"id cannot contain a '/' character: \" + thisId);\n\t}\n\n\tcache = CuratorFrameworkFactory.newCache(client, membershipPath, false);\n\tcache.start();\n\n\ttry {\n\t\tclient.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n\t} catch (NodeExistsException e) {\n\t\tthrow new IllegalStateException(\"Ephemeral node already exists: \" + membershipPath + \"/\" + thisId, e);\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Unexpected error creating ephemeral node: \" + membershipPath + \"/\" + thisId, e);\n\t}\n}", "CodeBleu_score": 36.23689883407363}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\tasync.watched().forPath(path).whenComplete((watchedEvent, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Watched event: \" + watchedEvent);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 69.53785342241044}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\tasync.checkExists().forPath(path).whenComplete((stat, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Node exists with stat: \" + stat);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 69.43400785735844}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tasync.checkExists().forPath(path).whenComplete((stat, ex) -> {\n\t\t\t\tif (ex!= null) {\n\t\t\t\t\tex.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tasync.watched().forPath(path).whenComplete((event, ex2) -> {\n\t\t\t\t\t\tif (ex2!= null) {\n\t\t\t\t\t\t\tex2.printStackTrace();\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tSystem.out.println(\"Event received: \" + event);\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 68.31292753398598}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = client.process(transaction);\n\tKeeperException.Code code = results.get(0).getErr();\n\tif (code!= KeeperException.Code.OK) {\n\t\tthrow KeeperException.create(code);\n\t}\n\treturn results;\n}", "CodeBleu_score": 24.841826056723182}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = client.process(transaction);\n\tKeeperException.Code code = results.get(0).getErr();\n\tif (code!= KeeperException.Code.OK) {\n\t\tthrow KeeperException.create(code);\n\t}\n\treturn results;\n}", "CodeBleu_score": 24.841826056723182}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = client.getZooKeeper().multi(transaction);\n\tif (results.size() > 0) {\n\t\tOpResult firstResult = results.get(0);\n\t\tif (firstResult.getErr()!= 0) {\n\t\t\tint errCode = firstResult.getErr();\n\t\t\tKeeperException ke = KeeperException.create(KeeperException.Code.get(errCode));\n\t\t\tthrow ke;\n\t\t}\n\t}\n\treturn results;\n}", "CodeBleu_score": 46.07916196781147}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\t// Query for all service names and their corresponding instances\n\tMap<String, List<ServiceInstance<InstanceDetails>>> instances = serviceDiscovery.queryForNames();\n\n\t// Print each service name and its instances\n\tfor (Map.Entry<String, List<ServiceInstance<InstanceDetails>>> entry : instances.entrySet()) {\n\t\tSystem.out.println(entry.getKey() + \":\");\n\t\tfor (ServiceInstance<InstanceDetails> instance : entry.getValue()) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n\n\t// If no instances are registered, catch NoNodeException and print error message\n\tif (instances.isEmpty()) {\n\t\tSystem.out.println(\"No instances registered.\");\n\t}\n\n\t// Close the ServiceDiscovery instance quietly\n\tcloseQuietly(serviceDiscovery);\n}", "CodeBleu_score": 41.39105462485549}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\ttry {\n\t\t// Query for all service names and their corresponding instances\n\t\tMap<String, List<ServiceInstance<InstanceDetails>>> namesToInstances = serviceDiscovery.queryForNames();\n\n\t\t// Print each service name and its instances\n\t\tfor (Map.Entry<String, List<ServiceInstance<InstanceDetails>>> entry : namesToInstances.entrySet()) {\n\t\t\tString serviceName = entry.getKey();\n\t\t\tList<ServiceInstance<InstanceDetails>> instances = entry.getValue();\n\t\t\tSystem.out.println(\"Service name: \" + serviceName);\n\t\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\t\toutputInstance(instance);\n\t\t\t}\n\t\t}\n\t} catch (NoNodeException e) {\n\t\t// No instances registered\n\t\tSystem.out.println(\"No instances registered\");\n\t} finally {\n\t\t// Close the ServiceDiscovery instance quietly\n\t\tcloseQuietly(serviceDiscovery);\n\t}\n}", "CodeBleu_score": 50.812482779231}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\t// Get the list of service names\n\tList<String> serviceNames = serviceDiscovery.queryForNames().get();\n\t// Iterate over each service name\n\tfor (String serviceName : serviceNames) {\n\t\t// Query for instances of the service\n\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName).get();\n\t\t// Print the service name\n\t\tSystem.out.println(serviceName);\n\t\t// Iterate over each instance\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\t// Print the instance details\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.56442114998805}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeAll { it == READY_NODE }\n\tchildren = children.collect { it }\n\tchildren.sort()\n\treturn children\n}", "CodeBleu_score": 12.55267739269222}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\treturn children.findAll { it!= READY_NODE }.collect { it as String }.sort()\n}", "CodeBleu_score": 10.143038685302901}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeAll { it == READY_NODE }\n\tchildren.sort()\n\treturn children\n}", "CodeBleu_score": 10.403727219902953}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 20.518259528243515}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\n\tzk = new ZooKeeper(newHost, timeout, this);\n\tif (options.get(\"readonly\")!= null) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 26.978691602619204}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tif (newHost == null) {\n\t\tthrow new IllegalArgumentException(\"host cannot be null\");\n\t}\n\tzk = new ZooKeeper(newHost, 3000, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly(true);\n\t}\n\tSystem.out.println(\"Connected to \" + newHost);\n}", "CodeBleu_score": 28.38045506827061}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acls = new ArrayList<>();\n\tString[] segments = aclString.split(\",\");\n\tfor (String segment : segments) {\n\t\tString[] parts = segment.split(\":\");\n\t\tif (parts.length!= 3) {\n\t\t\toutputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\n\t\t\tcontinue;\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tint perms = getPermFromString(parts[2]);\n\t\tACL acl = new ACL(perms, new Id(scheme, id));\n\t\tacls.add(acl);\n\t}\n\treturn acls;\n}", "CodeBleu_score": 23.916424250469454}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acls = new ArrayList<ACL>();\n\tif (aclString == null || aclString.length() == 0) {\n\t\treturn acls;\n\t}\n\tString[] aclStrings = aclString.split(\",\");\n\tfor (String acl : aclStrings) {\n\t\tacl = acl.trim();\n\t\tif (acl.length() == 0) {\n\t\t\tcontinue;\n\t\t}\n\t\tString[] parts = acl.split(\":\");\n\t\tif (parts.length!= 3) {\n\t\t\toutputStream.write((\"Invalid ACL string: \" + acl).getBytes());\n\t\t\tcontinue;\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tString perms = parts[2];\n\t\ttry {\n\t\t\tacls.add(new ACL(getId(scheme, id), getPermFromString(perms)));\n\t\t} catch (Exception e) {\n\t\t\toutputStream.write((\"Invalid ACL string: \" + acl).getBytes());\n\t\t}\n\t}\n\treturn acls;\n}", "CodeBleu_score": 29.732897160820055}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<>();\nString[] segments = aclString.split(\",\");\nfor (String segment : segments) {\nString[] parts = segment.split(\":\");\nif (parts.length!= 3) {\noutputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\ncontinue;\n}\nString scheme = parts[0];\nString id = parts[1];\nString perms = parts[2];\nint perm = getPermFromString(perms);\nACL acl = new ACL(ZooDefs.Perms.READ, new Id(scheme, id));\nacls.add(acl);\n}\nreturn acls;\n}", "CodeBleu_score": 23.789552952299754}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tObjects.requireNonNull(pathList);\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tzookeeperMap.get(serverId).delete(path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 93.68642587633285}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tObjects.requireNonNull(pathList);\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tzookeeperMap.get(serverId).delete(path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 93.68642587633285}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to Zookeeper instance at \" + url + \"\n\");\n\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.build();\n\tvar connection = factory.createAsync(params, Collections.emptyList());\n\twriter.write(\"Connected to Zookeeper instance at \" + url + \"\n\");\n\tvar zkMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 57.43044101541446}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t.format(\"Connecting to %s%n\", url));\nZookeeperConnection connection = new CuratorZookeeperConnectionFactory().create(id, url);\nZooKeeper zk = connection.getClient();\nwriter.write(String.format(\"Connected to %s%n\", url));\nZooKeeperMain zkMain = new ZooKeeperMain(zk, writer);\nreturn new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 39.73289456393715}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to Zookeeper...\n\");\nvar connection = new CuratorZookeeperConnectionFactory().createAsync(ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(new ArrayList<>())\n.maxRetries(10)\n.connectionTimeout(10000)\n.retryIntervalTime(1000)\n.sessionTimeout(10000)\n.build(), new ArrayList<>());\nvar client = connection.getZookeeperClient();\nwriter.write(\"Connected to Zookeeper\n\");\nreturn new Terminal(id, url, connection, new ZooKeeperMain(client));\n}", "CodeBleu_score": 48.10379694676554}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tnt attempts = 0;\n\twhile (attempts < 6) {\n\t\ttry {\n\t\t\tsshClient.connect(host, port);\n\t\t\tbreak;\n\t\t} catch (Exception e) {\n\t\t\tattempts++;\n\t\t\tlog.error(\"Failed to connect to \" + host + \":\" + port + \" (\" + attempts + \"/6)\");\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tlog.error(\"Interrupted while waiting for connection to \" + host + \":\" + port);\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!sshClient.isConnected()) {\n\t\tsshClient.close();\n\t\tthrow new IllegalStateException(\"Failed to connect to \" + host + \":\" + port);\n\t}\n}", "CodeBleu_score": 38.39470462682589}, {"code": "public void blockUntilConnected(){\n\tnt retries = 0;\n\tboolean connected = false;\n\twhile (!connected && retries < 6) {\n\t\ttry {\n\t\t\tsshClient.connect();\n\t\t\tconnected = true;\n\t\t} catch (IOException e) {\n\t\t\tretries++;\n\t\t\tlogger.warn(\"Failed to establish SSH tunnel connection, retrying in 1 second (\" + retries + \"/6)\");\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tthrow new IllegalStateException(e1);\n\t\t\t}\n\t\t}\n\t}\n\tif (!connected) {\n\t\tclose();\n\t\tthrow new IllegalStateException(\"Failed to establish SSH tunnel connection after 6 attempts\");\n\t}\n}", "CodeBleu_score": 35.86163371171613}, {"code": "public void blockUntilConnected(){\n\t/        if (proxySocket!= null) {\n//            try {\n//                proxySocket.close();\n//            } catch (IOException e) {\n//                throw new IllegalStateException(e);\n//            }\n//        }\n//\n//        if (sshClient!= null) {\n//            try {\n//                sshClient.close();\n//            } catch (IOException e) {\n//                throw new IllegalStateException(e);\n//            }\n//        }\n\n        int retries = 0;\n        while (retries < 6) {\n            try {\n                sshClient.connect(proxySocket);\n                return;\n            } catch (Exception e) {\n                retries++;\n                System.out.println(\"SSH connection attempt \" + retries + \" failed\");\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e1) {\n                    e1.printStackTrace();\n                }\n            }\n        }\n\n        try {\n            sshClient.close();\n        } catch (IOException e) {\n            throw new IllegalStateException(e);\n        }\n\n        throw new IllegalStateException(\"SSH connection failed\");\n    }", "CodeBleu_score": 50.072068394444756}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList)\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node(s) for server ${serverId}\", e)\n\t\tthrow new IllegalStateException(\"Error deleting node(s) for server ${serverId}\")\n\t}\n}", "CodeBleu_score": 56.80032891726506}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList)\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node: ${e.message}\", e)\n\t\tthrow new IllegalStateException(\"Error deleting node: ${e.message}\", e)\n\t}\n}", "CodeBleu_score": 58.03053451758743}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList)\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to delete node for serverId ${serverId} and pathList ${pathList}\", e)\n\t\tthrow new IllegalStateException(e)\n\t}\n}", "CodeBleu_score": 60.9823678195098}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfiguration.getId());\n\t\ttreeItemCache.remove(id);\n\t});\n}", "CodeBleu_score": 88.7355923352014}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfiguration.getId());\n\t\ttreeItemCache.remove(id);\n\t});\n}", "CodeBleu_score": 88.7355923352014}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfiguration.getId());\n\t\ttreeItemCache.remove(id);\n\t});\n}", "CodeBleu_score": 88.7355923352014}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = getServer(serverId);\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 18.382766808669125}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = serverService.getServer(serverId);\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"Server not found\");\n\t}\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 26.304820023983496}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = serverRepository.findById(serverId).orElseThrow(() -> new ResourceNotFoundException(\"Server not found\"));\n\tString connectionUrl = getConnectionUrl(server);\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 32.50021708889724}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zooKeeper = zooKeeperMap.get(id);\n\t\tzooKeeper.create(command, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Failed to execute command \" + command + \" on server \" + id);\n\t\tSystem.out.println(\"Error: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 36.74275659737366}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zk = zooKeeperMap.get(id);\n\t\tif (zk!= null) {\n\t\t\tzk.create(command, command.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t} else {\n\t\t\tlogger.error(\"Zookeeper server {} is not connected\", id);\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error executing command {} on server {}\", command, id, e);\n\t\tSystem.out.println(\"Error executing command \" + command + \" on server \" + id + \". Please retry.\");\n\t}\n}", "CodeBleu_score": 39.3283823140097}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzk.executeCommand(id, command);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error executing command on server {}: {}\", id, command, e);\n\t\tSystem.out.println(\"Error executing command on server \" + id + \": \" + command + \". Please retry.\");\n\t}\n}", "CodeBleu_score": 54.81032529113657}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tFile file = new File(ZOOKEEPER_SYSTEM_PROPERTIES_PATH);\n\t\tif (file.exists()) {\n\t\t\tprops.load(new FileInputStream(file));\n\t\t\tlog.info(\"Loaded zookeeper system properties from file: \" + file.getAbsolutePath());\n\t\t} else {\n\t\t\tlog.warn(\"Zookeeper system properties file does not exist: \" + file.getAbsolutePath());\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.warn(\"Failed to load zookeeper system properties from file: \" + ZOOKEEPER_SYSTEM_PROPERTIES_PATH, e);\n\t}\n\treturn props;\n}", "CodeBleu_score": 42.302661171603305}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tFile file = new File(System.getProperty(\"zookeeper.system.properties.file\"));\n\tif (file.exists()) {\n\t\ttry {\n\t\t\tproperties.load(new FileInputStream(file));\n\t\t\tlog.info(\"Loaded system properties from {}\", file.getAbsolutePath());\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Error loading system properties from {}: {}\", file.getAbsolutePath(), e.getMessage());\n\t\t}\n\t} else {\n\t\tlog.error(\"System properties file {} does not exist\", file.getAbsolutePath());\n\t}\n\treturn properties;\n}", "CodeBleu_score": 39.709573297837665}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tString filePath = \"zookeeper.properties\";\n\tFile file = new File(filePath);\n\tif (file.exists()) {\n\t\ttry {\n\t\t\tproperties.load(new FileInputStream(filePath));\n\t\t\tlog.info(\"Loaded system properties from file: {}\", filePath);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to load system properties from file: {}\", filePath, e);\n\t\t}\n\t} else {\n\t\tlog.warn(\"System properties file not found: {}\", filePath);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 42.58143968937752}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tproperties.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading system properties\", e);\n\t\tshowNotification(\"Error loading system properties\", e.getMessage(), NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tproperties.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n\t} catch (IOException e) {\n\t\tlog.error(\"Error saving system properties\", e);\n\t\tshowNotification(\"Error saving system properties\", e.getMessage(), NotificationType.ERROR);\n\t}\n}", "CodeBleu_score": 34.68178775048335}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to load properties from content\", e);\n\t\tshowNotification(\"Failed to load properties from content\", NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tprops.store(new FileOutputStream(SYS_PROP_PATH), null);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to save properties to file\", e);\n\t\tshowNotification(\"Failed to save properties to file\", NotificationType.ERROR);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 31.506115022043545}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to load properties from content\", e);\n\t\tshowNotification(\"Failed to load properties from content\", NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\n\t\tprops.store(fos, null);\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to save properties to file\", e);\n\t\tshowNotification(\"Failed to save properties to file\", NotificationType.ERROR);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 36.020794391587145}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tBufferedReader in = null;\n\tStringBuilder sb = new StringBuilder();\n\ttry {\n\t\tin = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = in.readLine())!= null) {\n\t\t\tsb.append(line);\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from client socket\", e);\n\t} finally {\n\t\tcleanup(in);\n\t\tcleanup(client);\n\t}\n\treturn sb.toString();\n}", "CodeBleu_score": 49.13342929235923}, {"code": "private String response(Socket client){\n\tBufferedReader reader = null;\n\tStringBuilder sb = new StringBuilder();\n\ttry {\n\t\treader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line = null;\n\t\twhile ((line = reader.readLine())!= null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tcleanup(reader);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Failed to read from client\", e);\n\t} finally {\n\t\tcleanup(reader);\n\t}\n}", "CodeBleu_score": 49.15266906667712}, {"code": "private String response(Socket client){\n\tStringBuilder sb = new StringBuilder();\n\tBufferedReader reader = null;\n\ttry {\n\t\treader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = reader.readLine())!= null) {\n\t\t\tsb.append(line);\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from client\", e);\n\t} finally {\n\t\tcleanup(reader);\n\t\tcleanup(client);\n\t}\n\treturn sb.toString();\n}", "CodeBleu_score": 50.6588140839604}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tatorFramework client = curatorFramework(params);\n\ttry {\n\t\tclient.start();\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tclient.close();\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 50.04781772710009}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework curatorFramework = curatorFramework(params);\n\tcuratorFramework.start();\n\ttry {\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (InterruptedException e) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(e);\n\t} catch (Exception e) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn new CuratorZookeeperConnection(curatorFramework);\n}", "CodeBleu_score": 47.50129798630232}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework client = curatorFramework(params);\n\ttry {\n\t\tclient.start();\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tclient.close();\n\t\tthrow new RuntimeException(\"Failed to connect to Zookeeper\", e);\n\t}\n\treturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 57.3087396226017}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString currentConnectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\tif (!isSync.get()) {\n\t\tlogger.info(\"Start to sync zookeeper nodes, currentConnectionString: {}\", currentConnectionString);\n\t\tisSync.set(true);\n\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\ttry {\n\t\t\ttreeCache.start();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to start tree cache, currentConnectionString: {}\", currentConnectionString, e);\n\t\t\tclose();\n\t\t}\n\t} else {\n\t\tlogger.info(\"Sync zookeeper nodes is in progress, currentConnectionString: {}\", currentConnectionString);\n\t}\n}", "CodeBleu_score": 53.82679601649536}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (!isSync.compareAndSet(false, true)) {\n\t\tlog.info(\"Zookeeper synchronization is already in progress.\");\n\t\treturn;\n\t}\n\tlog.info(\"Start synchronization.\");\n\tString connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners, connectionString));\n\ttry {\n\t\ttreeCache.start();\n\t} catch (Exception e) {\n\t\tlog.error(\"Zookeeper synchronization failed.\", e);\n\t\ttry {\n\t\t\ttreeCache.close();\n\t\t} catch (IOException e1) {\n\t\t\tlog.error(\"Close TreeCache failed.\", e1);\n\t\t}\n\t}\n}", "CodeBleu_score": 55.03642221300681}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\tif (isSync.compareAndSet(false, true)) {\n\t\tlog.debug(\"Start to sync Zookeeper nodes: \" + connectionString);\n\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\ttry {\n\t\t\ttreeCache.start();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error occurs when starting tree cache: \" + connectionString, e);\n\t\t\ttreeCache.close();\n\t\t}\n\t} else {\n\t\tlog.info(\"Zookeeper nodes are already in sync: \" + connectionString);\n\t}\n}", "CodeBleu_score": 48.94030489303105}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tlog.info(\"Unregistering service...\");\n\tList<String> paths = new ArrayList<String>();\n\tpaths.add(servicePath);\n\tpaths.add(servicePath + \"/config\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tcurator.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error unregistering service: \" + e.getMessage());\n\t\t}\n\t}\n\tcurator.close();\n}", "CodeBleu_score": 37.66639292534043}, {"code": "public void unregisterService(){\n\t\tlogger.info(\"Unregistering service...\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error unregistering service: \" + e.getMessage());\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 55.853269790026474}, {"code": "public void unregisterService(){\n\t\tlog.info(\"unregisterService\");\n\ttry {\n\t\tfor (String path : paths) {\n\t\t\ttry {\n\t\t\t\tcuratorClient.delete().forPath(path);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(e.getMessage());\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tcuratorClient.close();\n\t}\n}", "CodeBleu_score": 49.882394833358504}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> {\n\t\ttry {\n\t\t\tmakeClientReady(new ZkClient(zkServers, sessionTimeout, connectionTimeout, new ZkSerializer() {\n\t\t\t\tpublic byte[] serialize(Object data) {\n\t\t\t\t\treturn data.toString().getBytes();\n\t\t\t\t}\n\n\t\t\t\tpublic Object deserialize(byte[] bytes) {\n\t\t\t\t\treturn new String(bytes);\n\t\t\t\t}\n\t\t\t}), null);\n\t\t} catch (Throwable e) {\n\t\t\tmakeClientReady(null, e);\n\t\t}\n\t}).whenComplete((v, e) -> {\n\t\tif (e == null) {\n\t\t\tthis.client.subscribeStateChanges(listener);\n\t\t}\n\t}).exceptionally(ex -> {\n\t\tlogger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", ex);\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 37.45285546610552}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> {\n\t\ttry {\n\t\t\tmakeClientReady(new ZkClient(zkServers, sessionTimeout, connectionTimeout, zkSerializer), null);\n\t\t} catch (Throwable e) {\n\t\t\tmakeClientReady(null, e);\n\t\t}\n\t}).whenComplete((v, e) -> {\n\t\tif (e!= null) {\n\t\t\tlogger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", e);\n\t\t} else {\n\t\t\tclient.subscribeStateChanges(stateListener);\n\t\t}\n\t});\n}", "CodeBleu_score": 42.57276302732643}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> {\n\t\tmakeClientReady(listener);\n\t}).exceptionally(e -> {\n\t\tlogger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", e);\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 15.719353302909136}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(3000);\n\tif (authority!= null) {\n\t\tbuilder.authorization(\"digest\", authority.getBytes());\n\t}\n\tclient = builder.build();\n\tclient.getConnectionStateListenable().addListener(this);\n\tclient.start();\n\ttry {\n\t\tclient.blockUntilConnected();\n\t} catch (InterruptedException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 31.078072087264953}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(5000);\n\tif (authority!= null) {\n\t\tbuilder.authorization(\"digest\", authority.getBytes());\n\t}\n\tclient = builder.build();\n\tclient.getConnectionStateListenable().addListener(this);\n\tclient.start();\n\ttry {\n\t\tclient.getZookeeperClient().blockUntilConnectedOrTimedOut();\n\t} catch (InterruptedException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 34.025806378860324}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\tthis.client = CuratorFrameworkFactory.builder().connectString(serverAddr)\n\t\t\t.retryPolicy(new ExponentialBackoffRetry(1000, 3))\n\t\t\t.connectionTimeoutMs(10000)\n\t\t\t.authorization(\"digest\", authority.getBytes())\n\t\t\t.build();\n\tclient.getConnectionStateListenable().addListener(this);\n\tclient.start();\n\tif (client.getState()!= CuratorFrameworkState.STARTED) {\n\t\tthrow new IllegalStateException(\"Client is not started!\");\n\t}\n}", "CodeBleu_score": 32.009018327573244}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t", "CodeBleu_score": 6.268009501257914}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener must not be null\");\n\t}\n\tsynchronized (this.listeners) {\n\t\tChildListenerMap childListenerMap = this.listeners.get(path);\n\t\tif (childListenerMap!= null) {\n\t\t\tchildListenerMap.remove(listener);\n\t\t\tif (childListenerMap.isEmpty()) {\n\t\t\t\tthis.listeners.remove(path);\n\t\t\t}\n\t\t}\n\t}\n\tremoveTargetChildListener(path, listener);\n}", "CodeBleu_score": 42.45995189189993}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"Path must not be null.\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener must not be null.\");\n\t}\n\tsynchronized (this.childListenerMap) {\n\t\tMap<ChildListener, TargetChildListener> listeners = this.childListenerMap.get(path);\n\t\tif (listeners!= null) {\n\t\t\tTargetChildListener targetListener = listeners.remove(listener);\n\t\t\tif (targetListener!= null) {\n\t\t\t\tremoveTargetChildListener(path, targetListener);\n\t\t\t}\n\t\t\tif (listeners.isEmpty()) {\n\t\t\t\tthis.childListenerMap.remove(path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 62.146076088501225}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tif (!zh) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc_host;\n\tdeserialize_from_idc_host(zh, idc_host);\n\tzookeeper_close(zh);\n\n\tstring idc, host;\n\tdeserialize_idc_host(idc_host, idc, host);\n\tzh = zookeeper_init(host.c_str(), watcher_table, 10000, 0, 0, 0);\n\tif (!zh) {\n\t\tLOG_ERR(\"reconnect to zookeeper failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tinit_env_for_zk(zh, idc);\n\n\tif (watcher_table_init(zh)!= QCONF_OK) {\n\t\tLOG_ERR(\"watcher_table_init failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 30.195869368190287}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc_host;\n\tdeserialize_from_idc_host(zh, idc_host);\n\n\tzookeeper_close(zh);\n\n\tstring idc, host;\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\tzh = zookeeper_init(host.c_str(), watcher_table, ZOO_SESSION_TIMEOUT, 0, 0, 0);\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zookeeper_init failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tif (init_env_for_zk(zh, idc, host)!= QCONF_OK) {\n\t\tLOG_ERR(\"init_env_for_zk failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\twatcher_table.reset(zh);\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 35.11058414477962}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Retrieve and delete the IDC host information associated with the handle\n\tstring idc_host;\n\tint ret = lock_ht_find(g_idc_host_ht, g_idc_host_ht_mu, zh, idc_host);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERR(\"lock_ht_find failed\");\n\t\treturn ret;\n\t}\n\tlock_ht_delete(g_idc_host_ht, g_idc_host_ht_mu, zh);\n\n\t// Close the old handle\n\tzookeeper_close(zh);\n\n\t// Deserialize the IDC and host information\n\tstring idc, host;\n\tret = deserialize_from_idc_host(idc_host, idc, host);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERR(\"deserialize_from_idc_host failed\");\n\t\treturn ret;\n\t}\n\n\t// Initialize a new ZooKeeper handle with the deserialized information\n\tzh = zookeeper_init(host.c_str(), watcher_global, 30000, 0, NULL, 0);\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zookeeper_init failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Initialize the environment for the new handle\n\tret = init_env_for_zk(zh, idc, host);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERR(\"init_env_for_zk failed\");\n\t\treturn ret;\n\t}\n\n\t// Reset the table watcher\n\tret = watcher_reset_table_watcher(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERR(\"watcher_reset_table_watcher failed\");\n\t\treturn ret;\n\t}\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 41.746777611234656}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// Add the handle to the global table\n\tlock_ht_update(g_zh_ht, g_zh_ht_mu, zh, idc_host);\n\t// Add the IDC to the global table\n\tlock_ht_update(g_idc_ht, g_idc_ht_mu, idc_host, idc);\n\t// Check the connection state\n\tint state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is not connected\");\n\t\treturn;\n\t}\n\t// Register the current host on the Zookeeper server\n\tstring path = \"/idc/\" + idc;\n\tint ret = zoo_create(zh, path.c_str(), idc_host.c_str(), idc_host.length(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to register the current host on the Zookeeper server\");\n\t\treturn;\n\t}\n\t// Set a watcher on the notify node\n\tstring notify_node = \"/notify\";\n\tret = zoo_wexists(zh, notify_node.c_str(), watch_notify_node, reinterpret_cast<void *>(zh), NULL);\n\tif (ret!= ZOK) {\n\t\tLOG_FATAL_ERR(\"Failed to set a watcher on the notify node\");\n\t\treturn;\n\t}\n\t// Add the IDC to a gray list if the watcher is set successfully\n\tadd_gray_idc(idc);\n\tLOG_INFO(\"IDC %s added to the gray list\", idc.c_str());\n}", "CodeBleu_score": 52.53632210240774}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (zh == NULL) {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is NULL\");\n\t\treturn;\n\t}\n\tif (idc_host.empty() || idc.empty()) {\n\t\tLOG_FATAL_ERR(\"IDC host or IDC is empty\");\n\t\treturn;\n\t}\n\tif (zoo_state(zh)!= ZOO_CONNECTED_STATE) {\n\t\tLOG_INFO(\"Zookeeper handle is not connected\");\n\t\treturn;\n\t}\n\tzk_register_ephemeral(zh, idc_host, idc);\n\twatch_notify_node(zh, idc);\n\tif (gray_idc_map.find(idc) == gray_idc_map.end()) {\n\t\tadd_gray_idc(idc);\n\t} else {\n\t\tLOG_FATAL_ERR(\"IDC %s already in gray list\", idc.c_str());\n\t}\n}", "CodeBleu_score": 40.15718639805363}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// Update internal tables with the handle and host information\n\tlock_ht_update(g_idc_to_zk_ht, g_idc_to_zk_mu, idc, zh);\n\tlock_ht_update(g_zk_to_idc_ht, g_zk_to_idc_mu, zh, idc);\n\n\t// Check the connection state of the Zookeeper handle\n\tint state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\t// If the handle is not connected, exit early\n\t\treturn;\n\t}\n\n\t// Register the current host on the Zookeeper server\n\tstring host_path = g_idc_host_root + \"/\" + idc_host;\n\tint rc = zoo_create(zh, host_path.c_str(), NULL, 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (rc!= ZOK) {\n\t\t// If the operation fails, log an error and return\n\t\tLOG_FATAL_ERR(zh, rc, \"Failed to register host in Zookeeper\");\n\t\treturn;\n\t}\n\n\t// Set a watcher on the notify node\n\tstring notify_path = g_idc_notify_root + \"/\" + idc;\n\trc = zoo_wexists(zh, notify_path.c_str(), watch_notify_node, NULL, NULL);\n\tif (rc!= ZOK) {\n\t\t// If the operation fails, log an error and return\n\t\tLOG_FATAL_ERR(zh, rc, \"Failed to set watcher on notify node\");\n\t\treturn;\n\t}\n\n\t// If the watcher is set successfully, add the IDC to a gray list\n\tlock_ht_update(g_gray_idc_ht, g_gray_idc_mu, idc, true);\n\tLOG_INFO(\"IDC %s added to gray list\", idc.c_str());\n}", "CodeBleu_score": 49.54039443800604}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()\n\n", "CodeBleu_score": 36.66621936760511}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()", "CodeBleu_score": 36.66621936760511}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b':' + username.encode() + b':' + password.encode()).digest()\n    return username + ':' + b64encode(cred_hash).decode().strip()\n", "CodeBleu_score": 29.494352606676262}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.lock_path\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.processing_element.id\n", "CodeBleu_score": 34.224970509210856}, {"code": "def holds_lock(self)\n\t\n    if not self.process:\n        return False\n    lock_path = self.get_lock_path()\n    try:\n        self.zk.sync(lock_path)\n        lock_value = self.zk.get(lock_path)[0]\n        return lock_value == self.process.id\n    except:\n        return False\n", "CodeBleu_score": 35.43482287600968}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.instance_id\n", "CodeBleu_score": 35.04427099437371}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=lock_id)\n    transaction = self.client.transaction()\n    transaction.check(lock_path).check(entry_path).delete(lock_path).delete(entry_path)\n    if transaction.commit():\n        self.processing_element = None\n        return True\n    return False\n\n", "CodeBleu_score": 56.22840039208094}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    transaction = self.client.transaction()\n    transaction.check(lock_path)\n    transaction.delete(lock_path)\n    transaction.delete(entry_path)\n    transaction.commit()\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 55.85722642673352}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    transaction = self.client.transaction()\n    transaction.check(lock_path).delete(lock_path)\n    transaction.check(entry_path).delete(entry_path)\n    if transaction.commit():\n        self.processing_element = None\n        return True\n    return False\n", "CodeBleu_score": 55.72559056009476}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t    try:\n        self.logger.log(BLATHER, \"Reading socket, read_timeout=%s\", read_timeout)\n        header, buffer, offset = self._read_header(read_timeout)\n        self.logger.log(BLATHER, \"Read header: %r\", header)\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \"Received ping response\")\n            self.outstanding_pings.clear()\n        elif header.xid == AUTH_XID:\n            self._read_auth_response(buffer, offset)\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self._read_response(header, buffer, offset)\n    except Exception as exc:\n        self.logger.exception(\"Error reading from socket\")\n        self._handle_exception(exc)\n", "CodeBleu_score": 53.95398126458257}, {"code": "def _read_socket(self, read_timeout)\n\t    try:\n        header, buffer, offset = self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \"Received ping\")\n            self._outstanding_pings.clear()\n        elif header.xid == AUTH_XID:\n            self._read_auth_response(buffer, offset)\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self.logger.log(BLATHER, \"Received header: %r\", header)\n            self._read_response(header, buffer, offset)\n    except socket.timeout:\n        self.logger.log(BLATHER, \"Read timeout\")\n        raise\n    except Exception as exc:\n        self.logger.exception(\"Error reading from socket\")\n        self.close(exc)\n        raise exc\n", "CodeBleu_score": 55.23594484039365}, {"code": "def _read_socket(self, read_timeout)\n\t    try:\n        header, buffer = self._read_header_buffer(read_timeout)\n    except ZookeeperTimeoutError:\n        raise\n    except Exception as e:\n        self.logger.exception(\n            \"Exception raised while reading header \"\n            \"and buffer: %s\",\n            e,\n        )\n        return\n\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Read ping response\")\n        self._outstanding_pings.clear()\n        return\n\n    if header.xid == AUTH_XID:\n        if header.err == OK.code:\n            self.logger.log(BLATHER, \"Read auth response\")\n            self._auth_callback(self._auth_data)\n        else:\n            self.logger.log(BLATHER, \"Read auth error response\")\n            self._auth_callback(None)\n            raise AuthFailedError(\n                \"Authentication failed: %s\" % AUTH_EXCEPTIONS[header.err]\n            )\n\n    if header.xid == WATCH_XID:\n        self.logger.log(BLATHER, \"Read watch response\")\n        self._read_watch_event(buffer, 0)\n        return\n\n    self.logger.log(BLATHER, \"Read response\")\n    self._read_response(header, buffer, 0)\n\n", "CodeBleu_score": 41.74309885101704}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry.reset()\n            self.log.info(\"Connecting to Zookeeper\")\n            self.zk.start()\n            self.log.info(\"Connected to Zookeeper\")\n            self.connection_stopped.wait()\n        except ZookeeperError as e:\n            self.log.warning(\"Failed to connect to Zookeeper: %s\", e)\n            self.retry.wait()\n        except Exception as e:\n            self.log.exception(\"Failed to connect to Zookeeper: %s\", e)\n            self.retry.wait()\n    self.log.info(\"Stopping connection loop\")\n    self.connection_stopped.set()\n    self.session_callback(State.CLOSED)\n    self.log.info(\"Stopped connection loop\")\n", "CodeBleu_score": 41.567216228678724}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.connection_stopped.is_set():\n        try:\n            self.retry.start_retry()\n            self.logger.info(\"Connecting to Zookeeper\")\n            self.zk.start()\n            self.logger.info(\"Connected to Zookeeper\")\n            self.connection_stopped.wait()\n            self.logger.info(\"Connection to Zookeeper stopped\")\n        except Exception as e:\n            self.logger.warning(\"Connection to Zookeeper failed: %s\", e)\n            self.connection_stopped.wait(self.retry.get_backoff())\n    self.logger.info(\"Setting Zookeeper connection state to closed\")\n    self.set(State.CLOSED)\n    self.logger.info(\"Zookeeper connection loop stopped\")\n", "CodeBleu_score": 40.58912175778374}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry.retry(self._zk_connect)\n        except Exception as e:\n            self.logger.warning(\"Connection to Zookeeper failed: %s\", e)\n        if not self.stopped.is_set():\n            self.logger.info(\"Stopping Zookeeper connection loop\")\n            self.connection_stopped.set()\n            self.trigger_session_callback(ZookeeperState.CLOSED)\n            self.logger.info(\"Stopped Zookeeper connection loop\")\n            break\n", "CodeBleu_score": 46.90797654080884}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    idx = members.index(identifier)\n    return partitions[idx::len(members)]\n", "CodeBleu_score": 33.50856907528368}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    if len(members) == 0:\n        return []\n    if len(partitions) == 0:\n        return []\n    if len(members) < len(partitions):\n        raise ValueError(\"Number of partitions is greater than number of workers.\")\n    if identifier not in members:\n        raise ValueError(\"Identifier not in members list.\")\n    members_sorted = sorted(members)\n    partitions_sorted = sorted(partitions)\n    index = members_sorted.index(identifier)\n    partitions_per_worker = len(partitions) / len(members)\n    return partitions_sorted[index::partitions_per_worker]\n", "CodeBleu_score": 44.48704816393952}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = members.index(identifier)\n    return [partitions[i] for i in range(index, len(partitions), len(members))]\n\n", "CodeBleu_score": 36.27956862628124}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.retry(self.client.delete, self.leave_path)\n    except NoNodeError:\n        pass\n    except:\n        self._best_effort_cleanup\n    leave\n\n", "CodeBleu_score": 40.61501508029776}, {"code": "def leave(self)\n\t\n    self.client.retry(self.client.delete, self.leave_path)\n    self._best_effort_cleanup\n    self.participating = False\n\n", "CodeBleu_score": 29.828901167630995}, {"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.retry(self.client.delete, self.leave_path)\n    except NoNodeError:\n        pass\n    except Exception as e:\n        self._best_effort_cleanup\n        raise e\n\n", "CodeBleu_score": 42.884227494920616}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\tResult result = status()\n\tif (result.isSuccess()) {\n\t\tif (result.isServerRunning()) {\n\t\t\treturn new Result(true, \"HDFS over FTP server is already running\")\n\t\t}\n\t\telse {\n\t\t\treturn startServer()\n\t\t}\n\t}\n\telse {\n\t\treturn result\n\t}\n}", "CodeBleu_score": 27.292166698991334}, {"code": "public Result start(){\n\t\tif (status().equals(Status.STOPPED)) {\n\t\ttry {\n\t\t\tstartServer();\n\t\t\treturn new Result(Result.Status.SUCCESS, \"Started HDFS over FTP server.\");\n\t\t} catch (Exception e) {\n\t\t\treturn new Result(Result.Status.ERROR, \"Failed to start HDFS over FTP server.\", e);\n\t\t}\n\t} else {\n\t\treturn new Result(Result.Status.ERROR, \"HDFS over FTP server is already running.\");\n\t}\n}", "CodeBleu_score": 28.598881315317072}, {"code": "public Result start(){\n\t\tResult result = status()\n\tif (result.isSuccess()) {\n\t\treturn result\n\t}\n\tresult = startServer()\n\tif (result.isSuccess()) {\n\t\tresult = statusServer()\n\t}\n\treturn result\n}", "CodeBleu_score": 26.35905656760328}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (isServerRunning()) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"FTP server stopped successfully.\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error stopping FTP server: \" + e.getMessage());\n\t\t\treturn new Result(false, \"Error stopping FTP server: \" + e.getMessage());\n\t\t}\n\t} else {\n\t\treturn new Result(false, \"FTP server is not running.\");\n\t}\n}", "CodeBleu_score": 40.922606271114894}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (isRunning()) {\n\t\t\tftpServer.stop();\n\t\t\treturn new Result(true, \"FTP Server stopped successfully.\");\n\t\t} else {\n\t\t\treturn new Result(false, \"FTP Server is not running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error while stopping FTP Server.\", e);\n\t\treturn new Result(false, \"Error while stopping FTP Server.\");\n\t}\n}", "CodeBleu_score": 36.39453411208835}, {"code": "public Result stop(){\n\t\tif (isRunning()) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new Result(Result.SUCCESS, \"FTP server stopped\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Unable to stop FTP server\", e);\n\t\t\treturn new Result(Result.FAILURE, \"Unable to stop FTP server\");\n\t\t}\n\t}\n\treturn new Result(Result.SUCCESS, \"FTP server is not running\");\n}", "CodeBleu_score": 31.90402836500526}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.96809937919977}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.96809937919977}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.96809937919977}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\tFileSystem fs = null;\n\ttry {\n\t\tfs = FileSystem.get(conf);\n\t\treturn fs.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 64.79691970004873}, {"code": "public boolean mkdir(){\n\t\tFileSystem fileSystem = getFileSystem();\n\ttry {\n\t\treturn fileSystem.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.25618205081773}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fileSystem = FileSystem.get(new Configuration());\n\t\treturn fileSystem.mkdirs(fullPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 64.95949860683766}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\tFileSystem fs = getFileSystem();\n\tPath newPath = new Path(ftpFile.getParent().getPath().toString() + \"/\" + ftpFile.getName());\n\ttry {\n\t\tfs.rename(ftpFile.getPath(), newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 57.18198759461961}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fileSystem = FileSystem.get(new Configuration());\n\t\tPath newPath = new Path(getParent().getPath(), ftpFile.getName());\n\t\treturn fileSystem.rename(getPath(), newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.94712440327203}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tPath oldPath = new Path(ftpFile.getParent().getPath() + \"/\" + ftpFile.getName());\n\t\tPath newPath = new Path(ftpFile.getParent().getPath() + \"/\" + ftpFile.getName());\n\t\tfs.rename(oldPath, newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 60.60265228638539}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\tList<FtpFile> files = null;\n\n\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tFileStatus[] status = fs.listStatus(path);\n\n\t\tfiles = new ArrayList<FtpFile>(status.length);\n\n\t\tfor (FileStatus f : status) {\n\t\t\tfiles.add(new FtpFile(this, f));\n\t\t}\n\t} catch (IOException e) {\n\t\tlogger.error(\"IOException in listFiles: \" + e.getMessage());\n\t}\n\n\treturn Collections.unmodifiableList(files);\n}", "CodeBleu_score": 23.55089905956568}, {"code": "public List<FtpFile> listFiles(){\n\tList<FtpFile> files = null;\n\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\tfiles = new ArrayList<FtpFile>(status.length);\n\t\tfor (FileStatus file : status) {\n\t\t\tString fullName = file.getPath().toString();\n\t\t\tint filelen = fullName.length();\n\t\t\tif ((filelen!= 1) && (fullName.charAt(filelen - 1) == '/')) {\n\t\t\t\tfullName = fullName.substring(0, filelen - 1);\n\t\t\t}\n\t\t\tfiles.add(new FtpFile(fullName, file.isDirectory(), file.getLen()));\n\t\t}\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files in \" + path, e);\n\t}\n\treturn Collections.unmodifiableList(files);\n}", "CodeBleu_score": 34.908908289112496}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\t// Get the HDFS file system instance\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\t// List the status of files in the directory\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\t// Construct virtual file names based on the base directory's virtual path\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : status) {\n\t\t\tfiles.add(new FtpFile(this, file.getPath().getName()));\n\t\t}\n\t\t// Return an unmodifiable list of these FtpFile objects\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\t// Log the error\n\t\tlog.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 24.599667499426495}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tconfigured = true;\n\tuserDataProp = new Properties();\n\tFile userFile = new File(userDataPath);\n\tif (userFile.exists()) {\n\t\ttry {\n\t\t\tuserDataProp.load(new FileInputStream(userFile));\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to load user data from \" + userFile.getAbsolutePath(),\n\t\t\t\t\te);\n\t\t}\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 47.02657993727255}, {"code": "public void configure(){\n\t\tconfigured = true;\n\tuserDataProp = new Properties();\n\n\ttry {\n\t\tFile userDataFile = getUserDataFile();\n\n\t\tif (userDataFile.exists()) {\n\t\t\tFileInputStream fis = new FileInputStream(userDataFile);\n\t\t\tuserDataProp.load(fis);\n\t\t\tfis.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data from \" + getUserDataFile().getPath(),\n\t\t\t\te);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 58.7298740037681}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\n\tisConfigured = true;\n\n\tuserDataProp = new Properties();\n\n\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data from file: \" + userDataFile, e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 35.28458936788983}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tFile userDataFile = new File(userDirectory, USER_DATA_FILE);\n\tif (!userDataFile.getParentFile().exists() &&!userDataFile.getParentFile().mkdirs()) {\n\t\tthrow new ConfigurationException(\"Could not create directory \" + userDataFile.getParentFile().getAbsolutePath());\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserData.store(fos, null);\n\t} catch (IOException e) {\n\t\tLOGGER.error(\"Error saving user data\", e);\n\t\tthrow new FtpException(\"Error saving user data\", e);\n\t} finally {\n\t\tIOUtils.closeQuietly(fos);\n\t}\n}", "CodeBleu_score": 48.632790257856904}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile userDataFile = new File(userDataDir, userDataFileName);\n\tif (!userDataFile.getParentFile().exists()) {\n\t\tif (!userDataFile.getParentFile().mkdirs()) {\n\t\t\tthrow new FtpException(\"Failed to create directory: \" + userDataFile.getParentFile().getAbsolutePath());\n\t\t}\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tstore(fos);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Error writing user data to file: \" + userDataFile.getAbsolutePath());\n\t} finally {\n\t\tif (fos!= null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlogger.error(\"Error closing user data file: \" + userDataFile.getAbsolutePath(), e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 43.73022761457952}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile userDataFile = getUserDataFile();\n\tFile parentDir = userDataFile.getParentFile();\n\tif (!parentDir.exists() &&!parentDir.mkdirs()) {\n\t\tthrow new ConfigurationException(\"Failed to create directory: \" + parentDir.getAbsolutePath());\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tstore(fos);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t} finally {\n\t\tif (fos!= null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tLOG.error(\"Failed to close user data file: \" + userDataFile.getAbsolutePath(), e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.25927381305248}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManagerFactory = new HdfsUserManager();\n\t\tuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n\t\tuserManagerFactory.delete(user);\n\t\treturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 77.74143874051694}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManagerFactory = new HdfsUserManager();\n\t\tuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n\t\tuserManagerFactory.delete(user);\n\t\treturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 77.74143874051694}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManagerFactory = new HdfsUserManager();\n\t\tuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n\t\tuserManagerFactory.delete(user);\n\t\treturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 77.74143874051694}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tlog.debug(\"Opening file: \" + path + \" with buffer size: \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tFSDataInputStream fsDataInputStream = null;\n\ttry {\n\t\tfsDataInputStream = new FSDataInputStream(new SeaweedInputStream(store, qualifiedPath, bufferSize));\n\t} catch (Exception e) {\n\t\tlog.warn(\"Failed to open file: \" + qualifiedPath + \" with buffer size: \" + bufferSize, e);\n\t}\n\treturn fsDataInputStream;\n}", "CodeBleu_score": 32.60111240276142}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tString method = \"open\";\n\tlog.debug(method, \"path=\" + path + \", bufferSize=\" + bufferSize);\n\tpath = qualify(path);\n\tlog.debug(method, \"Qualified path=\" + path);\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = openFileForRead(path, bufferSize);\n\t\tlog.debug(method, \"Opened file for read\");\n\t} catch (IOException e) {\n\t\tlog.warn(method, \"Unable to open file for read\", e);\n\t\tthrow e;\n\t}\n\treturn in;\n}", "CodeBleu_score": 31.6936846061162}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\"Opening \" + path + \" with buffer size \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tLOG.debug(\"Qualified path is \" + qualifiedPath);\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = store.open(qualifiedPath, bufferSize);\n\t} catch (IOException e) {\n\t\tLOG.warn(\"Unable to open \" + qualifiedPath + \" for reading\", e);\n\t}\n\treturn in;\n}", "CodeBleu_score": 28.8978737649895}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 83.94906976433724}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\tif (src.isRoot()) {\n\t\treturn false;\n\t}\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\tFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\tPath adjustedDst = dst;\n\tif (entry!= null) {\n\t\tFileStatus dstFileStatus = getFileStatus(dst);\n\t\tString sourceFileName = src.getName();\n\t\tif (!dstFileStatus.isDirectory()) {\n\t\t\treturn false;\n\t\t}\n\t\tadjustedDst = new Path(dst, sourceFileName);\n\t}\n\tPath qualifiedSrcPath = qualify(src);\n\tPath qualifiedDstPath = qualify(adjustedDst);\n\tseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n\treturn true;\n}", "CodeBleu_score": 93.01236082576787}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 92.84785444656023}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn true;\n\t}\n\tif (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 41.40537022280631}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.equalsIgnoreCase(\"HSYNC\")) {\n\t\treturn supportSync;\n\t}\n\tif (capability.equalsIgnoreCase(\"HFLUSH\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 41.19340338361038}, {"code": "public boolean hasCapability(String capability){\n\t\treturn false;\n}", "CodeBleu_score": 6.236959909826931}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// Flush the bytes to the service.\n\tlong bytesToFlush = offset - lastFlushOffset;\n\tif (bytesToFlush > 0) {\n\t\t// Flush the bytes to the service.\n\t\tlong bytesWritten = 0;\n\t\twhile (bytesWritten < bytesToFlush) {\n\t\t\tbytesWritten += filerClient.write(offset + bytesWritten, bytesToFlush - bytesWritten, true, null);\n\t\t}\n\t\t// Update the last flush offset.\n\t\tlastFlushOffset = offset + bytesWritten;\n\t\t// Write metadata to the filer client.\n\t\twriteMeta();\n\t}\n}", "CodeBleu_score": 23.063552657169854}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\ttry {\n\t\tif (offset == 0) {\n\t\t\treturn;\n\t\t}\n\t\t// Flush the written bytes to the service starting from the offset.\n\t\tflushWrittenBytesToService(offset);\n\t\t// Write metadata to the filer client.\n\t\twriteMeta();\n\t\t// Update the last flush offset.\n\t\tlastFlushOffset = offset;\n\t} catch (IOException e) {\n\t\t// Throw an IOException if an exception occurs during the metadata write.\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 34.41636806718855}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t/ flip the buffer to prepare for reading\n\tbufferToWrite.flip();\n\t// calculate the byte length\n\tfinal int length = bufferToWrite.limit();\n\t// ensure the task queue is not overloaded\n\twaitForTaskToComplete();\n\t// submit a write task to the completion service\n\tfinal Future<Void> task = completionService.submit(new Callable<Void>() {\n\t\t@Override\n\t\tpublic Void call() throws Exception {\n\t\t\twriteData(bufferToWrite, writePosition);\n\t\t\treturn null;\n\t\t}\n\t});\n\t// record the write operation\n\twriteOperations.add(new WriteOperation(task, length));\n\t// manage the operation queue\n\tshrinkWriteOperationQueue();\n\t// return the number of bytes written\n\treturn length;\n}", "CodeBleu_score": 36.39793320631461}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tufferToWrite.flip();\n\tfinal int length = bufferToWrite.remaining();\n\tensureTaskQueueNotOverloaded();\n\tfinal Future<Integer> task = completionService.submit(new Callable<Integer>() {\n\t\t@Override\n\t\tpublic Integer call() throws Exception {\n\t\t\treturn writeData(bufferToWrite, writePosition);\n\t\t}\n\t});\n\twriteOperations.add(new WriteOperation(task, length));\n\treturn length;\n}", "CodeBleu_score": 30.51871233490921}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t/ Flip the buffer to prepare for reading\n\tbufferToWrite.flip();\n\t// Calculate the byte length of the buffer\n\tfinal int byteLength = bufferToWrite.remaining();\n\t// Ensure the task queue is not overloaded\n\tif (writeOperations.size() >= maxQueuedWriteOperations) {\n\t    waitForTaskToComplete();\n\t}\n\t// Submit a write task to the completion service\n\tfinal Future<Integer> writeTask = completionService.submit(new Callable<Integer>() {\n\t    @Override\n\t    public Integer call() throws IOException {\n\t\ttry {\n\t\t    return writeService.write(bufferToWrite, writePosition);\n\t\t} finally {\n\t\t    // Release the buffer\n\t\t    bufferToWrite.clear();\n\t\t}\n\t    }\n\t});\n\t// Record the write operation\n\twriteOperations.add(new WriteOperation(writeTask, byteLength));\n\t// Manage the operation queue\n\tshrinkWriteOperationQueue();\n\t// Return the number of bytes written\n\treturn byteLength;\n    }", "CodeBleu_score": 44.20657371602883}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\tboolean interrupted = false;\n\twhile (true) {\n\t\tFuture<String> result = completionService.poll();\n\t\tif (result == null) {\n\t\t\ttry {\n\t\t\t\tresult = completionService.take();\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tinterrupted = true;\n\t\t\t}\n\t\t}\n\t\tif (result!= null) {\n\t\t\ttry {\n\t\t\t\tresult.get();\n\t\t\t} catch (ExecutionException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t}\n\t\tif (interrupted) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow new IOException(\"Interrupted\");\n\t\t}\n\t}\n}", "CodeBleu_score": 32.74591017838369}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tFuture<String> result = completionService.poll();\n\t\tif (result == null) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(100);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t} else {\n\t\t\ttry {\n\t\t\t\tresult.get();\n\t\t\t} catch (ExecutionException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.27484205925595}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\tboolean done = false;\n\twhile (!done) {\n\t\ttry {\n\t\t\tFuture<String> completedTask = completionService.take();\n\t\t\tdone = true;\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 28.491271140154407}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (true) {\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op == null || op.isDone()) {\n\t\t\tif (op!= null) {\n\t\t\t\ttotalAppendOffset += op.getLength();\n\t\t\t}\n\t\t\twriteOperationQueue.remove();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 20.982189648918574}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation op = writeOperationQueue.peek();\n\t\tif (op.isDone()) {\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t\twriteOperationQueue.remove();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 24.327762342254992}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tif (writeOperationQueue.peek().isDone()) {\n\t\t\ttotalAppendOffset += writeOperationQueue.peek().getLength();\n\t\t\twriteOperationQueue.remove();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 26.33257821254552}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n\tif (this.homePath == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory cannot be null\");\n\t}\n}", "CodeBleu_score": 59.98399137245517}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User home directory cannot be null\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 68.39025613585503}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user.getHomeDirectory() cannot be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 74.59753900657485}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = Paths.get(dir);\n\t} else {\n\t\tnewPath = currentPath.resolve(dir);\n\t}\n\tif (newPath.toFile().isDirectory() &&!newPath.equals(newPath.getRoot())) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 18.628882565263392}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = Paths.get(dir);\n\tif (newPath.isAbsolute()) {\n\t\tcurrentPath = newPath;\n\t} else {\n\t\tcurrentPath = currentPath.resolve(newPath);\n\t}\n\tif (currentPath.toFile().isDirectory()) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 17.29269865089707}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = Paths.get(dir);\n\tif (newPath.isAbsolute()) {\n\t\tcurrentPath = newPath;\n\t} else {\n\t\tcurrentPath = currentPath.resolve(newPath);\n\t}\n\tif (currentPath.toFile().isDirectory()) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 17.29269865089707}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.conf = conf;\n\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.accessMode = conf.getAccessMode();\n\tthis.accessVolumeServerByPublicUrl = conf.getAccessVolumeServerByPublicUrl();\n\tthis.accessVolumeServerByFilerProxy = conf.getAccessVolumeServerByFilerProxy();\n}", "CodeBleu_score": 39.37065080561325}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.conf = conf;\n\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.filerClient.setAccessMode(conf.get(ACCESS_MODE_KEY, ACCESS_MODE_DEFAULT));\n}", "CodeBleu_score": 25.867661763008282}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tthis.filerClient = new FilerClient(host, port, grpcPort);\n\tthis.accessMode = conf.getAccessMode();\n}", "CodeBleu_score": 29.330076495221103}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nlog.debug(\"openFileForRead: \" + path);\n\nFilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, entry, path);\n\n}", "CodeBleu_score": 72.37685335498529}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tlog.info(\"openFileForRead: \" + path);\n\tFilerProto.Entry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(path.toString());\n\t}\n\treturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 69.1006181999441}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nlog.debug(\"openFileForRead: {}\", path);\n\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(path.toString());\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 69.12277238623726}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostName = \"localhost\";\n\t}\n\tthis.threadsPerMap = conf.getInt(\"threadsPerMap\", 1);\n\tthis.filesPerThread = conf.getInt(\"filesPerThread\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(this.threadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 52.67258204190415}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostname = \"localhost\";\n\t}\n\tthis.threadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.execution.thread.count\", 1);\n\tthis.filesPerThread = conf.getInt(\"mapred.map.tasks.speculative.execution.files.per.thread\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(threadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 49.86093398290932}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostname = \"localhost\";\n\t}\n\tthis.numThreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.execution.threads\", 1);\n\tthis.numFilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.execution.files.per.thread\", 1);\n\tthis.pool = Executors.newFixedThreadPool(this.numThreadsPerMap);\n\tfor (int i = 0; i < this.numThreadsPerMap; i++) {\n\t\tthis.pool.submit(new Thread(new SpeculativeExecutionThread(this.numFilesPerThread, this.conf, this.hostname)));\n\t}\n\tthis.pool.setDaemon(true);\n\tthis.pool.shutdown();\n}", "CodeBleu_score": 34.41161336884413}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n\t\treturn;\n\t}\n\ttry {\n\t\tUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n\t\temptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n\t\t\tJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n\t\t\tfs.initialize(uri, conf);\n\t\t\treturn fs;\n\t\t});\n\t\tBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n\t} catch (Exception e) {\n\t\tthrow new IOException(\"start trash failed!\",e);\n\t}\n}", "CodeBleu_score": 94.33486200671415}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tCheck if the trash emptier is already running for the specified host\nif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\n// Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\n// Start the trash emptier task using the initialized file system and the trash configuration, scheduling it to run every 10 minutes\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 88.52718430881573}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tCheck if the trash emptier is already running for the specified host\nif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\n// Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\n// Start the trash emptier task using the initialized file system and the trash configuration\n// Schedule it to run every 10 minutes\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 88.52718430881573}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\ttry {\n\t\t// Retrieve the current caller context and check its validity\n\t\tCallerContext callerContext = getCurrent();\n\t\tboolean isValid = isContextValid(callerContext);\n\n\t\tif (!isValid) {\n\t\t\t// If the current context is invalid or not set, create and set a new caller context\n\t\t\tCallerContext newContext = new CallerContext();\n\t\t\tnewContext.setContext(context);\n\t\t\tsetCurrent(newContext);\n\t\t} else {\n\t\t\t// If the current context is valid but lacks a signature and does not already include the provided context, append the new context to the existing one and set it\n\t\t\tif (callerContext.getSignature() == null &&!callerContext.getContext().contains(context)) {\n\t\t\t\tcallerContext.setContext(callerContext.getContext() + \"|\" + context);\n\t\t\t\tsetCurrent(callerContext);\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new Exception(\"Error setting caller context: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 33.9546483234116}, {"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getCurrent();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tString newContext = getContext(context);\n\t\tsetCurrent(newContext);\n\t} else {\n\t\tif (isContextValid(currentContext)) {\n\t\t\tString signature = getSignature(currentContext);\n\t\t\tif (signature == null || signature.isEmpty()) {\n\t\t\t\tString newContext = getContext(currentContext, context);\n\t\t\t\tsetCurrent(newContext);\n\t\t\t} else {\n\t\t\t\tString newContext = getContext(signature, context);\n\t\t\t\tsetCurrent(newContext);\n\t\t\t}\n\t\t} else {\n\t\t\tString newContext = getContext(context);\n\t\t\tsetCurrent(newContext);\n\t\t}\n\t}\n}", "CodeBleu_score": 32.15679300492944}, {"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"Context cannot be null\");\n\t}\n\tCallerContext callerContext = getCurrent();\n\tif (callerContext == null) {\n\t\tcallerContext = new CallerContext(context);\n\t\tsetCurrent(callerContext);\n\t} else if (callerContext.isValid()) {\n\t\tif (callerContext.getSignature() == null) {\n\t\t\tcallerContext.setSignature(context);\n\t\t} else if (!callerContext.getContext().endsWith(context)) {\n\t\t\tcallerContext.setContext(callerContext.getContext() + context);\n\t\t}\n\t} else {\n\t\tcallerContext.setContext(context);\n\t}\n}", "CodeBleu_score": 30.64263903949309}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t", "CodeBleu_score": 4.052206276703755}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef DEBUG\n  std::cout << \"HDFS::remove_file\" << std::endl;\n#endif\n  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  if (hdfsDelete(hdfs_, uri.to_path().c_str()) < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Unable to delete file '\") + uri.to_string() + \"'\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 53.54709104077527}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef HDFS_PARQUET_DEBUG\n  std::cout << \"HDFS::remove_file \" << uri.to_string() << std::endl;\n#endif\n  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  RETURN_NOT_OK(libhdfs_->hdfsDelete(hdfs_, uri.to_path().c_str()));\n  return Status::Ok();\n}", "CodeBleu_score": 49.53745915031587}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\t\tif (file == NULL) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot open file \" + uri.to_string() + \" for sync\"));\n\t\t}\n\t\tif (libhdfs_->hdfsHFlush(fs, file)!= 0) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot sync file \" + uri.to_string()));\n\t\t}\n\t\tif (libhdfs_->hdfsCloseFile(fs, file)!= 0) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot close file \" + uri.to_string()));\n\t\t}\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 53.63660837286943}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\t\tif (file == nullptr) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to open file for syncing\"));\n\t\t}\n\t\tif (libhdfs_->hdfsHFlush(fs, file) == -1) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to flush file\"));\n\t\t}\n\t\tif (libhdfs_->hdfsCloseFile(fs, file) == -1) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to close file\"));\n\t\t}\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 49.8177739186924}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\t\tif (file == NULL) {\n\t\t\tLOG_STATUS(Status_HDFSError(\"Cannot open file for sync\"));\n\t\t\treturn Status_HDFSError(\"Cannot open file for sync\");\n\t\t}\n\t\tret = libhdfs_->hdfsHFlush(fs, file);\n\t\tif (ret!= 0) {\n\t\t\tLOG_STATUS(Status_HDFSError(\"Cannot flush file for sync\"));\n\t\t\treturn Status_HDFSError(\"Cannot flush file for sync\");\n\t\t}\n\t\tret = libhdfs_->hdfsCloseFile(fs, file);\n\t\tif (ret!= 0) {\n\t\t\tLOG_STATUS(Status_HDFSError(\"Cannot close file for sync\"));\n\t\t\treturn Status_HDFSError(\"Cannot close file for sync\");\n\t\t}\n\t\treturn Status::Ok();\n\t} else {\n\t\treturn Status::Ok();\n\t}\n}", "CodeBleu_score": 52.8948571868783}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t", "CodeBleu_score": 3.187356454526044}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t", "CodeBleu_score": 3.187356454526044}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HDFS_DEBUG\n  std::cout << \"HDFS::file_size: \" << uri.to_string() << std::endl;\n#endif\n  RETURN_NOT_OK(connect(&hdfs_));\n  hdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(hdfs_, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot get file info\"));\n  }\n  if (!file_info->mKind == kObjectKindFile) {\n    return LOG_STATUS(Status_HDFSError(\"Path is not a file\"));\n  }\n  *nbytes = file_info->mSize;\n  libhdfs_->hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 53.844218172427595}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tPair<String, String> result = new Pair<String, String>();\n\tString quorum = \"\";\n\tString znodeParent = \"\";\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tfor (String cfg : hbaseCfg) {\n\t\tif (cfg.contains(\"zookeeper.quorum\")) {\n\t\t\tquorum = cfg.substring(cfg.indexOf(\"=\") + 1, cfg.length());\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum = quorum + \":2181\";\n\t\t\t}\n\t\t} else if (cfg.contains(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = cfg.substring(cfg.indexOf(\"=\") + 1, cfg.length());\n\t\t}\n\t}\n\tif (znodeParent.isEmpty()) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\tresult.setLeft(quorum);\n\tresult.setRight(znodeParent);\n\treturn result;\n}", "CodeBleu_score": 33.00337454648425}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString quorum = null;\n\tString znodeParent = null;\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tfor (String cfg : hbaseCfg) {\n\t\tString[] kv = cfg.split(\"=\");\n\t\tif (kv[0].equals(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = kv[1];\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum = quorum + \":2181\";\n\t\t\t}\n\t\t}\n\t\tif (kv[0].equals(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = kv[1];\n\t\t}\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 27.722907410307023}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString quorum = null;\n\tString znodeParent = null;\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tfor (String cfg : hbaseCfg) {\n\t\tString[] kv = cfg.split(\"=\");\n\t\tif (kv.length!= 2) {\n\t\t\tthrow new RuntimeException(\"Invalid HBase configuration string: \" + hbaseCfgString);\n\t\t}\n\t\tif (kv[0].equals(\"hbase.zookeeper.quorum\")) {\n\t\t\tquorum = kv[1];\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum += \":2181\";\n\t\t\t}\n\t\t} else if (kv[0].equals(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = kv[1];\n\t\t}\n\t}\n\tif (quorum == null) {\n\t\tthrow new RuntimeException(\"hbase.zookeeper.quorum not specified in HBase configuration string: \" + hbaseCfgString);\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 26.112543105019647}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t//\u83b7\u53d6\u8fde\u63a5\n\tConnection conn = getJdbcConnection(cfg);\n\t//\u83b7\u53d6\u8868\n\tString fullTableName = cfg.getFullTableName();\n\tString namespace = cfg.getNamespace();\n\tString tableName = cfg.getTableName();\n\t//\u6821\u9a8c\u8868\n\tcheckTable(conn, namespace, tableName, cfg.isThinClient());\n\t//\u83b7\u53d6\u8868\u7684\u5217\n\tList<Column> columns = getColumns(conn, fullTableName);\n\t//\u6821\u9a8c\u5217\n\tfor (HbaseSQLWriterColumn column : cfg.getColumns()) {\n\t\tString columnName = column.getColumnName();\n\t\tif (columnName.contains(\".\")) {\n\t\t\tcolumnName = columnName.replace(\".\", \":\");\n\t\t}\n\t\tColumn columnSchema = findColumn(columns, columnName);\n\t\tif (columnSchema == null) {\n\t\t\tthrow asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXISTS,\n\t\t\t\t\t\"Column \" + columnName + \" does not exist in table \" + fullTableName);\n\t\t}\n\t}\n}", "CodeBleu_score": 29.87806446863009}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\tString namespace = cfg.getNamespace();\n\t\tString tableName = cfg.getTableName();\n\t\tcheckTable(conn, namespace, tableName, cfg.isThinClient());\n\t\tPTable tableSchema = getTableSchema(conn, namespace + \".\" + tableName);\n\t\tList<Column> columns = getColumns(cfg);\n\t\tfor (Column column : columns) {\n\t\t\tString columnName = column.getName();\n\t\t\tif (!tableSchema.getColumns().containsKey(columnName)) {\n\t\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXIST,\n\t\t\t\t\t\t\"Column [\" + columnName + \"] does not exist in table [\" + tableName + \"]\");\n\t\t\t}\n\t\t}\n\t}\n\tcatch (AddaxException e) {\n\t\tthrow e;\n\t}\n\tcatch (Throwable e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n\t\t\t\t\"Unable to validate configuration for HbaseSQLWriter\", e);\n\t}\n\tfinally {\n\t\tif (conn!= null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t\tcatch (SQLException e) {\n\t\t\t\tLOG.warn(\"Unable to close JDBC connection\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 37.727022910873195}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(new Configuration());\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow new AddaxException(String.format(\"Kerberos login error: %s\", e.getMessage()), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 35.148269736137074}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\tConfiguration configuration = HadoopUtil.getHadoopConfiguration();\n\t\tUserGroupInformation.setConfiguration(configuration);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow AddaxException.asAddaxException(HadoopUtilErrorCode.KRB5_LOGIN_ERROR,\n\t\t\t\t\tString.format(\n\t\t\t\t\t\t\t\"Kerberos login error. Kerberos principal: %s, Kerberos keytab file path: %s\",\n\t\t\t\t\t\t\tkerberosPrincipal, kerberosKeytabFilePath));\n\t\t}\n\t}\n}", "CodeBleu_score": 49.41776280256537}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\ttry {\n\t\t\tConfiguration hadoopConf = HadoopConfiguration.get();\n\t\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tthrow DataXException.asAddaxException(HadoopWriterErrorCode.KERBEROS_LOGIN_ERROR,\n\t\t\t\t\tString.format(\"Kerberos login failed, kerberosPrincipal: %s, kerberosKeytabFilePath: %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 49.01959039251534}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\nMap<String, ThinClientPTable.ThinClientPColumn> cols = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\nResultSetMetaData meta = rs.getMetaData();\nint colsCount = meta.getColumnCount();\n\nfor (int i = 1; i <= colsCount; i++) {\nString colName = meta.getColumnLabel(i);\nif (colName == null) {\nthrow new SQLException(\"Column name is null\");\n}\nString colType = meta.getColumnTypeName(i);\nif (colType == null) {\nthrow new SQLException(\"Column type is null\");\n}\ncols.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\nreturn cols;\n}", "CodeBleu_score": 40.93884583067021}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colType = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnLabel(i);\nString colTypeStr = rsmd.getColumnTypeName(i);\nif (colName == null || colTypeStr == null) {\nthrow new SQLException(\"Error getting column type for column \" + i);\n}\ncolType.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colTypeStr));\n}\nreturn colType;\n}", "CodeBleu_score": 39.837033430787194}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colType = new HashMap<>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnLabel(i);\nif (colName == null || colName.isEmpty()) {\nthrow new SQLException(\"Invalid column name\");\n}\nString colTypeStr = rsmd.getColumnTypeName(i);\nif (colTypeStr == null || colTypeStr.isEmpty()) {\nthrow new SQLException(\"Invalid column type\");\n}\ncolType.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colTypeStr));\n}\nreturn colType;\n}", "CodeBleu_score": 40.25286088270621}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\tif (checkHdfsFileType(filePath, fileType)) {\n\t\tinfo(\"add source file \" + filePath);\n\t\tsourceFiles.add(filePath);\n\t} else {\n\t\tString message = String.format(\"The file type of [%s] is not [%s].\", filePath, fileType);\n\t\tLOG.error(message);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n\t}\n}", "CodeBleu_score": 32.478671235019455}, {"code": "private void addSourceFileByType(String filePath){\n\t\nif (checkHdfsFileType(filePath, fileType)) {\ninfo\nadd\nfilePath\nsourceFiles\n}\nelse {\nerror\nasAddaxException\nadd\nformat\n}\n}", "CodeBleu_score": 9.739403128166204}, {"code": "private void addSourceFileByType(String filePath){\n\tif (checkHdfsFileType(filePath, fileType)) {\ninfo\nadd\n}\nelse {\nerror\nasAddaxException\nadd\nformat\n}\n}", "CodeBleu_score": 7.673604563787697}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\ttaskPluginCollector.collectReaderStart();\nlogger.info(\"Start read sequence file, file path is : {}\", sourceSequenceFilePath);\nSequenceFile.Reader reader = null;\ntry {\nreader = new SequenceFile.Reader(new Path(sourceSequenceFilePath), readerSliceConfig);\nClass<?> keyClass = reader.getKeyClass();\nClass<?> valueClass = reader.getValueClass();\nlogger.info(\"The key class is : {}, the value class is : {}\", keyClass, valueClass);\nwhile (reader.next(key, value)) {\nif (StringUtils.isNotBlank(value.toString())) {\nStorageReaderUtil.transportOneRecord(recordSender, valueClass, value);\n}\n}\n} catch (Exception e) {\nlogger.error(e.getMessage(), e);\nthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n} finally {\nif (reader!= null) {\ntry {\nreader.close();\n} catch (IOException e) {\nlogger.error(e.getMessage(), e);\n}\n}\n}\ntaskPluginCollector.collectReaderSuccess();\n}", "CodeBleu_score": 48.86403445043066}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tlog.info(\"sequenceFileStartRead start, sourceSequenceFilePath:{}, readerSliceConfig:{}\", sourceSequenceFilePath, readerSliceConfig);\n\ntry {\nFileSystem fileSystem = FileSystem.get(URI.create(sourceSequenceFilePath), readerSliceConfig);\nPath path = new Path(sourceSequenceFilePath);\nSequenceFile.Reader reader = new SequenceFile.Reader(fileSystem, path, readerSliceConfig);\n\nClass<?> keyClass = reader.getKeyClass();\nClass<?> valueClass = reader.getValueClass();\n\nlog.info(\"sequenceFileStartRead start, sourceSequenceFilePath:{}, readerSliceConfig:{}, keyClass:{}, valueClass:{}\", sourceSequenceFilePath, readerSliceConfig, keyClass, valueClass);\n\nObject key = ReflectionUtils.newInstance(keyClass, readerSliceConfig);\nObject value = ReflectionUtils.newInstance(valueClass, readerSliceConfig);\n\nwhile (reader.next(key, value)) {\nString valueStr = String.valueOf(value);\nif (StringUtils.isNotBlank(valueStr)) {\nrecordSender.send(StorageReaderUtil.transportOneRecord(valueStr, readerSliceConfig));\n}\n}\n} catch (Exception e) {\nlog.error(e.getMessage(), e);\nthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n}\nlog.info(\"sequenceFileStartRead finish, sourceSequenceFilePath:{}\", sourceSequenceFilePath);\n}", "CodeBleu_score": 44.59943255777631}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tlog.info(\"start read sequence file from path:{}\", sourceSequenceFilePath);\nSequenceFile.Reader reader = null;\ntry {\nreader = new SequenceFile.Reader(new Path(sourceSequenceFilePath), readerSliceConfig);\nClass<?> keyClass = reader.getKeyClass();\nClass<?> valueClass = reader.getValueClass();\nlog.info(\"keyClass:{},valueClass:{}\", keyClass, valueClass);\nWritable key = (Writable) keyClass.newInstance();\nWritable value = (Writable) valueClass.newInstance();\nwhile (reader.next(key, value)) {\nString valueStr = value.toString();\nif (StringUtils.isNotBlank(valueStr)) {\nStorageReaderUtil.transportOneRecord(valueStr, recordSender, taskPluginCollector);\n}\n}\n} catch (Exception e) {\nlog.error(e.getMessage(), e);\nthrow DataXException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n} finally {\nif (reader!= null) {\ntry {\nreader.close();\n} catch (IOException e) {\nlog.error(e.getMessage(), e);\n}\n}\n}\n}", "CodeBleu_score": 45.60959151351432}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t try {\n//        Path path = new Path(filepath);\n//        FileSystem fs = path.getFileSystem(hadoopConf);\n//        FSDataInputStream in = fs.open(path);\n//        if (specifiedFileType.equalsIgnoreCase(\"orc\")) {\n//            return isORCFile(path, fs, in);\n//        }\n//        else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\n//            return isRCFile(filepath, in);\n//        }\n//        else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\n//            return isSequenceFile(path, in);\n//        }\n//        else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\n//            return isParquetFile(path);\n//        }\n//        else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\n//            return isCsvFile(filepath, in);\n//        }\n//        else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\n//            return isTextFile(filepath, in);\n//        }\n//        else {\n//            return false;\n//        }\n//    }\n//    catch (IOException e) {\n//        LOG.error(\"The file [{}] is not {} file.\", filepath, specifiedFileType);\n//        throw DataXException.asDataXException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n//    }\n}", "CodeBleu_score": 2.4376048724537416}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tystem fs = null;\n\tFSDataInputStream in = null;\n\ttry {\n\t\tPath file = new Path(filepath);\n\t\tfs = file.getFileSystem(hadoopConf);\n\t\tin = fs.open(file);\n\t\tif (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n\t\t\treturn isORCFile(file, fs, in);\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n\t\t\treturn isRCFile(filepath, in);\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"SEQUENCE\")) {\n\t\t\treturn isSequenceFile(file, in);\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"PARQUET\")) {\n\t\t\treturn isParquetFile(file);\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n\t\t\treturn true;\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"TEXT\")) {\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tthrow DataXException.asDataXException(HdfsReaderErrorCode.READER_CHECK_HDFS_FILE_TYPE_ERROR, e);\n\t}\n\tfinally {\n\t\tif (in!= null) {\n\t\t\ttry {\n\t\t\t\tin.close();\n\t\t\t}\n\t\t\tcatch (IOException e) {\n\t\t\t\tLOG.warn(\"close the FSDataInputStream failed.\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 48.4986598837166}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tString specifiedFileType = \"orc\";\n    FileSystem fs = null;\n    FSDataInputStream in = null;\n    try {\n        Path path = new Path(filepath);\n        fs = path.getFileSystem(hadoopConf);\n        in = fs.open(path);\n        if (specifiedFileType.equalsIgnoreCase(\"orc\")) {\n            return isORCFile(path, fs, in);\n        }\n        else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\n            return isRCFile(filepath, in);\n        }\n        else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\n            return isSequenceFile(path, in);\n        }\n        else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\n            return isParquetFile(path);\n        }\n        else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\n            return true;\n        }\n        else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    catch (IOException e) {\n        throw DataXException.asAddaxException(HdfsReaderErrorCode.HDFS_READER_CHECK_FILE_TYPE_ERROR, e);\n    }\n    finally {\n        try {\n            if (in!= null) {\n                in.close();\n            }\n            if (fs!= null) {\n                fs.close();\n            }\n        }\n        catch (IOException e) {\n            LOG.error(\"close file error\", e);\n        }\n    }\n}", "CodeBleu_score": 48.713933948194246}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new asAddaxException(asAddaxException.ERROR_CODE_HBASE_CONNECTION_CLOSE_FAILED, e.getMessage());\n\t}\n}", "CodeBleu_score": 46.319892355242764}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(e, asAddaxException.CLOSE_CONNECTION_ERROR);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.36901824391923}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close()\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(\"Unable to close HBase connection. \" + e.getMessage(), asAddaxExceptionCodes.HBASE_CONNECTION_CLOSE_ERROR)\n\t\t}\n\t}\n}", "CodeBleu_score": 39.52142753245567}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_CLOSE_ADMIN_ERROR, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.45674702136696}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_CLOSE_ADMIN_ERROR, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.45674702136696}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close()\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxErrorCode.HBASE_ADMIN_CLOSE_ERROR, e)\n\t\t}\n\t}\n}", "CodeBleu_score": 41.995541102030245}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Extract the row key, timestamp, family, qualifier, and value from the cell\nbyte[] rowKeyBytes = cell.getRowArray();\nint rowKeyOffset = cell.getRowOffset();\nint rowKeyLength = cell.getRowLength();\nbyte[] rowKey = Bytes.copy(rowKeyBytes, rowKeyOffset, rowKeyLength);\n\nlong timestamp = cell.getTimestamp();\n\nbyte[] familyBytes = cell.getFamilyArray();\nint familyOffset = cell.getFamilyOffset();\nint familyLength = cell.getFamilyLength();\nbyte[] family = Bytes.copy(familyBytes, familyOffset, familyLength);\n\nbyte[] qualifierBytes = cell.getQualifierArray();\nint qualifierOffset = cell.getQualifierOffset();\nint qualifierLength = cell.getQualifierLength();\nbyte[] qualifier = Bytes.copy(qualifierBytes, qualifierOffset, qualifierLength);\n\nbyte[] valueBytes = cell.getValueArray();\nint valueOffset = cell.getValueOffset();\nint valueLength = cell.getValueLength();\nbyte[] value = Bytes.copy(valueBytes, valueOffset, valueLength);\n\n// Convert the row key and value to the appropriate types\nObject rowKeyValue = convertBytesToAssignType(rowKey, rowKeyTypes[0]);\nObject valueValue = convertBytesToAssignType(value, valueTypes[0]);\n\n// Add the columns to the record\nrecord.addColumn(rowKeyColumnFamily, rowKeyColumnName, rowKeyValue);\nrecord.addColumn(familyColumnFamily, familyColumnName, family);\nrecord.addColumn(qualifierColumnFamily, qualifierColumnName, qualifier);\nrecord.addColumn(timestampColumnFamily, timestampColumnName, timestamp);\nrecord.addColumn(valueColumnFamily, valueColumnName, valueValue);\n}", "CodeBleu_score": 31.16541971932615}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// get row key\nString rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n// get timestamp\nlong timestamp = cell.getTimestamp();\n// get column family\nString family = Bytes.toString(CellUtil.cloneFamily(cell));\n// get qualifier\nString qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n// get column value\nObject value = null;\nString valueType = null;\nString valueFormat = null;\n// determine value type and format\nif (family.equals(\"info\")) {\nvalueType = \"string\";\nvalueFormat = \"string\";\n} else if (family.equals(\"data\")) {\nvalueType = \"string\";\nvalueFormat = \"string\";\n} else if (family.equals(\"meta\")) {\nvalueType = \"string\";\nvalueFormat = \"string\";\n} else {\nvalueType = \"string\";\nvalueFormat = \"string\";\n}\n// convert value to appropriate type\nif (valueType.equals(\"string\")) {\nvalue = Bytes.toString(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"long\")) {\nvalue = Bytes.toLong(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"double\")) {\nvalue = Bytes.toDouble(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"float\")) {\nvalue = Bytes.toFloat(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"boolean\")) {\nvalue = Bytes.toBoolean(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"byte\")) {\nvalue = Bytes.toByte(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"short\")) {\nvalue = Bytes.toShort(CellUtil.cloneValue(cell));\n} else if (valueType.equals(\"int\")) {\nvalue = Bytes.toInt(CellUtil.cloneValue(cell));\n} else {\nvalue = Bytes.toString(CellUtil.cloneValue(cell));\n}\n// add columns to record\nrecord.set(\"rowKey\", rowKey);\nrecord.set(\"timestamp\", timestamp);\nrecord.set(\"family\", family);\nrecord.set(\"qualifier\", qualifier);\nrecord.set(\"value\", value);\n}", "CodeBleu_score": 27.080736939435575}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key from the cell\nbyte[] rowKeyBytes = CellUtil.cloneRow(cell);\nString rowKey = Bytes.toString(rowKeyBytes);\n// Get the timestamp from the cell\nlong timestamp = cell.getTimestamp();\n// Get the column family name from the cell\nbyte[] familyBytes = CellUtil.cloneFamily(cell);\nString family = Bytes.toString(familyBytes);\n// Get the qualifier name from the cell\nbyte[] qualifierBytes = CellUtil.cloneQualifier(cell);\nString qualifier = Bytes.toString(qualifierBytes);\n// Get the value from the cell\nbyte[] valueBytes = CellUtil.cloneValue(cell);\nString value = Bytes.toString(valueBytes);\n// Convert the row key to the appropriate type and format\nString rowKeyConverted = convertBytesToAssignType(rowKeyBytes, rowKeyType, rowKeyFormat);\n// Convert the value to the appropriate type and format\nString valueConverted = convertBytesToAssignType(valueBytes, valueType, valueFormat);\n// Add the columns to the record\nrecord.add(new Column(\"rowKey\", rowKeyConverted));\nrecord.add(new Column(\"family\", family));\nrecord.add(new Column(\"qualifier\", qualifier));\nrecord.add(new Column(\"timestamp\", timestamp));\nrecord.add(new Column(\"value\", valueConverted));\n}", "CodeBleu_score": 33.79536741648535}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.get(HBaseConstants.START_ROW_KEY);\nif (isBlank(startRowKey)) {\nreturn new byte[0];\n}\nboolean isBinaryRowkey = configuration.getBoolean(HBaseConstants.IS_BINARY_ROWKEY, false);\nreturn stringToBytes(startRowKey, isBinaryRowkey);\n}", "CodeBleu_score": 50.31303758337744}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HBASE_START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn stringToBytes(startRowkey, configuration.getBoolean(HBASE_ROWKEY_IS_BINARY, false));\n}", "CodeBleu_score": 29.05824628599617}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\n\tboolean isBinaryRowkey = getBool(configuration, IS_BINARY_ROWKEY, false);\n\treturn stringToBytes(startRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 40.40827994733638}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HBaseConstants.START_ROWKEY)\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0]\n\t}\n\treturn toBytesBinary(startRowkey)\n}", "CodeBleu_score": 49.35869114842225}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 42.97930523872383}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (isBlank(startRowkey)) {\n\t\treturn EMPTY_BYTE_ARRAY;\n\t}\n\treturn toBytesBinary(startRowkey);\n}", "CodeBleu_score": 46.57619711632052}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(h -> headers.put(h.key(), h.value()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 49.23563574349973}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tkey = UUID.fromString(record.key());\n\theaders = new TbQueueMsgHeaders();\n\trecord.headers().forEach(h -> headers.put(h.key(), h.value()));\n\tvalue = record.value();\n}", "CodeBleu_score": 37.44520825599898}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\trecord.headers().forEach(h -> headers.put(h.key(), h.value()));\n\tthis.data = record.value();\n}", "CodeBleu_score": 49.23563574349973}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tString clientId = getServiceId() + \"-transport-notifications\";\n\tKafkaProducerSettings settings = transportNotificationsSettings.getKafkaProducerSettings();\n\tString defaultTopic = transportNotificationsSettings.getKafkaProducerSettings().getTopic();\n\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = createProducer(clientId, settings, defaultTopic);\n\tproducer.setAdmin(admin);\n\treturn producer;\n}", "CodeBleu_score": 41.8288391659688}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(\n\t\t\tkafkaTemplateBuilder.build(\n\t\t\t\t\tkafkaSettings.getTransportNotifications().getTopicName(),\n\t\t\t\t\tkafkaSettings.getTransportNotifications().getPartitions(),\n\t\t\t\t\tkafkaSettings.getTransportNotifications().getReplicationFactor(),\n\t\t\t\t\tkafkaSettings.getTransportNotifications().getRetentionMs(),\n\t\t\t\t\tkafkaSettings.getTransportNotifications().getRetentionBytes()\n\t\t\t),\n\t\t\tkafkaSettings.getTransportNotifications().getTopicName(),\n\t\t\tclientId + \"_transport_notifications\",\n\t\t\tkafkaSettings.getTransportNotifications().getPartitions(),\n\t\t\tkafkaSettings.getTransportNotifications().getReplicationFactor()\n\t);\n\tproducer.setAdmin(admin);\n\treturn producer;\n}", "CodeBleu_score": 37.3707602247429}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<String, TbProtoQueueMsg<ToCoreNotificationMsg>> kafkaConsumerTemplate = new TbKafkaConsumerTemplate<>(\n\t\t\tTbKafkaConsumerTemplate.Type.TO_CORE_NOTIFICATIONS,\n\t\t\tkafkaService.getSettings(),\n\t\t\tkafkaService.getTopicName(TbKafkaConsumerTemplate.Type.TO_CORE_NOTIFICATIONS),\n\t\t\tkafkaService.getSettings().getKafkaClientId(),\n\t\t\tkafkaService.getSettings().getKafkaConsumerGroupId(),\n\t\t\tnew TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class),\n\t\t\tkafkaService.getAdmin(),\n\t\t\tstatisticsService);\n\treturn kafkaConsumerTemplate;\n}", "CodeBleu_score": 29.517705519083187}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(\n\t\t\tkafkaConsumerSettings,\n\t\t\tbuildTopicName(ToCoreNotificationMsg.class),\n\t\t\tclientId,\n\t\t\tgroupId);\n\ttemplate.setMessageDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\n\ttemplate.setAdmin(admin);\n\ttemplate.setStatisticsService(statsService);\n\treturn template;\n}", "CodeBleu_score": 23.04221094571952}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n\t\t\tTbKafkaConsumerTemplate.KafkaConsumerType.TO_CORE_NOTIFICATIONS,\n\t\t\tkafkaService.getToCoreNotificationsTopic(),\n\t\t\tkafkaService.getClientId(),\n\t\t\tkafkaService.getGroupId(),\n\t\t\tkafkaService.getKafkaSettings(),\n\t\t\tnew TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class)\n\t);\n\tconsumerTemplate.setAdmin(kafkaService.getAdmin());\n\tconsumerTemplate.setStatisticsService(kafkaService.getStatisticsService());\n\treturn consumerTemplate;\n}", "CodeBleu_score": 31.113465952566877}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tconsumer.unsubscribe();\n\t}\n\telse {\n\t\tSet<String> topics = new HashSet<>(topicNames);\n\t\tconsumer.subscribe(topics);\n\t\tfor (String topic : topicNames) {\n\t\t\tif (!this.adminTemplate.topicExists(topic)) {\n\t\t\t\tlog.info(\"Creating topic: \" + topic);\n\t\t\t\tthis.adminTemplate.createTopic(topic);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 52.98788023836731}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tunsubscribe();\n\t}\n\telse {\n\t\ttopicNames.forEach(this::ensureTopicExists);\n\t\tsubscribe(topicNames);\n\t}\n}", "CodeBleu_score": 26.60210055395278}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (!topicNames.isEmpty()) {\n\t\t// Ensure topics exist\n\t\ttopicNames.each { topicName ->\n\t\t\tif (!this.topicExists(topicName)) {\n\t\t\t\tthis.createTopic(topicName)\n\t\t\t}\n\t\t}\n\t\t// Subscribe to topics\n\t\tthis.subscribe(topicNames)\n\t} else {\n\t\t// Log info and unsubscribe\n\t\tthis.logger.info(\"No topic names provided for subscription. Unsubscribing from all topics.\")\n\t\tthis.unsubscribe()\n\t}\n}", "CodeBleu_score": 53.7851619350147}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis()\n\tlogger.trace(\"Polling topic {} for {} ms\", topic, durationInMillis)\n\tlong endTime = startTime + durationInMillis\n\tList<ConsumerRecord<String, byte[]>> records = []\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tConsumerRecords<String, byte[]>> pollResult = consumer.poll(ofMillis(100))\n\t\tif (pollResult.isEmpty()) {\n\t\t\tlogger.trace(\"No records found\")\n\t\t\tbreak\n\t\t}\n\t\tpollResult.forEach(records::add)\n\t}\n\tlong totalTime = System.currentTimeMillis() - startTime\n\tlogger.trace(\"Polling took {} ms\", totalTime)\n\tif (records.isEmpty()) {\n\t\tlogger.trace(\"No records found\")\n\t\treturn Collections.emptyList()\n\t}\n\treturn records\n}", "CodeBleu_score": 45.09088721551622}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlog.trace(\"doPoll: durationInMillis={}\", durationInMillis);\n\tStopWatch stopWatch = new StopWatch();\n\tstopWatch.start();\n\tlog.debug(\"doPoll: starting poll for topic={} and duration={}\", getTopic(), durationInMillis);\n\tconsumer.poll(ofMillis(durationInMillis));\n\tstopWatch.stop();\n\tlog.debug(\"doPoll: finished poll for topic={} and duration={}; total time taken={}\", getTopic(), durationInMillis, stopWatch.getTotalTimeMillis());\n\tif (consumer.isEmpty()) {\n\t\tlog.trace(\"doPoll: returning empty list\");\n\t\treturn Collections.emptyList();\n\t}\n\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tconsumer.forEach(records::add);\n\tlog.trace(\"doPoll: returning {} records\", records.size());\n\treturn records;\n}", "CodeBleu_score": 50.910492979681955}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tlogger.trace(\"Polling topic {} for {} ms\", topic, durationInMillis);\n\tConsumerRecords<String, byte[]> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlong totalTime = endTime - startTime;\n\tlogger.trace(\"Polling topic {} for {} ms took {} ms\", topic, durationInMillis, totalTime);\n\tif (records.isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\treturn records.iterator().collect(Collectors.toList());\n}", "CodeBleu_score": 43.965900230001786}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (initError!= null) {\n\t\t\tlog.warn(\"[{}] Initialization error: {}\", ctx.getSelfId(), initError);\n\t\t\tctx.tellFailure(initError);\n\t\t\treturn;\n\t\t}\n\n\t\tif (msg.getMetaData().containsKey(TB_MSG_MD_ACK_KEY)) {\n\t\t\tctx.ackIfNeeded(msg);\n\t\t\treturn;\n\t\t}\n\n\t\tString topic = processTopicPattern(ctx, msg);\n\t\tString key = processKeyPattern(ctx, msg);\n\n\t\tctx.executeAsync(() -> publish(ctx, msg, topic, key));\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.tellFailure(e);\n\t}\n}", "CodeBleu_score": 31.73482735947764}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (!initialized) {\n\t\t\tlog.error(\"[{}] Failed to initialize rule node\", ctx.getSelfId());\n\t\t\tctx.tellFailure(msg, new RuntimeException(\"Failed to initialize rule node\"));\n\t\t\treturn;\n\t\t}\n\n\t\tString topicPattern = getTopicPattern(ctx, msg);\n\t\tString keyPattern = getKeyPattern(ctx, msg);\n\n\t\tctx.getExternalCallExecutor().executeAsync(() -> {\n\t\t\ttry {\n\t\t\t\tpublish(ctx, msg, topicPattern, keyPattern);\n\t\t\t\tctx.ackIfNeeded(msg);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\t\t\tctx.tellFailure(msg, e);\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.tellFailure(msg, e);\n\t}\n}", "CodeBleu_score": 37.260200671143096}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (initError!= null) {\n\t\t\tlog.error(\"[{}] Failed to initialize rule node: {}\", ctx.getSelfId(), initError);\n\t\t\tctx.tellFailure(initError);\n\t\t\treturn;\n\t\t}\n\t\texecuteAsync(ctx, msg);\n\t} catch (Exception e) {\n\t\tlog.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.tellFailure(e);\n\t}\n}", "CodeBleu_score": 20.96495688251925}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (key!= null &&!key.isEmpty()) {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\theaders.put(METADATA_KEY, msg.getMetadata().toJson());\n\t\t\tpublish(ctx, msg, topic, key, headers, (ctx1, msg1, metadata, e) -> {\n\t\t\t\tif (e == null) {\n\t\t\t\t\ttellSuccess(ctx1, processResponse(msg1, metadata));\n\t\t\t\t} else {\n\t\t\t\t\ttellFailure(ctx1, processException(msg1, e), e);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\tpublish(ctx, msg, topic, key, (ctx1, msg1, metadata, e) -> {\n\t\t\t\tif (e == null) {\n\t\t\t\t\ttellSuccess(ctx1, processResponse(msg1, metadata));\n\t\t\t\t} else {\n\t\t\t\t\ttellFailure(ctx1, processException(msg1, e), e);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t} else {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\theaders.put(METADATA_KEY, msg.getMetadata().toJson());\n\t\t\tpublish(ctx, msg, topic, headers, (ctx1, msg1, metadata, e) -> {\n\t\t\t\tif (e == null) {\n\t\t\t\t\ttellSuccess(ctx1, processResponse(msg1, metadata));\n\t\t\t\t} else {\n\t\t\t\t\ttellFailure(ctx1, processException(msg1, e), e);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\tpublish(ctx, msg, topic, (ctx1, msg1, metadata, e) -> {\n\t\t\t\tif (e == null) {\n\t\t\t\t\ttellSuccess(ctx1, processResponse(msg1, metadata));\n\t\t\t\t} else {\n\t\t\t\t\ttellFailure(ctx1, processException(msg1, e), e);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n}", "CodeBleu_score": 31.777219859374018}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (key!= null) {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = getMetaData(msg);\n\t\t\tif (!headers.isEmpty()) {\n\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, new RecordMetadata(new TopicPartition(topic, 0), 0, 0, 0, 0, 0, 0)));\n\t\t\t} else {\n\t\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception e) {\n\t\t\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, metadata));\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception e) {\n\t\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, metadata));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t} else {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = getMetaData(msg);\n\t\t\tif (!headers.isEmpty()) {\n\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, new RecordMetadata(new TopicPartition(topic, 0), 0, 0, 0, 0, 0, 0)));\n\t\t\t} else {\n\t\t\t\tproducer.send(new ProducerRecord<>(topic, msg.getData()), new Callback() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception e) {\n\t\t\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, metadata));\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, msg.getData()), new Callback() {\n\t\t\t\t@Override\n\t\t\t\tpublic void onCompletion(RecordMetadata metadata, Exception e) {\n\t\t\t\t\tctx.tellSuccess(ctx.processResponse(msg, metadata));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n}", "CodeBleu_score": 30.325800887644395}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (key!= null) {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\theaders.put(METADATA_KEY, msg.getMetaData().toString());\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), headers, (recordMetadata, exception) -> processRecord(ctx, msg, recordMetadata, exception));\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), (recordMetadata, exception) -> processRecord(ctx, msg, recordMetadata, exception));\n\t\t}\n\t} else {\n\t\tif (addMetaData) {\n\t\t\tMap<String, String> headers = new HashMap<>();\n\t\t\theaders.put(METADATA_KEY, msg.getMetaData().toString());\n\t\t\tproducer.send(new ProducerRecord<>(topic, msg.getData()), headers, (recordMetadata, exception) -> processRecord(ctx, msg, recordMetadata, exception));\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, msg.getData()), (recordMetadata, exception) -> processRecord(ctx, msg, recordMetadata, exception));\n\t\t}\n\t}\n}", "CodeBleu_score": 43.45494279402886}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.31318402746789}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.31318402746789}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.14510470097976}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\treturn createKafkaProducer(\n\t\t\tkafkaSettings,\n\t\t\tclientId,\n\t\t\tdefaultTopic,\n\t\t\tadmin,\n\t\t\tsettings,\n\t\t\tgetServiceId(),\n\t\t\tbuilder -> builder.keySerializer(StringSerializer.class).valueSerializer(ToRuleEngineMsgSerializer.class)\n\t);\n}", "CodeBleu_score": 24.881466591596773}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tString clientId = serviceInfoProvider.getServiceId();\n\tKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>>(\n\t\t\tkafkaSettings,\n\t\t\tclientId,\n\t\t\tToRuleEngineMsg.class,\n\t\t\tToRuleEngineMsg.class,\n\t\t\tadmin,\n\t\t\tclientId\n\t);\n\tbuilder.setDefaultTopic(buildTopicName(RULE_ENGINE_TOPIC_PREFIX, DEFAULT_TOPIC_NAME));\n\treturn builder.build();\n}", "CodeBleu_score": 43.894667756916775}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tmeout = getKafkaResponseTimeoutMs() / 2;\nscheduleWithFixedDelay(timeout, timeout, TimeUnit.MILLISECONDS, () -> {\nif (isStatsPrintRequired()) {\nfor (String groupId : consumerGroupIds) {\ntry {\nMap<TopicPartition, OffsetAndMetadata> groupOffsets = listConsumerGroupOffsets(groupId);\nMap<TopicPartition, Long> endOffsets = endOffsets(groupOffsets.keySet());\nList<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\nif (!consumerGroupStats.isEmpty()) {\nlog.info(\"Kafka consumer group [{}] has the following topics with lag: {}\", groupId, consumerGroupStats);\n}\n} catch (Exception e) {\nlog.warn(\"Failed to retrieve consumer group offsets for group [{}]. Error: {}\", groupId, e.getMessage(), e);\n}\n}\n}\n});\n}", "CodeBleu_score": 26.961375260142923}, {"code": "private void startLogScheduling(){\n\ta timeout duration based on the Kafka response timeout configuration\nDuration timeout = Duration.ofMillis(kafkaProperties.getKafkaResponseTimeoutMs());\n// Schedule a task with a fixed delay\nlog.info(\"Starting Kafka consumer group stats logging with a fixed delay of {} ms\", getPrintIntervalMs());\nexecutorService.scheduleWithFixedDelay(() -> {\n    try {\n        if (isStatsPrintRequired()) {\n            for (String groupId : consumerGroups) {\n                Map<TopicPartition, OffsetAndMetadata> groupOffsets = adminClient.listConsumerGroupOffsets(groupId).partitionsToOffsetAndMetadata();\n                Map<TopicPartition, Long> endOffsets = adminClient.endOffsets(groupOffsets.keySet());\n                List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n                if (!consumerGroupStats.isEmpty()) {\n                    log.info(\"Kafka consumer group [{}] stats: {}\", groupId, consumerGroupStats);\n                }\n            }\n        }\n    } catch (Exception e) {\n        log.warn(\"Failed to retrieve Kafka consumer group stats for group [{}]. Error: {}\", groupId, e.getMessage(), e);\n    }\n}, getPrintIntervalMs(), getPrintIntervalMs(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 37.708534596179454}, {"code": "private void startLogScheduling(){\n\ta timeout duration based on the Kafka response timeout configuration\nlong timeout = kafkaProperties.getKafkaResponseTimeoutMs();\n// Schedule a task with a fixed delay\nlogScheduler.scheduleWithFixedDelay(new Runnable() {\n@Override\npublic void run() {\n// Check if statistics printing is required\nif (isStatsPrintRequired()) {\n// For each monitored consumer group\nfor (String groupId : consumerGroupIds) {\ntry {\n// Retrieve and compare group offsets and end offsets\nMap<TopicPartition, OffsetAndMetadata> groupOffsets = adminClient.listConsumerGroupOffsets(groupId).partitionsToOffsetAndMetadata();\nMap<TopicPartition, Long> endOffsets = adminClient.endOffsets(groupOffsets.keySet());\n// Identify topics with lag\nList<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n// Log details of lagging topics\nif (!consumerGroupStats.isEmpty()) {\nlog.info(\"Group {} has lagging topics: {}\", groupId, consumerGroupStats);\n}\n} catch (Exception e) {\n// Log a warning with the group ID and error message, along with a detailed error trace\nlog.warn(\"Error while getting consumer group offsets for group {}: {}\", groupId, e.getMessage(), e);\n}\n}\n}\n}\n}, 0, getPrintIntervalMs(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 31.835603754914843}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n\n\tprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n\tprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\n\n\treturn props;\n}", "CodeBleu_score": 89.99215560999315}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n\n\tprops.put(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n\tprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);\n\n\treturn props;\n}", "CodeBleu_score": 74.93908302252915}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(scopedName, tags, metric);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Metric type not supported: {}\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 46.95314711964787}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(metric, scopedName, tags);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: {}\", metric.getClass());\n\t}\n}", "CodeBleu_score": 46.65032429569532}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(scopedName, tags);\n\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Metric type {} is not supported.\", metric.getClass().getSimpleName());\n\t}\n}", "CodeBleu_score": 46.635543450651106}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tdef value = gauge.getValue()\n\tif (metricEvent.getFields()) {\n\t\tmetricEvent.addField(field, value)\n\t} else {\n\t\tdef fields = [:]\n\t\tfields.put(field, value)\n\t\tmetricEvent.setFields(fields)\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 24.535819636509704}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tdef value = gauge.getValue()\n\tif (metricEvent.fields) {\n\t\tif (value instanceof Number) {\n\t\t\tmetricEvent.fields.put(field, value)\n\t\t} else {\n\t\t\tmetricEvent.fields.put(field, value.toString())\n\t\t}\n\t} else {\n\t\tmetricEvent.fields = [(field): (value instanceof Number? value : value.toString())]\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 29.678644720538223}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tdef value = gauge.getValue()\n\tif (metricEvent.getFields()) {\n\t\tmetricEvent.addField(field, value)\n\t} else {\n\t\tdef fields = [:]\n\t\tfields[field] = value\n\t\tmetricEvent.setFields(fields)\n\t}\n\treturn metricEvent\n}", "CodeBleu_score": 24.991209049920542}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Extract the Kafka lag metrics from the Gauge object.\n\tMap<String, String> kafkaLagMetrics = (Map<String, String>) gauge.getValue();\n\n\t// Split the Kafka lag metrics into components.\n\tString currentOffsets = kafkaLagMetrics.get(\"current-offsets\");\n\tString dataTimestamp = kafkaLagMetrics.get(\"data-timestamp\");\n\tString committedOffsets = kafkaLagMetrics.get(\"committed-offsets\");\n\n\t// Check for changes in the Kafka lag metrics to avoid duplicates.\n\tString kafkaLagTimesKey = currentOffsets + dataTimestamp + committedOffsets;\n\tif (kafkaLagTimes.containsKey(kafkaLagTimesKey)) {\n\t\treturn metricEvent;\n\t}\n\n\t// Update the kafkaLagTimes map.\n\tkafkaLagTimes.put(kafkaLagTimesKey, timestamp);\n\n\t// Set the event's timestamp.\n\tmetricEvent.setTimestamp(timestamp);\n\n\t// Add the Kafka lag metrics to the MetricEvent's fields.\n\tmetricEvent.addField(\"currentOffsets\", currentOffsets);\n\tmetricEvent.addField(\"dataTimestamp\", dataTimestamp);\n\tmetricEvent.addField(\"committedOffsets\", committedOffsets);\n\n\treturn metricEvent;\n}", "CodeBleu_score": 31.671527800395}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Split the gauge value into components\n\tString[] components = gauge.getValue().toString().split(\",\");\n\t// Extract the current offsets, data timestamp, and committed offsets\n\tLong currentOffsets = Long.parseLong(components[0]);\n\tLong dataTimestamp = Long.parseLong(components[1]);\n\tLong committedOffsets = Long.parseLong(components[2]);\n\t// Check for changes in the Kafka lag metrics\n\tif (kafkaLagTimes.get(metricEvent.getMetricGroup().getName())!= null\n\t\t\t&& kafkaLagTimes.get(metricEvent.getMetricGroup().getName()).equals(dataTimestamp)) {\n\t\t// No changes, skip\n\t\treturn metricEvent;\n\t}\n\t// Update the kafkaLagTimes map\n\tkafkaLagTimes.put(metricEvent.getMetricGroup().getName(), dataTimestamp);\n\t// Set the event's timestamp\n\tmetricEvent.setTimestamp(timestamp);\n\t// Update the event's fields\n\tmetricEvent.getFields().put(\"currentOffsets\", currentOffsets);\n\tmetricEvent.getFields().put(\"dataTimestamp\", dataTimestamp);\n\tmetricEvent.getFields().put(\"committedOffsets\", committedOffsets);\n\treturn metricEvent;\n}", "CodeBleu_score": 36.48094308533942}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Split the gauge's value into components.\n\tString[] parts = gauge.getValue().toString().split(\",\");\n\t// Extract the current offset, data timestamp, and committed offset from the gauge's value.\n\tlong currentOffset = Long.parseLong(parts[0].split(\":\")[1]);\n\tlong dataTimestamp = Long.parseLong(parts[1].split(\":\")[1]);\n\tlong committedOffset = Long.parseLong(parts[2].split(\":\")[1]);\n\t// Check for changes in the Kafka lag metrics.\n\tif (kafkaLagTimes.get(metricEvent.getMetricGroup()) == null || kafkaLagTimes.get(metricEvent.getMetricGroup()).longValue()!= dataTimestamp) {\n\t\t// Update the kafkaLagTimes map.\n\t\tkafkaLagTimes.put(metricEvent.getMetricGroup(), dataTimestamp);\n\t\t// Set the event's timestamp.\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\t// Update the event's fields with current offsets, data timestamp, and committed offsets.\n\t\tmetricEvent.getFields().put(\"currentOffset\", currentOffset);\n\t\tmetricEvent.getFields().put(\"dataTimestamp\", dataTimestamp);\n\t\tmetricEvent.getFields().put(\"committedOffset\", committedOffset);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 34.145225486382294}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tParameterTool parameterTool = getGlobalJobParameters();\nProperties props = buildKafkaProps(parameterTool);\n\nFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\nif (time!= null) {\nMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\nconsumer.setStartFromSpecificOffsets(partitionOffset);\n}\n\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 67.17786870902736}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameterTool = getGlobalJobParameters();\n\tProperties props = buildKafkaProps(parameterTool);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> offsetByTime = buildOffsetByTime(props, parameterTool, time);\n\t\tconsumer.setStartFromSpecificOffsets(offsetByTime);\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 61.859761984475256}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t// get global job parameters\nParameterTool parameterTool = getGlobalJobParameters();\n// build kafka properties\nProperties props = buildKafkaProps(parameterTool);\n// create a FlinkKafkaConsumer for MetricEvent\nFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n// if a specific start time is provided, set the consumer to start from the specific offsets based on the given time\nif (time!= null) {\nMap<KafkaTopicPartition, Long> offsets = buildOffsetByTime(props, parameterTool, time);\nconsumer.setStartFromSpecificOffsets(offsets);\n}\n// add the consumer as a source to the StreamExecutionEnvironment and return the DataStreamSource\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 61.491893280043364}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.setProperty(\"group.id\", time.toString());\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\tMap<TopicPartition, Long> topicPartitions = new HashMap<>();\n\tfor (PartitionInfo partition : partitions) {\n\t\tTopicPartition topicPartition = new TopicPartition(partition.topic(), partition.partition());\n\t\ttopicPartitions.put(topicPartition, time);\n\t}\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(topicPartitions);\n\tconsumer.close();\n\treturn offsets.entrySet().stream().collect(Collectors.toMap(e -> new KafkaTopicPartition(e.getKey().topic(), e.getKey().partition()), Map.Entry::getValue, (e1, e2) -> e2, LinkedHashMap::new));\n}", "CodeBleu_score": 51.241184156491336}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, time.toString());\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tList<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\tMap<TopicPartition, Long> timestampsToSearch = partitionInfos.stream()\n\t\t\t.collect(Collectors.toMap(\n\t\t\t\t\tpi -> new TopicPartition(pi.topic(), pi.partition()),\n\t\t\t\t\tpi -> time\n\t\t\t));\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampsToSearch);\n\tconsumer.close();\n\treturn offsets.entrySet().stream()\n\t\t\t.collect(Collectors.toMap(\n\t\t\t\t\te -> new KafkaTopicPartition(e.getKey().topic(), e.getKey().partition()),\n\t\t\t\t\tMap.Entry::getValue,\n\t\t\t\t\t(v1, v2) -> v2,\n\t\t\t\t\tLinkedHashMap::new\n\t\t\t));\n}", "CodeBleu_score": 42.39431291796939}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.setProperty(\"group.id\", time.toString())\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)\n\tList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"))\n\tMap<TopicPartition, Long> topicPartitions = new HashMap<>(partitions.size())\n\tpartitions.forEach(partitionInfo -> topicPartitions.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time))\n\tMap<KafkaTopicPartition, Long> offsets = consumer.offsetsForTimes(topicPartitions)\n\tconsumer.close()\n\treturn offsets\n}", "CodeBleu_score": 38.45044954440058}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test_event\");\n\tevent.setTags(new HashMap<>());\n\tevent.getTags().put(\"tag1\", \"value1\");\n\tevent.getTags().put(\"tag2\", \"value2\");\n\tevent.setFields(new HashMap<>());\n\tevent.getFields().put(\"field1\", \"value1\");\n\tevent.getFields().put(\"field2\", \"value2\");\n\n\tProducerRecord<String, String> record = new ProducerRecord<>(\"test_topic\", event.toJson());\n\tproducer.send(record);\n\n\tSystem.out.println(\"Sent data: \" + event.toJson());\n\tproducer.flush();\n}", "CodeBleu_score": 48.87929665438237}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"com.github.msemys.esjc.serialization.MetricEventSerializer\");\n\n\tKafkaProducer<String, MetricEvent> producer = new KafkaProducer<>(props);\n\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test\");\n\tevent.setTags(new HashMap<>());\n\tevent.getTags().put(\"host\", \"localhost\");\n\tevent.setFields(new HashMap<>());\n\tevent.getFields().put(\"value\", 1);\n\n\tProducerRecord<String, MetricEvent> record = new ProducerRecord<>(\"test\", event);\n\tproducer.send(record);\n\n\tSystem.out.println(\"Sent data: \" + event.toString());\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 45.59107064154263}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\"test-metric\");\nevent.setTags(new HashMap<>());\nevent.setFields(new HashMap<>());\nProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic\", event.toJson());\nproducer.send(record);\nSystem.out.println(\"Sent data: \" + record.value());\nproducer.flush();\n}", "CodeBleu_score": 44.39332903253702}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tevent.getLevel().isMoreSpecificThan(Level.WARN) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<>(topic, subAppend(event)));\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Error sending log event to Kafka topic: {}\", topic, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 42.77303341264492}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t{\n\t\tif (event.getLevel().isMoreSpecificThan(Level.WARN) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\t\tproducer.send(new ProducerRecord<>(topic, subAppend(event)));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.warn(\"Error sending log event to Kafka topic: {}\", topic, e);\n\t}\n}", "CodeBleu_score": 42.91725279643834}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t{\n\t\tif (event.getLevel().isMoreSpecificThan(level) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\t\tproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.warn(\"Error sending the log event to Kafka topic: {}\", topic, e);\n\t}\n}", "CodeBleu_score": 42.66503792511646}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, m := range validTopicSuffixMethods {\n\t\tif m == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 78.72835933549631}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\t// Check if the provided method is valid\n\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\t// If the method is not valid, return an error\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.39915802611816}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.29278467126518}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\t// If a routing tag is specified and present in the metric's tags, return the value of that tag as the key.\n\tif k.RoutingTag!= \"\" {\n\t\tif tagValue, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tagValue, nil\n\t\t}\n\t}\n\n\t// If the routing key is set to \"random\", generate and return a new UUID as the key.\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\t// Otherwise, return the routing key as the key.\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.558765296186195}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.452434865686484}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, r := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(r)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %w\", r, err)\n\t\t}\n\t\tk.regexps[i] = re\n\t}\n\treturn nil\n}", "CodeBleu_score": 61.79227285537653}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"error compiling regexp %s: %v\", re, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 56.617367892178684}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %q: %s\", re, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 56.883170643904876}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.mu.Unlock()\n\t\th.log.Errorf(\"Delivery ID %d not found in undelivered map\", track.ID)\n\t\treturn\n\t}\n\tmsg.Delivered()\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\tmsg.session.MarkMessage(track, nil)\n\th.log.Debugf(\"Delivered message %d to %s\", track.ID, msg.session.Name)\n\th.sem.Release(1)\n}", "CodeBleu_score": 56.33519237756165}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok {\n\t\tmsg.Delivered = true\n\t\tmsg.session.MarkMessage(msg, nil)\n\t\tdelete(h.undelivered, track.ID)\n\t\th.mu.Unlock()\n\t\th.sem.Release(1)\n\t} else {\n\t\th.mu.Unlock()\n\t\th.log.Errorf(\"Received delivery for unknown message: %v\", track)\n\t}\n}", "CodeBleu_score": 52.649934020102506}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif ok {\n\t\tmsg.Delivered = true\n\t\tmsg.session.MarkMessage(track, false)\n\t\tdelete(h.undelivered, track.ID)\n\t\th.sem <- struct{}{}\n\t}\n\th.mu.Unlock()\n\n\tif!ok {\n\t\th.log.Errorf(\"Delivery ID %d not found in undelivered map\", track.ID)\n\t}\n}", "CodeBleu_score": 53.58422817965307}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.WithValue(context.Background(), \"session\", session)\n\tfor {\n\t\tif err := h.Reserve(ctx); err!= nil {\n\t\t\treturn err\n\t\t}\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 64.22493517709238}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.Handle(ctx, msg)\n\t\t\tif err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 67.05237188335256}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := h.session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 59.34502810054574}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id!= null &&!logkafka_id.isEmpty, IllegalCharacterInLogkafkaId)\n\tcheckCondition(!logkafka_id.equals(\".\"), IllegalCharacterInLogkafkaId)\n\tcheckCondition(!logkafka_id.equals(\"..\"), IllegalCharacterInLogkafkaId)\n\tcheckCondition(logkafka_id.length <= 100, IllegalCharacterInLogkafkaId)\n\tcheckCondition(logkafka_id.matches(\"^[a-zA-Z0-9_\\\\-\\\\.]+$\"), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 36.65982503767232}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\nif (logkafka_id.equals(\"\") || logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\nthrow new IllegalCharacterInLogkafkaId()\n}\n\nif (logkafka_id.length > 255) {\nthrow new IllegalCharacterInLogkafkaId()\n}\n\nval rgx = \"\"\"^[a-zA-Z0-9_\\-\\.]+$\"\"\".r\n\nif (!rgx.findFirstIn(logkafka_id).isDefined) {\nthrow new IllegalCharacterInLogkafkaId()\n}\n}", "CodeBleu_score": 28.621173709664795}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tif(logkafka_id == null || logkafka_id.length() == 0) {\n\t\tthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n\t}\n\tif(logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n\t\tthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n\t}\n\tif(logkafka_id.length() > MAX_LOGKAFKA_ID_LENGTH) {\n\t\tthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n\t}\n\tval rgx = \"\"\"^[\\w\\d_\\-\\.]+$\"\"\".r\n\tif(!rgx.findFirstIn(logkafka_id).isDefined) {\n\t\tthrow new UtilException(UtilError.IllegalCharacterInLogkafkaId)\n\t}\n}", "CodeBleu_score": 36.455203520937985}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val command = KMClusterCommandRequest(clusterName, KMPreferredReplicaLeaderElectionCommand(topics))\n    sendCommand(command)\n  }", "CodeBleu_score": 18.405598138370845}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] = {\n    val request = KMClusterCommandRequest(clusterName, topics, PreferredReplicaLeaderElection)\n    kafkaManagerActor? request map {\n      case ClusterCommandSuccess(clusterContext) => \\/-(clusterContext)\n      case ClusterCommandError(error) => -\\/(error)\n    }\n  }\n}", "CodeBleu_score": 22.605495283616236}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tgetTopicList(clusterName).flatMap {\n  case \\/-(topics) =>\n    runPreferredLeaderElection(clusterName, topics.topics.map(_.name).toSet)\n  case -\\/(error) => Future.successful(-\\/(error))\n}\n}", "CodeBleu_score": 24.334058631156292}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\timplicit val ec = apiExecutionContext\n\tgetTopicList(clusterName).flatMap {\n\t\tcase \\/-(topicList) =>\n\t\t\trunPreferredLeaderElection(clusterName, topicList.topics.map(_.name).toSet)\n\t\tcase -\\/(error) =>\n\t\t\tFuture.successful(-\\/(error))\n\t}\n}", "CodeBleu_score": 63.28902156875111}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\timplicit val ec = apiExecutionContext\n\tgetTopicList(clusterName).flatMap {\n\t\tcase -\\/(error) => Future.successful(-\\/(error))\n\t\tcase \\/-(topics) => runPreferredLeaderElection(clusterName, topics.topics.toSet)\n\t}\n}", "CodeBleu_score": 63.56585345052245}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\tval results = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\nresults.map {\n  _.collect { case -\\/(err) => err }\n}.map { errs =>\n  if (errs.nonEmpty) {\n    -\\/(errs)\n  } else {\n    \\/-(())\n  }\n}\n}", "CodeBleu_score": 31.462440235424843}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster to get the available nodes within a specified timeout\n\tfinal DescribeClusterResult describeClusterResult = admin.describeCluster();\n\tfinal Config config = describeClusterResult.all().get(10, TimeUnit.SECONDS);\n\tfinal Set<Node> nodes = config.nodes();\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No nodes available\");\n\t}\n\n\t// Select the first node's ID and request its configuration\n\tfinal Node node = nodes.iterator().next();\n\tfinal ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n\tfinal DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(configResource));\n\tfinal Config nodeConfig = describeConfigsResult.all().get(configResource).get(10, TimeUnit.SECONDS);\n\tif (nodeConfig.entries().isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration found for node \" + node.idString());\n\t}\n\n\t// Return the broker's configuration\n\treturn nodeConfig;\n}", "CodeBleu_score": 54.50248545139236}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Get the cluster metadata\n\tClusterMetadata cluster = admin.describeCluster().get(timeout, TimeUnit.MILLISECONDS)\n\t// Check if the cluster has any nodes\n\tif (cluster.nodes().isEmpty()) {\n\t\tthrow new ConnectException(\"No nodes available in the cluster\")\n\t}\n\t// Get the first node's ID\n\tint firstNodeId = cluster.nodes().iterator().next().id()\n\t// Get the broker's configuration\n\tMap<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, firstNodeId))).all().get(timeout, TimeUnit.MILLISECONDS)\n\t// Check if the configuration was received\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration received for the broker\")\n\t}\n\t// Return the broker's configuration\n\treturn configs.values().iterator().next()\n}", "CodeBleu_score": 53.09920822357705}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Get the cluster metadata\n\tCluster cluster = admin.describeCluster().nodes().get(timeout, TimeUnit.MILLISECONDS);\n\tif (cluster.nodes().isEmpty()) {\n\t\tthrow new ConnectException(\"No nodes available\");\n\t}\n\n\t// Get the first node's ID\n\tNode node = cluster.nodes().iterator().next();\n\tint nodeId = node.id();\n\n\t// Get the node's configuration\n\tMap<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId))).all().get(timeout, TimeUnit.MILLISECONDS);\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(\"No configurations received\");\n\t}\n\n\t// Return the broker's configuration\n\treturn configs.values().iterator().next();\n}", "CodeBleu_score": 59.061684132363304}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (final Configuration configuration) -> {\n\t\tif (KafkaSchemaHistory.class.getName().equals(configuration.getString(SCHEMA_HISTORY_CONFIG))) {\n\t\t\treturn validator.validate(configuration);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 24.533858257076446}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Configuration configuration) {\n\t\t\treturn configuration.getSchemaHistory().equals(KafkaSchemaHistory.class.getName())? validator.validate(configuration) : 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 23.64672273596069}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (final Configuration config) -> {\n\t\tfinal String schemaHistory = config.getString(SCHEMA_HISTORY_CONFIG);\n\t\tif (schemaHistory.equals(KafkaSchemaHistory.class.getSimpleName())) {\n\t\t\treturn validator.validate(config);\n\t\t} else {\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 37.074450076535335}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString version = (String) config.get(VERSION_CONFIG);\n\tVersion connectVersion = Version.parseVersion(version);\n\tBoolean topicCreationEnabled = (Boolean) config.get(TOPIC_CREATION_ENABLE_CONFIG);\n\treturn topicCreationEnabled && connectVersion.compareTo(Version.parseVersion(\"2.0.0\")) >= 0;\n}", "CodeBleu_score": 39.640624957581}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tVersion connectVersion = Version.parse(Utils.getVersion(getClass()));\n\tBoolean topicCreationEnabled = (Boolean) config.get(\"topic.creation.enable\");\n\tif (topicCreationEnabled == null) {\n\t\ttopicCreationEnabled = true;\n\t}\n\tif (connectVersion.compareTo(Version.parse(\"2.2.0\")) >= 0) {\n\t\treturn topicCreationEnabled;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 41.36096415698828}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tVersion version = Version.parseVersion(version());\n\tif (version.compareTo(Version.parse(\"2.6.0\")) >= 0) {\n\t\treturn config.getOrDefault(\"topic.creation.enable\", true);\n\t}\n\treturn true;\n}", "CodeBleu_score": 20.976574328255023}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tString clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\tif (clientId == null) {\n\t\tthrow new ConfigException(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG, \"must be set\");\n\t}\n\tProperties adminProps = new Properties();\n\tadminProps.putAll(config);\n\tadminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n\tadminProps.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 10000);\n\tadminProps.put(AdminClientConfig.METADATA_MAX_AGE_CONFIG, 500);\n\tSharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\treturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 37.33514168146911}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\tif (clientId == null) {\n\t\tthrow new IllegalArgumentException(\"Missing required configuration: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\t}\n\tfinal Properties adminProps = new Properties();\n\tadminProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId + \"-admin\");\n\tadminProps.putAll(config);\n\tfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\treturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 38.11381569820642}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tString clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\tif (clientId == null) {\n\t\tthrow new IllegalArgumentException(\"Missing required configuration option \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\t}\n\n\tProperties adminProps = new Properties();\n\tadminProps.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.BOOTSTRAP_SERVERS_CONFIG));\n\tadminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId + \"-admin\");\n\tadminProps.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.REQUEST_TIMEOUT_MS_CONFIG));\n\tadminProps.put(AdminClientConfig.METADATA_MAX_AGE_CONFIG, config.get(KafkaOffsetBackingStoreConfig.METADATA_MAX_AGE_CONFIG));\n\tadminProps.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.RETRY_BACKOFF_MS_CONFIG));\n\tadminProps.put(AdminClientConfig.RETRY_BACKOFF_MAX_MS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.RETRY_BACKOFF_MAX_MS_CONFIG));\n\tadminProps.put(AdminClientConfig.RETRY_MAX_CONFIG, config.get(KafkaOffsetBackingStoreConfig.RETRY_MAX_CONFIG));\n\tadminProps.put(AdminClientConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION, config.get(KafkaOffsetBackingStoreConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION));\n\n\tSharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\n\treturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 36.458466990469894}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\tf (!node.isObject()) {\nthrow new IOException(\"Invalid key format: \" + node);\n}\nJsonNode payload = node.get(PAYLOAD_FIELD);\nif (payload!= null) {\nnode = payload;\n}\nIterator<String> fieldNames = node.fieldNames();\nif (!fieldNames.hasNext()) {\nthrow new IOException(\"Invalid key format: \" + node);\n}\nif (fieldNames.hasNext()) {\nString fieldName = fieldNames.next();\nif (fieldNames.hasNext()) {\nreturn reader.readValue(node);\n}\nelse {\nreturn reader.readValue(node.get(fieldName));\n}\n}\nthrow new IOException(\"Invalid key format: \" + node);\n}", "CodeBleu_score": 44.57178219692088}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\n\t\tJsonNode payload = node.get(PAYLOAD_FIELD);\n\t\tif (payload!= null) {\n\t\t\tnode = payload;\n\t\t}\n\t}\n\n\tIterator<String> fieldNames = node.fieldNames();\n\tif (fieldNames.hasNext()) {\n\t\tString fieldName = fieldNames.next();\n\t\tif (!fieldNames.hasNext()) {\n\t\t\treturn reader.readValue(node.get(fieldName));\n\t\t}\n\t}\n\treturn reader.readValue(node);\n}", "CodeBleu_score": 46.19098727362098}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tif (node.isObject()) {\n\t\tnode = node.get(PAYLOAD_FIELD);\n\t}\n\tif (node.has(Envelope.FieldName.KEY)) {\n\t\tnode = node.get(Envelope.FieldName.KEY);\n\t}\n\tif (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n\t\tnode = node.get(config.sourceField());\n\t}\n\tif (node.fieldNames().hasNext()) {\n\t\treturn reader.readValue(node);\n\t}\n\telse {\n\t\treturn reader.readValue(node.get(node.fieldNames().next()));\n\t}\n}", "CodeBleu_score": 43.59588530161377}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t// The topic name is constructed using the delegate method.\nString topicName = topicNameForDelegate(id, prefix, delimiter);\n// Iterate through the characters of the topic name.\nfor (int i = 0; i < topicName.length(); i++) {\n// If the character is invalid, replace it with a replacement character.\nif (!isValidTopicNameCharacter(topicName.charAt(i))) {\ntopicName = topicName.substring(0, i) + replacementCharacter + topicName.substring(i + 1);\n// Log a warning if any replacements are made.\nlog.warn(\"Invalid character in topic name: \" + topicName);\n// Break out of the loop.\nbreak;\n}\n}\n// Return the sanitized topic name.\nreturn topicName;\n}", "CodeBleu_score": 29.84577991349915}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tStringBuilder sanitized = new StringBuilder();\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (isValidTopicNameCharacter(c)) {\n\t\t\tsanitized.append(c);\n\t\t} else {\n\t\t\tlog.warn(\"Invalid topic name character {} at index {}. Replacing with {}.\", c, i, replacementCharacter);\n\t\t\tsanitized.append(replacementCharacter);\n\t\t}\n\t}\n\tif (sanitized.length()!= topicName.length()) {\n\t\tlog.warn(\"Topic name {} was sanitized to {}.\", topicName, sanitized);\n\t\treturn sanitized.toString();\n\t}\n\treturn topicName;\n}", "CodeBleu_score": 53.235951001033676}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tStringBuilder builder = new StringBuilder();\n\tboolean replaced = false;\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (isValidTopicNameCharacter(c)) {\n\t\t\tbuilder.append(c);\n\t\t} else {\n\t\t\tbuilder.append(replacement);\n\t\t\treplaced = true;\n\t\t}\n\t}\n\tif (replaced) {\n\t\tlog.warn(\"Sanitized topic name for id {} from {} to {}\", id, topicName, builder.toString());\n\t\treturn builder.toString();\n\t}\n\treturn topicName;\n}", "CodeBleu_score": 52.99480144988063}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 84.19188683016631}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 84.19188683016631}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 84.19188683016631}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tf (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 92.09592307139589}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n\t\treturn oldSchema;\n\t}\n\tSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n\tfor (Field field : oldSchema.fields()) {\n\t\tif (isContainedIn(field.name(), nestedFields)) {\n\t\t\tnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n\t\t} else {\n\t\t\tnewSchemabuilder.field(field.name(), field.schema());\n\t\t}\n\t}\n\tLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n\tfor (int i = 0; i < headers.size(); i++) {\n\t\tHeader currentHeader = headerToProcess.get(headers.get(i));\n\t\tOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n\t\tLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n\t\tif (currentFieldName.isPresent() && currentHeader!= null) {\n\t\t\tnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n\t\t}\n\t}\n\tLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n\treturn newSchemabuilder.build();\n}", "CodeBleu_score": 90.69195540082019}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 93.7937623835105}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source == null || source.schema().field(\"SNAPSHOT_KEY\") == null) {\n\t\treturn null;\n\t}\n\tString snapshotString = source.getString(\"SNAPSHOT_KEY\");\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 30.664647266413354}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null || source.schema() == null) {\nreturn null;\n}\nfinal Schema schema = source.schema();\nfinal Field field = schema.field(SNAPSHOT_KEY);\nif (field == null || field.schema().type()!= Schema.Type.STRING) {\nreturn null;\n}\nfinal String snapshotString = source.getString(SNAPSHOT_KEY);\nreturn snapshotString!= null? SnapshotRecord.valueOf(snapshotString.toUpperCase()) : null;\n}", "CodeBleu_score": 45.22072151049801}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.schema().field(SNAPSHOT_KEY).schema().name().equals(Schema.Type.STRING.name())) {\n\t\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\t\tif (snapshotString!= null) {\n\t\t\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 47.50174450442688}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null || version.isEmpty()) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length == 0) {\n\t\treturn Optional.empty();\n\t}\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] parts2 = parts[0].split(\"-\");\n\tif (parts2.length == 0) {\n\t\treturn Optional.empty();\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts2[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 54.233532439692276}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\t// TODO: Implement this function\n\treturn Optional.empty();\n}", "CodeBleu_score": 9.818742925388122}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] split = version.split(\"\\\\.\");\n\tif (split.length > 2) {\n\t\tsplit = Arrays.copyOf(split, 2);\n\t}\n\tString[] split2 = split[0].split(\"-\");\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(split2[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 52.46389024242644}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tild an AccessContext with relevant details and actions\nvar context = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\n// Validate access using the context\nreturn validateAccess(context).then(\n    // Call kafkaConnectService to create the connector\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 93.76489476931835}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tld an AccessContext with necessary details\nvar context = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n       .operationName(\"deleteConnector\")\n       .operationParams(Map.of(CONNECTOR_NAME, connectName))\n       .build();\n\n// Validate access using the context\nreturn validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n               .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 94.08641957275933}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t", "CodeBleu_score": 6.624085789973376}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t", "CodeBleu_score": 6.624085789973376}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tAction[] connectActions;\nif (RESTART_ACTIONS.contains(action)) {\n  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n} else {\n  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n}\n\nvar context = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(connectActions)\n   .operationName(\"updateConnectorState\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService\n       .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 97.54433373971412}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(dynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.474157817515355}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(dynamicConfigPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 40.474157817515355}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(new DynamicConfigPropertiesInitializer())\n\t\t.run(args);\n}", "CodeBleu_score": 40.64046746937218}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn (search == null)? c -> true : c -> getStringsForSearch(c).anyMatch(s -> containsIgnoreCase(s, search));\n}", "CodeBleu_score": 42.6604651431807}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null?\n\t\tconnector -> true :\n\t\tconnector -> getStringsForSearch(connector).anyMatch(s -> s.containsIgnoreCase(search));\n}", "CodeBleu_score": 43.435100611928746}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\n  return c -> true;\n}\nreturn c -> getStringsForSearch(c)\n   .anyMatch(s -> StringUtils.containsIgnoreCase(s, search));\n}", "CodeBleu_score": 75.39085245362435}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix == null? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(newKey, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 52.68930648521899}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap == null) {\n      return Collections.emptyMap();\n    }\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix == null? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(newKey, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 52.09354131944166}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\t// Initialize an empty map for the flattened result\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        // If the value is another map, recursively flatten it with the new key as the prefix\n        if (value instanceof Map) {\n          flattened.putAll(flattenClusterProperties(prefix == null? key : prefix + \".\" + key, (Map<String, Object>) value));\n        } else {\n          // Otherwise, add the key-value pair to the flattened map\n          flattened.put(prefix == null? key : prefix + \".\" + key, value);\n        }\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 51.10077071755009}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.addClientSslSupport();\n configDef.addClientSaslSupport();\n Set<String> configKeys = configDef.configKeys().entrySet().stream()\n.filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n.map(Map.Entry::getKey)\n.collect(Collectors.toSet());\n return configKeys;\n }", "CodeBleu_score": 68.19706800232804}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.addClientSslSupport();\n configDef.addClientSaslSupport();\n Set<String> configKeys = configDef.configKeys().entrySet().stream()\n.filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n.map(Map.Entry::getKey)\n.collect(Collectors.toSet());\n return configKeys;\n }", "CodeBleu_score": 68.19706800232804}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys().entrySet().stream()\n.filter(entry -> entry.getValue().type() == ConfigDef.Type.PASSWORD)\n.map(Map.Entry::getKey)\n.collect(toSet());\n }", "CodeBleu_score": 68.28223972701683}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn ofNullable(clusterDescription)\n\t\t\t.map(ClusterDescription::getAuthorizedOperations)\n\t\t\t.filter(operations -> operations.contains(AlterAclOperation.class))\n\t\t\t.flatMap(operations -> of(operations.contains(AlterAclOperation.class))\n\t\t\t\t\t.filter(aclViewEnabled)\n\t\t\t\t\t.map(value -> ClusterFeature.KAFKA_ACL_EDIT))\n\t\t\t.switchIfEmpty(empty());\n}", "CodeBleu_score": 26.03374287373527}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tif (aclViewEnabled(adminClient)) {\n  return clusterDescription.getAuthorizedOperations()\n   .flatMap(authorizedOperations -> {\n      if (authorizedOperations.contains(KafkaAcl.Operation.ALL) || authorizedOperations.contains(KafkaAcl.Operation.ALTER)) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n      }\n      return Mono.empty();\n    });\n}\nreturn Mono.empty();\n}", "CodeBleu_score": 37.04917652526272}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn adminClient.getClusterFeatures()\n.map(features -> {\nif (features.contains(SupportedFeature.AUTHORIZED_SECURITY_ENABLED)) {\nSet<Operation> authorizedOperations = clusterDescription.getAuthorizedOperations();\nif (authorizedOperations.contains(Operation.ALL) || authorizedOperations.contains(Operation.ALTER)) {\nreturn KAFKA_ACL_EDIT;\n}\n}\nreturn null;\n});\n}", "CodeBleu_score": 34.99893268480647}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nTreeMap<TopicPartition, FromToOffset> rangeToPoll = prevRange.isEmpty()? seekOperations.getOffsetsForSeek() : prevRange;\nint numMessagesToPollPerPartition = max(1, numMessagesToPoll / rangeToPoll.size());\nfor (Map.Entry<TopicPartition, FromToOffset> entry : rangeToPoll.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\nlong beginOffset = fromToOffset.getFrom();\nlong endOffset = fromToOffset.getTo();\nlong numMessagesToPoll = min(endOffset - beginOffset, numMessagesToPollPerPartition);\nlong startOffset = beginOffset + numMessagesToPoll;\nif (startOffset < beginOffset) {\n// The start offset has overflowed.\nstartOffset = endOffset;\n}\nnextRange.put(tp, new FromToOffset(startOffset, endOffset));\n}\nreturn nextRange;\n}", "CodeBleu_score": 34.809395438984176}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> fromToOffsets = new TreeMap<>();\n\nif (prevRange.isEmpty()) {\nseekOperations.forEach((topicPartition, offset) -> {\nfromToOffsets.put(topicPartition, new FromToOffset(offset, offset));\n});\n} else {\nfromToOffsets.putAll(prevRange);\n}\n\nint numMessagesPerPartition = Math.max(1, maxMessages / fromToOffsets.size());\n\nfor (Map.Entry<TopicPartition, FromToOffset> entry : fromToOffsets.entrySet()) {\nTopicPartition topicPartition = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\n\nlong startOffset = fromToOffset.from();\nif (startOffset < 0) {\nstartOffset = 0;\n}\nlong endOffset = startOffset + numMessagesPerPartition;\n\nfromToOffsets.put(topicPartition, new FromToOffset(startOffset, endOffset));\n}\n\nreturn fromToOffsets;\n}", "CodeBleu_score": 36.27695483921972}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>(comparingInt(tp -> tp.partition()));\nif (prevRange.isEmpty()) {\nseekOperations.forEach((tp, offset) -> {\nnextRange.put(tp, new FromToOffset(offset, offset));\n});\n} else {\nprevRange.forEach((tp, fromToOffset) -> {\nnextRange.put(tp, new FromToOffset(fromToOffset.to(), fromToOffset.to()));\n});\n}\nlong numMessagesToPoll = Math.min(maxNumMessagesPerPartition, maxNumMessagesPerPoll);\nlong numMessagesToPollPerPartition = Math.max(1, numMessagesToPoll / nextRange.size());\nnextRange.entrySet().forEach(entry -> {\nlong start = Math.max(entry.getValue().from(),\nMath.min(entry.getValue().to(), entry.getValue().to() - numMessagesToPollPerPartition));\nentry.setValue(new FromToOffset(start, entry.getValue().to()));\n});\nreturn nextRange;\n}", "CodeBleu_score": 38.047189833417704}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\tf (isLegacyMode()) {\n\t\tvalidateLegacyConfiguration();\n\t}\n\n\twaitForServerRunning();\n\tregisterForLifecycleEvents();\n\n\tif (isLegacyMode()) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\n\tscheduleAtFixedRate(this::updateLastSecBytesRead, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 13.623009330973709}, {"code": "public void doLaunch(final MessageInput input){\n\t check if legacy mode is enabled and validate the corresponding configuration settings for ZooKeeper or bootstrap servers\nif (configuration.getBoolean(CK_LEGACY_MODE, false)) {\n// wait for the server to be running\nawaitRunning();\n\n// register for server lifecycle events\nregister();\n\n// launch the legacy input\ndoLaunchLegacy(input);\n} else {\n// validate the corresponding configuration settings for ZooKeeper or bootstrap servers\nif (configuration.getString(CK_BOOTSTRAP).isNullOrEmpty() && configuration.getString(CK_ZOOKEEPER).isNullOrEmpty()) {\nthrow new IllegalArgumentException(\"Bootstrap servers or ZooKeeper must be specified\");\n}\n\n// wait for the server to be running\nawaitRunning();\n\n// register for server lifecycle events\nregister();\n\n// launch the consumer input\ndoLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read every second\nscheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 36.896840832121384}, {"code": "public void doLaunch(final MessageInput input){\n\tinal boolean legacyMode = configuration.getBoolean(CK_LEGACY_MODE, false);\n\tif (legacyMode) {\n\t\tif (configuration.getString(CK_ZOOKEEPER) == null) {\n\t\t\tthrow new RuntimeException(\"Zookeeper is not configured\");\n\t\t}\n\t} else {\n\t\tif (configuration.getString(CK_BOOTSTRAP) == null) {\n\t\t\tthrow new RuntimeException(\"Bootstrap servers are not configured\");\n\t\t}\n\t}\n\t// wait for the server to be running\n\twaitForServerRunning();\n\t// register for server lifecycle events\n\tlifecycleManager.register(this);\n\tif (legacyMode) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\t// schedule a task to update the last second bytes read every second\n\tscheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 42.50534850960951}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tprops.load(new StringReader(configuration))\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading custom properties\", e)\n\t}\n}", "CodeBleu_score": 21.834856618651415}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tProperties customProps = new Properties()\n\t\tcustomProps.load(new StringReader(customProperties))\n\t\tprops.putAll(customProps)\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading custom properties: \" + e.message)\n\t}\n}", "CodeBleu_score": 29.98563377011314}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tString customProps = System.getProperty(CUSTOM_PROPERTIES_KEY);\n\t\tif (customProps!= null) {\n\t\t\tProperties customProperties = new Properties();\n\t\t\tcustomProperties.load(new StringReader(customProps));\n\t\t\tprops.putAll(customProperties);\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Unable to load custom properties: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 45.38250537085894}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tfinal long start = System.currentTimeMillis();\n\tfinal List<Journal.Entry> journalEntries = entries.stream()\n\t\t\t.filter(Objects::nonNull)\n\t\t\t.map(this::toJournalEntry)\n\t\t\t.collect(Collectors.toList());\n\tfinal long writtenBytes = journalEntries.stream()\n\t\t\t.map(entry -> entry.getMessageId().length + entry.getMessage().length)\n\t\t\t.reduce(0L, Long::sum);\n\n\tfinal long writtenMessages = journalEntries.size();\n\tif (writtenMessages > 0) {\n\t\twriteToJournal(journalEntries);\n\n\t\twrittenMessagesCount.addAndGet(writtenMessages);\n\t\twrittenBytesCount.addAndGet(writtenBytes);\n\t}\n\n\tfinal long end = System.currentTimeMillis();\n\twriteTime.update(end - start);\n}", "CodeBleu_score": 43.37356971399198}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t", "CodeBleu_score": 2.767906284169963}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t// filter out null entries\nList<Journal.Entry> entriesToWrite = entries.stream()\n.filter(Objects::nonNull)\n.map(entry -> {\n// map each event to a journal entry\nJournal.Entry journalEntry = new Journal.Entry();\njournalEntry.setTopic(entry.getTopic());\njournalEntry.setKey(entry.getKey());\njournalEntry.setValue(entry.getMessage());\njournalEntry.setTimestamp(entry.getTimestamp());\nreturn journalEntry;\n})\n.collect(Collectors.toList());\n\n// calculate the total message bytes\nlong messageBytes = entriesToWrite.stream()\n.mapToLong(entry -> entry.getValue().length)\n.sum();\n\n// attempt to write the entries to the journal\nboolean success = false;\nlong lastOffset = -1L;\nint retryCount = 0;\nwhile (!success) {\ntry {\nlastOffset = kafkaJournal.write(entriesToWrite);\nsuccess = true;\n} catch (Exception e) {\n// exponential back-off strategy\nint backoffMillis = (int) Math.pow(2, retryCount) * 1000;\nLOG.warn(\"Failed to write to journal, retrying in {} ms.\", backoffMillis, e);\ntry {\nThread.sleep(backoffMillis);\n} catch (InterruptedException ex) {\nThread.currentThread().interrupt();\nthrow new MessageQueueException(\"Interrupted while waiting for retry.\", ex);\n}\nretryCount++;\n}\n}\n\n// update metrics\nwrittenMessages.addAndGet(entriesToWrite.size());\nwrittenBytes.addAndGet(messageBytes);\n\nLOG.debug(\"Wrote {} entries to journal, last offset: {}.\", entriesToWrite.size(), lastOffset);\n}", "CodeBleu_score": 46.08923304557769}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tmessages.stream()\n\t\t.filter(m -> m.getQueueId() > 0)\n\t\t.map(Message::getQueueId)\n\t\t.max(Comparator.naturalOrder())\n\t\t.ifPresent(max -> {\n\t\t\ttry {\n\t\t\t\tacknowledge(max);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Unable to acknowledge message with queue ID {}.\", max, e);\n\t\t\t}\n\t\t});\n\tmetrics.markAcknowledgedMessages(messages.size());\n}", "CodeBleu_score": 24.327894093361397}, {"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages.isEmpty()) {\n\t\treturn;\n\t}\n\tmessages.stream()\n\t\t.map(Message::getQueueId)\n\t\t.max(Long::compareTo)\n\t\t.ifPresent(queueId -> {\n\t\t\tacknowledgedMessages.put(queueId, true);\n\t\t\tmetrics.mark(acknowledgedMessages.size());\n\t\t});\n}", "CodeBleu_score": 19.55734444838421}, {"code": "public void acknowledge(List<Message> messages){\n\t\tmessages.stream().map(message -> message.getQueueId()).filter(queueId -> queueId!= null).max(Long::compareTo).ifPresent(queueId -> {\n\t\tacknowledge(queueId);\n\t});\n\tmetrics.mark(acknowledgedMessages, messages.size());\n}", "CodeBleu_score": 20.940805611873117}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry metricRegistry = getMetricRegistry();\n\tmetricRegistry.getMetrics().entrySet().stream()\n\t\t.filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n\t\t.forEach(entry -> {\n\t\t\tfinal String legacyName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"kafka\");\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyName, entry.getValue());\n\t\t\t} catch (IllegalArgumentException e) {\n\t\t\t\tLOG.warn(\"Cannot register legacy metric {} for metric {}. Skipping.\", legacyName, entry.getKey());\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 50.223218567168736}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry metricRegistry = getMetricRegistry();\n\tfinal String localKafkaJournalClassName = LocalKafkaJournal.class.getName();\n\tfinal Map<String, Metric> filteredMetrics = metricRegistry.getMetrics().entrySet().stream()\n\t\t\t.filter(entry -> entry.getKey().startsWith(localKafkaJournalClassName))\n\t\t\t.collect(Collectors.toMap(Map.Entry::getKey, Map.Entry::getValue));\n\n\tfor (final Map.Entry<String, Metric> entry : filteredMetrics.entrySet()) {\n\t\tfinal String originalMetricName = entry.getKey();\n\t\tfinal String legacyMetricName = originalMetricName.replace(localKafkaJournalClassName, \"\");\n\t\ttry {\n\t\t\tmetricRegistry.register(legacyMetricName, entry.getValue());\n\t\t} catch (final IllegalArgumentException e) {\n\t\t\tlog.warn(\"Unable to register legacy metric {} under original name {}\", legacyMetricName, originalMetricName);\n\t\t}\n\t}\n}", "CodeBleu_score": 38.474126617975976}, {"code": "private void registerLegacyMetrics(){\n\t\tmetricRegistry.getMetrics().entrySet().stream()\n\t\t.filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n\t\t.forEach(entry -> {\n\t\t\tfinal String legacyName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"akka.persistence.kafka.journal\");\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyName, entry.getValue());\n\t\t\t} catch (final IllegalArgumentException e) {\n\t\t\t\tlog.warn(\"Unable to register legacy metric: {} as {}\", entry.getKey(), legacyName);\n\t\t\t}\n\t\t});\n}", "CodeBleu_score": 57.8867134965487}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.register(metricName, new HdrTimer());\n\t} catch (IllegalArgumentException iae) {\n\t\treturn metricRegistry.getTimers().get(metricName);\n\t}\n}", "CodeBleu_score": 17.924085237404007}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tfinal Timer timer;\n\ttry {\n\t\ttimer = metricRegistry.register(metricName, new HdrTimer());\n\t} catch (IllegalArgumentException iae) {\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 38.10749543268037}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.register(metricName, new HdrTimer());\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 36.56011914334888}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tmetricRegistry.register(name, new Gauge<Long>() {\n\t\t@Override\n\t\tpublic Long getValue() {\n\t\t\tlong committedOffset = getCommittedOffset();\n\t\t\tlong size = size();\n\t\t\tif (size == 0) {\n\t\t\t\treturn 0L;\n\t\t\t}\n\t\t\tif (committedOffset == KafkaLog.DEFAULT_COMMITTED_OFFSET) {\n\t\t\t\treturn getLogEndOffset() - getLogStartOffset();\n\t\t\t}\n\t\t\treturn getLogEndOffset() - committedOffset;\n\t\t}\n\t});\n}", "CodeBleu_score": 42.20201271876443}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tmetricRegistry.register(name, new Gauge<Long>() {\n\t\t@Override\n\t\tpublic Long getValue() {\n\t\t\tif (size() == 0) {\n\t\t\t\treturn 0L;\n\t\t\t}\n\t\t\tlong committedOffset = committedOffset();\n\t\t\tif (committedOffset == KafkaLog.DefaultOffset) {\n\t\t\t\treturn getLogEndOffset() - getLogStartOffset();\n\t\t\t} else {\n\t\t\t\treturn getLogEndOffset() - committedOffset;\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 45.985800578106385}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tfinal Gauge<Long> uncommittedGauge = new Gauge<Long>() {\n\t\t@Override\n\t\tpublic Long getValue() {\n\t\t\tif (size() == 0) {\n\t\t\t\treturn 0L;\n\t\t\t}\n\t\t\tfinal long committedOffset = getCommittedOffset();\n\t\t\tif (committedOffset == KafkaLog.DEFAULT_COMMITTED_OFFSET) {\n\t\t\t\treturn getLogEndOffset() - getLogStartOffset();\n\t\t\t}\n\t\t\treturn getLogEndOffset() - committedOffset;\n\t\t}\n\t};\n\ttry {\n\t\tmetricRegistry.register(name, uncommittedGauge);\n\t} catch (IllegalArgumentException e) {\n\t\t// ignore\n\t}\n}", "CodeBleu_score": 51.37857620740903}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\ndebug(\"No messages to flush to {}.\", kafkaLog.file());\nreturn kafkaLog.lastOffset();\n}\n\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\ndebug(\"Flushing {} messages to {} with size {}.\", messages.size(), kafkaLog.file(), messageSet.sizeInBytes());\n\nlong lastOffset = kafkaLog.append(messageSet, payloadSize);\ndebug(\"Wrote {} messages to {} at offset {}.\", messages.size(), kafkaLog.file(), lastOffset);\n\nmark(messages.size());\n\nreturn lastOffset;\n}", "CodeBleu_score": 36.797170446072045}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n            log.debug(\"No messages to flush to {}.\", topicPartition);\n            return -1;\n        }\n\n        ByteBufferMessageSet messageSet = ByteBufferMessageSet.readFrom(new ByteBufferMessageSet.Builder(messages));\n        log.debug(\"Flushing {} messages for {} to log {} with payload size {}.\",\n            messages.size(), topicPartition, kafkaLog.file.getAbsolutePath(), payloadSize);\n\n        long lastOffset = kafkaLog.append(messageSet);\n        log.trace(\"Wrote {} messages for {} to log {} with last offset {}.\",\n            messages.size(), topicPartition, kafkaLog.file.getAbsolutePath(), lastOffset);\n\n        mark(messages.size());\n        return lastOffset;\n    }", "CodeBleu_score": 46.55195646218174}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\nif (messages.isEmpty()) {\nlog.debug(\"No messages to flush\");\nreturn -1;\n}\n\nByteBufferMessageSet messageSet = ByteBufferMessageSet.readFrom(messages);\n\nlog.debug(\"Flushing {} messages with total size {} to log {} with base offset {}\",\nmessages.size(), payloadSize, log.name(), log.logEndOffset);\n\nlong lastOffset = log.append(messageSet);\n\nif (lastOffset >= 0) {\nmark(lastOffset);\nmessagesFlushed.mark(messages.size());\n}\n\nreturn lastOffset;\n}", "CodeBleu_score": 34.646340416139424}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9a\u5ba2\u6237\u7aef\u6620\u5c04\u4ee5\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\uff0c\u5e76\u68c0\u7d22\u4e0e\u6307\u5b9a\u96c6\u7fa4ID\u5173\u8054\u7684Kafka AdminClient\u5b9e\u4f8b\u5217\u8868\u3002\n// \u5982\u679c\u672a\u627e\u5230\u5ba2\u6237\u7aef\uff0c\u5219\u8fd4\u56de\u3002\n// \u5b83\u8bb0\u5f55\u5173\u95ed\u8fc7\u7a0b\u7684\u5f00\u59cb\uff0c\u5e76\u5c1d\u8bd5\u5173\u95ed\u5217\u8868\u4e2d\u7684\u6240\u6709AdminClient\u5b9e\u4f8b\u3002\n// \u5982\u679c\u6240\u6709\u5ba2\u6237\u7aef\u90fd\u6210\u529f\u5173\u95ed\uff0c\u5219\u8bb0\u5f55\u6210\u529f\u6d88\u606f\uff0c\u5982\u679c\u4efb\u4f55\u5173\u95ed\u5931\u8d25\uff0c\u5219\u8bb0\u5f55\u9519\u8bef\u6d88\u606f\u3002\n// \u6355\u83b7\u8fc7\u7a0b\u4e2d\u53d1\u751f\u7684\u4efb\u4f55\u5f02\u5e38\u5e76\u8bb0\u5f55\u3002\n// \u6700\u540e\uff0c\u91ca\u653e\u9501\u5b9a\u3002\n        LOGGER.info(\"close kafka AdminClient start, clusterPhyId:{}\", clusterPhyId);\n        lock.lock();\n        try {\n            List<AdminClient> adminClientList = kafkaAdminClientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId, e);\n        } finally {\n            lock.unlock();\n        }\n    }", "CodeBleu_score": 74.57929880448567}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9a\u5ba2\u6237\u7aef\u6620\u5c04\u4ee5\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\nlock\n// \u68c0\u7d22\u4e0e\u6307\u5b9a\u96c6\u7fa4ID\u5173\u8054\u7684Kafka AdminClient\u5b9e\u4f8b\u5217\u8868\ninfo\n// \u5982\u679c\u6ca1\u6709\u627e\u5230\u5ba2\u6237\u7aef\uff0c\u5219\u8fd4\u56de\u3002\nif\n// \u8bb0\u5f55\u5173\u95ed\u8fc7\u7a0b\u7684\u5f00\u59cb\ninfo\n// \u5c1d\u8bd5\u5173\u95ed\u5217\u8868\u4e2d\u7684\u6240\u6709AdminClient\u5b9e\u4f8b\ninfo\n// \u5982\u679c\u6240\u6709\u5ba2\u6237\u7aef\u90fd\u6210\u529f\u5173\u95ed\uff0c\u5219\u8bb0\u5f55\u6210\u529f\u6d88\u606f\uff0c\u5426\u5219\u8bb0\u5f55\u9519\u8bef\u6d88\u606f\u3002\ninfo\n// \u6355\u83b7\u8fc7\u7a0b\u4e2d\u53d1\u751f\u7684\u4efb\u4f55\u5f02\u5e38\u5e76\u8bb0\u5f55\u5b83\u4eec\u3002\ninfo\n// \u91ca\u653e\u9501\u3002\nunlock\n}", "CodeBleu_score": 7.697382491012335}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u4f4fclientMap\uff0c\u4fdd\u8bc1\u7ebf\u7a0b\u5b89\u5168\nlock\n// \u53d6\u51faclientMap\u4e2d\u7684AdminClient\u5b9e\u4f8b\ninfo\nunlock\ninfo\nlock\ncloseAdminClientList\nunlock\ninfo\n}", "CodeBleu_score": 5.085701716144593}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList!= null) {\n\t\tadminClientList.each {\n\t\t\ttry {\n\t\t\t\tit.close(30, TimeUnit.SECONDS)\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Failed to close AdminClient for cluster: $clusterPhyId\", e)\n\t\t\t\tsuccess = false\n\t\t\t}\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 25.53182791903883}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(Duration.ofSeconds(30));\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing AdminClient for cluster {}: {}\", clusterPhyId, e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 62.625410531988855}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tadminClientList.each {\n\t\ttry {\n\t\t\tit.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tsuccess = false\n\t\t\tlog.error(\"Error while closing AdminClient for cluster $clusterPhyId: $e\")\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 28.293536857554624}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableSelfPreservation(false);\n\trunner.setKeyStore(\"keystore.jks\", \"changeit\".toCharArray());\n\trunner.setTrustStore(\"truststore.jks\", \"changeit\".toCharArray());\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 43.023880240119325}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config)\n\trunner.enableSelfPreservation(false)\n\trunner.setAdditionalConfigurations(additionalConfigurations)\n\trunner.enableSsl(true)\n\trunner.setKeyStore(keyStore, keyStorePassword)\n\trunner.setTrustStore(trustStore, trustStorePassword)\n\trunner.start()\n\trunner\n}", "CodeBleu_score": 33.50512900695208}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config)\n\trunner.enableSelfPreservation(false)\n\trunner.setAdditionalConfigurations([\n\t\t\t\"eureka.dashboard.enabled\": true,\n\t\t\t\"eureka.dashboard.path\": \"/eureka\",\n\t\t\t\"eureka.dashboard.ssl.enabled\": true,\n\t\t\t\"eureka.dashboard.ssl.key-store\": \"${System.getProperty(\"user.home\")}/eureka-server.jks\",\n\t\t\t\"eureka.dashboard.ssl.key-store-password\": \"\",\n\t\t\t\"eureka.dashboard.ssl.key-password\": \"\",\n\t\t\t\"eureka.dashboard.ssl.trust-store\": \"${System.getProperty(\"user.home\")}/eureka-server.jks\",\n\t\t\t\"eureka.dashboard.ssl.trust-store-password\": \"\",\n\t])\n\trunner.enableTls(true)\n\trunner.setKeyStore(\"${System.getProperty(\"user.home\")}/eureka-server.jks\", \"\", \"\")\n\trunner.setTrustStore(\"${System.getProperty(\"user.home\")}/eureka-server.jks\", \"\")\n\trunner.start()\n\trunner\n}", "CodeBleu_score": 30.68733178017843}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server);\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 44.27399491883336}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(server, config);\n\trunner.enableTls();\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 42.29043779058214}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(server, config);\n\trunner.start();\n\tenableTlsClient(runner);\n\trunner.startService(\"testservice\");\n\treturn runner;\n}", "CodeBleu_score": 49.84111001119258}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\t// Create CA certificate\n\tvar ca = KeyAndCert.createCA();\n\tsaveCert(ca);\n\n\t// Create server certificate signed by CA\n\tvar server = KeyAndCert.createServer(ca);\n\tsaveCert(server);\n\tsaveKeyAndCert(server);\n\n\t// Create client certificate signed by CA\n\tvar client = KeyAndCert.createClient(ca);\n\tsaveCert(client);\n\tsaveKeyAndCert(client);\n\n\t// Create second CA certificate\n\tvar secondCa = KeyAndCert.createCA();\n\tsaveCert(secondCa);\n\n\t// Create client certificate signed by second CA\n\tvar secondClient = KeyAndCert.createClient(secondCa);\n\tsaveCert(secondClient);\n\tsaveKeyAndCert(secondClient);\n}", "CodeBleu_score": 27.57367881718874}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create CA\n\tKeyAndCert ca = createCA();\n\n\t// Create server certificate signed by CA\n\tKeyAndCert server = createCert(ca, \"server\", \"127.0.0.1\");\n\n\t// Create client certificate signed by CA\n\tKeyAndCert client = createCert(ca, \"client\", \"127.0.0.1\");\n\n\t// Save CA certificate\n\tsaveCert(ca);\n\n\t// Save server certificate and key\n\tsaveKeyAndCert(server);\n\n\t// Save client certificate and key\n\tsaveKeyAndCert(client);\n\n\t// Create second CA\n\tKeyAndCert ca2 = createCA();\n\n\t// Create client certificate signed by second CA\n\tKeyAndCert client2 = createCert(ca2, \"client2\", \"127.0.0.1\");\n\n\t// Save second CA certificate\n\tsaveCert(ca2);\n\n\t// Save client certificate and key\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 29.095041987461006}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create CA\n\tKeyAndCert ca = KeyTool.createCA(CA_NAME, CA_PASSWORD);\n\n\t// Create server certificate and sign it with CA\n\tKeyAndCert server = KeyTool.createCert(SERVER_NAME, SERVER_PASSWORD, ca, CA_PASSWORD);\n\n\t// Create client certificate and sign it with CA\n\tKeyAndCert client = KeyTool.createCert(CLIENT_NAME, CLIENT_PASSWORD, ca, CA_PASSWORD);\n\n\t// Save certificates and keys\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveKeyAndCert(server);\n\tsaveCert(client);\n\tsaveKeyAndCert(client);\n\n\t// Create second CA\n\tKeyAndCert secondCA = KeyTool.createCA(SECOND_CA_NAME, SECOND_CA_PASSWORD);\n\n\t// Create second client certificate and sign it with second CA\n\tKeyAndCert secondClient = KeyTool.createCert(SECOND_CLIENT_NAME, SECOND_CLIENT_PASSWORD, secondCA, SECOND_CA_PASSWORD);\n\n\t// Save second CA and client certificates and keys\n\tsaveCert(secondCA);\n\tsaveCert(secondClient);\n\tsaveKeyAndCert(secondClient);\n}", "CodeBleu_score": 30.0832565333557}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong timeLimit = System.currentTimeMillis() + seconds * 1000\n\twhile (true) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn\n\t\t}\n\t\tif (System.currentTimeMillis() > timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion timed out after $seconds seconds\")\n\t\t}\n\t\tThread.sleep(100)\n\t}\n}", "CodeBleu_score": 39.612868525157964}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis()\n\tlong timeLimit = startTime + seconds * 1000\n\twhile (true) {\n\t\tif (System.currentTimeMillis() > timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion timed out after \" + seconds + \" seconds\")\n\t\t}\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn\n\t\t}\n\t\tThread.sleep(100)\n\t}\n}", "CodeBleu_score": 39.22052558752148}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tassertInSeconds(assertion, seconds, 100)\n}", "CodeBleu_score": 10.301165137596097}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate cert = null;\n\ttry {\n\t\tJcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(new X500Name(ca), BigInteger.valueOf(System.currentTimeMillis()), new Date(System.currentTimeMillis() - 1000L * 60 * 60 * 24), new Date(System.currentTimeMillis() + (1000L * 60 * 60 * 24 * 365 * 10)), new X500Name(\"CN=Test\"), keyPair.getPublic());\n\t\tcertBuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.keyEncipherment | KeyUsage.dataEncipherment | KeyUsage.keyAgreement | KeyUsage.digitalSignature));\n\t\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\t\tcert = new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(certBuilder.build(new JcaContentSignerBuilder(\"SHA256WithRSA\").setProvider(\"BC\").build(keyPair.getPrivate())));\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn cert;\n}", "CodeBleu_score": 34.43007388735031}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate cert = null;\n\ttry {\n\t\t// Create a certificate builder\n\t\tX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(\n\t\t\t\tnew X500Name(ca),\n\t\t\t\tBigInteger.valueOf(System.currentTimeMillis()),\n\t\t\t\tnew Date(System.currentTimeMillis() - 1000L * 60 * 60 * 24),\n\t\t\t\tnew Date(System.currentTimeMillis() + (1000L * 60 * 60 * 24 * 365 * 10)),\n\t\t\t\tnew X500Name(\"CN=localhost\"),\n\t\t\t\tkeyPair.getPublic());\n\n\t\t// Add key usage extension\n\t\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature));\n\n\t\t// Add basic constraints extension\n\t\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n\t\t// Sign the certificate\n\t\tcert = new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(builder.build(new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate())));\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn cert;\n}", "CodeBleu_score": 41.073805692091646}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t// Get the public key and CA information\n\tPublicKey publicKey = keyPair.getPublic();\n\tString issuer = ca;\n\tString subject = ca;\n\n\t// Construct a certificate builder with the public key and CA information\n\tJcaX509v3CertificateBuilder certBuilder = certBuilder(publicKey, issuer, subject);\n\n\t// Add key usage and basic constraints extensions to the certificate\n\tcertBuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\t// Sign the certificate with the private key and return the signed X509 certificate\n\treturn signCert(certBuilder, keyPair.getPrivate());\n}", "CodeBleu_score": 47.36060344537918}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.44550861954408}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\tsynchronized (this) {\n\t\t\tif (eurekaHttpClient == null) {\n\t\t\t\ttry {\n\t\t\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\t\t\tfield.setAccessible(true);\n\t\t\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t\t\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\t\t\t\tlogger.error(\"Cannot get the EurekaHttpClient instance\", e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 45.76691442156027}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\tsynchronized (this) {\n\t\t\tif (eurekaHttpClient == null) {\n\t\t\t\ttry {\n\t\t\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\t\t\tfield.setAccessible(true);\n\t\t\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t\t\t}\n\t\t\t\tcatch (IllegalAccessException e) {\n\t\t\t\t\tlogger.error(\"Cannot access registrationClient\", e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 48.7211402433213}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications!= null) {\n\t\tfor (Application app : applications.getRegisteredApplications()) {\n\t\t\tif (app.getInstances()!= null &&!app.getInstances().isEmpty()) {\n\t\t\t\tservices.add(app.getName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 56.79233059091601}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications!= null) {\n\t\tfor (Application application : applications.getRegisteredApplications()) {\n\t\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\t\tservices.add(application.getName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 56.03012450440753}, {"code": "public List<String> getServices(){\n\t\tApplications apps = this.eurekaClient.getApplications();\n\tif (apps == null || apps.getRegisteredApplications().isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application app : apps.getRegisteredApplications()) {\n\t\tif (!app.getInstances().isEmpty()) {\n\t\t\tservices.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 63.24072597464922}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tMap<String, Object> indicators = getIndicators();\n\tfor (Map.Entry<String, Object> entry : indicators.entrySet()) {\n\t\tString key = entry.getKey();\n\t\tObject value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor contributor = (DiscoveryCompositeHealthContributor) value;\n\t\t\tfor (Map.Entry<String, HealthIndicator> indicatorEntry : contributor.getIndicators().entrySet()) {\n\t\t\t\tif (!(indicatorEntry.getValue() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(key + \"-\" + indicatorEntry.getKey(), indicatorEntry.getValue());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, (HealthIndicator) value);\n\t\t}\n\t}\n}", "CodeBleu_score": 33.406908607060146}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tdiscoveryClient.getHealthIndicators().forEach((key, value) -> {\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) value).getIndicators().forEach((k, v) -> {\n\t\t\t\tif (!(v instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(k, v);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, value);\n\t\t}\n\t});\n}", "CodeBleu_score": 31.7473479575484}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tif (this.healthContributors!= null) {\n\t\tthis.healthContributors.forEach((key, value) -> {\n\t\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t\t((DiscoveryCompositeHealthContributor) value).getIndicators().forEach((k, v) -> {\n\t\t\t\t\tif (!(v instanceof EurekaHealthIndicator)) {\n\t\t\t\t\t\thealthContributors.put(k, v);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t}\n\t\t\telse {\n\t\t\t\thealthContributors.put(key, value);\n\t\t\t}\n\t\t});\n\t}\n}", "CodeBleu_score": 31.327299009728073}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n\tServiceInstance serviceInstance = instances.get(0);\n\tString url = serviceInstance.getUri() + \"/echo\";\n\treturn restTemplate.postForObject(url, \"Hello World\", String.class);\n}", "CodeBleu_score": 46.25488715489695}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances found\");\n\t}\n\tServiceInstance serviceInstance = instances.get(0);\n\tString uri = serviceInstance.getUri().toString();\n\tString result = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n\treturn result;\n}", "CodeBleu_score": 56.47685115316135}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() > 0) {\n\t\tServiceInstance serviceInstance = instances.get(0);\n\t\tString url = serviceInstance.getUri() + \"/echo\";\n\t\treturn restTemplate.postForObject(url, \"hello\", String.class);\n\t} else {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n}", "CodeBleu_score": 52.08184529458732}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\tURI uri = serviceInstance.getUri();\n\treturn restTemplate.postForObject(uri + \"/echo\", \"hello\", String.class);\n}", "CodeBleu_score": 36.80553356561983}, {"code": "public String world(){\n\t\t// load balancer client\n\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\t// construct a URI\n\tURI uri = URI.create(String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort()));\n\t// send a POST request to \"/echo\" endpoint of the chosen instance using a RestTemplate\n\treturn restTemplate.postForObject(uri, \"Hello World!\", String.class);\n}", "CodeBleu_score": 43.71385693465708}, {"code": "public String world(){\n\t\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\tURI uri = UriComponentsBuilder.fromUriString(instance.getUri().toString()).path(\"/echo\").build().toUri();\n\treturn new RestTemplate().postForObject(uri, \"Hello World\", String.class);\n}", "CodeBleu_score": 46.87216041590644}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Registering service \" + serviceName + \" with IP \" + ip + \" and port \" + port);\n\tsynchronized (serverMap) {\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\tserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n\t\t}\n\t\tServer server = new Server(ip, port);\n\t\tif (serverMap.get(serviceName).add(server)) {\n\t\t\tlogger.info(\"Service \" + serviceName + \" registered with IP \" + ip + \" and port \" + port);\n\t\t\treturn true;\n\t\t} else {\n\t\t\tlogger.info(\"Service \" + serviceName + \" already registered with IP \" + ip + \" and port \" + port);\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 56.424394430219785}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Received registration request for service {} with ip {} and port {}\", serviceName, ip, port);\n\tsynchronized (serverMap) {\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\tserverMap.put(serviceName, new HashSet<>());\n\t\t}\n\t\treturn serverMap.get(serviceName).add(new Server(ip, port));\n\t}\n}", "CodeBleu_score": 56.52640264271618}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Registering service: \" + serviceName + \" with ip: \" + ip + \" and port: \" + port);\n\tif (!serverMap.containsKey(serviceName)) {\n\t\tserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n\t}\n\tserverMap.get(serviceName).add(new Server(ip, port));\n\treturn true;\n}", "CodeBleu_score": 52.14823671465483}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tlogger.info(\"Deregistering server: \" + server);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tif (servers.remove(server)) {\n\t\t\tlogger.info(\"Successfully deregistered server: \" + server);\n\t\t\treturn true;\n\t\t}\n\t}\n\tlogger.info(\"Server: \" + server + \" not found\");\n\treturn false;\n}", "CodeBleu_score": 48.94479180734791}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tif (servers.remove(server)) {\n\t\t\tlogger.info(\"Deregistered server: \" + server);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 49.12910463227229}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> serverSet = serverMap.get(serviceName);\n\t\tif (serverSet.contains(server)) {\n\t\t\tserverSet.remove(server);\n\t\t\tlogger.info(\"Deregistered \" + server);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 53.97927081417028}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata\n\t\t\t.getAnnotationAttributes(RibbonClients.class.getCanonicalName(), true);\n\tif (attributes!= null) {\n\t\tMultiValueMap<String, Object> clients = (MultiValueMap<String, Object>) attributes\n\t\t\t\t.get(\"value\");\n\t\tif (clients!= null) {\n\t\t\tfor (Map<String, Object> client : clients.asList()) {\n\t\t\t\tif (client.containsKey(\"defaultConfiguration\")) {\n\t\t\t\t\tString name = \"default.\" + client.get(\"name\");\n\t\t\t\t\tregisterClientConfiguration(registry, name,\n\t\t\t\t\t\t\tclient.get(\"defaultConfiguration\"));\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 56.74839026799607}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> clientAnnotation = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\n\tif (clientAnnotation!= null && clientAnnotation.containsKey(\"value\")) {\n\t\tfor (Object name : (Object[]) clientAnnotation.get(\"value\")) {\n\t\t\tMap<String, Object> clientConfiguration = metadata.getAnnotationAttributes(\n\t\t\t\t\tRibbonClient.class.getName(), true);\n\t\t\tif (clientConfiguration == null) {\n\t\t\t\tthrow new IllegalStateException(\n\t\t\t\t\t\t\"@RibbonClient can not be used without @RibbonClients\");\n\t\t\t}\n\t\t\tif (clientConfiguration.containsKey(\"name\")) {\n\t\t\t\tname = clientConfiguration.get(\"name\");\n\t\t\t}\n\t\t\tregisterClientConfiguration(registry, name, clientConfiguration);\n\t\t}\n\t}\n\tMap<String, Object> clientConfiguration = metadata.getAnnotationAttributes(RibbonClient.class.getName());\n\tif (clientConfiguration!= null && clientConfiguration.containsKey(\"name\")) {\n\t\tregisterClientConfiguration(registry, clientConfiguration.get(\"name\"), clientConfiguration);\n\t}\n}", "CodeBleu_score": 44.20483064561981}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata\n\t\t\t.getAnnotationAttributes(RibbonClients.class.getCanonicalName(), false, false);\n\tif (attributes!= null) {\n\t\tObject defaultConfiguration = attributes.get(\"defaultConfiguration\");\n\t\tif (defaultConfiguration instanceof List) {\n\t\t\tfor (Object configuration : (List<?>) defaultConfiguration) {\n\t\t\t\tregisterDefaultConfiguration(registry, configuration);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tregisterDefaultConfiguration(registry, defaultConfiguration);\n\t\t}\n\t}\n\tMap<String, Object> classAnnotated = metadata.getAnnotationAttributes(\n\t\t\tRibbonClient.class.getCanonicalName(), false, false);\n\tif (classAnnotated!= null) {\n\t\tAnnotationAttributes attributes1 = AnnotationAttributes.fromMap(classAnnotated);\n\t\tregisterClientConfiguration(registry, attributes1.getString(\"name\"),\n\t\t\t\tattributes1.get(\"configuration\"));\n\t}\n\telse {\n\t\tSet<String> clientInterfaceNames = metadata.getAnnotatedInterfaceNames(RibbonClient.class);\n\t\tfor (String clientInterfaceName : clientInterfaceNames) {\n\t\t\tregisterClientConfiguration(registry, metadata.getClassName(clientInterfaceName),\n\t\t\t\t\tnull);\n\t\t}\n\t}\n}", "CodeBleu_score": 38.97359681848675}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// Get the default context\n\tContext context = request.getContext();\n\n\t// Get the service instances from the load balancer\n\tList<ServiceInstance> instances = loadBalancer.getInstances(serviceId);\n\n\t// If there are no instances, return null\n\tif (instances == null || instances.isEmpty()) {\n\t\treturn null;\n\t}\n\n\t// Get the server from the load balancer based on the service ID and context\n\tServiceInstance server = loadBalancer.choose(serviceId, context);\n\n\t// If the server is not null, create a TutuServiceInstance object and return it\n\tif (server!= null) {\n\t\treturn new TutuServiceInstance(server);\n\t}\n\n\t// If the server is null, return null\n\treturn null;\n}", "CodeBleu_score": 48.63036991434046}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tList<ServiceInstance> instances = getLoadBalancer(serviceId).getAllServers();\n\tif (instances == null || instances.size() == 0) {\n\t\treturn null;\n\t}\n\tServiceInstance server = instances.get(0);\n\treturn new TutuServiceInstance(server.getServiceId(), server.getHost(), server.getPort());\n}", "CodeBleu_score": 43.74685149744513}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\treturn new URI(server.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 23.66530228485717}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tURI uri = null;\n\ttry {\n\t\turi = new URI(server.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn uri;\n}", "CodeBleu_score": 34.11191430651832}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\treturn new URI(original.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 23.79849896352471}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\t// Create a map to store the parameters for the HTTP GET request\n\tMap<String, String> params = [:]\n\tparams.serviceName = serviceName\n\n\t// Send an HTTP GET request to the specified server address concatenated with \"/list\"\n\t// and parse the response as a JSON array\n\tJSONArray response = getServerAddr().get(\"/list\", params).parseArray()\n\n\t// Iterate over the JSON array and create a list of TutuServer objects\n\t// containing IP addresses and ports extracted from the JSON data\n\tList<TutuServer> servers = response.collect {\n\t\tnew TutuServer(it.ip, it.port)\n\t}\n\n\t// Return the list of TutuServer objects\n\tservers\n}", "CodeBleu_score": 11.911235076958203}, {"code": "private List<TutuServer> getServer(){\n\t\tString serviceName = \"tutu-server\"\n\tString serverAddr = getServerAddr()\n\tString url = \"${serverAddr}/list\"\n\tString json = get(url, [serviceName: serviceName])\n\tdef list = parseArray(json)\n\tlist.collect {\n\t\tnew TutuServer(it.ip, it.port)\n\t}\n}", "CodeBleu_score": 22.032355234187186}, {"code": "private List<TutuServer> getServer(){\n\t\tdef params = [serviceName: serviceName]\n\tdef url = getServerAddr() + \"/list\"\n\tdef response = get(url, params)\n\tdef servers = parseArray(response)\n\tservers.collect {\n\t\tnew TutuServer(it.ip, it.port)\n\t}\n}", "CodeBleu_score": 17.175300021510466}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routeLocations) {\n\t\tList<Route> routes = this.routes.get(location);\n\t\tif (routes!= null) {\n\t\t\tfor (Route route : routes) {\n\t\t\t\tif (this.pathMatcher.match(route.getPath(), path)) {\n\t\t\t\t\tString extractedPath = this.pathMatcher.extractPathWithinPattern(route.getPath(), path);\n\t\t\t\t\treturn new Route(extractedPath, route.getId());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.58330701488633}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routes.keySet()) {\n\t\tif (this.pathMatcher.match(location, path)) {\n\t\t\tString targetPath = path.substring(location.length());\n\t\t\treturn new Route(location, this.routes.get(location).getServiceId(), targetPath);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.65818175906524}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String routeId : this.routeLocator.getRoutes().keySet()) {\n\t\tRoute route = this.routeLocator.getRoute(routeId);\n\t\tif (route!= null) {\n\t\t\tString pathPrefix = route.getPath();\n\t\t\tif (this.pathMatcher.match(pathPrefix, path)) {\n\t\t\t\tString extractedPath = this.pathMatcher.extractPathWithinPattern(pathPrefix, path);\n\t\t\t\treturn new Route(routeId, extractedPath, route.getLocation(), route.getPrefix(),\n\t\t\t\t\t\troute.getRetryable(), route.getCustomSensitiveHeaders(), route.isCaseSensitive());\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 33.14490160975442}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(FeignClient.class.getName());\n\tString name = (String) attributes.get(\"name\");\n\tString contextId = (String) attributes.get(\"contextId\");\n\tString[] packages = (String[]) attributes.get(\"packagesToScan\");\n\tClass<?>[] types = (Class<?>[]) attributes.get(\"types\");\n\tString[] basePackages = (String[]) attributes.get(\"value\");\n\tString[] defaultConfiguration = (String[]) attributes.get(\"defaultConfiguration\");\n\tString[] configurations = (String[]) attributes.get(\"configuration\");\n\n\tif (packages.length == 0 && types.length == 0 && basePackages.length == 0) {\n\t\tpackages = new String[] { ClassUtils.getPackageName(importingClassMetadata.getClassName()) };\n\t}\n\n\tfor (String pkg : packages) {\n\t\tscanPackageByAnnotation(pkg, registry, name, contextId, defaultConfiguration, configurations);\n\t}\n\n\tfor (Class<?> type : types) {\n\t\tregisterBeanDefinition(type, registry, name, contextId, defaultConfiguration, configurations);\n\t}\n\n\tfor (String pkg : basePackages) {\n\t\tscanPackageByAnnotation(pkg, registry, name, contextId, defaultConfiguration, configurations);\n\t}\n}", "CodeBleu_score": 33.80779713177724}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// Get the package name of the importing class\n\tString packageName = getPackageName(importingClassMetadata);\n\n\t// Scan for classes with the FeignClient annotation in the package of the importing class\n\tSet<Class<?>> classes = scanPackageByAnnotation(packageName, FeignClient.class);\n\n\t// Iterate over the classes and register bean definitions for each annotated class\n\tfor (Class<?> clazz : classes) {\n\t\t// Create a bean definition for the class\n\t\tBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(FeignClientFactoryBean.class);\n\t\t// Configure the bean definition with FeignClientFactoryBean settings\n\t\tbuilder.addPropertyValue(\"contextId\", clazz.getSimpleName());\n\t\tbuilder.addPropertyValue(\"type\", clazz);\n\t\t// Register the bean definition with the BeanDefinitionRegistry\n\t\tregistry.registerBeanDefinition(clazz.getName(), builder.getBeanDefinition());\n\t}\n}", "CodeBleu_score": 35.38398622372449}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n\tString[] basePackages = (String[]) attributes.get(\"basePackages\");\n\tClass<?>[] basePackageClasses = (Class<?>[]) attributes.get(\"basePackageClasses\");\n\tString[] value = (String[]) attributes.get(\"value\");\n\n\t// If no base packages or base package classes are specified, use the package of the importing class\n\tif (basePackages.length == 0 && basePackageClasses.length == 0) {\n\t\tbasePackages = new String[] { ClassUtils.getPackageName(importingClassMetadata.getClassName()) };\n\t}\n\n\t// If no value is specified, use the default bean name generator\n\tif (value.length == 0) {\n\t\tvalue = new String[] { BeanDefinitionReaderUtils.GENERATED_BEAN_NAME_GENERATOR };\n\t}\n\n\t// Create a scanner to scan for classes annotated with @FeignClient\n\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n\tscanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n\n\t// Scan for classes annotated with @FeignClient in the specified base packages\n\tfor (String basePackage : basePackages) {\n\t\tSet<BeanDefinition> beanDefinitions = scanner.findCandidateComponents(basePackage);\n\t\tfor (BeanDefinition beanDefinition : beanDefinitions) {\n\t\t\t// Create a GenericBeanDefinition for the bean definition\n\t\t\tGenericBeanDefinition genericBeanDefinition = new GenericBeanDefinition();\n\t\t\tgenericBeanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\t\tgenericBeanDefinition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n\n\t\t\t// Configure the bean definition with FeignClient settings\n\t\t\tString beanName = beanDefinition.getBeanClassName();\n\t\t\tgenericBeanDefinition.getPropertyValues().add(\"contextId\", beanName);\n\t\t\tgenericBeanDefinition.getPropertyValues().add(\"type\", beanDefinition.getBeanClassName());\n\n\t\t\t// Register the bean definition with the BeanDefinitionRegistry\n\t\t\tString beanName = BeanDefinitionReaderUtils.generateBeanName(genericBeanDefinition, registry);\n\t\t\tregistry.registerBeanDefinition(beanName, genericBeanDefinition);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.09434949242814}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
