{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    return (self.loop_wait - 2) * 1000, self._orig_kazoo_connect(*args)\n\n\n\n\n", "CodeBleu_score": 53.35851895149868}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    wait_time = self.loop_wait - 2\n    return (wait_time * 1000, self._orig_kazoo_connect(*args)[1])\n\n\n\n\n", "CodeBleu_score": 47.460433299433326}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._orig_kazoo_connect(*args)\n    return (self.loop_wait - 2) * 1000, self._orig_kazoo_connect(*args)\n\n\n\n\n", "CodeBleu_score": 53.35851895149868}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, Config):\n        config = config.as_dict()\n    self.set_retry_timeout(config.get('retry_timeout', self._retry_timeout))\n    self.set_loop_wait(config.get('loop_wait', self._loop_wait))\n    self.set_ttl(config.get('ttl', self._ttl))\n    if self._handler_type == PatroniSequentialThreadingHandler:\n        self.set_connect_timeout(config.get('connect_timeout', self._connect_timeout))", "CodeBleu_score": 36.540583251972066}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_loop_wait(config.loop_wait)\n    self.set_ttl(config.ttl)\n    if self._client._handler == PatroniSequentialThreadingHandler:\n        self.set_connect_timeout(config.connect_timeout)\n    else:\n        self.close()", "CodeBleu_score": 35.84773549449971}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_loop_wait(config.loop_wait)\n    self.set_ttl(config.ttl)\n    if config.connect_timeout:\n        self.set_connect_timeout(config.connect_timeout)\n    if self.handler and self.handler.is_sequential_threading:\n        self.handler.close()\n\n", "CodeBleu_score": 35.707237163195025}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.get_node(path + self._INIT_STATE)[0])\n    cluster.config = ClusterConfig.from_node(self.get_node(path + self._CONFIG)[0])\n    cluster.timeline_history = TimelineHistory.from_node(self.get_node(path + self._TIMELINE_HISTORY)[0])\n    cluster.sync_state = SyncState.from_node(self.get_node(path + self._SYNC_STATE)[0])\n    cluster.members = self.load_members(path + self._MEMBERS)\n    cluster.leader = Leader.from_node(self.get_node(path + self._LEADER)[0])\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = Failover.from_node(self.get_node(path + self._FAILOVER)[0])\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster", "CodeBleu_score": 14.053808923746299}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self)\n    cluster.path = path\n    cluster.init = self.get_node(path + self._INIT)\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.timeline_history = TimelineHistory.from_node(self.get_node(path + self._TIMELINE_HISTORY))\n    cluster.sync_state = SyncState.from_node(self.get_node(path + self._SYNC_STATE))\n    cluster.members = self.load_members(path + self._MEMBERS)\n    cluster.leader = Leader.from_node(self.get_node(path + self._LEADER))\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = Failover.from_node(self.get_node(path + self._FAILOVER))\n    cluster.failsafe = Failsafe.from_node(self.get_node(path + self._FAILSAFE))\n    return cluster", "CodeBleu_score": 14.34144804336492}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Check if the initialization state component exists in the given path\n    if self.get_node(path + self._INIT_STATE):\n        # Retrieve the initialization state component\n        init_state = self.get_node(path + self._INIT_STATE)[0]\n        # Parse the initialization state component and create an InitializationState object\n        init_state_obj = InitializationState.from_node(init_state)\n    else:\n        # If the initialization state component does not exist, create an InitializationState object with the default values\n        init_state_obj = InitializationState()\n    # Check if the configuration component exists in the given path\n    if self.get_node(path + self._CONFIG):\n        # Retrieve the configuration component\n        config = self.get_node(path + self._CONFIG)[0]\n        # Parse the configuration component and create a ClusterConfig object\n        config_obj = ClusterConfig.from_node(config)\n    else:\n        # If the configuration component does not exist, create a ClusterConfig object with the default values\n        config_obj = ClusterConfig()\n    # Check if the timeline history component exists in the given path\n    if self.get_node(path + self._TIMELINE_HISTORY):\n        # Retrieve the timeline history component\n        timeline_history = self.get_node(path + self._TIMELINE_HISTORY)[0]\n        # Parse the timeline history component and create a TimelineHistory object\n        timeline_history_obj = TimelineHistory.from_node(timeline_history)\n    else:\n        # If the timeline history component does not exist, create a TimelineHistory object with the default values\n        timeline_history_obj = TimelineHistory()\n    # Check if the synchronization state component exists in the given path\n    if self.get_node(path + self._SYNC_STATE):\n        # Retrieve the synchronization state component\n        sync_state = self.get_node(path + self._SYNC_STATE)[0]\n        # Parse the synchronization state component and create a SyncState object\n        sync_state_obj = SyncState.from_node(sync_state)\n    else:\n        # If the synchronization state component does not exist, create a SyncState object with the default values\n        sync_state_obj = SyncState()\n    # Check if the members component exists in the given path\n    if self.get_node(path + self._MEMBERS):\n        # Retrieve the members component\n        members = self.load_members(", "CodeBleu_score": 21.847930683830338}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    path = self.get_leader_path()\n    try:\n        self.zk.create(path, b'', ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL)\n        self.logger.info(f'Acquired leader lock at {path}')\n        return True\n    except NodeExistsError:\n        self.logger.info(f'Another instance has the leader lock at {path}')\n        return False\n    except Exception as e:\n        self.logger.error(f'Error acquiring leader lock: {e}')\n        raise ZooKeeperError(e)\n", "CodeBleu_score": 39.60023910561642}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        with self.lock_path.create(ephemeral=True, makepath=True) as _", "CodeBleu_score": 12.016883336461822}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._zk.create(self._leader_path, b'', ZooKeeper.EPHEMERAL | ZooKeeper.SEQUENCE, self._zk_data_handler)\n        logger.info", "CodeBleu_score": 14.80974596861061}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session!= self.session:\n        logger.warning(f\"Leader session {leader.session} does not match current session {self.session}. Deleting existing leader node.\")\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            pass\n        except ZooKeeperError as e:\n            logger.error(f\"Error deleting existing leader node: {e}\")\n            return False\n        try:\n            self.zk.create(self.leader_path, leader.name.encode(\"utf-8\"), self.acl, self.leader_path)\n        except ZooKeeperError as e:\n            logger.error(f\"Error creating new leader node: {e}\")\n            return False\n        return True\n    else:\n        return True\n", "CodeBleu_score": 41.264778107635536}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session!= self._session:\n        logger.warning(f\"Leader session ID mismatch: {leader.session} vs {self._session}\")\n        try:\n            self._zk.delete(leader.path, recursive=True)\n        except ZooKeeperError as e:\n            if e.code == NoNodeError:\n                logger.debug(f\"Leader node deleted: {leader.path}\")\n            else:\n                logger.error(f\"Error deleting leader node: {leader.path}\")\n                raise\n        else:\n            logger.debug(f\"Leader node deleted: {leader.path}\")\n\n    try:\n        self._zk.create(leader.path, leader.name.encode(\"utf-8\"), acl=ACL_OPEN_ACL_UNSAFE)\n    except ZooKeeperError as e:\n        logger.error(f\"Error creating leader node: {leader.path}\")\n        raise\n    else:\n        logger.debug(f\"Leader node created: {leader.path}\")\n        return True\n", "CodeBleu_score": 39.43796765758769}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._leader is not None and self._leader.client_id!= leader.client_id:\n        logger.warning(\n            \"Leader client ID mismatch: expected %s, got %s\",\n            self._leader.client_id,\n            leader.client_id,\n        )\n        try:\n            self._zk.delete(self._leader_path, recursive=True)\n        except ZooKeeperError as e:\n            logger.error(\n                \"Failed to delete leader node: %s\",\n                e,\n            )\n            return False\n    self._leader = leader\n    return True", "CodeBleu_score": 28.772581399515374}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    now = time.time()\n    if now < self._last_poll + self.POLL_INTERVAL:\n        return False\n    self._last_poll = now\n    try:\n        data = self._query_exhibitors(self._exhibitors)\n        if data is None:\n            return False\n        if not isinstance(data, dict):\n            return False\n        if'server' not in data:\n            return False\n        if 'port' not in data:\n            return False\n        if 'path' not in data:\n            return False\n        server = data['server']\n        port = data['port']\n        path = data['path']\n        if server!= self._server:\n            self._server = server\n            self._port = port\n            self._path = path\n            self._zk.close()\n            self._zk = KazooClient(hosts=f'{server}:{port}')\n            self._zk.start()\n            logging.info('Exhibitor connection string changed to %s:%s%s', server, port, path)\n            return True\n        return False", "CodeBleu_score": 36.88130374867229}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None:\n        self._last_poll_time = time.time()\n        return False\n    if time.time() - self._last_poll_time < self.POLL_INTERVAL:\n        return False\n    self._last_poll_time = time.time()\n    exhibitors = self._query_exhibitors(self._exhibitors)\n    if exhibitors is None:\n        return False\n    if self._last_exhibitors!= exhibitors:\n        self._last_exhibitors = exhibitors\n        if self._zk_client is not None:\n            self._zk_client.stop()\n            self._zk_client = None\n        self._update_zk_connection_string(exhibitors)\n        return True\n    return False", "CodeBleu_score": 29.21785286700484}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time + self._poll_interval < time.time():\n        self._last_poll_time = time.time()\n        try:\n            exhibitors = self._query_exhibitors(self._exhibitors)\n            if exhibitors:\n                if self._zk_connection_string!= exhibitors['zkConnectionString']:\n                    self._zk_connection_string = exhibitors['zkConnectionString']\n                    logging.info('Updated ZooKeeper connection string to %s', self._zk_connection_string)\n                self._exhibitor_port = exhibitors['port']\n                return True\n        except Exception:\n            logging.exception('Error polling for Exhibitor status')\n            self._zk_connection_string = None\n            self._exhibitor_port = None\n        return False", "CodeBleu_score": 34.80824622848366}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (this.zookeeperListener == null) {\n\t\treturn;\n\t}\n\ttry {\n\t\tString group = getGroup();\n\t\tString dataId = getDataId();\n\t\tlogUnsubscribeStarted(group, dataId);\n\t\tthis.zookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(e);\n\t}\n}", "CodeBleu_score": 72.76018895772593}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = getGroup();\n\tString dataId = getDataId();\n\tlogUnsubscribeStarted(group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe(group, dataId);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(group, dataId, e);\n\t}\n}", "CodeBleu_score": 73.90108770612738}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\ttry {\n\t\tString dataId = getDataId();\n\t\tString group = getGroup();\n\t\tlogUnsubscribeStarted(dataId, group);\n\t\tzookeeperListener.unsubscribe(dataId, group);\n\t} catch (Exception e) {\n\t\tlogUnsubscribeFailed(e);\n\t}\n}", "CodeBleu_score": 75.3801991269155}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 38.497174905089544}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zkServer = (ZookeeperServer) server;\n\t\treturn zkServer.getPayload().getMetadata();\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 58.713109862467114}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\t\treturn zookeeperServer.getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 65.66660252503722}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tif (curatorFramework == null) {\n\t\tthrow new IllegalStateException(\"CuratorFramework is not initialized\");\n\t}\n\n\tif (group == null) {\n\t\tthrow new IllegalArgumentException(\"group is null\");\n\t}\n\n\tif (serviceId == null) {\n\t\tthrow new IllegalArgumentException(\"serviceId is null\");\n\t}\n\n\tif (zookeeperSubscribeCallback == null) {\n\t\tthrow new IllegalArgumentException(\"zookeeperSubscribeCallback is null\");\n\t}\n\n\tfinal String path = ZookeeperUtil.createConfigPath(group, serviceId);\n\tfinal NodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tzookeeperSubscribeCallback.onConfigChanged(convertConfig(nodeCache.getCurrentData().getData()));\n\t\t}\n\t});\n\treturn new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 40.07765726351582}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.259896962984144}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.259896962984144}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tif (serviceDiscovery == null) {\n\t\treturn null;\n\t}\n\tZookeeperServerListDecorator zookeeperServerListDecorator = new ZookeeperServerListDecorator(config, serviceDiscovery);\n\tif (config.getLoadBalancer() instanceof LoadBalancer) {\n\t\tLoadBalancer loadBalancer = (LoadBalancer) config.getLoadBalancer();\n\t\tloadBalancer.setLoadBalancerStats(new ZookeeperLoadBalancerStats(config, serviceDiscovery));\n\t\tzookeeperServerListDecorator.setLoadBalancer(loadBalancer);\n\t}\n\tzookeeperServerListDecorator.setLoadBalancerListenerExecutor(new LoadBalancerListenerExecutor(config, serviceDiscovery));\n\tzookeeperServerListDecorator.setServiceId(config.getClientName());\n\treturn zookeeperServerListDecorator;\n}", "CodeBleu_score": 51.14396715284385}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(new ZookeeperServerList(config), new LoadBalancerStats(config), new ZookeeperLoadBalancer(config, serviceDiscovery), config);\n}", "CodeBleu_score": 29.61308713516019}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\tif (registration.isEphemeral()) {\n\t\ttry {\n\t\t\tzkClient.createEphemeral(registration.getPath(), new ZKDataSerializer().serialize(registration.getData()));\n\t\t} catch (KeeperException e) {\n\t\t\tthrow new IllegalStateException(\"Failed to create ephemeral node '\" + registration.getPath() + \"': \" + e.getMessage(), e);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IllegalStateException(\"Failed to create ephemeral node '\" + registration.getPath() + \"': \" + e.getMessage(), e);\n\t\t}\n\t} else {\n\t\ttry {\n\t\t\tzkClient.createPersistent(registration.getPath(), new ZKDataSerializer().serialize(registration.getData()));\n\t\t} catch (KeeperException e) {\n\t\t\tthrow new IllegalStateException(\"Failed to create persistent node '\" + registration.getPath() + \"': \" + e.getMessage(), e);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IllegalStateException(\"Failed to create persistent node '\" + registration.getPath() + \"': \" + e.getMessage(), e);\n\t\t}\n\t}\n}", "CodeBleu_score": 23.18860664349257}, {"code": "public void register(ZookeeperRegistration registration){\n\t", "CodeBleu_score": 3.363093373099123}, {"code": "public void register(ZookeeperRegistration registration){\n\t\tif (registration.isEphemeral()) {\n\t\tthis.serviceRegistry.register(registration);\n\t}\n\telse {\n\t\tthis.serviceRegistry.register(registration);\n\t}\n}", "CodeBleu_score": 12.235179739809102}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\tif (registration == null) {\n\t\tthrow new IllegalArgumentException(\"Registration must not be null\");\n\t}\n\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t}\n\tcatch (BeansException ex) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 73.89569901220845}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\tif (registration == null) {\n\t\tthrow new IllegalArgumentException(\"Registration must not be null\");\n\t}\n\tif (registration.getServiceId() == null) {\n\t\tthrow new IllegalArgumentException(\"Registration must have a serviceId\");\n\t}\n\tif (registration.getHost() == null) {\n\t\tthrow new IllegalArgumentException(\"Registration must have a host\");\n\t}\n\tif (registration.getPort() == 0) {\n\t\tthrow new IllegalArgumentException(\"Registration must have a port\");\n\t}\n\n\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 74.04724676995336}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t// 1. Get group and dataId values\nString group = globalConfig? \"global\" : \"local\";\nString dataId = globalConfig? \"global.properties\" : \"local.properties\";\n\n// 2. Log the subscription start\nlogger.info(\"Subscribing to \" + group + \" configuration changes for \" + dataId);\n\n// 3. Attempt to subscribe using zookeeperOperation\ntry {\nreturn zookeeperOperation.subscribeConfig(group, dataId, new ConfigCallback());\n} catch (Exception e) {\n// 4. If an exception occurs, log the subscription failure\nlogger.error(\"Failed to subscribe to \" + group + \" configuration changes for \" + dataId, e);\n}\n\n// 5. Return null if the subscription fails\nreturn null;\n}", "CodeBleu_score": 36.459550980385124}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalConfig.getGroup() : config.getGroup();\n\tString dataId = globalConfig? globalConfig.getDataId() : config.getDataId();\n\tString dataIdWithGroup = dataId + \"/\" + group;\n\tif (log.isInfoEnabled()) {\n\t\tlog.info(\"Subscribe Config: \" + dataIdWithGroup);\n\t}\n\ttry {\n\t\tif (zkClient == null) {\n\t\t\tzkClient = new ZkClient(config.getServerAddresses(), config.getSessionTimeoutMs(), config.getConnectionTimeoutMs(), new ZkSerializer());\n\t\t}\n\t\tif (zkClient.exists(dataIdWithGroup)) {\n\t\t\treturn zkClient.subscribeDataChanges(dataIdWithGroup, new ConfigChangeListener(dataIdWithGroup, globalConfig));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Subscribe Config Failed: \" + dataIdWithGroup, e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 35.22382775933283}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = globalConfig.getGroup();\n\t\tdataId = globalConfig.getDataId();\n\t} else {\n\t\tgroup = config.getGroup();\n\t\tdataId = config.getDataId();\n\t}\n\tif (group == null || dataId == null) {\n\t\treturn null;\n\t}\n\tlog.info(\"Subscribing to config: \" + group + \"/\" + dataId);\n\tZookeeperListener listener = new ZookeeperListener(group, dataId);\n\ttry {\n\t\tzookeeperOperation.subscribe(listener);\n\t} catch (Exception e) {\n\t\tlog.error(\"Subscribe config failed.\", e);\n\t\treturn null;\n\t}\n\treturn listener;\n}", "CodeBleu_score": 38.539998470861754}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = environment.getProperty(ZOOKEEPER_CONNECTION_STRING);\n\tif (StringUtils.isBlank(connectionString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is not configured\");\n\t}\n\tCuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(connectionString)\n\t\t\t.retryPolicy(new ExponentialBackoffRetry(environment.getProperty(ZOOKEEPER_RETRY_COUNT, Integer.class), environment.getProperty(ZOOKEEPER_SLEEP_TIME, Integer.class)));\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 39.176623965477646}, {"code": "public CuratorFramework curatorFramework(){\n\tCuratorFramework curatorFramework = null;\ntry {\nString connectString = environment.getProperty(ZOOKEEPER_CONNECT_STRING);\nif (StringUtils.isEmpty(connectString)) {\nthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n}\ncuratorFramework = CuratorFrameworkFactory.newClient(connectString, new ExponentialBackoffRetry(environment.getProperty(ZOOKEEPER_RETRY_COUNT), environment.getProperty(ZOOKEEPER_SLEEP_TIME)));\ncuratorFramework.start();\n} catch (Exception e) {\nthrow new DiscoveryException(\"Failed to initialize CuratorFramework\", e);\n}\nreturn curatorFramework;\n}", "CodeBleu_score": 33.87712478619179}, {"code": "public CuratorFramework curatorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectionString(), retryPolicy());\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 10.818561028369754}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * Creates a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 47.52031032130162}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The bean method, which returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 47.52031032130162}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * GatewayStrategyRouteZookeeperProcessor bean method.\n\t * @return the new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 47.52031032130162}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(getZkHosts(), getSessionTimeoutMs(), getRetryPolicy(), getNamespace());\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 28.02485362231287}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(connectString)\n.namespace(namespace)\n.retryPolicy(retryPolicy)\n.sessionTimeoutMs(sessionTimeoutMs)\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 38.05851965760174}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(this.connectString)\n.sessionTimeoutMs(this.sessionTimeoutMs)\n.retryPolicy(this.retryPolicy)\n.namespace(this.namespace)\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 40.29123446455159}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\ttry {\nInterProcessMutex mutex = locksMap.get(path);\nif (mutex == null) {\nmutex = new InterProcessMutex(zk, path);\nlocksMap.put(path, mutex);\n}\nmutex.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(\"Unable to acquire lock\", e);\n}\n}", "CodeBleu_score": 28.015505882478365}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(path)) {\nlocksMap.get(path).acquire();\n} else {\nInterProcessMutex mutex = new InterProcessMutex(zk, path);\ntry {\nmutex.acquire();\nlocksMap.put(path, mutex);\n} catch (Exception e) {\nthrow new DistributedLockException(\"Could not acquire lock for path \" + path, e);\n}\n}\n}", "CodeBleu_score": 23.91098055464901}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\ttry {\n\t\tif (locksMap.containsKey(path)) {\n\t\t\tlocksMap.get(path).acquire(1000, TimeUnit.MILLISECONDS);\n\t\t} else {\n\t\t\tInterProcessMutex lock = new InterProcessMutex(zk, path);\n\t\t\tlocksMap.put(path, lock);\n\t\t\tlock.acquire(1000, TimeUnit.MILLISECONDS);\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(e);\n\t}\n}", "CodeBleu_score": 16.249814620391117}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tMap<Object, Object> properties = null;\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.ConfigType.PROPERTIES)) {\n\t\tproperties = genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.ConfigType.JSON)) {\n\t\tString configKey = getConfigKey(dtpProperties);\n\t\tString path = ZKPaths.makePath(nodePath, configKey);\n\t\tString value = getVal(path, curatorFramework);\n\t\tproperties = ConfigHandler.parseConfig(value);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 56.63939888987043}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tMap<Object, Object> properties = Maps.newHashMap();\nString nodePath = nodePath(dtpProperties);\nCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\nString configType = dtpProperties.getConfigType();\nif (configType.equalsIgnoreCase(DtpProperties.ConfigType.PROPERTIES.name())) {\nproperties = genPropertiesTypeMap(nodePath, curatorFramework);\n} else if (configType.equalsIgnoreCase(DtpProperties.ConfigType.JSON.name())) {\nString configKey = getConfigKey(dtpProperties);\nString value = getVal(nodePath, curatorFramework);\nproperties = ConfigHandler.parseConfig(value, configKey);\n}\nreturn properties;\n}", "CodeBleu_score": 55.105716849825505}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tString nodePath = ZKPaths.makePath(ZKPaths.makePath(zookeeper.getRootNode(), zookeeper.getConfigVersion()), zookeeper.getNode());\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tif (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.ConfigType.PROPERTIES)) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equalsIgnoreCase(DtpProperties.ConfigType.JSON)) {\n\t\tString path = ZKPaths.makePath(nodePath, getConfigKey(dtpProperties));\n\t\tString value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parseConfig(value);\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 51.92960214732697}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getDtpProperties();\n\tbindDtpProperties(environment, dtpProperties);\n\tMap<Object, Object> properties = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(environment);\n\tcreateZkPropertySource(environment, properties);\n}", "CodeBleu_score": 51.84169801662756}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getDtpProperties();\n\tif (dtpProperties!= null) {\n\t\tbindDtpProperties(environment, dtpProperties);\n\t\tgenPropertiesMap(dtpProperties);\n\t\tcheckPropertyExist(environment);\n\t\tcreateZkPropertySource(environment, propertiesMap);\n\t}\n}", "CodeBleu_score": 40.78418346360678}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = getDtpProperties();\n\tbindDtpProperties(environment, dtpProperties);\n\tMap<Object, Object> properties = genPropertiesMap(dtpProperties);\n\tcheckPropertyExist(environment);\n\tcreateZkPropertySource(environment, properties);\n}", "CodeBleu_score": 51.84169801662756}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tooKeeperRouteManager(builder, configInfo, (provider, config) => {\n\t\tvar serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n\t\tvar routeFactory = provider.GetRequiredService<IServiceRouteFactory>();\n\t\tvar logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n\t\tvar zookeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n\t\treturn new ZooKeeperServiceRouteManager(config, serializer, routeFactory, logger, zookeeperClientProvider);\n\t});\n}", "CodeBleu_score": 48.224649363859264}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tsterModule(new ZookeeperModule(configInfo));\nreturn this;\n}", "CodeBleu_score": 7.935345917678161}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tRouteManager = new ZooKeeperServiceRouteManager(configInfo);\n\tbuilder.RegisterAdapter<IServiceRouteManager>(serviceRouteManager).InstancePerLifetimeScope();\n\tbuilder.RegisterAdapter<ISerializer<byte[]>>(new ProtobufSerializer()).InstancePerLifetimeScope();\n\tbuilder.RegisterAdapter<ISerializer<string>>(new JsonSerializer()).InstancePerLifetimeScope();\n\tbuilder.RegisterAdapter<IServiceRouteFactory>(new ServiceRouteFactory()).InstancePerLifetimeScope();\n\tbuilder.RegisterAdapter<ILogger<ZooKeeperServiceRouteManager>>(new LoggerAdapter<ZooKeeperServiceRouteManager>(serviceRouteManager)).InstancePerLifetimeScope();\n\tbuilder.RegisterAdapter<IZookeeperClientProvider>(new ZookeeperClientProvider(configInfo)).InstancePerLifetimeScope();\n\treturn this;\n}", "CodeBleu_score": 35.82209881352381}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t  var commandManager = new ZookeeperServiceCommandManager(configInfo);\n//            builder.RegisterAdapter(provider => commandManager).As<IServiceCommandManager>();\n//            return this;\n//        }", "CodeBleu_score": 10.732983874874105}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tsterAdapter<IServiceCommandManager>(c => new ZookeeperServiceCommandManager(c.Resolve<ISerializer<string>>(), c.Resolve<ISerializer<byte[]>>(), c.Resolve<IServiceEntryManager>(), c.Resolve<ILogger<ZookeeperServiceCommandManager>>(), c.Resolve<IServiceRouteManager>(), c.Resolve<IZookeeperClientProvider>(), configInfo));\nreturn this;\n}", "CodeBleu_score": 49.89488638246795}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tp the command manager\nbuilder.RegisterAdapter<IServiceCommandManager>(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceEntryManager>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo));\n\n// 2. Set up the ZookeeperServiceCommandManager with the required services\nbuilder.RegisterAdapter<IServiceCommandManager>(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceEntryManager>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo));\n\n// 3. Register the ZookeeperServiceCommandManager with the container\nbuilder.RegisterAdapter<IServiceCommandManager>(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceEntryManager>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo));\n\n// 4. Return the ZookeeperModule instance\nreturn this;\n}", "CodeBleu_score": 38.103106725995644}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t", "CodeBleu_score": 8.063975559205591}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t", "CodeBleu_score": 8.063975559205591}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\nCheck.NotNull(path, nameof(path));\nif (provider == null) {\nif (!Path.IsPathRooted(path)) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\n}\nCheck.CheckCondition(provider!= null, nameof(provider));\nCheck.CheckCondition(!string.IsNullOrEmpty(path), nameof(path));\nvar source = new ZookeeperConfigurationSource {\nProvider = provider,\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n};\nbuilder.Add(source);\nreturn builder.Build();\n}", "CodeBleu_score": 62.38937421530195}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\nvar routes = _routes.ToList();\nforeach (var route in routes) {\nroute.Address = route.Address.Except(Address);\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 67.61518451361138}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\n\nforeach (var route in _routes) {\nroute.Address = route.Address.Except(Address);\n}\nawait SetRoutesAsync();\n}", "CodeBleu_score": 57.90503006505846}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\nvar routes = await GetRoutesAsync();\nforeach (var route in routes) {\nroute.Address = route.Address.Except(Address);\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 76.51028607807788}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePath = GetRoutePath(hostAddr);\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar existingRoutes = await zooKeeper.Item2.getChildrenAsync(routePath);\nvar existingRouteIds = existingRoutes.Select(i => i.Name).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar oldRouteIds = existingRouteIds.Except(newRouteIds).ToArray();\nforeach (var deletedRouteId in oldRouteIds) {\nvar address = routes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\nif (address.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(GetRoutePath(hostAddr) + \"/\" + deletedRouteId);\n}\n}\n}\n}", "CodeBleu_score": 49.24406009707346}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(p => GetRoutePath(p)).ToArray();\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar existingRoutes = await GetRoutesAsync(zooKeeper.Item1, zooKeeper.Item2);\nvar oldRouteIds = existingRoutes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\nforeach (var deletedRouteId in deletedRouteIds) {\nvar deletedRoute = existingRoutes.Where(p => p.ServiceDescriptor.Id == deletedRouteId).Select(p => p.Address).FirstOrDefault();\nif (deletedRoute!= null && deletedRoute.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(GetRoutePath(deletedRoute));\n}\n}\n}\n}", "CodeBleu_score": 51.47872153957085}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t", "CodeBleu_score": 4.511260546062985}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t_logger.LogDebug\n(\n$\"GetRoute(byte[] data): {data?.Length} bytes\");\n\nif \n(data == null) {\nreturn null;\n}\n\nvar descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\nreturn await _serviceRouteFactory.CreateAsync(descriptor);\n}", "CodeBleu_score": 27.213064871809834}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null)\nreturn null;\n\n_logger.LogDebug\n($\"GetRoute(data.Length = {data.Length})\");\n\nvar descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n\nreturn await _serviceRouteFactory.CreateServiceRoute(descriptor);\n}", "CodeBleu_score": 30.432032540918076}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) return null;\n_logger.LogDebug(\"GetRoute(byte[] data) {\");\n_logger.LogDebug($\"data: {data}\");\n_logger.LogDebug(\"}\");\n\nvar descriptor = Deserialize(data);\nreturn await GetRoute(descriptor);\n}", "CodeBleu_score": 39.0411033502122}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tData == null && newData == null) return;\nif (oldData!= null && newData!= null && DataEquals(oldData, newData)) return;\nvar newRoute = await GetRoute(newData);\nvar oldRoute = await GetRoute(oldData);\nif (newRoute == null && oldRoute == null) return;\nif (newRoute == null) {\nif (oldRoute!= null) {\n_routes.Remove(oldRoute);\nOnChanged(oldRoute, null);\n}\nreturn;\n}\nif (oldRoute == null) {\n_routes.Add(newRoute);\nOnChanged(null, newRoute);\nreturn;\n}\nif (oldRoute.ServiceDescriptor.Id!= newRoute.ServiceDescriptor.Id) {\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\nOnChanged(oldRoute, newRoute);\n}\n}", "CodeBleu_score": 43.25069038084474}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tdData == null && newData == null)\nreturn;\n\nif (oldData == null)\n{\nvar newRoute = await GetRoute(newData);\n_routes.Add(newRoute);\n_logger.LogInformation($\"\u6dfb\u52a0\u670d\u52a1\u8def\u7531\uff1a{newRoute.ServiceDescriptor.Id}\u3002\");\n\nOnChanged(newServiceRouteEventArgs(newRoute, null));\nreturn;\n}\n\nif (newData == null)\n{\nvar oldRoute = await GetRoute(oldData);\n_routes.Remove(oldRoute);\n_logger.LogInformation($\"\u79fb\u9664\u670d\u52a1\u8def\u7531\uff1a{oldRoute.ServiceDescriptor.Id}\u3002\");\n\nOnChanged(newServiceRouteEventArgs(null, oldRoute));\nreturn;\n}\n\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\n\nif (DataEquals(oldRoute.Data, newRoute.Data))\nreturn;\n\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n_logger.LogInformation($\"\u66f4\u65b0\u670d\u52a1\u8def\u7531\uff1a{newRoute.ServiceDescriptor.Id}\u3002\");\n\nOnChanged(newServiceRouteEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 38.087952644802115}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tData == null && newData == null)\nreturn;\n\nif (DataEquals(oldData, newData))\nreturn;\n\nvar oldRoute = GetRoute(oldData);\nvar newRoute = GetRoute(newData);\n\nif (oldRoute == null && newRoute == null)\nreturn;\n\nif (oldRoute == null)\n{\n_routes.Add(newRoute);\nreturn;\n}\n\nif (newRoute == null)\n{\n_routes.Remove(oldRoute);\nreturn;\n}\n\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n\nOnChanged(oldRoute, newRoute);\n}", "CodeBleu_score": 30.626477414972292}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tar serviceSubscribers = await GetSubscribers(subscribers.Select(p => p.ServiceDescriptor.Id));\nvar existingSubscribers = serviceSubscribers.Where(p => subscribers.Any(q => q.ServiceDescriptor.Id == p.ServiceDescriptor.Id));\nvar newSubscribers = subscribers.Except(existingSubscribers);\nvar updatedSubscribers = existingSubscribers.Select(p => {\nvar newAddresses = new HashSet<string>(p.Address.Concat(newSubscribers.Where(q => q.ServiceDescriptor.Id == p.ServiceDescriptor.Id).SelectMany(q => q.Address)));\nreturn new ServiceSubscriber(p.ServiceDescriptor, newAddresses);\n});\nawait base.SetSubscribersAsync(updatedSubscribers.Concat(newSubscribers));\n}", "CodeBleu_score": 34.98636681860946}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t", "CodeBleu_score": 2.5773076157108115}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tar serviceSubscribers = await GetSubscribers(subscribers.Select(p => p.ServiceDescriptor.Id));\nvar existingSubscribers = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\nif (existingSubscribers!= null) {\nexistingSubscribers.Address = existingSubscribers.Address.Concat(subscriber.Address.Except(existingSubscribers.Address)).ToArray();\n}\nawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 62.46197882786042}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar rootPath = $\"{_servicePath}/subscribers\";\nif\n_logger.LogDebug\nchildrens.Count\n           if\n_logger.IsEnabled\n }", "CodeBleu_score": 14.638237783764005}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t var rootPath = $\"{_config.Root}/{_config.SubscriberPath}\";\n var subscribers = new List<ServiceSubscriber>();\n if\n_logger.LogDebug\nchildrens.Count\n           if\n_logger.IsEnabled\n }", "CodeBleu_score": 18.565027580194236}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar rootPath = $\"{_rootPath}/{_nodeName}/subscribers\";\nif\n_logger.LogDebug\nchildrens.Count\n           if\n_logger.IsEnabled\n }", "CodeBleu_score": 18.461219518387523}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) return;\n\tvar zooKeeper = await GetZooKeeper();\n\tvar children = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\n\t_subscribers = GetSubscribers(children);\n}", "CodeBleu_score": 27.503261745390397}, {"code": "private async Task EnterSubscribers(){\n\tar zooKeeper = await GetZooKeeper();\nvar subscriberPath = _configInfo.SubscriberPath;\nif (!subscriberPath.EndsWith(\"/\"))\nsubscriberPath += \"/\";\n\nif (_subscribers!= null)\nreturn;\n\nvar childrens = await zooKeeper.Item2.getChildrenAsync(subscriberPath);\nif (childrens.Count == 0) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"Subscriber path {subscriberPath} does not exist.\");\n_subscribers = new ServiceSubscriber[0];\nreturn;\n}\n\n_subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 45.56087155563212}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null)\n\t\treturn;\n\n\tvar zooKeeper = await GetZooKeeper();\n\tvar childrens = await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath);\n\tvar subscribers = await GetSubscribers(childrens);\n\t_subscribers = subscribers;\n}", "CodeBleu_score": 30.272418479974196}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.5875867509581765}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.5875867509581765}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tData!= null && newData!= null && DataEquals(oldData, newData))\n{\nreturn;\n}\nvar newCommand = GetServiceCommand(newData);\nif (newCommand == null)\n{\nreturn;\n}\nvar oldCommand = _serviceCommands.FirstOrDefault(i => i.ServiceId!= newCommand.ServiceId);\nif (oldCommand!= null)\n{\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId).Concat(new[] { newCommand }).ToArray();\n}\nelse\n{\n_serviceCommands = _serviceCommands.Concat(new[] { newCommand }).ToArray();\n}\nOnChanged(new ServiceCommandChangedEventArgs(oldCommand, newCommand));\n}", "CodeBleu_score": 65.49666434250993}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar nodeData = await _zooKeeper.GetDataAsync(watchedEvent.Path);\n\t\tawait _action(nodeData, _watcher.SetCurrentData(nodeData));\n\t}\n}", "CodeBleu_score": 14.400158281667883}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\tvar nodeData = await _zooKeeper.Item2.getDataAsync(watchedEvent.getPath());\n\t\t_action(nodeData, _watcher.GetCurrentData());\n\t\t_watcher.SetCurrentData(nodeData);\n\t}\n}", "CodeBleu_score": 43.955445103084564}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar data = await _zooKeeper.GetDataAsync(_path, true);\n\t\t_action(data, await _zooKeeper.GetDataAsync(_path));\n\t}\n}", "CodeBleu_score": 15.035617937864659}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tices.Register(provider => new DefaultZookeeperClientProvider(GetConfigInfo(configInfo),\nprovider.Resolve<IHealthCheckService>(),\nprovider.Resolve<IZookeeperAddressSelector>(),\nprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\nreturn builder;\n}", "CodeBleu_score": 50.981425087487786}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tices.Register(provider =>\nnew DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.Resolve<IHealthCheckService>(),\nprovider.Resolve<IZookeeperAddressSelector>(),\nprovider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\nreturn builder;\n}", "CodeBleu_score": 61.77754844744291}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tices.Register(provider =>\n       new DefaultZookeeperClientProvider(\n           GetConfigInfo(configInfo),\n        provider.Resolve<IHealthCheckService>(),\n          provider.Resolve<IZookeeperAddressSelector>(),\n          provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance;\nreturn builder;\n}", "CodeBleu_score": 61.821596425825945}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t_logger.LogInformation(\"Setting routes\");\n\nvar zooKeepers = await GetZooKeepers();\n\nforeach (var zooKeeper in zooKeepers) {\n_logger.LogInformation($\"Setting routes for {zooKeeper.ZooKeeper.ConnectString}\");\n\nforeach (var route in routes) {\nvar nodePath = GetRouteNodePath(route);\n\n_logger.LogInformation($\"Setting route {route.Route} for {zooKeeper.ZooKeeper.ConnectString}\");\n\nvar nodeExists = await zooKeeper.ZooKeeper.ExistsAsync(nodePath);\n\nif (nodeExists == null) {\n_logger.LogInformation($\"Creating node {nodePath} for {zooKeeper.ZooKeeper.ConnectString}\");\n\nawait zooKeeper.ZooKeeper.CreateAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_\n\n_logger.LogInformation($\"Updating node {nodePath} for {zooKeeper.ZooKeeper.ConnectString}\");\n\nawait zooKeeper.ZooKeeper.SetDataAsync(nodePath, GetRouteData(route));\n}\n}\n}\n}", "CodeBleu_score": 41.352663745210485}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\n}", "CodeBleu_score": 1.1662014589334855}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic);\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic);\n\tvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n\tvar existingRoutes = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopics[0]).Select(p => p.MqttEndpoint).FirstOrDefault();\n\n\tforeach (var address in existingRoutes.Addresses) {\n\t\tif (address.HostAddress == hostAddr.HostAddress) {\n\t\t\tforeach (var zooKeeper in _zookeeperClientProvider.GetZooKeepers()) {\n\t\t\t\tvar routePath = GetRoutePath(address);\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(routePath);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 37.374528119360775}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(r => r.MqttDescriptor.RoutePath);\nvar zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar currentRoutes = await zooKeeper.Item2.getChildrenAsync(routePaths.ToArray());\nvar oldRouteTopics = currentRoutes.Select(i => i.Path).ToArray();\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nvar route = routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\nif (route.Addresses.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(deletedRouteTopic);\n}\n}\n}\n}", "CodeBleu_score": 56.84562437783477}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(i => i.MqttDescriptor.RoutePath);\nvar zooKeeperClients = _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeeperClients) {\nvar existingRoutes = await GetRoutesAsync(zooKeeper.Item2);\nvar oldRouteTopics = existingRoutes.Select(i => i.MqttDescriptor.Topic);\nvar newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic);\nvar deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\nforeach (var deletedRouteTopic in deletedRouteTopics) {\nvar deletedRoutePath = GetRoutePath(deletedRouteTopic);\nvar deletedRouteEndpoint = existingRoutes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\nif (deletedRouteEndpoint!= null && deletedRouteEndpoint.Addresses.Contains(hostAddr)) {\nawait zooKeeper.Item2.deleteAsync(deletedRoutePath);\n}\n}\n}\n}", "CodeBleu_score": 52.46743612856666}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\nif (cacheDescriptors == null)\n\n{\n\nreturn;\n\n}\n\nif (!cacheDescriptors.Any())\n\n{\n\nreturn;\n\n}\n\nvar zooKeepers = await GetZooKeepersAsync();\n\nforeach (var zooKeeper in zooKeepers)\n\n{\n\nvar cachePath = GetCachePath(zooKeeper.ServiceId);\n\nvar nodeExists = await zooKeeper.ExistsAsync(cachePath);\n\nif (!nodeExists)\n\n{\n\nawait zooKeeper.CreateAsync(cachePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\n}\n\nforeach (var cacheDescriptor in cacheDescriptors)\n\n{\n\nvar nodePath = GetCacheNodePath(cacheDescriptor);\n\nvar nodeExists = await zooKeeper.ExistsAsync(nodePath);\n\nvar nodeData = await zooKeeper.GetDataAsync(nodePath);\n\nif (!nodeExists ||!DataEquals(nodeData, cacheDescriptor))\n\n{\n\nvar serializedDescriptor = JsonConvert.SerializeObject(cacheDescriptor);\n\nawait zooKeeper.SetDataAsync(nodePath, Encoding.UTF8.GetBytes(serializedDescriptor));\n\n}\n\n}\n\n}\n\n}", "CodeBleu_score": 31.51580924545912}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\n// If the path already exists, the function returns without doing anything.\nif (await zooKeeper.Item2.existsAsync(path))\n    return;\n\n// If the path does not exist, the function logs the creation process and iteratively creates each subdirectory in the path.\n_logger.LogInformation($\"Creating Zookeeper node path \\\"{path}\\\"\");\nvar directories = path.Split('/');\nfor (int i = 1; i < directories.Length; i++) {\n    var directory = string.Join(\"/\", directories.Take(i + 1));\n    if (await zooKeeper.Item2.existsAsync(directory))\n        continue;\n    await zooKeeper.Item2.createAsync(directory, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n\n}", "CodeBleu_score": 43.56504603515962}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t// If the path is empty, return\nif (string.IsNullOrWhiteSpace(path)) {\nreturn;\n}\n\n// Split the path into subdirectories\nstring[] subdirectories = path.Split('/');\n\n// Create a new Zookeeper client\nvar client = zooKeeper.Item2;\n\n// Create the first subdirectory\nstring currentPath = subdirectories[0];\n\n// Wait for the manual reset event\nzooKeeper.Item1.WaitOne();\n\n// Check if the first subdirectory exists\nif (!await client.ExistsAsync(currentPath)) {\n// If it does not exist, create it\nawait client.CreateAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\n// Log the creation of the first subdirectory\n_logger.LogInformation($\"Created subdirectory {currentPath}\");\n}\n\n// Iterate over the remaining subdirectories\nfor (int i = 1; i < subdirectories.Length; i++) {\ncurrentPath += $\"/{subdirectories[i]}\";\n\n// Check if the subdirectory exists\nif (!await client.ExistsAsync(currentPath)) {\n// If it does not exist, create it\nawait client.CreateAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\n// Log the creation of the subdirectory\n_logger.LogInformation($\"Created subdirectory {currentPath}\");\n}\n}\n}", "CodeBleu_score": 44.25909776667042}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t", "CodeBleu_score": 6.677050525407208}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar healthyAddresses = await _healthCheckService.GetHealthyAddresses();\nvar zookeeperClients = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in healthyAddresses) {\nvar zookeeperClient = CreateZooKeeper(address);\nzookeeperClients.Add((zookeeperClient.Item1, zookeeperClient.Item2));\n}\nreturn zookeeperClients;\n}", "CodeBleu_score": 61.81015933547077}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.Addresses) {\nvar healthCheck = await _healthCheckService.IsHealth(ipAddress);\nif (healthCheck.IsHealthy) {\nvar zookeeper = CreateZooKeeper(ipAddress);\nresult.Add((zookeeper.Item1, zookeeper.Item2));\n}\n}\nreturn result;\n}", "CodeBleu_score": 68.28829439541944}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.Addresses)\n{\nif (_healthCheckService.IsHealth(ipAddress))\n{\nvar zookeeper = CreateZooKeeper(ipAddress);\nresult.Add((zookeeper.Item1, zookeeper.Item2));\n}\n}\nreturn result;\n}", "CodeBleu_score": 65.72279892844493}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t     if (helper == null) {\n//            synchronized (this) {\n//                if (helper == null) {\n//                    helper = new ZooKeeperHelper(this);\n//                }\n//            }\n//        }\n//        return helper.getZooKeeper();\n        return new ZooKeeper(getConnectionString(), 5000, new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                if (event.getState() == Event.KeeperState.SyncConnected) {\n                    synchronized (this) {\n                        if (helper == null) {\n                            helper = new ZooKeeperHelper(ZooKeeperFactory.this);\n                        }\n                    }\n                }\n            }\n        });\n    }", "CodeBleu_score": 34.874925471488815}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\teper zooKeeper = null;\nif (helper!= null) {\n    zooKeeper = helper.getZooKeeper();\n}\nif (zooKeeper == null) {\n    zooKeeper = new ZooKeeper(getConnectionString(), getSessionTimeout(), new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            if (event.getState() == Event.KeeperState.SyncConnected) {\n                synchronized (ZooKeeperHelper.this) {\n                    ZooKeeperHelper.this.notifyAll();\n                }\n            }\n        }\n    });\n}\nreturn zooKeeper;\n}", "CodeBleu_score": 35.811496625964814}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (helper == null) {\n\t\t\thelper = new ZooKeeperHelper(connectionString, sessionTimeout, connectionTimeout, watcher);\n\t\t}\n\t\treturn helper.getZooKeeper();\n\t}\n}", "CodeBleu_score": 21.598655424862464}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\ttry {\n\t\t\tif (this.zk.getState()!= ZooKeeper.States.CLOSED) {\n\t\t\t\tthis.zk.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 15.889544712228101}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zooKeeper = null;\n\tif (this.zooKeeperHelper!= null) {\n\t\tzooKeeper = this.zooKeeperHelper.getZooKeeper();\n\t}\n\tif (zooKeeper!= null) {\n\t\tif (this.defaultWatcher!= null) {\n\t\t\tzooKeeper.register(this.defaultWatcher);\n\t\t}\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\tzooKeeper.close();\n\t\t} else {\n\t\t\tzooKeeper.close(waitForShutdownTimeoutMs);\n\t\t}\n\t}\n\tthis.zooKeeperHelper = null;\n}", "CodeBleu_score": 32.07762289206621}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\tthis.zk.close();\n\t\tthis.zk = null;\n\t}\n\tif (this.defaultWatcher!= null) {\n\t\tthis.defaultWatcher.clear();\n\t}\n}", "CodeBleu_score": 7.264261074764889}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlong waitTimeMs = connectionTimeoutMs;\n\twhile (!state.isConnected() && (waitTimeMs > 0)) {\n\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\tWatcher tempWatcher = new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t};\n\n\t\tstate.addParentWatcher(tempWatcher);\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\ttry {\n\t\t\tlatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\tstate.removeParentWatcher(tempWatcher);\n\t\t}\n\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\twaitTimeMs -= elapsed;\n\t}\n\treturn state.isConnected();\n}", "CodeBleu_score": 23.726024892186302}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlong waitTimeMs = connectionTimeoutMs;\n\twhile (!state.isConnected() && (waitTimeMs > 0)) {\n\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\tWatcher tempWatcher = new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t};\n\n\t\tstate.addParentWatcher(tempWatcher);\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\ttry {\n\t\t\tlatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\tstate.removeParentWatcher(tempWatcher);\n\t\t}\n\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\twaitTimeMs -= elapsed;\n\t}\n\treturn state.isConnected();\n}", "CodeBleu_score": 23.726024892186302}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (started.get()) {\n\t\tlong waitTimeMs = connectionTimeoutMs;\n\t\twhile (!state.isConnected() && (waitTimeMs > 0)) {\n\t\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\t\tWatcher tempWatcher = new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\tlatch.countDown();\n\t\t\t\t}\n\t\t\t};\n\n\t\t\tstate.addParentWatcher(tempWatcher);\n\t\t\tlong startTimeMs = System.currentTimeMillis();\n\t\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\t\ttry {\n\t\t\t\tlatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n\t\t\t} finally {\n\t\t\t\tstate.removeParentWatcher(tempWatcher);\n\t\t\t}\n\t\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\t\twaitTimeMs -= elapsed;\n\t\t}\n\t\treturn state.isConnected();\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 23.697243746409242}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t//    if (started) {\n//        try {\n//            log.info(\"Shutting down \" + serviceType.getName() + \"...\");\n//            started = false;\n//            service.shutdown();\n//            if (service.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n//                log.info(\"Shutdown complete\");\n//            } else {\n//                log.warn(\"Shutdown timed out\");\n//            }\n//        } catch (InterruptedException e) {\n//            if (!Thread.currentThread().isInterrupted()) {\n//                log.warn(\"Interrupted while shutting down \" + serviceType.getName());\n//            }\n//        } catch (IOException e) {\n//            if (!Thread.currentThread().isInterrupted()) {\n//                log.error(\"Error shutting down \" + serviceType.getName(), e);\n//            }\n//        }\n//    }\n}", "CodeBleu_score": 3.6105990761642457}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\ttry {\n    if (started) {\n        log.info(\"Shutting down {}...\", this.getClass().getSimpleName());\n        started = false;\n        if (state!= null) {\n            state.close();\n        }\n        if (waitForShutdownTimeoutMs > 0) {\n            long timeout = System.currentTimeMillis() + waitForShutdownTimeoutMs;\n            while (started && System.currentTimeMillis() < timeout) {\n                Thread.sleep(100);\n            }\n            if (started) {\n                log.error(\"Timed out waiting for service to shutdown\");\n            }\n        }\n    }\n}\ncatch (Exception e) {\n    if (!Thread.currentThread().isInterrupted()) {\n        log.error(\"Error shutting down \" + this.getClass().getSimpleName(), e);\n    }\n}\n}", "CodeBleu_score": 34.18552139950391}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\n//    if (started) {\n//        try {\n//            logger.info(\"Shutting down {}...\", this);\n//            started = false;\n//            if (waitForShutdownTimeoutMs > 0) {\n//                // wait for the service to shut down\n//                long startTime = System.currentTimeMillis();\n//                long endTime = startTime + waitForShutdownTimeoutMs;\n//                while (state.getState()!= State.STOPPED && System.currentTimeMillis() < endTime) {\n//                    Thread.sleep(100);\n//                }\n//                if (state.getState()!= State.STOPPED) {\n//                    logger.warn(\"Timed out waiting for {} to shut down.\", this);\n//                }\n//            }\n//            state.close();\n//            logger.info(\"Shutdown complete.\");\n//        } catch (InterruptedException e) {\n//            Thread.currentThread().interrupt();\n//            logger.warn(\"Interrupted while shutting down {}.\", this, e);\n//        } catch (IOException e) {\n//            logger.error(\"Error while shutting down {}.\", this, e);\n//        }\n//    }\n}", "CodeBleu_score": 3.6105990761642457}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t// TODO: Implement this function\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t//    throw new UnsupportedOperationException(\"Not supported yet.\"); //To change body of generated methods, choose Tools | Templates.\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: implement this function\n}", "CodeBleu_score": 1.4820082928049525}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (foundNode!= null && client.getSessionId()!= null &&!client.getSessionId().equals(client.getFoundSessionId())) {\nif (foundNode.equals(client.getProtectedPath())) {\nclient.log(\"Protected node has changed session, deleting node: \" + foundNode);\nclient.getZooKeeper().delete(foundNode, client.getFoundSessionId(), new VoidCallback() {\n@Override\npublic void doInBackground() throws Exception {\n}\n});\n} else {\nclient.log(\"Session has changed, deleting node: \" + foundNode);\nclient.getZooKeeper().delete(foundNode, client.getFoundSessionId(), new VoidCallback() {\n@Override\npublic void doInBackground() throws Exception {\n}\n});\n}\nreturn client.getZooKeeper().create(client.getProtectedPath(), client.getProtectedData(), ZooDefs.Ids.OPEN_ACL_UNSAFE, createMode);\n}\nreturn foundNode;\n}", "CodeBleu_score": 32.11353414294819}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (client.isSessionExpired()) {\n    LOG.warn(\"Session expired, deleting {} and re-creating with new session\", foundNode);\n    client.delete().forPath(foundNode);\n    client.getZooKeeper().delete(foundNode, client.getSessionId());\n    client.setSessionId(client.getZooKeeper().getSessionId());\n    return client.getZooKeeper().create(foundNode, new byte[0], Ids.OPEN_ACL_UNSAFE, createMode.getFlag());\n}\nreturn foundNode;\n}", "CodeBleu_score": 31.628269998965852}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (client.getSessionId()!= null &&!client.getSessionId().equals(client.getProtectedId())) {\n            LOG.info(\"Session changed from {} to {}\", client.getProtectedId(), client.getSessionId());\n            client.getFailedDeleteManager().deleteFailedDelete(foundNode, createMode.isEphemeral());\n            client.setProtectedId(client.getSessionId());\n        }\n        return foundNode;\n    }", "CodeBleu_score": 26.16815309023502}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Stat stat = new Stat();\n\tfinal Trace trace = traceManager.startTrace(TraceType.SET_ACL);\n\ttry {\n\t\ttrace.setPath(path);\n\t\ttrace.setStatus(TraceStatus.STARTED);\n\t\ttrace.setAclList(aclList);\n\t\ttrace.commit();\n\t\tStat result = null;\n\t\tint retryCount = 0;\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\tresult = zooKeeper.setACL(path, aclList, stat);\n\t\t\t\tbreak;\n\t\t\t} catch (KeeperException.NoAuthException e) {\n\t\t\t\tif (retryCount++ < 5) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tthrow e;\n\t\t\t} catch (KeeperException.ConnectionLossException e) {\n\t\t\t\tif (retryCount++ < 5) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t\ttrace.setStatus(TraceStatus.SUCCESS);\n\t\ttrace.setStat(result);\n\t\ttrace.commit();\n\t\treturn result;\n\t} catch (Exception e) {\n\t\ttrace.setStatus(TraceStatus.FAILURE);\n\t\ttrace.setException(e);\n\t\ttrace.commit();\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 29.787085057017006}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Trace trace = new Trace(this, \"pathInForeground\");\n\ttrace.start();\n\ttry {\n\t\treturn pathInBackground(path, aclList);\n\t} catch (final Exception e) {\n\t\ttrace.error(\"Exception\", e);\n\t\tthrow e;\n\t} finally {\n\t\ttrace.commit();\n\t}\n}", "CodeBleu_score": 22.47086784935768}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis(client, membershipPath, thisId, payload, false);\n}", "CodeBleu_score": 11.710997208837808}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tif (thisId == null || thisId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null or empty\");\n\t}\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tif (client == null) {\n\t\tthrow new IllegalArgumentException(\"client cannot be null\");\n\t}\n\tif (membershipPath == null || membershipPath.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"membershipPath cannot be null or empty\");\n\t}\n\tmembershipCache = new CuratorCache(client, membershipPath);\n\tmembershipCache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tswitch (event.getType()) {\n\t\t\tcase NODE_ADDED:\n\t\t\t\tonMemberAdded(event.getData());\n\t\t\t\tbreak;\n\t\t\tcase NODE_REMOVED:\n\t\t\t\tonMemberRemoved(event.getData());\n\t\t\t\tbreak;\n\t\t\tcase NODE_UPDATED:\n\t\t\t\tonMemberUpdated(event.getData());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t});\n\tmembershipCache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tswitch (event.getType()) {\n\t\t\tcase NODE_ADDED:\n\t\t\t\tonMemberAdded(event.getData());\n\t\t\t\tbreak;\n\t\t\tcase NODE_REMOVED:\n\t\t\t\tonMemberRemoved(event.getData());\n\t\t\t\tbreak;\n\t\t\tcase NODE_UPDATED:\n\t\t\t\tonMemberUpdated(event.getData());\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t});\n\ttry {\n\t\tclient.create().creatingParentsIfNeeded().forPath(membershipPath, payload);\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 37.638644448955226}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tif (thisId == null || thisId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Member ID cannot be null or empty\");\n\t}\n\tthis.cache = new CuratorCache(client, membershipPath);\n\tthis.node = new PersistentNode(client, membershipPath, payload);\n}", "CodeBleu_score": 43.146720591865304}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).thenCompose(name -> {\n\t\treturn async.checkExists().forPath(name);\n\t}).thenAccept(exists -> {\n\t\tif (exists!= null) {\n\t\t\tSystem.out.println(\"Node already exists\");\n\t\t} else {\n\t\t\tSystem.out.println(\"Node does not exist\");\n\t\t}\n\t}).exceptionally(exception -> {\n\t\texception.printStackTrace();\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 59.99419296529421}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t/ create a node at the given path asynchronously\nAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\nasync.create().forPath(path).whenComplete((name, exception) -> {\n    if (exception!= null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // set up a watch on the node\n        async.checkExists().forPath(path).whenComplete((result, exception) -> {\n            if (exception!= null) {\n                // there was a problem\n                exception.printStackTrace();\n            } else {\n                System.out.println(\"Watching node name is: \" + result.getPath());\n            }\n        });\n    }\n});\n}", "CodeBleu_score": 64.79787096729773}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).thenCompose(name -> {\n\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\treturn async.checkExists().forPath(path);\n\t}).thenAccept(watchedEvent -> {\n\t\tSystem.out.println(\"Watch triggered for: \" + watchedEvent);\n\t}).exceptionally(exception -> {\n\t\texception.printStackTrace();\n\t\treturn null;\n\t});\n}", "CodeBleu_score": 56.0527038085503}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = new ArrayList<OpResult>();\n\n\tfor (int i = 0; i < operations.size(); i++) {\n\t\tCuratorTransactionBridge op = operations.get(i);\n\t\ttry {\n\t\t\tOpResult result = op.doOperation();\n\t\t\tresults.add(result);\n\t\t} catch (KeeperException e) {\n\t\t\tif (e.code()!= KeeperException.Code.OK) {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn results;\n}", "CodeBleu_score": 26.642030777938764}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = new ArrayList<OpResult>();\nList<CuratorOp> ops = transaction.getOps();\nfor (CuratorOp op : ops) {\nOpResult result = op.doOperation(client);\nresults.add(result);\n}\n\nfor (OpResult result : results) {\nif (result.hasError()) {\nthrow new KeeperException.Code(result.getErr(), result.getPath());\n}\n}\nreturn results;\n}", "CodeBleu_score": 26.53457190743729}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t", "CodeBleu_score": 3.001154690052189}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\ttry {\n    // Get a list of all service names\n    List<String> serviceNames = serviceDiscovery.queryForNames();\n\n    // Print the service names and their instances\n    for (String serviceName : serviceNames) {\n        System.out.println(\"Service name: \" + serviceName);\n        List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n        for (ServiceInstance<InstanceDetails> instance : instances) {\n            outputInstance(instance);\n        }\n        System.out.println();\n    }\n} catch (NoNodeException e) {\n    System.out.println(\"No instances registered for any services.\");\n}\n\nserviceDiscovery.close();\n}", "CodeBleu_score": 58.45866628677966}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Query for all service names and their corresponding instances.\nMap<String, List<ServiceInstance<InstanceDetails>>> instancesByServiceName = serviceDiscovery.queryForInstances(\"service-a\", \"service-b\");\n\n// Print the service names and their instances.\nfor (String serviceName : instancesByServiceName.keySet()) {\n    System.out.println(\"Service: \" + serviceName);\n    for (ServiceInstance<InstanceDetails> instance : instancesByServiceName.get(serviceName)) {\n        outputInstance(instance);\n    }\n}\n\n// Catch the NoNodeException and print an error message.\n}", "CodeBleu_score": 38.557287126133076}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tList<String> names = serviceDiscovery.queryForNames();\n\tfor (String name : names) {\n\t\tSystem.out.println(name);\n\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(name);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 43.23128473236821}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\t// Filter out the READY_NODE constant.\n\tchildren = children.stream().filter(child ->!child.equals(READY_NODE)).collect(Collectors.toList());\n\t// Convert the filtered results to a list.\n\tList<String> filteredChildren = new ArrayList<>(children);\n\t// Sort the list in ascending order.\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 39.53626263963115}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren = children.stream().filter(c ->!c.equals(READY_NODE)).collect(Collectors.toList());\n\tCollections.sort(children);\n\treturn children;\n}", "CodeBleu_score": 31.89350656568569}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren = children.stream().filter(child ->!child.equals(READY_NODE)).collect(Collectors.toList());\n\tchildren.sort(Comparator.naturalOrder());\n\treturn children;\n}", "CodeBleu_score": 31.85823784183384}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk!= null) {\n    zk.close();\n}\nif (newHost!= null) {\n    zk = new ZooKeeper(newHost, timeout, this);\n} else {\n    zk = new ZooKeeper(hosts, timeout, this);\n}\n}", "CodeBleu_score": 23.902392361805944}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk!= null) {\nzk.close();\n}\n\nif (newHost == null) {\nreturn;\n}\n\nif (newHost.equals(host)) {\nreturn;\n}\n\nif (newHost.equals(\"\")) {\nreturn;\n}\n\nhost = newHost;\n\nif (readOnly) {\nzk = new ZooKeeper(host, timeout, new ReadOnlyWatcher());\n} else {\nzk = new ZooKeeper(host, timeout, this);\n}\n}", "CodeBleu_score": 38.16989832671872}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk!= null) {\nzk.close();\n}\n\nString[] hosts = newHost.split(\",\");\n\nList<String> hostList = new ArrayList<>();\nfor (String host : hosts) {\nhostList.add(host);\n}\n\nzk = new ZooKeeper(newHost, timeout, this);\n\nif (readOnly) {\nzk.setReadOnly();\n}\n}", "CodeBleu_score": 35.97365710868633}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<>();\nif (aclString == null) {\nreturn aclList;\n}\nString[] aclStrings = aclString.split(\",\");\nfor (String aclString1 : aclStrings) {\nString[] aclParts = aclString1.split(\":\");\nif (aclParts.length!= 3) {\noutputStream.write((\"Invalid ACL: \" + aclString1).getBytes());\n} else {\nString scheme = aclParts[0];\nString id = aclParts[1];\nString perms = aclParts[2];\nACL acl = new ACL();\nacl.setId(id);\nacl.setPerms(getPermFromString(perms));\naclList.add(acl);\n}\n}\nreturn aclList;\n}", "CodeBleu_score": 26.358385177427856}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nfor (String acl : aclString.split(\",\")) {\nString[] parts = acl.split(\":\");\nif (parts.length!= 3) {\noutputStream.write((\"Invalid ACL: \" + acl).getBytes());\ncontinue;\n}\nint perms = getPermFromString(parts[2]);\nif (perms == -1) {\ncontinue;\n}\nACL acl = new ACL();\nacl.setId(parts[1]);\nacl.setPerms(perms);\nacls.add(acl);\n}\nreturn acls;\n}", "CodeBleu_score": 29.973661233927906}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<>();\nString[] segments = aclString.split(\",\");\nfor (String segment : segments) {\nString[] parts = segment.split(\":\");\nif (parts.length!= 3) {\noutputStream.write((\"Invalid ACL: \" + segment).getBytes());\n}\nelse {\nString scheme = parts[0];\nString id = parts[1];\nint perm = getPermFromString(parts[2]);\nACL acl = new ACL(scheme, id, perm);\nacl.setId(id);\nacl.setPerms(perm);\nacls.add(acl);\n}\n}\nreturn acls;\n}", "CodeBleu_score": 25.11895758428906}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to \" + url + \"\n\");\nvar connection = new CuratorZookeeperConnectionFactory().create(ZookeeperParams.builder()\n.id(id)\n.url(url)\n.build());\nwriter.write(\"Connected to \" + url + \"\n\");\nvar zooKeeperMain = new ZooKeeperMain(connection);\nreturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 40.5750029243336}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tnecting to \"\n+ url\n+ \"...\n\n\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(aclList)\n.maxRetries(maxRetries)\n.connectionTimeout(connectionTimeout)\n.retryIntervalTime(retryIntervalTime)\n.sessionTimeout(sessionTimeout)\n.build();\nvar connection = factory.createAsync(params, listeners);\nwriter\n.write\n(\"Connected to \"\n+ url\n+ \"\n\n\");\nvar zooKeeperMain = new ZooKeeperMain(id, url, connection, listeners);\nreturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 36.17170046716166}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tnecting to\n\"\n+\nurl\n+\n\"\n.\n.\n.\n\n\"\n)\n;\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(aclList)\n.maxRetries(maxRetries)\n.connectionTimeout(connectionTimeout)\n.retryIntervalTime(retryIntervalTime)\n.sessionTimeout(sessionTimeout)\n.build\n();\nvar connection = factory.createAsync(params, serverListeners);\nwriter\n.write\n(\"Connected to\n\"\n+\nurl\n+\n\"\n.\n.\n.\n\n\"\n)\n;\nreturn new Terminal(id, url, connection, new ZooKeeperMain());\n}", "CodeBleu_score": 30.285978023502125}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tt retries = 0;\nwhile (!isConnected()) {\ntry {\nconnect();\n} catch (Exception e) {\ntry {\nclose();\n} catch (Exception e2) {\nthrow new IllegalStateException(e2);\n}\n\nif (++retries > 6) {\nthrow new IllegalStateException(\"Failed to establish SSH tunnel connection after 6 attempts.\");\n}\n\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\nthrow new IllegalStateException(e);\n}\n}\n}\n}", "CodeBleu_score": 40.900117311811584}, {"code": "public void blockUntilConnected(){\n\t/        if (sshClient.isConnected()) {\n//            return;\n//        }\n        int attempt = 1;\n        while (!sshClient.isConnected()) {\n            if (attempt > 6) {\n                close();\n                throw new IllegalStateException(\"Could not connect to SSH server after 6 attempts.\");\n            }\n            logger.info(\"Attempting to connect to SSH server. Attempt \" + attempt + \" of 6.\");\n            connect();\n            attempt++;\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        }\n    }", "CodeBleu_score": 36.78854988168724}, {"code": "public void blockUntilConnected(){\n\try {\n\t\tconnect();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 8.686403913211315}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error deleting node\", e);\n\t\tthrow new IllegalStateException(\"Error deleting node\", e);\n\t}\n}", "CodeBleu_score": 65.46054951248529}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"An error occurred while attempting to delete nodes from Zookeeper.\", e);\n\t\tthrow new IllegalStateException(\"An error occurred while attempting to delete nodes from Zookeeper.\", e);\n\t}\n}", "CodeBleu_score": 61.06480210354513}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node\", e);\n\t\tthrow new IllegalStateException(\"Error deleting node\", e);\n\t}\n}", "CodeBleu_score": 66.05258034021489}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServerConfig config = this.serverConfigService.getServerConfig(serverId);\n\tString connectionUrl = getConnectionUrl(config);\n\tthis.zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 21.58606823918824}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tTerminalConfig config = zookeeperDomainService.getServerTerminalConfig(serverId);\n\tString url = config.getSshTunnelEnabled()? config.getSshTunnelUrl() : config.getTerminalUrl();\n\tzookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 34.95173941439349}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// get the server configuration\n\tServerConfiguration serverConfiguration = serverConfigurationService.getServerConfiguration(serverId);\n\t// get the connection URL\n\tString connectionUrl = getConnectionUrl(serverConfiguration);\n\t// start the terminal\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 24.77794019842524}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zooKeeper = getZooKeeper(id);\n\t\tzooKeeper.execute(command);\n\t} catch (Exception e) {\n\t\tlogger.error(String.format(\"Error executing command %s on ZooKeeper %s\", command, id), e);\n\t\tthrow new RuntimeException(String.format(\"Error executing command %s on ZooKeeper %s\", command, id), e);\n\t}\n}", "CodeBleu_score": 33.500323761848335}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zooKeeper = zooKeeperMap.get(id);\n\t\tzooKeeper.execute(command);\n\t} catch (KeeperException e) {\n\t\tlog.error(\"Error executing command {} on server {}: {}\", command, id, e.getMessage());\n\t\tthrow new RuntimeException(\"Error executing command \" + command + \" on server \" + id + \": \" + e.getMessage());\n\t} catch (InterruptedException e) {\n\t\tlog.error(\"Error executing command {} on server {}: {}\", command, id, e.getMessage());\n\t\tthrow new RuntimeException(\"Error executing command \" + command + \" on server \" + id + \": \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 34.44858589195009}, {"code": "public void executeCommand(String id, String command){\n\t\t// TODO Auto-generated method stub\n\n}", "CodeBleu_score": 7.627707831999869}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tFile file = new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE);\n\t\tif (file.exists()) {\n\t\t\tprops.load(new FileInputStream(file));\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.err.println(e.getMessage());\n\t}\n\treturn props;\n}", "CodeBleu_score": 27.608109984092234}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nproperties.load(new FileInputStream(new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH)));\nlog.info(\"Loaded Zookeeper system properties from file \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH);\n} catch (FileNotFoundException e) {\nlog.error(\"Zookeeper system properties file \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH + \" not found. Using default Zookeeper system properties.\");\n} catch (IOException e) {\nlog.error(\"Error loading Zookeeper system properties from file \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH + \". Using default Zookeeper system properties.\");\n}\nreturn properties;\n}", "CodeBleu_score": 32.24639354070938}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nproperties.load(new FileInputStream(ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH));\n} catch (FileNotFoundException e) {\nLOGGER.warn(\"System properties file not found: \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH);\nreturn properties;\n} catch (IOException e) {\nLOGGER.warn(\"Failed to load system properties from file: \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH, e);\nreturn properties;\n}\nLOGGER.info(\"Loaded system properties from file: \" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE_PATH);\nreturn properties;\n}", "CodeBleu_score": 36.53167919205315}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\ttry {\nProperties props = new Properties();\nprops.load(new StringReader(content));\nfor (Entry<Object, Object> entry : props.entrySet()) {\nSystem.setProperty(entry.getKey().toString(), entry.getValue().toString());\n}\n} catch (Exception e) {\nLOGGER.error(\"Failed to load system properties from content\", e);\nshowNotification(e.getMessage(), Notification.Type.ERROR_MESSAGE);\n}\ntry {\nFileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\nProperties props = new Properties();\nfor (Entry<Object, Object> entry : props.entrySet()) {\nprops.setProperty(entry.getKey().toString(), entry.getValue().toString());\n}\nprops.store(fos, \"Zookeeper system properties\");\nfos.close();\n} catch (Exception e) {\nLOGGER.error(\"Failed to save system properties to file\", e);\nshowNotification(e.getMessage(), Notification.Type.ERROR_MESSAGE);\n}\n}", "CodeBleu_score": 33.02223190788809}, {"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties properties = new Properties();\ntry {\nproperties.load(new StringReader(content));\n} catch (IOException e) {\nlog.error(\"Failed to load system properties from content\", e);\nshowNotification(\"Failed to load system properties from content\", e);\nreturn;\n}\ntry {\nproperties.store(newOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n} catch (IOException e) {\nlog.error(\"Failed to save system properties to file\", e);\nshowNotification(\"Failed to save system properties to file\", e);\nreturn;\n}\n}", "CodeBleu_score": 29.10524690321331}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading properties from content: \" + e);\n\t\tshowNotification(e.getMessage(), Notification.TYPE_ERROR_MESSAGE);\n\t\treturn;\n\t}\n\ttry {\n\t\tprops.store(newOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n\t} catch (IOException e) {\n\t\tlog.error(\"Error saving properties to file: \" + e);\n\t\tshowNotification(e.getMessage(), Notification.TYPE_ERROR_MESSAGE);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 32.33461620821683}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tBufferedReader in = null;\n\tStringBuilder response = new StringBuilder();\n\ttry {\n\t\tin = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line = null;\n\t\twhile ((line = in.readLine())!= null) {\n\t\t\tresponse.append(line);\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Could not read from socket\", e);\n\t} finally {\n\t\tcleanup(in);\n\t\tcleanup(client);\n\t}\n\treturn response.toString();\n}", "CodeBleu_score": 49.126441832093846}, {"code": "private String response(Socket client){\n\tufferedReader in = null;\nStringBuilder response = new StringBuilder();\ntry {\nin = new BufferedReader(new InputStreamReader(client.getInputStream()));\nString line;\nwhile ((line = in.readLine())!= null) {\nresponse.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(\"Error reading from socket\", e);\n} finally {\ncleanup(in);\n}\nreturn response.toString();\n}", "CodeBleu_score": 48.64189049744145}, {"code": "private String response(Socket client){\n\tufferedReader in = null;\ntry {\nin = new BufferedReader(new InputStreamReader(client.getInputStream()));\n} catch (IOException e) {\nthrow new IllegalStateException(\"Could not create BufferedReader\", e);\n}\nStringBuilder response = new StringBuilder();\nString line;\ntry {\nwhile ((line = in.readLine())!= null) {\nresponse.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(\"Could not read from socket\", e);\n} finally {\ncleanup(in);\n}\nreturn response.toString();\n}", "CodeBleu_score": 48.375882213862496}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tatorFramework curatorFramework = curatorFramework(params);\n\tcuratorFramework.start();\n\n\ttry {\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(\"Could not connect to Zookeeper.\", e);\n\t}\n\n\treturn new CuratorZookeeperConnection<>(curatorFramework, params);\n}", "CodeBleu_score": 55.2269062032188}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\ttorFramework curatorFramework = curatorFramework(params);\ncuratorFramework.start();\n\ntry {\ncuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (Exception e) {\ncuratorFramework.close();\nthrow new ZookeeperConnectionException(e);\n}\n\nreturn new CuratorZookeeperConnection(curatorFramework, params);\n}", "CodeBleu_score": 47.7112913463009}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework curatorFramework = curatorFramework(params);\n\tcuratorFramework.start();\n\ttry {\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (InterruptedException e) {\n\t\tcuratorFramework.close();\n\t\tthrow new IllegalStateException(\"Connection interrupted\", e);\n\t}\n\tif (!curatorFramework.getZookeeperClient().isConnected()) {\n\t\tcuratorFramework.close();\n\t\tthrow new IllegalStateException(\"Connection failed\");\n\t}\n\treturn new CuratorZookeeperConnection(params, curatorFramework);\n}", "CodeBleu_score": 53.798466608478904}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.get()) {\nlog.info(\"Already synchronizing\");\nreturn\n}\nlog.info(\"Starting synchronization\");\nisSync.set(true);\ntry {\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener() {\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nswitch (event.getType()) {\ncase NODE_ADDED:\ncase NODE_UPDATED:\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeChanged(event.getData().getPath(), event.getData().getData());\n}\nbreak\ncase NODE_REMOVED:\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeRemoved(event.getData().getPath());\n}\nbreak\ndefault:\nbreak\n}\n}\n});\ntreeCache.start();\n}\ncatch (Exception e) {\nlog.error(\"Error synchronizing\", e);\ntreeCache.close();\n}\nfinally {\nisSync.set(false);\n}\n}", "CodeBleu_score": 46.73044285366158}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (!isSync.get()) {\nisSync.set(true);\ntry {\nString curConnectionString = getCurrentConnectionString();\nlogger.info(\"Starting Zookeeper synchronization for {}. Current connection string: {}\", id, curConnectionString);\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n@Override\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.nodeChanged(event);\n}\n}\n});\ntreeCache.start();\n} catch (Exception e) {\nlogger.error(\"Error starting Zookeeper synchronization for {}. Current connection string: {}. Error: {}\", id, curConnectionString, e.getMessage());\ntreeCache.close();\nisSync.set(false);\n}\n} else {\nlogger.info(\"Zookeeper synchronization for {} already in progress. Current connection string: {}\", id, getCurrentConnectionString());\n}\n}", "CodeBleu_score": 44.89149658643649}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.get()) {\nlog.info(\"Zookeeper sync already in progress. Skipping...\");\nreturn;\n}\ntry {\nlog.info(\"Starting Zookeeper sync...\");\nString connectionString = curatorFramework.getZookeeperClient().getConnectionString();\nlog.info(\"Zookeeper connection string: \" + connectionString);\nisSync.set(true);\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n@Override\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nswitch (event.getType()) {\ncase NODE_ADDED:\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeAdded(event.getData().getPath(), event.getData().getData());\n}\nbreak;\ncase NODE_UPDATED:\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeUpdated(event.getData().getPath(), event.getData().getData());\n}\nbreak;\ncase NODE_REMOVED:\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeRemoved(event.getData().getPath());\n}\nbreak;\n}\n}\n});\ntreeCache.start();\n}\ncatch (Exception e) {\nlog.error(\"Error starting Zookeeper sync\", e);\ntreeCache.close();\nisSync.set(false);\n}\n}", "CodeBleu_score": 45.01184258565299}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path cannot be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener cannot be null\");\n\t}\n\tif (!this.connected) {\n\t\tthrow new IllegalStateException(\"Not connected\");\n\t}\n\tif (this.watchingChildren) {\n\t\tthrow new IllegalStateException(\"Already watching children\");\n\t}\n\tthis.watchingChildren = true;\n\tthis.childrenCache = new PathChildrenCache(this.client, path, true);\n\tthis.childrenCache.getListenable().addListener(listener);\n\tthis.childrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 39.70272507472142}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tlog.info(\"Unregistering services...\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tcurator.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error deleting path: \" + path, e);\n\t\t}\n\t}\n\tcurator.close();\n}", "CodeBleu_score": 49.013131170694415}, {"code": "public void unregisterService(){\n\t\tlog.info(\"Unregistering services\");\n\ttry {\n\t\tfor (String path : paths) {\n\t\t\tlog.info(\"Deleting path: \" + path);\n\t\t\tcurator.delete().forPath(path);\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting path: \" + e.getMessage());\n\t} finally {\n\t\tcurator.close();\n\t}\n}", "CodeBleu_score": 49.66179814559015}, {"code": "public void unregisterService(){\n\t\tlog.info(\"Unregistering service...\");\n\ttry {\n\t\tfor (String path : paths) {\n\t\t\tclient.delete().forPath(path);\n\t\t\tlog.info(\"Deleted path: \" + path);\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting path: \" + e.getMessage());\n\t} finally {\n\t\tclient.close();\n\t}\n}", "CodeBleu_score": 49.71679534519285}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t/        CompletableFuture.runAsync(() -> makeClientReady(client, null), Executors.newSingleThreadExecutor())\n//               .thenApply(aVoid -> {\n//                    client.subscribeStateChanges(listener);\n//                    return null;\n//                });\n    }", "CodeBleu_score": 9.807841061921552}, {"code": "public void addListener(IZkStateListener listener){\n\t/        CompletableFuture.runAsync(() -> makeClientReady(client, null), executor)\n//               .thenRun(() -> client.subscribeStateChanges(listener));\n        client.subscribeStateChanges(listener);\n    }", "CodeBleu_score": 25.90985032054065}, {"code": "public void addListener(IZkStateListener listener){\n\tthis.client.subscribeStateChanges(listener);\n}", "CodeBleu_score": 5.68360949712927}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, new RetryOneTime(10000));\n}", "CodeBleu_score": 3.688177803772677}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t//    this(serverAddr, authority, new ExponentialBackoffRetry(1000, 3), 5000);\n}", "CodeBleu_score": 2.629007367308569}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, new RetryOneTime(1000), new RetryOneTime(1000));\n}", "CodeBleu_score": 4.078816098650778}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (listener == null)\n\t\treturn;\n\tsynchronized (listeners) {\n\t\tMap<String, ChildListener> map = listeners.get(path);\n\t\tif (map!= null) {\n\t\t\tmap.remove(listener);\n\t\t\tif (map.isEmpty())\n\t\t\t\tlisteners.remove(path);\n\t\t}\n\t\tif (childListeners.containsKey(path)) {\n\t\t\tTargetChildListener tcl = childListeners.get(path);\n\t\t\ttcl.remove(listener);\n\t\t\tif (tcl.isEmpty())\n\t\t\t\tchildListeners.remove(path);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.84957094323744}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tsynchronized (this) {\n\t\tMap<String, ChildListener> childListeners = childListeners.get(path);\n\t\tif (childListeners!= null) {\n\t\t\tchildListeners.remove(listener);\n\t\t\tif (childListeners.size() == 0) {\n\t\t\t\tchildListeners.remove(path);\n\t\t\t\tif (childListeners.size() == 0) {\n\t\t\t\t\tchildListeners.remove(path);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.907351832742414}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tsynchronized(this) {\n\t\tif (listener == null) return;\n\t\tMap<String, ChildListener> map = childListeners.get(path);\n\t\tif (map!= null) {\n\t\t\tmap.remove(listener);\n\t\t\tif (map.size() == 0) {\n\t\t\t\tchildListeners.remove(path);\n\t\t\t\tremoveTargetChildListener(path, listener);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.06744900900952}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn ret;\n\t}\n\tif (idc_host.empty()) {\n\t\tLOG_ERR(\"idc_host is empty\");\n\t\treturn ret;\n\t}\n\tif (zk_handle!= NULL) {\n\t\tlock_ht_delete(lock_ht, lock_mu, idc_host);\n\t\tzookeeper_close(zk_handle);\n\t\tzk_handle = NULL;\n\t}\n\tif (zk_handle == NULL) {\n\t\tzk_handle = zookeeper_init(idc_host.c_str, watcher, 10000, 0, NULL, 0);\n\t\tif (zk_handle == NULL) {\n\t\t\tLOG_ERR(\"zookeeper_init failed\");\n\t\t\treturn ret;\n\t\t}\n\t}\n\tif (zk_handle!= NULL) {\n\t\tinit_env_for_zk(zk_handle);\n\t\tret = QCONF_OK;\n\t}\n\treturn ret;\n}", "CodeBleu_score": 31.254761670150614}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\tLOG_ERR(\"zh is null\");\n\t\treturn ret;\n\t}\n\tmap<string, string> hosts;\n\tmap<string, string> idc_hosts;\n\tif (deserialize_from_idc_host(idc_hosts, hosts)!= QCONF_OK) {\n\t\tLOG_ERR(\"deserialize_from_idc_host error\");\n\t\treturn ret;\n\t}\n\tif (deserialize_from_zk_host(hosts)!= QCONF_OK) {\n\t\tLOG_ERR(\"deserialize_from_zk_host error\");\n\t\treturn ret;\n\t}\n\tif (zk_handle!= NULL) {\n\t\tlock_ht_delete(lock_ht, mu, zk_handle);\n\t\tzookeeper_close(zk_handle);\n\t}\n\tzk_handle = zookeeper_init(hosts[\"host\"].c_str, watcher_zk_connected, ZOOKEEPER_TIMEOUT, 0, (void *)zh, 0);\n\tif (zk_handle == NULL) {\n\t\tLOG_ERR(\"zookeeper_init error\");\n\t\treturn ret;\n\t}\n\tif (init_env_for_zk(zk_handle)!= QCONF_OK) {\n\t\tLOG_ERR(\"init_env_for_zk error\");\n\t\treturn ret;\n\t}\n\tret = QCONF_OK;\n\treturn ret;\n}", "CodeBleu_score": 36.89793471029699}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// 1. update internal tables\n\tidc_host_map[idc] = idc_host;\n\tidc_zk_map[idc] = zh;\n\n\t// 2. check connection state\n\tint ret = zoo_state(zh);\n\tif (ret == ZOO_CONNECTING_STATE) {\n\t\tLOG_FATAL_ERR(\"idc %s is connecting\", idc.c_str);\n\t} else if (ret == ZOO_CONNECTED_STATE) {\n\t\t// 3. register current host on the Zookeeper server\n\t\tstring notify_node = get_notify_node(idc);\n\t\tint ret = zk_register_ephemeral(zh, notify_node);\n\t\tif (ret == ZOK) {\n\t\t\t// 4. set watcher on the notify node\n\t\t\tret = watch_notify_node(zh, notify_node);\n\t\t\tif (ret == ZOK) {\n\t\t\t\t// 5. add IDC to gray list\n\t\t\t\tadd_gray_idc(idc);\n\t\t\t} else {\n\t\t\t\tLOG_FATAL_ERR(\"idc %s failed to set watcher on node %s\", idc.c_str, notify_node.c_str);\n\t\t\t}\n\t\t} else {\n\t\t\tLOG_FATAL_ERR(\"idc %s failed to register ephemeral node %s\", idc.c_str, notify_node.c_str);\n\t\t}\n\t} else {\n\t\tLOG_FATAL_ERR(\"idc %s failed to connect to Zookeeper\", idc.c_str);\n\t}\n}", "CodeBleu_score": 42.48855948641258}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tLOG_INFO(\"idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n\tif (zh == NULL) {\n\t\tLOG_FATAL_ERR(\"zh is NULL\");\n\t\treturn;\n\t}\n\n\t// update internal tables\n\tlock_ht_update(zk_ht, zk_mu, zh, zh);\n\tlock_ht_update(idc_ht, idc_mu, idc, idc_host);\n\n\t// check connection state\n\tint ret = zoo_state(zh);\n\tif (ret == ZOO_CONNECTED_STATE) {\n\t\t// register current host on the Zookeeper server\n\t\tret = zk_register_ephemeral(zh, idc_host, idc);\n\t\tif (ret == ZOK) {\n\t\t\t// set watcher on the notify node\n\t\t\tret = watch_notify_node(zh, idc);\n\t\t\tif (ret == ZOK) {\n\t\t\t\t// add IDC to the gray list\n\t\t\t\tadd_gray_idc(idc);\n\t\t\t} else {\n\t\t\t\tLOG_FATAL_ERR(\"watch_notify_node failed, ret: %d\", ret);\n\t\t\t}\n\t\t} else {\n\t\t\tLOG_FATAL_ERR(\"zk_register_ephemeral failed, ret: %d\", ret);\n\t\t}\n\t} else {\n\t\tLOG_FATAL_ERR(\"zoo_state failed, ret: %d\", ret);\n\t}\n}", "CodeBleu_score": 51.524010806718536}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// 1. Update internal tables with the handle and host information\n\tupdate_ht_zk(zh, idc_host, idc);\n\n\t// 2. Check the connection state of the Zookeeper handle\n\tif (zh->state == ZOO_CONNECTED_STATE) {\n\t\t// 3. Register the current host on the Zookeeper server\n\t\tadd_gray_idc(zh, idc_host, idc);\n\n\t\t// 4. Set a watcher on the notify node\n\t\twatch_notify_node(zh);\n\t} else {\n\t\tLOG_FATAL_ERR(\"Zookeeper handle is not connected, idc_host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n\t}\n}", "CodeBleu_score": 28.263282954593592}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(password.encode()).digest()\n    cred_hash = b64encode(cred_hash).strip()\n    return \"%s:%s\" % (username, cred_hash.decode())\n", "CodeBleu_score": 26.324481520072162}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(password.encode()).digest()\n    return '%s:%s' % (username, b64encode(cred_hash).strip())\n", "CodeBleu_score": 18.57459080254511}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + b\":\" + b64encode(cred_hash).decode()\n", "CodeBleu_score": 28.933068882292307}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element.lock_path\n    lock_value = self.processing_element.lock_value\n    return self.zk.exists(lock_path) and self.zk.get(lock_path)[0] == lock_value\n", "CodeBleu_score": 37.92728306019289}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.get_lock_path()\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.id\n", "CodeBleu_score": 30.600526967008967}, {"code": "def holds_lock(self)\n\t\n    return self.lock_path and self.client.exists(self.lock_path) and self.client.get(self.lock_path)[0] == self.instance_id\n", "CodeBleu_score": 9.538638817768067}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        value, stat = self.client.retry(self.client.get, lock_path)\n        if value == self.id:\n            with self.client.transaction(self.client.path_join(self._lock_path, self.id)):\n                self.client.delete(lock_path)\n                self.client.delete(self.client.path_join(self._lock_path, self.id))\n                self.processing_element = None\n            return True\n        else:\n            return False\n\n", "CodeBleu_score": 54.40608968356276}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    self.client.sync(lock_path)\n    with self.client.transaction(lock_path) as transaction:\n        transaction.delete(lock_path)\n        if self.processing_element is not None:\n            self.processing_element = None\n        transaction.commit()\n    return True\n\n", "CodeBleu_score": 53.979808262180754}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    self.client.sync(lock_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value!= self.id:\n        return False\n    transaction = self.client.transaction()\n    transaction.delete(lock_path)\n    transaction.delete(\"{path}/{id}\".format(path=self._lock_path, id=lock_id))\n    transaction.commit()\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 58.259602496343646}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t    header = self._read_header(read_timeout)\n    buffer = self._read(header.size, read_timeout)\n    self.logger.debug(\"Read %d bytes\", header.size)\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Read ping response\")\n    elif header.xid == AUTH_XID:\n        self._read_auth_response(header, buffer)\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, 0)\n    else:\n        self._read_response(header, buffer, 0)\n", "CodeBleu_score": 31.82858383086269}, {"code": "def _read_socket(self, read_timeout)\n\t    self._read_header(read_timeout)\n    self._read_watch_event(self._buffer, self._offset)\n    self._read_response(self._header, self._buffer, self._offset)", "CodeBleu_score": 5.5813733814308915}, {"code": "def _read_socket(self, read_timeout)\n\t    buffer = b\"\"\n    offset = 0\n    while True:\n        try:\n            data = self._socket.recv(1024)\n        except socket.error as exc:\n            if exc.errno == errno.EAGAIN:\n                # Timeout\n                if read_timeout is not None:\n                    if read_timeout <= 0:\n                        return buffer, offset\n                    else:\n                        time.sleep(read_timeout)\n                        read_timeout -= read_timeout\n                        continue\n                else:\n                    return buffer, offset\n            else:\n                raise\n        except socket.timeout:\n            if read_timeout is not None:\n                if read_timeout <= 0:\n                    return buffer, offset\n                else:\n                    time.sleep(read_timeout)\n                    read_timeout -= read_timeout\n                    continue\n            else:\n                raise\n        except socket.error:\n            raise\n        if not data:\n            break\n        buffer += data\n    return buffer, offset", "CodeBleu_score": 23.51933054947294}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    log.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped:\n        try:\n            self.connect()\n            break\n        except ZookeeperError as e:\n            log.warning(\"Zookeeper connection failed: %s\" % e)\n            time.sleep(self.retry_interval)\n    log.info(\"Zookeeper connection loop stopped\")\n    self.connection_stopped.set()\n    self.trigger_session_callback(state=CLOSED)\n    log.info(\"Zookeeper connection loop stopped (2)\")\n", "CodeBleu_score": 37.48734675537141}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    try:\n        self.connect()\n    except KazooException as e:\n        self.log.warning(\"Failed to connect to Zookeeper: %s\" % e)\n        self.connection_stopped.set()\n        self.trigger_session_callback(zk.STATE_CLOSED)\n        self.log.info(\"Zookeeper connection loop stopped\")\n        return\n    self.connection_stopped.set()\n    self.trigger_session_callback(zk.STATE_CONNECTED)\n    self.log.info(\"Zookeeper connection loop stopped\")\n", "CodeBleu_score": 41.631769183718795}, {"code": "def zk_loop(self)\n\t\n    log", "CodeBleu_score": 0.3731343283582089}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    if identifier in sorted_members:\n        return sorted_partitions[sorted_members.index(identifier):]\n    else:\n        return []\n\n", "CodeBleu_score": 32.6335888103806}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    partition_index = sorted_members.index(identifier)\n    return sorted_partitions[partition_index::len(sorted_members)]\n", "CodeBleu_score": 33.93550406782369}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    identifier_index = sorted_members.index(identifier)\n    return sorted_partitions[identifier_index::len(sorted_members)]\n", "CodeBleu_score": 33.93468769181854}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    if self.participating:\n        self.participating = False\n        self.client.retry(self.client.delete, self.create_path)\n    self._best_effort_cleanup()\n\n", "CodeBleu_score": 38.5266132090296}, {"code": "def leave(self)\n\t\n    self.participating = False\n    self._best_effort_cleanup\n    retry\n\n", "CodeBleu_score": 21.281042690411624}, {"code": "def leave(self)\n\t\n    self.participating = False\n    self.client.retry(self.client.delete, self.create_path)\n    self._best_effort_cleanup()\n\n", "CodeBleu_score": 39.62966829967701}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\ttry {\n\t\tif (statusServer().equals(\"running\")) {\n\t\t\treturn Result.success(\"The HDFS over FTP server is already running.\");\n\t\t}\n\t\tif (statusServer().equals(\"not running\")) {\n\t\t\tstartServer();\n\t\t\treturn Result.success(\"The HDFS over FTP server has been started successfully.\");\n\t\t}\n\t\treturn Result.error(\"An error occurred while starting the HDFS over FTP server.\");\n\t} catch (Exception e) {\n\t\treturn Result.error(\"An error occurred while starting the HDFS over FTP server.\");\n\t}\n}", "CodeBleu_score": 31.50393862548061}, {"code": "public Result start(){\n\t\t// TODO Auto-generated method stub\n\treturn null;\n}", "CodeBleu_score": 1.7491138303215137}, {"code": "public Result start(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (statusServer().isSuccess()) {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMessage(\"The server is already running.\");\n\t\t} else {\n\t\t\tresult = startServer();\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 31.71351533548658}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\ttry {\n\t\tif (server!= null) {\n\t\t\tserver.stop();\n\t\t\tserver = null;\n\t\t\treturn new Result(Result.SUCCESS, \"Server stopped\");\n\t\t}\n\t\treturn new Result(Result.SUCCESS, \"Server is not running\");\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\treturn new Result(Result.FAILURE, \"Server could not be stopped\");\n\t}\n}", "CodeBleu_score": 31.481491188078593}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (running) {\n\t\t\tserver.stop();\n\t\t\trunning = false;\n\t\t\treturn new Result(true, \"Server stopped.\");\n\t\t} else {\n\t\t\treturn new Result(false, \"Server is not running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\treturn new Result(false, \"Error stopping server.\");\n\t}\n}", "CodeBleu_score": 33.160835582116945}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (running) {\n\t\t\tftpServer.stop();\n\t\t\trunning = false;\n\t\t\treturn Result.success(\"Server stopped\");\n\t\t} else {\n\t\t\treturn Result.failure(\"Server already stopped\");\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\treturn Result.failure(\"Error stopping server: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 31.123358451341232}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 39.923205031042976}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tgetDfs().mkdirs(getFullPath());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 38.13365917730316}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tprintStackTrace(e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 39.923205031042976}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getFileSystem();\n\t\tPath src = new Path(path.toString() + \"/\" + ftpFile.getName());\n\t\tPath dest = new Path(ftpFile.getParent().toString() + \"/\" + ftpFile.getName());\n\t\tfs.rename(src, dest);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.72254534154996}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fileSystem = FileSystem.get(URI.create(ftpFile.getDfs()), new Configuration());\n\t\tFileStatus status = fileSystem.getFileStatus(this);\n\t\tString newName = ftpFile.getParent().getName() + \"/\" + ftpFile.getName();\n\t\tfileSystem.rename(status.getPath(), URI.create(newName));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.32269586329887}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getFileSystem();\n\t\tfs.rename(this.path, ftpFile.path);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 50.18522554128775}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\tFileSystem fs = getDfs();\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus s : status) {\n\t\t\tFtpFile file = new FtpFile(this, s);\n\t\t\tfiles.add(file);\n\t\t}\n\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 23.47711798663462}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\tFileSystem fs = getFileSystem();\n\t\tFileStatus[] files = fs.listStatus(path);\n\t\tList<FtpFile> fileList = new ArrayList<FtpFile>();\n\n\t\tfor (FileStatus file : files) {\n\t\t\tFtpFile fileObj = new FtpFile(file);\n\t\t\tfileList.add(fileObj);\n\t\t}\n\n\t\treturn Collections.unmodifiableList(fileList);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error listing files in directory: \" + path, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 25.02560512858974}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\t// get the HDFS file system instance\n\t\tFileSystem fs = getDfs();\n\n\t\t// list the files in the directory\n\t\tFileStatus[] status = fs.listStatus(path);\n\n\t\t// construct virtual file names based on the base directory's virtual path\n\t\tString basePath = getAbsolutePath();\n\t\tFtpFile[] files = new FtpFile[status.length];\n\t\tfor (int i = 0; i < status.length; i++) {\n\t\t\tfiles[i] = new FtpFile(this, status[i], basePath);\n\t\t}\n\n\t\treturn Arrays.asList(files);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error listing files: \" + e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 33.0548680470731}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (configured) {\n\t\tthrow new FtpServerConfigurationException(\"Already configured\");\n\t}\n\n\tconfigured = true;\n\n\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data\", e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 23.444541128054507}, {"code": "public void configure(){\n\t\ttry {\n\t\tFile file = new File(getAbsolutePath());\n\t\tif (file.exists()) {\n\t\t\tuserDataProp = new Properties();\n\t\t\tuserDataProp.load(new FileInputStream(file));\n\t\t} else {\n\t\t\tuserDataProp = new Properties();\n\t\t}\n\t\tconfigured = true;\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data\", e);\n\t}\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 42.294399581199464}, {"code": "public void configure(){\n\t\ttry {\n\t\tsetConfigurationState(true);\n\t\tloadUserData();\n\t\tconvertDeprecatedPropertyNames();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data\", e);\n\t}\n}", "CodeBleu_score": 15.145145075807372}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tFile userDataFile = getUserDataFile();\n\tFile parentDirectory = userDataFile.getParentFile();\n\tif (parentDirectory!= null &&!parentDirectory.exists()) {\n\t\tif (!parentDirectory.mkdirs()) {\n\t\t\tthrow new FtpException(\"Unable to create directory: \" + parentDirectory.getAbsolutePath());\n\t\t}\n\t}\n\ttry (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n\t\tfos.write(userData.getBytes());\n\t} catch (IOException e) {\n\t\tLOGGER.error(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t}\n}", "CodeBleu_score": 34.795139322616706}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile userFile = new File(userFileName);\n\tif (!userFile.getParentFile().exists()) {\n\t\tif (!userFile.getParentFile().mkdirs()) {\n\t\t\tthrow new FtpException(\"Unable to create user data directory.\");\n\t\t}\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(userFile);\n\t\tObjectOutputStream oos = new ObjectOutputStream(fos);\n\t\toos.writeObject(userData);\n\t\toos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Unable to save user data.\", e);\n\t\tthrow new FtpException(\"Unable to save user data.\", e);\n\t}\n}", "CodeBleu_score": 39.2451739096536}, {"code": "private void saveUserData() throws FtpException{\n\tFile file = new File(userDataFile.getAbsolutePath());\nFile parentDir = file.getParentFile();\nif (parentDir!= null &&!parentDir.exists() &&!parentDir.mkdirs()) {\nthrow new FtpException(\"Failed to create directory for user data file: \" + userDataFile.getAbsolutePath());\n}\ntry (FileOutputStream out = new FileOutputStream(file)) {\nout.write(userData.getBytes(StandardCharsets.UTF_8));\n} catch (IOException e) {\nlog.error(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath(), e);\nthrow new FtpException(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath(), e);\n}\n}", "CodeBleu_score": 43.721628435880284}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\tHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\ntry {\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 72.28018633537563}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\n    HdfsUserManager userManagerFactory = new HdfsUserManager();\n    userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n    userManagerFactory.delete(user);\n    return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\n    log.error(e);\n    return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 82.1770155143436}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tPath qualifiedPath = qualify(path);\nFSDataInputStream in = null;\ntry {\nin = new FSDataInputStream(new BufferedInputStream(store.open(qualifiedPath, bufferSize)));\n} catch (IOException e) {\nwarn(\"Exception opening \" + qualifiedPath + \" with bufferSize \" + bufferSize, e);\n}\nreturn in;\n}", "CodeBleu_score": 30.61216465518961}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tPath qualified = qualify(path);\nif (debug) {\nwarn(\"open \" + qualified + \" \" + bufferSize);\n}\ntry {\nreturn new FSDataInputStream(new BufferedInputStream(new FSDataInputStream(\nnew SeaweedFileSystemStore(qualified, bufferSize).open(qualified))));\n} catch (IOException e) {\nwarn(\"open \" + qualified + \" \" + bufferSize + \" failed: \" + e);\nreturn null;\n}\n}", "CodeBleu_score": 26.226194922847203}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tPath qualifiedPath = qualify(path);\n\ttry {\n\t\tFSDataInputStream in = fs.open(qualifiedPath);\n\t\tif (bufferSize > 0) {\n\t\t\tin = new BufferedFSDataInputStream(in, bufferSize);\n\t\t}\n\t\treturn in;\n\t} catch (IOException e) {\n\t\twarn(\"open(Path, int) for \" + qualifiedPath + \" failed: \" + e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 30.28468123653909}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t//        LOG.debug(\"rename path: {} => {}\", src, dst);\n\n//        if (src.isRoot()) {\n//            return false;\n//        }\n\n//        if (src.equals(dst)) {\n//            return true;\n//        }\n//        FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n//        Path adjustedDst = dst;\n\n//        if (entry!= null) {\n//            FileStatus dstFileStatus = getFileStatus(dst);\n//            String sourceFileName = src.getName();\n//            if (!dstFileStatus.isDirectory()) {\n//                return false;\n//            }\n//            adjustedDst = new Path(dst, sourceFileName);\n//        }\n\n//        Path qualifiedSrcPath = qualify(src);\n//        Path qualifiedDstPath = qualify(adjustedDst);\n\n//        seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n//        return true;\n\n//        return seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n//    }", "CodeBleu_score": 3.957500776646815}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 92.84785444656023}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (src.isRoot()) {\n\t\treturn false;\n\t}\n\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\n\tFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n\tPath adjustedDst = dst;\n\n\tif (entry!= null) {\n\t\tFileStatus dstFileStatus = getFileStatus(dst);\n\t\tString sourceFileName = src.getName();\n\t\tif (!dstFileStatus.isDirectory()) {\n\t\t\treturn false;\n\t\t}\n\t\tadjustedDst = new Path(dst, sourceFileName);\n\t}\n\n\tPath qualifiedSrcPath = qualify(src);\n\tPath qualifiedDstPath = qualify(adjustedDst);\n\n\tseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n\treturn true;\n}", "CodeBleu_score": 84.19205025432}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\t//TODO: implement hasCapability\n\treturn false;\n}", "CodeBleu_score": 6.236730668142945}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability == null) {\n\t\tthrow new NullPointerException();\n\t}\n\tcapability = capability.toLowerCase();\n\tif (capability.equals(\"hsync\") || capability.equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 38.64333485569238}, {"code": "public boolean hasCapability(String capability){\n\t\treturn (capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\")) && supportFlush;\n}", "CodeBleu_score": 34.299865855366924}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t//        if (offset >= 0) {\n//            // The offset is valid.\n//            if (offset > lastFlushOffset) {\n//                // The offset is greater than the last flush offset.\n//                // Flush the metadata to the service.\n//                writeMetadataToService();\n//                // Update the last flush offset.\n//                lastFlushOffset = offset;\n//            }\n//        } else {\n//            // The offset is invalid.\n//            // Flush the metadata to the service.\n//            writeMetadataToService();\n//        }\n}", "CodeBleu_score": 11.58463478293713}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset > this.lastFlushOffset) {\n\t\tthis.lastFlushOffset = offset;\n\t\tthis.metadata.flush();\n\t}\n}", "CodeBleu_score": 28.162419020453523}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tt bytesWritten = 0;\nif (bufferToWrite!= null) {\ntry {\nbufferToWrite.flip();\nbytesWritten = bufferToWrite.remaining();\nif (bytesWritten > 0) {\nwriteOperations.add(new WriteOperation(new FutureTask(new WriteTask(bufferToWrite, writePosition)), bytesWritten));\nif (writeOperations.size() > MAX_WRITE_QUEUE_SIZE) {\nshrinkWriteOperationQueue();\n}\n}\n} catch (BufferOverflowException e) {\nlastError = new IOException(e);\n}\n}\nreturn bytesWritten;\n}", "CodeBleu_score": 26.983406806836115}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t", "CodeBleu_score": 5.431302323101653}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tt bytesWritten = 0;\ntry {\nif (bufferToWrite.remaining() > 0) {\nif (writePosition > lastTotalAppendOffset) {\nlastTotalAppendOffset = writePosition;\n}\nif (writePosition < lastTotalAppendOffset) {\nthrow new IOException(\"Attempt to write to a position before the end of the file.  Position: \" + writePosition + \", Last position: \" + lastTotalAppendOffset);\n}\nif (writePosition == lastTotalAppendOffset) {\nbytesWritten = writeData(bufferToWrite, writePosition);\n} else {\nwriteOperations.add(new WriteOperation(bufferToWrite, writePosition));\nif (writeOperations.size() > 1000) {\nshrinkWriteOperationQueue();\n}\n}\n}\n} catch (Exception e) {\nlastError = new IOException(e);\nthrow lastError;\n}\nreturn bytesWritten;\n}", "CodeBleu_score": 28.626914967650453}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\t// poll for completion of the task\n\twhile (true) {\n\t\t// check for task completion\n\t\tif (completionService.poll() == null) {\n\t\t\t// no task was completed, so wait for the next one\n\t\t\tcompletionService.take();\n\t\t}\n\t\telse {\n\t\t\t// task completed, so break out of the loop\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 12.739839844758436}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tCompletionService<Void> completionService = this.completionService;\n\t\t\tif (completionService == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tCompletionService<Void> cs = completionService;\n\t\t\tFuture<Void> future = cs.poll();\n\t\t\tif (future == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (cs!= completionService) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tfuture.get();\n\t\t} catch (InterruptedException ex) {\n\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", ex);\n\t\t} catch (ExecutionException ex) {\n\t\t\tThrowable cause = ex.getCause();\n\t\t\tif (cause instanceof IOException) {\n\t\t\t\tthrow (IOException) cause;\n\t\t\t}\n\t\t\tif (cause instanceof RuntimeException) {\n\t\t\t\tthrow (RuntimeException) cause;\n\t\t\t}\n\t\t\tthrow new IOException(\"Unexpected exception while waiting for task to complete\", cause);\n\t\t}\n\t}\n}", "CodeBleu_score": 23.41915358044592}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\t// TODO Auto-generated method stub\n\n}", "CodeBleu_score": 2.867701401704043}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tif (writeOperationQueue.size() > 0) {\n\t\ttry {\n\t\t\tfor (int i = 0; i < writeOperationQueue.size(); i++) {\n\t\t\t\tif (writeOperationQueue.get(i).isDone()) {\n\t\t\t\t\twriteOperationQueue.get(i).get();\n\t\t\t\t\twriteOffset += writeOperationQueue.get(i).getLength();\n\t\t\t\t\twriteOperationQueue.remove(i);\n\t\t\t\t\ti--;\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 36.254755634280485}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (true) {\n\t\tif (writeOperationQueue.isEmpty()) {\n\t\t\treturn;\n\t\t}\n\t\tWriteOperation operation = writeOperationQueue.peek();\n\t\tif (operation.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\ttotalAppendOffset += operation.getLength();\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 26.315973762626722}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tfor (int i = 0; i < writeOperationQueue.size(); i++) {\n\t\tif (writeOperationQueue.get(i).isDone()) {\n\t\t\ttotalAppendOffset += writeOperationQueue.get(i).getLength();\n\t\t\twriteOperationQueue.remove(i);\n\t\t\ti--;\n\t\t}\n\t}\n}", "CodeBleu_score": 24.559837829199015}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user.getHomeDirectory() is null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory().getPath();\n}", "CodeBleu_score": 64.49662850546476}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null)\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\tif (user.getHomeDirectory() == null)\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory().getAbsolutePath();\n}", "CodeBleu_score": 56.38152426865075}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User must not be null.\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User must have a home directory.\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory().toString();\n}", "CodeBleu_score": 63.48013660252094}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\tif (dir.equals\n(\n\".\"\n)\n)\nreturn\ntrue\n;\nif (dir.equals\n(\n\"..\"\n)\n)\nreturn\nfalse\n;\nif (dir.startsWith\n(\n\"/\"\n)\n)\n{\nPath newPath\n=\nnew\nPath\n(\ndir\n)\n;\nif\n(\nnewPath\n.\nisAbsolute\n(\n)\n)\n{\nif\n(\nnewPath\n.\ngetParent\n(\n)\n.\nequals\n(\nnewPath\n)\n)\nreturn\nfalse\n;\ncurrentPath\n=\nnewPath\n;\nreturn\ntrue\n;\n}\nreturn\nfalse\n;\n}\nelse\n{\nPath newPath\n=\nnew\nPath\n(\ncurrentPath\ndir\n)\n;\nif\n(\nnewPath\n.\nisAbsolute\n(\n)\n)\n{\nif\n(\nnewPath\n.\ngetParent\n(\n)\n.\nequals\n(\nnewPath\n)\n)\nreturn\nfalse\n;\ncurrentPath\n=\nnewPath\n;\nreturn\ntrue\n;\n}\nreturn\nfalse\n;\n}\n}", "CodeBleu_score": 18.443370384065858}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.equals(\"..\")) {\n\t\tif (currentPath.getParent()!= null) {\n\t\t\tcurrentPath = currentPath.getParent();\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} else if (dir.startsWith(\"/\")) {\n\t\tcurrentPath = new Path(dir);\n\t\treturn true;\n\t} else {\n\t\tcurrentPath = currentPath.resolve(dir);\n\t\treturn currentPath.toFile().isDirectory();\n\t}\n}", "CodeBleu_score": 27.82081355823288}, {"code": "public boolean changeWorkingDirectory(String dir){\n\tif (dir == null)\nthrow new NullPointerException\n(\"dir\");\nif (dir.isEmpty())\nthrow new IllegalArgumentException\n(\"dir\");\nPath newPath = new Path(dir);\nif (newPath.isAbsolute()) {\nif (newPath.isParentOf(currentPath))\nreturn false;\ncurrentPath = newPath;\n} else {\ncurrentPath = currentPath.resolve(newPath);\n}\nreturn currentPath.isDirectory();\n}", "CodeBleu_score": 19.35516944664849}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tthis.accessMode = conf.getAccessMode();\n\tthis.accessVolumeServerByFilerProxy = conf.getAccessVolumeServerByFilerProxy();\n\tthis.accessVolumeServerByPublicUrl = conf.getAccessVolumeServerByPublicUrl();\n}", "CodeBleu_score": 31.23203667560295}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.conf = conf;\n\tthis.accessVolumeServer = conf.getAccessVolumeServer();\n\tthis.filerClient = new FilerClient(host, port, grpcPort);\n}", "CodeBleu_score": 33.75404736666889}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis(new FilerClient(host, port, grpcPort, conf));\n}", "CodeBleu_score": 13.521061229460141}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nfinal FilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\nthrow new FileNotFoundException(path.toString());\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 51.15662308137623}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nfinal FilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\nthrow new FileNotFoundException(\"File not found: \" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 61.976552533490846}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nfinal FilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\nthrow new FileNotFoundException(\"File not found: \" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path, entry);\n\n}", "CodeBleu_score": 58.909266613444345}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\tsuper.configure(conf);\nhostName = getHostName();\nnumThreadsPerMap = conf.getInt(\"mapred.thread.pool.size\", 1);\nnumFilesPerThread = conf.getInt(\"mapred.thread.pool.files\", 1);\n}", "CodeBleu_score": 19.68221045636314}, {"code": "public void configure(JobConf conf){\n\tsuper.configure(conf);\nthis.conf = conf;\ntry {\nthis.hostName = InetAddress.getLocalHost().getHostName();\n} catch (UnknownHostException e) {\nthis.hostName = \"localhost\";\n}\nthis.numThreadsPerMap = conf.getInt(\"mapred.thread.pool.size\", 1);\nthis.numFilesPerThread = conf.getInt(\"mapred.thread.pool.files\", 1);\nthis.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap, new ThreadFactory() {\npublic Thread newThread(Runnable r) {\nThread thread = new Thread(r);\nthread.setDaemon(true);\nreturn thread;\n}\n});\n}", "CodeBleu_score": 46.91621864252762}, {"code": "public void configure(JobConf conf){\n\tthis\n.conf\n=\nconf\n;\ntry {\nhostName\n=\nInetAddress\n.\ngetLocalHost\n(\n)\n.\ngetHostName\n(\n)\n;\n}\ncatch\n(UnknownHostException\ne)\n{\nhostName\n=\n\"localhost\"\n;\n}\nnumThreadsPerMap\n=\nconf\n.\ngetInt\n(\n\"mapred.job.map.tasks\"\n,\n1\n)\n;\nnumFilesPerThread\n=\nconf\n.\ngetInt\n(\n\"mapred.job.map.files\"\n,\n1\n)\n;\nthreadPool\n=\nnewFixedThreadPool\n(\nnumThreadsPerMap\n)\n;\n}", "CodeBleu_score": 36.12793942958263}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null)\n\t\tthrow new IllegalArgumentException(\"context cannot be null\");\n\tif (context.length() == 0)\n\t\tthrow new IllegalArgumentException(\"context cannot be empty\");\n\tif (!context.matches(\"^[a-zA-Z0-9_\\\\-]+$\"))\n\t\tthrow new IllegalArgumentException(\"context must match ^[a-zA-Z0-9_\\\\-]+$\");\n\tString current = getCurrent();\n\tif (current == null) {\n\t\tsetCurrent(context);\n\t} else {\n\t\tif (!isContextValid(current)) {\n\t\t\tsetCurrent(context);\n\t\t} else {\n\t\t\tif (!current.contains(context)) {\n\t\t\t\tsetCurrent(current + context);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 25.427204422128547}, {"code": "public static void setContext(String context) throws Exception{\n\t}", "CodeBleu_score": 3.1494709380915578}, {"code": "public static void setContext(String context) throws Exception{\n\t\t// TODO: Implement this function\n}", "CodeBleu_score": 3.1494709380915578}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs;\n\tRETURN_NOT_OK(connect(&fs));\n\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfsDelete(fs, uri.to_path().c_str, 0) == -1) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Error deleting file\"));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 53.354937983538164}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs;\nRETURN_NOT_OK(connect(&fs));\nRETURN_NOT_OK(libhdfs_->status());\nif (hdfsDelete(fs, uri.to_path().c_str, 0)!= 0) {\n  return LOG_STATUS(Status_HDFSError(\"Could not delete file \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 62.05591525824355}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs;\n\tRETURN_NOT_OK(connect(&fs));\n\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfsDelete(fs, uri.to_path().c_str, 0)!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not delete file\"));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 54.58957752721836}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t#ifdef HADOOP_HDFS_SYNC\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Failed to open file for sync\"));\n  }\n  RETURN_NOT_OK(libhdfs_->hdfsHFlush(file));\n  RETURN_NOT_OK(libhdfs_->hdfsCloseFile(file));\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_HDFSError(\"HDFS sync not supported\"));\n#endif\n}", "CodeBleu_score": 45.88374159728572}, {"code": "Status HDFS::sync(const URI& uri){\n\t//  LOG_STATUS(Status_HDFSError(\"Not implemented\"));\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == NULL) {\n    return LOG_STATUS(Status_HDFSError(\"Error opening file\"));\n  }\n  RETURN_NOT_OK(libhdfs_->hdfsHFlush(file));\n  RETURN_NOT_OK(libhdfs_->hdfsCloseFile(file));\n  return Status::Ok();\n}", "CodeBleu_score": 33.458631545962604}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\treturn Status::Ok();\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(),\n\t\t\tO_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Error opening file: \" + uri.to_path()));\n\t}\n\tint ret1 = libhdfs_->hdfsHFlush(fs, file);\n\tif (ret1!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Error flushing file: \" + uri.to_path()));\n\t}\n\tlibhdfs_->hdfsCloseFile(fs, file);\n\treturn Status::Ok();\n}", "CodeBleu_score": 51.72188440304756}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = nullptr;\n\thdfsFileInfo* info = nullptr;\n\tStatus status = connect(&fs);\n\tif (!status.ok()) {\n\t\treturn status;\n\t}\n\tif (uri.is_file()) {\n\t\tinfo = hdfsGetPathInfo(fs, uri.to_path().c_str, 0);\n\t\tif (info == nullptr) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\"HDFS file info not found\"));\n\t\t}\n\t\t*nbytes = info->mSize;\n\t\thdfsFreeFileInfo(info, 1);\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 43.37815775284609}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs;\n\tRETURN_NOT_OK(connect(&fs));\n\thdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str);\n\tif (file_info == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Error getting file information\"));\n\t}\n\t*nbytes = static_cast<uint64_t>(file_info->mSize);\n\thdfsFreeFileInfo(file_info, 0);\n\treturn Status::Ok();\n}", "CodeBleu_score": 37.73186923067197}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HDFS_DEBUG\n  LOG_INFO(\"HDFS::file_size: uri = %s\", uri.to_string().c_str());\n#endif\n  hdfsFileInfo* info;\n  Status status;\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  info = hdfsGetPathInfo(hdfs_, uri.to_path().c_str());\n  if (info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"HDFS::file_size: Failed to get file info for path: \" + uri.to_path()));\n  }\n  *nbytes = static_cast<uint64_t>(info->mSize);\n  hdfsFreeFileInfo(info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 48.91553870481472}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString quorum = null;\n\tString znodeParent = null;\n\tif (hbaseCfgString!= null) {\n\t\tString[] cfgArray = hbaseCfgString.split(\",\");\n\t\tif (cfgArray.length > 0) {\n\t\t\tquorum = cfgArray[0];\n\t\t}\n\t\tif (cfgArray.length > 1) {\n\t\t\tznodeParent = cfgArray[1];\n\t\t}\n\t}\n\tif (quorum == null) {\n\t\tquorum = \"localhost:2181\";\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 25.306538687120206}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString quorum = null;\nString znodeParent = null;\nString[] hbaseCfgArray = hbaseCfgString.split(\",\");\nfor (String hbaseCfg : hbaseCfgArray) {\nif (hbaseCfg.contains(\"zookeeper.znode.parent\")) {\nznodeParent = hbaseCfg.substring(hbaseCfg.indexOf(\"=\") + 1);\n}\nif (hbaseCfg.contains(\"zookeeper.quorum\")) {\nquorum = hbaseCfg.substring(hbaseCfg.indexOf(\"=\") + 1);\n}\n}\nif (quorum == null) {\nquorum = \"localhost:2181\";\n}\nif (znodeParent == null) {\nznodeParent = \"/hbase\";\n}\nreturn Pair.of(quorum, znodeParent);\n}", "CodeBleu_score": 24.40566688685996}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (hbaseCfgString == null) {\n\t\treturn new Pair<String, String>(null, null);\n\t}\n\tString hbaseCfg = hbaseCfgString.trim();\n\tif (hbaseCfg.isEmpty()) {\n\t\treturn new Pair<String, String>(null, null);\n\t}\n\tString[] hbaseCfgArray = hbaseCfg.split(\",\");\n\tString hbaseQuorum = null;\n\tString hbaseParent = null;\n\tfor (String hbaseCfgElement : hbaseCfgArray) {\n\t\tif (hbaseCfgElement.startsWith(\"hbase.zookeeper.quorum\")) {\n\t\t\thbaseQuorum = hbaseCfgElement.substring(21);\n\t\t} else if (hbaseCfgElement.startsWith(\"hbase.zookeeper.znode.parent\")) {\n\t\t\thbaseParent = hbaseCfgElement.substring(27);\n\t\t}\n\t}\n\tif (hbaseQuorum == null) {\n\t\treturn new Pair<String, String>(null, null);\n\t}\n\tif (hbaseParent == null) {\n\t\thbaseParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(hbaseQuorum, hbaseParent);\n}", "CodeBleu_score": 26.18056387507861}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\t//check table exist\n\t\tcheckTable(conn, cfg.getNamespace(), cfg.getTableName(), cfg.isThinClient());\n\t\t//check columns exist\n\t\tPTable table = getTableSchema(conn, cfg.getTableName());\n\t\tList<String> columnNames = cfg.getColumnNames();\n\t\tfor (String columnName : columnNames) {\n\t\t\tif (!table.getColumn(columnName).isPresent()) {\n\t\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXIST,\n\t\t\t\t\t\tString.format(\"The column [%s] does not exist in the table [%s].\", columnName, cfg.getTableName()));\n\t\t\t}\n\t\t}\n\t}\n\tcatch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.GET_HBASE_CONNECTION_ERROR,\n\t\t\t\t\"Unable to connect to hbase cluster, please check the configuration and cluster status \", e);\n\t}\n\tfinally {\n\t\tif (conn!= null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t\tcatch (SQLException e) {\n\t\t\t\tLOG.error(\"Failed to close the connection to the HBase cluster.\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.571416201546455}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t// 1.\u8fde\u63a5HBase\u96c6\u7fa4\n\tConnection conn = getJdbcConnection(cfg);\n\t// 2.\u68c0\u67e5namespace\u548c\u8868\u540d\u662f\u5426\u5b58\u5728\n\tString namespace = cfg.getNamespace();\n\tString tableName = cfg.getTableName();\n\tcheckTable(conn, namespace, tableName, cfg.isThinClient());\n\t// 3.\u83b7\u53d6\u8868\u7ed3\u6784\n\tPTable table = getTableSchema(conn, tableName);\n\t// 4.\u68c0\u67e5\u5217\u662f\u5426\u5b58\u5728\n\tcheckColumns(table, cfg.getColumns());\n\t// 5.\u5173\u95ed\u8fde\u63a5\n\ttry {\n\t\tconn.close();\n\t}\n\tcatch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.CLOSE_CONNECTION_ERROR, \"Close connection error\", e);\n\t}\n}", "CodeBleu_score": 26.615967325063462}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\ttry {\nif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\nConfiguration hadoopConfiguration = new Configuration();\nhadoopConfiguration.set(\"hadoop.security.authentication\", \"kerberos\");\nhadoopConfiguration.set(\"hadoop.security.auth_to_local\", \"kerberos\");\nUserGroupInformation.setConfiguration(hadoopConfiguration);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n}\n} catch (IOException e) {\nthrow new AddaxException(String.format(\"Kerberos authentication failed for principal: %s, keytab file path: %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n}\n}", "CodeBleu_score": 42.704743614195486}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\ntry {\nConfiguration conf = new Configuration();\nUserGroupInformation.setConfiguration(conf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nthrow new AddaxException(String.format(\"Kerberos login failed with principal %s and keytab file path %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n}\n}\n}", "CodeBleu_score": 40.34829141249384}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\ntry {\nConfiguration conf = new Configuration();\nUserGroupInformation.setConfiguration(conf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nthrow new AddaxException(String.format(\"Failed to login using principal %s and keytab file path %s\", kerberosPrincipal, kerberosKeytabFilePath), e);\n}\n}\n}", "CodeBleu_score": 39.99862732369297}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\nResultSetMetaData rsmd = rs.getMetaData();\nint numCols = rsmd.getColumnCount();\nfor (int i = 1; i <= numCols; i++) {\nString colName = rsmd.getColumnName(i);\nString colType = rsmd.getColumnTypeName(i);\nif (colName == null || colType == null) {\nthrow new SQLException(\"Column name or type is null\");\n}\ncolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\nreturn colMap;\n}", "CodeBleu_score": 37.808197282321665}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tfor (int i = 1; i <= numCols; i++) {\n\t    String colName = rsmd.getColumnLabel(i);\n\t    int colType = rsmd.getColumnType(i);\n\t    ThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(colName, colType);\n\t    columns.put(colName, col);\n\t}\n\treturn columns;\n    }", "CodeBleu_score": 32.96225993602951}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> cols = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData meta = rs.getMetaData();\n\tint colCount = meta.getColumnCount();\n\tfor (int i = 1; i <= colCount; i++) {\n\t    String colName = meta.getColumnLabel(i);\n\t    int colType = meta.getColumnType(i);\n\t    ThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(colName, colType);\n\t    cols.put(colName, col);\n\t}\n\treturn cols;\n    }", "CodeBleu_score": 34.50097023424024}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\theckTable(conn, tableName);\n\ttruncateTable(conn, tableName, true);\n}", "CodeBleu_score": 8.189961107872195}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, tableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 76.89175178086242}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\tString fileType = this.fileType;\n\tif (fileType == null) {\n\t\tfileType = HdfsConstant.TEXT;\n\t}\n\tif (checkHdfsFileType(filePath, fileType)) {\n\t\tsourceFiles.add(filePath);\n\t\tLOG.info(\"Add file {} to source files.\", filePath);\n\t}\n\telse {\n\t\tString message = String.format(\"The file type of the file [%s] does not match the configured file type [%s].\",\n\t\t\t\tfilePath, fileType);\n\t\tLOG.error(message);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n\t}\n}", "CodeBleu_score": 42.94742794550616}, {"code": "private void addSourceFileByType(String filePath){\n\tif (checkHdfsFileType(filePath, fileType)) {\nsourceFiles.add(filePath);\nLOG.info(\"add file {} to source file list\", filePath);\n}\nelse {\nString message = String.format(\"File %s is not %s file\", filePath, fileType);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n}\n}", "CodeBleu_score": 32.016142287921376}, {"code": "private void addSourceFileByType(String filePath){\n\tString fileExtension = getFileExtension(filePath);\nif (StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.ORC)) {\naddSourceFile(filePath, HdfsConstant.ORC);\n}\nelse if (StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.RC)) {\naddSourceFile(filePath, HdfsConstant.RC);\n}\nelse if (StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.SEQ)) {\naddSourceFile(filePath, HdfsConstant.SEQ);\n}\nelse if (StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.PARQUET)) {\naddSourceFile(filePath, HdfsConstant.PARQUET);\n}\nelse if (StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.CSV)\n|| StringUtils.equalsIgnoreCase(fileExtension, HdfsConstant.TEXT)) {\naddSourceFile(filePath, HdfsConstant.CSV);\n}\nelse {\nString message = String.format(\"Unsupported file type [%s] for file [%s].\", fileExtension, filePath);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n}\n}", "CodeBleu_score": 36.78617115919092}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\ttry {\n// Get the key class from the reader slice config\nClass keyClass = getKeyClass(readerSliceConfig);\n// Get the value class from the reader slice config\nClass valueClass = getValueClass(readerSliceConfig);\n// Log the start of the reading process\nLOG.info(\"Reading sequence file from path: \" + sourceSequenceFilePath);\n// Open the sequence file using the provided file path\nFileSystem fs = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\nFSDataInputStream inputStream = fs.open(new Path(sourceSequenceFilePath));\n// Read the key-value pairs from the sequence file\nwhile (inputStream.available() > 0) {\nString key = inputStream.readLine();\nString value = inputStream.readLine();\n// If the value is non-blank, transport the record using StorageReaderUtil\nif (isNotBlank(value)) {\ntry {\nrecordSender.send(\nStorageReaderUtil.readRecord(keyClass, valueClass, key, value, readerSliceConfig));\n} catch (Exception e) {\n// Log an error message and throw an AddaxException with relevant details\nLOG.error(\"Error reading record from sequence file: \" + sourceSequenceFilePath, e);\nthrow new AddaxException(\"Error reading record from sequence file: \" + sourceSequenceFilePath, e);\n}\n}\n}\n// Close the sequence file\ninputStream.close();\n} catch (Exception e) {\n// Log an error message and throw an AddaxException with relevant details\nLOG.error(\"Error reading sequence file: \" + sourceSequenceFilePath, e);\nthrow new AddaxException(\"Error reading sequence file: \" + sourceSequenceFilePath, e);\n}\n}", "CodeBleu_score": 36.27307670034751}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t//    try {\n//        FileSystem fs = FileSystem.get(URI.create(sourceSequenceFilePath), readerSliceConfig);\n//        FSDataInputStream fsDataInputStream = fs.open(new Path(sourceSequenceFilePath));\n//        SequenceFile.Reader reader = new SequenceFile.Reader(fs, new Path(sourceSequenceFilePath), readerSliceConfig);\n//        Text key = new Text();\n//        Text value = new Text();\n//        long count = 0;\n//        while (reader.next(key, value)) {\n//            if (value.toString().trim().length()!= 0) {\n//                try {\n//                    TransportRecord record = StorageReaderUtil.transportOneRecord(key, value, readerSliceConfig);\n//                    recordSender.sendRecord(record);\n//                } catch (AddaxException e) {\n//                    throw e;\n//                } catch (Exception e) {\n//                    throw new AddaxException(e.getMessage(), e);\n//                }\n//            }\n//            count++;\n//        }\n//        reader.close();\n//        fsDataInputStream.close();\n//        LOG.info(String.format(\"Sequence file start read finished. Total records: %d\", count));\n//    } catch (IOException e) {\n//        throw new AddaxException(e.getMessage(), e);\n//    }\n}", "CodeBleu_score": 4.241384187539755}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tan isSupportedFileType = false;\n\tif (filepath == null || specifiedFileType == null) {\n\t\tthrow new IllegalArgumentException(\"Filepath and specifiedFileType cannot be null.\");\n\t}\n\tif (filepath.isEmpty() || specifiedFileType.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Filepath and specifiedFileType cannot be empty.\");\n\t}\n\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(filepath), hadoopConf);\n\t\tFSDataInputStream in = fs.open(new Path(filepath));\n\t\tif (isRCFile(filepath, in)) {\n\t\t\tisSupportedFileType = true;\n\t\t}\n\t\telse if (isSequenceFile(new Path(filepath), in)) {\n\t\t\tisSupportedFileType = true;\n\t\t}\n\t\telse if (isParquetFile(new Path(filepath))) {\n\t\t\tisSupportedFileType = true;\n\t\t}\n\t\telse if (isORCFile(new Path(filepath), fs, in)) {\n\t\t\tisSupportedFileType = true;\n\t\t}\n\t\telse {\n\t\t\tLOG.info(\"The file [{}] is not [{}].\", filepath, specifiedFileType);\n\t\t}\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new AddaxException(e);\n\t}\n\tcatch (IOException e) {\n\t\tthrow new AddaxException(e);\n\t}\n\treturn isSupportedFileType;\n}", "CodeBleu_score": 31.745192920310476}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tilepath == null) {\n\t\treturn false;\n\t}\n\tif (specifiedFileType == null) {\n\t\treturn false;\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n\t\treturn isORCFile(new Path(filepath));\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n\t\treturn isRCFile(new Path(filepath));\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"SEQUENCE\")) {\n\t\treturn isSequenceFile(new Path(filepath));\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"PARQUET\")) {\n\t\treturn isParquetFile(new Path(filepath));\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n\t\treturn isCSVFile(new Path(filepath));\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(\"TEXT\")) {\n\t\treturn isTextFile(new Path(filepath));\n\t}\n\treturn false;\n}", "CodeBleu_score": 16.222646661231995}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\ttringUtils.isEmpty(filepath) || StringUtils.isEmpty(specifiedFileType)) {\n\t\treturn false;\n\t}\n\tboolean isFile = false;\n\tif (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n\t\tisFile = isORCFile(new Path(filepath), FileSystem.get(new Configuration()), null);\n\t}\n\telse if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n\t\tisFile = isRCFile(filepath, null);\n\t}\n\telse if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n\t\tisFile = isSequenceFile(new Path(filepath), null);\n\t}\n\telse if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n\t\tisFile = isParquetFile(new Path(filepath));\n\t}\n\telse if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n\t\tisFile = isCSVFile(new Path(filepath));\n\t}\n\telse if (specifiedFileType.equalsIgnoreCase(\"Text\")) {\n\t\tisFile = isTextFile(new Path(filepath));\n\t}\n\treturn isFile;\n}", "CodeBleu_score": 28.656532085593412}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new asAddaxException(e.getMessage(), e);\n\t}\n}", "CodeBleu_score": 44.6084989773364}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxException.ERROR_CODE_HBASE_CONNECTION_CLOSE_EXCEPTION, e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 42.50565391197066}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new asAddaxException(asAddaxException.HBASE_CLOSE_CONNECTION_ERROR, e.getMessage());\n\t}\n}", "CodeBleu_score": 46.32316215795424}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new asAddaxException(asAddaxException.IO_EXCEPTION, e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 39.230500482674366}, {"code": "public static void closeAdmin(Admin admin){\n\tif (admin!= null) {\ntry {\nadmin.close();\n} catch (IOException e) {\nthrow new asAddaxException(asAddaxException.ERROR_CODE_HBASE_ADMIN_CLOSE_FAILED, \"Failed to close HBase Admin instance: \" + e.getMessage());\n}\n}\n}", "CodeBleu_score": 41.87208056603809}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tcloseAsAddaxException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 32.13461335841677}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\tString rowKey = cell.getRow();\nlong timestamp = cell.getTimestamp();\nbyte[] family = cell.getFamilyArray();\nbyte[] qualifier = cell.getQualifierArray();\nbyte[] value = cell.getValueArray();\nrecord.addColumn(rowKey, family, qualifier, timestamp, value);\n}", "CodeBleu_score": 11.719293607151599}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t//    String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n//    long timestamp = cell.getTimestamp();\n//    String family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n//    String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n//    String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n//    record.addColumn(family, qualifier, timestamp, value);\n}", "CodeBleu_score": 2.1029777907619387}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\tString rowKey = cell.getRow().toString();\nString familyName = cell.getFamily().toString();\nString qualifierName = cell.getQualifier().toString();\nlong timestamp = cell.getTimestamp();\nbyte[] value = cell.getValue();\nString valueString = new String(value);\nString valueType = determineValueType(value);\nString valueFormat = determineValueFormat(value);\nString valueFormatted = formatValue(value, valueType, valueFormat);\nrecord.addColumn(familyName, qualifierName, timestamp, valueFormatted);\n}", "CodeBleu_score": 21.24484170035824}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(START_ROWKEY_PROPERTY);\n\tboolean isBinaryRowkey = configuration.getBoolean(BINARY_ROWKEY_PROPERTY, false);\n\treturn stringToBytes(startRowKey, isBinaryRowkey);\n}", "CodeBleu_score": 33.655728289815976}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(Constants.START_ROW_KEY);\n\tif (isBlank(startRowKey)) {\n\t\treturn new byte[0];\n\t}\n\treturn stringToBytes(startRowKey, configuration.getBoolean(Constants.BINARY_ROW_KEY, false));\n}", "CodeBleu_score": 35.33011114748661}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(Constants.START_ROW_KEY, \"\");\n\treturn stringToBytes(startRowKey, configuration.getBoolean(Constants.IS_BINARY_ROW_KEY, false));\n}", "CodeBleu_score": 27.672661477467653}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\treturn convertInnerStartRowkey(configuration, null);\n}", "CodeBleu_score": 11.874278016764812}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\treturn convertInnerStartRowkey(configuration, null);\n}", "CodeBleu_score": 11.874278016764812}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\treturn convertInnerStartRowkey(configuration, null);\n}", "CodeBleu_score": 11.874278016764812}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis\n.\nkey\n(\nUUID\n.\nfromString\n(\nrecord\n.\nkey\n(\n)\n)\n)\n;\nthis\n.\nheaders\n(\nnew\nTbQueueMsgHeaders\n(\nrecord\n.\nheaders\n(\n)\n)\n)\n;\nthis\n.\ndata\n(\nrecord\n.\nvalue\n(\n)\n)\n;\n}", "CodeBleu_score": 20.9712779541447}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis\n.key\n=\nUUID\n.\nfromString\n(\nrecord\n.\nkey\n)\n;\nthis\n.\nheaders\n=\nnew\nTbQueueMsgHeaders\n(\nrecord\n.\nheaders\n)\n;\nthis\n.\ndata\n=\nrecord\n.\nvalue\n;\n}", "CodeBleu_score": 17.27112438282318}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders(record.headers());\n\tthis.data = record.value();\n}", "CodeBleu_score": 41.799182095012796}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\treturn createTransportNotificationsMsgProducer(getSettings().getKafka());\n}", "CodeBleu_score": 10.846293360937192}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = null;\n\ttry {\n\t\tproducer = createTransportNotificationsMsgProducer(getKafkaSettings(), getClientId(), getNotificationsTopic());\n\t\tproducer.setAdmin(createAdmin(getKafkaSettings()));\n\t} catch (Exception e) {\n\t\tlogger.error(e.getMessage(), e);\n\t}\n\treturn producer;\n}", "CodeBleu_score": 30.881800458738812}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\treturn createTransportNotificationsMsgProducer(settings.getKafkaSettings(), getServiceId(), getNotificationsTopic());\n}", "CodeBleu_score": 14.202382115253076}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createToCoreNotificationsMsgConsumer(settings);\n}", "CodeBleu_score": 5.495779964822529}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createToCoreNotificationsMsgConsumer(settings, topic, clientId, groupId);\n}", "CodeBleu_score": 6.540067111040157}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createToCoreNotificationsMsgConsumer(settings, topic, clientId, groupId);\n}", "CodeBleu_score": 6.540067111040157}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\tif (!topicNames.isEmpty()) {\nfor (String topicName : topicNames) {\nif (!topicExists(topicName)) {\ncreateTopic(topicName);\n}\nsubscribe(topicName);\n}\n} else {\ninfo(\"No topics to subscribe to.\");\nunsubscribe();\n}\n}", "CodeBleu_score": 55.951911204408276}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlog.info(\"No topics specified, unsubscribing from all topics\");\nunsubscribe();\n} else {\nfor (String topicName : topicNames) {\nif (topicName.isEmpty()) {\nthrow new IllegalArgumentException(\"Topic name cannot be empty\");\n}\nif (!topics.containsKey(topicName)) {\nTopic topic = createTopic(topicName);\ntopics.put(topicName, topic);\n}\ntopics.get(topicName).subscribe(this);\n}\n}\n}", "CodeBleu_score": 49.012234224512284}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlog.info(\"No topics to subscribe to, unsubscribing consumer\");\nunsubscribe();\n} else {\nlog.info(\"Subscribing consumer to topics: \" + topicNames);\nfor (String topicName : topicNames) {\nif (!topics.containsKey(topicName)) {\nlog.info(\"Creating topic: \" + topicName);\ntopics.put(topicName, new Topic(topicName));\n}\n}\nsubscribe();\n}\n}", "CodeBleu_score": 50.20255748827669}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tfinal Stopwatch stopwatch = Stopwatch.createStarted();\n\tfinal List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\ttry {\n\t\tfinal ConsumerRecords<String, byte[]> recordsFromTopic = consumer.poll(Duration.ofMillis(durationInMillis));\n\t\tstopwatch.stop();\n\t\tif (recordsFromTopic.count() > 0) {\n\t\t\trecords.addAll(recordsFromTopic);\n\t\t\tLOGGER.info(\"Retrieved {} records from topic {} within {} ms\", recordsFromTopic.count(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\t\t} else {\n\t\t\tLOGGER.info(\"No records retrieved from topic {} within {} ms\", topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\t\t}\n\t} catch (final Exception e) {\n\t\tLOGGER.error(\"Error retrieving records from topic {} within {} ms\", topic, stopwatch.elapsed(TimeUnit.MILLISECONDS), e);\n\t}\n\treturn records;\n}", "CodeBleu_score": 44.218556141799056}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlog.info(\"Topic: \" + topic + \" Duration: \" + durationInMillis + \" ms\");\n\tlog.info(\"Total time taken: \" + (endTime - startTime) + \" ms\");\n\tif (records.isEmpty()) {\n\t\tlog.info(\"No records found\");\n\t}\n\treturn records;\n}", "CodeBleu_score": 33.40614287248357}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlog.info(\"Topic: {} Duration: {}ms Total Time: {}ms\", topic, durationInMillis, endTime - startTime);\n\treturn records;\n}", "CodeBleu_score": 29.200556142592347}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tString topic = getTopicPattern(msg);\n\t\tString key = getKeyPattern(msg);\n\t\tif (topic == null || key == null) {\n\t\t\tlog.error(\"[{}] Failed to get topic and key from message: {}\", ctx.getSelfId(), msg);\n\t\t\ttellFailure(ctx, msg, new TbException(\"Failed to get topic and key from message\"));\n\t\t\treturn;\n\t\t}\n\t\tpublish(ctx, msg, topic, key);\n\t} catch (Exception e) {\n\t\tlog.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\ttellFailure(ctx, msg, new TbException(\"Failed to process message\", e));\n\t}\n}", "CodeBleu_score": 28.979848611662206}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t//        log.debug(\"[{}] onMsg: {}\", ctx.getSelfId(), msg);\n        String topic = getTopicPattern(msg);\n        String key = getKeyPattern(msg);\n        if (topic == null || key == null) {\n            tellFailure(ctx, msg, \"Failed to get topic or key pattern from message\");\n            return;\n        }\n        if (ctx.getSelfId().equals(ctx.getSelfId())) {\n            log.warn(\"[{}] onMsg: self-loop detected\", ctx.getSelfId());\n            return;\n        }\n        try {\n            ctx.executeAsync(() -> publish(ctx, msg, topic, key));\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n            tellFailure(ctx, msg, \"Failed to process message: \" + e.getMessage());\n        }\n    }", "CodeBleu_score": 35.4919187310763}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t//        log.info(\"onMsg: {}\", msg);\n        if (initError!= null) {\n            tellFailure(ctx, msg, initError);\n            return;\n        }\n        String topic = getTopicPattern(msg);\n        if (topic == null) {\n            log.error(\"[{}] Failed to get topic pattern from message: {}\", ctx.getSelfId(), msg);\n            tellFailure(ctx, msg, new RuntimeException(\"Failed to get topic pattern from message\"));\n            return;\n        }\n        String key = getKeyPattern(msg);\n        if (key == null) {\n            log.error(\"[{}] Failed to get key pattern from message: {}\", ctx.getSelfId(), msg);\n            tellFailure(ctx, msg, new RuntimeException(\"Failed to get key pattern from message\"));\n            return;\n        }\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Publishing message to topic [{}], key [{}]\", ctx.getSelfId(), topic, key);\n        }\n        publish(ctx, msg, topic, key);\n    }", "CodeBleu_score": 34.50549906531432}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t//        if (log.isDebugEnabled()) {\n//            log.debug(\"Publishing message with key {} to topic {}.\", key, topic);\n//        }\n        if (key!= null) {\n            if (msg.getMetadata() == null) {\n                msg.setMetadata(new HashMap<>());\n            }\n            msg.getMetadata().put(key, key);\n        }\n        try {\n            send(ctx, topic, msg);\n        } catch (Exception e) {\n            if (log.isDebugEnabled()) {\n                log.debug(\"Failed to publish message with key {} to topic {}.\", key, topic, e);\n            }\n        }\n    }", "CodeBleu_score": 30.8000681209612}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tpublish(ctx, msg, topic, key, null);\n}", "CodeBleu_score": 9.399555434179016}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t//        if (metadata!= null && metadata.size() > 0) {\n//            Map<String, String> headers = new HashMap<>();\n//            for (Map.Entry<String, String> entry : metadata.entrySet()) {\n//                headers.put(entry.getKey(), entry.getValue());\n//            }\n//            ctx.publish(topic, key, msg, headers);\n//        } else {\n//            ctx.publish(topic, key, msg);\n//        }\n        ctx.publish(topic, key, msg);\n    }", "CodeBleu_score": 7.170814410332844}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 45.72654482156777}, {"code": "public void destroy(){\n\ttry {\nif (producer!= null) {\nproducer.close();\n}\n} catch (Exception e) {\nlog.error(\"Error closing Kafka producer: {}\", e.getMessage());\n}\n}", "CodeBleu_score": 40.48349741628057}, {"code": "public void destroy(){\n\t\ttry {\n\t\tproducer.close();\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to close the producer\", e);\n\t}\n}", "CodeBleu_score": 51.34219668538209}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = TbQueueProducer.builder()\n\t\t\t.kafkaSettings(getKafkaSettings())\n\t\t\t.clientId(getServiceId())\n\t\t\t.defaultTopic(buildTopicName())\n\t\t\t.admin(admin)\n\t\t\t.build();\n\treturn producer;\n}", "CodeBleu_score": 33.23481008284807}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\treturn createRuleEngineMsgProducer(\n\t\t\tgetKafkaSettings(),\n\t\t\tgetKafkaClientId(),\n\t\t\tbuildTopicName(),\n\t\t\tgetKafkaAdmin());\n}", "CodeBleu_score": 12.003972193853773}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tfinal String clientId = getServiceId();\n\tfinal String topic = getTopic();\n\tfinal Admin admin = getAdmin();\n\tfinal TbQueueProducerBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = TbQueueProducer.builder(admin, clientId, topic);\n\treturn builder.build();\n}", "CodeBleu_score": 27.909623552582474}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tog.info(\"Starting log scheduling for consumer groups.\");\nlong printIntervalMs = getPrintIntervalMs();\nlong kafkaResponseTimeoutMs = getKafkaResponseTimeoutMs();\nlong timeoutDurationMs = kafkaResponseTimeoutMs + printIntervalMs;\nscheduleWithFixedDelay(() -> {\ntry {\nif (isStatsPrintRequired()) {\nMap<TopicPartition, Long> endOffsets = getEndOffsets();\nMap<TopicPartition, OffsetAndMetadata> groupOffsets = listConsumerGroupOffsets();\nList<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\nif (!consumerGroupStats.isEmpty()) {\nlog.info(\"Consumer groups with lagging topics: {}\", consumerGroupStats);\n}\n}\n} catch (Exception e) {\nlog.warn(\"Error occurred while retrieving consumer group statistics.\", e);\n}\n}, timeoutDurationMs, printIntervalMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 27.3185252587485}, {"code": "private void startLogScheduling(){\n\tfkaResponseTimeoutMs = kafkaProperties.getKafkaResponseTimeoutMs();\nlong printIntervalMs = kafkaProperties.getPrintIntervalMs();\nlog.info(\"Kafka response timeout: {} ms\", kafkaResponseTimeoutMs);\nlog.info(\"Print interval: {} ms\", printIntervalMs);\nscheduleWithFixedDelay(this::printConsumerGroupStats, kafkaResponseTimeoutMs, printIntervalMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 11.379651642659178}, {"code": "private void startLogScheduling(){\n\ttatsPrintRequired()) {\nint printIntervalMs = getPrintIntervalMs();\nif (printIntervalMs > 0) {\nscheduleWithFixedDelay(\n() -> {\ntry {\nlog.info(\"Kafka consumer group statistics:\");\nMap<String, List<GroupTopicStats>> consumerGroupStatsMap = new HashMap<>();\nfor (String groupId : consumerGroupIds) {\nMap<TopicPartition, OffsetAndMetadata> groupOffsets = listConsumerGroupOffsets(groupId);\nMap<TopicPartition, Long> endOffsets = partitionsToOffsetAndMetadata(groupOffsets);\nList<GroupTopicStats> groupTopicStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\nconsumerGroupStatsMap.put(groupId, groupTopicStats);\n}\nlog.info(\"Kafka consumer group statistics:\");\nfor (Map.Entry<String, List<GroupTopicStats>> entry : consumerGroupStatsMap.entrySet()) {\nlog.info(\"Group ID: \" + entry.getKey());\nfor (GroupTopicStats groupTopicStats : entry.getValue()) {\nlog.info(groupTopicStats.toString());\n}\n}\n} catch (Exception e) {\nlog.warn(\"Failed to retrieve consumer group statistics. Error message: \" + e.getMessage());\nlog.warn(\"Error trace: \", e);\n}\n},\nprintIntervalMs,\nprintIntervalMs,\nTimeUnit.MILLISECONDS\n);\n}\n}\n}", "CodeBleu_score": 32.514849407273054}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent metricEvent = new MetricEvent(scopedName, tags, metric);\n\tswitch (metric.getMetricType()) {\n\t\tcase COUNTER:\n\t\t\tcounterMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase GAUGE:\n\t\t\tgaugeMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase HISTOGRAM:\n\t\t\thistogramMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase METER:\n\t\t\tmeterMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog.warn(\"Metric type {} not supported\", metric.getMetricType());\n\t\t\tbreak;\n\t}\n}", "CodeBleu_score": 32.00461740508352}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tif (metric instanceof Counter) {\n\t\tmetrics.put(scopedName, new MetricEvent(metric, scopedName, tags));\n\t\tcounters.put(scopedName, (Counter) metric);\n\t} else if (metric instanceof Gauge) {\n\t\tmetrics.put(scopedName, new MetricEvent(metric, scopedName, tags));\n\t\tgauges.put(scopedName, (Gauge) metric);\n\t} else if (metric instanceof Histogram) {\n\t\tmetrics.put(scopedName, new MetricEvent(metric, scopedName, tags));\n\t\thistograms.put(scopedName, (Histogram) metric);\n\t} else if (metric instanceof Meter) {\n\t\tmetrics.put(scopedName, new MetricEvent(metric, scopedName, tags));\n\t\tmeters.put(scopedName, (Meter) metric);\n\t} else {\n\t\tlog.warn(\"Unknown metric type: {}\", metric.getClass());\n\t}\n}", "CodeBleu_score": 49.20936403392713}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tif (metric instanceof Counter) {\n\t\tcounterMap.put(scopedName, tags, (Counter) metric);\n\t} else if (metric instanceof Gauge) {\n\t\tgaugeMap.put(scopedName, tags, (Gauge) metric);\n\t} else if (metric instanceof Histogram) {\n\t\thistogramMap.put(scopedName, tags, (Histogram) metric);\n\t} else if (metric instanceof Meter) {\n\t\tmeterMap.put(scopedName, tags, (Meter) metric);\n\t} else {\n\t\twarn(\"Metric type is not supported: \" + metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 44.958905860943965}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\t// Check if the MetricEvent already has fields\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields == null) {\n\t\tfields = new HashMap<>();\n\t}\n\n\t// Get the value from the Gauge\n\tObject value = gauge.getValue();\n\n\t// Check the type of the value and convert it to a Number or String as needed\n\tif (value instanceof Number) {\n\t\tfields.put(field, ((Number) value).doubleValue());\n\t} else if (value instanceof String) {\n\t\tfields.put(field, (String) value);\n\t} else {\n\t\tfields.put(field, value);\n\t}\n\n\t// Add the fields to the MetricEvent\n\tmetricEvent.setFields(fields);\n\n\treturn metricEvent;\n}", "CodeBleu_score": 55.39056850456554}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t//TODO: Implement this function\nreturn null;\n}", "CodeBleu_score": 6.174706013738723}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields!= null) {\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tfields.put(field, ((Number) gauge.getValue()).doubleValue());\n\t\t} else {\n\t\t\tfields.put(field, gauge.getValue().toString());\n\t\t}\n\t} else {\n\t\tfields = new HashMap<>();\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tfields.put(field, ((Number) gauge.getValue()).doubleValue());\n\t\t} else {\n\t\t\tfields.put(field, gauge.getValue().toString());\n\t\t}\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 49.96546499596133}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tif (metricEvent == null || gauge == null) {\n\t\treturn metricEvent;\n\t}\n\t// Get the Kafka lag metric values.\n\tMap<String, Object> metricValues = gauge.getValues();\n\tif (metricValues == null || metricValues.isEmpty()) {\n\t\treturn metricEvent;\n\t}\n\t// Get the Kafka lag metric fields.\n\tMap<String, String> kafkaLagMetricFields = metricEvent.getFields();\n\tif (kafkaLagMetricFields == null) {\n\t\tkafkaLagMetricFields = new HashMap<>();\n\t\tmetricEvent.setFields(kafkaLagMetricFields);\n\t}\n\t// Get the Kafka lag metric timestamp.\n\tLong kafkaLagTimestamp = kafkaLagTimes.get(gauge);\n\tif (kafkaLagTimestamp == null) {\n\t\tkafkaLagTimestamp = timestamp;\n\t\tkafkaLagTimes.put(gauge, kafkaLagTimestamp);\n\t}\n\t// Update the Kafka lag metric fields.\n\tfor (Map.Entry<String, Object> metricValue : metricValues.entrySet()) {\n\t\tkafkaLagMetricFields.put(metricValue.getKey(), metricValue.getValue().toString());\n\t}\n\t// Set the Kafka lag metric timestamp.\n\tmetricEvent.setTimestamp(kafkaLagTimestamp);\n\treturn metricEvent;\n}", "CodeBleu_score": 28.70453484175407}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tProperties kafkaProps = buildKafkaProps();\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> offsets = buildOffsetByTime(kafkaProps, ParameterTool.fromSystemProperties(), time);\n\t\tkafkaProps.put(\"auto.offset.reset\", \"earliest\");\n\t\toffsets.forEach((key, value) -> kafkaProps.put(\"auto.offset.reset\", key.getTopic() + \"_\" + key.getPartition() + \"=\" + value));\n\t}\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n\tenv.addSource(consumer);\n\treturn consumer.getDataStream();\n}", "CodeBleu_score": 48.476475892187395}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t", "CodeBleu_score": 8.44308697353304}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tProperties props = buildKafkaProps();\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> offsetByTime = buildOffsetByTime(props, ParameterTool.fromSystemProperties(), time);\n\t\toffsetByTime.forEach((key, value) -> props.setProperty(key.toString(), value.toString()));\n\t}\n\tKafkaConsumer<MetricEvent, MetricEvent> consumer = new KafkaConsumer<>(props);\n\treturn env.addSource(new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props));\n}", "CodeBleu_score": 41.76552240329108}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\nKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\nconsumer.subscribe(Collections.singletonList(parameterTool.getRequired(\"topic\")));\nMap<TopicPartition, Long> timestampToPartition = parameterTool.getLongs(\"timestamp\").stream().collect(Collectors.toMap(t -> new TopicPartition(parameterTool.getRequired(\"topic\"), t), Function.identity()));\nList<TopicPartition> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\nfor (TopicPartition partition : partitions) {\npartitionOffsets.put(partition, timestampToPartition.get(partition));\n}\nconsumer.close();\nreturn partitionOffsets;\n}", "CodeBleu_score": 41.867273728841525}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\nKafkaConsumer<byte[], byte[]> consumer = null;\ntry {\n// Set the consumer group ID using the provided time\nprops.setProperty(ConsumerConfig.GROUP_ID_CONFIG, \"consumer-group-\" + time);\n// Create a KafkaConsumer with the properties\nconsumer = new KafkaConsumer<>(props);\n// Get partition information for the specified topic\nList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n// Create a map associating each partition with the timestamp\nMap<Integer, Long> partitionToTime = new HashMap<>();\nfor (PartitionInfo partition : partitions) {\npartitionToTime.put(partition.partition(), time);\n}\n// Fetch offsets for the given times\nconsumer.offsetsForTimes(partitionToTime);\n// Build a map of KafkaTopicPartition to offsets\nfor (PartitionInfo partition : partitions) {\nKafkaTopicPartition partitionKey = new KafkaTopicPartition(parameterTool.getRequired(\"topic\"), partition.partition());\nLong offset = consumer.committed(partitionKey);\npartitionOffsets.put(partitionKey, offset);\n}\n} catch (Exception e) {\nthrow new RuntimeException(\"Error building offset by time\", e);\n} finally {\nif (consumer!= null) {\nconsumer.close();\n}\n}\nreturn partitionOffsets;\n}", "CodeBleu_score": 49.94496130483634}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tKafkaConsumer<String, String> consumer = null;\ntry {\nconsumer = new KafkaConsumer<>(props);\n} catch (Exception e) {\nthrow new RuntimeException(e);\n}\nString topic = parameterTool.get(\"topic\");\nMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\nMap<String, Integer> topicPartitions = consumer.partitionsFor(topic);\nfor (Map.Entry<String, Integer> entry : topicPartitions.entrySet()) {\nString partition = entry.getKey();\nint partitionId = entry.getValue();\nKafkaTopicPartition partitionOffset = new KafkaTopicPartition(topic, partitionId);\nLong offset = consumer.offsetsForTimes(Collections.singletonMap(partitionOffset, time)).get(partitionOffset);\npartitionOffsets.put(partitionOffset, offset);\n}\nconsumer.close();\nreturn partitionOffsets;\n}", "CodeBleu_score": 42.72972722817732}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t// Create Kafka producer properties\nProperties properties = new Properties();\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());\n\n// Create Kafka producer\nKafkaProducer<String, MetricEvent> producer = new KafkaProducer<>(properties);\n\n// Create a MetricEvent with the current timestamp, name, tags, and fields\nlong timestamp = System.currentTimeMillis();\nString name = \"my_metric\";\nMap<String, String> tags = new HashMap<>();\ntags.put(\"tag1\", \"value1\");\ntags.put(\"tag2\", \"value2\");\nMap<String, Object> fields = new HashMap<>();\nfields.put(\"field1\", 1);\nfields.put(\"field2\", 2);\nMetricEvent metricEvent = new MetricEvent(timestamp, name, tags, fields);\n\n// Create a ProducerRecord with the serialized MetricEvent and send it to the specified topic\nProducerRecord<String, MetricEvent> record = new ProducerRecord<>(\"my_topic\", metricEvent);\nproducer.send(record);\n\n// Print the sent data and flush the producer to ensure all data is sent\nSystem.out.println(\"Sent data: \" + metricEvent);\nproducer.flush();\n}", "CodeBleu_score": 52.04658572653354}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t// Create Kafka producer properties\nProperties props = new Properties();\nprops.put(\"bootstrap.servers\", \"localhost:9092\");\nprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\nprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n\n// Create a Kafka producer\nKafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);\n\n// Create a MetricEvent with the current timestamp, name, tags, and fields\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\"test_metric\");\nevent.setTags(Arrays.asList(\"tag1\", \"tag2\"));\nevent.setFields(new HashMap<String, Object>() {{\nput(\"field1\", \"value1\");\nput(\"field2\", \"value2\");\n}});\n\n// Create a ProducerRecord with the serialized MetricEvent and send it to the specified topic\nProducerRecord<String, byte[]> record = new ProducerRecord<>(\"test_topic\", event.toJson().getBytes());\nproducer.send(record);\n\n// Print the sent data and flush the producer to ensure all data is sent\nSystem.out.println(\"Sent data: \" + event.toJson());\nproducer.flush();\n\n// Close the Kafka producer\nproducer.close();\n}", "CodeBleu_score": 46.47890070156509}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"retries\", 0);\n\tprops.put(\"batch.size\", 16384);\n\tprops.put(\"linger.ms\", 1);\n\tprops.put(\"buffer.memory\", 33554432);\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n\n\tKafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);\n\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test\");\n\tevent.setTags(new HashMap<>());\n\tevent.setFields(new HashMap<>());\n\tevent.getFields().put(\"field1\", 123);\n\tevent.getFields().put(\"field2\", 456);\n\n\tProducerRecord<String, byte[]> record = new ProducerRecord<>(\"topic\", event.toJson().getBytes());\n\n\tproducer.send(record);\n\tSystem.out.println(\"Sent: \" + event.toJson());\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 48.5771805808541}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (event.getLevel().toInt() > level.toInt() || event.getLoggerName().contains(loggerName)) {\nreturn;\n}\n\nString json = subAppend(event);\n\nif (json!= null) {\nproducer.send(new ProducerRecord<>(topic, json));\n}\n}", "CodeBleu_score": 32.688679880662015}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (event.getLevel().toString().equals(\"INFO\") || event.getLevel().toString().equals(\"WARN\") || event.getLevel().toString().equals(\"ERROR\")) {\nif (!event.getLoggerName().contains(\"xxx\")) {\nif (event.getLoggerName().contains(\"org.apache.kafka\")) {\nreturn;\n}\nString subAppend = subAppend(event);\nproducer.send(new ProducerRecord<String, String>(topic, subAppend));\n}\n}\n}", "CodeBleu_score": 49.32624145533413}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t", "CodeBleu_score": 4.214743313165087}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range []string{\"\", \"topic\", \"topic_partition\", \"topic_partition_offset\"} {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 78.00929137139312}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range topicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 88.63673172674783}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, v := range topicSuffixMethods {\n\t\tif v == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 77.83490095281837}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\tif k.RoutingTag!= \"\" {\n\t\ttag, err := metric.GetTag(k.RoutingTag)\n\t\tif err!= nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn tag, nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 64.53844208320547}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\ttag, err := metric.GetTag(k.RoutingTag)\n\t\tif err!= nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\tif tag!= \"\" {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 70.109147778053}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\ttag, ok := metric.GetTag(k.RoutingTag)\n\t\tif!ok {\n\t\t\treturn \"\", fmt.Errorf(\"RoutingTag %q not found in metric tags\", k.RoutingTag)\n\t\t}\n\t\treturn tag, nil\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 51.40555971938166}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tif regexp, err := regexp.Compile(topicRegexp); err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp: %s, error: %v\", topicRegexp, err)\n\t\t} else {\n\t\t\tk.regexps[i] = *regexp\n\t\t}\n\t}\n\treturn nil\n}", "CodeBleu_score": 52.91991261125525}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tcompiledRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"error compiling topic regexp %q: %v\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = compiledRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.63753056983772}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\ttopicRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp: %s: %v\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = topicRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.07631628494711}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.MessageID]\n\tif!ok {\n\t\th.log.Errorf(\"message ID %s not found in undelivered map\", track.MessageID)\n\t\treturn\n\t}\n\n\tmsg.session.MarkMessage(track.MessageID)\n\tdelete(h.undelivered, track.MessageID)\n\th.sem.Release()\n}", "CodeBleu_score": 59.03167762786451}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.MessageID]\n\tif!ok {\n\t\th.log.Debugf(\"Message with delivery ID %s not found in undelivered map\", track.MessageID)\n\t\treturn\n\t}\n\n\tif msg.session.MarkMessage(track.MessageID) {\n\t\th.log.Debugf(\"Message with delivery ID %s marked as delivered\", track.MessageID)\n\t}\n\n\tdelete(h.undelivered, track.MessageID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 59.505352076469066}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\tmsg := h.undelivered[track.MessageID]\n\tif msg == nil {\n\t\th.log.Errorf(\"Message with ID %d not found in undelivered map\", track.MessageID)\n\t\treturn\n\t}\n\tmsg.session.MarkMessage(track.MessageID)\n\tdelete(h.undelivered, track.MessageID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 54.49089483950497}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\th.Handle(ctx, session, claim)\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif!more {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.acc.Handle(ctx, msg)\n\t\t\tif err!= nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t\tlog.Printf(\"Error handling message: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 60.78195674454505}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif more {\n\t\t\t\terr := h.Handle(ctx, msg)\n\t\t\t\tif err!= nil {\n\t\t\t\t\th.acc.AddError(err)\n\t\t\t\t\th.logger.Error(err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 59.29916888779046}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif more {\n\t\t\t\tif err := h.Handle(ctx, msg); err!= nil {\n\t\t\t\t\th.acc.AddError(err)\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 59.94951150453593}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.nonEmpty, IllegalCharacterInLogkafkaId)\ncheckCondition(!logkafka_id.equals(\".\"), IllegalCharacterInLogkafkaId)\ncheckCondition(!logkafka_id.equals(\"..\"), IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.length <= MAX_LOGKAFKA_ID_LENGTH, IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.matches(LOGKAFKA_ID_REGEX), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 41.323325062334554}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length <= 255, IllegalCharacterInLogkafkaId)\ncheckCondition(!logkafka_id.equals(\".\"), IllegalCharacterInLogkafkaId)\ncheckCondition(!logkafka_id.equals(\"..\"), IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.findFirstIn(\"..|\\\\.\").isEmpty, IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 31.60008116740089}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t", "CodeBleu_score": 1.1892782233472832}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => Future.successful(-\\/(ApiError.fromThrowable(t)))\n    }\n  }", "CodeBleu_score": 82.60897232527465}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\trunPreferredLeaderElection(clusterName, getTopicList(clusterName).flatMap)\n}", "CodeBleu_score": 8.257624481186589}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\n}", "CodeBleu_score": 3.151754181750609}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t\trunPreferredLeaderElection(clusterName, getTopicList(clusterName).flatMap(_.topics.toSet))\n}", "CodeBleu_score": 9.761991934022795}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\\/-(KMClusterCommandRequest (\n      clusterName,\n      CMManualPartitionAssignments(assignments)\n    )\n  )\n}", "CodeBleu_score": 10.793478964534948}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\tList<String> nodeIds = admin.describeCluster().nodes().get().stream().map(Node::id).map(Node::idString).collect(Collectors.toList());\n\t\tif (nodeIds.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No nodes available\");\n\t\t}\n\t\tString nodeId = nodeIds.get(0);\n\t\tMap<String, Config> configs = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, nodeId))).all().get();\n\t\tif (configs.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No configurations received\");\n\t\t}\n\t\treturn configs.get(nodeId);\n\t} catch (Exception e) {\n\t\tthrow new ConnectException(\"Error retrieving Kafka broker configuration\", e);\n\t}\n}", "CodeBleu_score": 57.89390247990176}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster to get the available nodes within a specified timeout.\n\tDescribeClusterResult describeCluster = admin.describeCluster(Duration.ofSeconds(5));\n\t// If no nodes are available, throw a ConnectException.\n\tif (describeCluster.nodes().isEmpty()) {\n\t\tthrow new ConnectException(\"No nodes available.\");\n\t}\n\t// Select the first node's ID and request its configuration.\n\tString idString = describeCluster.nodes().iterator().next().id().toString();\n\tDescribeConfigsResult describeConfigs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, idString)));\n\t// If no configurations are received, throw another ConnectException.\n\tif (describeConfigs.all().isEmpty()) {\n\t\tthrow new ConnectException(\"No configurations received.\");\n\t}\n\t// Finally, return the broker's configuration.\n\treturn describeConfigs.all().iterator().next().config();\n}", "CodeBleu_score": 47.5888394419649}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\tList<Node> nodes = admin.describeCluster(Duration.ofSeconds(10)).all().get();\n\t\tif (nodes.isEmpty()) {\n\t\t\tthrow new ConnectException(\"No nodes available\");\n\t\t}\n\t\tConfig config = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, nodes.get(0).id().toString())), Duration.ofSeconds(10)).all().get().get(0).config();\n\t\treturn config;\n\t} catch (ExecutionException e) {\n\t\tthrow new ConnectException(e.getCause());\n\t}\n}", "CodeBleu_score": 46.91952811368015}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\npublic int validate(final Config config) {\nif (config.getString\nequals\n(\n\"\nkafka.schema.history.bootstrap.servers\n\"\n)\n) {\nreturn validator\n.validate\n(\nconfig\n)\n;\n}\nelse {\nreturn 0;\n}\n}\n};\n}", "CodeBleu_score": 18.81642241103195}, {"code": "private static Validator forKafka(final Validator validator){\n\t", "CodeBleu_score": 4.879352022375934}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n@Override\npublic int validate(final Config config, final ConfigReadContext context) {\nif (config.hasPath(SchemaHistory.SCHEMA_HISTORY_CONFIG_PATH)) {\nreturn validator.validate(config, context);\n}\nreturn 0;\n}\n};\n}", "CodeBleu_score": 24.874925066566487}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tif (this.topicCreationEnabled!= null) {\n\t\treturn this.topicCreationEnabled;\n\t}\n\tString kafkaConnectVersion = config.get(ConfigDef.IMPORT_VERSION_KEY);\n\tif (kafkaConnectVersion == null) {\n\t\tkafkaConnectVersion = \"0.10.0.0\";\n\t}\n\tVersion kafkaConnectVersionParsed = Version.parse(kafkaConnectVersion);\n\tif (kafkaConnectVersionParsed.compareTo(Version.parse(\"0.10.0.0\")) < 0) {\n\t\tthis.topicCreationEnabled = false;\n\t\treturn false;\n\t}\n\tthis.topicCreationEnabled = Boolean.parseBoolean(config.get(ConfigDef.TOPIC_CREATION_ENABLE_KEY).toString());\n\treturn this.topicCreationEnabled;\n}", "CodeBleu_score": 44.03733916911807}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// Get the current Kafka Connect version\n\tString connectVersion = config.get(ConfigDef.IMPORT_CONNECT_VERSION_KEY);\n\n\t// Parse the Kafka Connect version and retrieve the \"topic.creation.enable\" property\n\tBoolean topicCreationEnabled = config.get(ConfigDef.IMPORT_TOPIC_CREATION_ENABLE_KEY);\n\n\t// Check if topic creation is enabled based on the Kafka Connect version and the \"topic.creation.enable\" property\n\tif (isCompatibleVersion(connectVersion) && topicCreationEnabled!= null) {\n\t\treturn topicCreationEnabled;\n\t}\n\n\t// Default to true if topic creation is not enabled or the Kafka Connect version is not compatible\n\treturn true;\n}", "CodeBleu_score": 26.906808983169395}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// Get the current Kafka Connect version\nString kafkaConnectVersion = KafkaConnect.getVersion();\n\n// Parse the \"topic.creation.enable\" property from the configuration, defaulting to true if not set\nString topicCreationEnable = config.get(\"topic.creation.enable\")!= null? config.get(\"topic.creation.enable\").toString() : \"true\";\n\n// Check if the Kafka Connect version is compatible with topic creation and the property is set to true\nreturn KafkaConnect.isCompatibleWithTopicCreation(kafkaConnectVersion) && Boolean.parseBoolean(topicCreationEnable);\n}", "CodeBleu_score": 40.1915817849591}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new IllegalArgumentException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n}\nfinal Map<String, Object> adminProperties = new HashMap<>();\nadminProperties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.BOOTSTRAP_SERVERS_CONFIG));\nadminProperties.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\nfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\nfinal Converter converter = converterForOffsetStore();\nreturn new KafkaOffsetBackingStore(admin, clientId, converter);\n}", "CodeBleu_score": 38.34813963043751}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\nfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new IllegalArgumentException(\"Missing required configuration property: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n}\n\nfinal Properties adminProperties = new Properties();\nadminProperties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.BOOTSTRAP_SERVERS_CONFIG));\nadminProperties.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n\nfinal KafkaOffsetBackingStore backingStore = new KafkaOffsetBackingStore(adminProperties, converterForOffsetStore());\n\nreturn backingStore;\n}", "CodeBleu_score": 31.282432404462917}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\nif (node.has(PAYLOAD_FIELD)) {\nnode = node.get(PAYLOAD_FIELD);\n}\nif (fieldNames.hasNext()) {\nreturn reader.readValue(node);\n}\nelse {\nreturn reader.readValue(node);\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 33.764323634195975}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\nif (config.keyFields().isEmpty()) {\nreturn reader.readValue(node);\n}\nelse {\nMap<String, Object> map = new HashMap<>();\nfor (String field : config.keyFields()) {\nmap.put(field, node.get(field).asText());\n}\nreturn reader.readValue(map);\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 33.68633782982195}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\nif (config.asEnvelope()) {\nreturn reader.readValue(node);\n}\nelse if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\nreturn reader.readValue(node.get(config.sourceField()));\n}\nelse {\nreturn reader.readValue(node);\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 35.72699953041259}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = topicNameFor(id);\nif (topicName == null) {\nthrow new IllegalArgumentException(\"The topic name cannot be null.\");\n}\nif (prefix == null) {\nthrow new IllegalArgumentException(\"The prefix cannot be null.\");\n}\nif (delimiter == null) {\nthrow new IllegalArgumentException(\"The delimiter cannot be null.\");\n}\nString sanitizedTopicName = topicName;\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (!isValidTopicNameCharacter(c)) {\nsanitizedTopicName = sanitizedTopicName.substring(0, i) + replacementCharacter + sanitizedTopicName.substring(i + 1);\n}\n}\nif (!sanitizedTopicName.equals(topicName)) {\nlog.warn(\"The topic name \" + topicName + \" was sanitized to \" + sanitizedTopicName + \".\");\n}\nreturn sanitizedTopicName;\n}", "CodeBleu_score": 39.57357049386739}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t", "CodeBleu_score": 3.5991384671705497}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = topicNameFor(id);\nif (topicName.indexOf(delimiter)!= -1) {\nStringBuilder sb = new StringBuilder(topicName.length());\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isValidTopicNameCharacter(c)) {\nsb.append(c);\n} else {\nsb.append(replacement);\nlog.warn(\"Topic name \" + topicName + \" contains invalid characters. Replaced with \" + replacement);\n}\n}\nreturn sb.toString();\n}\nreturn topicName;\n}", "CodeBleu_score": 42.55629278723661}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t//        super(connectorType, connectorConfig, queue);\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.retries = getRetriesOnError(connectorConfig);\n        this.producerThrowable = new AtomicReference<Throwable>();\n        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.retries = getRetriesOnError(connectorConfig);\n        this.producerThrowable = new AtomicReference<Throwable>();\n        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.retries = getRetriesOnError(connectorConfig);\n        this.producerThrowable = new AtomicReference<Throwable>();\n    }", "CodeBleu_score": 42.110001014037664}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 83.49744238572188}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t}", "CodeBleu_score": 5.129079475140064}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 83.49744238572188}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader!= null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.99048304009487}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 94.19376238351049}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader!= null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.99048304009487}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tif\n(\nsource\n.\ngetStruct\n(\nSNAPSHOT_KEY\n)\n.\nget\n(\n0\n)\n.\ntoString\n(\n)\n.\ntoUpperCase\n(\n)\n.\nequals\n(\nSNAPSHOT_RECORD_SNAPSHOT\n)\n)\n{\nreturn\nSNAPSHOT_RECORD_SNAPSHOT\n;\n}\nelse\nif\n(\nsource\n.\ngetStruct\n(\nSNAPSHOT_KEY\n)\n.\nget\n(\n0\n)\n.\ntoString\n(\n)\n.\ntoUpperCase\n(\n)\n.\nequals\n(\nSNAPSHOT_RECORD_SNAPSHOT_END\n)\n)\n{\nreturn\nSNAPSHOT_RECORD_SNAPSHOT_END\n;\n}\nelse\nif\n(\nsource\n.\ngetStruct\n(\nSNAPSHOT_KEY\n)\n.\nget\n(\n0\n)\n.\ntoString\n(\n)\n.\ntoUpperCase\n(\n)\n.\nequals\n(\nSNAPSHOT_RECORD_SNAPSHOT_START\n)\n)\n{\nreturn\nSNAPSHOT_RECORD_SNAPSHOT_START\n;\n}\nelse\n{\nreturn\nnull\n;\n}\n}", "CodeBleu_score": 18.389493939616727}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString\n= source\n.get\nfield\n(\nSNAPSHOT_KEY\n)\n.\ntoString\n(\n)\n;\nif\n(\nsnapshotString\n==\nnull\n|\n|\nsnapshotString\n.\nisEmpty\n(\n)\n)\n{\nreturn\nnull\n;\n}\nreturn\nSnapshotRecord\n.\nvalueOf\n(\nsnapshotString\n.\ntoUpperCase\n(\n)\n)\n;\n}", "CodeBleu_score": 19.66891081452306}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString = source\n.get\n(\nSNAPSHOT_KEY\n)\n.\ntoString\n(\n)\n;\nif\n(\nsnapshotString\n.\nisEmpty\n(\n)\n)\n{\nreturn\nnull\n;\n}\nreturn\nvalueOf\n(\nsnapshotString\n.\ntoUpperCase\n(\n)\n)\n;\n}", "CodeBleu_score": 17.203128744315748}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\tString[] hyphenParts = parts[0].split(\"-\");\n\tif (hyphenParts.length > 1) {\n\t\tparts[0] = hyphenParts[0];\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 56.3318646612707}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\", 2);\n\tif (parts.length > 2) {\n\t\tparts = new String[] { parts[0], parts[1] };\n\t}\n\ttry {\n\t\tString[] versionParts = parts[0].split(\"-\", 2);\n\t\treturn Optional.of(Float.parseFloat(versionParts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 52.011950939727505}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\n\tString[] hyphens = parts[0].split(\"-\");\n\tif (hyphens.length > 1) {\n\t\tparts[0] = hyphens[0];\n\t}\n\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 56.72169466287036}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t", "CodeBleu_score": 9.923969587835135}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t", "CodeBleu_score": 9.923969587835135}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tectActions;\nif (RESTART_ACTIONS.contains(action)) {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n} else {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n}\n\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(connectActions)\n.operationName(\"updateConnectorState\")\n.operationParams(Map.of(CONNECTOR_NAME, connectorName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService\n.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 92.50574949903945}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t", "CodeBleu_score": 6.624085789973376}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tction[] connectActions;\nif (RESTART_ACTIONS.contains(action)) {\n  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n} else {\n  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n}\n\nvar context = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(connectActions)\n   .operationName(\"updateConnectorState\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService\n       .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 97.50894872893765}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(String clusterName, String connectName, String pluginName, Mono<Map<String, Object>> requestBody, ServerWebExchange exchange) {\n\t\treturn kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody).map(ResponseEntity::ok);\n\t}\n}", "CodeBleu_score": 70.78735945126175}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tOverride\n\tpublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(String clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody, ServerWebExchange exchange) {\n\t\treturn kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody).map(ResponseEntity::ok);\n\t}\n}", "CodeBleu_score": 63.87340533835367}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tOverride\n\tpublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n\t\tString clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody,\n\t\tServerWebExchange exchange) {\n\t\treturn kafkaConnectService\n\t\t\t.validateConnectorPluginConfig(\n\t\t\t\tgetCluster(clusterName), connectName, pluginName, requestBody)\n\t\t\t.map(ResponseEntity::ok);\n\t}\n}", "CodeBleu_score": 73.93058429352996}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigPropertiesInitializer());\n\treturn builder.run(args);\n}", "CodeBleu_score": 44.72881051305274}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigPropertiesInitializer());\n\tConfigurableApplicationContext context = builder.run(args);\n\treturn context;\n}", "CodeBleu_score": 41.49788782102157}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigPropertiesInitializer());\n\tConfigurableApplicationContext context = builder.run(args);\n\treturn context;\n}", "CodeBleu_score": 41.49788782102157}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn (search == null)?\n\t\t(Predicate<FullConnectorInfoDTO>) (o -> true) :\n\t\t(Predicate<FullConnectorInfoDTO>) (o -> getStringsForSearch(o).anyMatch(search::equalsIgnoreCase));\n}", "CodeBleu_score": 50.981115933376906}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null? null : (Predicate<FullConnectorInfoDTO>) connectorInfo -> getStringsForSearch(connectorInfo)\n\t\t\t.anyMatch(connectorInfoString -> connectorInfoString.containsIgnoreCase(search));\n}", "CodeBleu_score": 24.788326971995765}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn (search == null)?\n    (Predicate<FullConnectorInfoDTO>) (o) -> true :\n    (Predicate<FullConnectorInfoDTO>) (o) -> getStringsForSearch(o).anyMatch(search::equalsIgnoreCase);\n}", "CodeBleu_score": 50.51438507007266}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\nMap<String, Object> flattenedMap = new HashMap<>();\n\nif (propertiesMap == null) {\n  return flattenedMap;\n}\n\nfor (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n  String key = entry.getKey();\n  Object value = entry.getValue();\n\n  if (value instanceof Map) {\n    Map<String, Object> nestedMap = (Map<String, Object>) value;\n    flattenedMap.putAll(flattenClusterProperties(key, nestedMap));\n  } else {\n    flattenedMap.put(prefix!= null? prefix + \".\" + key : key, value);\n  }\n}\n\nreturn flattenedMap;\n}", "CodeBleu_score": 47.45912408259726}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      propertiesMap = new HashMap<>();\n//    }\n//\n//    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n//      String key = prefix == null? entry.getKey() : prefix + \".\" + entry.getKey();\n//      if (entry.getValue() instanceof Map) {\n//        propertiesMap.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n//      } else {\n//        propertiesMap.put(key, entry.getValue());\n//      }\n//    }\n//\n//    return propertiesMap;\n    return null;\n  }", "CodeBleu_score": 11.32222271913422}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    Map<String, Object> flattened = new HashMap<>();\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        if (value instanceof Map) {\n          Map<String, Object> flattenedProperties = flattenClusterProperties(key, (Map<String, Object>) value);\n          flattened.putAll(flattenedProperties);\n        } else {\n          String newKey = prefix == null? key : prefix + \".\" + key;\n          flattened.put(newKey, value);\n        }\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 55.405263035729845}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n addClientSslSupport(configDef);\n addClientSaslSupport(configDef);\n return configDef.configKeys()\n.stream()\n.filter(key -> key.startsWith(\"password\"))\n.collect(toSet());\n }", "CodeBleu_score": 54.722220594394685}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.justOrEmpty(clusterDescription)\n.flatMap(this::getAuthorizedOperations)\n.flatMap(authorizedOperations -> {\nif (aclViewEnabled(adminClient).block()) {\nreturn Mono.just(ReactiveAdminClient.SupportedFeature.KAFKA_ACL_EDIT);\n} else {\nreturn Mono.empty();\n}\n})\n.switchIfEmpty(Mono.error(new UnsupportedOperationException(\"ACL editing is not supported\")));\n}", "CodeBleu_score": 27.1320810601038}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.just(clusterDescription)\n.map(ClusterDescription::getAuthorizedOperations)\n.filter(operations -> operations.contains(Operation.ALTER) || operations.contains(Operation.ALTER_CONFIG))\n.flatMap(operations -> Mono.just(operations)\n.filter(operations -> operations.contains(Operation.ALTER) || operations.contains(Operation.ALTER_CONFIG))\n.filter(operations -> aclViewEnabled(adminClient))\n.map(operations -> ClusterFeature.KAFKA_ACL_EDIT)\n.defaultIfEmpty(ClusterFeature.EMPTY));\n}", "CodeBleu_score": 28.95142329697234}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t", "CodeBleu_score": 4.927575001772918}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nfor (TopicPartition topicPartition : prevRange.keySet()) {\nFromToOffset prevRangeForTopicPartition = prevRange.get(topicPartition);\nlong beginOffset = prevRangeForTopicPartition.getFromOffset();\nlong endOffset = prevRangeForTopicPartition.getToOffset();\nlong numMessagesToPoll = Math.min(endOffset - beginOffset + 1, maxMessagesToPoll);\nlong newBeginOffset = beginOffset + numMessagesToPoll;\nnextRange.put(topicPartition, new FromToOffset(newBeginOffset, endOffset));\n}\nreturn nextRange;\n}", "CodeBleu_score": 25.87644764347648}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nfor (TopicPartition topicPartition : prevRange.keySet()) {\nFromToOffset prevOffset = prevRange.get(topicPartition);\nlong numMessagesToPoll = getMessagesToPoll(topicPartition, prevOffset);\nlong startOffset = prevOffset.fromOffset + numMessagesToPoll;\nif (startOffset < topicPartition.beginOffset()) {\nstartOffset = topicPartition.beginOffset();\n}\nnextRange.put(topicPartition, new FromToOffset(startOffset, prevOffset.toOffset));\n}\nreturn nextRange;\n}", "CodeBleu_score": 25.145538558482595}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\nfor (TopicPartition topicPartition : prevRange.keySet()) {\nFromToOffset fromToOffset = prevRange.get(topicPartition);\nlong beginOffset = fromToOffset.getFromOffset();\nlong endOffset = fromToOffset.getToOffset();\nif (endOffset == -1) {\nendOffset = seekOperations.getOffsetsForSeek(topicPartition).get(topicPartition).get();\n}\nlong numMessagesToPoll = endOffset - beginOffset;\nif (numMessagesToPoll > 0) {\nlong numMessagesToPollPerPartition = numMessagesToPoll / numPartitions;\nlong beginOffsetForPartition = beginOffset;\nif (numMessagesToPollPerPartition > 0) {\nbeginOffsetForPartition = beginOffset + numMessagesToPollPerPartition;\n}\nnextRange.put(topicPartition, new FromToOffset(beginOffsetForPartition, endOffset));\n}\n}\nreturn nextRange;\n}", "CodeBleu_score": 30.649153093367374}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t (configuration.getBoolean(CK_LEGACY)) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read every second\nexecutor.scheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead = lastSecBytesReadTmp.getAndSet(0);\n}\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 23.139597052646288}, {"code": "public void doLaunch(final MessageInput input){\n\t (configuration.getBoolean(CK_LEGACY)) {\n    doLaunchLegacy(input);\n} else {\n    doLaunchConsumer(input);\n}\n// schedule a task to update the last second bytes read every second\nexecutor.scheduleAtFixedRate(() -> {\n    final long lastSecBytesRead = lastSecBytesReadTmp.getAndSet(0);\n    if (lastSecBytesRead > 0) {\n        totalBytesRead.addAndGet(lastSecBytesRead);\n    }\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 25.378444019993257}, {"code": "public void doLaunch(final MessageInput input){\n\ty {\nif (legacyMode) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n} catch (final Exception e) {\nLOG.error(\"Failed to launch message input\", e);\n}\n\n// schedule a task to update the last second bytes read every second.\nexecutor.scheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 19.279238519745594}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tString customProperties = System.getProperty(CUSTOM_PROPERTIES_PROPERTY);\n\t\tif (customProperties!= null) {\n\t\t\tProperties customProps = new Properties();\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t}\n\t} catch (IOException e) {\n\t\tLOG.error(\"Error while loading custom properties\", e);\n\t}\n}", "CodeBleu_score": 48.38711195922937}, {"code": "private void insertCustomProperties(Properties props){\n\t// TODO Auto-generated method stub\n}", "CodeBleu_score": 3.0487516405470023}, {"code": "private void insertCustomProperties(Properties props){\n\tString config = props.getProperty(\"customProperties\");\nif (config!= null) {\ntry {\nProperties customProps = new Properties();\ncustomProps.load(new StringReader(config));\nprops.putAll(customProps);\n} catch (IOException e) {\nlog.error(\"Error loading custom properties: \" + e.getMessage());\n}\n}\n}", "CodeBleu_score": 39.595784251047235}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t//        entries.stream().filter(Objects::nonNull).forEach(this::write);\n        int totalBytes = 0;\n        for (RawMessageEvent event : entries) {\n            if (event == null) {\n                continue;\n            }\n            totalBytes += event.getMessage().length();\n            write(event);\n        }\n        writtenBytes.addAndGet(totalBytes);\n        writtenMessages.addAndGet(entries.size());\n    }", "CodeBleu_score": 16.581696756324416}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n// filter out null entries\nentries = entries.stream()\n.filter(Objects::nonNull)\n.collect(Collectors.toList());\n\n// map each event to a journal entry\nfinal List<Journal.Entry> journalEntries = entries.stream()\n.map(this::map)\n.collect(Collectors.toList());\n\n// calculate the total message bytes\nfinal long messageBytes = entries.stream()\n.mapToLong(RawMessageEvent::getMessageBytes)\n.sum();\n\ntry {\n// attempt to write to the journal\nfinal long lastOffset = kafkaJournal.write(journalEntries);\n\n// update the written messages and bytes metrics\nwrittenMessages.addAndGet(entries.size());\nwrittenBytes.addAndGet(messageBytes);\n\n// signalling the reader\nLOG.debug(\"Processed batch, last journal offset: {}, signalling reader.\", lastOffset);\njournalFilled.release();\n} catch (final IOException e) {\n// if the write fails, retry using an exponential back-off strategy\nLOG.warn(\"Failed to write to journal, retrying.\", e);\n\n// sleep for a random amount of time\nfinal long sleepTime = random.nextInt(1000);\ntry {\nThread.sleep(sleepTime);\n} catch (final InterruptedException e1) {\n// if interrupted, exit the thread\nLOG.warn(\"Interrupted while waiting for journal to fill up, exiting.\");\nThread.currentThread().interrupt();\n}\n\n// retry\nwrite(entries);\n}\n}", "CodeBleu_score": 46.54261346189692}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\nfinal List<Journal.Entry> journalEntries = entries.stream()\n.filter(Objects::nonNull)\n.map(this::map)\n.collect(Collectors.toList());\n\nif (journalEntries.isEmpty()) {\nreturn;\n}\n\nfinal long start = System.nanoTime();\ntry {\nwriteToJournal(journalEntries);\n} catch (final MessageQueueException e) {\nif (e.getCause() instanceof IOException) {\nLOG.warn(\"Failed to write to journal, retrying in {} ms\",\nRETRY_BACKOFF_MS, e);\n} else {\nLOG.error(\"Failed to write to journal\", e);\n}\n\n// retry\ntry {\nThread.sleep(RETRY_BACKOFF_MS);\n} catch (final InterruptedException e) {\nThread.currentThread().interrupt();\n}\n\n// exponential backoff\nRETRY_BACKOFF_MS *= 2;\n}\n\nfinal long end = System.nanoTime();\n\n// update metrics\nwrittenBytes.addAndGet(journalEntries.stream()\n.mapToLong(Journal.Entry::getMessageBytes)\n.sum());\n\nwrittenMessages.addAndGet(journalEntries.size());\n\nLOG.debug(\"Wrote {} entries in {} ms\",\njournalEntries.size(),\n(end - start) / 1_000_000);\n}", "CodeBleu_score": 44.67203175416614}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\tif\n(messages\nisEmpty\n) {\nreturn\n;\n}\nint max =\n0\n;\nfor\n(Message message\n:\nmessages\n) {\nif\n(message\n.\ngetQueueId\n(\n)\n>\nmax\n) {\nmax =\nmessage\n.\ngetQueueId\n(\n)\n;\n}\n}\nif\n(max\n>\n0\n) {\nacknowledgedMessages\n.\nput\n(\nstream\n,\nmax\n)\n;\n}\n}", "CodeBleu_score": 13.985525449760166}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages\n.\nisEmpty\n) {\nreturn\n;\n}\nif (messages\n.\nsize\n(\n)\n>\n1\n) {\nthrow new IllegalStateException\n(\n\"The acknowledge function can process only a single message at a time.\"\n)\n;\n}\nMessage message\n=\nmessages\n.\nget\n(\n0\n)\n;\nif (message\n.\ngetQueueId\n(\n)\n>\nmax\n) {\nmax\n=\nmessage\n.\ngetQueueId\n(\n)\n;\n}\nif (message\n.\ngetQueueId\n(\n)\n>\nacknowledgedMessages\n.\nsize\n(\n)\n) {\nacknowledgedMessages\n.\nput\n(\nmessage\n.\ngetQueueId\n(\n)\nmessage\n)\n;\n}\nifPresent\n.\naccept\n(\nmessage\n.\ngetQueueId\n(\n)\n)\n;\nmetrics\n.\nacknowledgedMessages\n.\nincrement\n(\n)\n;\n}", "CodeBleu_score": 21.657652427834336}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages\n.\nisEmpty\n)\n{\nreturn\n;\n}\nint max =\nmessages\n.\nstream\n.\nmapToInt\n(\nm\n->\nm\n.\ngetMessageId\n(\n)\n)\n.\nmax\n.\norElseThrow\n(\n()\n->\nnew\nIllegalArgumentException\n(\n\"\nNo\nmessages\nfound\nin\nthe\nlist\n\"\n)\n)\n;\nacknowledgedMessages\n.\nputIfAbsent\n(\nmax\n,\n0\n)\n;\nacknowledgedMessages\n.\ncompute\n(\nmax\n(\nm\n->\nm\n+\n1\n)\n)\n;\n}", "CodeBleu_score": 22.921226963065994}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry metricRegistry = this.metricRegistry;\n\tfinal String journalName = this.getClass().getSimpleName();\n\tfinal Set<Metric> metrics = this.metrics.getMetrics();\n\tfor (final Metric metric : metrics) {\n\t\tfinal String metricName = metric.name();\n\t\tif (metricName.startsWith(journalName)) {\n\t\t\tfinal String legacyName = metricName.substring(journalName.length());\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyName, metric);\n\t\t\t}\n\t\t\tcatch (final Exception ex) {\n\t\t\t\tthis.logger.warn(\"Failed to register legacy metric {} with name {}\", metric, legacyName, ex);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 34.49196760276805}, {"code": "private void registerLegacyMetrics(){\n\tfinal MetricRegistry metricRegistry = this.metrics;\nfinal String metricNamePrefix = this.getClass().getName();\nfor (final MetricName metricName : metricRegistry.getNames()) {\nif (metricName.getName().startsWith(metricNamePrefix)) {\ntry {\nfinal String legacyMetricName = metricName.getName().replace(metricNamePrefix, \"kafka.log.LocalKafkaJournal\");\nthis.metrics.register(legacyMetricName, metricRegistry.getMetrics().get(metricName));\n} catch (final Exception e) {\nthis.log.warn(\"Failed to register legacy metric {} as {}: {}\", metricName, legacyMetricName, e.getMessage());\n}\n}\n}\n}", "CodeBleu_score": 32.71572421571401}, {"code": "private void registerLegacyMetrics(){\n\tfinal MetricRegistry metricRegistry = this.metrics;\nfinal String metricPrefix = LocalKafkaJournal.class.getName();\nfinal MetricFilter filter = new MetricFilter() {\n@Override\npublic boolean matches(final MetricName metricName) {\nreturn metricName.getName().startsWith(metricPrefix);\n}\n};\n\nfinal List<MetricName> filteredMetrics = metricRegistry.getNames(filter);\nfor (final MetricName metricName : filteredMetrics) {\nfinal String legacyMetricName = metricName.getName();\ntry {\nmetricRegistry.register(legacyMetricName, metricRegistry.getMetrics().get(metricName));\n} catch (final Exception e) {\nLocalKafkaJournal.LOGGER.warn(\"Failed to register legacy metric \" + legacyMetricName + \" under \" + metricName, e);\n}\n}\n}", "CodeBleu_score": 36.36648932321395}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t", "CodeBleu_score": 4.722075566997135}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\treturn metricRegistry.register(metricName, new Timer() {\n@Override\npublic void update(long duration, TimeUnit unit) {\nlong durationInNanos = unit.toNanos(duration);\nif (durationInNanos == 0) {\nreturn;\n}\nif (durationInNanos < 0) {\nthrow new IllegalArgumentException(\"duration must be greater than zero\");\n}\nif (durationInNanos > Integer.MAX_VALUE) {\nthrow new IllegalArgumentException(\"duration must be less than Integer.MAX_VALUE\");\n}\ngetTimers().add(durationInNanos);\n}\n});\n}", "CodeBleu_score": 19.37001194984452}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer\n=\nmetricRegistry\n.\ntimer\n(\nmetricName\n)\n;\nreturn\ntimer\n;\n}", "CodeBleu_score": 8.754746467920555}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nfinal Gauge<Long> gauge = new Gauge<Long>() {\n@Override\npublic Long getValue() {\nfinal long size = size();\nif (size == 0) {\nreturn 0;\n}\nfinal long committedOffset = kafkaLog.committedOffset();\nif (committedOffset == KafkaLog.DEFAULT_COMMITTED_OFFSET) {\nreturn getLogEndOffset() - getLogStartOffset();\n} else {\nreturn getLogEndOffset() - committedOffset;\n}\n}\n};\nmetricRegistry.register(name, gauge);\n} catch (IllegalArgumentException e) {\nlog.warn(\"Failed to register metric {}\", name, e);\n}\n}", "CodeBleu_score": 42.9238003544859}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(name, new Gauge<Long>() {\n                public Long getValue() {\n                    final long size = size();\n                    if (size == 0) {\n                        return 0L;\n                    }\n                    final long committedOffset = kafkaLog.committedOffset();\n                    if (committedOffset == KafkaLog.DEFAULT_COMMITTED_OFFSET) {\n                        return getLogEndOffset() - getLogStartOffset();\n                    }\n                    return getLogEndOffset() - committedOffset;\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n    }", "CodeBleu_score": 55.15074883154178}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nfinal Function0<Long> uncommittedMessages = new Function0<Long>() {\n@Override\npublic Long apply() {\nfinal long logEndOffset = getLogEndOffset();\nfinal long logStartOffset = getLogStartOffset();\nfinal long committedOffset = kafkaLog.committedOffset();\nif (committedOffset == KafkaLog.DEFAULT_COMMITTED_OFFSET) {\nreturn logEndOffset - logStartOffset;\n} else {\nreturn logEndOffset - committedOffset;\n}\n}\n};\nmetricRegistry.register(name, new Gauge<Long>(uncommittedMessages));\n} catch (IllegalArgumentException e) {\n// ignore\n}\n}", "CodeBleu_score": 38.827508186037505}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to write\");\nreturn lastOffset;\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlog.debug(\"Writing message set of size {}\", messageSet.size());\nkafkaLog.append(messageSet);\nlong offset = kafkaLog.lastOffset();\nlog.debug(\"Wrote message set at offset {}\", offset);\nnumWrittenMessages += messages.size();\nreturn offset;\n}", "CodeBleu_score": 33.59000140638228}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n    logger.debug(\"No messages to write\");\n    return -1;\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlogger.debug(\"Writing {} messages of size {} bytes to Kafka log\", messages.size(), payloadSize);\nlong lastOffset = kafkaLog.append(messageSet);\nlogger.debug(\"Wrote {} messages of size {} bytes to Kafka log at offset {}\", messages.size(), payloadSize, lastOffset);\nreturn lastOffset;\n}", "CodeBleu_score": 36.12951490417124}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n    log.debug(\"No messages to write.\");\n    return -1;\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlog.debug(\"Writing {} messages of size {} bytes\", messageSet.size(), payloadSize);\nlong lastOffset = kafkaLog.append(messageSet);\nlog.debug(\"Wrote {} messages to offset {}\", messageSet.size(), lastOffset);\nreturn lastOffset;\n}", "CodeBleu_score": 33.24600504568664}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t//        lock.lock();\n//        try {\n//            LOGGER.info(\"close kafka AdminClient start, clusterPhyId:{}\", clusterPhyId);\n//            List<AdminClient> adminClientList = clientMap.get(clusterPhyId);\n//            if (adminClientList!= null) {\n//                boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n//                if (allSuccess) {\n//                    LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n//                } else {\n//                    LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n//                }\n//            }\n//        } finally {\n//            lock.unlock();\n//        }\n//    }", "CodeBleu_score": 2.774556204846159}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tif (clusterPhyId == null) {\n\t\treturn;\n\t}\n\t// \u52a0\u9501\n\tsynchronized (adminClientMap) {\n\t\t// \u83b7\u53d6\u5ba2\u6237\u7aef\u5217\u8868\n\t\tList<AdminClient> adminClientList = adminClientMap.get(clusterPhyId);\n\t\tif (adminClientList == null) {\n\t\t\treturn;\n\t\t}\n\t\t// \u5173\u95ed\u5ba2\u6237\u7aef\n\t\tboolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n\t\t// \u91ca\u653e\u9501\n\t\tadminClientMap.remove(clusterPhyId);\n\t\t// \u6253\u5370\u65e5\u5fd7\n\t\tif (allSuccess) {\n\t\t\tLOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n\t\t} else {\n\t\t\tLOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n\t\t}\n\t}\n}", "CodeBleu_score": 53.183265860744314}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\n// 1. \u83b7\u53d6\u9501\nlock: this.clientMap.lock();\ntry {\n// 2. \u83b7\u53d6\u5ba2\u6237\u7aef\u5217\u8868\nList<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n// 3. \u5173\u95ed\u5ba2\u6237\u7aef\nthis.closeAdminClientList(clusterPhyId, adminClientList);\n// 4. \u5220\u9664\u5ba2\u6237\u7aef\u5217\u8868\nthis.clientMap.remove(clusterPhyId);\n} finally {\n// 5. \u91ca\u653e\u9501\nthis.clientMap.unlock();\n}\n\n}", "CodeBleu_score": 18.433569487356717}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30000);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing admin client for cluster with physical id {}: {}\", clusterPhyId, e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 59.08311368941133}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList!= null) {\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close(30000);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Failed to close admin client for cluster \" + clusterPhyId + \" with error: \" + e.getMessage());\n\t\t\t\tsuccess = false;\n\t\t\t}\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 46.39183286127266}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30000);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error closing AdminClient for clusterId: \" + clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 53.26624934747856}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\tenableTls(eurekaServerRunner);\n\tsetKeyStore(eurekaServerRunner);\n\tsetTrustStore(eurekaServerRunner);\n\tstart(eurekaServerRunner);\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 31.906148633343562}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\tenableTls(eurekaServerRunner);\n\tsetTrustStore(eurekaServerRunner);\n\tsetKeyStore(eurekaServerRunner);\n\tstart(eurekaServerRunner);\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 31.906148633343562}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\neurekaServerRunner.enableTls();\neurekaServerRunner.setKeyStore(keyStore);\neurekaServerRunner.setTrustStore(trustStore);\neurekaServerRunner.start();\nreturn eurekaServerRunner;\n}", "CodeBleu_score": 39.378717836646324}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tKeyAndCert ca = new KeyAndCert(new X500Name(\"CN=CA,O=My Company,L=My City,ST=My State,C=US\"), null, null);\n\tKeyAndCert server = new KeyAndCert(new X500Name(\"CN=Server,O=My Company,L=My City,ST=My State,C=US\"), null, ca.storeCert(KEY_PASSWORD));\n\tKeyAndCert client = new KeyAndCert(new X500Name(\"CN=Client,O=My Company,L=My City,ST=My State,C=US\"), null, ca.storeCert(KEY_PASSWORD));\n\tKeyAndCert client2 = new KeyAndCert(new X500Name(\"CN=Client2,O=My Company,L=My City,ST=My State,C=US\"), null, ca.storeCert(KEY_PASSWORD));\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveCert(client);\n\tsaveCert(client2);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 32.41018970481848}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyAndCert ca = createCA();\n\tsaveCert(ca);\n\tsaveKeyAndCert(ca);\n\n\tKeyAndCert server = createServer(ca);\n\tsaveCert(server);\n\tsaveKeyAndCert(server);\n\n\tKeyAndCert client = createClient(ca);\n\tsaveCert(client);\n\tsaveKeyAndCert(client);\n}", "CodeBleu_score": 21.062287260637884}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyAndCert ca = new KeyAndCert(new File(CA_KEYSTORE), CA_PASSWORD);\n\tKeyAndCert server = new KeyAndCert(new File(SERVER_KEYSTORE), SERVER_PASSWORD);\n\tKeyAndCert client = new KeyAndCert(new File(CLIENT_KEYSTORE), CLIENT_PASSWORD);\n\tKeyAndCert client2 = new KeyAndCert(new File(CLIENT2_KEYSTORE), CLIENT_PASSWORD);\n\tKeyAndCert ca2 = new KeyAndCert(new File(CA2_KEYSTORE), CA_PASSWORD);\n\n\t// Create a CA certificate and sign server and client certificates with it.\n\tca.createCA(CA_DN, CA_PASSWORD, CA_PASSWORD, null, null);\n\tca.sign(server.subject(), CA_PASSWORD, CA_PASSWORD);\n\tca.sign(client.subject(), CA_PASSWORD, CA_PASSWORD);\n\tca.sign(client2.subject(), CA_PASSWORD, CA_PASSWORD);\n\tca2.createCA(CA2_DN, CA_PASSWORD, CA_PASSWORD, null, null);\n\tca2.sign(client2.subject(), CA_PASSWORD, CA_PASSWORD);\n\n\t// Save the certificates and keys.\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveCert(client);\n\tsaveKeyAndCert(client2);\n\tsaveCert(ca2);\n}", "CodeBleu_score": 26.770877025211487}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tint timeLimit = (int) (System.currentTimeMillis() + (seconds * 1000));\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(String.format(\"Assertion failed after %d seconds\", seconds));\n}", "CodeBleu_score": 45.92533566325968}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong timeLimit = TimeUnit.SECONDS.toMillis(seconds);\n\tlong startTime = currentTimeMillis();\n\twhile (true) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tif (currentTimeMillis() - startTime > timeLimit) {\n\t\t\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds.\");\n\t\t}\n\t\tyield\n\t}\n}", "CodeBleu_score": 42.574735752022136}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + (seconds * 1000);\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 47.64268848641222}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\n\tJcaX509v3CertificateBuilder builder = certBuilder(publicKey, ca, \"client\");\n\n\tbuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\treturn signCert(builder, privateKey);\n}", "CodeBleu_score": 51.946947271976796}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\n\tJcaX509v3CertificateBuilder builder = certBuilder(publicKey, ca, \"test\");\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\tX509Certificate signCert = signCert(builder, privateKey);\n\treturn signCert;\n}", "CodeBleu_score": 46.62644411273698}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\n\tJcaX509v3CertificateBuilder builder = certBuilder(publicKey, ca, \"localhost\");\n\n\taddExtension(builder, Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign));\n\taddExtension(builder, Extension.basicConstraints, true, new BasicConstraints(true));\n\n\treturn signCert(builder, privateKey);\n}", "CodeBleu_score": 49.56280876922033}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField eurekaTransportField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\teurekaTransportField.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) eurekaTransportField.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tlogger.error(\"Error retrieving EurekaHttpClient instance: \" + e.getMessage());\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.12511844437095}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tlogger.error(\"Could not access field'registrationClient' on class 'com.netflix.discovery.shared.transport.EurekaTransport'\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 43.566962046142564}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tlog.error(\"Failed to retrieve EurekaHttpClient instance\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.873012537716264}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications(false);\n\tif (applications == null || applications.isEmpty()) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 50.15502859664201}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications(false).getRegisteredApplications();\n\tif (applications!= null) {\n\t\tfor (Application application : applications) {\n\t\t\tfor (InstanceInfo instanceInfo : application.getInstances()) {\n\t\t\t\tservices.add(instanceInfo.getAppName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 49.44019983218468}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications(false);\n\tif (!applications.isEmpty()) {\n\t\tfor (Application application : applications) {\n\t\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\t\tservices.add(instance.getAppName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 46.237507471782926}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthContributor indicator : composite.getHealthContributors().values()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 47.01540014025608}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.entrySet().stream().filter(entry -> entry.getValue() instanceof DiscoveryCompositeHealthContributor).forEach(entry -> {\n\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\tcomposite.getHealthIndicators().entrySet().stream().filter(indicator ->!(indicator.getValue() instanceof EurekaHealthIndicator)).forEach(indicator -> {\n\t\t\thealthContributors.put(indicator.getKey(), indicator.getValue());\n\t\t});\n\t});\n}", "CodeBleu_score": 33.29952314017694}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.forEach((name, contributor) -> {\n\t\tif (contributor instanceof DiscoveryCompositeHealthContributor) {\n\t\t\t((DiscoveryCompositeHealthContributor) contributor).getIndicators().forEach((indicator) -> {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicator.getName(), indicator);\n\t\t\t\t}\n\t\t\t});\n\t\t} else {\n\t\t\thealthContributors.put(contributor.getName(), contributor);\n\t\t}\n\t});\n}", "CodeBleu_score": 32.82148995290546}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances of provider-application were found\");\n\t}\n\tServiceInstance instance = instances.get(0);\n\tString uri = instance.getUri().toString();\n\tRestTemplate restTemplate = new RestTemplate();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 58.58117569323716}, {"code": "public String hello(){\n\t\ttry {\n\t\tURI uri = discoveryClient.getInstances(\"provider-application\").get(0).getUri();\n\t\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n\t}\n\tcatch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 25.101572611473866}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances == null || instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances of provider-application available\");\n\t}\n\tServiceInstance instance = instances.get(0);\n\tString uri = instance.getUri();\n\tRestTemplate restTemplate = new RestTemplate();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n\treturn response;\n}", "CodeBleu_score": 60.651464794195356}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tServiceInstance providerInstance = loadBalancerClient.choose(\"provider-application\");\n\tif (providerInstance == null) {\n\t\tthrow new RuntimeException(\"No provider-application instance found\");\n\t}\n\tURI uri = providerInstance.getUri();\n\turi = uri.resolve(\"/echo\");\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 50.94361645874843}, {"code": "public String world(){\n\t\tString serviceInstance = loadBalancerClient.choose(\"provider-application\").getUri().toString();\n\tURI uri = URI.create(serviceInstance + \"/echo\");\n\treturn restTemplate.postForObject(uri, \"Hello World!\", String.class);\n}", "CodeBleu_score": 33.87347824095303}, {"code": "public String world(){\n\t\tServiceInstance providerApplicationInstance = loadBalancerClient.choose(\"provider-application\");\n\tURI uri = providerApplicationInstance.getUri();\n\turi = uri.resolve(\"/echo\");\n\treturn restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 38.98338648004241}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tsynchronizedSet = serverMap.get(serviceName);\n\t}\n\telse {\n\t\tsynchronizedSet = new HashSet<Server>();\n\t\tserverMap.put(serviceName, synchronizedSet);\n\t}\n\tsynchronizedSet.add(new Server(ip, port));\n\tlogger.info(\"Service: \" + serviceName + \" registered with IP: \" + ip + \" and port: \" + port);\n\treturn true;\n}", "CodeBleu_score": 49.819121226079545}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\treturn false;\n\t}\n\telse {\n\t\tHashSet<Server> servers = new HashSet<Server>();\n\t\tservers.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, servers);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 42.739974301534495}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tsynchronizedSet = serverMap.get(serviceName);\n\t} else {\n\t\tsynchronizedSet = new HashSet<Server>();\n\t\tserverMap.put(serviceName, synchronizedSet);\n\t}\n\tsynchronizedSet.add(new Server(ip, port));\n\tlogger.info(\"Registered \" + serviceName + \" with IP \" + ip + \" and port number \" + port);\n\treturn true;\n}", "CodeBleu_score": 49.50560276288291}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: Implement this method\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tfor (Server server : servers) {\n\t\t\tif (server.getIp().equals(ip) && server.getPort().equals(port)) {\n\t\t\t\tservers.remove(server);\n\t\t\t\tif (servers.isEmpty()) {\n\t\t\t\t\tserverMap.remove(serviceName);\n\t\t\t\t}\n\t\t\t\tlogger.info(\"Deregistered server: \" + ip + \":\" + port);\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 38.639494366472384}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: Implement this method\n\tServer server = new Server(ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tif (serverMap.get(serviceName).contains(server)) {\n\t\t\tserverMap.get(serviceName).remove(server);\n\t\t\tSystem.out.println(\"Deregistered server: \" + ip + \":\" + port);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 49.063448819523046}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tServer server = new Server(serviceName, ip, port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> servers = serverMap.get(serviceName);\n\t\tif (servers.contains(server)) {\n\t\t\tservers.remove(server);\n\t\t\tlogger.info(\"Deregistered server \" + server.toString() + \" from \" + serviceName);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 50.844773172970115}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tap<String, Object> attributes = getAttributes(metadata);\n\nif (attributes.containsKey(DEFAULT_CONFIGURATION_KEY)) {\nObject configuration = attributes.get(DEFAULT_CONFIGURATION_KEY);\nString name = generateName(metadata, configuration);\nregisterClientConfiguration(registry, name, configuration);\n}\n}", "CodeBleu_score": 33.32341941663673}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t// 1. \u83b7\u53d6RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027\n\tMap<String, Object> attributes = getAttributes(metadata);\n\t// 2. \u5982\u679c\u5305\u542bdefaultConfiguration\u5c5e\u6027\uff0c\u5219\u6ce8\u518c\u4e00\u4e2aRibbonClientSpecification\n\tif (attributes.containsKey(\"defaultConfiguration\")) {\n\t\tregisterClientConfiguration(registry, \"default\", attributes.get(\"defaultConfiguration\"));\n\t}\n\t// 3. \u904d\u5386RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027\uff0c\u6ce8\u518c\u4e00\u4e2aRibbonClientSpecification\n\tfor (Map.Entry<String, Object> entry : attributes.entrySet()) {\n\t\tif (!\"defaultConfiguration\".equals(entry.getKey())) {\n\t\t\tregisterClientConfiguration(registry, entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 33.43084527205076}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tap<String, Object> attributes = getAttributes(metadata);\nString name = attributes.get(DEFAULT_CONFIGURATION_KEY).toString();\nObject configuration = attributes.get(CLIENT_CONFIGURATION_KEY);\nregisterClientConfiguration(registry, name, configuration);\n}", "CodeBleu_score": 34.35612857487801}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn null;\n}", "CodeBleu_score": 11.883009317135098}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn null;\n}", "CodeBleu_score": 11.883009317135098}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\t// TODO Auto-generated method stub\n\treturn null;\n}", "CodeBleu_score": 4.040153837282234}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t", "CodeBleu_score": 3.8941988765375157}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final java.net.URI originalURI = original;\n\tURI originalURI = original;\n\tif (originalURI == null) {\n\t\tthrow new IllegalArgumentException(\"Original URI cannot be null\");\n\t}\n\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"ServiceInstance cannot be null\");\n\t}\n\tURI reconstructed = null;\n\ttry {\n\t\treconstructed = new URI(originalURI.getScheme(), originalURI.getUserInfo(), originalURI.getHost(), originalURI.getPort(), originalURI.getRawPath(), originalURI.getRawQuery(), originalURI.getFragment());\n\t\tif (reconstructed.getHost() == null) {\n\t\t\treconstructed = reconstructed.resolve(server.getUri().getHost() + \":\" + server.getPort());\n\t\t}\n\t\telse if (reconstructed.getHost().equals(server.getUri().getHost()) && reconstructed.getPort() == -1) {\n\t\t\treconstructed = reconstructed.resolve(\":\" + server.getPort());\n\t\t}\n\t\telse {\n\t\t\treconstructed = reconstructed.resolve(server.getUri().getHost() + \":\" + server.getPort());\n\t\t}\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Unable to reconstruct URI\", e);\n\t}\n\treturn reconstructed;\n}", "CodeBleu_score": 37.52188645849848}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\t// TODO: implement this method\n\tString url = \"http://\" + getServerAddr() + \"/list\";\n\tHttpGet get = new HttpGet(url);\n\tString json;\n\ttry {\n\t\tHttpResponse response = client.execute(get);\n\t\tjson = EntityUtils.toString(response.getEntity());\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn null;\n\t}\n\tJSONArray jsonArray = new JSONArray(json);\n\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\tJSONObject jsonObj = jsonArray.getJSONObject(i);\n\t\tString ip = jsonObj.getString(\"ip\");\n\t\tint port = jsonObj.getInt(\"port\");\n\t\tservers.add(new TutuServer(ip, port));\n\t}\n\treturn servers;\n}", "CodeBleu_score": 36.89646370865696}, {"code": "private List<TutuServer> getServer(){\n\t\t// Construct the parameters\n\tMap<String, Object> params = new HashMap<>();\n\tparams.put(\"serviceName\", serviceName);\n\n\t// Send the request and parse the response\n\tString response = HttpRequest.get(serverAddr + \"/list\").params(params).execute().body();\n\tJSONArray jsonArray = JSON.parseArray(response);\n\n\t// Convert the JSON array into a list of TutuServer objects\n\tList<TutuServer> servers = new ArrayList<>();\n\tfor (int i = 0; i < jsonArray.size(); i++) {\n\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\t\tString ip = jsonObject.getString(\"ip\");\n\t\tint port = jsonObject.getInteger(\"port\");\n\t\tservers.add(new TutuServer(ip, port));\n\t}\n\n\treturn servers;\n}", "CodeBleu_score": 46.15408298653671}, {"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\tString url = \"http://\" + getServerAddr() + \"/list\";\n\tHttpGet get = new HttpGet(url);\n\ttry {\n\t\tHttpResponse response = client.execute(get);\n\t\tif (response.getStatusLine().getStatusCode()!= 200) {\n\t\t\tSystem.out.println(\"Error: \" + response.getStatusLine().getStatusCode());\n\t\t\treturn servers;\n\t\t}\n\t\tString responseString = EntityUtils.toString(response.getEntity());\n\t\tJSONArray jsonArray = new JSONArray(responseString);\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject json = jsonArray.getJSONObject(i);\n\t\t\tString ip = json.getString(\"ip\");\n\t\t\tint port = json.getInt(\"port\");\n\t\t\tservers.add(new TutuServer(ip, port));\n\t\t}\n\t} catch (IOException | JSONException e) {\n\t\te.printStackTrace();\n\t}\n\treturn servers;\n}", "CodeBleu_score": 34.71998498458504}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (Route route : routes) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = path.substring(route.getPath().length());\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.525698774720173}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (this.routes == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.routes) {\n\t\tif (pathMatcher.match(route.getPattern(), path)) {\n\t\t\tString targetPath = pathMatcher.extractPathWithinPattern(route.getPattern(), path);\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 33.137430437734444}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.routes) {\n\t\tif (this.pathMatcher.match(route.getPath(), path)) {\n\t\t\treturn new Route(path.substring(route.getPath().length()), route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 22.95486626121411}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClientImpl(tutuDiscoveryProperties);\n}", "CodeBleu_score": 53.983787205743496}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
