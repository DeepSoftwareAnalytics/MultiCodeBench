{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    model_config = self.config.model\n    model_config.half_attention = half_attention\n    model_config.memory_format = torch.channels_last if self.config.model.memory_format == \"channels_last\" else torch.contiguous_format\n    model_config.load_file = self.config.model.load_file\n    model_config.load_path = self.config.model.load_path\n    model_config.load_from_cache = self.config.model.load_from_cache\n    model_config.cache_path = self.config.model.cache_path\n    model_config.cache_prefix = self.config.model.cache_prefix\n    model_config.cache_suffix = self.config.model.cache_suffix\n    model_config.cache_max_size = self.config.model.cache_max_size\n    model_config.cache_max_length = self.config.model.cache_max_length\n    model_config.cache_max_sequence_length = self.config.model.cache_max_sequence_length\n    model_config.cache_max_batch_size = self.config.model.cache_max_batch_size\n    model_config.cache_max_tokens = self.config.model.cache_max_tokens\n    model_config.cache_max_tokens_per_batch = self.config.model.cache_max_tokens_per_batch\n    model_config.cache_max_tokens_per_sequence = self.config.model.cache_max_tokens_per_sequence\n    model_config.cache_max_tokens_per_sequence_per_batch = self.config.model.cache_max_tokens_per_sequence_per_batch\n    model_config.cache_max_tokens_per_sequence_per_batch_per_gpu = self.config.model.cache_max_tokens_per_sequence_per_batch_per_gpu\n    model_config.cache_max_tokens_per_sequence_per_gpu = self.config.model.cache_max_tokens_per_sequence_per_gpu\n    model_config.cache_max_tokens_per_gpu = self.config.model.cache_max_tokens_per_gpu\n    model_config.cache_max_sequence_length", "CodeBleu_score": 20.622338756799895}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    model_path = self.config.model.path\n    model_extension = extension(model_path)\n    model_name = model_path.split", "CodeBleu_score": 0.6939247280596201}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.model_file.exists():\n        print(f\"Loading model from cache at {self.model_file.resolve()}\")\n        model = torch.load(self.model_file, map_location=self.device)\n    else:\n        print(f\"Loading model from {self.model_file.resolve()}\")\n        model = torch.load(self.model_file, map_location=self.device)\n        torch.save(model, self.model_file)\n    model = self.model_class.from_config(model[\"config\"])\n    model.load_state_dict(model[\"model\"])\n    model.to(self.device)\n    model.eval()\n    if half_attention:\n        model = model.half()\n    if self.memory_format == \"channels_last\":\n        model = model.to(memory_format=\"channels_last\")\n    return model\n", "CodeBleu_score": 31.301214226620466}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    if x0 is None:\n        x0 = torch.randn(batch_size, *shape[1:], device=model.device, dtype=model.dtype)\n    else:\n        assert x0.shape == shape[1:]\n    if quantize_x0:\n        x0 = quantize(x0, model.quantize_codebook_size, model.quantize_codebook_dim)\n    if score_corrector is not None:\n        x0 = score_corrector(x0, **corrector_kwargs)\n    if x_t is not None:\n        x_t = score_corrector(x_t, **corrector_kwargs)\n    ddim = DDIMSampler(model, steps, eta=eta, callback=callback, temperature=temperature)\n    samples = ddim.sample(x0, cond, shape, mask=mask, x_t=x_t)\n    return samples\n", "CodeBleu_score": 43.58581595126051}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    # print(f'batch_size: {batch_size}')\n    # print(f'eta: {eta}')\n    # print(f'steps: {steps}')\n    # print(f'shape: {shape}')\n    # print(f'cond: {cond}')\n    # print(f'x0: {x0}')\n    # print(f'quantize_x0: {quantize_x0}')\n    # print(f'temperature: {temperature}')\n    # print(f'score_corrector: {score_corrector}')\n    # print(f'corrector_kwargs: {corrector_kwargs}')\n    # print(f'x_t: {x_t}')\n    ddim = DDIMSampler(model, batch_size=batch_size, shape=shape, cond=cond, eta=eta, steps=steps, callback=callback, normals_sequence=normals_sequence, mask=mask, x0=x0, quantize_x0=quantize_x0, temperature=temperature, score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, x_t=x_t)\n    return ddim.sample\n", "CodeBleu_score": 22.392897262704437}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    if x_t is None:\n        x_t = torch.zeros_like(cond)\n    if mask is None:\n        mask = torch.ones_like(cond)\n    if normals_sequence is None:\n        normals_sequence = torch.ones_like(cond)\n    if x0 is None:\n        x0 = torch.randn_like(cond)\n    if quantize_x0:\n        x0 = quantize(x0)\n    if score_corrector is None:\n        score_corrector = get_score_corrector(model)\n    if corrector_kwargs is None:\n        corrector_kwargs = dict()\n    ddim = DDIMSampler(model, shape, eta=eta, steps=steps, callback=callback,\n                       normals_sequence=normals_sequence, mask=mask, x0=x0,\n                       quantize_x0=quantize_x0, temperature=temperature,\n                       score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, x_t=x_t)\n    return ddim.sample()\n", "CodeBleu_score": 46.350955972597404}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = \"EMA\"\n    with tf.variable_scope(context):\n        with tf.variable_scope(self.scope, reuse=tf.AUTO_REUSE):\n            self.ema = tf.train.ExponentialMovingAverage(decay=0.999)\n            self.ema_variables = self.ema.variables_to_restore()\n            self.ema_restore = tf.train.Saver(self.ema_variables)\n            self.ema_restore.restore(self.sess, self.ckpt_path)\n            self.ema_weights = tf.get_collection(tf.GraphKeys.GLOBAL_VARIABLES, scope=self.scope)\n            self.ema_weights_dict = {self.ema.average_name(var): var for var in self.ema_weights}\n            self.ema_weights_dict.update({var.op.name: var for var in self.ema_weights})\n            self.ema_weights_dict.update({var.op.name.split(\"/\")[0]: var for var in self.ema_weights})\n            self.ema_weights_dict.update({var.op.name.split(\"/\")[0] + \"/\" + var.op.name.split(\"/\")[1]: var for var in self.ema_weights})\n            self.ema_weights_dict.update({var.op.name.split(\"/\")[0] + \"/\" + var.op.name.split(\"/\")[1] + \"/\" + var.op.name.split(\"/\")[2]: var for var in self.ema_weights})\n            self.ema_weights_dict.update({var.op.name.split(\"/\")[0] + \"/\" + var.op.name.split(\"/\")[1] + \"/\" + var.op.name.split(\"/\")[2] + \"/\" + var.op.name.split(\"/\")[3]: var for var in self.ema_weights})\n            self.ema_weights_dict.update({var.op.name.split(\"/\")[0] + \"/\" + var.op.name.split(\"/\")[1] + \"/\" + var.op.name.split(\"/\")[2] + \"/\" + var.op.name.split(\"/\")[3] + \"/\" + var.op.name.split(\"/\")[4]: var for var in self.ema_weights})\n            self.ema_", "CodeBleu_score": 28.642205784182394}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is not None:\n        print(\"EMA enabled\")\n    self.ema_enabled = True\n    self.ema_original_weights = copy.deepcopy(self.parameters)\n    self.ema_weights = copy.deepcopy(self.parameters)\n    self.ema_weights.update(self.parameters)\n    self.parameters = self.ema_weights\n    self.ema_enabled = False\n    if context is not None:\n        print(\"EMA disabled\")\n", "CodeBleu_score": 38.05369324876368}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = \"\"\n    self.ema_context = context\n    self.ema_weights = self.parameters.copy()\n    self.parameters = self.ema_weights\n    self.ema_enabled = True\n    if self.ema_context:\n        print(f\"EMA weights enabled for {self.ema_context}\")\n    return self\n", "CodeBleu_score": 29.40039494141616}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    ckpt_state_dict = torch.load(path)\n    state_dict = self.state_dict()\n    for k in ckpt_state_dict.keys():\n        if k in state_dict.keys():\n            state_dict[k] = ckpt_state_dict[k]\n        else:\n            print(f\"Key '{k}' missing from state dict.\")\n    if ignore_keys:\n        for k in ignore_keys:\n            if k in state_dict.keys():\n                del state_dict[k]\n            else:\n                print(f\"Key '{k}' missing from state dict.\")\n    self.load_state_dict(state_dict)\n    print(\"Loaded model from checkpoint.\")\n", "CodeBleu_score": 27.96130118089023}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    ckpt = torch.load(path, map_location=self.device)\n    sd = ckpt['state_dict']\n    if ignore_keys is not None:\n        sd = {k: v for k, v in sd.items() if not any(k.startswith(i) for i in ignore_keys)}\n    self.load_state_dict(sd, strict=False)\n    print('Missing keys: {}'.format(list(set(self.state_dict().keys()) - set(sd.keys()))))\n    print('Unexpected keys: {}'.format(list(set(sd.keys()) - set(self.state_dict().keys()))))\n    print('Loaded from checkpoint: {}'.format(path))\n", "CodeBleu_score": 31.692706207897835}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    ckpt = torch.load(path)\n    sd = ckpt['state_dict']\n    if ignore_keys:\n        for k in list(sd.keys()):\n            if k.startswith(ignore_keys):\n                del sd[k]\n    self.load_state_dict(sd, strict=False)\n    print('Loaded checkpoint from', path)\n    print('Missing keys:', set(self.state_dict().keys()) - set(sd.keys()))\n    print('Unexpected keys:', set(sd.keys()) - set(self.state_dict().keys()))\n    print('Updated state keys:', set(self.state_dict().keys()) & set(sd.keys()))\n\n", "CodeBleu_score": 28.178694522841624}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        pred_indices = self.predict(dec)\n        return dec, emb_loss, pred_indices\n    else:\n        return dec, emb_loss\n", "CodeBleu_score": 35.11091479902726}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        pred_indices = self.pred_indices(quant)\n        return dec, pred_indices\n    else:\n        return dec, emb_loss, info\n", "CodeBleu_score": 36.32987894353315}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        return dec, emb_loss, info, info['pred_indices']\n    else:\n        return dec, emb_loss, info\n", "CodeBleu_score": 39.00171336532741}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    x = batch[k].unsqueeze(0)\n    x = x.permute(0, 3, 1, 2)\n    x = x.contiguous().float()\n    if self.batch_resizing:\n        x = F.interpolate(x, size=self.batch_resizing_range, mode='bicubic', align_corners=False)\n    x = x.detach()\n    return x\n", "CodeBleu_score": 24.730101139094348}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(0)\n    x = x.permute(0, 3, 1, 2)\n    x = x.contiguous().float()\n    if self.resize:\n        x = F.interpolate(x, size=(self.resize_size, self.resize_size), mode='bicubic', align_corners=True)\n    x = x.detach()\n    return x\n", "CodeBleu_score": 33.825688538842265}, {"code": "def get_input(self, batch, k)\n\t\n    x = batch[k]\n    if len(x.shape) == 3:\n        x = x.unsqueeze(0)\n    x = x.permute(0, 3, 1, 2)\n    x = x.contiguous().float()\n    if self.batch_resizing:\n        x = F.interpolate(x, size=(self.batch_size, self.batch_size), mode='bicubic', align_corners=False)\n    x = x.detach()\n    return x\n", "CodeBleu_score": 34.2743050552963}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    if optimizer_idx == 0:\n        x = self.get_input(batch, 0)\n        z = self.encode(x)\n        x_hat = self.decode(z)\n        loss = self.loss(x, x_hat)\n        self.log(\"train_loss\", loss)\n        return loss\n    else:\n        x = self.get_input(batch, 0)\n        x_hat = self.decode(x)\n        loss = self.loss(x, x_hat)\n        self.log(\"train_loss\", loss)\n        return loss", "CodeBleu_score": 21.5742980387699}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    x = self.get_input(batch, \"x\")\n    x_hat = self.forward(x)\n    if optimizer_idx == 0:\n        loss = self.loss(x, x_hat)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    else:\n        loss = self.discriminator_loss(x, x_hat)\n        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    return loss\n\n", "CodeBleu_score": 22.62273134639074}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    x = self.get_input(batch, 0)\n    x_hat = self.forward(x)\n    if optimizer_idx == 0:\n        loss = self.loss(x, x_hat)\n    elif optimizer_idx == 1:\n        loss = self.discriminator_loss(x, x_hat)\n    else:\n        raise ValueError(\"Invalid optimizer index\")\n    self.log(\"loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    return loss", "CodeBleu_score": 21.09049542413628}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    x = batch[self.input_key]\n    x = x.detach()\n    if self.ema_scope is not None:\n        x = self.ema_scope.apply(x)\n    if self.image_key == \"segmentation\":\n        x = self.to_rgb(x)\n    if only_inputs:\n        self.logger.experiment.add_image(\"inputs\", x, self.global_step)\n    else:\n        x = self.ema_scope.apply(x)\n        if self.image_key == \"segmentation\":\n            x = self.to_rgb(x)\n        self.logger.experiment.add_image(\"inputs\", x, self.global_step)\n        x = self.ema_scope.apply(x)\n        if self.image_key == \"segmentation\":\n            x = self.to_rgb(x)\n        self.logger.experiment.add_image(\"reconstructions\", x, self.global_step)\n\n", "CodeBleu_score": 30.24721735485968}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    if self.ema_scope is None:\n        self.log_images(batch, only_inputs, plot_ema, **kwargs)\n        return\n    x = self.get_input(batch, self.image_key)\n    if self.image_key == \"segmentation\":\n        x = self.to_rgb(x)\n    if self.ema_scope is not None:\n        with torch.no_grad():\n            self.ema_scope.eval()\n            y = self.ema_scope.get_input(batch, self.image_key)\n            if self.image_key == \"segmentation\":\n                y = self.ema_scope.to_rgb(y)\n        self.ema_scope.train()\n    else:\n        y = None\n    if not only_inputs:\n        if self.ema_scope is not None:\n            self.log_images(batch, only_inputs, plot_ema, x=x, y=y, **kwargs)\n        else:\n            self.log_images(batch, only_inputs, plot_ema, x=x, **kwargs)\n", "CodeBleu_score": 33.70687609802546}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    if self.ema_scope is None:\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.ema_scope.is_master():\n        return\n    if not self.", "CodeBleu_score": 12.026834865238477}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss == 'l1':\n        return self.loss.mean(pred, target)\n    elif self.loss == 'l2':\n        return self.loss.mean(pred, target, mean)\n    else:\n        raise NotImplementedError('Unknown loss type:'+ self.loss)\n", "CodeBleu_score": 23.914517693030042}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return abs(pred - target).mean()\n        else:\n            return abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return mse_loss(pred, target).mean()\n        else:\n            return mse_loss(pred, target)\n    else:\n        raise NotImplementedError('Unknown loss type: {}'.format(self.loss_type))\n", "CodeBleu_score": 36.12270536321982}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss == 'l2':\n        if mean:\n            return torch.mean(torch.pow(pred - target, 2))\n        else:\n            return torch.pow(pred - target, 2)\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 31.406363654450907}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.time_steps is not None:\n        if self.time_steps_forward is None:\n            t = torch.randint(0, self.time_steps, (x.shape[0],), device=x.device)\n        else:\n            assert hasattr(self.time_steps_model, self.time_steps_forward)\n            t = getattr(self.time_steps_model, self.time_steps_forward)(x)\n        t = t.clamp(0, self.time_steps - 1)\n    else:\n        t = None\n    if self.cond_stage_forward is not None:\n        c = self.cond_stage_model(c)\n    else:\n        c = self.cond_stage_model.encode(c)\n    x = self.model(x, t, c, *args, **kwargs)\n    return x\n", "CodeBleu_score": 47.786433062576194}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.cond_stage_forward is None:\n        if hasattr(self.cond_stage_model, 'encode') and callable(self.cond_stage_model.encode):\n            c = self.cond_stage_model.encode(c)\n            if isinstance(c, DiagonalGaussianDistribution):\n                c = c.mode()\n        else:\n            c = self.cond_stage_model(c)\n    else:\n        assert hasattr(self.cond_stage_model, self.cond_stage_forward)\n        c = getattr(self.cond_stage_model, self.cond_stage_forward)(c)\n    t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device)\n    return self.p_losses(x, t, c)\n", "CodeBleu_score": 44.84600129783143}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.cond_stage_forward is not None:\n        c = self.get_learned_conditioning(c)\n    x = self.model(x, c, *args, **kwargs)\n    return x", "CodeBleu_score": 18.91498159821041}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # if self.unmap_to_all:\n    #     indices = unmap_to_all(self, indices)\n    # indices = indices.reshape(indices.shape[0], -1)\n    # used = self.used.to(indices)\n    # if self.re_embed > self.used.shape[0]:  # extra token\n    #     indices[indices >= self.used.shape[0]] = 0  # simply set to zero\n    # back = torch.gather(used[None, :][indices.shape[0] * [0], :], 1, indices)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.reshape(indices.shape)\n    # return back.", "CodeBleu_score": 2.083333333333333}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # indices = torch.LongTensor(indices)\n    # shape = tuple(shape)\n    # if self.re_embed > self.used.shape[0]:\n    #     indices[indices >= self.used.shape[0]] = 0\n    # back = torch.gather(self.embedding[None, :][indices.shape[0] * [0], :], 1, indices)\n    # return back.view(shape)\n    # return back.view(shape).permute(1, 0, 2)\n    return self.embedding.gather(1, indices.view(-1, 1)).view(shape).permute(1, 0, 2)\n\n", "CodeBleu_score": 10.062558828837796}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # print(f\"indices: {indices}\")\n    # print(f\"shape: {shape}\")\n    # print(f\"self.embedding: {self.embedding}\")\n    # print(f\"self.embedding.shape: {self.embedding.shape}\")\n    # print(f\"self.embedding.permute: {self.embedding.permute}\")\n    # print(f\"self.embedding.permute.shape: {self.embedding.permute.shape}\")\n    # print(f\"self.embedding.permute.permute: {self.embedding.permute.permute}\")\n    # print(f\"self.embedding.permute.permute.shape: {self.embedding.permute.permute.shape}\")\n    # print(f\"self.embedding.permute.permute.permute: {self.embedding.permute.permute.permute}\")\n    # print(f\"self.embedding.permute.permute.permute.shape: {self.embedding.permute.permute.permute.shape}\")\n    # print(f\"self.embedding.permute.permute.permute.permute: {self.embedding.permute.permute.permute.permute}\")\n    # print(f\"self.embedding.permute.permute.permute.permute.shape: {self.embedding.permute.permute.permute.permute.shape}\")\n    # print(f\"self.embedding.permute.permute.permute.permute.permute: {self.embedding.permute.permute.permute.permute.permute}\")\n    # print(f\"self.embedding.permute.permute.permute.permute.permute.shape: {self.embedding.permute.permute.permute.permute.permute.shape}\")\n    # print(f\"self.embedding.permute.permute.permute.permute.permute.permute: {self.embedding.permute.permute.permute.permute.permute.permute}\")\n    # print(f\"self.embedding.permute.permute.permute.permute.permute.permute.shape: {self.embedding.permute.permute.permute.permute.permute.permute.shape}\")", "CodeBleu_score": 2.083333333333333}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0:\n        if dimension % factor == 0:\n            return factor, dimension // factor\n        else:\n            return 1, dimension\n    else:\n        m, n = 1, dimension\n        while m < n:\n            factor = (m + n) // 2\n            if dimension % factor == 0:\n                m = factor\n            else:\n                n = factor\n        return m, n\n\n", "CodeBleu_score": 36.506341958229676}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor >= 0:\n        m = factor\n        n = dimension // factor\n    else:\n        m = 1\n        n = dimension\n        while m <= n:\n            if dimension % m == 0:\n                n = dimension // m\n                break\n            m += 1\n    return m, n\n\n", "CodeBleu_score": 30.65655031969795}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor < 0:\n        factor = abs(factor)\n        m = 1\n        n = dimension\n        while m <= n:\n            if dimension % m == 0 and dimension % n == 0:\n                return m, n\n            if m < n:\n                m += 1\n            else:\n                n -= 1\n    else:\n        m = 1\n        n = dimension\n        while m <= n:\n            if dimension % m == 0 and dimension % n == 0 and m <= factor and n <= factor:\n                return m, n\n            if m < n:\n                m += 1\n            else:\n                n -= 1\n    return 1, dimension", "CodeBleu_score": 39.68996028207042}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown_weight = updown.to(self.device)\n    orig_weight = orig_weight.to(self.device)\n    updown_weight = updown_weight.transpose(0, 1)\n    orig_weight = orig_weight.reshape(updown_weight.size())\n    norm = torch.norm(updown_weight, p=2, dim=1)\n    norm = norm.reshape(norm.size(0), 1)\n    updown_weight = updown_weight / norm\n    updown_weight = updown_weight * self.weight_scale\n    updown_weight = updown_weight - orig_weight\n    return updown_weight.transpose(0, 1)\n", "CodeBleu_score": 24.352890511247523}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown.to(orig_weight.device)\n    orig_weight.to(updown.device)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n    orig_weight.to(torch.float32)\n    updown.to(torch.float32)\n   ", "CodeBleu_score": 8.204878870044338}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    updown.to\n    orig_weight.to\n    transpose\n    to\n    reshape\n    merged_scale1.transpose\n    norm\n    adjusted_weight = updown - orig_weight\n    return adjusted_weight\n", "CodeBleu_score": 4.366529102357535}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t # Adjust the updown tensor with the bias and reshape it according to the output shape\n    updown = updown.to(device=orig_weight.device)\n    if ex_bias is not None:\n        updown = updown + ex_bias.to(device=orig_weight.device)\n    updown = updown.reshape(output_shape)\n\n    # If the original and updown weights have the same number of elements, reshape updown to match the original weight's shape\n    if updown.numel() == orig_weight.numel():\n        updown = updown.reshape(orig_weight.shape)\n\n    # If an additional bias is provided, apply a multiplier to it\n    if ex_bias is not None:\n        ex_bias = ex_bias.to(device=orig_weight.device)\n        ex_bias = ex_bias * self.multiplier()\n\n    # If a scaling factor is defined, apply a weight decomposition to updown\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown, ex_bias", "CodeBleu_score": 61.480693904078166}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t if ex_bias is None:\n        ex_bias = torch.zeros(1)\n\n    # Adjust the updown tensor with the bias and reshape it according to the output shape\n    updown = updown + ex_bias\n    updown = updown.reshape(output_shape)\n\n    # If the original and updown weights have the same number of elements, reshape updown to match the original weight's shape\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n\n    # If an additional bias is provided, apply a multiplier to it\n    if ex_bias.numel() > 1:\n        ex_bias = ex_bias * self.multiplier()\n\n    # If a scaling factor is defined, apply a weight decomposition to updown\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown, ex_bias\n\n", "CodeBleu_score": 50.17385191368457}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t # Calculate the final updown tensor\n    final_updown = self.apply_bias(updown, ex_bias)\n    final_updown = self.apply_reshape(final_updown, output_shape)\n    if orig_weight.numel() == final_updown.numel():\n        final_updown = self.apply_reshape(final_updown, orig_weight.shape)\n    if self.multiplier is not None:\n        final_updown = self.apply_multiplier(final_updown, self.multiplier)\n    if self.apply_weight_decompose:\n        final_updown = self.apply_weight_decompose(final_updown, orig_weight)\n    return final_updown, ex_bias", "CodeBleu_score": 33.13594103725105}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n    output_shape = self.weight.shape\n    updown = self.weight.to(orig_weight.device, dtype=self.weight.dtype)\n\n    if self.dora_scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    updown = updown.reshape(output_shape)\n    updown = self.finalize_updown(updown, orig_weight, output_shape)\n    return updown\n\n", "CodeBleu_score": 40.83285789564975}, {"code": "def calc_updown(self, orig_weight)\n\t\n    updown = self.weight.clone().detach().to(orig_weight.device)\n    updown = self.finalize_updown(updown, orig_weight, updown.shape, self.bias)\n    return updown\n", "CodeBleu_score": 14.791725590850863}, {"code": "def calc_updown(self, orig_weight)\n\t\n    updown = self.updown(orig_weight)\n    return self.finalize_updown(updown, orig_weight, updown.shape)\n", "CodeBleu_score": 9.893080882031393}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    global networks_in_memory_limit\n    if len(networks_in_memory) > networks_in_memory_limit:\n        print(f\"Purging {len(networks_in_memory)} networks from memory.\")\n        networks_in_memory = []\n        gc.collect()\n", "CodeBleu_score": 26.98279320779129}, {"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    global networks_in_memory_limit\n    if len(networks_in_memory) > networks_in_memory_limit:\n        networks_to_remove = len(networks_in_memory) - networks_in_memory_limit\n        networks_to_remove = networks_to_remove // 2\n        networks_to_remove = networks_to_remove * 2\n        for i in range(networks_to_remove):\n            networks_in_memory.pop()\n        torch.cuda.empty_cache()\n        gc.collect()\n        print(\"Purged \" + str(networks_to_remove) + \" networks from memory\")\n    else:\n        print(\"Memory usage is within limit\")\n", "CodeBleu_score": 30.726762662943756}, {"code": "def purge_networks_from_memory()\n\t\n    global networks_in_memory\n    if len(networks_in_memory) > networks_in_memory_limit:\n        while len(networks_in_memory) > networks_in_memory_limit:\n            networks_in_memory.pop()\n        gc.collect()\n    return True\n", "CodeBleu_score": 36.82763537388477}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n   ...\n", "CodeBleu_score": 12.326435246995993}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n   ...\n", "CodeBleu_score": 12.326435246995993}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, 'backup_weights') and hasattr(self, 'backup_biases'):\n        if isinstance(self, torch.nn.MultiheadAttention):\n            self.in_proj_weight = self.backup_weights\n            self.in_proj_bias = self.backup_biases\n            self.out_proj.weight = self.backup_weights\n            self.out_proj.bias = self.backup_biases\n        else:\n            self.weight = self.backup_weights\n            self.bias = self.backup_biases\n    return\n\n\n\n\n", "CodeBleu_score": 29.866652365131703}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if org_module.network_weights_backup is None:\n        org_module.network_reset_cached_weight()\n\n    if org_module.network_current_names!= org_module.network_names:\n        org_module.network_reset_cached_weight()\n        org_module.network_restore_weights_from_backup()\n        org_module.network_current_names = org_module.network_names\n\n    if org_module.network_names is not None:\n        if org_module.network_names == org_module.network_current_names:\n            input = org_module.network_forward(input)\n        else:\n            org_module.network_reset_cached_weight()\n            org_module.network_restore_weights_from_backup()\n            org_module.network_current_names = org_module.network_names\n            input = org_module.network_forward(input)\n\n    return original_forward(input)\n", "CodeBleu_score": 26.297117183712338}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if hasattr(org_module, \"network_current_names\"):\n        if org_module.network_current_names == ():\n            return original_forward(org_module, input)\n        else:\n            for network in org_module.network_current_names:\n                if isinstance(network, torch.nn.Module):\n                    input = network(input)\n                else:\n                    input = network(input, original_forward)\n            return input\n    else:\n        return original_forward(org_module, input)\n\n", "CodeBleu_score": 33.047609728013065}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if org_module.network_current_names is None:\n        org_module.network_reset_cached_weight()\n        return original_forward(input)\n    else:\n        org_module.network_restore_weights_from_backup()\n        org_module.network_current_names = ()\n        output = original_forward(input)\n        for network in org_module.network_current_names:\n            output = network(output)\n        org_module.network_reset_cached_weight()\n        return output\n", "CodeBleu_score": 28.391743121761827}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n    return None\n", "CodeBleu_score": 1.1384168500651382}, {"code": "def trainables(self)\n\t\n    return None\n", "CodeBleu_score": 1.1384168500651382}, {"code": "def trainables(self)\n\t\n   ...\n", "CodeBleu_score": 0.862068965517866}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    if not isinstance(multipliers, list):\n        multipliers = [multipliers] * len(names)\n\n    shared.hypernetworks.clear()\n\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n\n        if hypernetwork is None:\n            errors.report(f\"Could not load hypernetwork {name}\")\n            continue\n\n        hypernetwork.set_multiplier(multiplier)\n        shared.hypernetworks.append(hypernetwork)\n\n    return shared.hypernetworks\n\n", "CodeBleu_score": 39.25072362698199}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    if len(names)!= len(multipliers):\n        raise ValueError(\"Names and multipliers must be the same length\")\n\n    loaded_hypernetworks = shared.hypernetworks.get()\n    loaded_hypernetworks.clear()\n\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is None:\n            raise ValueError(f\"Hypernetwork {name} does not exist\")\n\n        hypernetwork.set_multiplier(multiplier)\n        loaded_hypernetworks.append(hypernetwork)\n\n    return loaded_hypernetworks\n\n", "CodeBleu_score": 39.242678716360366}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    if not isinstance(multipliers, list):\n        raise TypeError(\"multipliers must be a list\")\n\n    if len(names)!= len(multipliers):\n        raise ValueError(\"names and multipliers must have the same length\")\n\n    already_loaded = shared.hypernetworks.get(names)\n\n    if already_loaded is not None:\n        shared.hypernetworks.clear()\n\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n\n        if hypernetwork is None:\n            continue\n\n        hypernetwork.set_multiplier(multiplier)\n        shared.hypernetworks.append(hypernetwork)\n\n", "CodeBleu_score": 41.302921183735045}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n\n    for hypernetwork_k, hypernetwork_v in hypernetworks.items():\n        context_k, context_v = apply_single_hypernetwork(hypernetwork_k, context_k, context_v, layer)\n        context_k, context_v = apply_single_hypernetwork(hypernetwork_v, context_k, context_v, layer)\n\n    return context_k, context_v\n\n\n", "CodeBleu_score": 56.33382636940696}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n\n    for context_k, context_v in zip(context_k, context_v):\n        context_k, context_v = apply_single_hypernetwork(hypernetworks[0], context_k, context_v, layer)\n        context_k, context_v = apply_single_hypernetwork(hypernetworks[1], context_k, context_v, layer)\n\n    return context_k, context_v", "CodeBleu_score": 47.64642085877665}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k, context_v = context, context\n\n    for context_k, context_v in zip(hypernetworks.keys(), apply_single_hypernetwork(hypernetworks[context_k], context_k, context_v, layer=layer)):\n        pass\n\n    return context_k, context_v\n\n", "CodeBleu_score": 38.80858791996356}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    assert not (context is None and self.context_layer is not None), \"Attention requires either context or context_layer.\"\n    if context is None:\n        context = self.context_layer(x)\n\n    if self.context_layer is not None:\n        context_k, context_v = apply_hypernetworks(self.hypernetworks, context, layer=self.context_layer)\n    else:\n        context_k, context_v = context, context\n\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n    q = self.to", "CodeBleu_score": 25.283263132618394}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if self.use_hypernetworks:\n        context_k, context_v = apply_hypernetworks(self.hypernetworks, context, self.layer)\n    else:\n        context_k = context_v = context\n    if self.use_multihead_attention:\n        # Reshape to (batch, heads, seq_len, dim_per_head)\n        # and transpose to (batch, heads, dim_per_head, seq_len)\n        context_k = context_k.transpose(1, 2).contiguous().view(\n            context_k.size(0), self.heads, self.dim_per_head, context_k.size(2))\n        context_v = context_v.transpose(1, 2).contiguous().view(\n            context_v.size(0), self.heads, self.dim_per_head, context_v.size(2))\n        # Reshape to (batch, seq_len, heads, dim_per_head)\n        # and transpose to (batch, seq_len, dim_per_head, heads)\n        x = x.transpose(1, 2).contiguous().view(\n            x.size(0), x.size(1), self.heads, self.dim_per_head)\n        # Reshape to (batch, heads, seq_len, dim_per_head)\n        # and transpose to (batch, heads, dim_per_head, seq_len)\n        x = x.transpose(2, 3).contiguous().view(\n            x.size(0), self.heads, self.dim_per_head, x.size(3))\n        # Reshape to (batch, heads, seq_len, dim_per_head)\n        # and transpose to (batch, heads, dim_per_head, seq_len)\n        context_v = context_v.transpose(2, 3).contiguous().view(\n            context_v.size(0), self.heads, self.dim_per_head, context_v.size(3))\n        # Reshape to (batch, heads, seq_len, dim_per_head)\n        # and transpose to (batch, heads, dim_per_head, seq_len)\n        context_k = context_k.transpose(2, 3).contiguous().view(\n            context_k.", "CodeBleu_score": 23.944906195852933}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    if self.is_hypernetwork:\n        context_k, context_v = apply_hypernetworks(self.hypernetworks, context)\n    else:\n        context_k = context_v = context\n\n    q = self.to_q(x)\n    k = self.to_k(context_k)\n    v = self.to_v(context_v)\n\n    if self.is_hypernetwork:\n        q, k, v = rearrange_for_attention(q, k, v, self.heads)\n\n    q = q * self.scale\n    sim = sim.softmax(sim.einsum('b h d, b h d -> b h h', q, k), mask=mask, dim=-1)\n    context = sim.einsum('b h h, b h d -> b h d', sim, v)\n\n    if self.is_hypernetwork:\n        context = rearrange_for_output(context, self.heads)\n\n    context = self.to_out(context)\n\n    return context\n\n", "CodeBleu_score": 39.56938572156827}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t    hypernetwork.optimizer_name = checkpoint['optimizer_name']\n    hypernetwork.optimizer_state_dict = checkpoint['optimizer_state_dict']\n    hypernetwork.sd_checkpoint = checkpoint['sd_checkpoint']\n    hypernetwork.sd_checkpoint_name = checkpoint['sd_checkpoint_name']\n    hypernetwork.step = checkpoint['step']\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.optional_info = checkpoint['optional_info']\n    hypernetwork.save(filename)\n\n", "CodeBleu_score": 18.091053878172552}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t    hypernetwork.checkpoint = checkpoint\n    hypernetwork.hypernetwork_name = hypernetwork_name\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.checkpoint = None\n        hypernetwork.hypernetwork_name = None\n        raise e\n    hypernetwork.checkpoint = None\n    hypernetwork.hypernetwork_name = None\n\n", "CodeBleu_score": 21.48987098423264}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    # Back up original attributes\n    original_checkpoint = hypernetwork.sd_checkpoint\n    original_checkpoint_name = hypernetwork.sd_checkpoint_name\n    original_name = hypernetwork.name\n    original_layer_structure = hypernetwork.layer_structure\n    original_activation_func = hypernetwork.activation_func\n    original_add_layer_norm = hypernetwork.add_layer_norm\n    original_weight_init = hypernetwork.weight_init\n    original_optimizer_name = hypernetwork.optimizer_name\n    original_optimizer_state_dict = hypernetwork.optimizer_state_dict\n    original_optional_info = hypernetwork.optional_info\n\n    # Update attributes with new checkpoint data\n    hypernetwork.sd_checkpoint = checkpoint\n    hypernetwork.sd_checkpoint_name = hypernetwork_name\n    hypernetwork.name = hypernetwork_name + '_' + checkpoint\n    hypernetwork.layer_structure = hypernetwork.sd_checkpoint['layer_structure']\n    hypernetwork.activation_func = hypernetwork.sd_checkpoint['activation_func']\n    hypernetwork.add_layer_norm = hypernetwork.sd_checkpoint['is_layer_norm']\n    hypernetwork.weight_init = hypernetwork.sd_checkpoint['weight_initialization']\n    hypernetwork.optimizer_name = hypernetwork.sd_checkpoint['optimizer_name']\n    hypernetwork.optimizer_state_dict = hypernetwork.sd_checkpoint['optimizer_state_dict']\n    hypernetwork.optional_info = hypernetwork.sd_checkpoint['optional_info']\n\n    # Save the hypernetwork\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        # Restore original attributes\n        hypernetwork.sd_checkpoint = original_checkpoint\n        hypernetwork.sd_checkpoint_name = original_checkpoint_name\n        hypernetwork.name = original_name\n        hypernetwork.layer_structure = original_layer_structure\n        hypernetwork.activation_func = original_activation_func\n        hypernetwork.add_layer_norm = original_add_layer_norm\n        hypernetwork.weight_init = original_weight_init\n        hypernetwork.optimizer_name = original_optimizer_name\n        hypernetwork.optimizer_state_dict = original_optimizer_state_dict\n        hypernetwork.optional_info = original_optional_info\n\n        raise e\n\n", "CodeBleu_score": 33.694658437709194}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.ema_enabled = False\n        self.ema_copy_to(context)\n        if self.ema_log:\n            self.ema_log_copy_to(context)\n    else:\n        self.ema_enabled = True\n        if self.ema_log:\n            self.ema_log_restore(context)\n        self.ema_restore(context)\n    return\n", "CodeBleu_score": 25.16647223717849}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = self.get_context()\n    if context.ema_enabled:\n        if context.ema_restore_params:\n            context.ema_params = self.get_parameters()\n        self.set_parameters(context.ema_params)\n        if context.ema_log:\n            self.log_parameters(context.ema_params, 'EMA')\n        return context.ema_params\n    else:\n        return None\n", "CodeBleu_score": 33.175160362648505}, {"code": "def ema_scope(self, context=None)\n\t\n    if self.ema_enabled:\n        self.ema_copy_to_model()\n        if self.ema_log_copy:\n            self.log_ema_copy()\n        self.ema_restore()\n        if self.ema_log_restore:\n            self.log_ema_restore()\n", "CodeBleu_score": 19.346986812013835}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_t = self.model(x, t)\n    if clip_denoised:\n        x_t = x_t.clamp(-1, 1)\n    x_recon = self.predict_start_from_noise(x_t, t, self.noise)\n    posterior_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(x, x_t, t)\n    return x_recon, posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 36.97807942186672}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_recon = self.model(x, t)\n    if clip_denoised:\n        x_recon = x_recon.clamp_(-1, 1)\n    posterior_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(x, x_recon, t)\n    return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 31.857482965563356}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_t, x_start = self.model(x, t)\n    noise = self.predict_start_from_noise(x_start, t, x_t)\n    if clip_denoised:\n        x_t = torch.clamp(x_t, -1, 1)\n    posterior_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(x_start, x_t, t)\n    return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 34.15517839353067}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='mean' if mean else 'none')\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='mean' if mean else 'none')\n    else:\n        raise NotImplementedError\n    return loss", "CodeBleu_score": 37.06309566529338}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = abs(pred - target)\n        if mean:\n            loss = loss.mean()\n        return loss\n    elif self.loss_type == 'l2':\n        loss = (pred - target) ** 2\n        if mean:\n            loss = loss.mean()\n        return loss\n    else:\n        raise NotImplementedError('Loss type {} not implemented'.format(self.loss_type))\n", "CodeBleu_score": 46.47955733363742}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss == 'l1':\n        if mean:\n            return abs(pred - target).mean()\n        else:\n            return abs(pred - target)\n    elif self.loss == 'l2':\n        if mean:\n            return mse_loss(pred, target, reduction='mean')\n        else:\n            return mse_loss(pred, target, reduction='none')\n    else:\n        raise NotImplementedError('Unknown loss type: {}'.format(self.loss))", "CodeBleu_score": 35.37538822083772}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.full((batch_size, ), self.num_timesteps - 1, device=x_start.device)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    return (self.kl_divergence(mean, variance, log_variance).mean() / np.log(2.0)).item()\n\n", "CodeBleu_score": 29.066150461939465}, {"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.ones(batch_size, device=x_start.device) * (self.num_diffusion_timesteps - 1)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    return torch.mean(normal_kl(mean, variance, log_variance)) / np.log(2)\n\n", "CodeBleu_score": 29.35294342913205}, {"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.tensor([self.num_diffusion_timesteps - 1] * batch_size)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    kl = self.normal_kl(mean, variance, log_variance)\n    return kl.mean() / np.log(2)\n\n", "CodeBleu_score": 30.219533411831673}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(f'/tmp/cache/{subsection}', size_limit=4294967296, min_file_size=262144)\n", "CodeBleu_score": 39.49986036084675}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = os.path.join(os.getcwd(), 'cache')\n    cache = diskcache.Cache(path=cache_dir, size_limit=4294967296, sqlite_filename='cache.sqlite', sqlite_table='cache', sqlite_autovacuum=True, sqlite_auto_vacuum=True, sqlite_busy_timeout=5000, sqlite_check_same_thread=True, sqlite_synchronous=True, sqlite_journal_mode=diskcache.sqlite.JournalMode.WAL, sqlite_temp_store=diskcache.sqlite.TempStore.MEMORY, sqlite_wal_autocheckpoint=1000, sqlite_wal_autocheckpoint_min=1000, sqlite_wal_checkpoint=diskcache.sqlite.Checkpoint.PASSIVE, sqlite_wal_checkpoint_min=1000, sqlite_wal_checkpoint_sync=diskcache.sqlite.CheckpointSync.FULL, sqlite_wal_checkpoint_sync_min=1000, sqlite_wal_checkpoint_sync_thresh=diskcache.sqlite.CheckpointSyncThresh.DEFAULT, sqlite_wal_checkpoint_sync_thresh_min=1000, sqlite_wal_max_page_count=diskcache.sqlite.MaxPageCount.DEFAULT, sqlite_wal_max_page_count_min=1000, sqlite_wal_max_size=diskcache.sqlite.MaxSize.DEFAULT, sqlite_wal_max_size_min=1000, sqlite_wal_min_checkpoint_count=1000, sqlite_wal_min_checkpoint_count_min=1000, sqlite_wal_min_checkpoint_size=diskcache.sqlite.MinCheckpointSize.DEFAULT, sqlite_wal_min_checkpoint_size_min=1000, sqlite_wal_min_sync_count=1000, sqlite_wal_min_sync_count_min=1000, sqlite_wal_min_sync_size=diskcache.sqlite.MinSyncSize.DEFAULT, sqlite_wal_min_sync_size_min=1000, sqlite_wal_sync=diskcache.sqlite.Sync.FULL, sqlite_wal_sync_min=1000, sqlite_wal_sync_thresh", "CodeBleu_score": 35.17900435508007}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = os.path.join(os.path.dirname(os.path.abspath(__file__)), \"cache\")\n    cache = diskcache.Cache(cache_dir, size_limit=4 * 1024 * 1024 * 1024, min_file_size=256 * 1024)\n    return cache\n", "CodeBleu_score": 50.753818869248605}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    global caches\n    global cache_lock\n    if subsection not in caches:\n        with cache_lock:\n            if subsection not in caches:\n                if not os.path.isdir(cache_dir):\n                    os.makedirs(cache_dir)\n                if not os.path.isfile(cache_filename):\n                    convert_old_cached_data()\n                if subsection not in caches:\n                    caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 42.47494647426075}, {"code": "def cache(subsection)\n\t\n    global caches\n    cache_obj = caches.get(subsection)\n    if cache_obj is None:\n        with cache_lock:\n            cache_obj = caches.get(subsection)\n            if cache_obj is None:\n                if not os.path.exists(cache_dir):\n                    os.makedirs(cache_dir)\n                if not os.path.isfile(cache_filename):\n                    convert_old_cached_data()\n                cache_obj = make_cache(subsection)\n                caches[subsection] = cache_obj\n    return cache_obj\n\n", "CodeBleu_score": 62.189731529207634}, {"code": "def cache(subsection)\n\t\n    global caches\n    global cache_lock\n    with cache_lock:\n        cache_obj = caches.get(subsection)\n        if cache_obj is None:\n            cache_obj = make_cache(subsection)\n            caches[subsection] = cache_obj\n        return cache_obj\n\n", "CodeBleu_score": 43.446805083809295}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = getmtime(filename)\n    if title in cache_obj:\n        entry = cache_obj[title]\n        if entry.getmtime() > mtime:\n            cache_obj.delete(title)\n            dump_cache()\n            return cached_data_for_file(subsection, title, filename, func)\n\n    if title not in cache_obj:\n        data = func()\n        cache_obj[title] = data\n        cache_obj.setmtime(title, mtime)\n        dump_cache()\n        return data\n\n    return cache_obj[title]\n", "CodeBleu_score": 30.411127596683613}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache = dump_cache.get(subsection)\n    mtime = getmtime(filename)\n    entry = cache.get(title)\n    if entry:\n        if mtime > entry.getmtime():\n            cache.delete(title)\n            entry = None\n\n    if not entry:\n        data = func()\n        cache.set(title, data, mtime)\n        dump_cache()\n        entry = cache.get(title)\n\n    return entry.get()", "CodeBleu_score": 31.75565255734722}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache = cache(subsection)\n    mtime = getmtime(filename)\n    entry = cache.get(title)\n    if entry", "CodeBleu_score": 3.494663523082284}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n\n    record_exception()\n\n    print(\"***\", message)\n\n    if exc_info:\n        print(\"---\")\n        print(traceback.format_exc())\n\n", "CodeBleu_score": 29.762011755558092}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    print(message.splitlines())\n    if exc_info:\n        print(textwrap.indent(traceback.format_exc(), \"    \"))\n        print(\"---\")\n\n", "CodeBleu_score": 37.4547632903184}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    print(\"***\", message)\n    if exc_info:\n        print(\"***\", traceback.format_exc())\n        print(\"---\")\n\n", "CodeBleu_score": 30.23332018267787}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if style.prompt == \"\" or style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    positive_prompt_extracted, positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    negative_prompt_extracted, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not positive_prompt_extracted or not negative_prompt_extracted:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 60.80896494727747}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, \"\", \"\"\n\n    if style.prompt == \"\":\n        positive_prompt, _ = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n        return True, \"\", negative_prompt\n    elif style.negative_prompt == \"\":\n        negative_prompt, _ = extract_style_text_from_prompt(style.prompt, prompt)\n        return True, prompt, \"\"\n    else:\n        positive_prompt, _ = extract_style_text_from_prompt(style.prompt, prompt)\n        negative_prompt, _ = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n        return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 42.81918120631026}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == \"\" and style.negative_prompt == \"\":\n        return False, prompt, negative_prompt\n\n    extracted_positive_prompt, prompt = extract_style_text_from_prompt(style.prompt, prompt)\n    extracted_negative_prompt, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not extracted_positive_prompt or not extracted_negative_prompt:\n        return False, prompt, negative_prompt\n\n    return True, prompt, negative_prompt", "CodeBleu_score": 61.95688390244973}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n    return a\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n\n    utterances = self.utterance_cycler.sample(count)\n\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n\n    return a", "CodeBleu_score": 94.20475781398312}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError('increase_only and decrease_only are mutually exclusive')\n    if increase_only:\n        change_in_dBFS = target_dBFS - wav.dBFS\n    elif decrease_only:\n        change_in_dBFS = target_dBFS - wav.dBFS\n    else:\n        change_in_dBFS = target_dBFS - wav.dBFS\n        if change_in_dBFS > 0:\n            increase_only = True\n        elif change_in_dBFS < 0:\n            decrease_only = True\n        else:\n            return wav\n    return wav.apply_gain(change_in_dBFS)\n\n", "CodeBleu_score": 32.572587425344445}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError('Increase and decrease are mutually exclusive')\n    if increase_only:\n        change = target_dBFS - wav.dBFS\n    elif decrease_only:\n        change = wav.dBFS - target_dBFS\n    else:\n        change = target_dBFS - wav.dBFS\n        if change <= 0:\n            change = target_dBFS - wav.dBFS\n        else:\n            change = wav.dBFS - target_dBFS\n    wav.dBFS = target_dBFS\n    return wav\n", "CodeBleu_score": 31.713661936864124}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"You cannot set both increase_only and decrease_only to True.\")\n    if increase_only:\n        change_in_dbfs = target_dbfs - wav.dBFS\n        return wav.apply_gain(change_in_dbfs)\n    if decrease_only:\n        change_in_dbfs = target_dbfs - wav.dBFS\n        return wav.apply_gain(-change_in_dbfs)\n    else:\n        return wav\n", "CodeBleu_score": 33.50890293515558}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath, map_location=device))\n    _model.eval()\n    print(f'Loaded model from {weights_fpath} to {device}')", "CodeBleu_score": 37.45317792537261}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _model = SpeakerEncoder(is_available=True)\n    _model.load_state_dict(torch.load(weights_fpath, map_location=device))\n    _model.to(device)\n    _model.eval()\n    print(\"Loaded model from {} to device {}\".format(weights_fpath, device))\n    return _model\n\n", "CodeBleu_score": 44.83638818831169}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    if device is None:\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    _model = SpeakerEncoder(\n        embedding_dim=128,\n        hidden_dim=256,\n        num_layers=3,\n        rnn_type=\"gru\",\n        bidirectional=True,\n        padding_idx=0,\n        dropout=0.5,\n        num_classes=0,\n        device=device,\n    )\n    if weights_fpath.is_file():\n        checkpoint = torch.load(weights_fpath, map_location=device)\n        _model.load_state_dict(checkpoint[\"model_state_dict\"])\n        _model.eval()\n        print(\"Loaded speaker encoder model from checkpoint: {}\".format(weights_fpath))\n    else:\n        print(\"No speaker encoder checkpoint found at: {}\".format(weights_fpath))\n    return _model\n", "CodeBleu_score": 47.91908035218822}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    # Check if the model is loaded\n    if _model is None:\n        raise Exception(\"The model has not been loaded yet. Please run the function load_model() first.\")\n    # Convert the input frames_batch from a NumPy array to a PyTorch tensor\n    frames_batch = torch.from_numpy(frames_batch)\n    # Transfer the tensor to the appropriate device\n    frames_batch = frames_batch.to(_device)\n    # Perform a forward pass through the model to compute the embeddings\n    embeds = _model.forward(frames_batch)\n    # Detach the result from the computation graph\n    embeds = embeds.detach()\n    # Move the tensor back to the CPU\n    embeds = embeds.cpu()\n    # Convert the tensor back to a NumPy array\n    embeds = embeds.numpy()\n    return embeds\n\n", "CodeBleu_score": 52.39673116675908}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception(\"The model is not loaded. Please load the model first.\")\n    frames_batch = torch.from_numpy(frames_batch)\n    frames_batch = frames_batch.to(_device)\n    with torch.no_grad():\n        embeds = _model.forward(frames_batch)\n        embeds = embeds.detach().cpu().numpy()\n    return embeds\n\n", "CodeBleu_score": 54.09037500823661}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    # Check if the model is loaded\n    if _model is None:\n        raise Exception(\"Model not loaded.\")\n    # Convert the input frames_batch from a NumPy array to a PyTorch tensor\n    frames_batch = torch.from_numpy(frames_batch)\n    # Transfer it to the appropriate device\n    frames_batch = frames_batch.to(_device)\n    # Perform a forward pass through the model to compute the embeddings\n    embeds = _model.forward(frames_batch)\n    # Detach the result from the computation graph\n    embeds = embeds.detach()\n    # Move it to the CPU\n    embeds = embeds.cpu()\n    # Convert it back to a NumPy array\n    embeds = embeds.numpy()\n    return embeds\n\n", "CodeBleu_score": 55.69221917466638}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0 <= partial_utterance_n_frames <= n_samples, 'Partial utterance n frames must be between 0 and n samples'\n    assert 0 <= min_pad_coverage <= 1, 'Minimum pad coverage must be between 0 and 1'\n    assert 0 <= overlap <= 1, 'Overlap must be between 0 and 1'\n    n_frames = int(np.ceil(n_samples / float(sampling_rate)))\n    frame_step = int(np.round(sampling_rate * overlap))\n    wav_slices = []\n    mel_slices = []\n    for i in range(0, n_frames - partial_utterance_n_frames + 1, frame_step):\n        wav_slice = wav[i:i + partial_utterance_n_frames]\n        mel_slice = mel[i:i + partial_utterance_n_frames]\n        wav_slices.append(wav_slice)\n        mel_slices.append(mel_slice)\n    if wav_slices[-1].shape[0] < partial_utterance_n_frames:\n        wav_slices = wav_slices[:-1]\n        mel_slices = mel_slices[:-1]\n    if len(wav_slices) > 1 and wav_slices[-1].shape[0] < partial_utterance_n_frames:\n        wav_slices = wav_slices[:-1]\n        mel_slices = mel_slices[:-1]\n    return wav_slices, mel_slices\n", "CodeBleu_score": 37.8155690169125}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert partial_utterance_n_frames > 0, 'Partial utterance n frames must be greater than 0'\n    assert min_pad_coverage >= 0 and min_pad_coverage <= 1, 'Min pad coverage must be between 0 and 1'\n    assert overlap >= 0 and overlap <= 1, 'Overlap must be between 0 and 1'\n    assert n_samples > 0, 'N samples must be greater than 0'\n    n_frames = int(np.ceil(n_samples / sample_rate))\n    frame_step = int(np.round(sample_rate * overlap))\n    wav_slices = []\n    mel_slices = []\n    for i in range(0, n_frames - partial_utterance_n_frames + 1, frame_step):\n        wav_slice = wav[i:i + partial_utterance_n_frames]\n        mel_slice = mel[i:i + partial_utterance_n_frames]\n        wav_slices.append(wav_slice)\n        mel_slices.append(mel_slice)\n    if len(wav_slices) > 1:\n        last_wav_slice = wav_slices[-1]\n        last_mel_slice = mel_slices[-1]\n        last_wav_slice_coverage = np.sum(last_wav_slice) / (len(last_wav_slice) * sample_rate)\n        last_mel_slice_coverage = np.sum(last_mel_slice) / (len(last_mel_slice) * mel_fmax)\n        if last_wav_slice_coverage < min_pad_coverage and last_mel_slice_coverage < min_pad_coverage:\n            wav_slices.pop()\n            mel_slices.pop()\n    return wav_slices, mel_slices\n", "CodeBleu_score": 34.260257777515505}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    # Assert that the partial utterance n frames is valid\n    assert partial_utterance_n_frames >= 2\n    # Assert that the min pad coverage is valid\n    assert min_pad_coverage > 0 and min_pad_coverage <= 1\n    # Assert that the overlap is valid\n    assert overlap > 0 and overlap < 1\n    # Calculate the number of frames and frame step\n    n_frames = int(np.ceil(n_samples / sample_rate))\n    frame_step = int(np.round(n_frames * overlap))\n    # Compute wav and mel slices\n    wav_slices = []\n    mel_slices = []\n    for i in range(0, n_frames - partial_utterance_n_frames + 1, frame_step):\n        wav_slice = wav[i:i + partial_utterance_n_frames]\n        mel_slice = mel[i:i + partial_utterance_n_frames]\n        wav_slices.append(wav_slice)\n        mel_slices.append(mel_slice)\n    # Check if there is extra padding required\n    if len(wav_slices) > 1:\n        last_wav_slice = wav_slices[-1]\n        last_mel_slice = mel_slices[-1]\n        last_wav_slice_coverage = np.sum(last_wav_slice) / partial_utterance_n_frames / sample_rate\n        last_mel_slice_coverage = np.sum(last_mel_slice) / partial_utterance_n_frames / sample_rate\n        if last_wav_slice_coverage < min_pad_coverage:\n            wav_slices.pop()\n            mel_slices.pop()\n    return wav_slices, mel_slices\n\n\n", "CodeBleu_score": 36.56840932329646}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = (int(np.sqrt(len(embed))), int(np.sqrt(len(embed))))\n    embed = embed.reshape(shape)\n    cmap = cm.get_cmap(\"viridis\", 12)\n    sm = plt.cm.ScalarMappable(cmap=cmap)\n    sm.set_clim(color_range)\n    ax.imshow(embed, cmap=cmap)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    plt.colorbar(sm)\n    return ax\n", "CodeBleu_score": 58.480015733641224}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = np.sqrt(len(embed))\n    embed = embed.reshape(shape, shape)\n    cmap = cm.get_cmap(\"viridis\", 12)\n    sm = plt.cm.ScalarMappable(cmap=cmap, norm=plt.Normalize(vmin=color_range[0], vmax=color_range[1]))\n    sm.set_array([])\n    im = ax.imshow(embed, cmap=cmap)\n    plt.colorbar(sm)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    return ax\n\n", "CodeBleu_score": 61.0583027538607}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = np.sqrt(embed.shape[0])\n    embed = embed.reshape(shape, shape)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_title(title)\n    sm = plt.cm.ScalarMappable(cmap=\"viridis\", norm=plt.Normalize(vmin=color_range[0], vmax=color_range[1]))\n    sm.set_array([])\n    cbar = plt.colorbar(sm)\n    cbar.set_label(\"Embedding\")\n    ax.imshow(embed, cmap=\"viridis\")\n    return ax\n", "CodeBleu_score": 55.514908384010766}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    batch_size, num_speakers, num_utterances, embed_dim = embeds.shape\n    centroids_incl = torch.zeros(num_speakers, embed_dim).to(self.device)\n    centroids_excl = torch.zeros(num_speakers, embed_dim).to(self.device)\n    for i in range(num_speakers):\n        centroids_incl[i] = torch.mean(embeds[i], dim=0)\n        centroids_excl[i] = torch.mean(embeds[i, :i] + embeds[i, i + 1:], dim=0)\n    centroids_incl = centroids_incl / torch.norm(centroids_incl, dim=1, keepdim=True)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=1, keepdim=True)\n    similarity_matrix = torch.zeros(num_speakers, num_speakers).to(self.device)\n    mask_matrix = torch.eye(num_speakers, dtype=torch.bool).to(self.device)\n    for i in range(num_speakers):\n        similarity_matrix[i] = torch.sum((embeds[i] - centroids_incl[i]) * (embeds[mask_matrix] - centroids_excl[mask_matrix]), dim=1)\n    similarity_matrix = similarity_matrix / torch.sum(similarity_matrix, dim=1, keepdim=True)\n    return similarity_matrix\n", "CodeBleu_score": 39.019325806950555}, {"code": "def similarity_matrix(self, embeds)\n\t\n    num_speakers = embeds.shape[0]\n    num_utterances = embeds.shape[1]\n    centroids_incl = torch.zeros(num_speakers, embeds.shape[2]).to(embeds.device)\n    centroids_excl = torch.zeros(num_speakers, embeds.shape[2]).to(embeds.device)\n    for i in range(num_speakers):\n        for j in range(num_utterances):\n            centroids_incl[i] += embeds[i, j]\n            centroids_excl[i] += embeds[i, j]\n        centroids_incl[i] /= num_utterances\n        centroids_excl[i] /= (num_utterances - 1)\n    centroids_incl = centroids_incl / torch.norm(centroids_incl, dim=1, keepdim=True)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=1, keepdim=True)\n    sim_matrix = torch.zeros(num_speakers, num_speakers).to(embeds.device)\n    mask = torch.ones(num_speakers, num_speakers).to(embeds.device)\n    for i in range(num_speakers):\n        for j in range(num_speakers):\n            if i == j:\n                mask[i, j] = 0\n    for i in range(num_speakers):\n        for j in range(num_speakers):\n            sim_matrix[i, j] = torch.sum(centroids_incl[i] * centroids_excl[j])\n    sim_matrix = sim_matrix * mask\n    sim_matrix = sim_matrix / torch.sum(sim_matrix)\n    sim_matrix = sim_matrix + torch.eye(num_speakers).to(embeds.device)\n    sim_matrix = sim_matrix / torch.norm(sim_matrix)\n    return sim_matrix\n", "CodeBleu_score": 34.64663472009099}, {"code": "def similarity_matrix(self, embeds)\n\t\n    # Determine the number of speakers and utterances per speaker\n    num_speakers, num_utterances = embeds.shape[0], embeds.shape[1]\n    # Compute centroids\n    centroids_incl = embeds.clone()\n    centroids_excl = embeds.clone()\n    for i in range(num_speakers):\n        centroids_incl[i, :] = torch.mean(embeds[i, :], dim=0)\n        centroids_excl[i, :] = torch.mean(embeds[i, :][1:], dim=0)\n    centroids_incl = centroids_incl.to(self.device)\n    centroids_excl = centroids_excl.to(self.device)\n    # Compute similarity matrix\n    similarity_matrix = torch.zeros((num_speakers, num_speakers)).to(self.device)\n    mask = torch.eye(num_speakers).to(self.device)\n    for i in range(num_speakers):\n        similarity_matrix[i, i] = -100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "CodeBleu_score": 24.424334475000602}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch, utterances_per_speaker, -1)\n    labels = torch.arange(speakers_per_batch).to(self.loss_device)\n    labels = labels.repeat(utterances_per_speaker, 1)\n    labels = labels.reshape(speakers_per_batch, utterances_per_speaker, -1)\n    labels = labels == labels.transpose(1, 2)\n    labels = labels.float()\n    loss = self.loss_fn(sim_matrix, labels)\n    fpr, tpr, thresholds = roc_curve(labels.flatten(), sim_matrix.flatten())\n    eer = brentq(lambda x : 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n    return loss, eer\n", "CodeBleu_score": 50.00356977567424}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker,\n                                    speakers_per_batch)\n    labels = np.repeat(np.arange(speakers_per_batch), utterances_per_speaker)\n    loss = self.loss_fn(sim_matrix, labels)\n    preds = inv_argmax(sim_matrix, labels)\n    fpr, tpr, thresholds = roc_curve(labels, sim_matrix.cpu().numpy())\n    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n    return loss, eer\n", "CodeBleu_score": 48.25390907088186}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker, speakers_per_batch)\n    labels = torch.zeros(speakers_per_batch * utterances_per_speaker).to(self.loss_device)\n    for i in range(speakers_per_batch):\n        labels[i * utterances_per_speaker:(i + 1) * utterances_per_speaker] = i\n    loss = self.loss_fn(sim_matrix, labels)\n    fpr, tpr, thresholds = roc_curve(labels.cpu().numpy(), sim_matrix.cpu().numpy())\n    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n    return loss, eer\n\n", "CodeBleu_score": 49.17400809389101}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    if self.params_log:\n        params = \"\"\n        for k, v in self.params.items():\n            params += \"    {}: {}", "CodeBleu_score": 3.867313559636599}, {"code": "def log_params(self)\n\t\n    if self.params_log:\n        params_str = \"Model parameters:", "CodeBleu_score": 0.4284843511096501}, {"code": "def log_params(self)\n\t\n    if self.params_log:\n        # import parameter configurations\n        from. import parameters\n        # initialize string\n        s = \"\"\n        # iterate through model and data parameters\n        for p in parameters.model_parameters:\n            s += p + \": \" + str(getattr(self, p)) + \"", "CodeBleu_score": 8.422532780143415}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n    embeds = np.concatenate(embeds, axis=0)\n    embeds = embeds.reshape(len(embeds), -1)\n    reducer = umap.UMAP(n_neighbors=5, min_dist=0.1, n_components=2)\n    embeds = reducer.fit_transform(embeds)\n    plt.clf()\n    plt.scatter(embeds[:, 0], embeds[:, 1], s=1, c=np.arange(len(embeds)))\n    plt.set_aspect('equal')\n    plt.xlim(np.min(embeds[:, 0]), np.max(embeds[:, 0]))\n    plt.ylim(np.min(embeds[:, 1]), np.max(embeds[:, 1]))\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title(\"Step %d\" % step)\n    plt.savefig(out_fpath)\n    plt.clf()\n    return embeds\n", "CodeBleu_score": 44.05112133478192}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.config.disable_plots:\n        return\n    if self.config.disable_umap:\n        return\n    if self.config.disable_umap_plot:\n        return\n    if len(embeds) == 0:\n        return\n    if len(embeds) < 10000:\n        max_speakers = len(embeds)\n    else:\n        max_speakers = 10\n    embeds = embeds[:max_speakers]\n    utterances_per_speaker = utterances_per_speaker[:max_speakers]\n    speakers = [self.config.speaker_to_idx[speaker] for speaker in self.config.speakers[:max_speakers]]\n    speakers = np.array(speakers)\n    speakers = np.repeat(speakers, utterances_per_speaker)\n    speakers = speakers.reshape(max_speakers, utterances_per_speaker)\n    speakers = speakers.flatten()\n    embeds = embeds.reshape(max_speakers, utterances_per_speaker, -1)\n    embeds = embeds.mean(axis=1)\n    reducer = umap.UMAP(random_state=self.config.seed)\n    embeds = reducer.fit_transform(embeds)\n    embeds = embeds.reshape(max_speakers, -1)\n    embeds = embeds.flatten()\n    plt.clf()\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=speakers, s=20, cmap='tab10')\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title(f'Step {step}')\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()\n    plt.clf()\n\n", "CodeBleu_score": 45.5364871310495}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n    embeds = embeds.flatten()\n    speakers = [utterance.speaker for utterance in utterances_per_speaker]\n    speakers = speakers[:max_speakers]\n    speakers = np.array(speakers)\n    speakers = speakers.flatten()\n    colors = speakers\n    umap_model = umap.UMAP(n_neighbors=5, min_dist=0.1, n_components=2)\n    embeds = umap_model.fit_transform(embeds)\n    plt.clf()\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=colors)\n    plt.set_aspect(\"equal\")\n    plt.gca().invert_yaxis()\n    plt.title(f\"Step {step}\")\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n    else:\n        plt.show()", "CodeBleu_score": 44.71268900374573}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    speaker_embedding_dim = speaker_embedding.size(1)\n    x_dim = x.dim()\n    speaker_embedding_index = x_dim - 1\n    x = x.repeat_interleave(speaker_embedding.size(0), dim=speaker_embedding_index)\n    x = x.reshape(-1, x_size[speaker_embedding_index], x_size[speaker_embedding_index + 1])\n    x = x.transpose(speaker_embedding_index, x_dim - 1)\n    x = torch.cat((x, speaker_embedding), dim=speaker_embedding_index)\n    return x\n", "CodeBleu_score": 35.08500499601711}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    speaker_embedding_dim = speaker_embedding.size(0)\n    speaker_embedding_length = speaker_embedding.size(1)\n    x_dim = x_size[0]\n    x_length = x_size[1]\n    x_dim_index = x.dim() - 2\n    speaker_embedding = speaker_embedding.repeat_interleave(x_length, dim=x_dim_index)\n    speaker_embedding = speaker_embedding.reshape(x_dim, speaker_embedding_dim, speaker_embedding_length)\n    speaker_embedding = speaker_embedding.transpose(1, 2)\n    x = torch.cat((speaker_embedding, x), dim=x_dim_index)\n    return x\n\n", "CodeBleu_score": 36.246105897589395}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_size = x.size()\n    speaker_embedding_size = speaker_embedding.size()\n    x_dim = x_size[-1]\n    speaker_embedding_dim = speaker_embedding_size[-1]\n    speaker_embedding_index = x_dim - speaker_embedding_dim\n    x = x.repeat_interleave(speaker_embedding_size[0], dim=speaker_embedding_index)\n    x = x.reshape(x_size[0], -1, x_dim)\n    x = x.transpose(1, 2)\n    x = torch.cat((x, speaker_embedding), dim=1)\n    return x\n", "CodeBleu_score": 38.46090935088904}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters.device\n    encoder_seq_proj_size = encoder_seq_proj.size()\n    self.cum_attn = torch.zeros(encoder_seq_proj_size[0], encoder_seq_proj_size[1], device=device)\n    self.attn = torch.zeros(encoder_seq_proj_size[0], encoder_seq_proj_size[1], device=device)\n", "CodeBleu_score": 18.748111189279683}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters.device\n    batch_size = encoder_seq_proj.size(1)\n    seq_len = encoder_seq_proj.size(0)\n    self.cumulative = torch.zeros(batch_size, seq_len).to(device)\n    self.attention = torch.zeros(batch_size, seq_len).to(device)\n", "CodeBleu_score": 21.88382118922974}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = self.parameters.device\n    batch_size, seq_len = encoder_seq_proj.size(0), encoder_seq_proj.size(1)\n    self.cumulative_attention = torch.zeros(batch_size, seq_len).to(device)\n    self.attention_weights = torch.zeros(batch_size, seq_len).to(device)\n", "CodeBleu_score": 20.42885269415486}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    text = _clean_text(text, cleaner_names)\n    arpabet = _arpabet_to_sequence(text)\n    sequence = []\n    curly_re = _curly_re\n    m = curly_re.search(text)\n    while m:\n        sequence += arpabet\n        sequence += _symbols_to_sequence(m.group(1).split())\n        text = text[m.end():]\n        m = curly_re.search(text)\n    sequence += arpabet\n    sequence += _symbols_to_sequence(text.split())\n    sequence += [_symbol_to_id[\" \"]]\n    return sequence", "CodeBleu_score": 33.880406919185404}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    curly_re = _curly_re\n    m = curly_re.match(text)\n    while m:\n        sequence += _symbols_to_sequence(m.group(1))\n        text = text[m.end():]\n        m = curly_re.match(text)\n    sequence += _symbols_to_sequence(_clean_text(text, cleaner_names))\n    sequence += [_symbol_to_id[\" \"]]\n    return sequence", "CodeBleu_score": 47.21336754337637}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    text = _clean_text(text, cleaner_names)\n    arpabet = _curly_re.findall(text)\n    arpabet_sequences = [_arpabet_to_sequence(a) for a in arpabet]\n    text_sequences = [_symbols_to_sequence(s) for s in text.split() if not _curly_re.match(s)]\n    return [0] + sum(arpabet_sequences, []) + [1] + sum(text_sequences, []) + [2]", "CodeBleu_score": 21.332681370970242}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    # Create a dictionary of symbols\n    symbols = dict(enumerate(alphabet))\n    # Create an empty string\n    result = ''\n    # Iterate over the sequence\n    for symbol_id in sequence:\n        # Retrieve the corresponding symbol from the dictionary\n        symbol = symbols[symbol_id]\n        # Enclose ARPAbet symbols in curly braces\n        symbol = '{' + symbol + '}'\n        # Concatenate the symbol to the result string\n        result += symbol\n    # Replace adjacent curly braces with a space\n    result = result.replace('}{','')\n    return result\n", "CodeBleu_score": 36.89467849404515}, {"code": "def sequence_to_text(sequence)\n\t\n    # Create a dictionary of symbols and their corresponding IDs\n    symbols_dict = {0: \" \", 1: \"a\", 2: \"b\", 3: \"c\", 4: \"d\", 5: \"e\", 6: \"f\", 7: \"g\", 8: \"h\", 9: \"i\", 10: \"j\", 11: \"k\", 12: \"l\", 13: \"m\", 14: \"n\", 15: \"o\", 16: \"p\", 17: \"q\", 18: \"r\", 19: \"s\", 20: \"t\", 21: \"u\", 22: \"v\", 23: \"w\", 24: \"x\", 25: \"y\", 26: \"z\", 27: \"1\", 28: \"2\", 29: \"3\", 30: \"4\", 31: \"5\", 32: \"6\", 33: \"7\", 34: \"8\", 35: \"9\", 36: \"0\", 37: \" \", 38: \" \", 39: \" \", 40: \" \", 41: \" \", 42: \" \", 43: \" \", 44: \" \", 45: \" \", 46: \" \", 47: \" \", 48: \" \", 49: \" \", 50: \" \", 51: \" \", 52: \" \", 53: \" \", 54: \" \", 55: \" \", 56: \" \", 57: \" \", 58: \" \", 59: \" \", 60: \" \", 61: \" \", 62: \" \", 63: \" \", 64: \" \", 65: \" \", 66: \" \", 67: \" \", 68: \" \", 69: \" \", 70: \" \", 71: \" \", 72: \" \", 73: \" \", 74: \" \", 75: \" \", 76: \" \", 77: \" \", 7", "CodeBleu_score": 3.443612888028274}, {"code": "def sequence_to_text(sequence)\n\t\n    # Create a dictionary of IDs and corresponding symbols\n    symbol_dict = {0: \" \", 1: \"'\", 2: \",\", 3: \".\", 4: \"!\", 5: \"?\", 6: \":\", 7: \";\", 8: \"-\", 9: \"(\", 10: \")\", 11: \"[\", 12: \"]\", 13: \"0\", 14: \"1\", 15: \"2\", 16: \"3\", 17: \"4\", 18: \"5\", 19: \"6\", 20: \"7\", 21: \"8\", 22: \"9\", 23: \"A\", 24: \"B\", 25: \"C\", 26: \"D\", 27: \"E\", 28: \"F\", 29: \"G\", 30: \"H\", 31: \"I\", 32: \"J\", 33: \"K\", 34: \"L\", 35: \"M\", 36: \"N\", 37: \"O\", 38: \"P\", 39: \"Q\", 40: \"R\", 41: \"S\", 42: \"T\", 43: \"U\", 44: \"V\", 45: \"W\", 46: \"X\", 47: \"Y\", 48: \"Z\", 49: \"a\", 50: \"b\", 51: \"c\", 52: \"d\", 53: \"e\", 54: \"f\", 55: \"g\", 56: \"h\", 57: \"i\", 58: \"j\", 59: \"k\", 60: \"l\", 61: \"m\", 62: \"n\", 63: \"o\", 64: \"p\", 65: \"q\", 66: \"r\", 67: \"s\", 68: \"t\", 69: \"u\", 70: \"v\", 71: \"w\", 72: \"x\", 73: \"y\", 74: \"z\",", "CodeBleu_score": 3.587611401023284}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n", "CodeBleu_score": 95.3261531719067}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    wav_dir = synthesizer_root.joinpath('wavs')\n    embed_dir = synthesizer_root.joinpath('embeddings')\n    metadata_fpath = synthesizer_root.joinpath('metadata.csv')\n    if not wav_dir.exists():\n        raise FileNotFoundError(f'Wav directory {wav_dir} does not exist.')\n    if not embed_dir.exists():\n        embed_dir.mkdir()\n    if not metadata_fpath.exists():\n        raise FileNotFoundError(f'Metadata file {metadata_fpath} does not exist.')\n    metadata = pd.read_csv(metadata_fpath)\n    metadata['wav_path'] = wav_dir.joinpath(metadata['wav_path'])\n    metadata['embed_path'] = embed_dir.joinpath(metadata['embed_path'])\n    pool = Pool(n_processes)\n    tqdm_args = {'total': len(metadata), 'unit': 'file', 'unit_scale': True, 'leave': True}\n    with tqdm(**tqdm_args) as pbar:\n        for _ in pool.imap(partial(create_embedding, encoder_model_fpath=encoder_model_fpath), metadata.itertuples()):\n            pbar.update()", "CodeBleu_score": 43.7191977119001}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check if the synthesizer root directory exists\n    if not synthesizer_root.exists():\n        raise ValueError(f\"Synthesizer root directory {synthesizer_root} does not exist.\")\n\n    # Check if the encoder model file exists\n    if not encoder_model_fpath.exists():\n        raise ValueError(f\"Encoder model file {encoder_model_fpath} does not exist.\")\n\n    # Create a directory to store the embeddings\n    embed_dir = synthesizer_root.joinpath(\"embeddings\")\n    if not embed_dir.exists():\n        embed_dir.mkdir()\n\n    # Read the metadata file\n    metadata_fpath = synthesizer_root.joinpath(\"metadata.csv\")\n    if not metadata_fpath.exists():\n        raise ValueError(f\"Metadata file {metadata_fpath} does not exist.\")\n    metadata = pd.read_csv(metadata_fpath)\n\n    # Create a list of file paths for audio and embeddings\n    wav_dir = synthesizer_root.joinpath(\"wavs\")\n    wav_paths = list(wav_dir.glob(\"**/*.wav\"))\n    embed_paths = [embed_dir.joinpath(path.name.replace(\".wav\", \".npy\")) for path in wav_paths]\n\n    # Verify that all required files and directories exist\n    for path in wav_paths + embed_paths:\n        if not path.exists():\n            raise ValueError(f\"File or directory {path} does not exist.\")\n\n    # Create a multiprocessing pool\n    pool = Pool(n_processes)\n\n    # Create a function to generate embeddings for a single audio file\n    def generate_embeddings(wav_path, embed_path):\n        # Load the encoder model\n        encoder = torch.hub.load(\"pytorch/fairseq\", \"wav2vec2_large_librivox_530h\")\n        encoder.eval()\n        # Load the audio file\n        audio, sample_rate = torchaudio.load(wav_path)\n        # Generate embeddings\n        with torch.no_grad():\n            embeddings = encoder.extract_features(audio)\n        # Save the embeddings to a file\n        np.save(embed_path, embeddings.numpy())\n\n    # Generate embeddings for each audio file using the multiprocessing pool\n    with tqdm(total=len(wav_paths)) as pbar:\n        for wav_path, embed_path in zip(wav_paths, embed_", "CodeBleu_score": 39.089804359622484}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    # Check if the synthesizer root directory exists\n    if not synthesizer_root.exists():\n        raise ValueError(f\"Synthesizer root directory {synthesizer_root} does not exist.\")\n    # Check if the encoder model file exists\n    if not encoder_model_fpath.exists():\n        raise ValueError(f\"Encoder model file {encoder_model_fpath} does not exist.\")\n    # Check if the metadata file exists\n    metadata_fpath = synthesizer_root.joinpath(\"metadata.csv\")\n    if not metadata_fpath.exists():\n        raise ValueError(f\"Metadata file {metadata_fpath} does not exist.\")\n    # Check if the embeddings directory exists\n    embed_dir = synthesizer_root.joinpath(\"embeddings\")\n    if not embed_dir.exists():\n        raise ValueError(f\"Embeddings directory {embed_dir} does not exist.\")\n    # Read the metadata file\n    metadata = pd.read_csv(metadata_fpath)\n    # Create a list of audio file paths\n    audio_paths = [synthesizer_root.joinpath(row[\"audio_filename\"]) for index, row in metadata.iterrows()]\n    # Create a list of embeddings file paths\n    embed_paths = [embed_dir.joinpath(row[\"audio_filename\"].replace(\".wav\", \".npy\")) for index, row in metadata.iterrows()]\n    # Verify that all audio files exist\n    for audio_path in audio_paths:\n        if not audio_path.exists():\n            raise ValueError(f\"Audio file {audio_path} does not exist.\")\n    # Verify that all embeddings files do not exist\n    for embed_path in embed_paths:\n        if embed_path.exists():\n            raise ValueError(f\"Embedding file {embed_path} already exists.\")\n    # Create a multiprocessing pool\n    pool = Pool(n_processes)\n    # Create a partial function to process an audio file\n    process_audio = partial(process_audio_file, encoder_model_fpath=encoder_model_fpath)\n    # Process the audio files using multiprocessing\n    with tqdm(total=len(audio_paths)) as pbar:\n        for i, _ in enumerate(pool.imap(process_audio, audio_paths)):\n            pbar.update(1)\n    # Close the multiprocessing pool\n    pool.close()\n    pool.join()\n\n", "CodeBleu_score": 37.98062969452392}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save the attention plot\n    save_attention(attention, plot_dir.joinpath(f\"step_{step}_sample_{sample_num}_attn\"))\n\n    # Save the predicted mel spectrogram\n    np.save(mel_output_dir.joinpath(f\"step_{step}_sample_{sample_num}_mel_pred\"), mel_prediction)\n\n    # Save the reconstructed waveform\n    audio.save_wav(wav_dir.joinpath(f\"step_{step}_sample_{sample_num}_wav\"), hparams,\n                   audio.inv_mel_spectrogram(mel_prediction))\n\n    # Plot the predicted and target mel spectrograms\n    plot_spectrogram(mel_prediction, mel_output_dir.joinpath(f\"step_{step}_sample_{sample_num}_mel_pred_plot\"),\n                     f\"Mel-spectrogram", "CodeBleu_score": 13.452163638883755}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n\n    # save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"{sample_num}_attn\"))\n\n    # save mel prediction\n    np.save(mel_output_dir.joinpath(f\"{sample_num}_mel\"), mel_prediction.cpu().numpy())\n\n    # save wav\n    audio.save_wav(wav_dir.joinpath(f\"{sample_num}_wav\"),\n                   audio.inv_mel_spectrogram(mel_prediction.cpu().numpy()))\n\n    # plot spectrogram\n    plot_spectrogram(mel_prediction.cpu().numpy(),\n                     plot_dir.joinpath(f\"{sample_num}_mel_spectrogram\"),\n                     f\"Step: {step}, Loss: {loss:.2f}\")\n\n    # plot mel target\n    plot_spectrogram(target_spectrogram.cpu().numpy(),\n                     plot_dir.joinpath(f\"{sample_num}_target_spectrogram\"),\n                     f\"Step: {step}, Loss: {loss:.2f}\",\n                     target_spectrogram=target_spectrogram.cpu().numpy())\n\n", "CodeBleu_score": 21.421703649700003}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    save_attention(attention, plot_dir.joinpath(f\"{sample_num:06d}\"))\n\n    # Save mel spectrogram\n    np.save(mel_output_dir.joinpath(f\"{sample_num:06d}\"), mel_prediction)\n\n    # Save wav\n    wav = audio.inv_mel_spectrogram(mel_prediction)\n    audio.save_wav(wav, wav_dir.joinpath(f\"{sample_num:06d}.wav\"))\n\n    # Save plot\n    plot_spectrogram(mel_prediction, plot_dir.joinpath(f\"{sample_num:06d}.png\"),\n                     title=f\"Step {step:08d}, Loss: {loss:.2f}\",\n                     target_spectrogram=target_spectrogram,\n                     max_len=hparams.max_mel_length, auto_aspect=True)\n\n    # Print input sequence\n    print(f\"Step {step:08d}: {sequence_to_text(input_seq)}\")\n\n", "CodeBleu_score": 22.525384078454007}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    return sum([np.prod(p.size()) for p in self.parameters() if p.requires_grad]) / 1e6\n", "CodeBleu_score": 17.37289526406843}, {"code": "def num_params(self)\n\t\n    return sum([np.prod(p.size()) for p in self.parameters() if p.requires_grad]) / 1e6\n", "CodeBleu_score": 17.37289526406843}, {"code": "def num_params(self)\n\t\n    p = filter(lambda p: p.requires_grad, self.parameters())\n    n_params = np.sum([np.prod(p.size()) for p in p])\n    print('Number of trainable parameters: %.3f million' % (n_params/1e6))\n", "CodeBleu_score": 36.37411243315476}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        new_size = x.size(0) + 2 * pad\n    elif side == 'before':\n        new_size = x.size(0) + pad\n    elif side == 'after':\n        new_size = x.size(0) + pad\n    else:\n        raise ValueError(\"Invalid side: {}\".format(side))\n    padded = torch.zeros(new_size, *x.size()[1:])\n    if x.is_cuda:\n        padded = padded.cuda()\n    padded = padded.long()\n    padded[:x.size(0)] = x\n    return padded\n", "CodeBleu_score": 34.29506368630228}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'before':\n        new_total_size = x.size(0) + pad * 2\n    elif side == 'after':\n        new_total_size = x.size(0) + pad\n    else:\n        new_total_size = x.size(0)\n    if x.is_cuda:\n        padded_tensor = torch.cuda.FloatTensor(new_total_size, x.size(1), x.size(2))\n    else:\n        padded_tensor = torch.FloatTensor(new_total_size, x.size(1), x.size(2))\n    if side == 'before':\n        padded_tensor[:, :, :] = 0\n        padded_tensor[pad:x.size(0) + pad, :, :] = x\n    elif side == 'after':\n        padded_tensor[:, :, :] = 0\n        padded_tensor[0:x.size(0), :, :] = x\n    else:\n        padded_tensor[:, :, :] = x\n    return padded_tensor\n", "CodeBleu_score": 34.850666917598275}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'both':\n        return torch.cat((pad, x, pad), 0)\n    elif side == 'before':\n        return torch.cat((pad, x), 0)\n    elif side == 'after':\n        return torch.cat((x, pad), 0)\n    else:\n        raise ValueError(\"Side must be either 'before', 'after', or 'both'.\")\n", "CodeBleu_score": 22.26294890316979}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t    import matplotlib.pyplot as plt\n    fig = plt.figure(figsize=(10, 10))\n    plt.imshow(attn)\n    plt.axis('off')\n    plt.savefig(path, dpi=300)\n    plt.close(fig)\n", "CodeBleu_score": 46.664885633640786}, {"code": "def save_attention(attn, path)\n\t    import matplotlib.pyplot as plt\n    fig = plt.figure()\n    plt.imshow(attn)\n    plt.axis('off')\n    plt.savefig(path, bbox_inches='tight', pad_inches=0)\n    plt.close(fig)\n", "CodeBleu_score": 41.19606855417966}, {"code": "def save_attention(attn, path)\n\t    import matplotlib.pyplot as plt\n    fig = plt.figure(figsize=(8, 8))\n    plt.imshow(attn, cmap='gray')\n    plt.axis('off')\n    fig.savefig(path, bbox_inches='tight')\n    plt.close(fig)\n", "CodeBleu_score": 56.064783920939135}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\n        'image_name': image_name,\n        'prediction': prediction,\n        'confidence': confidence\n    }\n    with open('results.csv', 'a', newline='') as csv_file:\n        writer = csv.DictWriter(csv_file, fieldnames=data.keys())\n        if not csv_file.is_open():\n            writer.writeheader()\n        writer.writerow(data)\n\n", "CodeBleu_score": 53.353154251287336}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\n        'image_name': image_name,\n        'prediction': prediction,\n        'confidence': confidence\n    }\n    with open(CSV_PATH, 'a', newline='') as f:\n        writer = csv.DictWriter(f, fieldnames=data.keys())\n        if not f.tell():\n            writer.writeheader()\n        writer.writerow(data)\n", "CodeBleu_score": 61.62559218972095}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    prediction_dict = {\n        'Image': image_name,\n        'Prediction': prediction,\n        'Confidence': confidence\n    }\n    with open(csv_path, 'a', newline='') as csv_file:\n        writer = csv.DictWriter(csv_file, fieldnames=prediction_dict.keys())\n        if not csv_path.is_file():\n            writer.writeheader()\n        writer.writerow(prediction_dict)\n\n", "CodeBleu_score": 54.30478495776603}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} Exporting TorchScript model\")\n    traced = torch.jit.trace(model, im)\n    traced.save(file)\n    if optimize:\n        traced_file = file.with_suffix(\".pt\")\n        traced.save(traced_file)\n        optimize_for_mobile(traced_file)\n        return traced_file\n    return file\n\n", "CodeBleu_score": 28.231737917200984}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    LOGGER.info(f\"{prefix} Exporting TorchScript model\")\n    ts = torch.jit.trace(model, im)\n    if optimize:\n        LOGGER.info(f\"{prefix} Optimizing TorchScript model\")\n        ts = optimize_for_mobile(ts)\n    file = file.with_suffix(\".pt\")\n    ts.save(file)\n    LOGGER.info(f\"{prefix} Saved: {file}\")\n    return file, None\n\n", "CodeBleu_score": 31.166357402962525}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    model_info(self, verbose, img_size)\n\n    with open(file, \"wb\") as f:\n        f.write(ts.save(model, im))\n\n    if optimize:\n        model_file = file.with_suffix(\".pt\")\n        LOGGER.info(f\"{prefix} Optimizing for mobile...\")\n        optimize_for_mobile(model_file)\n        return model_file\n    return file\n\n", "CodeBleu_score": 25.27438407804089}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    if not coremltools:\n        raise ImportError(f\"{prefix}coremltools is not installed.\")\n    LOGGER.info(f\"{prefix}Exporting to CoreML format\")\n    file = file.with_suffix(\".mlmodel\")\n    if nms:\n        model = iOSModel(model)\n    if int8:\n        model = torch.quantize_model(model, torch.quantization.QuantStub(), torch.quantization.DeQuantStub())\n    if half:\n        model = model.half()\n    model = model.eval()\n    model = model.to(\"cpu\")\n    if int8:\n        model = model.to(torch.int8)\n    elif half:\n        model = model.to(torch.float16)\n    model.eval()\n    torch.onnx.export(model, im, file, verbose=False, opset_version=13)\n    LOGGER.info(f\"{prefix}Exporting to CoreML format completed\")\n    return file, model\n\n", "CodeBleu_score": 34.831160515785356}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    LOGGER.info(f\"{prefix} Exporting to CoreML...\")\n    if not coremltools:\n        raise ValueError(f\"{prefix} Please install coremltools to export to CoreML\")\n    if int8 and not coremltools.models.is_supported_backend(\"neural_network\"):\n        raise ValueError(f\"{prefix} CoreML int8 export requires the neural_network backend.\")\n    if half and not coremltools.models.is_supported_backend(\"neural_network\"):\n        raise ValueError(f\"{prefix} CoreML half export requires the neural_network backend.\")\n    if nms and not coremltools.models.is_supported_backend(\"neural_network\"):\n        raise ValueError(f\"{prefix} CoreML NMS export requires the neural_network backend.\")\n    if nms:\n        model = iOSModel(model)\n    model.to(\"cpu\")\n    model.eval()\n    model.half() if half else model.float()\n    model.to(torch.device(\"cpu\"))\n    model.trace = True\n    model.trace_input = torch.zeros(1, 3, im.shape[0], im.shape[1])\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace_input.float()\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace_input.float()\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace_input.float()\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace_input.float()\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace_input.float()\n    model.trace_input = model.trace_input.to(model.device)\n    model.trace_input = model.trace_input.half() if half else model.trace", "CodeBleu_score": 27.426997095178173}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    if not coremltools:\n        raise ImportError(\"CoreML export requires coremltools\")\n    LOGGER.info(prefix + \"Exporting CoreML model...\")\n    model_file = file.with_suffix(\".mlmodel\")\n    if nms:\n        model = iOSModel(model)\n    model_traced = torch.jit.trace(model, im)\n    model_coreml = ct.convert(model_traced, inputs=[ct.ImageType(name=\"image\", shape=im.shape)], convert_to=\"mlprogram\")\n    if int8:\n        model_coreml = quantize_weights(model_coreml, axis=(0, 3, 1, 2))\n    if half:\n        model_coreml = model_coreml.convert(fp16=True)\n    model_coreml.save(model_file)\n    LOGGER.info(prefix + \"CoreML model saved as \" + model_file)\n    return model_file, model_coreml\n\n", "CodeBleu_score": 36.982522419941574}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n", "CodeBleu_score": 26.945683776730807}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n", "CodeBleu_score": 26.945683776730807}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n\n\n\n", "CodeBleu_score": 26.945683776730807}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        log_alpha_fn = interpolate_fn\n    elif self.schedule_type == 'linear':\n        log_alpha_fn = lambda x: x * self.log_alpha_max\n    elif self.schedule_type == 'cosine':\n        log_alpha_fn = lambda x: self.log_alpha_max * (1 + torch.cos(x * math.pi)) / 2\n    else:\n        raise ValueError('Unsupported schedule type: {}'.format(self.schedule_type))\n    return log_alpha_fn(t)\n\n", "CodeBleu_score": 37.512929785521095}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return self.log_alpha_fn(t)\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_fn(t) - self.log_alpha_fn(0)\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_fn(t) - self.log_alpha_fn(0) + self.log_alpha_fn(1) - self.log_alpha_fn(0)\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 28.930203988839367}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return self.log_alpha_fn(t)\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_fn(t) + torch.log(self.log_alpha_fn(self.T) - self.log_alpha_fn(0))\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_fn(t) + torch.log(self.log_alpha_fn(self.T) - self.log_alpha_fn(0)) * 0.5 * (1.0 + torch.cos(np.pi * t / self.T))\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 34.889453288134106}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        t = self.beta * lamb\n    else:\n        log_alpha = self.log_alpha\n        if self.schedule == 'discrete':\n            t = interpolate_fn(lamb, log_alpha, torch.zeros_like(log_alpha))\n        else:\n            t = torch.arccos(torch.exp(log_alpha))\n    return t\n\n", "CodeBleu_score": 16.578729951061565}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        beta = self.beta\n        T = self.T\n        t = (T - 1) * lamb + beta\n        return t\n    elif self.schedule == 'discrete':\n        log_alpha = self.log_alpha\n        t = interpolate_fn(lamb, torch.exp(log_alpha), torch.log(torch.exp(log_alpha) + 1))\n        return t\n    else:\n        log_alpha = self.log_alpha\n        t = torch.arccos(torch.exp(log_alpha))\n        return t\n\n", "CodeBleu_score": 23.659348278802923}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == \"linear\":\n        t = self.beta * lamb\n    elif self.schedule == \"discrete\":\n        log_alpha = self.log_alpha\n        t = interpolate_fn(lamb, log_alpha, self.log_alpha)\n    else:\n        log_alpha = torch.log(torch.exp(self.log_alpha) - 1)\n        t = torch.arccos(torch.exp(log_alpha) * torch.cos(torch.arccos(lamb) - log_alpha)) / self.pi\n    return t\n\n", "CodeBleu_score": 20.80565035175078}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t# Expand the time input to match the batch size\n    t_continuous = expand_dims(t_continuous, x.dim())\n\n    # Process the input through the model\n    if model_type == \"RNN\":\n        x = model(x, t_continuous)\n    elif model_type == \"GRU\":\n        x = model(x, t_continuous)\n    elif model_type == \"LSTM\":\n        x = model(x, t_continuous)\n    elif model_type == \"Transformer\":\n        x = model(x, t_continuous)\n\n    # Apply the noise schedule to the model output\n    if noise_schedule.type == \"log_normal\":\n        x = x * noise_schedule.marginal_std(t_continuous) + noise_schedule.marginal_alpha(t_continuous)\n    elif noise_schedule.type == \"log_normal_mixture\":\n        x = x * noise_schedule.marginal_std(t_continuous) + noise_schedule.marginal_alpha(t_continuous)\n    elif noise_schedule.type == \"log_normal_mixture_2d\":\n        x = x * noise_schedule.marginal_std(t_continuous) + noise_schedule.marginal_alpha(t_continuous)\n\n    # Apply the conditioning if it is provided\n    if cond is not None:\n        x = x + cond\n\n    # Return the processed model output\n    return x", "CodeBleu_score": 31.32748877490293}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\tif cond is not None:\n        x = torch.cat([x, cond], dim=-1)\n    t_continuous = t_continuous.expand(x.size(0), *t_continuous.size()[1:])\n    if model.type =='resnet':\n        x = model.forward(x)\n    elif model.type == 'unet':\n        x = model.forward(x, t_continuous)\n    else:\n        raise NotImplementedError('Model type not supported.')\n    if model.type =='resnet':\n        x = x.reshape(x.size(0), -1)\n    elif model.type == 'unet':\n        x = x.reshape(x.size(0), -1, t_continuous.size(-1))\n    else:\n        raise NotImplementedError('Model type not supported.')\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x.reshape(x.size(0), -1)\n    x = x", "CodeBleu_score": 29.127279223105962}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\t# Expand the time input to match the batch size.\n    t_continuous = expand_dims(t_continuous, x.dim())\n    # Process the input through the model.\n    if cond is not None:\n        x = model(x, cond)\n    else:\n        x = model(x)\n    # Apply the noise schedule to the model output.\n    if noise_schedule.type =='marginal':\n        x = x * noise_schedule.marginal_std(t_continuous) + noise_schedule.marginal_alpha(t_continuous)\n    elif noise_schedule.type == 'conditional':\n        x = x * noise_schedule.conditional_std(t_continuous, cond) + noise_schedule.conditional_alpha(t_continuous, cond)\n    elif noise_schedule.type == 'independent':\n        x = x * noise_schedule.independent_std(t_continuous) + noise_schedule.independent_alpha(t_continuous)\n    elif noise_schedule.type == 'independent_conditional':\n        x = x * noise_schedule.independent_conditional_std(t_continuous, cond) + noise_schedule.independent_conditional_alpha(t_continuous, cond)\n    return x\n", "CodeBleu_score": 30.82394387399738}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    if t is None:\n        t = self.t\n    x0 = x0.abs()\n    x0 = x0.reshape(x0.shape[0], -1)\n    x0 = torch.quantile(x0, t, dim=1)\n    x0 = torch.clamp(x0, min=1e-6)\n    x0 = x0.reshape(x0.shape[0], 1, 1, 1)\n    return self.scale * x0\n\n", "CodeBleu_score": 34.36511434178681}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    if t is None:\n        t = torch.quantile(torch.abs(x0), 0.999)\n    x0 = x0 / t\n    x0 = torch.clamp(x0, -1.0, 1.0)\n    return x0 * t\n", "CodeBleu_score": 21.356813804468516}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    x0 = expand_dims(x0, 0)\n    x0 = torch.abs(x0)\n    x0 = torch.quantile(x0, 0.5, dim=0)\n    x0 = torch.clamp(x0, 0, 1)\n    x0 = torch.maximum(x0, 0.0001)\n    x0 = torch.log(x0)\n    x0 = torch.exp(x0)\n    x0 = x0 * 2\n    x0 = torch.clamp(x0, 0, 1)\n    x0 = x0 * 2\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 = x0 * x0\n    x0 =", "CodeBleu_score": 14.425989225972147}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t  threshold = self.threshold_ratio * self.max_threshold\n    x = torch.clamp(x, min=0., max=threshold)\n    x = x / threshold\n    return x", "CodeBleu_score": 9.067215880455777}, {"code": "def data_prediction_fn(self, x, t)\n\t  threshold_ratio = self.threshold_ratio\n    max_threshold = self.max_threshold\n    x = self.dynamic_thresholding_fn(x, threshold_ratio, max_threshold)\n    x = x / x.max()\n    return x", "CodeBleu_score": 4.246608759401211}, {"code": "def data_prediction_fn(self, x, t)\n\t  threshold = self.threshold_ratio * self.max_threshold\n    clamped = torch.clamp(x, min=-threshold, max=threshold)\n    return clamped / threshold", "CodeBleu_score": 9.354618717286552}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    input = input.view(sigma_in.shape)\n    output = model(input)\n    eps = output + sigma_in * input\n    return eps\n\n", "CodeBleu_score": 22.233259466768573}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    # Reshape sigma to match the dimensions of the input\n    sigma = sigma_in.view(input.size())\n    # Scale the input\n    scaled_input = input * sigma\n    # Compute the prediction\n    prediction = model(scaled_input)\n    # Adjust the prediction with the scaled input and sigma\n    adjusted_prediction = prediction + scaled_input\n    return adjusted_prediction\n\n", "CodeBleu_score": 20.728347401289156}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.view(input.shape)\n    scaled_input = input * sigma_in\n    prediction = model(scaled_input)\n    adjusted_prediction = prediction + scaled_input\n    return adjusted_prediction\n\n", "CodeBleu_score": 20.78661200126854}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        grad_log_alpha = torch.autograd.grad(log_alpha, taus, retain_graph=True)[0]\n        return torch.exp(-0.5 * taus ** 2 * (beta_1 - beta_0) - taus * beta_0) * grad_log_alpha\n\n", "CodeBleu_score": 33.9375004534093}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = alpha.log()\n        log_alpha.backward(gradient=torch.ones_like(taus))\n        return alpha * log_alpha.grad\n\n", "CodeBleu_score": 32.047928073851914}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.inference_mode():\n        taus.requires_grad_()\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        grad_log_alpha = torch.autograd.grad(log_alpha, taus)[0]\n        integrand = alpha * grad_log_alpha\n    return integrand\n\n", "CodeBleu_score": 37.70348822420348}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if disable is None:\n        disable = []\n    x = x.detach().requires_grad_()\n    sigmas = [s.detach().requires_grad_() for s in sigmas]\n    denoised = model(x, **extra_args)\n    for i, sigma in enumerate(sigmas):\n        if i in disable:\n            continue\n        sigma_down, sigma_up = get_ancestral_step(sigma, sigma, eta)\n        if sigma_down > 0:\n            x = x + sigma_down * to_d(x, sigma, denoised)\n        if sigma_up > 0:\n            noise = noise_sampler(sigma_up, sigma_down)\n            x = x + sigma_up * noise\n        if callback is not None:\n            callback(x, sigma, denoised, i, s_noise)\n    if s_noise > 0:\n        x = x + s_noise * noise_sampler(s_noise, 0)\n    return x\n\n", "CodeBleu_score": 37.607596888336545}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if not noise_sampler:\n        noise_sampler = default_noise_sampler\n    if not extra_args:\n        extra_args = {}\n    if not disable:\n        disable = []\n    # Initialize the input and the noise\n    x_ = x\n    sigma_ = sigmas[0]\n    sigma_next = sigmas[1]\n    # Add noise if required\n    if s_noise:\n        x_ = x_ + noise_sampler(sigma_, sigma_next)\n    # Iterate over the sigmas\n    for sigma in sigmas[1:]:\n        # Denoise the input\n        x_ = model(x_, **extra_args)\n        # Calculate the ancestral step\n        sigma_down, sigma_up = get_ancestral_step(sigma_, sigma, eta)\n        # Update the input\n        x_ = x_ + sigma_down * to_d(x_, sigma_, x_) + sigma_up * noise_sampler(sigma_, sigma_next)\n        # Add noise if required\n        if s_noise:\n            x_ = x_ + noise_sampler(sigma_, sigma_next)\n        # Call the callback function\n        if callback and sigma not in disable:\n            callback(x_, sigma)\n    return x_\n\n", "CodeBleu_score": 29.170075225464643}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if disable is None:\n        disable = []\n    if callback is None:\n        callback = lambda x, sigma, denoised: None\n    x = x.clone()\n    for sigma in sigmas:\n        if sigma == 0:\n            continue\n        sigma_down, sigma_up = get_ancestral_step(sigma, sigma, eta=eta)\n        if sigma_up:\n            sigma_up = sigma_up.to(x.device)\n        if sigma_down:\n            sigma_down = sigma_down.to(x.device)\n        if sigma_down:\n            x = x + sigma_down * to_d(x, sigma_down, model(x, **extra_args))\n        if sigma_up:\n            x = x + sigma_up * to_d(x, sigma_up, model(x, **extra_args))\n        if s_noise:\n            x = x + s_noise * noise_sampler(sigma, sigma_next=sigma_up)\n        if sigma_down:\n            x = x + sigma_down * to_d(x, sigma_down, model(x, **extra_args))\n        if sigma_up:\n            x = x + sigma_up * to_d(x, sigma_up, model(x, **extra_args))\n        callback(x, sigma, model(x, **extra_args))\n    return x\n\n", "CodeBleu_score": 31.440172570074814}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product(i, j):\n        if i == j:\n            return 1\n        else:\n            return (t[j] - t[i])/(t[j] - t[i-1])\n    if order < i:\n        raise ValueError(\"Order is too high for the index.\")\n    elif order == i:\n        return product(i, j)\n    else:\n        return product(i, j) * linear_multistep_coeff(order - 1, t, i, j)\n\n", "CodeBleu_score": 27.066501079462}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    if order > 2:\n        raise ValueError(\"order must be 1 or 2\")\n    if order == 2:\n        if i > j:\n            raise ValueError(\"i must be less than or equal to j\")\n        if i == j:\n            return 0\n        else:\n            def product_term(k):\n                return linear_multistep_coeff(order, t, i, k) * linear_multistep_coeff(order, t, k, j)\n            return quad(product_term, i, j + 1)[0]\n    else:\n        if i > j:\n            raise ValueError(\"i must be less than or equal to j\")\n        if i == j:\n            return 0\n        else:\n            return (t[j] - t[i]) / (t[j] - t[i - 1])\n\n", "CodeBleu_score": 23.041942372588377}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product_term(k):\n        return (k+1)**order * (t[i+1] - t[i]) / (k+1)**order\n    return integrate(product_term, (k, i+1, j-1))\n\n\n\n\n", "CodeBleu_score": 11.235977397565206}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n    for sigma, sigma_next in zip(sigmas[:-1], sigmas[1:]):\n        x = model(x, **extra_args)\n        if sigma > 0:\n            noise = noise_sampler(sigma, sigma_next)\n            x = x + noise * sigma\n        if callback is not None:\n            callback(x, sigma)\n    return x\n\n", "CodeBleu_score": 28.78030074214105}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if callback is None:\n        callback = lambda i, x, sigma, sigma_next, noise_scaling, x_next: None\n    if disable is None:\n        disable = []\n    disable = disable + [\"noise_scaling\"]\n    x_next = x\n    for i, sigma in enumerate(sigmas):\n        if i == 0:\n            x_next = model(x, **extra_args)\n        else:\n            noise_scaling = sigmas[i - 1] / sigmas[i]\n            if noise_scaling > 0:\n                noise_scaling = noise_scaling ** (1 / (len(sigmas) - 1))\n            x_next = model(x_next, **extra_args)\n            x_next = x_next + noise_scaling * noise_sampler(x_next, x_next)\n        callback(i, x, sigma, sigmas[i + 1] if i < len(sigmas) - 1 else 0, noise_scaling, x_next)\n    return x_next\n\n", "CodeBleu_score": 35.6426059976199}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler\n    if disable is None:\n        disable = []\n    if callback is None:\n        callback = lambda x, sigma: None\n    x_ = x\n    for sigma in sigmas:\n        if sigma == 0:\n            continue\n        if sigma > 0:\n            x_ = x_.detach()\n        if sigma not in disable:\n            if sigma not in extra_args:\n                extra_args[sigma] = {}\n            x_ = model(x_, **extra_args[sigma])\n            if sigma > 0:\n                x_ = x_ + noise_scaling * noise_sampler(x_, sigma, sigma_next=sigmas[sigmas.index(sigma) + 1])\n        callback(x_, sigma)\n    return x_\n\n", "CodeBleu_score": 30.3529105900747}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t    if x.ndimension() < target_dims:\n        n_dims_to_append = target_dims - x.ndimension()\n        x = x.expand(x.shape + (n_dims_to_append,))\n    return x.detach() if x.device.type =='mps' else x\n", "CodeBleu_score": 35.20228351190479}, {"code": "def append_dims(x, target_dims)\n\t    if x.ndim < len(target_dims):\n        raise ValueError(f\"The target dimensions {target_dims} are less than the current dimensions {x.ndim}.\")\n    if x.ndim == len(target_dims):\n        return x\n    else:\n        new_dims = target_dims[x.ndim:]\n        return x.expand(new_dims)\n\n", "CodeBleu_score": 28.72348028669186}, {"code": "def append_dims(x, target_dims)\n\t    if x.ndim < target_dims:\n        raise ValueError(f\"The target dimensions are less than the current dimensions. Current dimensions: {x.ndim}, Target dimensions: {target_dims}\")\n    if x.device.type =='mps':\n        return x.expand(x.shape + tuple(1 for _ in range(target_dims - x.ndim)))\n    else:\n        return x.expand(x.shape + tuple(1 for _ in range(target_dims - x.ndim)))\n", "CodeBleu_score": 27.031476087624235}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists():\n        path.parent.mkdir(parents=True, exist_ok=True)\n        with urlopen(url) as response, open(path, 'wb') as file:\n            shutil.copyfileobj(response, file)\n    if digest:\n        with open(path, 'rb') as file:\n            hash = hashlib.sha256(file.read()).hexdigest()\n        if hash!= digest:\n            raise OSError(f\"Downloaded file {path} has incorrect hash. Expected {digest}, got {hash}\")\n    return path\n\n", "CodeBleu_score": 54.42530184667525}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists(path):\n        path.mkdir(parents=True, exist_ok=True)\n        with urlopen(url) as response, path.open('wb') as file:\n            shutil.copyfileobj(response, file)\n    if digest is not None:\n        with path.open('rb') as file:\n            hash = hashlib.sha256()\n            while True:\n                data = file.read(1024)\n                if not data:\n                    break\n                hash.update(data)\n            if hash.hexdigest()!= digest:\n                raise OSError(f'File {path} does not match expected hash {digest}')\n    return path\n", "CodeBleu_score": 38.375143216253505}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not path.exists(path):\n        path.mkdir(parents=True, exist_ok=True)\n    file_path = path / url.split('/')[-1]\n    if not file_path.exists():\n        with urlopen(url) as response, file_path.open('wb') as file:\n            shutil.copyfileobj(response, file)\n    if digest:\n        with file_path.open('rb') as file:\n            hash = hashlib.sha256()\n            hash.update(file.read())\n            if hash.hexdigest()!= digest:\n                raise OSError('File hash mismatch')\n    return file_path\n", "CodeBleu_score": 41.617914163282975}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    original_modes = []\n    for module in model.modules():\n        original_modes.append(module.training)\n        module.train(mode)\n    return original_modes\n\n", "CodeBleu_score": 29.092397719482545}, {"code": "def train_mode(model, mode=True)\n\t\n    model.train(mode)\n    return model\n\n", "CodeBleu_score": 3.5228876052714493}, {"code": "def train_mode(model, mode=True)\n\t\n    model.train(mode)\n    return model\n\n", "CodeBleu_score": 3.5228876052714493}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    for p_name, p_param in model.named_parameters():\n        if p_param.requires_grad:\n            averaged_param = averaged_model.state_dict()[p_name]\n            averaged_param.copy_(averaged_param * decay + (1 - decay) * p_param.data)\n    for p_name, p_buffer in model.named_buffers():\n        averaged_buffer = averaged_model.state_dict()[p_name]\n        averaged_buffer.copy_(averaged_buffer * decay + (1 - decay) * p_buffer.data)\n    return averaged_model\n", "CodeBleu_score": 35.79433219511714}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    for p_averaged, p_current in zip(averaged_model.parameters(), model.parameters()):\n        p_averaged.data.mul_(decay).add_(1 - decay, p_current.data)\n    for p_averaged, p_current in zip(averaged_model.buffers(), model.buffers()):\n        p_averaged.data.copy_(p_current.data)\n", "CodeBleu_score": 26.533281585419278}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    for p_model, p_averaged in zip(model.parameters(), averaged_model.parameters()):\n        p_averaged.data.mul_(decay).add_(1 - decay, p_model.data)\n    for p_model, p_averaged in zip(model.buffers(), averaged_model.buffers()):\n        p_averaged.data.mul_(decay).add_(1 - decay, p_model.data)\n    return averaged_model\n\n", "CodeBleu_score": 28.651621596293563}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    log_logistic = torch.log(torch.log(max_value / min_value) * (u ** (1 / scale) - 1) + 1)\n    log_logistic = (log_logistic - log_logistic.min()) / (log_logistic.max() - log_logistic.min())\n    log_logistic = (log_logistic * (max_value - min_value) + min_value).logit()\n    log_logistic = torch.exp(log_logistic)\n    return log_logistic\n\n", "CodeBleu_score": 39.67229875290313}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.as_tensor(max_value, device=device, dtype=dtype)\n    cdf_min = torch.log(min_value / scale) - loc\n    cdf_max = torch.log(max_value / scale) - loc\n    u = torch.rand(shape, device=device, dtype=dtype)\n    return torch.exp(cdf_min + torch.log(u / (1 - u)) * (cdf_max - cdf_min))\n\n", "CodeBleu_score": 38.75096535406764}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.as_tensor(min_value, dtype=dtype, device=device)\n    max_value = torch.as_tensor(max_value, dtype=dtype, device=device)\n    u = torch.rand(shape, dtype=dtype, device=device)\n    div = torch.div(max_value - min_value, torch.exp(loc) - 1)\n    exp = torch.exp(div * torch.log(u))\n    u = torch.log(exp - 1 + torch.exp(loc))\n    return u.mul(div).add(min_value)\n", "CodeBleu_score": 32.949469107945376}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU()\n    if activation == \"snake\":\n        return SnakeBeta(channels=channels)\n    if activation == \"none\":\n        return Identity()\n    raise ValueError(f\"Unknown activation type {activation}\")\n\n", "CodeBleu_score": 36.893607081759754}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if antialias:\n        if activation == \"elu\":\n            return Activation1d(nn.ELU(inplace=True))\n        elif activation == \"snake\":\n            return Activation1d(SnakeBeta(channels=channels))\n        elif activation == \"none\":\n            return Identity()\n        else:\n            raise ValueError\n    else:\n        if activation == \"elu\":\n            return nn.ELU(inplace=True)\n        elif activation == \"snake\":\n            return SnakeBeta(channels=channels)\n        elif activation == \"none\":\n            return Identity()\n        else:\n            raise ValueError", "CodeBleu_score": 36.95043085508799}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return ELU()\n    if activation == \"snake\":\n        return SnakeBeta(channels=channels)\n    if activation == \"none\":\n        return Identity()\n    raise ValueError(f\"Invalid activation type: {activation}\")\n\n", "CodeBleu_score": 34.97225847245098}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    t = t.float() if t.dtype == torch.float16 else t\n    t_unrotated, freqs = t.chunk(2, dim = -1)\n    freqs = freqs.float() if freqs.dtype == torch.float16 else freqs\n    freqs = rearrange(freqs, '... (j d) ->... j d', j = 2)\n    freqs_sin, freqs_cos = freqs.unbind(dim = -2)\n    freqs_sin = rearrange(freqs_sin, '... j d ->... (j d)')\n    freqs_cos = rearrange(freqs_cos, '... j d ->... (j d)')\n    t_rotated = t_unrotated * (freqs_cos.unsqueeze(-2) + 1j * freqs_sin.unsqueeze(-2))\n    t_rotated = rearrange(t_rotated, '... (j d) ->... j d', j = 2)\n    return torch.cat((t_rotated, t_unrotated), dim = -1)\n\n", "CodeBleu_score": 30.787963459257362}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    t = t.to(torch.float32)\n    freqs = freqs.to(torch.float32)\n    t = rearrange(t, '... (j d) ->... j d', j = 2)\n    freqs = rearrange(freqs, 'j d -> (j d)')\n    t_unrotated, freqs_unrotated = t.unbind(dim = -2)\n    t_unrotated = t_unrotated * scale\n    t_unrotated = t_unrotated + freqs_unrotated\n    t_unrotated = rearrange(t_unrotated, '... j d ->... (j d)')\n    return torch.cat((t_unrotated, t), dim = -1)\n\n", "CodeBleu_score": 25.87065356905963}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float64:\n        freqs = freqs.float()\n    t_unrotated = rearrange(t, '... (j d) ->... j d', j = 2)\n    freqs = freqs * scale\n    freqs = rearrange(freqs, '... (j d) ->... j d', j = 2)\n    freqs = freqs.sin() + freqs.cos() * 1j\n    t_rotated = torch.cat((t_unrotated.real, t_unrotated.imag), dim = -1) * freqs\n    return torch.cat((t_rotated, t_unrotated), dim = -2)\n\n", "CodeBleu_score": 31.1636976905622}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    if dim == -1:\n        return self.codebook[idx]\n    else:\n        return self.codebook[idx].movedim(dim)\n", "CodeBleu_score": 30.49179837245764}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook.idx2vq(idx, dim)\n", "CodeBleu_score": 16.925384650152672}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.codebook.idx2vq(idx, dim=dim)\n", "CodeBleu_score": 17.69186662453662}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t   z_q_x, (vq_loss, commit_loss), indices = self.forward(x, get_losses=True)\n    if quantize:\n        return z_q_x, x, indices, (vq_loss, commit_loss)\n    return z_q_x, (vq_loss, commit_loss)\n\n", "CodeBleu_score": 26.30011546363129}, {"code": "def encode(self, x, quantize=False)\n\t   z_q_x, (vq_loss, commit_loss), indices = self.forward(x, get_losses=True)\n    if quantize:\n        return z_q_x, x, indices, (vq_loss, commit_loss)\n    return z_q_x\n\n", "CodeBleu_score": 26.201490530540116}, {"code": "def encode(self, x, quantize=False)\n\t   x = self.in_block(x)\n    for down_block in self.down_blocks:\n        x = down_block(x)\n    if quantize:\n        z_q_x, (vq_loss, commit_loss), indices = self.forward(x, get_losses=True)\n        return z_q_x, x, indices, vq_loss + commit_loss\n    return self.forward(x)\n\n", "CodeBleu_score": 35.54336061617245}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    with self.no_sync():\n        if self.is_master_weight():\n            self.store(self.parameters())\n        with contextlib.ExitStack() as stack:\n            if self.is_master_weight():\n                stack.enter_context(self.ema_switch())\n            if context is not None:\n                stack.enter_context(context)\n            return stack\n", "CodeBleu_score": 44.083096203903374}, {"code": "def ema_scope(self, context=None)\n\t\n    with self.ema_scope_context(context):\n        self.store(self.parameters())\n        self.copy_to(self)\n        self.restore(self.parameters())\n", "CodeBleu_score": 22.685647178031072}, {"code": "def ema_scope(self, context=None)\n\t\n    self.m_name2s_name = dict()\n    for name, param in self.named_parameters():\n        self.m_name2s_name[name] = param.name\n        param.name = name\n    self.shadow = dict()\n    for name, param in self.named_parameters():\n        if param.requires_grad:\n            self.shadow[name] = param.clone()\n    def __enter__(self):\n        self.store(self.parameters())\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        self.restore(self.parameters())\n    return __enter__\n", "CodeBleu_score": 33.28117596697665}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    assert not self.pre_only\n    x = self.proj(x)\n    x = self.proj_drop(x)\n    x = attn + x\n    x = self.norm2(x)\n    x = self.modulate(x, shift_mlp, scale_mlp)\n    x = self.gate_mlp(x)\n    return x\n", "CodeBleu_score": 47.9403491387632}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    assert not self.pre_only\n    x = self.proj(x)\n    x = self.proj_drop(x)\n    x = attn + x\n    x = self.norm1(x)\n    x = self.attn_drop(x)\n    x = self.attn_proj(x)\n    x = self.attn_proj_drop(x)\n    x = self.shift_drop(x)\n    shift = shift_mlp(x)\n    scale = scale_mlp(x)\n    x = modulate(x, shift, scale)\n    x = self.mlp(x)\n    x = self.mlp_drop(x)\n    x = self.norm2(x)\n    x = self.gate_drop(x)\n    x = gate_mlp(x)\n    return x\n\n", "CodeBleu_score": 42.733115531769315}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    assert not self.pre_only\n    x = self.proj(x)\n    x = self.proj_drop(x)\n    x = x + attn\n    x = self.norm1(x)\n    x = self.shift_mlp(x)\n    x = self.scale_mlp(x)\n    x = self.gate_mlp(x)\n    x = self.norm2(x)\n    return x\n\n", "CodeBleu_score": 48.64766344869802}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    context_block.pre_attention(context)\n    x_block.pre_attention(x)\n    context_block.post_attention(context)\n    x_block.post_attention(x)\n    return (context, x)\n\n", "CodeBleu_score": 4.971871538594893}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv = context_block.pre_attention(context)\n    q, k, v = split_qkv(qkv, c)\n    q = q.reshape(q.shape[0], q.shape[1], -1)\n    k = k.reshape(q.shape[0], q.shape[1], -1)\n    v = v.reshape(q.shape[0], q.shape[1], -1)\n    qkv = torch.cat((q, k, v), dim=-1)\n    qkv = optimized_attention(qkv, c)\n    q, k, v = split_qkv(qkv, c)\n    q = q.reshape(q.shape[0], q.shape[1], -1)\n    k = k.reshape(q.shape[0], q.shape[1], -1)\n    v = v.reshape(q.shape[0], q.shape[1], -1)\n    context = context_block.post_attention(context)\n    x = x_block.post_attention(x)\n    return context, x\n", "CodeBleu_score": 17.300178782786226}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    context_qkv = context_block.pre_attention(context)\n    x_qkv = x_block.pre_attention(x)\n    context_qkv = torch.cat([context_qkv[0], context_qkv[1], context_qkv[2]], dim=-1)\n    x_qkv = torch.cat([x_qkv[0], x_qkv[1], x_qkv[2]], dim=-1)\n    context_qkv, x_qkv = optimized_attention(context_qkv, c)\n    context = context_block.post_attention(context_qkv[0])\n    x = x_block.post_attention(x_qkv[0])\n    return context, x\n", "CodeBleu_score": 15.935461527470624}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    timesteps = timesteps.float()\n    log_timesteps = torch.log(timesteps + 1e-9)\n    embeddings = torch.cat([torch.cos(timesteps * (2 ** ((i // 2) - 1) / embedding_dim)), torch.sin(timesteps * (2 ** ((i // 2) - 1) / embedding_dim))], dim=-1) * math.sqrt(embedding_dim)\n    embeddings = embeddings * (embedding_dim ** (1 / 2)) / log_timesteps\n    if embedding_dim % 2 == 1:\n        embeddings = F.pad(embeddings, (0, 1))\n    return embeddings\n", "CodeBleu_score": 23.53704500873503}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    if timesteps.dim() > 1:\n        timesteps = timesteps.flatten()\n    pos_emb = torch.zeros(timesteps.shape[0], embedding_dim)\n    pos_emb[:, 0::2] = torch.sin(timesteps.float() * (2 ** (torch.arange(embedding_dim // 2, dtype=torch.float32)) / 10000))\n    pos_emb[:, 1::2] = torch.cos(timesteps.float() * (2 ** (torch.arange(embedding_dim // 2, dtype=torch.float32)) / 10000))\n    pos_emb = pos_emb * math.log(10000) / (embedding_dim // 2)\n    return torch.cat([pos_emb, torch.zeros(pos_emb.shape[0], embedding_dim - pos_emb.shape[1])], dim=1)\n", "CodeBleu_score": 32.4170905559687}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    timesteps = timesteps.float()\n    position_embeddings = torch.cat([torch.sin(timesteps), torch.cos(timesteps)], dim=-1)\n    position_embeddings = position_embeddings * math.log(10000.0 / (embedding_dim ** 0.5))\n    position_embeddings = position_embeddings.to(device)\n    return position_embeddings\n", "CodeBleu_score": 15.497246341394142}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n    r1 = torch.zeros_like(k, device=q.device)\n    scale = (int(q.shape[-1])**(-0.5))\n\n    mem_free_total = model_management.get_free_memory(q.device)\n\n    gb = 1024 ** 3\n    tensor_size = q.shape[0] * q.shape[1] * k.shape[2] * q.element_size()\n    modifier = 3 if q.element_size() == 2 else 2.5\n    mem_required = tensor_size * modifier\n    steps = 1\n\n    if mem_required > mem_free_total:\n        steps = 2**(math.ceil(math.log(mem_required / mem_free_total, 2)))\n\n    while True:\n        try:\n            slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n            for i in range(0, q.shape[1], slice_size):\n                end = i + slice_size\n                s1 = torch.bmm(q[:, i:end], k) * scale\n\n                s2 = torch.nn.functional.softmax(s1, dim=2).permute(0,2,1)\n                del s1\n\n                r1[:, :, i:end] = torch.bmm(v, s2)\n                del s2\n            break\n        except model_management.OOM_EXCEPTION as e:\n            model_management.soft_empty_cache(True)\n            steps *= 2\n            if steps > 128:\n                raise e\n            logging.warning(\"out of memory error, increasing steps and trying again {}\".format(steps))\n\n    return r1\n\n", "CodeBleu_score": 25.111281714646637}, {"code": "def pytorch_attention(q, k, v)\n\t\n    r1 = torch.zeros_like(k, device=q.device)\n    scale = (int(q.shape[-1])**(-0.5))\n\n    mem_free_total = model_management.get_free_memory(q.device)\n\n    gb = 1024 ** 3\n    tensor_size = q.shape[0] * q.shape[1] * k.shape[2] * q.element_size()\n    modifier = 3 if q.element_size() == 2 else 2.5\n    mem_required = tensor_size * modifier\n    steps = 1\n\n    if mem_required > mem_free_total:\n        steps = 2**(math.ceil(math.log(mem_required / mem_free_total, 2)))\n\n    while True:\n        try:\n            slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n            for i in range(0, q.shape[1], slice_size):\n                end = i + slice_size\n                s1 = torch.bmm(q[:, i:end], k) * scale\n\n                s2 = torch.nn.functional.softmax(s1, dim=2).permute(0,2,1)\n                del s1\n\n                r1[:, :, i:end] = torch.bmm(v, s2)\n                del s2\n            break\n        except model_management.OOM_EXCEPTION as e:\n            model_management.soft_empty_cache(True)\n            steps *= 2\n            if steps > 128:\n                raise e\n            logging.warning(\"out of memory error, increasing steps and trying again {}\".format(steps))\n\n    return r1\n\n", "CodeBleu_score": 25.111281714646637}, {"code": "def pytorch_attention(q, k, v)\n\t\n    r1 = torch.zeros_like(k, device=q.device)\n    scale = (int(q.shape[-1])**(-0.5))\n\n    mem_free_total = model_management.get_free_memory(q.device)\n\n    gb = 1024 ** 3\n    tensor_size = q.shape[0] * q.shape[1] * k.shape[2] * q.element_size()\n    modifier = 3 if q.element_size() == 2 else 2.5\n    mem_required = tensor_size * modifier\n    steps = 1\n\n    if mem_required > mem_free_total:\n        steps = 2**(math.ceil(math.log(mem_required / mem_free_total, 2)))\n\n    while True:\n        try:\n            slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n            for i in range(0, q.shape[1], slice_size):\n                end = i + slice_size\n                s1 = torch.bmm(q[:, i:end], k) * scale\n\n                s2 = torch.nn.functional.softmax(s1, dim=2).permute(0,2,1)\n                del s1\n\n                r1[:, :, i:end] = torch.bmm(v, s2)\n                del s2\n            break\n        except model_management.OOM_EXCEPTION as e:\n            model_management.soft_empty_cache(True)\n            steps *= 2\n            if steps > 128:\n                raise e\n            logging.warning(\"out of memory error, increasing steps and trying again {}\".format(steps))\n\n    return r1", "CodeBleu_score": 25.111281714646637}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if name in control:\n            control.pop(name)\n            try:\n                h.add_control(control[name])\n            except:\n                logging.warning('Could not add control'+ name +'to'+ h.name)\n    return h\n\n\n\n\n", "CodeBleu_score": 34.74802994294315}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        try:\n            h.add_control(control, name)\n        except:\n            logging.warning(\"Failed to apply control %s to %s.\" % (name, h))\n    return h\n\n\n\n\n", "CodeBleu_score": 21.98125577551142}, {"code": "def apply_control(h, control, name)\n\t\n    if name in control:\n        control_value = control.pop(name)\n        try:\n            h.add_control(control_value)\n        except ValueError:\n            logging.warning(\"Could not add control %s to %s\" % (name, h))\n    return h\n", "CodeBleu_score": 33.3421520927618}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    one_hot = self.one_hot(indices, shape)\n    return torch.matmul(one_hot, self.embedding.weight.permute(1, 0))\n", "CodeBleu_score": 6.186620002033635}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    one_hot = torch.zeros(shape).to(self.device)\n    one_hot.scatter_(1, indices.view(-1, 1), 1)\n    quantized = torch.matmul(one_hot, self.embedding.weight.data)\n    if shape is not None:\n        quantized = quantized.view(*shape)\n    return quantized\n", "CodeBleu_score": 33.07408415694643}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # Create one-hot encoding of indices\n    one_hot = torch.zeros(indices.shape[0], self.num_embeddings, device=self.device)\n    one_hot.scatter_(1, indices.unsqueeze(1), 1)\n    # Multiply one-hot encoding with embedding weights\n    quantized_vectors = one_hot @ self.embedding_weights\n    # Reshape and permute quantized vectors\n    if shape is not None:\n        quantized_vectors = quantized_vectors.view(*shape).permute(1, 0, 2)\n    return quantized_vectors\n", "CodeBleu_score": 33.294477697338394}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    self.noise = []\n    self.noise.append(torch.randn(4, 4).to(self.device))\n    for i in range(3, self.log_size + 1):\n        self.noise.append(torch.randn(2 ** i, 2 ** i).to(self.device))\n    return self.noise\n\n", "CodeBleu_score": 32.016240449273084}, {"code": "def make_noise(self)\n\t\n    noise = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, self.log_size + 1):\n        noise.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noise\n", "CodeBleu_score": 29.43234279200515}, {"code": "def make_noise(self)\n\t\n    log_size = int(math.log(self.image_size, 2))\n    noise_list = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, log_size + 1):\n        noise_list.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noise_list\n", "CodeBleu_score": 29.209551933302546}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    latent_inputs = torch.randn(num_latent, self.latent_size)\n    latent_inputs = self.style_mlp(latent_inputs)\n    return latent_inputs.mean(0)\n", "CodeBleu_score": 19.456815609106364}, {"code": "def mean_latent(self, num_latent)\n\t\n    z = torch.randn(num_latent, self.latent_dim)\n    z = self.style_mlp(z)\n    return z.mean(0)\n\n", "CodeBleu_score": 12.613673031678404}, {"code": "def mean_latent(self, num_latent)\n\t\n    latent_inputs = torch.randn(num_latent, self.latent_dim)\n    latent_inputs = self.style_mlp(latent_inputs)\n    return latent_inputs.mean(0)\n\n", "CodeBleu_score": 19.41846565131618}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    jittered_img = img.copy()\n    for i in range(3):\n        jittered_img[..., i] = np.clip(img[..., i] + np.random.uniform(-shift, shift), 0, 1)\n    return jittered_img\n\n", "CodeBleu_score": 39.53832117216638}, {"code": "def color_jitter(img, shift)\n\t\n    img = img.astype(np.float32)\n    for i in range(3):\n        img[:, :, i] = np.clip(img[:, :, i] + np.random.uniform(-shift, shift), 0, 1)\n    return img.astype(np.uint8)\n\n", "CodeBleu_score": 42.255202398425936}, {"code": "def color_jitter(img, shift)\n\t\n    jitter = torch.zeros_like(img)\n    for i in range(3):\n        jitter[:, i, :, :] = torch.clamp(img[:, i, :, :] + torch.rand(1) * shift, 0, 1)\n    return jitter\n\n", "CodeBleu_score": 32.3777002139204}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    if self.device == 'cpu':\n        self.lq = data['lq'].to(self.device)\n        if 'gt' in data:\n            self.gt = data['gt'].to(self.device)\n        if 'eyes' in data:\n            self.eyes = data['eyes'].to(self.device)\n        if'mouth' in data:\n            self.mouth = data['mouth'].to(self.device)\n        if 'landmarks' in data:\n            self.landmarks = data['landmarks'].to(self.device)\n    else:\n        self.lq = data['lq'].cuda()\n        if 'gt' in data:\n            self.gt = data['gt'].cuda()\n        if 'eyes' in data:\n            self.eyes = data['eyes'].cuda()\n        if'mouth' in data:\n            self.mouth = data['mouth'].cuda()\n        if 'landmarks' in data:\n            self.landmarks = data['landmarks'].cuda()\n\n", "CodeBleu_score": 47.71853602354406}, {"code": "def feed_data(self, data)\n\t\n    if self.device == 'cpu':\n        self.lq = data['lq'].to(self.device)\n        if 'gt' in data:\n            self.gt = data['gt'].to(self.device)\n    elif self.device == 'gpu':\n        self.lq = data['lq'].cuda()\n        if 'gt' in data:\n            self.gt = data['gt'].cuda()\n    if 'eyes' in data:\n        self.eyes = data['eyes'].to(self.device)\n    if'mouth' in data:\n        self.mouth = data['mouth'].to(self.device)\n    if 'eyebrow' in data:\n        self.eyebrow = data['eyebrow'].to(self.device)\n\n", "CodeBleu_score": 51.32990452328065}, {"code": "def feed_data(self, data)\n\t\n    if self.device == 'cpu':\n        self.lq = data['lq'].to(self.device)\n        if 'gt' in data:\n            self.gt = data['gt'].to(self.device)\n    elif self.device == 'cuda':\n        self.lq = data['lq'].cuda()\n        if 'gt' in data:\n            self.gt = data['gt'].cuda()\n    if 'eyes' in data:\n        self.eyes = data['eyes']\n    if'mouth' in data:\n        self.mouth = data['mouth']\n\n", "CodeBleu_score": 56.957478781024676}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.img_gt]\n    for i in range(self.num_scales - 1):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=2))\n    return img_pyramid\n\n", "CodeBleu_score": 17.46149798755563}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.gt_img]\n    for i in range(self.num_of_scales - 1):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=0.5, mode='bilinear'))\n    return img_pyramid\n", "CodeBleu_score": 22.390189797798737}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.gt]\n    for i in range(self.num_scales):\n        img_pyramid.insert(0, F.interpolate(img_pyramid[0], scale_factor=2, mode='bilinear', align_corners=False))\n    return img_pyramid\n\n", "CodeBleu_score": 24.24911722819234}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    save_network(self.G, self.G_ema, epoch, current_iter, self.opt.save_dir, self.opt.gpu_ids)\n    save_network(self.D, epoch, current_iter, self.opt.save_dir, self.opt.gpu_ids)\n    if self.opt.use_face_discriminator:\n        save_network(self.D_left, epoch, current_iter, self.opt.save_dir, self.opt.gpu_ids)\n        save_network(self.D_right, epoch, current_iter, self.opt.save_dir, self.opt.gpu_ids)\n        save_network(self.D_mouth, epoch, current_iter, self.opt.save_dir, self.opt.gpu_ids)\n    save_training_state(epoch, current_iter, self.opt.save_dir)\n\n", "CodeBleu_score": 31.03111543035836}, {"code": "def save(self, epoch, current_iter)\n\t\n    # Save the generator network\n    self.save_network(self.G, 'G', epoch, current_iter)\n    # Save the EMA generator network\n    self.save_network(self.G_ema, 'G_ema', epoch, current_iter)\n    # Save the discriminator network\n    self.save_network(self.D, 'D', epoch, current_iter)\n    # Save the facial discriminator networks\n    if self.use_facial_discriminator:\n        self.save_network(self.D_A, 'D_A', epoch, current_iter)\n        self.save_network(self.D_B, 'D_B', epoch, current_iter)\n        self.save_network(self.D_C, 'D_C', epoch, current_iter)\n    # Save the training state\n    self.save_training_state(epoch, current_iter)\n", "CodeBleu_score": 53.32407185968437}, {"code": "def save(self, epoch, current_iter)\n\t\n    print(\"Saving model at epoch %d, iteration %d\" % (epoch, current_iter))\n    save_path = self.save_path\n    if not os.path.isdir(save_path):\n        os.makedirs(save_path)\n    save_network(self.G, save_path + \"/G.pth\", epoch, current_iter)\n    save_network(self.G_ema, save_path + \"/G_ema.pth\", epoch, current_iter)\n    save_network(self.D, save_path + \"/D.pth\", epoch, current_iter)\n    if self.use_facial_discriminator:\n        save_network(self.D_left_eye, save_path + \"/D_left_eye.pth\", epoch, current_iter)\n        save_network(self.D_right_eye, save_path + \"/D_right_eye.pth\", epoch, current_iter)\n        save_network(self.D_mouth, save_path + \"/D_mouth.pth\", epoch, current_iter)\n    save_training_state(self.training_state, save_path + \"/training_state.pth\")\n", "CodeBleu_score": 44.298743703590475}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        if os.path.isfile(item_path):\n            try:\n                os.unlink(item_path)\n            except Exception as e:\n                print('Error deleting file {}: {}'.format(item_path, e))\n        elif os.path.isdir(item_path):\n            try:\n                shutil.rmtree(item_path)\n            except Exception as e:\n                print('Error deleting directory {}: {}'.format(item_path, e))\n", "CodeBleu_score": 41.33916149770471}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        if os.path.isfile(item_path):\n            try:\n                os.unlink(item_path)\n            except Exception as e:\n                print(\"Error: Could not delete file {}. Reason: {}\".format(item_path, e))\n        elif os.path.isdir(item_path):\n            try:\n                shutil.rmtree(item_path)\n            except Exception as e:\n                print(\"Error: Could not delete directory {}. Reason: {}\".format(item_path, e))\n", "CodeBleu_score": 40.804788919378716}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        if isfile(item_path):\n            try:\n                os.unlink(item_path)\n            except:\n                print(f\"Error deleting file {item_path}\")\n        elif isdir(item_path):\n            try:\n                shutil.rmtree(item_path)\n            except:\n                print(f\"Error deleting directory {item_path}\")\n", "CodeBleu_score": 36.10568047670207}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    if len(self.exp_list) < sample_size:\n        sample_size = len(self.exp_list)\n    batch = random.sample(self.exp_list, sample_size)\n    for exp in batch:\n        self.exp_list.remove(exp)\n    return batch\n", "CodeBleu_score": 44.205699694056236}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if self.sample_size >= sample_size:\n        batch = random.sample(self.memory, sample_size)\n        self.memory = [i for i in self.memory if i not in batch]\n        self.sample_size -= sample_size\n    else:\n        batch = random.sample(self.memory, self.sample_size)\n        self.memory = [i for i in self.memory if i not in batch]\n        self.sample_size -= self.sample_size\n    return batch\n\n", "CodeBleu_score": 41.63309863861511}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.experiences):\n        sample_size = len(self.experiences)\n    indices = np.random.randint(low=0, high=len(self.experiences), size=sample_size)\n    batch = [self.experiences[index] for index in indices]\n    for index in indices:\n        self.experiences.pop(index)\n    return batch\n\n", "CodeBleu_score": 45.090456728352045}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    if self.all_configs is None:\n        return None\n    if self.metric not in self.cost_model.metrics:\n        raise ValueError(\n            \"The metric {} is not supported by the cost model {}. \".format(\n                self.metric, self.cost_model\n            )\n            + \"Supported metrics are: {}\".format(self.cost_model.metrics)\n        )\n    if self.metric == \"cost\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"runtime\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"power\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"energy\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"throughput\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"latency\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"accuracy\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"performance\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_size\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_complexity\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_latency\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_accuracy\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_throughput\":\n        return np.argsort(self.cost_model.predict(self.all_configs))\n    if self.metric == \"model_power\":\n        return np.argsort(self.cost_model.predict(self.all", "CodeBleu_score": 12.075826870272383}, {"code": "def find_estimated_top_configs(self)\n\t\n    # Flatten all configurations\n    flattened_ds_config = dict()\n    for key, val in self.all_configs.items():\n        flattened_ds_config[key] = [item for sublist in val for item in sublist]\n    # Collect numerical values\n    feature_val = []\n    for key, val in flattened_ds_config.items():\n        feature_val.append(val)\n    # Convert into numpy array\n    feature_val = np.array(feature_val)\n    # Predict the cost model\n    cost_model_pred = self.cost_model.predict(feature_val)\n    # Sort the predictions\n    sort_idx = np.argsort(cost_model_pred)\n    # Return the indices of the top configurations\n    return sort_idx\n", "CodeBleu_score": 34.979284096250005}, {"code": "def find_estimated_top_configs(self)\n\t\n    # Flatten each configuration in all_configs\n    flattened_ds_config = {}\n    for ds_config in self.all_configs:\n        for key, value in ds_config.items():\n            if isinstance(value, list):\n                for val in value:\n                    flattened_ds_config[key + '_' + str(val)] = ds_config[key]\n            else:\n                flattened_ds_config[key] = ds_config[key]\n\n    # Collect numerical values\n    feature_val = []\n    for key, value in flattened_ds_config.items():\n        if key in self.config_dict.keys():\n            feature_val.append(value)\n\n    # Convert into numpy array\n    feature_val = np.array(feature_val)\n\n    # Predict cost\n    cost = self.cost_model.predict(feature_val)\n\n    # Sort the predictions\n    cost_idx = np.argsort(cost)\n\n    # Return the indices of the top configurations\n    return cost_idx\n\n\n\n\n", "CodeBleu_score": 39.34804497161072}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(\"Executing command: {}\".format(self.optimal_cmd))\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info(\"Command finished successfully\")\n    else:\n        logger.info(\"No optimal command found\")\n", "CodeBleu_score": 53.134735486582386}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info(\"Running optimal command\")\n        result = subprocess.Popen(self.optimal_cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        result.wait()\n        if result.returncode == 0:\n            logger.info(\"Command completed successfully\")\n        else:\n            logger.info(\"Command failed\")\n            logger.info(\"Command output: {}\".format(result.stdout.read()))\n            logger.info(\"Command error: {}\".format(result.stderr.read()))\n    else:\n        logger.info(\"No optimal command found\")\n\n\n\n", "CodeBleu_score": 45.1713194456105}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        logger.info('Running optimal command: %s' % self.optimal_cmd)\n        result = subprocess.Popen(self.optimal_cmd, shell=True)\n        result.wait()\n        logger.info('Finished running optimal command.')\n    else:\n        logger.info('No optimal command found.')\n", "CodeBleu_score": 52.85326981261992}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.logger.info('Starting experiment: %s', exp)\n    self.master_port = self.get_free_port()\n    self.result_dir = self.get_result_dir()\n    user_args = self.get_user_args(exp)\n    self.logger.info('Running experiment with arguments: %s', user_args)\n    thread = threading.Thread(target=self.run_experiment, args=(exp, user_args, reservations))\n    thread.start()\n    self.running_experiments[exp['id']] = {\n        'thread': thread,\n       'start_time': time.time(),\n        'exp': exp,\n        'user_args': user_args\n    }\n    self.logger.info('Experiment started: %s', exp)\n", "CodeBleu_score": 23.90999055471421}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    master_port = self.get_master_port()\n    result_dir = self.get_result_dir()\n    user_args = self.get_user_args(exp)\n    self.update_user_args(user_args, reservations)\n    self.set_user_args(user_args)\n    self.set_master_port(master_port)\n    self.set_result_dir(result_dir)\n    self.set_user_args(user_args)\n    t = threading.Thread(target=self.run_experiment, args=(exp['script'], user_args))\n    t.start()\n    self.running_experiments[exp['name']] = t\n    return t\n", "CodeBleu_score": 19.651706936180798}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    exp_id = exp[\"id\"]\n    exp_name = exp[\"name\"]\n    exp_script = exp[\"script\"]\n    exp_args = exp[\"args\"]\n    exp_master_port = self.get_master_port()\n    exp_result_dir = self.get_result_dir()\n    user_args = self.get_user_args(exp_args)\n    exp_args = self.get_exp_args(exp_args, user_args)\n    exp_args = self.get_exp_args(exp_args, reservations)\n    exp_args = self.get_exp_args(exp_args, self.get_user_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(exp_args, self.get_exp_args())\n    exp_args = self.get_exp_args(exp_args, self.get_default_args())\n    exp_args = self.get_exp_args(", "CodeBleu_score": 12.04089999242974}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        if ranks is not None:\n            if dist.get_rank() in ranks:\n                self.logger.debug(message)\n                if path is not None:\n                    with open(path, \"a\") as outfile:\n                        json.dump(message, outfile)\n                        outfile.write(\"", "CodeBleu_score": 27.903435266534064}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        if ranks is None:\n            ranks = [dist.get_rank()]\n        else:\n            ranks = ranks\n        if self.log_to_database:\n            for rank in ranks:\n                message[\"rank\"] = rank\n                with open(path, \"a\") as outfile:\n                    json.dump(message, outfile)\n                    outfile.write(\"", "CodeBleu_score": 31.878555605821095}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if dist.is_initialized():\n        if ranks is None:\n            ranks = [dist.get_rank()]\n        else:\n            ranks = ranks\n        for rank in ranks:\n            message['rank'] = rank\n            if path is None:\n                path = self.config.get('exp_results_path')\n            if path is not None:\n                if not os.path.exists(path):\n                    os.makedirs(path)\n                outfile = open(os.path.join(path, 'exp_results.json'), 'a')\n                json.dump(message, outfile)\n                outfile.write('", "CodeBleu_score": 30.847496168339774}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self.layer_files[layer_index]:\n        return {}\n    if layer_index < 0 or layer_index >= len(self.layer_files):\n        raise ValueError(f\"Layer index {layer_index} is out of bounds.\")\n    layer_files = self.layer_files[layer_index]\n    tp_other_layer_map = {}\n    for layer_file in layer_files:\n        partition_index = layer_file.partition_index\n        if partition_index not in tp_other_layer_map:\n            tp_other_layer_map[partition_index] = []\n        tp_other_layer_map[partition_index].append(layer_file)\n    return tp_other_layer_map\n", "CodeBleu_score": 33.126905569323135}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    layer_files = self._get_layer_files(layer_index)\n    if not layer_files:\n        raise ValueError(f\"No layer files found for layer index {layer_index}.\")\n    if layer_index < 0 or layer_index >= self.num_layers:\n        raise ValueError(f\"Layer index {layer_index} is out of range [0, {self.num_layers}).\")\n    tp_other_layer_map = {}\n    for layer_file in layer_files:\n        partition_indices = self._get_partition_indices_from_file(layer_file)\n        for partition_index in partition_indices:\n            if partition_index not in tp_other_layer_map:\n                tp_other_layer_map[partition_index] = []\n            tp_other_layer_map[partition_index].append(layer_file)\n    return tp_other_layer_map\n\n", "CodeBleu_score": 25.348055026609167}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self._layer_files_exist(layer_index):\n        raise ValueError(f\"Layer {layer_index} does not exist.\")\n    if layer_index not in self._layer_map:\n        self._layer_map[layer_index] = {}\n        self._layer_map[layer_index][\"files\"] = self._get_files_with_prefix(layer_index)\n        self._layer_map[layer_index][\"partitions\"] = self._partition_data(self._layer_map[layer_index][\"files\"])\n    return self._layer_map[layer_index]\n", "CodeBleu_score": 29.033317696344348}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    return {\n        \"OS\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version()\n    }\n", "CodeBleu_score": 75.14062228572467}, {"code": "def system_info()\n\t\n    return {\n        \"Operating System\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version(),\n    }\n\n", "CodeBleu_score": 69.65854801721277}, {"code": "def system_info()\n\t\n    return {\n        'OS': platform.system(),\n        'Architecture': platform.architecture(),\n        'Version': platform.version(),\n        'Processor': platform.processor(),\n        'Python Version': platform.python_version()\n    }\n", "CodeBleu_score": 68.7182115062614}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    device_count = torch.cuda.device_count()\n    device_name = torch.cuda.get_device_name(0)\n    is_available = torch.cuda.is_available()\n    range = torch.cuda.range(0, device_count)\n    return device_count, device_name, is_available, range", "CodeBleu_score": 29.420526165038368}, {"code": "def cuda_info()\n\t\n    print(\"CUDA Information\")\n    print(\"=================\")\n    print(\"Device names: \", get_device_name())\n    print(\"Device count: \", device_count())\n    print(\"Is available: \", is_available())\n    print(\"CUDA version: \", cuda_version())", "CodeBleu_score": 19.814157202734144}, {"code": "def cuda_info()\n\t\n    print(\"CUDA Info:\")\n    print(\"Device Name: \", get_device_name())\n    print(\"Device Count: \", device_count())\n    print(\"CUDA is available: \", is_available())\n    print(\"CUDA Version: \", version())\n", "CodeBleu_score": 20.76826348909444}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_name_key = encoder_manager.class_name_key\n    class_id_to_name = encoder_manager.class_id_to_name\n    class_acc_dict = {}\n    for item in tqdm(dataset_items):\n        audio_file = item[0]\n        audio_file_name = os.path.basename(audio_file)\n        class_name = item[1]\n        class_id = item[2]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        embedding = embedding.cuda\n        if class_name_key is not None:\n            class_name = item[class_name_key]\n        if class_id_to_name is not None:\n            class_id = item[class_id_to_name]\n        if class_id is not None:\n            class_id = int(class_id)\n        if class_name is not None:\n            class_name = str(class_name)\n        if class_id is not None and class_id in class_acc_dict:\n            class_acc_dict[class_id] += 1\n        else:\n            class_acc_dict[class_id] = 1\n        if class_name is not None:\n            prediction = inference(embedding)\n            prediction_class_id = prediction[0]\n            prediction_class_name = prediction[1]\n            prediction_class_name = str(prediction_class_name)\n            if prediction_class_name == class_name:\n                if class_id is not None:\n                    class_acc_dict[class_id] += 1\n                else:\n                    class_acc_dict[class_name] += 1\n    for class_id, class_acc in class_acc_dict.items():\n        class_name = class_id_to_name[class_id]\n        print(f\"{class_name}: {class_acc} / {len(dataset_items)} = {class_acc / len(dataset_items):.2f}\")\n    print(f\"Average accuracy: {sum(class_acc_dict.values()) / len(dataset_items):.2f}\")", "CodeBleu_score": 35.69531514340177}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_acc_dict = {}\n    class_id_to_name_dict = encoder_manager.class_id_to_name_dict\n    class_name_to_id_dict = encoder_manager.class_name_to_id_dict\n    class_name_key = encoder_manager.class_name_key\n    for item in tqdm(dataset_items):\n        audio_file = item[0]\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if encoder_manager.class_name_key:\n            true_class_name = item[class_name_key]\n            predicted_class_name = encoder_manager.predict_class_name(embedding)\n            if true_class_name in class_acc_dict:\n                class_acc_dict[true_class_name] += 1\n            else:\n                class_acc_dict[true_class_name] = 1\n            if predicted_class_name == true_class_name:\n                if true_class_name in class_acc_dict:\n                    class_acc_dict[true_class_name] += 1\n                else:\n                    class_acc_dict[true_class_name] = 1\n            else:\n                if true_class_name in class_acc_dict:\n                    class_acc_dict[true_class_name] += 0\n                else:\n                    class_acc_dict[true_class_name] = 0\n        else:\n            true_class_id = item[1]\n            predicted_class_id = encoder_manager.predict_class_id(embedding)\n            if true_class_id in class_acc_dict:\n                class_acc_dict[true_class_id] += 1\n            else:\n                class_acc_dict[true_class_id] = 1\n            if predicted_class_id == true_class_id:\n                if true_class_id in class_acc_dict:\n                    class_acc_dict[true_class_id] += 1\n                else:\n                    class_acc_dict[true_class_id] = 1\n            else:\n                if true_class_id in class_acc_dict:\n                    class_acc_dict[true_class_id] += 0\n                else:\n                    class_acc_dict[true_class_", "CodeBleu_score": 25.634380810414125}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    class_acc_dict = {}\n    class_name_key = encoder_manager.config.get(\"class_name_key\", None)\n    class_id_to_name_map = encoder_manager.config.get(\"class_id_to_name_map\", None)\n    for item in tqdm(dataset_items):\n        audio_file = item[0]\n        class_name = item[1]\n        if class_name_key is not None:\n            class_name = item[class_name_key]\n        if class_id_to_name_map is not None:\n            class_name = class_id_to_name_map.get(class_name, class_name)\n        class_name = class_name.lower()\n        embedding = encoder_manager.compute_embedding_from_clip(audio_file)\n        if embedding is not None:\n            embedding = embedding.unsqueeze(0)\n            if encoder_manager.config.get(\"cuda\", False):\n                embedding = embedding.cuda()\n            prediction = inference(encoder_manager.model, embedding)\n            prediction = prediction.cpu().numpy()\n            prediction = np.argmax(prediction)\n            prediction = encoder_manager.id_to_class_name_map[prediction]\n            prediction = prediction.lower()\n            if prediction == class_name:\n                if class_name not in class_acc_dict:\n                    class_acc_dict[class_name] = 1\n                else:\n                    class_acc_dict[class_name] += 1\n    class_acc_dict = {class_name: acc / len(dataset_items) for class_name, acc in class_acc_dict.items()}\n    for class_name, acc in class_acc_dict.items():\n        print(\"Accuracy for class {}: {:.2f}%\".format(class_name, acc * 100))\n    print(\"Average accuracy: {:.2f}%\".format(sum(class_acc_dict.values()) / len(class_acc_dict) * 100))\n    return class_acc_dict", "CodeBleu_score": 42.77393991406967}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the output path\n    out_path = audio_path.replace(input_dir, output_dir)\n    out_path = pathlib.Path(out_path)\n\n    # if the output path already exists and force is not specified, return the output path and a False flag\n    if out_path.exists() and not force:\n        return out_path, False\n\n    # create the necessary directory structure\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # remove silence from the audio\n    out_path, is_speech = remove_silence(model_and_utils, audio_path, out_path, vad_sample_rate, trim_just_beginning_and_end, use_cuda)\n\n    return out_path, is_speech\n", "CodeBleu_score": 32.89014567782854}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the output path\n    out_path = pathlib.Path(audio_path).parent / pathlib.Path(audio_path).name\n    # check if the file already exists\n    if pathlib.Path(out_path).exists():\n        # if force is not specified, return the output path and a False flag\n        if not force:\n            return out_path, False\n        # if force is specified, remove the file\n        else:\n            pathlib.Path(out_path).unlink()\n    # create the necessary directory structure\n    pathlib.Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n    # remove silence from the audio\n    out_path, is_speech = remove_silence(model_and_utils, audio_path, out_path, vad_sample_rate, trim_just_beginning_and_end, use_cuda)\n    return out_path, is_speech\n\n", "CodeBleu_score": 36.23574127343707}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the output path\n    out_path = pathlib.Path(audio_path).with_suffix(\".wav\")\n\n    # check if the output path exists and if so, return the path and a False flag\n    if out_path.exists():\n        return out_path, False\n\n    # check if the output path's parent directory exists and if not, create it\n    out_path.parent.mkdir(parents=True, exist_ok=True)\n\n    # remove silence\n    out_path, is_speech = remove_silence(model_and_utils, audio_path, out_path, vad_sample_rate=8000, trim_just_beginning_and_end=True, use_cuda=False)\n\n    return out_path, is_speech\n\n", "CodeBleu_score": 32.759207879711994}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    if not os.path.exists(output_dir):\n        raise ValueError(f\"Output directory {output_dir} does not exist.\")\n    if not os.path.exists(input_dir):\n        raise ValueError(f\"Input directory {input_dir} does not exist.\")\n    if not file_ext.startswith(\".\"):\n        file_ext = f\".{file_ext}\"\n    if not os.path.exists(os.path.join(output_dir, \"resampled\")):\n        os.makedirs(os.path.join(output_dir, \"resampled\"))\n    if not os.path.exists(os.path.join(output_dir, \"failed\")):\n        os.makedirs(os.path.join(output_dir, \"failed\"))\n    input_files = glob.glob(os.path.join(input_dir, f\"**/*{file_ext}\"), recursive=True)\n    print(f\"Found {len(input_files)} files to resample.\")\n    pbar = tqdm(total=len(input_files))\n    with Pool(n_jobs) as p:\n        for i, _ in enumerate(p.imap_unordered(resample_file, input_files)):\n            pbar.update()\n    pbar.close()\n    print(f\"Resampling complete.\")\n\n", "CodeBleu_score": 46.45922624487182}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    input_files = glob.glob(os.path.join(input_dir, \"*.\" + file_ext))\n    p = Pool(n_jobs)\n    pbar = tqdm(total=len(input_files))\n    for i, input_file in enumerate(input_files):\n        input_file = os.path.abspath(input_file)\n        output_file = os.path.join(output_dir, os.path.basename(input_file))\n        output_file = os.path.splitext(output_file)[0] + \".wav\"\n        p.apply_async(resample_file, args=(input_file, output_file, output_sr))\n        pbar.update(1)\n    p.close()\n    p.join()\n    print(\"Resampling complete.\")\n    return output_dir\n", "CodeBleu_score": 40.973119521135196}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    else:\n        os.makedirs(output_dir, exist_ok=True)\n        copytree(input_dir, output_dir)\n    files = glob.glob(os.path.join(output_dir, f\"*.{file_ext}\"))\n    p = Pool(n_jobs)\n    with tqdm(total=len(files)) as pbar:\n        for i, _ in enumerate(p.imap_unordered(resample_file, enumerate(files))):\n            pbar.update()\n    print(f\"Completed resampling all audio files in {output_dir} to {output_sr} Hz.\")\n\n", "CodeBleu_score": 42.181089994366324}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    eval_acc = 0\n    eval_figures = []\n    eval_stats = {}\n    with torch.no_grad():\n        for inputs, labels in data_loader:\n            inputs = inputs.view(inputs.size(0), -1)\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n            eval_acc += (outputs.argmax(dim=1) == labels).sum().item()\n            eval_figures.append(\n                plot_embeddings(outputs.cpu().numpy(), num_classes_in_batch=10)\n            )\n        eval_loss /= len(data_loader)\n        eval_acc /= len(data_loader.dataset)\n        eval_stats[\"eval_loss\"] = eval_loss\n        eval_stats[\"eval_acc\"] = eval_acc\n        dashboard_logger.eval_stats = eval_stats\n        dashboard_logger.eval_figures = eval_figures\n    return eval_loss\n\n", "CodeBleu_score": 35.61369571442033}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0.0\n    eval_figures = []\n    with torch.no_grad():\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n            eval_figures.append(\n                plot_embeddings(outputs.cpu().numpy(), len(np.unique(labels.numpy())))\n            )\n            global_step += 1\n    eval_loss /= len(data_loader)\n    dashboard_logger.eval_stats(\n        global_step,\n        eval_loss,\n        np.mean(np.array(eval_figures).reshape(-1, 10, 28, 28), axis=1),\n    )\n    return global_step\n\n", "CodeBleu_score": 26.93596030979496}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    with torch.no_grad():\n        total_loss = 0\n        for step, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n            if step % 100 == 0:\n                print(f\"Evaluating step {step} of {len(data_loader)}\")\n\n        avg_loss = total_loss / len(data_loader)\n        dashboard_logger.eval_stats(global_step, avg_loss)\n        plot_embeddings(outputs.detach().cpu().numpy(), num_classes_in_batch=10)\n        return avg_loss\n\n", "CodeBleu_score": 26.39975072991556}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    class_name = to_camel(model_name)\n    if model_name == \"xtts\":\n        from.xtts.config import Config as Config\n    else:\n        from.config import Config as Config\n    try:\n        return find_module(model_name, class_name)\n    except ModuleNotFoundError:\n        raise ModuleNotFoundError(f\"No configuration class found for {model_name}.\")\n\n", "CodeBleu_score": 26.784675090799997}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    config_class_name = to_camel(model_name)\n    if model_name == \"xtts\":\n        config_class = importlib.import_module(\"coqpit.models.xtts.config\").Config\n    else:\n        config_class = find_module(\"coqpit.models\", model_name)\n    return config_class\n\n", "CodeBleu_score": 21.837428840415075}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    class_name = to_camel(model_name)\n    if model_name == \"xtts\":\n        from. import xtts_config\n        return getattr(xtts_config, class_name)\n    else:\n        module_name = model_name.lower()\n        try:\n            module = importlib.import_module(\"coqpit.models.\" + module_name + \"_config\")\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(\"Could not find configuration for model \" + model_name + \".\")\n        return getattr(module, class_name)", "CodeBleu_score": 33.46085771173485}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = read_json_with_comments(config_path)\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 11.267861974901514}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = None\n    config_dict = read_json_with_comments(config_path)\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config\n", "CodeBleu_score": 16.09858978523915}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = None\n    if config_path.endswith(\".yaml\"):\n        config_dict = yaml.safe_load(fsspec.open(config_path, \"r\", encoding=\"utf-8\"))\n    elif config_path.endswith(\".json\"):\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise ValueError(f\" [!] Config file extension {config_path} is not supported.\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config = config_class()\n    config.from_dict(config_dict)\n    return config", "CodeBleu_score": 43.67639381373448}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for root, dirnames, filenames in os.walk(basePath):\n        for filename in filenames:\n            # if the contains string was supplied, ensure that it's present\n            if contains is not None and contains not in filename:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\") + 1:].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the file and yield it\n                yield os.path.join(root, filename)\n\n", "CodeBleu_score": 53.283268886001714}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    if validExts is None:\n        validExts = ['jpg', 'png', 'jpeg', 'gif', 'tiff']\n    if contains is None:\n        contains = ''\n    for (rootDir, subdir, files) in os.walk(basePath):\n        for filename in files:\n            if filename.find(contains)!= -1:\n                ext = filename[filename.rfind('.') + 1:].lower()\n                if ext in validExts:\n                    yield os.path.join(rootDir, filename)\n", "CodeBleu_score": 44.263298045285325}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # construct the full path to the file\n            path = os.path.join(rootDir, filename)\n            # check if the file is a valid file and continue to the next iteration if the file is not\n            if not validExts or os.path.splitext(path)[1][1:] in validExts:\n                if contains and contains not in filename:\n                    continue\n                # yield the full path to the file\n                yield path", "CodeBleu_score": 43.68771959014642}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    # clear the GPU cache\n    clear_gpu_cache()\n\n    # check if the required paths are provided\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        print(\"Error: Missing required paths for loading XTTS model.\")\n        return\n\n    # load the configuration from the provided path\n    config = load_json(xtts_config)\n\n    # initialize the XTTS model\n    model = XTTSModel(config)\n\n    # load the model checkpoint and vocabulary\n    model.load_checkpoint(\n        config,\n        checkpoint_dir=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n    )\n\n    # move the model to the GPU if available\n    if torch.cuda.is_available():\n        model.cuda()\n\n    # print a success message\n    print(\"XTTS model loaded successfully.\")\n    return model\n\n", "CodeBleu_score": 48.52318728410372}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        print(\"Error: Please provide a valid checkpoint, config, and vocab path.\")\n        return\n\n    print(\"Loading XTTS model from checkpoint...\")\n    XTTS_MODEL = XTTS(config=xtts_config)\n    XTTS_MODEL.load_checkpoint(\n        checkpoint_dir=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n        eval=True,\n        strict=True,\n        use_deepspeed=False,\n        speaker_file_path=None,\n    )\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n\n    print(\"XTTS model loaded successfully.\")\n    return XTTS_MODEL\n", "CodeBleu_score": 46.70145575508124}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Please provide all the required paths to load the XTTS model.\"\n    XttsConfig = XTTSConfig.load_json(xtts_config)\n    XTTS_MODEL = XTTS_MODEL.load_checkpoint(\n        XttsConfig,\n        checkpoint_path=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n        eval=True,\n        strict=True,\n        use_deepspeed=False,\n    )\n    if torch.cuda.is_available():\n        XTTS_MODEL.cuda()\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 50.279821950339155}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    hop_length = self.hop_length\n    if isinstance(x, torch.Tensor):\n        x = x.cpu().numpy()\n    num_frames = int(num_frames)\n    num_eval = int(num_eval)\n    if num_frames > len(x):\n        num_frames = len(x)\n    if num_frames < 1:\n        num_frames = 1\n    if num_eval > num_frames:\n        num_eval = num_frames\n    if num_eval < 1:\n        num_eval = 1\n    if num_eval > 1:\n        offsets = np.linspace(0, len(x) - num_frames, num_eval, dtype=int)\n    else:\n        offsets = [0]\n    frames_batch = []\n    for offset in offsets:\n        frames_batch.append(x[offset:offset + num_frames])\n    frames_batch = torch.tensor(frames_batch)\n    frames_batch = frames_batch.to(self.device)\n    embeddings = self.inference(frames_batch)\n    if return_mean:\n        embeddings = torch.mean(embeddings, dim=0)\n        if l2_norm:\n            embeddings = embeddings / torch.norm(embeddings)\n        return embeddings\n    else:\n        return embeddings\n\n", "CodeBleu_score": 48.9235135245586}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.device == 'cuda':\n        x = x.cuda()\n    if self.hop_length > 1:\n        num_frames = int(np.ceil(x.shape[1] / self.hop_length))\n    if num_frames > x.shape[1]:\n        num_frames = x.shape[1]\n    if num_frames < 1:\n        num_frames = 1\n    x = x[:, :num_frames]\n    num_eval = min(num_eval, num_frames)\n    offset_positions = np.linspace(0, x.shape[1] - num_eval, num_eval, dtype=int)\n    frames_batch = []\n    for i in offset_positions:\n        frames_batch.append(x[:, i:i + num_eval])\n    frames_batch = torch.stack(frames_batch)\n    frames_batch = frames_batch.to(self.device)\n    if self.model_type == 'torch':\n        embedding = self.model(frames_batch)\n    else:\n        embedding = self.model.inference(frames_batch)\n    if return_mean:\n        embedding = torch.mean(embedding, dim=0)\n    if l2_norm:\n        embedding = embedding / torch.norm(embedding)\n    return embedding\n\n", "CodeBleu_score": 41.7521958559565}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.use_torch:\n        hop_length = self.hop_length\n        num_frames = int(np.ceil(x.shape[0] / hop_length))\n        if num_frames > num_frames:\n            num_frames = num_frames\n        if num_frames < num_frames:\n            num_frames = num_frames\n        x = x[0:num_frames * hop_length]\n        x = x.reshape(-1, 1, self.num_mels)\n        x = torch.from_numpy(x).float().to(self.device)\n        x = self.model.infer(x)\n        x = x.cpu().detach().numpy()\n        if l2_norm:\n            x = l2_normalize(x, axis=1)\n        if return_mean:\n            return np.mean(x, axis=0)\n        return x\n    else:\n        hop_length = self.hop_length\n        num_frames = int(np.ceil(x.shape[0] / hop_length))\n        if num_frames > num_frames:\n            num_frames = num_frames\n        if num_frames < num_frames:\n            num_frames = num_frames\n        x = x[0:num_frames * hop_length]\n        x = x.reshape(-1, 1, self.num_mels)\n        x = np.transpose(x, (0, 2, 1))\n        x = np.expand_dims(x, axis=0)\n        x = self.model.predict(x)\n        x = np.squeeze(x, axis=0)\n        if l2_norm:\n            x = l2_normalize(x, axis=1)\n        if return_mean:\n            return np.mean(x, axis=0)\n        return x\n\n", "CodeBleu_score": 35.43372688839026}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n", "CodeBleu_score": 85.54080921158837}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n", "CodeBleu_score": 85.54080921158837}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n    return nn.Sequential(*layers)\n", "CodeBleu_score": 85.54080921158837}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    if num_classes_in_batch > 10:\n        num_classes_in_batch = 10\n    num_classes = len(np.unique(embeddings[:, 0]))\n    if num_classes > num_classes_in_batch:\n        num_classes = num_classes_in_batch\n    umap_model = umap.UMAP(n_neighbors=15, min_dist=0.0, n_components=2, random_state=42)\n    umap_embeddings = umap_model.fit_transform(embeddings[:, 1:])\n    plt.figure(figsize=(10, 10))\n    plt.set_aspect(\"equal\")\n    plt.title(\"UMAP projection\", fontsize=24)\n    plt.scatter(\n        umap_embeddings[:, 0],\n        umap_embeddings[:, 1],\n        c=embeddings[:, 0],\n        s=10,\n        cmap=\"Spectral\",\n        alpha=0.5,\n    )\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.colorbar(boundaries=np.arange(num_classes + 1) - 0.5).set_ticks(\n        np.arange(num_classes)\n    )\n    plt.savefig(\"umap\")\n    return plt.gcf()\n\n", "CodeBleu_score": 42.506298062725264}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    umap_model = umap.UMAP(n_neighbors=15, min_dist=0.1, n_components=2)\n    umap_results = umap_model.fit_transform(embeddings)\n    fig, ax = plt.subplots(figsize=(10, 10))\n    ax.scatter(umap_results[:, 0], umap_results[:, 1], c=num_classes_in_batch, s=0.3)\n    ax.set_aspect('equal', 'datalim')\n    ax.set_title('UMAP projection', fontsize=24)\n    plt.tight_layout()\n    plt.savefig('umap.png')\n    return fig", "CodeBleu_score": 22.252611890872277}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    num_classes = embeddings.shape[1]\n    num_classes_in_batch = min(num_classes_in_batch, num_classes)\n    num_classes_in_batch = min(num_classes_in_batch, 10)\n    num_utterances_per_class = int(embeddings.shape[0] / num_classes_in_batch)\n    embeddings = umap.UMAP(n_components=2, random_state=42).fit_transform(embeddings)\n    plt.figure(figsize=(10, 10))\n    plt.gca().set_aspect('equal', 'datalim')\n    plt.title('UMAP projection', fontsize=24)\n    plt.scatter(\n        embeddings[:num_utterances_per_class, 0],\n        embeddings[:num_utterances_per_class, 1],\n        c=np.array(list(range(num_classes_in_batch)) * num_utterances_per_class)[:num_utterances_per_class],\n        s=1,\n        cmap='Spectral',\n        alpha=0.5\n    )\n    plt.tight_layout()\n    plt.savefig('umap')\n    return plt.gcf()\n", "CodeBleu_score": 28.337029382266504}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, utt in enumerate(range(len(dvecs[spkr]))):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n        cos_sim = torch.mm(dvecs[spkr, utt].unsqueeze(0), new_centroids.transpose(0, 1))\n        cos_sim = torch.clamp(cos_sim, min=1e-10)\n        cs_row = []\n        for i in range(len(cos_sim)):\n            cs_row.append(cos_sim[i].item())\n        cos_sim_matrix.append(cs_row)\n    return torch.stack(cos_sim_matrix)\n", "CodeBleu_score": 37.64298389241529}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, utt in enumerate(dvecs):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n        cs_row = []\n        for i, centroid in enumerate(new_centroids):\n            cs_row.append(\n                torch.clamp(\n                    torch.mm(\n                        torch.unsqueeze(dvecs[spkr, utt], 0),\n                        torch.unsqueeze(centroid, 0),\n                    ),\n                    min=0,\n                    max=1,\n                )\n            )\n        cos_sim_matrix.append(torch.cat(cs_row))\n    return torch.stack(cos_sim_matrix)\n\n", "CodeBleu_score": 48.520303937825794}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cos_sim_matrix = []\n    for spkr, utt in enumerate(range(len(dvecs))):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n        cs_row = []\n        for i, centroid in enumerate(new_centroids):\n            cs_row.append(cos_sim(dvecs[spkr, utt], centroid))\n        cs_row = torch.stack(cs_row)\n        cs_row = torch.clamp(cs_row, min=0)\n        cos_sim_matrix.append(cs_row)\n    cos_sim_matrix = torch.cat(cos_sim_matrix)\n    return cos_sim_matrix\n\n", "CodeBleu_score": 43.64062375229755}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    loss_L = []\n    for i in range(len(self.embeddings)):\n        loss_row = []\n        for j in range(len(self.embeddings)):\n            if i == j:\n                continue\n            else:\n                loss_row.append(F.log_softmax(cos_sim_matrix[i][j], dim=0))\n        loss_L.append(torch.stack(loss_row))\n    return torch.stack(loss_L)\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.81994658046477}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    # Compute the negative log softmax of the cosine similarity matrix for each embedding\n    # This is equivalent to calculating the embedding loss using softmax\n    # Note: This is a vectorized implementation of the softmax loss function\n    # Note: The log_softmax function is equivalent to the softmax function followed by the log function\n    # Note: The dim argument specifies the dimension along which the softmax function is applied\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument is set to 1 because we want to apply the softmax function to the rows of the cosine similarity matrix\n    # Note: The dim argument is set to 0 because we want to apply the softmax function to the columns of the cosine similarity matrix\n    # Note: The dim argument", "CodeBleu_score": 2.26010101010101}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for i, dvec in enumerate(dvecs):\n        cos_sim_matrix[i] = cos_sim_matrix[i] / cos_sim_matrix[i].norm()\n        loss = F.log_softmax(cos_sim_matrix[i], dim=0)\n        losses.append(loss)\n    return torch.stack(losses)\n\n", "CodeBleu_score": 31.57087584677209}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(dvecs.shape[0]):\n        dvecs_i = dvecs[i]\n        cos_sim_matrix_i = cos_sim_matrix[i]\n        cos_sim_matrix_i_exclude = cos_sim_matrix_i.clone()\n        cos_sim_matrix_i_exclude[i] = -100000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000", "CodeBleu_score": 14.104913023767049}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    L_row = []\n    for i in range(len(dvecs)):\n        cos_sim_matrix[i, i] = 0\n        L_row.append(torch.sigmoid(cos_sim_matrix[i]).sum())\n    return torch.stack(L_row)\n", "CodeBleu_score": 19.309711308736848}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    loss_row = []\n    for i in range(len(dvecs)):\n        sim_matrix = cos_sim_matrix.clone()\n        sim_matrix[i, :] = -np.inf\n        sim_matrix[:, i] = -np.inf\n        loss = torch.sigmoid(-sim_matrix[i, :])\n        loss_row.append(loss)\n    loss_row = torch.stack(loss_row)\n    return loss_row\n", "CodeBleu_score": 27.7343781315721}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    if x.size(1) < 2:\n        return self.embed_loss(x, _label)\n    dvecs = x.transpose(0, 1)\n    centroids = self.calc_centroids(dvecs)\n    cos_sim_matrix = self.calc_cosine_sim(dvecs, centroids)\n    scaled_cos_sim_matrix = self.scale_cos_sim(cos_sim_matrix)\n    shifted_cos_sim_matrix = self.shift_cos_sim(scaled_cos_sim_matrix)\n    loss = self.embed_loss(shifted_cos_sim_matrix, _label)\n    return loss\n", "CodeBleu_score": 40.18855812233818}, {"code": "def forward(self, x, _label=None)\n\t\n    x = x.transpose(0, 1)\n    num_speakers, num_utts_per_speaker, dvec_feats = x.size()\n    # ensure at least 2 utts per speaker\n    if num_utts_per_speaker < 2:\n        raise ValueError(\n            f\"Error: input must have at least 2 utterances per speaker, but input has {num_utts_per_speaker} utterances per speaker.\"\n        )\n    # compute centroids\n    centroids = self.calc_centroids(x)\n    # make cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n    # scale and shift cosine similarity matrix\n    cos_sim_matrix = self.scale_and_shift(cos_sim_matrix)\n    # compute embedding loss\n    embedding_loss = self.calc_embedding_loss(cos_sim_matrix)\n    # average embedding loss\n    embedding_loss = embedding_loss.mean()\n    # return embedding loss\n    return embedding_loss\n\n", "CodeBleu_score": 23.863070751019468}, {"code": "def forward(self, x, _label=None)\n\t\n    # Check if there are more than one utterance per speaker\n    if x.size(1) < 2:\n        raise ValueError(\"There should be at least two utterances per speaker.\")\n    # Calculate the centroids\n    centroids = self.calc_centroids(x)\n    # Calculate the cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n    # Scale and shift the cosine similarity matrix\n    scaled_cos_sim_matrix = self.scale_and_shift(cos_sim_matrix)\n    # Calculate the embedding loss\n    embedding_loss = self.embed_loss(scaled_cos_sim_matrix)\n    # Calculate the mean loss\n    mean_loss = torch.mean(embedding_loss)\n    return mean_loss\n\n", "CodeBleu_score": 42.68013217727319}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toices = {}\n    for voice_dir in extra_voice_dirs:\n        for root, dirs, files in os.walk(voice_dir):\n            if len(files) > 0:\n                voices[root] = [os.path.join(root, file) for file in files if file.endswith('.npz') or file.endswith('.wav') or file.endswith('.mp3')]\n            else:\n                voices[root] = [os.path.join(root, file) for file in files if file.endswith('.wav') or file.endswith('.mp3')]\n    return voices\n", "CodeBleu_score": 26.468755543398014}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toices = {}\n    for voice_dir in [os.path.join(os.getcwd(), 'voices'), *extra_voice_dirs]:\n        if not os.path.isdir(voice_dir):\n            continue\n        for root, dirs, files in os.walk(voice_dir):\n            for file in files:\n                file_path = os.path.join(root, file)\n                if file.endswith('.npz'):\n                    if root not in voices:\n                        voices[root] = []\n                    voices[root].append(file_path)\n                elif file.endswith('.wav') or file.endswith('.mp3'):\n                    if root not in voices:\n                        voices[root] = []\n                    voices[root].append(file_path)\n    return voices\n\n", "CodeBleu_score": 27.29645191057642}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toices = {}\n    for voice_dir in extra_voice_dirs:\n        for root, dirs, files in os.walk(voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    voices[root] = voices.get(root, []) + [os.path.join(root, file)]\n                elif file.endswith(\".wav\") or file.endswith(\".mp3\"):\n                    voices[root] = voices.get(root, []) + [os.path.join(root, file)]\n    return voices\n\n", "CodeBleu_score": 30.043918245195766}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, seq_len, _ = pos_score.size()\n    pos_score = torch.cat((torch.zeros(batch_size, 1, seq_len), pos_score[:, :-1, :]), dim=1)\n    pos_score = pos_score.view(batch_size, seq_len, 1, seq_len)\n    pos_score = pos_score.permute(0, 2, 3, 1)\n    pos_score = pos_score.contiguous().view(batch_size, seq_len, seq_len)\n    return pos_score\n", "CodeBleu_score": 27.592870658424722}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, seq_len = pos_score.size()\n    zero_tensor = torch.zeros(batch_size, 1, seq_len)\n    padded_pos_score = torch.cat([zero_tensor, pos_score], dim=1)\n    shifted_pos_score = padded_pos_score.view(batch_size, seq_len + 1, 1)[:, 1:, :]\n    shifted_pos_score = shifted_pos_score.view(batch_size, seq_len, 1)\n    return shifted_pos_score\n", "CodeBleu_score": 29.15694875139022}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    batch_size, seq_length, _ = pos_score.size()\n    zero_tensor = torch.zeros(batch_size, 1, seq_length)\n    pos_score = torch.cat([zero_tensor, pos_score], dim=1)\n    pos_score = pos_score.view(batch_size, -1)\n    pos_score = pos_score[:, :seq_length]\n    return pos_score.view(batch_size, seq_length, seq_length)\n", "CodeBleu_score": 28.02772192392151}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = []\n    for i in range(self.n_layers):\n        context_embedded.append(self.embedding(context))\n        context_embedded[i] = self.dropout(context_embedded[i])\n        context_embedded[i] = self.conv[i](context_embedded[i])\n        context_embedded[i] = self.activation(context_embedded[i])\n        context_embedded[i] = self.dropout(context_embedded[i])\n    context_embedded = torch.cat(context_embedded, dim=2)\n    context_embedded = self.dropout(context_embedded)\n    context_embedded = pad_sequence(context_embedded, batch_first=True, padding_value=0)\n    return context_embedded\n", "CodeBleu_score": 26.03416109733282}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    # Create a mask that indicates which elements are valid in the sequence.\n    mask = (torch.arange(context.size(1), device=context.device)[None, :] < lens[:, None]).float()\n    # Apply the convolutional layers to each element of the sequence.\n    conv_out = self.dropout(self.relu(self.conv(context)))\n    # Pad the results to create a consistent batch size.\n    conv_out = pad_sequence(conv_out, batch_first=True, padding_value=0.0)\n    # Apply the mask to the padded sequence.\n    return conv_out * mask\n\n", "CodeBleu_score": 13.761968429696864}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_embedded = [self.embedding(context[:, i]) for i in range(context.size(1))]\n    context_embedded = torch.stack(context_embedded, dim=1)\n    context_embedded = self.dropout(context_embedded)\n    for i in range(self.num_layers):\n        context_embedded = self.conv(context_embedded)\n        context_embedded = self.activation(context_embedded)\n        context_embedded = self.dropout(context_embedded)\n    context_embedded = pad_sequence(context_embedded, batch_first=True)\n    context_embedded = context_embedded.transpose(1, 2)\n    return context_embedded\n", "CodeBleu_score": 26.687646977610974}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lens_sorted, indices_sorted = torch.sort(lens, descending=True)\n    context_packed = pack_padded_sequence(context, lens_sorted, enforce_sorted=False)\n    result = fn(context_packed, context_packed.batch_sizes)\n    result_unpacked, _ = pad_packed_sequence(result, batch_first=True)\n    result_unsorted = result_unpacked[indices_sorted]\n    return result_unsorted\n", "CodeBleu_score": 13.691699574716473}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    # Sort the lengths and indices\n    lens_sorted, indices_sorted = torch.sort(lens, descending=True)\n    # Pack the context sequences\n    context_packed, lens_packed = pack_padded_sequence(context, lens_sorted, enforce_sorted=False)\n    # Run the function on the packed context\n    output_packed = fn(context_packed)\n    # Unpack the output\n    output_unpacked, _ = pad_packed_sequence(output_packed, batch_first=True)\n    # Map the results back to the original indices\n    output_mapped = output_unpacked[indices_sorted]\n    return output_mapped\n", "CodeBleu_score": 12.982489541234715}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    # Sort the lengths and indices based on their lengths\n    lens_sorted, indices_sorted = torch.sort(lens, descending=True)\n    context_sorted = pack_padded_sequence(context, lens_sorted, enforce_sorted=False)\n    # Run the function on the sorted inputs\n    results = fn(context_sorted, lens_sorted)\n    # Unpack the results\n    results_unpacked, lens_unpacked = pad_packed_sequence(results, batch_first=True)\n    # Map the results back to the original indices\n    results_mapped = results_unpacked[indices_sorted]\n    # Return the context in its original order\n    return results_mapped\n", "CodeBleu_score": 13.881782198420762}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n", "CodeBleu_score": 70.15353357610886}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t   torch_name = mx_name.lower()\n    if torch_name.startswith('se_'):\n        torch_name = torch_name.replace('se_','se_resnext_')\n    elif torch_name.startswith('senet_'):\n        torch_name = torch_name.replace('senet_','senet_')\n    elif torch_name.startswith('inceptionv3'):\n        torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    return 'gluon_' + torch_name\n\n", "CodeBleu_score": 62.65944930877835}, {"code": "def map_mx_to_torch_model(mx_name)\n\t   torch_name = mx_name.lower()\n    if torch_name.startswith('se_'):\n        torch_name = torch_name.replace('se_','senet_')\n    elif torch_name.startswith('senet_'):\n        torch_name = torch_name.replace('senet_','senet_')\n    elif torch_name.startswith('inceptionv3'):\n        torch_name = torch_name.replace('inceptionv3', 'inception_v3')\n    torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 69.92375207128096}, {"code": "def map_mx_to_torch_model(mx_name)\n\t   torch_name = mx_name.lower()\n    if torch_name.startswith('se_'):\n        torch_name = 'gluon_' + torch_name.replace('se_','se_resnext')\n    elif torch_name.startswith('senet_'):\n        torch_name = 'gluon_' + torch_name.replace('senet_','senet154')\n    elif torch_name.startswith('inceptionv3'):\n        torch_name = 'gluon_' + torch_name.replace('inceptionv3', 'inception_v3')\n    else:\n        torch_name = 'gluon_' + torch_name\n    return torch_name\n\n", "CodeBleu_score": 63.68908115423759}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    if self.num_replicas > 1:\n        return math.ceil(self.num_samples / self.num_replicas)\n    elif self.num_workers > 1:\n        return math.ceil(self.num_samples / self.num_workers)\n    else:\n        return self.num_samples\n\n", "CodeBleu_score": 20.586180148697757}, {"code": "def _num_samples_per_worker(self)\n\t\n    if self.num_workers == 0:\n        if self.total_samples is None:\n            raise ValueError(\"total_samples must be specified when num_workers is 0\")\n        if self.repeats is None:\n            raise ValueError(\"repeats must be specified when num_workers is 0\")\n        if self.batch_size is None:\n            self.batch_size = 1\n        return math.ceil(self.total_samples / self.repeats / self.batch_size)\n    else:\n        if self.total_samples is None:\n            raise ValueError(\"total_samples must be specified when num_workers is not 0\")\n        if self.repeats is None:\n            raise ValueError(\"repeats must be specified when num_workers is not 0\")\n        if self.batch_size is None:\n            self.batch_size = 1\n        return math.ceil(self.total_samples / self.repeats / self.batch_size / self.num_workers)\n", "CodeBleu_score": 21.483695236960347}, {"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self.num_samples\n    num_workers = self.num_workers\n    num_replicas = self.num_replicas\n    if self.repeats > 0:\n        num_samples = num_samples * self.repeats\n    if num_replicas > 1:\n        num_samples = math.ceil(num_samples / num_replicas)\n    if self.batch_size > 0:\n        num_samples = math.ceil(num_samples / self.batch_size) * self.batch_size\n    return int(num_samples)\n", "CodeBleu_score": 42.36218616732558}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    # Check if folder exists\n    if not os.path.exists(folder):\n        raise FileNotFoundError(f'Folder \"{folder}\" does not exist!')\n\n    # Get all files in folder\n    files = []\n    for root, _, filenames in os.walk(folder):\n        for filename in filenames:\n            files.append(os.path.join(root, filename))\n\n    # Filter by file types\n    if types is not None:\n        files = [f for f in files if f.split('.')[-1].lower() in types]\n\n    # Get labels\n    labels = []\n    for file in files:\n        label = file.split(os.sep)[-2]\n        if leaf_name_only:\n            label = label.split(os.sep)[-1]\n        labels.append(label)\n\n    # Check if class-to-index mapping is provided\n    if class_to_idx is None:\n        class_to_idx = {label: idx for idx, label in enumerate(set(labels))}\n\n    # Pair images and labels\n    img_and_labels = [(file, class_to_idx[label]) for file, label in zip(files, labels)]\n\n    # Sort if requested\n    if sort:\n        img_and_labels.sort(key=natural_key)\n\n    return img_and_labels, class_to_idx\n\n", "CodeBleu_score": 38.977298798616566}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    # check if folder exists\n    if not os.path.exists(folder):\n        raise FileNotFoundError(f'Folder {folder} does not exist!')\n    # check if types are valid\n    if types is not None:\n        for t in types:\n            if not isinstance(t, str):\n                raise TypeError(f'Types must be a string or a list of strings!')\n    # check if class_to_idx is a dict\n    if class_to_idx is not None and not isinstance(class_to_idx, dict):\n        raise TypeError(f'class_to_idx must be a dictionary!')\n    # check if leaf_name_only is a bool\n    if not isinstance(leaf_name_only, bool):\n        raise TypeError(f'leaf_name_only must be a boolean!')\n    # check if sort is a bool\n    if not isinstance(sort, bool):\n        raise TypeError(f'sort must be a boolean!')\n    # check if the folder is empty\n    if not os.listdir(folder):\n        raise FileNotFoundError(f'Folder {folder} is empty!')\n    # get the list of files and directories\n    files = []\n    for root, _, fnames in os.walk(folder):\n        for fname in fnames:\n            files.append(os.path.join(root, fname))\n    # filter by file types\n    if types is not None:\n        files = [f for f in files if f.lower().endswith(tuple(types))]\n    # get the list of labels\n    labels = []\n    for f in files:\n        labels.append(os.path.dirname(f))\n    # create a mapping from labels to indices\n    if class_to_idx is None:\n        class_to_idx = {l: i for i, l in enumerate(sorted(set(labels)))}\n    # sort the results\n    if sort:\n        files, labels = zip(*sorted(zip(files, labels), key=natural_key))\n    # get the list of image paths and labels\n    imgs = []\n    for f, l in zip(files, labels):\n        if leaf_name_only:\n            f = os.path.basename(f)\n        imgs.append((f, class_to_idx[l]))\n    return imgs, class_to_idx\n\n", "CodeBleu_score": 38.517801216930536}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if not types:\n        types = ['jpg', 'jpeg', 'png', 'bmp']\n    if not class_to_idx:\n        class_to_idx = {v: k for k, v in enumerate(sorted(set(labels)))}\n    filenames = []\n    labels = []\n    for root, _, files in os.walk(folder):\n        for file in files:\n            ext = splitext(file)[1][1:].lower()\n            if ext in types:\n                rel_path = relpath(join(root, file), folder)\n                if leaf_name_only:\n                    rel_path = basename(rel_path)\n                filenames.append(rel_path)\n                labels.append(class_to_idx[splitext(rel_path)[0]])\n    if sort:\n        zipped = zip(filenames, labels)\n        zipped = sorted(zipped, key=natural_key)\n        filenames, labels = zip(*zipped)\n    return filenames, labels\n\n", "CodeBleu_score": 37.98865889317716}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    return _pytorch_worker_seed\n\n", "CodeBleu_score": 2.545860912591809}, {"code": "def pytorch_worker_seed()\n\t\n    return pytorch_worker_seed.get_worker_info()\n\n", "CodeBleu_score": 5.151208853961713}, {"code": "def pytorch_worker_seed()\n\t\n    return pytorch_worker_seed.get_worker_info()\n\n", "CodeBleu_score": 5.151208853961713}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    img = img.convert('RGB')\n    lut = []\n    for i in range(256):\n        lut.append(min(i + add, 255))\n    return img.point(lut)\n", "CodeBleu_score": 28.71892554009912}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in ('L', 'RGB'):\n        return img\n    lut = []\n    for i in range(256):\n        lut.append(i + add if i < thresh else i)\n    return img.point(lut)", "CodeBleu_score": 38.32241940116252}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in (\"L\", \"RGB\"):\n        return img\n    if img.mode == \"L\":\n        return img.point(lambda p: p + add if p < thresh else p, \"1\")\n    return img.point(lambda p: p[0] + add[0] if p[0] < thresh else p[0], \"1\") + img.point(lambda p: p[1] + add[1] if p[1] < thresh else p[1], \"1\") + img.point(lambda p: p[2] + add[2] if p[2] < thresh else p[2], \"1\")\n\n\n\n\n", "CodeBleu_score": 29.622154910988097}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    # Get the transform names and their probabilities\n    transform_names = list(transforms.keys())\n    transform_probs = list(transforms.values())\n\n    # Normalize the probabilities\n    transform_probs = np.array(transform_probs) / np.sum(transform_probs)\n\n    return transform_names, transform_probs\n", "CodeBleu_score": 21.436835970267783}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names = list(transforms.keys())\n    transform_probabilities = list(transforms.values())\n    transform_probabilities = np.array(transform_probabilities)\n    transform_probabilities = transform_probabilities / np.sum(transform_probabilities)\n    return transform_names, transform_probabilities\n\n", "CodeBleu_score": 17.31199721575088}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    # get the transform names and their corresponding probabilities\n    transform_names = []\n    probabilities = []\n    for transform in transforms:\n        transform_names.append(transform)\n        probabilities.append(transforms[transform])\n    # normalize the probabilities\n    probabilities = np.array(probabilities)\n    probabilities = probabilities / np.sum(probabilities)\n    return transform_names, probabilities\n\n", "CodeBleu_score": 32.14839921952933}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size, dtype=np.uint8)\n    for weight in mixing_weights:\n        mixed += weight * self._apply_single(img)\n    mixed = np.clip(mixed, 0, 255)\n    mixed = Image.fromarray(mixed)\n    return Image.blend(img, mixed, m)\n\n", "CodeBleu_score": 20.97110763373703}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.size)\n    for w in mixing_weights:\n        mixed = np.clip(mixed + self._apply_single(img, w, m), 0, 255)\n    mixed = np.asarray(Image.fromarray(mixed).convert('RGB'))\n    return Image.blend(img, mixed, self.blend_alpha)\n", "CodeBleu_score": 20.294594444041447}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed = np.zeros(img.shape)\n    for w in mixing_weights:\n        for op in self.augmentation_sequence(img, m):\n            mixed = op(mixed)\n        mixed = np.clip(mixed, 0, 255)\n    mixed = mixed.astype(np.uint8)\n    mixed = Image.fromarray(mixed)\n    mixed = Image.blend(img, mixed, self.blend_factor)\n    return mixed\n", "CodeBleu_score": 25.448107320095335}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if isinstance", "CodeBleu_score": 2.060251745944187}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance", "CodeBleu_score": 2.2157072138928102}, {"code": "def adapt_to_chs(x, n)\n\t\n    if isinstance", "CodeBleu_score": 2.060251745944187}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = torch.utils.data.get_worker_info()\n    if worker_info is None:\n        return\n    if worker_id >= worker_info.num_workers:\n        return\n    if worker_seeding == 'all':\n        if worker_info.seed is not None:\n            worker_seed = worker_info.seed + worker_id\n        else:\n            worker_seed = None\n        seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        np.random.seed(worker_seed)\n    elif isinstance(worker_seeding, str):\n        if worker_info.seed is not None:\n            seed(worker_info.seed + worker_id)\n        else:\n            seed(None)\n    elif callable(worker_seeding):\n        worker_seeding(worker_id)\n    else:\n        raise TypeError('worker_seeding should be a string, a callable, or \"all\"')\n", "CodeBleu_score": 32.19968454414882}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = get_worker_info()\n    if worker_info is None:\n        return\n    if worker_info.id!= worker_id:\n        return\n    if worker_seeding == 'all':\n        seed = worker_info.seed % 2**32\n        torch.manual_seed(seed)\n        random.seed(seed)\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, str):\n        seed = worker_info.seed % 2**32\n        np.random.seed(seed)\n    elif callable(worker_seeding):\n        seed = worker_info.seed % 2**32\n        worker_seeding(seed)\n    else:\n        raise TypeError('worker_seeding must be a string, a callable, or \"all\".')\n", "CodeBleu_score": 44.584778278897275}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = torch.utils.data.get_worker_info()\n    if worker_info is None:\n        return\n    if worker_id >= worker_info.num_workers:\n        raise ValueError('worker_id is not less than the number of workers')\n    if worker_seeding == 'all':\n        worker_seed = worker_info.seed % (2**32 - 1)\n        seed(worker_seed)\n        torch.manual_seed(worker_seed)\n        np.random.seed(worker_seed)\n    elif isinstance(worker_seeding, str):\n        seed(worker_info.seed % (2**32 - 1))\n        np.random.seed(worker_info.seed % (2**32 - 1))\n    elif callable(worker_seeding):\n        worker_seeding(worker_info.seed % (2**32 - 1))\n    else:\n        raise ValueError('worker_seeding must be a string, callable or None')\n\n\n\n\n", "CodeBleu_score": 50.92897891746486}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    image_shape = tf.shape(image)\n    padded_center_crop_size = tf.cast(\n        tf.math.ceil(\n            tf.math.minimum(image_size[0], image_size[1]) *\n            (1 + 1 / 4)),\n        tf.int32)\n    offset_height = ((image_shape[0] - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_shape[1] - padded_center_crop_size) + 1) // 2\n    image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, padded_center_crop_size,\n        padded_center_crop_size)\n    image = resize(image, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 34.50280889034955}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    image_shape = tf.image.extract_jpeg_shape(image_bytes)\n    image_height = image_shape[0]\n    image_width = image_shape[1]\n    padded_center_crop_size = tf.cast(\n        tf.math.minimum(image_size[0], image_size[1]), tf.int32)\n    offset_height = ((image_height - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_width - padded_center_crop_size) + 1) // 2\n    crop_window = tf.stack([offset_height, offset_width, padded_center_crop_size, padded_center_crop_size])\n    image = tf.image.crop_to_bounding_box(image, offset_height, offset_width, padded_center_crop_size, padded_center_crop_size)\n    image = tf.image.resize(image, image_size, method=resize_method)\n    return image\n", "CodeBleu_score": 43.10574564037471}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image_shape = tf.stack([image_size[0] + 2 * padding, image_size[1] + 2 * padding, 3])\n    crop_window = tf.stack([image_size[0], image_size[1], 3])\n    offset_height = ((image_shape[0] - crop_window[0]) // 2)\n    offset_width = ((image_shape[1] - crop_window[1]) // 2)\n    image = tf.image.decode_and_crop_jpeg(image_bytes, offset_height, offset_width, crop_window)\n    image = tf.image.resize(image, image_size, method=resize_method)\n    return image\n", "CodeBleu_score": 17.033184685080354}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 40.640941678840136}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 40.640941678840136}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    image = _decode_and_random_crop(image, image_size, interpolation)\n    image = _flip(image)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    if use_bfloat16:\n        image = tf.cast(image, tf.bfloat16)\n    else:\n        image = tf.cast(image, tf.float32)\n    return image\n\n", "CodeBleu_score": 40.5677642753364}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 38.3611525419684}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = convert_image_dtype(image, tf.float32)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    if use_bfloat16:\n        image = tf.cast(image, tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 32.33934528769484}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 29.83411034599408}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    if output_file is None:\n        output_file = self.output_file\n    predictions = predict_loop(model, eval_dataloader)\n    save_predictions(predictions, output_file)\n    results = compute_metrics(output_file)\n    return results", "CodeBleu_score": 56.81861025857325}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    # Set the model to evaluation mode\n    model.eval()\n\n    # If the dataloader is not specified, use the default evaluation dataloader\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n\n    # Initialize the prediction output file\n    output_file = os.path.join(self.output_dir, output_file)\n    with open(output_file, \"w\") as f:\n        f.write(\"id,label", "CodeBleu_score": 50.82158270958882}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    if output_file is None:\n        output_file = self.output_file\n    # Run prediction loop\n    predictions, labels = predict_loop(model, eval_dataloader)\n    # Compute metrics\n    metrics = compute_metrics(labels, predictions)\n    # Save results to file\n    if output_file is not None:\n        save_predictions(output_file, labels, predictions)\n    return metrics\n\n", "CodeBleu_score": 51.87905613216351}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    print(\"Rank-1: {:.4f}\".format(metrics[\"rank1\"]))\n    print(\"Rank-5: {:.4f}\".format(metrics[\"rank5\"]))\n    print(\"mIOU: {:.4f}\".format(metrics[\"miou\"]))\n", "CodeBleu_score": 25.306985561238736}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    print('Rank1:'+ str(round(metrics['rank1'], 4)) +' Rank5:'+ str(round(metrics['rank5'], 4)) +' mIoU:'+ str(round(metrics['miou'], 4)))", "CodeBleu_score": 19.249443822809216}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    print(\"Rank-1: {:.4f}\".format(metrics[\"rank1\"]))\n    print(\"Rank-5: {:.4f}\".format(metrics[\"rank5\"]))\n    print(\"mIoU: {:.4f}\".format(metrics[\"miou\"]))\n", "CodeBleu_score": 25.326456593453063}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment, data_point in zip(segments, data):\n        iou = self._iou(segment, data_point)\n        rank = self._rank(segment, data_point)\n        average_iou.append(iou)\n        average_ranks.append(rank)\n    return np.mean(average_iou), np.mean(average_ranks), np.mean(average_iou), np.mean(average_ranks)\n", "CodeBleu_score": 22.548963743283707}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_iou = []\n    average_ranks = []\n    for segment, data_segment in zip(segments, data):\n        iou = self._iou(segment, data_segment)\n        rank = self._rank(segment, data_segment)\n        average_iou.append(iou)\n        average_ranks.append(rank)\n    return np.mean(average_iou), np.mean(average_ranks)\n\n", "CodeBleu_score": 20.399792560044133}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    average_ranks = []\n    average_iou = []\n    for segment, data_segment in zip(segments, data):\n        gt = data_segment['gt']\n        pred = data_segment['pred']\n        iou = self._iou(pred, gt)\n        average_iou.append(iou)\n        rank = self._rank(pred, gt)\n        average_ranks.append(rank)\n    return np.mean(average_iou), np.mean(average_ranks)\n\n", "CodeBleu_score": 25.808919903356824}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    self.model.eval()\n    self.model.to_ctx(0)\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            output = self.model(batch)\n        scores.update(output)\n    self.model.finalize(output_file)\n    return scores\n\n", "CodeBleu_score": 36.79219036770968}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to_ctx(ctx=0)\n    for batch in eval_dataloader:\n        batch = self.to_ctx(batch, ctx=0)\n        with torch.no_grad():\n            outputs = model(batch)\n        scores.update(outputs.update(batch))\n    self.finalize(output_file)\n    return scores\n\n", "CodeBleu_score": 44.563177438105164}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    scores = []\n    model.eval()\n    model.to_ctx(0)\n    for batch in eval_dataloader:\n        batch = self.to_ctx(batch, 0)\n        with torch.no_grad():\n            outputs = model(batch)\n            scores.update(outputs.update(batch))\n    self.finalize(output_file)\n    return scores\n\n", "CodeBleu_score": 44.311993454803584}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    scores = np.concatenate(scores, axis=1)\n    self.full_scores = None\n    return np.dot(scores[0], scores[1])\n", "CodeBleu_score": 34.58762282838971}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    text_scores, video_scores = scores\n    full_scores = np.concatenate((text_scores, video_scores), axis=0)\n    self.full_scores = full_scores\n    return np.dot(self.full_scores, self.full_scores.T)\n\n", "CodeBleu_score": 36.9773461317653}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    video_scores, text_scores = scores\n    video_scores = np.concatenate(video_scores, axis=0)\n    text_scores = np.concatenate(text_scores, axis=0)\n    self.full_scores = None\n    return np.dot(video_scores, text_scores)\n\n", "CodeBleu_score": 39.30538098104304}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = np.concatenate(Y_pred)\n    Y_true = np.concatenate(Y_true)\n    if self.config.label_type == 'categorical':\n        Y_pred = np.argmax(Y_pred, axis=1)\n        Y_true = np.argmax(Y_true, axis=1)\n    if self.config.label_type == 'integer':\n        Y_pred = np.round(Y_pred)\n        Y_true = np.round(Y_true)\n    if self.config.label_type == 'float':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type =='string':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type == 'integer_string':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type == 'float_string':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type =='string_float':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type == 'integer_float':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type == 'float_integer':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type =='string_integer':\n        Y_pred = np.round(Y_pred, decimals=2)\n        Y_true = np.round(Y_true, decimals=2)\n    if self.config.label_type == 'integer", "CodeBleu_score": 29.716964584717648}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = Y_pred.detach().cpu().numpy()\n    Y_true = Y_true.detach().cpu().numpy()\n    Y_pred = Y_pred.argmax(axis=1)\n    Y_true = Y_true.argmax(axis=1)\n    error_mask = Y_pred!= Y_true\n    if output_file:\n        with open(output_file, 'wb') as f:\n            pickle.dump((Y_pred, Y_true), f)\n    if error_mask.any():\n        print(f'There are {error_mask.sum()} errors out of {len(error_mask)} samples.')\n        print('The first 10 samples with errors are:')\n        print(f'Predicted labels: {Y_pred[error_mask][:10]}')\n        print(f'True labels: {Y_true[error_mask][:10]}')\n    return {'Y_pred': Y_pred, 'Y_true': Y_true}\n", "CodeBleu_score": 37.989270591516174}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = torch.cat(Y_pred).cpu().numpy()\n    Y_true = torch.cat(Y_true).cpu().numpy()\n    Y_pred = np.argmax(Y_pred, axis=1)\n    Y_true = np.argmax(Y_true, axis=1)\n    self.check_predictions(Y_pred, Y_true)\n    if output_file is not None:\n        self.save_predictions(output_file, Y_pred, Y_true)\n    return {'Y_pred': Y_pred, 'Y_true': Y_true}\n\n", "CodeBleu_score": 27.898319488555163}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get_scalar('loss', 0) for log in logging_outputs)\n    sample_size = sum(log.get_scalar('sample_size', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size)\n", "CodeBleu_score": 50.92391317186975}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get_item('loss', 0) for log in logging_outputs)\n    sample_size = sum(log.get_item('sample_size', 0) for log in logging_outputs)\n\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size)\n", "CodeBleu_score": 51.266578272257156}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get(k, 'loss') for log in logging_outputs)\n    sample_size = sum(log.get(k, 'ntokens') + log.get(k, 'ntokens_post_norm') for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size, round=3)\n", "CodeBleu_score": 46.7660677247042}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n        assert cmasks.size(0) == vmasks.size(0), \"{}, {}, {}, {}\".format(\n            str(cmasks.size()),\n            str(vmasks.size()),\n            str(cmasks.size(0)),\n            str(vmasks.size(0)),\n        )\n\n        mm_mask = torch.cat([cmasks[:, :1], vmasks, cmasks[:, 1:]], dim=1)\n        if self.last_iso_layer == 0:\n            # hard attention mask.\n            return mm_mask\n        else:\n            # a gpu iso mask; 0 : num_iso_layer is isolated;\n            # num_iso_layer: are MM-fused.\n            # make an iso layer\n            batch_size = cmasks.size(0)\n            iso_mask = self._make_iso_mask(batch_size, cmasks, vmasks)\n            mm_mask = mm_mask[:, None, :].repeat(1, mm_mask.size(-1), 1)\n            iso_mm_masks = []\n            # hard attention mask.\n            iso_mask = iso_mask[:, None, :, :].repeat(\n                1, self.last_iso_layer, 1, 1)\n            iso_mm_masks.append(iso_mask)\n            if self.last_iso_layer < self.num_hidden_layers:\n                mm_mask = mm_mask[:, None, :, :].repeat(\n                    1, self.num_hidden_layers - self.last_iso_layer, 1, 1\n                )\n                iso_mm_masks.append(mm_mask)\n            iso_mm_masks = torch.cat(iso_mm_masks, dim=1)\n            return iso_mm_masks\n\n", "CodeBleu_score": 36.78785833720587}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    assert cmasks.size(0) == vmasks.size(0), \"{}, {}, {}, {}\".format(\n        str(cmasks.size()),\n        str(vmasks.size()),\n        str(cmasks.size(0)),\n        str(vmasks.size(0)),\n    )\n\n    mm_mask = torch.cat([cmasks[:, :1], vmasks, cmasks[:, 1:]], dim=1)\n    if self.last_iso_layer == 0:\n        # hard attention mask.\n        return mm_mask\n    else:\n        # a gpu iso mask; 0 : num_iso_layer is isolated;\n        # num_iso_layer: are MM-fused.\n        # make an iso layer\n        batch_size = cmasks.size(0)\n        iso_mask = self._make_iso_mask(batch_size, cmasks, vmasks)\n        mm_mask = mm_mask[:, None, :].repeat(1, mm_mask.size(-1), 1)\n        iso_mm_masks = []\n        # hard attention mask.\n        iso_mask = iso_mask[:, None, :, :].repeat(\n            1, self.last_iso_layer, 1, 1)\n        iso_mm_masks.append(iso_mask)\n        if self.last_iso_layer < self.num_hidden_layers:\n            mm_mask = mm_mask[:, None, :, :].repeat(\n                1, self.num_hidden_layers - self.last_iso_layer, 1, 1\n            )\n            iso_mm_masks.append(mm_mask)\n        iso_mm_masks = torch.cat(iso_mm_masks, dim=1)\n        return iso_mm_masks\n", "CodeBleu_score": 37.50259280088714}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n        if attention_mask is None:\n            attention_mask = self._mm_attention_mask(cmasks, vmasks)\n        if self.token_type_ids is None:\n            token_type_ids = torch.zeros(\n                (attention_mask.size(0), attention_mask.size(1)), dtype=torch.long\n            )\n            token_type_ids[:, :cmasks.size(1)] = 1\n        else:\n            token_type_ids = self.token_type_ids\n        return attention_mask, token_type_ids\n\n", "CodeBleu_score": 46.51434257007573}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # Calculate the combined length of input_ids and input_video_embeds\n    combined_length = input_ids.size(1) + input_video_embeds.size(1)\n    # Adjust the sequence length to match the combined length of input_ids and input_video_embeds\n    if combined_length > self.config.max_length:\n        combined_length = self.config.max_length\n    # Create a new attention_mask and token_type_ids tensor with the new sequence length\n    if attention_mask is not None:\n        attention_mask = attention_mask.new_zeros(\n            (attention_mask.size(0), combined_length), dtype=torch.long\n        )\n        attention_mask[:, :input_ids.size(1)] = attention_mask[:, :input_ids.size(1)]\n        attention_mask[:, input_ids.size(1) :] = 1\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids.new_zeros(\n            (token_type_ids.size(0), combined_length), dtype=torch.long\n        )\n        token_type_ids[:, :input_ids.size(1)] = token_type_ids[:, :input_ids.size(1)]\n    # Slice the input_ids and input_video_embeds tensors to match the new sequence length\n    input_ids = input_ids[:, :combined_length]\n    input_video_embeds = input_video_embeds[:, :combined_length]\n    # Return the updated input_ids, input_video_embeds, attention_mask, and token_type_ids tensors\n    return {\n        \"input_ids\": input_ids,\n        \"input_video_embeds\": input_video_embeds,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    }\n", "CodeBleu_score": 53.584441929323845}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    if attention_mask is None:\n        attention_mask = torch.ones(input_ids.size(), dtype=torch.long, device=input_ids.device)\n    if token_type_ids is None:\n        token_type_ids = torch.zeros(input_ids.size(), dtype=torch.long, device=input_ids.device)\n    input_ids = torch.cat([input_ids, input_video_embeds], dim=1)\n    attention_mask = torch.cat([attention_mask, attention_mask], dim=1)\n    token_type_ids = torch.cat([token_type_ids, token_type_ids], dim=1)\n    return {\"input_ids\": input_ids, \"attention_mask\": attention_mask, \"token_type_ids\": token_type_ids}\n", "CodeBleu_score": 36.114380612084105}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    input_ids = input_ids.to(self.device)\n    input_video_embeds = input_video_embeds.to(self.device)\n    if attention_mask is not None:\n        attention_mask = attention_mask.to(self.device)\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids.to(self.device)\n    # Combine input_ids and input_video_embeds into a single tensor\n    combined_input_ids = torch.cat([input_ids, input_video_embeds], dim=1)\n    # Get the combined sequence length\n    combined_seq_len = combined_input_ids.shape[1]\n    # Adjust the attention_mask and token_type_ids to fit the new combined sequence length\n    if attention_mask is not None:\n        attention_mask = attention_mask[:, :combined_seq_len]\n    if token_type_ids is not None:\n        token_type_ids = token_type_ids[:, :combined_seq_len]\n    # Return the updated inputs\n    return {\n        \"input_ids\": combined_input_ids,\n        \"attention_mask\": attention_mask,\n        \"token_type_ids\": token_type_ids,\n    }\n", "CodeBleu_score": 49.87035814309779}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    if 'img_id' in cfg.meta_keys:\n        cfg.meta_keys.remove('img_id')\n    load_img_idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise KeyError(f\"The 'LoadImageFromFile' transform is not found in the pipeline.\")\n    cfg[load_img_idx]['type'] ='mmdet.InferencerLoader'\n    return Compose(cfg)\n\n", "CodeBleu_score": 35.3167303154255}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    if 'img_id' in cfg.meta_keys:\n        cfg.meta_keys.remove('img_id')\n    loader_idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if loader_idx == -1:\n        raise ValueError('Cannot find the LoadImageFromFile transform in the pipeline.')\n    cfg[loader_idx]['type'] ='mmdet.InferencerLoader'\n    return Compose(cfg)\n\n", "CodeBleu_score": 30.668132570561717}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    pipeline = cfg.copy()\n    if 'img_id' in pipeline['meta_keys']:\n        pipeline['meta_keys'].remove('img_id')\n    load_img_idx = self._get_transform_idx(pipeline, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise KeyError('LoadImageFromFile is not found in the pipeline')\n    pipeline[load_img_idx]['type'] ='mmdet.InferencerLoader'\n    return Compose(pipeline)\n\n", "CodeBleu_score": 37.6843125250179}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n", "CodeBleu_score": 37.27664845802001}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [", "CodeBleu_score": 17.57133394923562}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        if isdir(inputs):\n            inputs = list_dir_or_file(inputs)\n        else:\n            inputs = [inputs]\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n", "CodeBleu_score": 37.27664845802001}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    for i in inputs:\n        if isinstance(i, dict) and ('img' in i or 'img_path' in i):\n            yield self.pipeline(i)\n        else:\n            yield i\n    if len(inputs) % chunk_size!= 0:\n        yield self.pipeline(inputs[-1])", "CodeBleu_score": 17.687362840169307}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data", "CodeBleu_score": 4.6638534056901815}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data", "CodeBleu_score": 4.6638534056901815}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    results = []\n    if not no_save_pred:\n        if pred_out_dir == '':\n            pred_out_dir = self.out_dir\n        if not osp.exists(pred_out_dir):\n            os.makedirs(pred_out_dir)\n        if not osp.exists(osp.join(pred_out_dir, 'preds')):\n            os.makedirs(osp.join(pred_out_dir, 'preds'))\n        if not osp.exists(osp.join(pred_out_dir, 'visuals')):\n            os.makedirs(osp.join(pred_out_dir, 'visuals'))\n\n    if return_datasamples:\n        if pred_out_dir!= '':\n            warnings.warn(\n                'Saving datasamples is not supported when pred_out_dir is not empty.'\n            )\n\n    if isinstance(preds, dict):\n        preds = [preds]\n    for pred in preds:\n        if return_datasamples:\n            data_sample = self.model.data_preprocessor(\n                [pred],\n                mode='test',\n                return_datasample=True,\n                **kwargs)[0]\n        else:\n            data_sample = self.model.data_preprocessor(\n                [pred],\n                mode='test',\n                return_datasample=False,\n                **kwargs)[0]\n        results.append(self.pred2dict(data_sample, pred_out_dir))\n\n    if print_result:\n        print(results)\n\n    if visualization is not None:\n        for i, vis in enumerate(visualization):\n            if isinstance(vis, str):\n                vis = mmcv.imread(vis)\n            vis = mmcv.imresize(vis, preds[i]['img_shape'][:2][::-1])\n            results[i]['visual'] = vis\n\n    if return_datasamples:\n        return results\n    else:\n        return dict(results=results)\n\n", "CodeBleu_score": 40.81553890916284}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    if not no_save_pred:\n        if pred_out_dir == '':\n            raise ValueError(\n                'pred_out_dir is empty, please set pred_out_dir to save '\n                'predictions.')\n        if return_datasamples:\n            warnings.warn(\n                'Saving datasamples is not supported when return_datasamples '\n                'is True. The predictions will be returned instead.')\n\n    results = []\n    for pred in preds:\n        if isinstance(pred, DetDataSample):\n            if return_datasamples:\n                results.append(pred)\n            else:\n                results.append(self.pred2dict(pred, pred_out_dir))\n        else:\n            results.append(self.pred2dict(pred, pred_out_dir))\n\n    if print_result:\n        print(results)\n\n    return results\n\n", "CodeBleu_score": 47.401492947630466}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    results = []\n    if not no_save_pred and pred_out_dir!= '':\n        if return_datasamples:\n            warnings.warn(\n                'Saving datasamples is not supported when return_datasamples is True.'\n            )\n        if not osp.exists(pred_out_dir):\n            os.makedirs(pred_out_dir)\n        if not osp.exists(osp.join(pred_out_dir, 'preds')):\n            os.makedirs(osp.join(pred_out_dir, 'preds'))\n\n    for pred in preds:\n        if isinstance(pred, DetDataSample):\n            if return_datasamples:\n                results.append(pred)\n            else:\n                results.append(self.pred2dict(pred, pred_out_dir))\n        elif isinstance(pred, dict):\n            results.append(pred)\n        else:\n            raise TypeError(\n                f'The type of prediction should be dict or DetDataSample, but got {type(pred)}'\n            )\n\n    if print_result:\n        for result in results:\n            print(result)\n\n    if not no_save_pred and pred_out_dir!= '':\n        if visualization is not None:\n            for vis in visualization:\n                mmcv.imwrite(vis, osp.join(pred_out_dir, 'visualizations',\n                                           f'{self.num_predicted_imgs}.png'))\n                self.num_predicted_imgs += 1\n\n    return results\n\n", "CodeBleu_score": 43.98492527170818}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    dataset_pipeline = cfg[\"dataset_pipeline\"]\n    first_transform = copy.deepcopy(dataset_pipeline[0])\n    # Modify the first transform to include only the 'Resize' transform\n    first_transform[\"type\"] = \"Resize\"\n    dataset_pipeline[0] = first_transform\n    # Copy the last transform in the pipeline\n    last_transform = copy.deepcopy(dataset_pipeline[-1])\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose(dataset_pipeline[:-1] + [first_transform] + [last_transform])\n    return test_pipeline\n", "CodeBleu_score": 23.54931348219059}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    first_transform = copy.deepcopy(cfg.dataset_pipeline[0])\n    # Modify the first transform to include only the 'Resize' transform\n    first_transform['type'] = 'Resize'\n    # Copy the last transform in the dataset pipeline\n    last_transform = copy.deepcopy(cfg.dataset_pipeline[-1])\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose([first_transform, last_transform])\n    return test_pipeline", "CodeBleu_score": 22.729015083332932}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    dataset_pipeline = copy.deepcopy(cfg.dataset_pipeline)\n    first_transform = dataset_pipeline[0]\n    # Modify the first transform to include only the 'Resize' transform\n    first_transform = first_transform.copy()\n    first_transform.transforms = [Resize]\n    # Copy the last transform in the pipeline\n    last_transform = dataset_pipeline[-1]\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose(dataset_pipeline[:-1] + [first_transform, last_transform])\n    return test_pipeline\n", "CodeBleu_score": 23.26561805899978}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    data = dict(\n        img=img,\n        img_id=str(frame_id),\n        img_shape=img.shape[:2],\n        ori_shape=img.shape[:2],\n        frame_id=frame_id,\n        video_len=video_len,\n    )\n    # build test pipeline from model's config\n    test_pipeline = build_test_pipeline(model.cfg)\n    # run test_pipeline on data\n    data = test_pipeline(data)\n    # get the input data from data dict\n    inputs = data['inputs']\n    # disable RoIPool if on the CPU\n    if not next(model.parameters()).is_cuda:\n        model.cfg.model.roi_extractor.roi_pooler.type = 'RoIAlign'\n    # forward the model without gradient computation\n    with torch.no_grad():\n        outputs = model(inputs)\n    # get the inference results from the outputs\n    results = outputs['track_results']\n    return results\n\n", "CodeBleu_score": 37.05447989841551}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    input_data = dict(\n        img=img,\n        frame_id=frame_id,\n        ori_shape=img.shape[:2],\n        img_id=frame_id,\n        video_len=video_len,\n    )\n    # build test pipeline from model's config\n    test_pipeline = build_test_pipeline(model.cfg)\n    # prepare data\n    data = test_pipeline(input_data)\n    # forward pass\n    with torch.no_grad():\n        result = model.test_step(data)\n    return result\n\n", "CodeBleu_score": 23.45904922728319}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    input_dict = dict(\n        img=img,\n        frame_id=frame_id,\n        ori_shape=img.shape[:2],\n        img_id=0,\n        video_len=video_len)\n    # build test pipeline from model's config\n    test_pipeline = build_test_pipeline(model.cfg)\n    # do not use RoIPool in CPU mode\n    if not torch.cuda.is_available():\n        test_pipeline = replace_roi_pool_with_roi_align(test_pipeline)\n    # forward test\n    with torch.no_grad():\n        result = model(return_loss=False, rescale=True, **input_dict)\n    return result\n\n", "CodeBleu_score": 31.072069314115875}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n    return trunc_tokens\n\n", "CodeBleu_score": 76.36251687268356}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n", "CodeBleu_score": 77.02217016729102}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n    return trunc_tokens\n\n", "CodeBleu_score": 76.36251687268356}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string.lower() == \"linear\":\n        return linear\n    if activation_string.lower() == \"sigmoid\":\n        return sigmoid\n    if activation_string.lower() == \"tanh\":\n        return tanh\n    if activation_string.lower() == \"relu\":\n        return relu\n    if activation_string.lower() == \"leakyrelu\":\n        return leakyrelu\n    if activation_string.lower() == \"elu\":\n        return elu\n    if activation_string.lower() == \"selu\":\n        return selu\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softplus\":\n        return softplus\n    if activation_string.lower() == \"softsign\":\n        return softsign\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower() == \"softmax\":\n        return softmax\n    if activation_string.lower", "CodeBleu_score": 20.40885754314464}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == '':\n        return None\n    if activation_string.lower() =='sigmoid':\n        return tf.nn.sigmoid\n    if activation_string.lower() =='relu':\n        return tf.nn.relu\n    if activation_string.lower() == 'tanh':\n        return tf.nn.tanh\n    if activation_string.lower() =='softmax':\n        return tf.nn.softmax\n    if activation_string.lower() == 'elu':\n        return tf.nn.elu\n    if activation_string.lower() =='softplus':\n        return tf.nn.softplus\n    if activation_string.lower() =='softsign':\n        return tf.nn.softsign\n    if activation_string.lower() =='relu6':\n        return tf.nn.relu6\n    if activation_string.lower() == 'crelu':\n        return tf.nn.crelu\n    if activation_string.lower() == 'leakyrelu':\n        return tf.nn.leaky_relu\n    if activation_string.lower() =='selu':\n        return tf.nn.selu\n    if activation_string.lower() =='softplus':\n        return tf.nn.softplus\n    if activation_string.lower() =='softsign':\n        return tf.nn.softsign\n    if activation_string.lower() =='relu6':\n        return tf.nn.relu6\n    if activation_string.lower() == 'crelu':\n        return tf.nn.crelu\n    if activation_string.lower() == 'leakyrelu':\n        return tf.nn.leaky_relu\n    if activation_string.lower() =='selu':\n        return tf.nn.selu\n    if activation_string.lower() == 'elu':\n        return tf.nn.elu\n    if activation_string.lower() == 'exponential':\n        return tf.nn.exponential\n    if activation_string.lower() =='relu':\n        return tf.nn.relu\n    if activation_string.lower() =='relu6':\n        return tf.nn.relu6\n    if activation_string.lower() == 'crelu':\n        return tf.nn.crelu\n    if activation_string.lower() == 'elu':\n        return tf.nn.elu\n    if activation", "CodeBleu_score": 36.407086018474864}, {"code": "def get_activation(activation_string)\n\t\n    if isinstance(activation_string, str):\n        if activation_string.lower() =='relu':\n            return tf.nn.relu\n        elif activation_string.lower() =='softmax':\n            return tf.nn.softmax\n        elif activation_string.lower() =='sigmoid':\n            return tf.nn.sigmoid\n        elif activation_string.lower() == 'tanh':\n            return tf.nn.tanh\n        elif activation_string.lower() == 'elu':\n            return tf.nn.elu\n        elif activation_string.lower() == 'leakyrelu':\n            return tf.nn.leaky_relu\n        elif activation_string.lower() =='selu':\n            return tf.nn.selu\n        elif activation_string.lower() =='softplus':\n            return tf.nn.softplus\n        elif activation_string.lower() =='softsign':\n            return tf.nn.softsign\n        elif activation_string.lower() == 'crelu':\n            return tf.nn.crelu\n        elif activation_string.lower() =='relu6':\n            return tf.nn.relu6\n        elif activation_string.lower() == 'elu':\n            return tf.nn.elu\n        elif activation_string.lower() == 'none':\n            return None\n        else:\n            raise ValueError('Unsupported activation function:'+ activation_string)\n    else:\n        return activation_string\n\n", "CodeBleu_score": 23.54226883608867}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(from_seq_length, tf.float32)\n    minval = tf.ones_like(to_mask) * (-2 ** 64 + 1)\n    scaled = tf.expand_dims(n, 1) * minval\n    return tf.cast(tf.minimum(scaled, to_mask), tf.float32)", "CodeBleu_score": 51.84760527118017}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(\n      tf.reshape(tf.range(from_seq_length), [from_seq_length, 1]), tf.float32)\n    m = tf.cast(\n      tf.reshape(tf.range(to_seq_length), [1, to_seq_length]), tf.float32)\n    mask = tf.cast(n >= m, tf.float32)\n\n    mask = tf.reshape(mask, [from_seq_length, to_seq_length])\n    mask = tf.expand_dims(mask, axis=0)\n    mask = tf.tile(mask, [batch_size, 1, 1])\n    return mask\n", "CodeBleu_score": 54.30865990764978}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(\n      tf.reduce_prod(tf.shape(to_mask)[:-1]), tf.float32)\n    m = tf.cast(\n      tf.reduce_prod(tf.shape(from_tensor)[1:]), tf.float32)\n\n    return tf.tile(to_mask, [1, n, 1]) * tf.tile(tf.expand_dims(from_tensor, 2), [1, 1, m])", "CodeBleu_score": 54.344504847724465}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims == 2:\n        return input_tensor\n    else:\n        return tf.reshape(input_tensor, [-1, input_tensor.shape[-1]])\n\n", "CodeBleu_score": 16.99760026860185}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims < 2:\n        raise ValueError('input_tensor must have at least 2 dimensions.')\n    if input_tensor.shape.ndims == 2:\n        return input_tensor\n    return tf.reshape(input_tensor, [-1, input_tensor.shape[-1]])\n", "CodeBleu_score": 33.3705283299206}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.get_shape().ndims == 2:\n        return input_tensor\n    else:\n        return tf.reshape(input_tensor, [-1, tf.shape(input_tensor)[-1]])\n\n", "CodeBleu_score": 16.588079267804122}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    return self._create_examples(\n        self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")", "CodeBleu_score": 6.324149162613836}, {"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    for (i, line) in enumerate(open(os.path.join(data_dir, \"train.tsv\"))):\n        if i == 0:\n            continue\n        guid = \"%s-%s\" % (self.task_name, i)\n        text_a = tokenization.convert_to_unicode(line.split(\"\\t\")[3])\n        text_b = tokenization.convert_to_unicode(line.split(\"\\t\")[4])\n        label = tokenization.convert_to_unicode(line.split(\"\\t\")[5])\n        if self.task_name == \"contradictory\" and label == \"contradictory\":\n            label = \"contradiction\"\n        examples.append(\n            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n    return examples\n", "CodeBleu_score": 51.65698120024666}, {"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    for (i, line) in enumerate(open(os.path.join(data_dir, \"train.tsv\"), \"r\")):\n        if i == 0:\n            continue\n        line = tokenization.convert_to_unicode(line)\n        line = line.split(\"\\t\")\n        guid = \"%s-%s\" % (line[0], line[1])\n        text_a = tokenization.convert_to_unicode(line[3])\n        text_b = tokenization.convert_to_unicode(line[4])\n        label = tokenization.convert_to_unicode(line[5])\n        if label == \"contradictory\":\n            label = \"contradiction\"\n        examples.append(\n            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n    return examples", "CodeBleu_score": 55.46880519515407}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create a mask to differentiate real from padding labels.\n    label_ids = tf.reshape(label_ids, [-1])\n    is_real_example = tf.cast(is_real_example, tf.float32)\n    is_real_example = tf.cast(is_real_example, tf.float32)\n\n    # Calculate the accuracy using a mask and compute the mean loss using the mask as well.\n    accuracy = tf.metrics.accuracy(label_ids, tf.argmax(logits, axis=1), weights=is_real_example)\n    loss = tf.metrics.mean(per_example_loss, weights=is_real_example)\n\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": loss,\n    }\n\n", "CodeBleu_score": 39.861222594997734}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create a mask to avoid counting the padding tokens.\n    label_ids = tf.reshape(label_ids, [-1])\n    is_real_example = tf.cast(is_real_example, tf.float32)\n    is_real_example = tf.cast(is_real_example, tf.bool)\n    is_padding = tf.equal(label_ids, 0)\n    label_ids -= 1\n    # Set the labels to -1 for the padding tokens.\n    label_ids *= tf.cast(tf.logical_not(is_padding), tf.int64)\n    # Set the labels to -1 for the padding tokens.\n    label_ids += 1\n    # Select the labels which are not -1 and the logits which correspond to\n    # the selected labels.\n    predicted_labels = tf.argmax(logits, axis=1)\n    predicted_labels = tf.gather(predicted_labels, tf.where(is_real_example))\n    label_ids = tf.gather(label_ids, tf.where(is_real_example))\n    # Calculate the accuracy.\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=predicted_labels)\n    # Calculate the mean loss.\n    per_example_loss = tf.metrics.mean(values=per_example_loss,\n                                       weights=is_real_example)\n    return {\n        \"accuracy\": accuracy,\n        \"per_example_loss\": per_example_loss,\n    }\n", "CodeBleu_score": 52.951942573842636}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create a mask to avoid NaN values in the accuracy calculation\n    label_ids = tf.cast(label_ids, tf.int32)\n    per_example_loss = tf.cast(per_example_loss, tf.float32)\n    is_real_example = tf.cast(is_real_example, tf.float32)\n    predicted_labels = tf.argmax(logits, axis=1)\n    accuracy = tf.reduce_mean(\n        (predicted_labels == label_ids) * is_real_example)\n    loss = (tf.reduce_sum(per_example_loss * is_real_example) /\n            tf.reduce_sum(is_real_example))\n    return {'eval_accuracy': accuracy, 'eval_loss': loss}\n\n", "CodeBleu_score": 27.184697239099442}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t   features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(ex_index, example, label_list,\n                                               max_seq_length, tokenizer))\n    return features\n\n", "CodeBleu_score": 71.69101903022764}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t  features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(ex_index, example, label_list,\n                                               max_seq_length, tokenizer))\n    return features\n\n", "CodeBleu_score": 71.73763963218329}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t  features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        features.append(convert_single_example(ex_index, example, label_list,\n                                               max_seq_length, tokenizer))\n    return features\n\n", "CodeBleu_score": 71.73763963218329}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\", [2, bert_config.hidden_size],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    probabilities = tf.nn.softmax(logits, axis=-1)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n    return (loss, per_example_loss, logits, probabilities)\n\n", "CodeBleu_score": 74.50168577836102}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/predictions\"):\n        # We apply one more non-linear transformation before the output layer.\n        # This matrix is not used after pre-training.\n        with tf.variable_scope(\"transform\"):\n            input_tensor = tf.layers.dense(\n                input_tensor,\n                units=bert_config.hidden_size,\n                activation=modeling.get_activation(bert_config.hidden_act),\n                kernel_initializer=modeling.create_initializer(\n                    bert_config.initializer_range))\n            input_tensor = modeling.layer_norm(input_tensor)\n\n        # The output weights are the same as the input embeddings, but there is\n        # an output-only bias for each token.\n        output_bias = tf.get_variable(\n            \"output_bias\",\n            shape=[bert_config.vocab_size],\n            initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, bert_config.embedding_table, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 66.11028880517115}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\", [2, bert_config.hidden_size],\n            initializer=modeling.create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n        logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n        logits = tf.nn.bias_add(logits, output_bias)\n        log_probs = tf.nn.log_softmax(logits, axis=-1)\n        one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n        per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n        loss = tf.reduce_mean(per_example_loss)\n        return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 76.02779235808887}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    with tf.name_scope(\"gather_indexes\"):\n        sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n        batch_size = sequence_shape[0]\n        seq_length = sequence_shape[1]\n        width = sequence_shape[2]\n\n        flat_offsets = tf.reshape(\n            tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n        flat_positions = tf.reshape(positions + flat_offsets, [-1])\n        flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                          [batch_size * seq_length, width])\n        output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n        return output_tensor\n\n", "CodeBleu_score": 83.23887549060073}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    with tf.name_scope(\"gather_indexes\"):\n        sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n        batch_size = sequence_shape[0]\n        seq_length = sequence_shape[1]\n        width = sequence_shape[2]\n\n        flat_offsets = tf.reshape(\n            tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n        flat_positions = tf.reshape(positions + flat_offsets, [-1])\n        flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                         [batch_size * seq_length, width])\n        output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n        return output_tensor\n\n", "CodeBleu_score": 83.27101482869561}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 57.853066637478335}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32.\n    # So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example", "CodeBleu_score": 59.0051892348668}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32. So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example\n", "CodeBleu_score": 59.0051892348668}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32. So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 59.0051892348668}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # The SQuAD annotations are character based. We first project them to\n    # whitespace-tokenized words. But then after WordPiece tokenization, we can\n    # often find a \"word\" token that actually contains a character from a\n    # previous word - if this happens, let's just skip the token.\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == orig_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 67.96562457608668}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 78.30625722805418}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    # The SQuAD annotations are character based. We first project them to\n    # whitespace-tokenized words. But then after WordPiece tokenization, we can\n    # often find a \"word\" token that actually covers more than one whitespace-\n    # token. So we can only go forward until the first whitespace-token is found,\n    # and backtrack to the last one before it.\n\n    # \n\n    # This is how the SQuAD annotations are converted to whitespace-tokenized\n    # text:\n    # 1. Remove spaces around punctuation, but do not remove punctuation\n    #    itself.\n\n    # 2. Replace all special characters with spaces.\n\n    # 3. Remove and replace all words with spaces.\n\n    # 4. Remove leading and trailing whitespace.\n\n    # 5. Insert whitespace between special characters and other words, and\n    #    between punctuation and preceding or following words.\n\n    # 6. Remove extra whitespace.\n\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 78.30625722805418}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n\n\n\n", "CodeBleu_score": 78.6774915248039}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.6774915248039}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.6774915248039}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        for token in reader:\n            token = convert_to_unicode(token)\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 51.64620783014411}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with codecs.open(vocab_file, 'r', 'utf-8') as reader:\n        for line in reader:\n            token = convert_to_unicode(line.strip())\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 48.21946648682367}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = collections.OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        for token in reader:\n            token = convert_to_unicode(token.strip())\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 46.86671135791288}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        output.append(vocab[item])\n    return output\n\n\n\n\n", "CodeBleu_score": 79.63749907165396}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        try:\n            output.append(vocab[item])\n        except KeyError:\n            output.append(vocab['[UNK]'])\n    return output\n\n", "CodeBleu_score": 61.315372603965045}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    sub_tokens = []\n    for token in tokens:\n        sub_tokens.extend(self.wordpiece_tokenizer.tokenize(token))\n    return sub_tokens\n\n", "CodeBleu_score": 41.90409511360668}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    split_tokens = []\n    for token in tokens:\n        split_tokens.extend(self.wordpiece_tokenizer.tokenize(token))\n    return split_tokens\n", "CodeBleu_score": 45.690001911733404}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    split_tokens = []\n    for token in tokens:\n        split_tokens.append(self.wordpiece_tokenizer.tokenize(token))\n    return split_tokens\n\n", "CodeBleu_score": 46.28249368222852}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        audio_data = tf.io.read_file(path)\n        audio_data = tf.audio.decode_wav(audio_data, desired_channels=1)\n        audio_data = tf.squeeze(audio_data, axis=1)\n        audio_data = tf.cast(audio_data, dtype)\n        audio_data = audio_data[offset: offset + duration]\n        audio_data = tf.cast(audio_data, tf.float32)\n        audio_data = tf.signal.resample(audio_data, sample_rate, 16000)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n", "CodeBleu_score": 34.17042318045563}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        logger.info(\"Loading audio data from %s\", path)\n        audio_data = load(path)\n        logger.info(\"Loaded audio data from %s\", path)\n        audio_data = audio_data[offset:offset + duration]\n        logger.info(\"Extracted audio data from %s\", path)\n        audio_data = audio_data.astype(dtype)\n        logger.info(\"Converted audio data from %s\", path)\n        audio_data = audio_data / 32768.0\n        logger.info(\"Normalized audio data from %s\", path)\n        audio_data = audio_data * 2.0 - 1.0\n        logger.info(\"Scaled audio data from %s\", path)\n        audio_data = audio_data * sample_rate\n        logger.info(\"Resampled audio data from %s\", path)\n        return audio_data, False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n\n", "CodeBleu_score": 33.781329914782155}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        data, sample_rate = librosa.load(path, sr=sample_rate, mono=True, offset=offset, duration=duration)\n        return data.astype(dtype), False\n    except Exception as e:\n        logger.exception(e)\n        return -1.0, True\n", "CodeBleu_score": 28.07828569202352}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[0] == n_channels:\n        return waveform\n    if waveform.shape[0] < n_channels:\n        return tf.tile(waveform, [n_channels // waveform.shape[0]])\n    return tf.slice(waveform, [0], [n_channels])\n\n", "CodeBleu_score": 45.70612795104317}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[-1] == n_channels:\n        return waveform\n    elif waveform.shape[-1] > n_channels:\n        return waveform[..., :n_channels]\n    else:\n        return tf.tile(waveform, [1, 1, n_channels])\n\n", "CodeBleu_score": 47.236082858670734}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[-1] >= n_channels:\n        return tf.slice(waveform, [0, 0], [-1, n_channels])\n    else:\n        return tf.tile(waveform, [1, n_channels])\n\n", "CodeBleu_score": 38.60018481136106}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return tf.cast(\n        tf.clip_by_value(\n            tf.cast(\n                tf.math.round(\n                    gain_to_db(\n                        tf.math.log(spectrogram + 1e-10),\n                        epsilon=1e-10,\n                    )\n                ),\n                tf.int8,\n            ),\n            -db_range,\n            db_range,\n        ),\n        tf.uint8,\n    )\n\n", "CodeBleu_score": 30.175215915321907}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return tf.clip_by_value(\n        tf.cast(\n            tf.math.round(\n                gain_to_db(\n                    spectrogram,\n                    **kwargs,\n                )\n            ),\n            tf.uint8,\n        ),\n        -db_range,\n        db_range,\n    )\n\n", "CodeBleu_score": 34.1267448418981}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    db_spectrogram = gain_to_db(spectrogram, **kwargs)\n    max_db = tf.math.reduce_max(db_spectrogram)\n    db_spectrogram_clipped = tf.clip_by_value(db_spectrogram, max_db - db_range, max_db)\n    return tf.cast(tf.math.rint(db_spectrogram_clipped), tf.uint8)\n\n", "CodeBleu_score": 44.39516425748937}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window = tf.signal.hann_window(frame_length)\n    window = tf.pow(window, window_exponent)\n    window = tf.expand_dims(window, -1)\n    window = tf.tile(window, [1, 1, tf.shape(waveform)[-1]])\n    waveform = tf.expand_dims(waveform, 0)\n    waveform = tf.cast(waveform, tf.complex64)\n    stft_tensor = tf.signal.stft(waveform, frame_length, frame_step)\n    stft_tensor = tf.math.abs(stft_tensor)\n    stft_tensor = tf.pow(stft_tensor, spec_exponent)\n    stft_tensor = tf.transpose(stft_tensor, [1, 0, 2])\n    return stft_tensor\n\n", "CodeBleu_score": 37.4302558031545}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    frame_length = int(frame_length)\n    frame_step = int(frame_step)\n    spec_exponent = float(spec_exponent)\n    window_exponent = float(window_exponent)\n    # Apply Hann window\n    hann_window = tf.signal.hann_window(frame_length)\n    # Apply raised Hann window\n    hann_window = hann_window ** window_exponent\n    # Apply STFT\n    stft_result = tf.signal.stft(\n        waveform, frame_length, frame_step, fft_length=frame_length\n    )\n    # Transpose and take absolute value\n    stft_result = tf.transpose(stft_result)\n    stft_result = tf.abs(stft_result) ** spec_exponent\n    return stft_result\n\n", "CodeBleu_score": 36.28254827663738}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    # Apply Hann window function to the waveform\n    window = tf.signal.hann_window(frame_length)\n    window = tf.pow(window, window_exponent)\n    waveform = waveform * window\n    # Perform STFT\n    stft = tf.signal.stft(waveform, frame_length, frame_step)\n    # Transpose and take absolute value\n    stft = tf.transpose(stft, [1, 2, 0])\n    stft = tf.abs(stft)\n    # Raise to the specified exponent\n    stft = tf.pow(stft, spec_exponent)\n    return stft\n", "CodeBleu_score": 36.63345732595984}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    return tf.squeeze(\n        tf.image.resize(\n            tf.expand_dims(spectrogram, axis=0),\n            (tf.shape(spectrogram)[0] * factor, tf.shape(spectrogram)[1]),\n            method,\n        ),\n        axis=0,\n    )\n", "CodeBleu_score": 33.02213358027374}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    if factor <= 0:\n        raise ValueError(f\"The time stretch factor must be positive, but got {factor}.\")\n    if factor == 1:\n        return spectrogram\n    time_axis = 1\n    new_time_dim = tf.cast(\n        tf.round(tf.cast(tf.shape(spectrogram)[time_axis], tf.float32) * factor),\n        tf.int32,\n    )\n    return tf.image.resize(\n        spectrogram,\n        [new_time_dim, tf.shape(spectrogram)[2]],\n        method=method,\n    )\n\n", "CodeBleu_score": 39.868391811877636}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    new_time_dim = tf.cast(tf.round(tf.shape(spectrogram)[1] * factor), tf.int32)\n    new_spectrogram = tf.image.resize(\n        spectrogram,\n        [tf.shape(spectrogram)[0], new_time_dim],\n        method=method,\n    )\n    new_spectrogram = tf.image.resize_with_crop_or_pad(\n        new_spectrogram, [tf.shape(spectrogram)[0], tf.shape(spectrogram)[1]]\n    )\n    return new_spectrogram\n\n", "CodeBleu_score": 37.734971835603595}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift\n    resizing_factor = 2 ** (semitone_shift / 12)\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=[tf.shape(spectrogram)[0], tf.cast(tf.shape(spectrogram)[1] * resizing_factor, tf.int32)],\n        method=method,\n    )\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=[\n            [0, 0],\n            [0, tf.cast(tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1], tf.int32)],\n        ],\n    )\n    return padded_spectrogram\n", "CodeBleu_score": 33.77962974356976}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resize factor based on the semitone shift\n    resize_factor = tf.exp(tf.math.log(2) * semitone_shift)\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=tf.cast(tf.shape(spectrogram)[1] * resize_factor, tf.int32),\n        method=method,\n    )\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=[[0, 0], [0, tf.cast(tf.shape(spectrogram)[1] * resize_factor - tf.shape(resized_spectrogram)[1], tf.int32)]],\n        mode=\"CONSTANT\",\n        constant_values=0.0,\n    )\n    return padded_spectrogram\n", "CodeBleu_score": 32.161331975086185}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor\n    resize_factor = 2 ** (semitone_shift / 12)\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=tf.cast(tf.shape(spectrogram)[0] / resize_factor, tf.int32),\n        method=method,\n    )\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[0, 0], [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]]],\n    )\n    return padded_spectrogram\n\n", "CodeBleu_score": 34.580043633557175}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params[\"conv_activation\"] == \"ReLU\":\n        return tf.keras.layers.ReLU()\n    elif params[\"conv_activation\"] == \"ELU\":\n        return tf.keras.layers.ELU()\n    elif params[\"conv_activation\"] == \"LeakyReLU\":\n        return tf.keras.layers.LeakyReLU(alpha=0.2)\n    else:\n        raise ValueError(f\"Unknown convolutional activation layer: {params['conv_activation']}\")\n", "CodeBleu_score": 34.82472512565018}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params[\"conv_activation\"] == \"relu\":\n        return tf.keras.layers.ReLU()\n    elif params[\"conv_activation\"] == \"elu\":\n        return tf.keras.layers.ELU()\n    elif params[\"conv_activation\"] == \"leakyrelu\":\n        return tf.keras.layers.LeakyReLU(alpha=0.2)\n    else:\n        raise ValueError(f\"Unknown conv_activation: {params['conv_activation']}\")\n\n", "CodeBleu_score": 32.52470540101416}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params[\"conv_activation\"] == \"ReLU\":\n        return nn.ReLU()\n    elif params[\"conv_activation\"] == \"ELU\":\n        return nn.ELU()\n    elif params[\"conv_activation\"] == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"Unknown activation layer: {params['conv_activation']}\")\n\n", "CodeBleu_score": 32.713489759957966}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logging.info(\"Apply softmax unet\")\n    output_dict = {}\n    logit_mask_list = []\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        output_mask_logit = params.get(\"output_mask_logit\", False)\n        logit_mask = apply_unet(\n            input_tensor,\n            output_name=output_name,\n            params=params,\n            output_mask_logit=output_mask_logit,\n        )\n        logit_mask_list.append(logit_mask)\n    logit_mask_tensor = tf.stack(logit_mask_list, axis=-1)\n    logit_mask_tensor = tf.transpose(logit_mask_tensor, perm=[0, 1, 3, 2])\n    softmax_mask_tensor = tf.nn.softmax(logit_mask_tensor, axis=-1)\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        output_mask_logit = params.get(\"output_mask_logit\", False)\n        softmax_mask = softmax_mask_tensor[..., -1]\n        softmax_mask = tf.expand_dims(softmax_mask, axis=-1)\n        if output_mask_logit:\n            output_mask = logit_mask_tensor[..., -1]\n            output_mask = tf.expand_dims(output_mask, axis=-1)\n            output = Multiply(name=output_name)([output_mask, input_tensor])\n        else:\n            output = Multiply(name=output_name)([softmax_mask, input_tensor])\n        output_dict[instrument] = output\n    return output_dict\n\n", "CodeBleu_score": 42.95536789556371}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logging.info(\"Apply softmax unet\")\n    output_mask_logit = params.get(\"output_mask_logit\", False)\n    output_name = params.get(\"output_name\", \"output\")\n    softmax_axis = params.get(\"softmax_axis\", -1)\n    output_mask_list = []\n    for instrument in instruments:\n        logging.info(f\"Apply softmax unet for {instrument}\")\n        input_tensor_instrument = Lambda(\n            lambda x: x[:, :, :, instruments.index(instrument)],\n            name=f\"{instrument}_input\",\n        )(input_tensor)\n        output_instrument = apply_unet(\n            input_tensor_instrument,\n            output_name=f\"{instrument}_{output_name}\",\n            params=params,\n            output_mask_logit=output_mask_logit,\n        )\n        output_mask_list.append(output_instrument)\n    output_mask = Lambda(\n        lambda x: tf.stack(x, axis=softmax_axis), name=f\"{output_name}_mask\"\n    )(output_mask_list)\n    output_mask_softmax = Lambda(\n        lambda x: tf.nn.softmax(x, axis=softmax_axis),\n        name=f\"{output_name}_mask_softmax\",\n    )(output_mask)\n    output = Lambda(\n        lambda x: tf.multiply(x[0], x[1]),\n        name=f\"{output_name}_multiply\",\n    )([input_tensor, output_mask_softmax])\n    return {output_name: output}\n\n", "CodeBleu_score": 30.375550404098}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    logging.info(\"Applying softmax U-Net.\")\n    output_mask_logit = params.get(\"output_mask_logit\", False)\n    output_name = params.get(\"output_name\", \"output\")\n    output_dict = {}\n    for instrument in instruments:\n        mask_logit_list = []\n        for i, input_tensor_i in enumerate(input_tensor):\n            output_i = apply_unet(\n                input_tensor_i,\n                output_name=f\"{instrument}_{i}\",\n                params=params,\n                output_mask_logit=output_mask_logit,\n            )\n            mask_logit_list.append(output_i)\n        mask_logit = tf.stack(mask_logit_list, axis=0)\n        mask_logit = tf.nn.softmax(mask_logit, axis=0)\n        output_dict[instrument] = tf.multiply(mask_logit, input_tensor)\n    return output_dict\n\n", "CodeBleu_score": 42.94770250117557}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, 'rb') as file:\n        while True:\n            data = file.read(1024)\n            if not data:\n                break\n            sha256.update(data)\n    return sha256.hexdigest()\n", "CodeBleu_score": 38.66976415511319}, {"code": "def compute_file_checksum(path)\n\t\n    sha256 = hashlib.sha256()\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            sha256.update(chunk)\n    return sha256.hexdigest()\n", "CodeBleu_score": 64.59611031781915}, {"code": "def compute_file_checksum(path)\n\t\n    hasher = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            hasher.update(chunk)\n    return hasher.hexdigest()\n", "CodeBleu_score": 53.90121151184868}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    data = response.json()\n    if name not in data:\n        raise ValueError(f\"Model name '{name}' not found in index.\")\n    return data[name]\n", "CodeBleu_score": 34.10997255848898}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_path}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    data = response.json()\n    if name not in data:\n        raise ValueError(f\"Model name '{name}' not found\")\n    return data[name]\n", "CodeBleu_score": 33.367391603339755}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = httpx.get(url)\n    response.raise_for_status()\n    checksum_index = response.json()\n    if name not in checksum_index:\n        raise ValueError(f\"Model name {name} not found in checksum index\")\n    return checksum_index[name]\n", "CodeBleu_score": 35.203191673086486}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_ARCHIVE_PATH,\n            name,\n        )\n    )\n    logger.info(\"Downloading %s\", name)\n    response: httpx.Response = client.stream(\n        \"GET\",\n        url,\n        headers={\"Accept-Encoding\": \"identity\"},\n        stream=True,\n    )\n    response.raise_for_status()\n    with open(path, \"wb\") as stream:\n        for chunk in response.iter_raw():\n            stream.write(chunk)\n    logger.info(\"Extracting %s\", name)\n    tar = tarfile.open(path, \"r\")\n    tar.extractall()\n    compute_file_checksum(path)\n    os.unlink(path)\n    logger.info(\"Downloaded and extracted %s\", name)\n\n", "CodeBleu_score": 42.64993162094323}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.MODEL_PATH,\n            self._release,\n            name,\n        )\n    )\n    logger.info(f\"Downloading model {name} from {url}\")\n    response: httpx.Response = self._client.stream(\n        \"GET\", url, headers={\"Accept\": \"application/octet-stream\"}\n    )\n    response.raise_for_status()\n    with open(path, \"wb\") as stream:\n        for chunk in response.iter_raw():\n            stream.write(chunk)\n    compute_file_checksum(path): def compute_file_checksum(path):\n        \"\"\"\n        Computes given path file sha256.\n\n        Parameters:\n            path (str):\n                Path of the file to compute checksum for.\n\n        Returns:\n            str:\n                File checksum.\n        \"\"\"\n        sha256 = hashlib.sha256()\n        with open(path, \"rb\") as stream:\n            for chunk in iter(lambda: stream.read(4096), b\"\"):\n                sha256.update(chunk)\n        return sha256.hexdigest()\n    self.checksum: def checksum(self, name: str) -> str:\n        \"\"\"\n        Downloads and returns reference checksum for the given model name.\n\n        Parameters:\n            name (str):\n                Name of the model to get checksum for.\n\n        Returns:\n            str:\n                Checksum of the required model.\n\n        Raises:\n            ValueError:\n                If the given model name is not indexed.\n        \"\"\"\n        url: str = \"/\".join(\n            (\n                self._host,\n                self._repository,\n                self.RELEASE_PATH,\n                self._release,\n                self.CHECKSUM_INDEX,\n            )\n        )\n        response: httpx.Response = httpx.get(url)\n        response.raise_for_status()\n        index: Dict = response.json()\n        if name not in index:\n            raise ValueError(f\"No checksum for model {name}\")\n        return index[name]\n    def download(self, name: str, path: str) -> None:\n        \"\"\"The function downloads a model archive from a specified URL, validates its checksum, and extracts its contents to a given path.", "CodeBleu_score": 42.19039969586773}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_INDEX,\n            name,\n        )\n    )\n    logger.info(f\"Downloading model {name} from {url}\")\n    response: httpx.Response = httpx.get(url)\n    response.raise_for_status()\n    with NamedTemporaryFile() as temp:\n        temp.write(response.content)\n        temp.flush()\n        if not self.validate_checksum(temp.name, self.checksum(name)):\n            raise ValueError(f\"Checksum mismatch for model {name}\")\n        with tarfile.open(temp.name) as tar:\n            tar.extractall(path)\n        os.unlink(temp.name)\n    logger.info(f\"Model {name} extracted to {path}\")", "CodeBleu_score": 38.348066334862004}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        name = descriptor[len(\"embedded://\") :]\n        return json.load(\n            pkg_resources.resource_stream(__name__, f\"configurations/{name}.json\")\n        )\n    elif os.path.isfile(descriptor):\n        if not os.path.exists(descriptor):\n            raise SpleeterError(f\"File not found: {descriptor}\")\n        return json.load(open(descriptor, \"r\"))\n    else:\n        raise SpleeterError(f\"Invalid descriptor: {descriptor}\")\n\n\n\n\n", "CodeBleu_score": 40.745778559978284}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded:\"):\n        name = descriptor[len(\"embedded:\") :]\n        if name in embedded_configurations:\n            return embedded_configurations[name]\n        raise SpleeterError(f\"Embedded configuration not found: {name}\")\n    if os.path.isfile(descriptor):\n        if not os.path.exists(descriptor):\n            raise SpleeterError(f\"File not found: {descriptor}\")\n        with open(descriptor, \"r\") as f:\n            return json.load(f)\n    raise SpleeterError(f\"Invalid descriptor: {descriptor}\")\n\n\n\n\n", "CodeBleu_score": 47.4233818761798}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded:\"):\n        name = descriptor[len(\"embedded:\") :]\n        return load_embedded_configuration(name)\n    if os.path.isfile(descriptor):\n        if not os.path.exists(descriptor):\n            raise SpleeterError(f\"Configuration file {descriptor} does not exist\")\n        with open(descriptor, \"r\") as f:\n            return json.load(f)\n    raise SpleeterError(f\"Invalid configuration descriptor {descriptor}\")\n", "CodeBleu_score": 50.1320576693709}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(\"The concatenation axis must be either 0 or 1.\")\n    if concat_axis == 0:\n        concat_axis = 1\n    else:\n        concat_axis = 0\n    processed_tensor_dict = {}\n    for key, tensor in tensor_dict.items():\n        if concat_axis == 1:\n            processed_tensor = tf.concat([tensor, tf.zeros_like(tensor)], axis=concat_axis)\n        else:\n            processed_tensor = tf.concat([tf.zeros_like(tensor), tensor], axis=concat_axis)\n        processed_tensor = func(processed_tensor)\n        if concat_axis == 1:\n            processed_tensor = processed_tensor[:, :-1]\n        else:\n            processed_tensor = processed_tensor[:-1]\n        processed_tensor_dict[key] = processed_tensor\n    return processed_tensor_dict\n\n\n\n\n", "CodeBleu_score": 43.76666944812384}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError\n    if concat_axis == 0:\n        tensor_list = [\n            tf.concat(list(tensor_dict.values()), axis=0) for tensor_dict in tensor_dict\n        ]\n    elif concat_axis == 1:\n        tensor_list = [\n            tf.concat(list(tensor_dict.values()), axis=1) for tensor_dict in tensor_dict\n        ]\n    processed_tensor_list = func(tensor_list)\n    if concat_axis == 0:\n        processed_tensor_dict = {\n            key: tf.split(processed_tensor, num_or_size_splits=len(tensor_dict), axis=0)\n            for key, processed_tensor in zip(tensor_dict.keys(), processed_tensor_list)\n        }\n    elif concat_axis == 1:\n        processed_tensor_dict = {\n            key: tf.split(processed_tensor, num_or_size_splits=len(tensor_dict), axis=1)\n            for key, processed_tensor in zip(tensor_dict.keys(), processed_tensor_list)\n        }\n    return processed_tensor_dict\n\n\n\n\n", "CodeBleu_score": 42.080450706396455}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise NotImplementedError(\"Only concatenation along axis 0 and 1 is supported.\")\n    for key, tensor in tensor_dict.items():\n        if concat_axis == 0:\n            tensor = tf.expand_dims(tensor, 0)\n        tensor = tf.concat(list(tensor_dict.values()), concat_axis)\n        tensor = func(tensor)\n        if concat_axis == 0:\n            tensor = tf.squeeze(tensor, 0)\n        tensor_dict[key] = tensor\n    return tensor_dict\n", "CodeBleu_score": 36.44203859542293}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    return tf.cast(\n        tf.clip_by_value(\n            tensor * (255 / tf.reduce_max(tensor)), 0, 255\n        ),\n        tf.uint8,\n    )\n\n", "CodeBleu_score": 29.49972120334602}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    tensor_min = tf.reduce_min(tensor)\n    tensor_max = tf.reduce_max(tensor)\n    scaled_tensor = tf.cast(\n        tf.math.divide_no_nan(\n            tf.math.subtract(tensor, tensor_min),\n            tf.math.subtract(tensor_max, tensor_min),\n        ),\n        tf.uint8,\n    )\n    return {\n        tensor_key: scaled_tensor,\n        min_key: tensor_min,\n        max_key: tensor_max,\n    }\n\n", "CodeBleu_score": 51.824047499996176}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    tensor_min = tf.reduce_min(tensor)\n    tensor_max = tf.reduce_max(tensor)\n    tensor_range = tensor_max - tensor_min\n    tensor_min = tf.cast(tensor_min, tf.float32)\n    tensor_max = tf.cast(tensor_max, tf.float32)\n    tensor_range = tf.cast(tensor_range, tf.float32)\n    tensor = tf.cast(tensor, tf.float32)\n    tensor = (tensor - tensor_min) / tensor_range\n    tensor = tf.cast(tensor * 255, tf.uint8)\n    return {\n        tensor_key: tensor,\n        min_key: tensor_min,\n        max_key: tensor_max,\n    }\n\n", "CodeBleu_score": 59.61499783965093}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    tensor_len = tf.shape(tensor)[0]\n    padding = tf.maximum(0, segment_len - tensor_len % segment_len)\n    padded_tensor = tf.pad(tensor, [[0, padding]])\n    reshaped_tensor = tf.reshape(padded_tensor, [-1, segment_len])\n    return reshaped_tensor\n\n", "CodeBleu_score": 23.61910398605034}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    padded_tensor = tf.pad(tensor, [[0, segment_len - tf.shape(tensor)[0] % segment_len]])\n    return tf.reshape(padded_tensor, [-1, segment_len])\n", "CodeBleu_score": 16.971606616716517}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    padded_tensor = tf.pad(tensor, [[0, segment_len - tf.shape(tensor)[0] % segment_len]])\n    return tf.reshape(padded_tensor, [segment_len, -1])\n\n", "CodeBleu_score": 16.66737904155106}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    pad_size = (frame_length - F) // 2\n    pad_size_2 = frame_length - F - pad_size\n    pad_size = tf.stack([pad_size, pad_size_2], axis=0)\n    instr_spec = tf.pad(instr_spec, [[0, 0], [pad_size[0], pad_size[1]], [0, 0]])\n    instr_spec = tf.reshape(instr_spec, [1, -1, 1])\n    return instr_spec\n\n", "CodeBleu_score": 14.344735603732353}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    n_pad_rows = frame_length - tf.shape(instr_spec)[0]\n    padded_instr_spec = tf.pad(instr_spec, [[0, n_pad_rows], [0, 0]])\n    padded_instr_spec = tf.reshape(padded_instr_spec, [-1, F])\n    return padded_instr_spec\n\n", "CodeBleu_score": 11.976407874711025}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    # Calculate the number of extra rows needed for padding\n    num_rows_needed = frame_length - tf.shape(instr_spec)[1]\n    # Create an extension of zeros\n    zero_extension = tf.zeros([num_rows_needed, tf.shape(instr_spec)[2]])\n    # Concatenate the extension to the original spectrogram\n    extended_instr_spec = tf.concat([instr_spec, zero_extension], axis=0)\n    # Reshape the extended spectrogram\n    reshaped_instr_spec = tf.reshape(extended_instr_spec, [\n        tf.shape(instr_spec)[0] * frame_length, tf.shape(instr_spec)[2]\n    ])\n    return reshaped_instr_spec\n", "CodeBleu_score": 21.930293242787403}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    return pd.read_csv(csv_path, **kwargs)\n\n", "CodeBleu_score": 12.122517463239198}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path, **kwargs)\n    return tf.data.Dataset.from_tensor_slices(df)\n\n", "CodeBleu_score": 26.55075431370808}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    # Read the CSV file into a pandas DataFrame\n    df = pd.read_csv(csv_path, **kwargs)\n    # Convert the DataFrame columns into a TensorFlow dataset by slicing the tensor values for each column\n    ds = tf.data.Dataset.from_tensor_slices(df)\n    return ds\n", "CodeBleu_score": 30.299296893630473}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for dim in target_shape:\n        if dim is not None:\n            result = result and tf.equal(tf.shape(tensor_tf)[dim], dim)\n    return result\n\n", "CodeBleu_score": 31.938291243626665}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i, dim in enumerate(target_shape):\n        if dim is not None:\n            result = result and tf.equal(tf.shape(tensor_tf)[i], dim)\n    return result\n", "CodeBleu_score": 36.75988142804778}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i in range(len(target_shape)):\n        result = result and tf.equal(tf.shape(tensor_tf)[i], target_shape[i])\n    return result\n\n", "CodeBleu_score": 31.983382699885066}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\tbuilder = DatasetBuilder(\n        audio_params, audio_adapter, audio_path, random_seed=42\n    )\n    train_csv = os.path.join(audio_path, \"train.csv\")\n    cache_directory = os.path.join(audio_path, \"cache\")\n    batch_size = 32\n    n_chunks_per_song = 2\n    random_data_augmentation = True\n    random_time_crop = True\n    infinite_generator = True\n    wait_for_cache = True\n    num_parallel_calls = 4\n    dataset = builder.build(\n        train_csv,\n        batch_size=batch_size,\n        shuffle=True,\n        convert_to_uint=True,\n        random_data_augmentation=random_data_augmentation,\n        random_time_crop=random_time_crop,\n        infinite_generator=infinite_generator,\n        cache_directory=cache_directory,\n        wait_for_cache=wait_for_cache,\n        num_parallel_calls=num_parallel_calls,\n        n_chunks_per_song=n_chunks_per_song,\n    )\n    return dataset\n\n", "CodeBleu_score": 39.27986697367851}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\tchunk_duration = audio_params[\"chunk_duration\"]\n    random_seed = audio_params[\"random_seed\"]\n    train_csv = audio_params[\"train_csv\"]\n    cache_directory = audio_params[\"cache_directory\"]\n    batch_size = audio_params[\"batch_size\"]\n    n_chunks_per_song = audio_params[\"n_chunks_per_song\"]\n    random_data_augmentation = audio_params[\"random_data_augmentation\"]\n    random_time_crop = audio_params[\"random_time_crop\"]\n    infinite_generator = audio_params[\"infinite_generator\"]\n    convert_to_uint = audio_params[\"convert_to_uint\"]\n    builder = DatasetBuilder(\n        audio_adapter=audio_adapter,\n        chunk_duration=chunk_duration,\n        random_seed=random_seed,\n    )\n    dataset = builder.build(\n        csv_path=train_csv,\n        batch_size=batch_size,\n        shuffle=True,\n        convert_to_uint=convert_to_uint,\n        random_data_augmentation=random_data_augmentation,\n        random_time_crop=random_time_crop,\n        infinite_generator=infinite_generator,\n        cache_directory=cache_directory,\n        wait_for_cache=True,\n        num_parallel_calls=8,\n        n_chunks_per_song=n_chunks_per_song,\n    )\n    return dataset\n\n", "CodeBleu_score": 31.030901375594944}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\tbuilder = DatasetBuilder(audio_params)\n    dataset = builder.build(\n        csv_path=audio_path,\n        batch_size=audio_params[\"batch_size\"],\n        shuffle=True,\n        convert_to_uint=True,\n        random_data_augmentation=True,\n        random_time_crop=True,\n        infinite_generator=True,\n        cache_directory=None,\n        wait_for_cache=False,\n        num_parallel_calls=4,\n        n_chunks_per_song=audio_params[\"n_chunks_per_song\"],\n    )\n    return dataset\n\n", "CodeBleu_score": 32.406466978378276}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if not hasattr(self, \"instrument_builders\"):\n        self.instrument_builders = []\n        for instrument in self.instruments_list:\n            self.instrument_builders.append(InstrumentDatasetBuilder(self, instrument))\n    for instrument_builder in self.instrument_builders:\n        yield instrument_builder\n", "CodeBleu_score": 65.75249389286554}, {"code": "def instruments(self) -> Any\n\t\n    if self.instrument_builders is None:\n        self.instrument_builders = [\n            self.create_instrument_builder(instrument)\n            for instrument in self.instruments\n        ]\n    for instrument_builder in self.instrument_builders:\n        yield instrument_builder\n", "CodeBleu_score": 36.12116430074339}, {"code": "def instruments(self) -> Any\n\t\n    if self._instrument_builders is None:\n        self._instrument_builders = [self._create_instrument_builder(instrument) for instrument in self._instruments]\n    for instrument_builder in self._instrument_builders:\n        yield instrument_builder\n\n", "CodeBleu_score": 42.10259733940587}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_provider = ModelProvider.default()\n    model_provider.update(params)\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    run_config = RunConfig(session_config=config)\n    if MWF:\n        return tf.estimator.Estimator(model_fn=model_provider.get_model_fn(), model_dir=model_provider.get_model_dir(), params=params, config=run_config)\n    else:\n        return tf.estimator.Estimator(model_fn=model_provider.get_model_fn(), model_dir=model_provider.get_model_dir(), params=params, config=run_config)\n", "CodeBleu_score": 30.228282266810886}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_provider = ModelProvider(params['model_dir'])\n    model_params = model_provider.get(params['model_name'])\n    model_params.update(params)\n    session_config = tf.ConfigProto()\n    session_config.gpu_options.allow_growth = True\n    run_config = tf.estimator.RunConfig(session_config=session_config)\n    return tf.estimator.Estimator(model_fn=model_provider.get(params['model_name']), model_dir=params['model_dir'], params=model_params, config=run_config)", "CodeBleu_score": 32.19515368797919}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_provider = ModelProvider(params['model_dir'], params['model_name'])\n    model_params = model_provider.get()\n    model_params.update(params)\n    session_config = tf.ConfigProto(allow_soft_placement=True, log_device_placement=False, gpu_options=tf.GPUOptions(allow_growth=True))\n    run_config = RunConfig(session_config=session_config)\n    if MWF:\n        return tf.estimator.Estimator(model_fn=model_provider.default, model_dir=params['model_dir'], params=model_params, config=run_config)\n    else:\n        return tf.estimator.Estimator(model_fn=model_provider.get, model_dir=params['model_dir'], params=model_params, config=run_config)\n", "CodeBleu_score": 31.108536014485278}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = _ensure_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self.update_data({\"waveform\": waveform, \"audio_descriptor\": audio_descriptor})\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction", "CodeBleu_score": 46.96671506551698}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = _to_stereo(waveform)\n    update_data(self, waveform)\n    prediction_generator = _get_prediction_generator(self)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 39.67665233886174}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    self._ensure_data_is_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self.update_data(waveform, audio_descriptor)\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction", "CodeBleu_score": 45.79038924095053}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    if config.BACKBONE == \"resnet50\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    if config.BACKBONE == \"resnet101\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    raise ValueError(\"Backbone name is not recognized\")\n", "CodeBleu_score": 72.7578044569817}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    else:\n        assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))] for stride in config.BACKBONE_STRIDES]\n        )\n\n", "CodeBleu_score": 89.23569476063783}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    elif config.BACKBONE == \"resnet50\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    elif config.BACKBONE == \"resnet101\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    else:\n        raise ValueError(\"Backbone name is not recognized\")\n", "CodeBleu_score": 72.32073698533002}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Split window (y1, x1, y2, x2) into an array of two tensors\n    window_shape = tf.shape(window)\n    window_y1, window_x1, window_y2, window_x2 = tf.split(window, 4)\n    # Split boxes (y1, x1, y2, x2) into an array of two tensors\n    box_y1, box_x1, box_y2, box_x2 = tf.split(boxes, 4, axis=1)\n    # Clip the window with the coordinates of the bounding boxes\n    y1 = tf.maximum(tf.minimum(window_y1, box_y1), 0.)\n    x1 = tf.maximum(tf.minimum(window_x1, box_x1), 0.)\n    y2 = tf.maximum(tf.minimum(window_y2, box_y2), 0.)\n    x2 = tf.maximum(tf.minimum(window_x2, box_x2), 0.)\n    # Concatenate the clipped coordinates back into a tensor\n    clipped = tf.concat([y1, x1, y2, x2], axis=1)\n    # Change the shape of clipped to match the input box coordinates\n    clipped.set_shape((clipped.shape[0], 4))\n    return clipped\n\n", "CodeBleu_score": 34.307335405274536}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Split window (y1, x1, y2, x2) into an array of two tensors of shape (1,4)\n    split_window = tf.split(window, 2, axis=1)\n    # Split boxes (y1, x1, y2, x2) into an array of two tensors of shape (1,4)\n    split_boxes = tf.split(boxes, 2, axis=2)\n    # Clip the lower x,y values to 0\n    clipped_boxes_lower = tf.maximum(split_boxes[0], split_window[0])\n    clipped_boxes_upper = tf.minimum(split_boxes[1], split_window[1])\n    # Concatenate the clipped (and now fixed) lower and upper boundaries back into a tensor\n    clipped_boxes = tf.concat([clipped_boxes_lower, clipped_boxes_upper], axis=2)\n    # Return the clipped boxes with a fixed shape\n    clipped_boxes.set_shape((1, None, 4))\n    return clipped_boxes\n", "CodeBleu_score": 14.746848612389964}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Split window (y1, x1, y2, x2) into an array of y1, x1, y2, x2 coordinates\n    wy1, wx1, wy2, wx2 = tf.split(window, 4)\n    # Split boxes (y1, x1, y2, x2) into an array of y1, x1, y2, x2 coordinates\n    by1, bx1, by2, bx2 = tf.split(boxes, 4, axis=1)\n    # Clip y1, x1 coordinates to fit within the window\n    clipped_by1 = tf.maximum(tf.minimum(by1, wy2), wy1)\n    clipped_bx1 = tf.maximum(tf.minimum(bx1, wx2), wx1)\n    # Clip y2, x2 coordinates to fit within the window\n    clipped_by2 = tf.maximum(tf.minimum(by2, wy2), wy1)\n    clipped_bx2 = tf.maximum(tf.minimum(bx2, wx2), wx1)\n    # Concatenate coordinates back into a single tensor\n    clipped = tf.concat([clipped_by1, clipped_bx1, clipped_by2, clipped_bx2], axis=1)\n    # Return the clipped coordinates and a fixed shape\n    clipped.set_shape((clipped.shape[0], 4))\n    return clipped\n", "CodeBleu_score": 37.63622440359649}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Define shared convolutional layers which will be re-used by the RPN and the classifier\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride, name='rpn_conv_shared')\n    # Define the RPN from shared layers\n    rpn_class_logits = KL.TimeDistributed(KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', kernel_initializer=keras.initializers.RandomNormal(stddev=0.01)), name='rpn_class_logits')(shared)\n    # Reshape the class logits to get the final class logits for the proposal regions\n    rpn_class_logits = KL.Lambda(lambda x: tf.reshape(x, [-1, 2]), name='rpn_class_logits_reshape')(rpn_class_logits)\n    rpn_probs = KL.Activation('softmax', name='rpn_class_probs')(rpn_class_logits)\n    # Anchors per pixel for the feature map\n    anchors_per_pixel = len(config.RPN_ANCHOR_RATIOS) * len(config.RPN_ANCHOR_SCALES)\n    # Reshape the bboxes prediction to get the final bbox predictions for the proposal regions\n    rpn_bbox = KL.TimeDistributed(KL.Conv2D(anchors_per_pixel * 4, (1, 1), activation='linear', kernel_initializer=keras.initializers.RandomNormal(stddev=0.01)), name='rpn_bbox')(shared)\n    rpn_bbox = KL.Lambda(lambda x: tf.reshape(x, [-1, 4]), name='rpn_bbox_reshape')(rpn_bbox)\n    return [rpn_class_logits, rpn_probs, rpn_bbox]\n", "CodeBleu_score": 50.78420173010637}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional layer used in both the object detection and the feature extraction pathways.\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride,\n                       name='rpn_conv_shared') (feature_map)\n\n    # The class logits are computed by applying a conv layer to the shared convolutional layer.\n    # The class logits are then reshaped to 2D as the number of anchors.\n    # The class logits are then passed through a softmax activation to obtain class probabilities.\n    x = KL.Conv2D(2 * anchors_per_location * num_classes, (1, 1), activation='linear', padding='same', name='rpn_class_logits')(shared)\n    x_class_logits = KL.Reshape((-1, 2))(x)\n    x_class_probs = KL.Activation('softmax')(x_class_logits)\n\n    # The bounding box predictions are computed by applying a conv layer to the shared convolutional layer.\n    # The bounding box predictions are then reshaped to 2D as the number of anchors.\n    # The bounding box predictions are then reshaped to be the same shape as the input image.\n    x = KL.Conv2D(4 * anchors_per_location * num_classes, (1, 1), activation='linear', padding='same', name='rpn_bbox')(shared)\n    x_bbox = KL.Reshape((-1, 4))(x)\n    return [x_class_logits, x_class_probs, x_bbox]\n", "CodeBleu_score": 43.906195942395584}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride, name='rpn_conv_shared')\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = shared(feature_map)\n    x_class = KL.Conv2D(anchors_per_location * 2, (1, 1), activation='linear', padding='valid', name='rpn_class_raw')(x)\n    # Reshape to [batch, anchors, 2]\n    x_class = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x_class)\n    # Softmax on last dimension of class scores.\n    x_class_prob = KL.Lambda(lambda t: tf.nn.softmax(t))(x_class)\n    # Bounding box refinement. [batch, height, width, anchors per location * depth]\n    x_regr = KL.Conv2D(anchors_per_location * 4, (1, 1), activation='linear', padding='valid', name='rpn_regress_raw')(x)\n    # Reshape to [batch, anchors, 4]\n    x_regr = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x_regr)\n    return [x_class, x_class_prob, x_regr]\n\n", "CodeBleu_score": 60.353918303504884}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    diff = K.abs(y_true - y_pred)\n    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n    return loss\n", "CodeBleu_score": 60.928513203413225}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    diff = K.abs(y_true - y_pred)\n    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n    loss = (less_than_one * 0.5 * diff**2) + (1 - less_than_one) * (diff - 0.5)\n    return loss\n\n", "CodeBleu_score": 60.928513203413225}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), 'float32')\n    loss = (abs_diff - 0.5) * mask + (abs_diff ** 2) * (1 - mask)\n    return loss\n\n", "CodeBleu_score": 31.149806898470672}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    inputs = KL.Input(shape=x_train.shape[1:])\n    x = KL.Conv2D(32, 3, activation='relu')(inputs)\n    x = KL.MaxPooling2D(pool_size=2)(x)\n    x = KL.Conv2D(64, 3, activation='relu')(x)\n    x = KL.MaxPooling2D(pool_size=2)(x)\n    x = KL.Flatten()(x)\n    x = KL.Dense(128, activation='relu')(x)\n    outputs = KL.Dense(num_classes, activation='softmax')(x)\n    model = KM.Model(inputs=inputs, outputs=outputs)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n", "CodeBleu_score": 30.771769859247044}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    input_layer = KL.Input(shape=x_train.shape[1:])\n    conv_layer1 = KL.Conv2D(filters=32, kernel_size=(3, 3), activation='relu')(input_layer)\n    max_pool_layer1 = KL.MaxPooling2D(pool_size=(2, 2))(conv_layer1)\n    conv_layer2 = KL.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')(max_pool_layer1)\n    max_pool_layer2 = KL.MaxPooling2D(pool_size=(2, 2))(conv_layer2)\n    flatten_layer = KL.Flatten()(max_pool_layer2)\n    dense_layer1 = KL.Dense(units=128, activation='relu')(flatten_layer)\n    output_layer = KL.Dense(units=num_classes, activation='softmax')(dense_layer1)\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 27.95481997737038}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    input_layer = KL.Input(shape=(x_train.shape[1:]))\n    conv_1 = KL.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(input_layer)\n    conv_2 = KL.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(conv_1)\n    max_pool_1 = KL.MaxPooling2D(pool_size=(2, 2))(conv_2)\n    conv_3 = KL.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(max_pool_1)\n    conv_4 = KL.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(conv_3)\n    max_pool_2 = KL.MaxPooling2D(pool_size=(2, 2))(conv_4)\n    flatten = KL.Flatten()(max_pool_2)\n    dense_1 = KL.Dense(units=128, activation='relu')(flatten)\n    output_layer = KL.Dense(units=num_classes, activation='softmax')(dense_1)\n    model = KM.Model(inputs=input_layer, outputs=output_layer)\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 27.920533562774462}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros((mask.shape[-1], 4), dtype='int')\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        if np.any(m):\n            rows = np.where(np.any(m, axis=1))[0]\n            cols = np.where(np.any(m, axis=0))[0]\n            if rows.shape[0] == 0 or cols.shape[0] == 0:\n                # No box -- try to resize some of the classes\n                this_mask = np.zeros(m.shape, dtype=np.uint8)\n                this_mask[cols[0]:cols[-1] + 1, rows[0]:rows[-1] + 1] = 1\n                boxes[i] = resize_mask(this_mask, mask.shape[:2])\n                continue\n            rows = np.where(np.any(m, axis=1))[0]\n            cols = np.where(np.any(m, axis=0))[0]\n            x1, x2 = cols[0], cols[-1]\n            y1, y2 = rows[0], rows[-1]\n            w, h = x2 - x1, y2 - y1\n            if w < h:\n                x1, x2 = cols[0] - 1, cols[-1] + 1\n            else:\n                y1, y2 = rows[0] - 1, rows[-1] + 1\n            w, h = x2 - x1, y2 - y1\n            boxes[i] = np.array([x1, y1, x2, y2])\n    return boxes.astype('int')\n", "CodeBleu_score": 41.02594398609676}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = []\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        if not np.any(m):\n            boxes.append(np.zeros((0, 4), dtype=np.int32))\n            continue\n        # Bounding box coordinates\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            # x2 and y2 should not be part of the box. Increment by 1.\n            x2 += 1\n            y2 += 1\n        else:\n            # No mask for this instance. Might happen due to\n            # resizing or cropping. Set bbox to zeros\n            x1, x2, y1, y2 = 0, 0, 0, 0\n        boxes.append([x1, y1, x2, y2])\n    # Convert into numpy array\n    boxes = np.array(boxes, dtype=np.int32)\n    return boxes\n\n", "CodeBleu_score": 67.8064056240506}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros((mask.shape[-1], 4), dtype='int')\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        if np.any(m):\n            x, y, w, h = cv2.boundingRect(np.stack([m], axis=-1))\n            boxes[i] = [y, x + w, y + h, x]\n    return boxes\n", "CodeBleu_score": 21.727858896782156}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    # Calculate the intersection areas\n    intersection_areas = np.minimum(box[2], boxes[2]) * np.minimum(box[3], boxes[3])\n    # Calculate the union areas\n    union_areas = box_area + boxes_area - intersection_areas\n    # Compute the IoU\n    iou = intersection_areas / union_areas\n    return iou\n", "CodeBleu_score": 19.745446540282202}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    x1 = np.maximum(box[0], boxes[:, 0])\n    y1 = np.maximum(box[1], boxes[:, 1])\n    x2 = np.minimum(box[2], boxes[:, 2])\n    y2 = np.minimum(box[3], boxes[:, 3])\n\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    union = box_area + boxes_area[:] - intersection[:]\n\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 55.49021365037661}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    box_area = box_area\n    boxes_area = boxes_area\n    intersection_area = np.maximum(0, np.minimum(box[2], boxes[:, 2]) - np.maximum(box[0], boxes[:, 0])) * np.maximum(0, np.minimum(box[3], boxes[:, 3]) - np.maximum(box[1], boxes[:, 1]))\n    union_area = box_area + boxes_area - intersection_area\n    iou = intersection_area / union_area\n    return iou\n", "CodeBleu_score": 39.73840342339669}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # Areas of anchors and GT boxes\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n\n    # Compute overlaps to generate matrix [boxes1 count, boxes2 count]\n    # Each cell contains the IoU value.\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        box2 = boxes2[i]\n        overlaps[:, i] = compute_iou(box2, boxes1, area2[i], area1)\n    return overlaps\n\n", "CodeBleu_score": 62.2853282032944}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # Areas of anchors and GT boxes\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n\n    # Compute overlaps to generate matrix [boxes1 count, boxes2 count]\n    # Each cell contains the IoU value.\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        box2 = boxes2[i]\n        overlaps[:, i] = compute_iou(box2, boxes1, area2[i], area1)\n    return overlaps\n", "CodeBleu_score": 62.2853282032944}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # 1. Tile boxes2 and repeate boxes1. This allows us to compare every\n    #    box in boxes1 to every box in boxes2.\n    boxes1 = np.tile(boxes1, [1, 1, 1, 2])\n    boxes2 = np.tile(boxes2, [1, 2, 1, 1])\n    # 2. Compute coordinates of intersection boxes.\n    # x1 = np.maximum(boxes1[..., 0], boxes2[..., 0])\n    # y1 = np.maximum(boxes1[..., 1], boxes2[..., 1])\n    # x2 = np.minimum(boxes1[..., 2], boxes2[..., 2])\n    # y2 = np.minimum(boxes1[..., 3], boxes2[..., 3])\n    x1 = np.maximum(boxes1[..., 0], boxes2[..., 0])\n    y1 = np.maximum(boxes1[..., 1], boxes2[..., 1])\n    x2 = np.minimum(boxes1[..., 2], boxes2[..., 2])\n    y2 = np.minimum(boxes1[..., 3], boxes2[..., 3])\n    # 3. Compute the area of intersection boxes.\n    intersection = np.maximum(x2 - x1, 0) * np.maximum(y2 - y1, 0)\n    # 4. Compute the area of union boxes.\n    area1 = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n    area2 = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n    union = area1 + area2 - intersection\n    # 5. Compute the IoU and return it.\n    iou = intersection / union\n    return iou\n\n", "CodeBleu_score": 15.105837124674274}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n    if image_id in self.image_info:\n        image = self.image_info[image_id][\"image\"]\n    else:\n        image_path = os.path.join(self.dataset_dir, image_id)\n        image = skimage.io.imread(image_path)\n        if image.ndim == 2:\n            image = skimage.color.gray2rgb(image)\n        if image.shape[-1] == 4:\n            image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 71.35379195232142}, {"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = skimage.io.imread(image_path)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n", "CodeBleu_score": 63.64741927437648}, {"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = skimage.io.imread(image_path)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n", "CodeBleu_score": 63.64741927437648}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert len(images)!= 0, \"No images provided!\"\n    assert cols!= 0, \"No columns provided!\"\n    rows = int(np.ceil(len(images) / float(cols)))\n    f = plt.figure()\n    for i, image in enumerate(images):\n        plt.subplot(rows, cols, i+1)\n        if titles is not None:\n            plt.title(titles[i])\n        if cmap is not None:\n            plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        else:\n            plt.imshow(image, norm=norm, interpolation=interpolation)\n    plt.show()\n\n", "CodeBleu_score": 39.6903197774743}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert len(images) <= cols ** 2, \"Number of images is greater than number of available subplots.\"\n    rows = int(np.ceil(len(images) / cols))\n    fig = plt.figure()\n    for i, image in enumerate(images):\n        plt.subplot(rows, cols, i + 1)\n        if titles is not None:\n            plt.title(titles[i])\n        if cmap is not None:\n            plt.imshow(image, cmap=cmap)\n        elif norm is not None:\n            plt.imshow(image, norm=norm)\n        else:\n            plt.imshow(image)\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 37.908172009373544}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert len(images) <= cols ** 2, \"Too many images for specified number of columns.\"\n    rows = int(np.ceil(len(images) / cols))\n    fig = plt.figure(figsize=(15, 15))\n    for i, image in enumerate(images):\n        plt.subplot(rows, cols, i + 1)\n        if titles is not None:\n            plt.title(titles[i])\n        if cmap is not None:\n            plt.imshow(image, cmap=cmap)\n        else:\n            plt.imshow(image)\n        plt.axis('off')\n    plt.show()\n", "CodeBleu_score": 40.88307273936407}]}
