{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\treturn_value = self._orig_kazoo_connect(*args)\n    return (max(2, self.loop_wait - 2) * 1000, return_value[1])", "CodeBleu_score": 52.23543945659041}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\tself._orig_kazoo_connect = self._kazoo_connect\n    self._kazoo_connect = self._orig_kazoo_connect\n    wait_time = max(self.loop_wait - 2, 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n\n", "CodeBleu_score": 54.793610218327004}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\treturn (max(self.loop_wait - 2, 2) * 1000, self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 56.56505279380974}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\tif isinstance(config, dict):\n        config = Config(config)\n\n    if self._retry_timeout != config.retry_timeout:\n        self.set_retry_timeout(config.retry_timeout)\n\n    if self._loop_wait != config.loop_wait:\n        self.set_loop_wait(config.loop_wait)\n\n        if isinstance(self._handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n\n    if self._ttl != config.ttl:\n        if not self.set_ttl(config.ttl):\n            self.close()\n\n", "CodeBleu_score": 37.334105122958796}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\tif isinstance(config, dict):\n        config = Config(config)\n    if self._client:\n        self._client.set_retry_timeout(config.retry_timeout)\n        self._client.set_connect_timeout(config.loop_wait)\n        if self._client.set_ttl(config.ttl) is None and self._client.handler.connect_timeout != config.loop_wait:\n            self._client.handler.connect_timeout = config.loop_wait\n            self._client.handler.close()\n\n", "CodeBleu_score": 40.98436758214225}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\tif isinstance(config, dict):\n        config = Config(config)\n\n    if config.retry_timeout != self._client.retry.deadline:\n        self.set_retry_timeout(config.retry_timeout)\n\n    if config.loop_wait != self._client.handler.loop_wait:\n        self._client.handler.loop_wait = config.loop_wait\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config.loop_wait)\n\n    if self.set_ttl(config.ttl):\n        self.close()\n\n", "CodeBleu_score": 45.872026499875716}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\tcluster = Cluster(path)\n    cluster.initialize(self.get_node(path + self._INIT))\n    cluster.config = ClusterConfig.from_node(self.get_node(path + self._CONFIG))\n    cluster.history = TimelineHistory.from_node(self.get_node(path + self._HISTORY))\n    cluster.sync = SyncState.from_node(self.get_node(path + self._SYNC))\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path, cluster.members)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = Failover.from_node(self.get_node(path + self._FAILOVER))\n    cluster.failsafe = Failsafe.from_node(self.get_node(path + self._FAILSAFE))\n    return cluster\n\n", "CodeBleu_score": 13.78908146406877}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\tself.get_children: def get_children(self, key: str) -> List[str]:\n        try:\n            return self._client.get_children(key)\n        except NoNodeError:\n            return []\n    self.get_node: def get_node(\n            self, key: str, watch: Optional[Callable[[WatchedEvent], None]] = None\n    ) -> Optional[Tuple[str, ZnodeStat]]:\n        try:\n            ret = self._client.get(key, watch)\n            return (ret[0].decode('utf-8'), ret[1])\n        except NoNodeError:\n            return None\n    self.get_node: def get_node(\n            self, key: str, watch: Optional[Callable[[WatchedEvent], None]] = None\n    ) -> Optional[Tuple[str, ZnodeStat]]:\n        try:\n            ret = self._client.get(key, watch)\n            return (ret[0].decode('utf-8'), ret[1])\n        except NoNodeError:\n            return None\n    self.get_node: def get_node(\n            self, key: str, watch: Optional[Callable[[WatchedEvent], None]] = None\n    ) -> Optional[Tuple[str, ZnodeStat]]:\n        try:\n            ret = self._client.get(key, watch)\n            return (ret[0].decode('utf-8'), ret[1])\n        except NoNodeError:\n            return None\n    self.get_node: def get_node(\n            self, key: str, watch: Optional[Callable[[WatchedEvent], None]] = None\n    ) -> Optional[Tuple[str, ZnodeStat]]:\n        try:\n            ret = self._client.get(key, watch)\n            return (ret[0].decode('utf-8'), ret[1])\n        except NoNodeError:\n            return None\n    self.get_node: def get_node(\n            self, key: str, watch: Optional[Callable[[WatchedEvent], None]] = None\n    ) -> Optional[Tuple[str, ZnodeStat]]:\n        try:\n            ret = self._client.", "CodeBleu_score": 19.611389922445856}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t# Initialize a Cluster object\n    cluster = Cluster()\n    # Load the cluster initialization state\n    cluster.initialize(self.get_node(path + self._INITIALIZE))\n    # Load the cluster configuration\n    cluster.config = ClusterConfig.from_node(self.get_node(path + self._CONFIG))\n    # Load the timeline history\n    cluster.history = TimelineHistory.from_node(self.get_node(path + self._HISTORY))\n    # Load the synchronization state\n    cluster.sync = SyncState.from_node(self.get_node(path + self._SYNC))\n    # Load the cluster members\n    cluster.members = self.load_members(path)\n    # Load the cluster leader\n    cluster.leader = self.leader(self.get_node(path + self._LEADER), cluster.members)\n    # Load the cluster status\n    cluster.status = self.get_status(path, cluster.leader)\n    # Load the failover state\n    cluster.failover = Failover.from_node(self.get_node(path + self._FAILOVER))\n    # Load the failsafe configuration\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n", "CodeBleu_score": 14.262727129507793}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\ttry:\n        self.zk.create(self.leader_path, self.host_name.encode(), ephemeral=True, sequence=True)\n        self.leader_path_created = True\n        self.logger.info('Leader lock acquired.')\n        return True\n    except NodeExistsError:\n        self.logger.info('Leader lock not acquired.')\n        return False\n    except Exception as e:\n        if isinstance(e, ZooKeeperError):\n            raise e\n        self.logger.error('Unexpected error while acquiring leader lock.', exc_info=True)\n        return False\n\n\n\n\n", "CodeBleu_score": 50.61484938618148}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\ttry:\n        self.zk.create(self.zk_path, self.zk_data, acl=self.zk_acl, ephemeral=True, sequence=True)\n        self.zk_node = self.zk_path + \"/\" + self.zk.get_children(self.zk_path)[-1]\n        logger.info(\"Acquired leader lock: %s\", self.zk_node)\n        return True\n    except Exception as e:\n        if isinstance(e, NodeExistsError):\n            logger.info(\"Leader lock already acquired: %s\", self.zk_path)\n            return False\n        elif isinstance(e, ZooKeeperError):\n            raise e\n        else:\n            logger.error(\"Unexpected error acquiring leader lock: %s\", e)\n            return False\n\n\n\n\n", "CodeBleu_score": 45.825607370348884}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\tdef _attempt_to_acquire_leader(self) -> bool:\n        \"\"\"This function attempts to acquire a leader lock by creating an ephemeral node in ZooKeeper at a specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error unless the exception is a NodeExistsError, indicating another instance has the lock. If the lock cannot be acquired, it logs an info message and returns False.\"\"\"\n\n        def _attempt_to_acquire_leader(self) -> bool:\n            \"\"\"This function attempts to acquire a leader lock by creating an ephemeral node in ZooKeeper at a specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error unless the exception is a NodeExistsError, indicating another instance has the lock. If the lock cannot be acquired, it logs an info message and returns False.\"\"\"\n\n            def _attempt_to_acquire_leader(self) -> bool:\n                \"\"\"This function attempts to acquire a leader lock by creating an ephemeral node in ZooKeeper at a specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error unless the exception is a NodeExistsError, indicating another instance has the lock. If the lock cannot be acquired, it logs an info message and returns False.\"\"\"\n\n                def _attempt_to_acquire_leader(self) -> bool:\n                    \"\"\"This function attempts to acquire a leader lock by creating an ephemeral node in ZooKeeper at a specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooK", "CodeBleu_score": 33.500133409822546}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\tif self.leader_node.session != leader.session:\n        logger.warning(\n            f\"Leader mismatch: {self.leader_node.session} != {leader.session}\"\n        )\n        try:\n            self.delete(self.leader_node.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError) as e:\n            logger.error(f\"Failed to delete leader node: {e}\")\n            return False\n    try:\n        self.create(\n            self.leader_node.path,\n            leader.name.encode(\"utf-8\"),\n            ephemeral=True,\n            sequence=True,\n        )\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(f\"Failed to create leader node: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 40.1815943148296}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\tif leader.client_id != self.client_id:\n        logger.warning(f\"Leader is not the current client. Expected: {self.client_id}, Found: {leader.client_id}\")\n        try:\n            self.delete(self.leader_path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n\n    try:\n        self.create(self.leader_path, self.client_id.encode(), ephemeral=True, sequence=False, makepath=True)\n    except (ConnectionClosedError, RetryFailedError, NoNodeError) as e:\n        logger.error(f\"Error while creating leader ZNode: {e}\")\n        return False\n    return True", "CodeBleu_score": 31.064087975579348}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\tif leader.client_id != self.client_id:\n        logger.warning(f\"Leader mismatch: current client ID: {self.client_id}, leader's client ID: {leader.client_id}\")\n        try:\n            self.delete(leader.path, version=leader.version)\n        except NoNodeError:\n            logger.warning(\"Leader node does not exist. Creating a new one.\")\n        except (ConnectionClosedError, RetryFailedError) as e:\n            raise ZooKeeperError(f\"Failed to delete leader node: {e}\") from e\n\n    try:\n        self.create(\n            LEADER_NODE_PATH,\n            leader.client_id.encode(),\n            acl=[self.make_acl(self.client_id, \"rwcda\")],\n            ephemeral=True,\n            sequence=False,\n        )\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.error(f\"Failed to create leader node: {e}\")\n        return False\n    return True", "CodeBleu_score": 44.311806874551465}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\tnow = time.time()\n    if self._last_poll_time is None or now - self._last_poll_time >= self._poll_interval:\n        self._last_poll_time = now\n        data = self._query_exhibitors(self._exhibitors)\n        if data is None:\n            return False\n        if isinstance(data, dict):\n            zk_hosts = data['servers']\n            zk_port = data['port']\n        else:\n            zk_hosts = data\n            zk_port = self._zk_port\n        zk_hosts_string = ','.join(zk_hosts)\n        if zk_hosts_string != self._zk_hosts_string:\n            logging.info('ZooKeeper connection string changed from %s to %s', self._zk_hosts_string, zk_hosts_string)\n            self._zk_hosts_string = zk_hosts_string\n            self._zk_hosts = zk_hosts\n            self._zk_port = zk_port\n            self._zk_client.hosts = zk_hosts\n            self._zk_client.port = zk_port\n            return True\n        return False\n    return False\n\n\n", "CodeBleu_score": 37.521813319123396}, {"code": "def poll(self) -> bool\n\tif time.time() - self._last_poll_time < self._poll_interval:\n        return False\n    self._last_poll_time = time.time()\n    exhibitors = self._exhibitors\n    random.shuffle(exhibitors)\n    for host in exhibitors:\n        try:\n            response = requests_get(uri('http', (host, self._exhibitor_port), self._uri_path), timeout=self.TIMEOUT)\n            data = json.loads(response.data.decode('utf-8'))\n            if not isinstance(data, dict):\n                logging.warning('Exhibitor returned invalid data: %s', data)\n                continue\n            if 'servers' not in data:\n                logging.warning('Exhibitor returned invalid data: %s', data)\n                continue\n            servers = data['servers']\n            if not isinstance(servers, dict):\n                logging.warning('Exhibitor returned invalid data: %s', data)\n                continue\n            zk_hosts = []\n            for server in servers.values():\n                if not isinstance(server, dict):\n                    logging.warning('Exhibitor returned invalid data: %s', data)\n                    continue\n                if 'host' not in server or 'port' not in server:\n                    logging.warning('Exhibitor returned invalid data: %s', data)\n                    continue\n                host = server['host']\n                port = server['port']\n                if not isinstance(host, str) or not isinstance(port, int):\n                    logging.warning('Exhibitor returned invalid data: %s', data)\n                    continue\n                zk_hosts.append(host + ':' + str(port))\n            zk_hosts.sort()\n            zk_hosts_str = ','.join(zk_hosts)\n            if zk_hosts_str != self._zk_hosts_str:\n                logging.info('ZooKeeper connection string changed: %s', zk_hosts_str)\n                self._zk_hosts_str = zk_hosts_str\n                self._zk_hosts = zk_hosts\n                self._zk_hosts_changed = True", "CodeBleu_score": 34.27741741641963}, {"code": "def poll(self) -> bool\n\tif self._last_poll is None or time.time() - self._last_poll > self.POLL_INTERVAL:\n        self._last_poll = time.time()\n        exhibitors = self._get_exhibitors()\n        if exhibitors is None:\n            return False\n        zk_string = self._get_zk_string(exhibitors)\n        if zk_string != self._zk_string:\n            self._zk_string = zk_string\n            logging.info('ZooKeeper connection string has changed: %s', zk_string)\n            return True\n    return False\n\n", "CodeBleu_score": 28.08820555535708}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\tif self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 97.36568541552093}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\tif self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 97.36568541552093}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\tif self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 97.36568541552093}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n    nodeCache.getListenable().addListener(nodeCacheListener);\n}", "CodeBleu_score": 62.20116850376204}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.51700357174724}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 80.2370284474588}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\tif (zookeeperListener == null) {\n        return;\n    }\n\n    String group = getGroup();\n    String dataId = getDataId();\n\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribeConfig(dataId);\n    } catch (Exception e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 80.69023802306839}, {"code": "public void destroy(){\n\tif (zookeeperListener == null) {\n        return;\n    }\n    String dataId = getDataId();\n    String group = getGroup();\n    logUnsubscribeStarted(dataId, group);\n    try {\n        zookeeperListener.unsubscribeConfig(dataId, group);\n    } catch (NacosException e) {\n        logUnsubscribeFailed(dataId, group);\n    }\n}", "CodeBleu_score": 69.50099364548625}, {"code": "public void destroy(){\n\tif (zookeeperListener == null) {\n        return;\n    }\n    String dataId = getDataId();\n    String group = getGroup();\n    logUnsubscribeStarted(dataId, group);\n    try {\n        zookeeperListener.unsubscribeConfig(dataId, group);\n    } catch (Exception e) {\n        logUnsubscribeFailed(dataId, group, e);\n    }\n}", "CodeBleu_score": 72.70898986726081}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    } else {\n        return Collections.emptyMap();\n    }\n}", "CodeBleu_score": 60.13065395096392}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    }\n    return new HashMap<>();\n}", "CodeBleu_score": 59.22400867545194}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 59.89180790357456}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = getConfigPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path);\n        nodeCache.start();\n\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getPath(), new String(nodeCache.getCurrentData().getData()));\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        zookeeperListenerMap.put(path, zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 72.97705196326399}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = \"/\" + group + \"/\" + serviceId + \"/config\";\n        NodeCache nodeCache = new NodeCache(curatorFramework, path);\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getPath());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        nodeCache.start(true);\n        return new ZookeeperListener(nodeCache, nodeCacheListener);\n    }", "CodeBleu_score": 68.42660995139475}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = getConfigPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path);\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getPath(), new String(nodeCache.getCurrentData().getData()));\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        nodeCache.start();\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        zookeeperListener.addListener();\n        return zookeeperListener;\n    }", "CodeBleu_score": 74.20846268100222}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.81278207135417}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\treturn new ZookeeperServerListDecorator(config, serviceDiscovery, new ZookeeperServerListUpdater(config, serviceDiscovery));\n}", "CodeBleu_score": 24.74028774053162}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.81278207135417}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.09638065942949}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.09638065942949}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.09638065942949}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.10458663952991}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.10458663952991}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.10458663952991}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.3595927181432}, {"code": "public void close(){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.3595927181432}, {"code": "public void close(){\n\ttry {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.3595927181432}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tString group = globalConfig ? config.globalConfig.group : config.localConfig.group\n    String dataId = globalConfig ? config.globalConfig.dataId : config.localConfig.dataId\n\n    logger.info(\"Subscribing to configuration: group={}, dataId={}\", group, dataId)\n    try {\n        return zookeeperOperation.subscribeConfig(group, dataId, {\n            logger.info(\"Configuration updated: group={}, dataId={}, content={}\", group, dataId, it)\n            config.load(it)\n        })\n    } catch (Exception e) {\n        logger.error(\"Failed to subscribe to configuration: group={}, dataId={}\", group, dataId, e)\n        return null\n    }\n}", "CodeBleu_score": 37.844483829260554}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tString group = globalConfig ? this.globalConfigGroup : this.configGroup;\n    String dataId = globalConfig ? this.globalConfigDataId : this.configDataId;\n    logger.info(\"Subscribe {} {}\", group, dataId);\n    try {\n        ZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, new ConfigChangeCallback());\n        logger.info(\"Subscribe {} {} success\", group, dataId);\n        return listener;\n    } catch (Exception e) {\n        logger.error(\"Subscribe {} {} failed\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 36.66443823958332}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tString group = getGroup(globalConfig);\n    String dataId = getDataId(globalConfig);\n    log.info(\"Subscribe config start, group: {}, dataId: {}\", group, dataId);\n    try {\n        ZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, new Callback() {\n            @Override\n            public void callback(String config) {\n                log.info(\"Config updated, group: {}, dataId: {}, config: {}\", group, dataId, config);\n                if (globalConfig) {\n                    globalConfigCache.set(config);\n                } else {\n                    localConfigCache.set(config);\n                }\n            }\n        });\n        log.info(\"Subscribe config finished, group: {}, dataId: {}\", group, dataId);\n        return listener;\n    } catch (Exception e) {\n        log.error(\"Subscribe config failed, group: {}, dataId: {}\", group, dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 50.54926135747707}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\tString connectString = getProperty(\"zookeeper.connectString\");\n  if (isEmpty(connectString)) {\n    throw new DiscoveryException(\"zookeeper.connectString is not set\");\n  }\n  int retryCount = getProperty(\"zookeeper.retryCount\", 3);\n  int retrySleepTime = getProperty(\"zookeeper.retrySleepTime\", 1000);\n  RetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n  CuratorFramework builder = CuratorFrameworkFactory.newClient(connectString, retryPolicy);\n  builder.start();\n  return builder;\n}", "CodeBleu_score": 30.480458802725025}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectString = getProperty(\"ZOOKEEPER_CONNECT_STRING\");\n    if (connectString == null || connectString.isEmpty()) {\n        throw new DiscoveryException(\"Zookeeper connection string is not set\");\n    }\n    int retryCount = Integer.parseInt(getProperty(\"ZOOKEEPER_RETRY_COUNT\", \"3\"));\n    int retrySleepTime = Integer.parseInt(getProperty(\"ZOOKEEPER_RETRY_SLEEP_TIME\", \"1000\"));\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 40.2785325894934}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectString = getProperty(ZK_CONNECT_STRING, \"\");\n    if (connectString.isEmpty()) {\n        throw new DiscoveryException(\"Zookeeper connection string is empty\");\n    }\n    int retryCount = getProperty(ZK_RETRY_COUNT, 10);\n    int retrySleep = getProperty(ZK_RETRY_SLEEP, 1000);\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleep, retryCount);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 39.808971432076255}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(CuratorFramework curator,\n\t\t\tObjectProvider<List<RouteLocator>> routeLocators) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(curator, routeLocators.getIfAvailable(Collections::emptyList));\n\t}\n\n}", "CodeBleu_score": 31.680932726562833}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(CuratorFramework curatorFramework,\n\t\t\tObjectProvider<List<RouteLocator>> routeLocators) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(curatorFramework,\n\t\t\t\trouteLocators.getIfAvailable(Collections::emptyList));\n\t}\n\n}", "CodeBleu_score": 25.227416805157993}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(CuratorFramework curatorFramework,\n\t\t\tObjectProvider<List<RouteDefinitionLocator>> definitionLocators) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(curatorFramework, definitionLocators.getIfAvailable());\n\t}\n\n}", "CodeBleu_score": 41.932085025719125}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t// create a CuratorFramework instance\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            // set the connection string\n            .connectString(getZkHosts())\n            // set the session timeout\n            .sessionTimeoutMs(getSessionTimeout())\n            // set the namespace\n            .namespace(getNamespace())\n            // set the retry policy\n            .retryPolicy(retryPolicy)\n            .build();\n\n    // start the CuratorFramework instance\n    curatorFramework.start();\n\n    // return the CuratorFramework instance\n    return curatorFramework;\n}", "CodeBleu_score": 44.91459055564641}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t// Create a CuratorFramework instance and set the connection properties\n    CuratorFramework curatorFramework = builder\n        .connectString(getZkHosts())\n        .sessionTimeoutMs(getSessionTimeout())\n        .namespace(getNamespace())\n        .retryPolicy(retryPolicy)\n        .build();\n\n    // Start the CuratorFramework instance\n    curatorFramework.start();\n\n    return curatorFramework;\n}", "CodeBleu_score": 40.092762213992486}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tString zkHosts = getZkHosts();\n    int sessionTimeoutMs = getSessionTimeout();\n    String namespace = getNamespace();\n    RetryPolicy retryPolicy = getRetryPolicy();\n    CuratorFramework builder = CuratorFrameworkFactory.builder()\n            .connectString(zkHosts)\n            .sessionTimeoutMs(sessionTimeoutMs)\n            .retryPolicy(retryPolicy)\n            .namespace(namespace)\n            .build();\n    builder.start();\n    return builder;\n}", "CodeBleu_score": 47.102432035402366}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t// If we already have a lock, re-acquire it\n    if (locksMap.containsKey(path)) {\n        try {\n            locksMap.get(path).acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(e);\n        }\n        return;\n    }\n\n    // If we don't have a lock, create a new one, acquire it, and store it in the map\n    InterProcessMutex lock = new InterProcessMutex(getZkCleint(), path);\n    try {\n        lock.acquire();\n        locksMap.put(path, lock);\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}", "CodeBleu_score": 33.05708733588966}, {"code": "public void lock(String path) throws DistributedLockException{\n\ttry {\n        if (!locksMap.containsKey(path)) {\n            InterProcessMutex lock = new InterProcessMutex(getZkCleint(), path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } else {\n            locksMap.get(path).acquire();\n        }\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}", "CodeBleu_score": 24.0421410290752}, {"code": "public void lock(String path) throws DistributedLockException{\n\ttry {\n        InterProcessMutex lock = locksMap.get(path);\n        if (lock == null) {\n            lock = new InterProcessMutex(getZkCleint(), path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } else {\n            lock.acquire();\n        }\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}", "CodeBleu_score": 27.934940636277773}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tString nodePath = nodePath(dtpProperties);\n        CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        DtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n        String configType = zookeeper.getConfigType();\n        if (ConfigTypeEnum.PROPERTIES.name().equalsIgnoreCase(configType)) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        } else if (ConfigTypeEnum.JSON.name().equalsIgnoreCase(configType)) {\n            String configKey = zookeeper.getConfigKey();\n            String configVal = getVal(makePath(nodePath, configKey), curatorFramework);\n            return ConfigHandler.parseConfig(configVal);\n        } else {\n            throw new DtpException(\"Unsupported configuration type, configType: \" + configType);\n        }\n    }", "CodeBleu_score": 44.79759251068703}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tString nodePath = nodePath(dtpProperties);\n        CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        if (dtpProperties.getZookeeper().getConfigType().equalsIgnoreCase(ConfigTypeEnum.PROPERTIES.getType())) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        } else {\n            final String configKey = getConfigKey(dtpProperties);\n            final String configType = getConfigType(dtpProperties);\n            final String path = makePath(nodePath, configKey);\n            final String value = getVal(path, curatorFramework);\n            return parseConfig(configType, value);\n        }\n    }", "CodeBleu_score": 45.66796540832691}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tString nodePath = nodePath(dtpProperties);\n        CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        DtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n        if (zookeeper.getConfigType() == ConfigType.PROPERTIES) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        } else {\n            String configKey = getConfigKey(zookeeper.getConfigKey());\n            String configVal = getVal(ZKPaths.makePath(nodePath, configKey), curatorFramework);\n            return ConfigHandler.parseConfig(configVal);\n        }\n    }", "CodeBleu_score": 46.62106089107265}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = getInstance(environment);\n        bindDtpProperties(environment, dtpProperties);\n        Map<Object, Object> properties = genPropertiesMap(dtpProperties);\n        if (!checkPropertyExist(environment)) {\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 66.12241295304248}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = getInstance(environment);\n    bindDtpProperties(environment, dtpProperties);\n    Map<Object, Object> properties = genPropertiesMap(dtpProperties);\n    if (!checkPropertyExist(environment)) {\n        createZkPropertySource(environment, properties);\n    }\n}", "CodeBleu_score": 65.80475307109153}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = getInstance(environment);\n        bindDtpProperties(environment, dtpProperties);\n        Map<Object, Object> properties = genPropertiesMap(dtpProperties);\n        if (!checkPropertyExist(environment)) {\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 66.12241295304248}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterAdapter(provider => new ZooKeeperServiceRouteManager(\n        provider.GetRequiredService<ISerializer<byte[]>>(),\n        provider.GetRequiredService<ISerializer<string>>(),\n        provider.GetRequiredService<IServiceRouteFactory>(),\n        provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>(),\n        provider.GetRequiredService<IZookeeperClientProvider>(),\n        GetConfigInfo(configInfo)\n    )).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 73.42103235451786}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterAdapter(provider =>\n    {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var factory = provider.GetRequiredService<IServiceRouteFactory>();\n        var clientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(configInfo, factory, clientProvider, logger, serializer);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 44.45619646659566}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterAdapter(provider => new ZooKeeperServiceRouteManager(\n        GetConfigInfo(configInfo),\n        provider.GetRequiredService<ISerializer<byte[]>>(),\n        provider.GetRequiredService<ISerializer<string>>(),\n        provider.GetRequiredService<IServiceRouteFactory>(),\n        provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>(),\n        provider.GetRequiredService<IZookeeperClientProvider>()\n    ))\n    .As<IServiceRouteManager>()\n    .SingleInstance();\n    return this;\n}", "CodeBleu_score": 75.04908183712908}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.Register(provider =>\n            {\n                var result = GetConfigInfo(configInfo);\n                var logger = provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>();\n                var serviceEntryManager = provider.GetRequiredService<IServiceEntryManager>();\n                var serviceRouteManager = provider.GetRequiredService<IServiceRouteManager>();\n                var zookeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n                var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n                return new ZookeeperServiceCommandManager(\n                    zookeeperClientProvider,\n                    serviceEntryManager,\n                    serviceRouteManager,\n                    logger,\n                    serializer,\n                    result\n                    );\n            }).As<IServiceCommandManager>().SingleInstance();\n            return this;\n        }", "CodeBleu_score": 56.540796185590395}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterAdapter(provider => new ZookeeperServiceCommandManager(provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<IServiceRouteManager>(), provider.GetRequiredService<IServiceEntryManager>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo))\n                .As<IServiceCommandManager>()\n                .SingleInstance();\n            return this;\n        }", "CodeBleu_score": 63.575768765373994}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tvar config = GetConfigInfo(configInfo);\n            UseCommandManager(builder, provider => new ZookeeperServiceCommandManager(\n                provider.GetRequiredService<ISerializer<byte[]>>(),\n                provider.GetRequiredService<ISerializer<string>>(),\n                provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\n                provider.GetRequiredService<IServiceRouteManager>(),\n                provider.GetRequiredService<IZookeeperClientProvider>(),\n                config));\n            return this;\n        }", "CodeBleu_score": 67.7494730994826}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\n    Check.CheckCondition(() => !string.IsNullOrEmpty(path), \"path must not be null or empty.\");\n    if (!Path.IsPathRooted(path)) {\n        provider = provider ?? builder.GetFileProvider();\n        if (provider == null) {\n            throw new ArgumentException(\"provider is null and path is not rooted.\");\n        }\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 62.79481186194749}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\n    Check.CheckCondition(() => !string.IsNullOrEmpty(path), \"path must be a non-empty string\");\n\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 68.68116460990707}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tCheck.NotNull(builder, nameof(builder));\n    Check.CheckCondition(() => !string.IsNullOrEmpty(path), \"The path cannot be null or empty.\");\n\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n\n    builder.Add(source);\n\n    return builder;\n}", "CodeBleu_score": 68.72150151424073}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\n    foreach (var route in _routes) {\n        route.Address = route.Address.Except(Address);\n    }\n    await base.SetRoutesAsync(_routes);\n}", "CodeBleu_score": 66.70797425500999}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\n    var routesToUpdate = new List<ServiceRoute>();\n    foreach (var route in _routes)\n    {\n        route.Address = route.Address.Except(Address).ToList();\n        routesToUpdate.Add(route);\n    }\n    await base.SetRoutesAsync(routesToUpdate);\n}", "CodeBleu_score": 56.974390290928234}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\n    foreach (var route in _routes) {\n        route.Address.Except(Address);\n    }\n    await base.SetRoutesAsync(_routes);\n}", "CodeBleu_score": 43.04944214107692}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar path = _configInfo.RoutePath;\n    var routeIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var zookeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zookeeperClients) {\n        var oldRouteIds = (await zooKeeper.Item2.getChildrenAsync(path)).ToArray();\n        var newRouteIds = routeIds.Except(oldRouteIds).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = (await zooKeeper.Item2.getChildrenAsync($\"{path}{Zookeeper.PathSeparator}{deletedRouteId}\")).ToArray();\n            var deletedAddresses = addresses.Where(address => address.EndsWith(hostAddr.ToString())).ToArray();\n            foreach (var deletedAddress in deletedAddresses) {\n                await zooKeeper.Item2.deleteAsync($\"{path}{Zookeeper.PathSeparator}{deletedRouteId}{Zookeeper.PathSeparator}{deletedAddress}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 55.4204044727167}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar path = _configInfo.RoutePath;\n    var routeIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zookeeper in zooKeeper) {\n        var oldRouteIds = (await zookeeper.Item1.getChildrenAsync(path)).ToArray();\n        var newRouteIds = routeIds.Except(oldRouteIds).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(routeIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = (await zookeeper.Item1.getChildrenAsync($\"{path}/{deletedRouteId}\")).ToArray();\n            var deletedAddresses = addresses.Where(address => !routes.Select(p => p.Address).Contains(address)).ToArray();\n            foreach (var deletedAddress in deletedAddresses) {\n                if (addresses.Contains(hostAddr.ToString())) {\n                    await zookeeper.Item2.deleteAsync($\"{path}/{deletedRouteId}/{deletedAddress}\");\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 51.32573650378443}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar path = _configInfo.RoutePath;\n    var routeIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers().FirstOrDefault(p => p.Item1.EndsWith(path));\n    if (zooKeeper.Item1 != null) {\n        var oldRouteIds = (await zooKeeper.Item2.getChildrenAsync(path)).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(routeIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = (await zooKeeper.Item2.getChildrenAsync($\"{path}/{deletedRouteId}\")).ToArray();\n            if (addresses.Contains(hostAddr.ToString())) {\n                await zooKeeper.Item2.deleteAsync($\"{path}/{deletedRouteId}/{hostAddr}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 45.626342636965916}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\n        return null;\n    }\n\n    var descriptor = await _serializer.Deserialize(data);\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Deserialized route data: {JsonConvert.SerializeObject(descriptor, Formatting.Indented)}\");\n    }\n\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 44.05040441861764}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data is null) {\n        return null;\n    }\n\n    _logger.LogDebug(\"Received route data: {Data}\", Convert.ToBase64String(data));\n\n    var descriptor = await JsonSerializer.DeserializeAsync<ServiceRouteDescriptor>(new MemoryStream(data), _options.JsonSerializerOptions);\n    return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 44.88520876448456}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug(\n            \"Received route data: {data}\",\n            Convert.ToBase64String(data));\n    }\n\n    var descriptor = await Task.Run(() => {\n        using var stream = new MemoryStream(data);\n        using var reader = new BinaryReader(stream);\n        return new ServiceRouteDescriptor(reader);\n    });\n\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 38.35366376075511}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData)) {\n        return;\n    }\n\n    var newRoute = await GetRoute(newData);\n    if (newRoute == null) {\n        return;\n    }\n\n    var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n    if (oldRoute == null) {\n        _routes = _routes.Concat(new[] { newRoute }).ToArray();\n    }\n    else {\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id).Concat(new[] { newRoute }).ToArray();\n    }\n\n    OnChanged(new ServiceRouteChangedEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 76.38912458908263}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData))\n        return;\n\n    var newRoute = await GetRoute(newData);\n    if (newRoute == null)\n        return;\n\n    lock (_routesLock)\n    {\n        _routes = _routes\n            .Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    OnChanged(new ServiceRouteChangedEventArgs(newRoute,\n        _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id && DataEquals(i.Data, oldData))));\n}", "CodeBleu_score": 81.50094330912874}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData)) return;\n\n    var newRoute = await GetRoute(newData);\n    var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n    if (oldRoute == null) return;\n\n    lock (_routesLock) {\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    OnChanged(new ServiceRouteChangedEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 83.99370265749734}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar rootPath = _configInfo.SubscriberPath;\n    if (!rootPath.EndsWith(\"/\"))\n        rootPath += \"/\";\n\n    subscribers = subscribers.ToArray();\n    var serviceSubscribers = new List<ServiceSubscriber>(subscribers.Count());\n\n    foreach (var subscriber in subscribers) {\n        var nodePath = $\"{rootPath}{subscriber.ServiceDescriptor.Id}\";\n        var existingSubscriber = await GetSubscriber(nodePath);\n        if (existingSubscriber != null) {\n            subscriber.Address = existingSubscriber.Address.Concat(subscriber.Address).ToArray();\n        }\n        serviceSubscribers.Add(subscriber);\n    }\n\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 54.756316157901075}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar rootPath = _configInfo.SubscriberPath;\n    if (!rootPath.EndsWith(\"/\"))\n        rootPath += \"/\";\n\n    subscribers = subscribers.ToArray();\n    var serviceSubscribers = await GetSubscribers(subscribers.Select(p => p.ServiceDescriptor.Id));\n    foreach (var subscriber in subscribers) {\n        var serviceSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (serviceSubscriber != null) {\n            subscriber.Address = subscriber.Address.Concat(serviceSubscriber.Address.Except(subscriber.Address)).ToArray();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 79.90865328678952}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar rootPath = _configInfo.SubscriberPath;\n    if (!rootPath.EndsWith(\"/\"))\n        rootPath += \"/\";\n\n    var childrens = await _zookeeperClient.GetChildrenAsync(rootPath);\n    subscribers = await GetSubscribers(childrens);\n\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 20.819824789441856}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\n            var rootPath = $\"{_configuration.BasePath}{_configuration.SubscribersPath}\";\n            foreach (var children in childrens) {\n                _logger.LogDebug(\"Retrieving subscriber for {children}.\", children);\n                var fullPath = $\"{rootPath}/{children}\";\n                var subscriber = await _zookeeperClient.GetDataAsync<ServiceSubscriber>(fullPath).ConfigureAwait(false);\n                subscribers.Add(subscriber);\n            }\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 45.26569691159643}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\n            var rootPath = $\"{_options.BasePath}{_options.ServicePath}/\";\n            _logger.LogDebug(\"Getting subscribers for {childrens}\", childrens);\n            foreach (var children in childrens) {\n                var fullPath = $\"{rootPath}{children}\";\n                _logger.LogDebug(\"Getting subscriber for {fullPath}\", fullPath);\n                var subscriber = await _zooKeeperClient.GetDataAsync<ServiceSubscriber>(fullPath);\n                subscribers.Add(subscriber);\n            }\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 49.9171687319199}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\n\n            foreach (var children in childrens) {\n\n                _logger.LogDebug($\"Getting subscriber for node {children}\");\n\n                var rootPath = $\"{_configuration.BasePath}{children}\";\n\n                if (!rootPath.EndsWith(\"/\")) {\n                    rootPath += \"/\";\n                }\n\n                var fullPath = $\"{rootPath}{_configuration.DataIdentifier}\";\n\n                var subscriber = await _zookeeper.GetDataAsync(fullPath);\n\n                subscribers.Add(JsonSerializer.Deserialize<ServiceSubscriber>(subscriber));\n            }\n\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 49.25353175793068}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null) {\n    return;\n  }\n  var (event, zooKeeper) = await GetZooKeeper();\n  event.WaitOne();\n  if (_subscribers != null) {\n    return;\n  }\n  var rootPath = _configInfo.SubscriberPath;\n  if (!rootPath.EndsWith(\"/\")) {\n    rootPath += \"/\";\n  }\n  var exists = await zooKeeper.existsAsync(rootPath);\n  if (exists == null) {\n    if (_logger.IsEnabled(LogLevel.Warning)) {\n      _logger.LogWarning($\"\u65e0\u6cd5\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\uff0c\u56e0\u4e3a\u8282\u70b9\uff1a{rootPath}\uff0c\u4e0d\u5b58\u5728\u3002\");\n    }\n    _subscribers = Array.Empty<ServiceSubscriber>();\n    return;\n  }\n  var childrens = await zooKeeper.getChildrenAsync(rootPath);\n  _subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 51.91153683836303}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null) {\n        return;\n    }\n\n    var (_, zooKeeper) = await GetZooKeeper();\n    zooKeeper.existsAsync(_subscriberPath).then(result => {\n        if (result.Stat != null) {\n            zooKeeper.getChildrenAsync(_subscriberPath).then(result => {\n                var subscribers = result.Children.ToArray();\n                GetSubscribers(subscribers).then(subscribers => {\n                    _subscribers = subscribers;\n                    _subscribersChanged.Set();\n                });\n            });\n        } else {\n            _logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{_subscriberPath}\u4e0d\u5b58\u5728\u3002\");\n            _subscribers = new ServiceSubscriber[0];\n            _subscribersChanged.Set();\n        }\n    });\n}", "CodeBleu_score": 44.66348555230293}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null) return;\n    var zooKeeper = await GetZooKeeper();\n    var result = await zooKeeper.Item2.existsAsync(SubscriberPath);\n    if (result == null) {\n        _logger.LogWarning($\"\u8ba2\u9605\u8005\u8282\u70b9\uff1a{SubscriberPath}\u4e0d\u5b58\u5728\u3002\");\n        _subscribers = new ServiceSubscriber[0];\n        return;\n    }\n    var childrens = (await zooKeeper.Item2.getChildrenAsync(SubscriberPath)).Children.ToArray();\n    _subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 50.891527082126174}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"\u51c6\u5907\u5904\u7406\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65e7\u6570\u636e\uff1a{Encoding.UTF8.GetString(oldData)}\uff0c\u65b0\u6570\u636e\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\n    var oldDescriptor = GetServiceCommand(oldData);\n    var newDescriptor = GetServiceCommand(newData);\n\n    if (oldDescriptor == null && newDescriptor == null)\n        return;\n\n    if (newDescriptor != null && (oldDescriptor == null || !DataEquals(oldData, newData)))\n    {\n        ServiceCommands = ServiceCommands\n            .Where(i => i.ServiceId != newDescriptor.ServiceId)\n            .Concat(new[] { newDescriptor }).ToArray();\n    }\n    else if (oldDescriptor != null && newDescriptor == null)\n    {\n        ServiceCommands = ServiceCommands\n            .Where(i => i.ServiceId != oldDescriptor.ServiceId)\n            .ToArray();\n    }\n\n    //\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\n    OnChanged(new ServiceCommandChangedEventArgs(newDescriptor, oldDescriptor));\n}", "CodeBleu_score": 58.91030426273915}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null && newData == null)\n        return;\n\n    var oldDescriptor = GetServiceCommand(oldData);\n    var newDescriptor = GetServiceCommand(newData);\n\n    if (DataEquals(oldData, newData))\n        return;\n\n    if (oldDescriptor != null && newDescriptor != null) {\n        if (oldDescriptor.ServiceId != newDescriptor.ServiceId) {\n            _logger.LogError($\"The service ID of the old command is {oldDescriptor.ServiceId} and the new one is {newDescriptor.ServiceId}.\");\n            return;\n        }\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"The service command for service {newDescriptor?.ServiceId} has changed.\");\n\n    lock (_serviceCommands) {\n        if (newDescriptor == null) {\n            _serviceCommands = _serviceCommands.Where(i => i.ServiceId != oldDescriptor.ServiceId).ToArray();\n        } else if (oldDescriptor == null) {\n            _serviceCommands = _serviceCommands.Concat(new[] { newDescriptor }).ToArray();\n        } else {\n            _serviceCommands = _serviceCommands.Where(i => i.ServiceId != newDescriptor.ServiceId)\n                                               .Concat(new[] { newDescriptor }).ToArray();\n        }\n    }\n\n    OnChanged(newDescriptor, oldDescriptor);\n}", "CodeBleu_score": 57.061290839369036}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"\u51c6\u5907\u5904\u7406\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65e7\u6570\u636e\uff1a{Encoding.UTF8.GetString(oldData)}\uff0c\u65b0\u6570\u636e\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\n    if (DataEquals(oldData, newData))\n        return;\n\n    var oldDescriptor = GetServiceCommand(oldData);\n    var newDescriptor = GetServiceCommand(newData);\n\n    if (oldDescriptor != null && newDescriptor != null)\n    {\n        if (oldDescriptor.ServiceId != newDescriptor.ServiceId)\n        {\n            _serviceCommands = _serviceCommands\n                .Where(i => i.ServiceId != oldDescriptor.ServiceId)\n                .Concat(new[] { newDescriptor }).ToArray();\n        }\n        else\n        {\n            _serviceCommands = _serviceCommands\n                .Where(i => i.ServiceId != newDescriptor.ServiceId)\n                .Concat(new[] { newDescriptor }).ToArray();\n        }\n    }\n    else if (newDescriptor != null)\n    {\n        _serviceCommands = _serviceCommands\n            .Where(i => i.ServiceId != newDescriptor.ServiceId)\n            .Concat(new[] { newDescriptor }).ToArray();\n    }\n    else if (oldDescriptor != null)\n    {\n        _serviceCommands = _serviceCommands\n            .Where(i => i.ServiceId != oldDescriptor.ServiceId)\n            .ToArray();\n    }\n\n    //\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\n    OnChanged(new ValueChangedEventArgs<ServiceCommandDescriptor>(oldDescriptor, newDescriptor));\n}", "CodeBleu_score": 60.81687665437813}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n\t\tvar zooKeeper = _zooKeeperCall();\n\t\tvar currentData = _watcher.get_CurrentData();\n\t\tvar newData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path());\n\t\t_action(currentData, newData);\n\t\t_watcher.SetCurrentData(newData);\n\t}\n}", "CodeBleu_score": 25.989072222015764}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        var zooKeeper = _zooKeeperCall();\n        var newData = await zooKeeper.Item2.getDataAsync(watchedEvent.getPath()).ConfigureAwait(false);\n        _action(watchedEvent.getPath(), newData);\n        _watcher.SetCurrentData(watchedEvent.getPath(), newData);\n    }\n}", "CodeBleu_score": 50.429876969119434}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        var zooKeeper = _zooKeeperCall();\n        var currentData = _watcher.GetCurrentData();\n        var newData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path()).ConfigureAwait(false);\n        _action(currentData, newData);\n        _watcher.SetCurrentData(newData);\n    }\n}", "CodeBleu_score": 29.750510216049854}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 91.90781942212435}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 91.90781942212435}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 91.90781942212435}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t_logger.LogInformation(\"Beginning to set MQTT service routes in ZooKeeper...\");\n\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n\n    foreach (var zooKeeper in zooKeepers) {\n        try {\n            await zooKeeper.CreateNodeWithDataAsync(\n                MqttServiceRoute.GetMqttServiceRouteRootPath(),\n                null,\n                ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                CreateMode.PERSISTENT\n            );\n            _logger.LogInformation(\"Created root node for MQTT service routes.\");\n        } catch (KeeperException.NodeExistsException) {\n            _logger.LogInformation(\"Root node for MQTT service routes already exists.\");\n        }\n\n        var path = MqttServiceRoute.GetMqttServiceRoutePath();\n        var pathCreated = await zooKeeper.CreateNodeWithDataAsync(\n            path,\n            null,\n            ZooDefs.Ids.OPEN_ACL_UNSAFE,\n            CreateMode.PERSISTENT\n        );\n        if (pathCreated) {\n            _logger.LogInformation(\"Created MQTT service route path.\");\n        }\n\n        foreach (var route in routes) {\n            var nodePath = MqttServiceRoute.GetMqttServiceRouteNodePath(route);\n            var nodeData = route.ToByteArray();\n            var nodeCreated = await zooKeeper.CreateNodeWithDataAsync(\n                nodePath,\n                nodeData,\n                ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                CreateMode.PERSISTENT\n            );\n            if (nodeCreated) {\n                _logger.LogInformation(\"Created MQTT service route node: {nodePath}\", nodePath);\n            } else {\n                var updateResult = await zooKeeper.SetDataAsync(nodePath, nodeData);\n                _logger.LogInformation(\"Set data for MQTT service route node: {nodePath}\", nodePath);\n            }\n        }\n\n        _logger.LogInformation(\"Successfully added MQTT service routes to ZooK", "CodeBleu_score": 41.62464830485089}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tvar logger = _logger.ForContext<MqttRouteManager>();\n    logger.LogInformation(\"Adding routes...\");\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        logger.LogInformation(\"Ensuring MQTT route path subdirectory exists...\");\n        await zooKeeper.CreateNodeRecursivelyAsync(_confi\n\n\n\n\n", "CodeBleu_score": 15.281529900961871}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tvar path = _confi", "CodeBleu_score": 2.5601280491148355}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    var zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var deletedRouteTopic in deletedRouteTopics) {\n        var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (deletedRoute != null && deletedRoute.Addresses.Contains(hostAddr)) {\n            var addresses = deletedRoute.Addresses.Except(new[] { hostAddr }).ToArray();\n            await zooKeeper.Item2.deleteAsync($\"/dotnetty.mqtt/routes/{deletedRouteTopic}\", -1);\n            if (addresses.Length > 0) {\n                var newRoute = new MqttServiceRoute {\n                    MqttDescriptor = deletedRoute.MqttDescriptor,\n                    MqttEndpoint = new IPEndPointModel {\n                        Addresses = addresses\n                    }\n                };\n                await CreateRouteNode(zooKeeper.Item1, zooKeeper.Item2, newRoute);\n            }\n        }\n    }\n}", "CodeBleu_score": 61.55980077214327}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    var zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n    var addresses = zooKeeper.Item2.getChildrenAsync(ZookeeperManager.GetRoutePath).Result.Children.Select(c => c.Substring(0, c.LastIndexOf('_')));\n    foreach (var routeTopic in deletedRouteTopics) {\n        var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == routeTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (addresses.Contains(deletedRoute)) {\n            var path = ZookeeperManager.GetRoutePath + \"/\" + routeTopic + \"_\" + deletedRoute;\n            await zooKeeper.Item2.deleteAsync(path);\n        }\n    }\n}", "CodeBleu_score": 56.143875626590045}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tvar oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var deletedRouteTopic in deletedRouteTopics) {\n        var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (deletedRoute != null) {\n            var addresses = deletedRoute.Addresses.Select(i => i.ToAddressModel()).ToArray();\n            var address = addresses.FirstOrDefault(i => i.Equals(hostAddr));\n            if (address != null) {\n                var zooKeeperClient = zooKeeper.Item2;\n                var path = $\"{_zookeeperConfiguration.RoutePath}/{deletedRouteTopic}\";\n                await zooKeeperClient.deleteAsync(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 61.54262470210096}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (cacheDescriptors == null) {\n        throw new ArgumentNullException(nameof(cacheDescriptors));\n    }\n\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n    if (zooKeepers == null || !zooKeepers.Any()) {\n        throw new ArgumentException(\"Zookeeper client collection is null or empty\");\n    }\n\n    var cachePath = _configInfo.CachePath;\n    if (string.IsNullOrEmpty(cachePath)) {\n        throw new ArgumentNullException(nameof(_configInfo.CachePath));\n    }\n\n    var rootPath = _configInfo.RootPath;\n    if (!rootPath.EndsWith(\"/\")) {\n        rootPath += \"/\";\n    }\n\n    var path = $\"{rootPath}{cachePath}\";\n    if (!path.StartsWith(\"/\")) {\n        path = $\"/{path}\";\n    }\n\n    foreach (var zooKeeper in zooKeepers) {\n        if (await zooKeeper.ExistsAsync(path) == null) {\n            await zooKeeper.CreateAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        }\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var nodePath = $\"{path}{cacheDescriptor.CacheDescriptorId}\";\n            if (await zooKeeper.ExistsAsync(nodePath) == null) {\n                var nodeData = _serializer.Serialize(cacheDescriptor);\n                await zooKeeper.CreateAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            } else {\n                var nodeBytes = (await zooKeeper.GetDataAsync(nodePath)).ToArray();\n                var cacheDescriptorNew = _serializer.Deserialize<ServiceCacheDescriptor>(nodeBytes);\n                if (cacheDescriptorNew.CacheDescriptorId != cacheDescriptor.CacheDescriptorId ||\n                    cacheDescriptorNew.LastRefreshtime != cacheDescriptor.LastRefreshtime ||\n                    !Data", "CodeBleu_score": 53.0033147368673}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t_logger.LogInformation(\"Setting service caches\");\n    var zooKeepers = await _zooKeeperProvider.GetZooKeepers();\n    var cachePath = _confi\n    foreach (var zooKeeper in zooKeepers) {\n        await zooKeeper.CreateNodeRecursivelyAsync(cachePath);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cacheDescriptorBytes = Serialize(cacheDescriptor);\n            var nodePath = $\"{cachePath}/{cacheDescriptor.ServiceName}\";\n            var nodeData = await zooKeeper.GetDataAsync(nodePath);\n            if (nodeData == null) {\n                await zooKeeper.CreateNodeAsync(nodePath, cacheDescriptorBytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            } else if (!DataEquals(nodeData, cacheDescriptorBytes)) {\n                await zooKeeper.SetDataAsync(nodePath, cacheDescriptorBytes);\n            }\n        }\n    }\n    _logger.LogInformation(\"Set service caches\");\n}", "CodeBleu_score": 39.74287579499636}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tvar nodePath = $\"{_confi\n        _logger.LogInformation(\n            \"Setting caches for {serviceName} with {count} descriptors.\",\n            _confi\n            cacheDescriptors.Count());\n\n        var zooKeeperClients = _zooKeeperProvider.GetZooKeepers();\n        foreach (var zooKeeper in zooKeeperClients) {\n            var cachePath = $\"{_confi\n            if (await zooKeeper.ExistsAsync(cachePath) == null) {\n                await zooKeeper.CreateAsync(\n                    cachePath,\n                    null,\n                    ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                    CreateMode.PERSISTENT);\n            }\n\n            foreach (var cacheDescriptor in cacheDescriptors) {\n                var nodeData = Serialize(cacheDescriptor);\n                var nodePath = $\"{cachePath}/{cacheDescriptor.CacheId}\";\n                if (await zooKeeper.ExistsAsync(nodePath) == null) {\n                    await zooKeeper.CreateAsync(\n                        nodePath,\n                        nodeData,\n                        ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                        CreateMode.PERSISTENT);\n                } else {\n                    var currentData = await zooKeeper.GetDataAsync(nodePath);\n                    if (!DataEquals(nodeData, currentData)) {\n                        await zooKeeper.SetDataAsync(nodePath, nodeData);\n                    }\n                }\n            }\n        }\n\n        _logger.LogInformation(\n            \"Set caches for {serviceName} with {count} descriptors.\",\n            _confi\n            cacheDescriptors.Count());\n    }\n\n    private static bool DataEquals(byte[] data1, byte[] data2) {\n        if (data1.Length != data2.Length) {\n            return false;\n        }\n\n        for (var i = 0; i < data1.Length; i++) {\n            if (data1[i] != data2[i]) {\n                return false;", "CodeBleu_score": 52.8761998315193}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tzooKeeper.Item2.existsAsync(path, null).Wait();\n    if (zooKeeper.Item2.existsAsync(path, null).Result == null) {\n        _logger.LogInformation(\"Creating Zookeeper node path: \" + path);\n        string[] pathParts = path.Split('/');\n        string currentPath = \"\";\n        foreach (string pathPart in pathParts) {\n            if (pathPart.Length > 0) {\n                currentPath += \"/\" + pathPart;\n                if (zooKeeper.Item2.existsAsync(currentPath, null).Result == null) {\n                    await zooKeeper.Item2.createAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 50.54785487890702}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation(\"Creating Zookeeper subdirectory {Path}\", path);\n    zooKeeper.Item2.existsAsync(path, null, (_, result) => {\n        if (result.ResultCode == KeeperException.Code.NONODE) {\n            _logger.LogInformation(\"Subdirectory {Path} does not exist\", path);\n            zooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT, (_, _) => {\n                _logger.LogInformation(\"Subdirectory {Path} created\", path);\n                zooKeeper.Item1.Set();\n            }, null);\n        } else {\n            _logger.LogInformation(\"Subdirectory {Path} exists\", path);\n            zooKeeper.Item1.Set();\n        }\n    }, null);\n    zooKeeper.Item1.WaitOne();\n}", "CodeBleu_score": 47.613031264965485}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t_logger.LogInformation(\"Creating Zookeeper subdirectory {path} if it does not exist\", path);\n    zooKeeper.Item2.existsAsync(path, false, null);\n    zooKeeper.Item1.WaitOne();\n    if (zooKeeper.Item2.existsAsync(path, false, null) == null) {\n        _logger.LogInformation(\"Creating Zookeeper subdirectory {path}\", path);\n        var pathSegments = path.Split('/');\n        var subdirectoryPath = \"\";\n        foreach (var pathSegment in pathSegments) {\n            if (pathSegment.Length == 0) continue;\n            subdirectoryPath += \"/\" + pathSegment;\n            zooKeeper.Item2.existsAsync(subdirectoryPath, false, null);\n            zooKeeper.Item1.WaitOne();\n            if (zooKeeper.Item2.existsAsync(subdirectoryPath, false, null) == null) {\n                await zooKeeper.Item2.createAsync(subdirectoryPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 49.291580287898086}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var ipAddress in _config.IpAddresses)\n    {\n        if (await _healthCheckService.IsHealth(ipAddress))\n        {\n            result.Add(CreateZooKeeper(ipAddress));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 78.07768321555395}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var ipAddress in _config.IpAddresses) {\n        if (await _healthCheckService.IsHealth(ipAddress)) {\n            result.Add(CreateZooKeeper(ipAddress));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 76.74738801756732}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var ipAddress in _config.IpAddresses) {\n        if (await _healthCheckService.IsHealth(ipAddress)) {\n            result.Add(CreateZooKeeper(ipAddress));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 76.74738801756732}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\tsynchronized (this) {\n            if (zk == null) {\n                zk = new ZooKeeper(getConnectionString(), getSessionTimeout(), this);\n            }\n            return zk;\n        }\n    }", "CodeBleu_score": 29.160630746913036}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\tsynchronized (this) {\n            if (zk == null) {\n                String connectionString = ensembleProvider.getConnectionString();\n                LOG.debug(\"Creating new ZooKeeper instance with connection string: {}\", connectionString);\n                zk = new ZooKeeper(connectionString, sessionTimeout, watcher);\n                helper = new ZooKeeperHelper(zk, ensembleProvider, sessionTimeout, watcher);\n            }\n            return zk;\n        }\n    }", "CodeBleu_score": 42.887695522271216}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\tsynchronized (this) {\n            if (zooKeeper == null) {\n                zooKeeper = newZooKeeper();\n            }\n            return zooKeeper;\n        }\n    }", "CodeBleu_score": 20.19291141184616}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\tif (zooKeeper != null) {\n        if (waitForShutdownTimeoutMs > 0) {\n            // Register a dummy watcher to prevent new events from being processed\n            zooKeeper.register(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    // Do nothing\n                }\n            });\n            // Wait for the specified timeout before closing\n            Thread.sleep(waitForShutdownTimeoutMs);\n        }\n        // Close the ZooKeeper instance\n        zooKeeper.close();\n    }\n}", "CodeBleu_score": 30.19574234729916}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\tif (zk == null) {\n        return;\n    }\n    try {\n        zk.register(new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n            }\n        });\n        if (waitForShutdownTimeoutMs <= 0) {\n            zk.close();\n        } else {\n            zk.close(waitForShutdownTimeoutMs);\n        }\n    } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n    }\n    zk = null;\n}", "CodeBleu_score": 40.19867331238303}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\tif (zk != null) {\n        // first try to close the ZooKeeper instance\n        try {\n            zk.close();\n        } catch (InterruptedException e) {\n            // restore the interrupt status and continue\n            Thread.currentThread().interrupt();\n        }\n\n        // then wait for the specified timeout\n        if (waitForShutdownTimeoutMs > 0) {\n            // wait for the specified timeout\n            Thread.sleep(waitForShutdownTimeoutMs);\n        }\n    }\n}", "CodeBleu_score": 23.6783239101775}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\tboolean isConnected = false;\n    try (OperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\")) {\n        trace.setDetail(\"timeout\", connectionTimeoutMs);\n        isConnected = state.blockUntilConnected(connectionTimeoutMs);\n    }\n    return isConnected;\n}", "CodeBleu_score": 28.897528357311884}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\treturn blockUntilConnectedOrTimedOut(connectionTimeoutMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 5.478188465361449}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\tOperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n    try {\n        internalBlockUntilConnectedOrTimedOut();\n        return state.isConnected();\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 31.581165414451483}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\ttry {\n        log.info(\"Shutting down {}\", getName());\n        setStarted(false);\n        closeState(waitForShutdownTimeoutMs);\n    } catch (IOException e) {\n        if (checkInterrupted(e)) {\n            log.info(\"Interrupted while closing {}\", getName());\n        } else {\n            log.error(\"Error closing {}\", getName(), e);\n        }\n    }\n}", "CodeBleu_score": 54.5580890223179}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tlog.info(\"Attempting to shut down service\");\n    started.set(false);\n    try {\n        if (service != null) {\n            service.close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n        }\n    } catch (IOException e) {\n        if (Thread.currentThread().isInterrupted()) {\n            log.info(\"Thread interrupted while shutting down service\");\n        } else {\n            log.error(\"Error while shutting down service\", e);\n        }\n    }\n}", "CodeBleu_score": 55.149251489934144}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tlogger.info(\"Closing service.\");\n    this.started = false;\n    try {\n        this.service.close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (IOException e) {\n        if (Thread.currentThread().isInterrupted()) {\n            logger.warn(\"Service interrupted while closing.\");\n        } else {\n            logger.error(\"Error while closing service.\", e);\n        }\n    }\n}", "CodeBleu_score": 43.29082767554172}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tif (this.connectionTimeout == 0) {\n        this.blockUntilConnected();\n    } else {\n        final CountDownLatch latch = new CountDownLatch(1);\n        final Watcher watcher = new Watcher() {\n            public void process(WatchedEvent event) {\n                if (event.getState() == Event.KeeperState.SyncConnected) {\n                    latch.countDown();\n                }\n            }\n        };\n        this.register(watcher);\n        try {\n            long remainingTimeout = this.connectionTimeout;\n            while (true) {\n                try {\n                    latch.await(remainingTimeout, TimeUnit.MILLISECONDS);\n                    break;\n                } catch (InterruptedException e) {\n                    this.unregister(watcher);\n                    throw e;\n                }\n                remainingTimeout = this.connectionTimeout - (System.currentTimeMillis() - this.startTime);\n                if (remainingTimeout <= 0) {\n                    break;\n                }\n                this.unregister(watcher);\n                this.register(watcher);\n            }\n        } finally {\n            this.unregister(watcher);\n        }\n    }\n}", "CodeBleu_score": 38.86007169323273}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tfinal CountDownLatch latch = new CountDownLatch(1);\n    final Watcher watcher = new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            if (event.getState() == Event.KeeperState.SyncConnected) {\n                latch.countDown();\n            }\n        }\n    };\n    try {\n        addWatcher(watcher);\n        long waitTime = this.connectionTimeout;\n        while (true) {\n            if (latch.await(waitTime, TimeUnit.MILLISECONDS)) {\n                break;\n            }\n            if (!watcher.getState().isAlive()) {\n                throw new IllegalStateException(\"Watcher died\");\n            }\n            waitTime = this.connectionTimeout - (this.connectionTimeout - latch.getCount()) * 2;\n            if (waitTime <= 0) {\n                throw new IllegalStateException(\"Connection timed out\");\n            }\n        }\n    } finally {\n        removeWatcher(watcher);\n    }\n}", "CodeBleu_score": 44.698859478461294}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tfinal long startTime = System.currentTimeMillis();\n    final long timeout = getConnectionTimeout();\n    final long interval = getConnectionTimeoutCheckInterval();\n\n    final CountDownLatch latch = new CountDownLatch(1);\n\n    Watcher watcher = new Watcher() {\n        public void process(WatchedEvent event) {\n            if (event.getState() == KeeperState.SyncConnected) {\n                latch.countDown();\n            }\n        }\n    };\n\n    try {\n        for (long waitTime = timeout; waitTime > 0; waitTime -= interval) {\n            if (getState() == CuratorFrameworkState.STOPPED) {\n                throw new IllegalStateException(\"Instance was stopped before connecting\");\n            }\n\n            if (getZooKeeperClient().blockUntilConnectedOrTimedOut(interval, TimeUnit.MILLISECONDS)) {\n                return;\n            }\n\n            getZooKeeperClient().getZooKeeper().register(watcher);\n            try {\n                if (latch.await(waitTime, TimeUnit.MILLISECONDS)) {\n                    return;\n                }\n            } finally {\n                getZooKeeperClient().getZooKeeper().unregister(watcher);\n            }\n        }\n    } finally {\n        latch.countDown();\n    }\n\n    throw new InterruptedException(\"Timed out waiting to connect. Connection time exceeded \" + timeout + \" ms\");\n}", "CodeBleu_score": 38.91436079507311}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode.isEphemeral()) {\n            if (client.getSessionId() != protectedId) {\n                LOG.debug(\"Session has changed, deleting old ephemeral node \" + foundNode);\n                client.delete().forPath(foundNode);\n                protectedId = client.getSessionId();\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 29.078987397295197}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode.isEphemeral()) {\n            if (doProtected()) {\n                if (client.getZooKeeper().getSessionId() != sessionId) {\n                    log.warn(\"Session has changed during protected mode operation. Deleting znode \" + foundNode);\n                    deleteNode(client, foundNode);\n                    sessionId = client.getZooKeeper().getSessionId();\n                }\n            } else {\n                sessionId = client.getZooKeeper().getSessionId();\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 41.67763352099879}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode == CreateMode.EPHEMERAL) {\n            if (client.getZooKeeper().getSessionId() != sessionId) {\n                client.getFailedDeleteManager().addFailedDelete(foundNode);\n                client.logError(\"Session has changed. Deleting ephemeral node \" + foundNode, null);\n                client.delete().forPath(foundNode);\n                sessionId = client.getZooKeeper().getSessionId();\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 36.884926961479756}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tfinal Trace trace = getZooKeeper().startAdvancedTrace(\"setACL\", \"path\", path);\n    Stat stat = null;\n    boolean isDone = false;\n    for (int retry = 0; retry < 3; retry++) {\n        try {\n            stat = getZooKeeper().setACL(path, aclList, -1);\n            isDone = true;\n        } catch (final KeeperException.NoNodeException e) {\n            getZooKeeper().create(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        }\n    }\n    trace.setResult(stat, isDone);\n    trace.commit();\n    return stat;\n}", "CodeBleu_score": 34.87099116573628}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tStat stat = null;\n    boolean isDone = false;\n    int retryCount = 0;\n\n    while (!isDone) {\n        try {\n            stat = getZooKeeper().setACL(path, aclList, -1);\n            isDone = true;\n        } catch (Exception e) {\n            retryCount++;\n            if (retryCount > 3) {\n                throw e;\n            }\n            Thread.sleep(1000);\n        }\n    }\n\n    return stat;\n}", "CodeBleu_score": 26.3904402620035}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t// Start an advanced trace for the operation\n    Trace trace = getZooKeeper().startAdvancedTrace(\"setACL\", path);\n\n    // Define the retry loop\n    RetryLoop retryLoop = new RetryLoop() {\n        public boolean execute() throws Exception {\n            // Set the ACL in ZooKeeper\n            Stat stat = getZooKeeper().setACL(path, aclList, -1);\n\n            // Record the result in the trace\n            trace.addData(\"path\", path);\n            trace.addData(\"status\", stat);\n\n            // Return true if the ACL was set successfully\n            return stat != null;\n        }\n    };\n\n    // Execute the retry loop\n    boolean result = retryLoop.execute();\n\n    // Commit the trace\n    trace.commit();\n\n    return result ? trace.getData(\"status\") : null;\n}", "CodeBleu_score": 44.85390715739591}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tPreconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkNotNull(payload, \"payload cannot be null\");\n    Preconditions.checkArgument(thisId.length() > 0, \"thisId cannot be empty\");\n    Preconditions.checkArgument(payload.length > 0, \"payload cannot be empty\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    // Create a CuratorCache for the membership path\n    this.cache = CuratorCache.build(client, membershipPath);\n\n    // Create a PersistentNode for this member\n    this.node = new PersistentNode(client, CreateMode.EPHEMERAL, false, membershipPath, payload);\n}", "CodeBleu_score": 48.021735564056186}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tthis.client = client;\n  this.membershipPath = membershipPath;\n  this.thisId = thisId;\n  this.payload = payload;\n\n  checkNotNull(this.client, \"client cannot be null\");\n  checkNotNull(this.membershipPath, \"membershipPath cannot be null\");\n  checkNotNull(this.thisId, \"thisId cannot be null\");\n\n  if (!this.thisId.matches(\"[a-zA-Z0-9_-]+\")) {\n    throw new IllegalArgumentException(\"thisId must be alpha-numeric with dashes and underscores\");\n  }\n\n  try {\n    this.cache = CuratorCache.build(this.client, this.membershipPath);\n    this.cache.start();\n  } catch (Exception e) {\n    throw new RuntimeException(e);\n  }\n\n  this.node = new PersistentNode(this.client, PersistentNode.Mode.EPHEMERAL, this.membershipPath + \"/\" + this.thisId, this.payload);\n}", "CodeBleu_score": 42.253911193905886}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tPreconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    // check the validity of the member ID\n    try {\n        PathUtils.validatePath(this.thisId);\n    } catch (IllegalArgumentException e) {\n        throw new IllegalArgumentException(\"Invalid member ID: \" + this.thisId, e);\n    }\n\n    // set up a CuratorCache for the specified membership path\n    this.cache = CuratorCache.build(client, membershipPath);\n    this.cache.start();\n\n    // create a PersistentNode with ephemeral mode for the member using the provided payload\n    this.member = new PersistentNode(client, CreateMode.EPHEMERAL, true, membershipPath + \"/\" + thisId, payload);\n}", "CodeBleu_score": 49.43900857271035}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n    // create a node at the given path with the given payload asynchronously\n    async.create().forPath(path).whenComplete((name, exception) -> {\n        if (exception != null) {\n            // there was a problem\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Created node name is: \" + name);\n            // setup a watch on the node\n            async.checkExists().forPath(path).whenComplete((stat, ex) -> {\n                if (ex != null) {\n                    ex.printStackTrace();\n                } else {\n                    System.out.println(\"Node: \" + path + \" stat: \" + stat);\n                    // setup a watch on the node\n                    async.checkExists().watched().forPath(path).whenComplete((stat2, ex2) -> {\n                        if (ex2 != null) {\n                            ex2.printStackTrace();\n                        } else {\n                            System.out.println(\"Node: \" + path + \" stat: \" + stat2);\n                        }\n                    });\n                }\n            });\n        }\n    });\n}", "CodeBleu_score": 73.13124682747069}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n    async.create()\n            .forPath(path)\n            .whenComplete((name, exception) -> {\n                if (exception != null) {\n                    exception.printStackTrace();\n                } else {\n                    System.out.println(\"Created node name is: \" + name);\n                    watch(client, path);\n                }\n            });\n}", "CodeBleu_score": 72.9446913995691}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n    async.create().forPath(path).whenComplete((name, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Created node name is: \" + name);\n        }\n    });\n    async.checkExists().forPath(path).whenComplete((stat, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Node exists: \" + stat);\n        }\n    });\n}", "CodeBleu_score": 77.70624812755791}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = client.transaction().forOperations(transaction.getOperations()).commit();\n    OpResult result = results.get(0);\n    if (result instanceof ErrorResult) {\n        ErrorResult errorResult = (ErrorResult) result;\n        throw KeeperException.create(KeeperException.Code.get(errorResult.getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 35.46557306728723}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = transaction.commit();\n    if (results.isEmpty()) {\n        throw new KeeperException.BadArgumentsException();\n    }\n    OpResult result = results.get(0);\n    if (result instanceof ErrorResult) {\n        ErrorResult error = (ErrorResult) result;\n        throw KeeperException.create(Code.get(error.getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 29.673297049409026}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> results = client.getZooKeeperClient().getZooKeeper().multi(transaction.getOperations());\n\n    if (results.get(0).getType() == ZooDefs.OpCode.error) {\n        throw KeeperException.create(KeeperException.Code.get(((ErrorResult) results.get(0)).getErr()));\n    }\n\n    return results;\n}", "CodeBleu_score": 28.895243879561917}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\ttry {\n        System.out.println(\"Querying for service instances...\");\n        for (String serviceName : serviceDiscovery.queryForNames()) {\n            System.out.println(serviceName);\n            for (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(serviceName)) {\n                outputInstance(instance);\n            }\n        }\n    } catch (NoNodeException e) {\n        System.out.println(\"No service instances registered\");\n    } finally {\n        closeQuietly(serviceDiscovery);\n    }\n}", "CodeBleu_score": 49.690400487783435}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\ttry {\n        // Query for all service names and their instances\n        ServiceCache<InstanceDetails> cache = serviceDiscovery.serviceCacheBuilder().build();\n        cache.start();\n        // Print each service name and its instances\n        for (String serviceName : cache.getServices()) {\n            System.out.println(serviceName);\n            for (ServiceInstance<InstanceDetails> instance : cache.getInstances(serviceName)) {\n                outputInstance(instance);\n            }\n        }\n    } catch (NoNodeException e) {\n        System.out.println(\"No services registered.\");\n    }\n    // Close the ServiceDiscovery instance\n    closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 48.91505325033195}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\ttry {\n        for (String serviceName : serviceDiscovery.queryForNames()) {\n            System.out.println(serviceName);\n            for (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(serviceName)) {\n                outputInstance(instance);\n            }\n        }\n    } catch (NoNodeException e) {\n        System.out.println(\"No instances registered.\");\n    } finally {\n        closeQuietly(serviceDiscovery);\n    }\n}", "CodeBleu_score": 48.5741506948446}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\treturn children.stream()\n\t\t\t.filter(child -> !child.equals(READY_NODE))\n\t\t\t.sorted()\n\t\t\t.collect(Collectors.toList());\n}", "CodeBleu_score": 15.445720075954378}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\tList<String> filteredChildren = children.stream().filter(child -> !child.equals(READY_NODE)).collect(Collectors.toList());\n    Collections.sort(filteredChildren);\n    return filteredChildren;\n}", "CodeBleu_score": 35.552177516705505}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\treturn children.stream()\n        .filter(n -> !n.equals(READY_NODE))\n        .sorted()\n        .collect(Collectors.toList());\n}", "CodeBleu_score": 16.409929036479443}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk != null) {\n        zk.close();\n    }\n\n    zk = new ZooKeeper(newHost, Integer.parseInt(options.get(\"-timeout\")), this);\n    zk.addAuthInfo(\"digest\", (\"ben:passwd\").getBytes());\n}", "CodeBleu_score": 40.70505215672496}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tclose();\n        zk = new ZooKeeper(newHost, timeout, this);\n        setState(State.CONNECTING);\n    }", "CodeBleu_score": 14.151547284310723}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t// Close existing connection, if any\n            close();\n\n            // Connect to new host\n            zk = new ZooKeeper(newHost, timeout, this);\n\n            // Set read-only mode based on command-line option\n            if (getOption(\"read-only\").equals(\"true\")) {\n                zk.addAuthInfo(\"digest\", \"pat:passwd\".getBytes());\n            }\n        }", "CodeBleu_score": 25.814392780279977}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acl = new ArrayList<ACL>();\n        String[] aclSegments = aclString.split(\",\");\n        for (int i = 0; i < aclSegments.length; i++) {\n            String[] aclFields = aclSegments[i].split(\":\");\n            if (aclFields.length != 3) {\n                outputStream.write((\"Invalid ACL segment \" + aclSegments[i]).getBytes());\n                continue;\n            }\n            ACL newAcl = new ACL();\n            newAcl.setId(new Id(aclFields[0], aclFields[1]));\n            newAcl.setPerms(getPermFromString(aclFields[2]));\n            acl.add(newAcl);\n        }\n        return acl;\n    }", "CodeBleu_score": 42.240447158830776}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\n        String[] aclSegments = aclString.split(\",\");\n        for (String aclSegment : aclSegments) {\n            String[] aclFields = aclSegment.split(\":\");\n            if (aclFields.length != 3) {\n                outputStream.write((\"Invalid ACL segment: \" + aclSegment).getBytes());\n                continue;\n            }\n            ACL acl = new ACL();\n            acl.setId(new Id(aclFields[0], aclFields[1]));\n            acl.setPerms(getPermFromString(aclFields[2]));\n            aclList.add(acl);\n        }\n        return aclList;\n    }", "CodeBleu_score": 33.06480918309121}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\n        String[] aclArray = aclString.split(\",\");\n        for (String acl : aclArray) {\n            String[] aclSegments = acl.split(\":\");\n            if (aclSegments.length == 3) {\n                ACL newAcl = new ACL();\n                newAcl.setId(new Id(aclSegments[0], aclSegments[1]));\n                newAcl.setPerms(getPermFromString(aclSegments[2]));\n                aclList.add(newAcl);\n            } else {\n                outputStream.write((\"Invalid ACL: \" + acl).getBytes());\n            }\n        }\n        return aclList;\n    }", "CodeBleu_score": 35.06187734134017}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeperMap.get(serverId).delete(path);\n        }\n    } else {\n        zookeeperMap.get(serverId).deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 99.45743761910349}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeperMap.get(serverId).delete(path);\n        }\n    } else {\n        zookeeperMap.get(serverId).deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 99.45743761910349}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeperMap.get(serverId).delete(path);\n        }\n    } else {\n        zookeeperMap.get(serverId).deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 99.45743761910349}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter.write(String.format(\"Connecting to Zookeeper at %s...\n\", url));\n        var connection = factory.create(new ZookeeperParams(id, url));\n        var client = connection.getClient();\n        writer.write(String.format(\"Connected to Zookeeper at %s!\n\", url));\n        var main = new ZooKeeperMain(client);\n        return new Terminal(id, url, connection, main);\n    }", "CodeBleu_score": 38.70529360904733}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter.write(\"Connecting to Zookeeper at \" + url + \"\n\");\n        var connection = factory.create(params);\n        var client = connection.getClient();\n        writer.write(\"Successfully connected to Zookeeper at \" + url + \"\n\");\n        var main = new ZooKeeperMain(client);\n        return new Terminal(id, url, connection, main);\n    }", "CodeBleu_score": 39.51539406523814}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\twriter.write(\"Connecting to \" + url + \"\n\");\n        var connection = factory.create(ZookeeperParams.builder()\n                .id(id)\n                .url(url)\n                .aclList(aclList)\n                .maxRetries(connectionConfiguration.getMaxRetries())\n                .connectionTimeout(connectionConfiguration.getConnectionTimeout())\n                .retryIntervalTime(connectionConfiguration.getRetryIntervalTime())\n                .sessionTimeout(connectionConfiguration.getSessionTimeout())\n                .build());\n        var client = connection.getClient();\n        writer.write(\"Connected to \" + url + \"\n\");\n        var zkMain = new ZooKeeperMain(client);\n        return new Terminal(id, url, connection, zkMain);\n    }", "CodeBleu_score": 54.25675059880825}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tfor (int i = 0; i < 6; i++) {\n            try {\n                if (sshClient.isConnected()) {\n                    break;\n                }\n                sshClient.connect();\n                proxySocket = sshClient.openProxySocket(host, port);\n                break;\n            } catch (Exception e) {\n                logger.error(\"SSH Tunnel connection failed, retrying...\", e);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e1) {\n                    throw new IllegalStateException(e1);\n                }\n            }\n        }\n        if (!sshClient.isConnected()) {\n            close();\n            throw new IllegalStateException(\"SSH Tunnel connection failed\");\n        }\n    }", "CodeBleu_score": 40.62469567551902}, {"code": "public void blockUntilConnected(){\n\tint retries = 0;\n        while (!isConnected()) {\n            try {\n                connect();\n                retries++;\n            } catch (IOException e) {\n                log.error(\"Exception while attempting to connect to SSH tunnel\", e);\n                close();\n                throw new IllegalStateException(e);\n            }\n            if (retries > 6) {\n                close();\n                throw new IllegalStateException(\"Unable to establish SSH tunnel connection\");\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                log.error(\"Exception while attempting to sleep\", e);\n                close();\n                throw new IllegalStateException(e);\n            }\n        }\n    }", "CodeBleu_score": 40.84263057372309}, {"code": "public void blockUntilConnected(){\n\tint attempts = 0;\n        while (!sshClient.isConnected()) {\n            try {\n                sshClient.connect();\n            } catch (IOException e) {\n                logger.error(\"Failed to establish SSH tunnel connection on attempt \" + attempts + \" of 6\", e);\n                close();\n                throw new IllegalStateException(e);\n            }\n            if (!sshClient.isConnected()) {\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException e) {\n                    logger.error(\"Interrupted while waiting to retry SSH tunnel connection\", e);\n                }\n                attempts++;\n                if (attempts > 6) {\n                    close();\n                    throw new IllegalStateException(\"Failed to establish SSH tunnel connection after 6 attempts\");\n                }\n            }\n        }\n    }", "CodeBleu_score": 45.60055309515791}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"Exception occurred while deleting node\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 82.5789972268653}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"Error deleting nodes\", e);\n        throw new IllegalStateException(\"Error deleting nodes\", e);\n    }\n}", "CodeBleu_score": 68.20729888616695}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        LOGGER.error(\"Error deleting node for serverId: \" + serverId + \" and pathList: \" + pathList, e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 69.99538809797548}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\n        ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        treeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 92.2321062355902}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\n        ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        treeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 92.2321062355902}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\n        ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        treeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 92.2321062355902}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\tServer server = getById(serverId);\n    String connectionUrl = getConnectionUrl(server);\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 18.98748664317677}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\tServer server = getById(serverId);\n    String url = getUrl(server);\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 17.112041458255316}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\tServer server = serverService.getById(serverId);\n    String url = getConnectionUrl(server);\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 21.453618852970248}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\ttry {\n    execute(id, command);\n  } catch (Exception e) {\n    log.error(\"Failed to execute command \" + command + \" on server \" + id, e);\n    error(\"Failed to execute command \" + command + \" on server \" + id + \". Please retry.\");\n  }\n}", "CodeBleu_score": 57.925155854111686}, {"code": "public void executeCommand(String id, String command){\n\ttry {\n        // Execute the command on the server\n    } catch (Exception e) {\n        // Log the error with the server ID and command\n        System.out.println(\"Command execution failed. Please retry.\");\n    }\n}", "CodeBleu_score": 29.3066245609354}, {"code": "public void executeCommand(String id, String command){\n\ttry {\n        execute(id, command);\n    } catch (Exception e) {\n        log.error(\"Error executing command \" + command + \" on server \" + id, e);\n        error(\"Error executing command \" + command + \" on server \" + id + \". Please retry.\");\n    }\n}", "CodeBleu_score": 58.07553045158027}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties props = new Properties();\n    File file = new File(System.getProperty(\"zookeeper.configfile\"));\n    if (file.exists()) {\n        try {\n            FileInputStream in = new FileInputStream(file);\n            props.load(in);\n            in.close();\n            log.info(\"Loaded \" + file);\n        } catch (IOException e) {\n            log.error(\"Unable to load \" + file, e);\n        }\n    } else {\n        log.error(file + \" not found\");\n    }\n    return props;\n}", "CodeBleu_score": 40.16059887395072}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties zookeeperProperties = new Properties();\n    String zookeeperPropertiesPath = System.getProperty(\"zookeeper.properties.path\");\n    if (zookeeperPropertiesPath == null) {\n        return zookeeperProperties;\n    }\n    File zookeeperPropertiesFile = new File(zookeeperPropertiesPath);\n    if (!zookeeperPropertiesFile.exists()) {\n        return zookeeperProperties;\n    }\n    try {\n        zookeeperProperties.load(new FileInputStream(zookeeperPropertiesFile));\n        for (String propertyName : zookeeperProperties.stringPropertyNames()) {\n            log.info(\"Loaded system property \" + propertyName + \" from \" + zookeeperPropertiesPath);\n        }\n    } catch (IOException e) {\n        log.error(\"Error loading system properties from \" + zookeeperPropertiesPath + \": \" + e.getMessage());\n    }\n    return zookeeperProperties;\n}", "CodeBleu_score": 42.74542646584709}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\n    try {\n        FileInputStream input = new FileInputStream(propertiesPath);\n        try {\n            properties.load(input);\n            log.info(\"Loaded Zookeeper System Properties from: \" + propertiesPath);\n            return properties;\n        } finally {\n            input.close();\n        }\n    } catch (FileNotFoundException e) {\n        log.error(\"Could not find Zookeeper System Properties file: \" + propertiesPath);\n        return properties;\n    } catch (IOException e) {\n        log.error(\"Error loading Zookeeper System Properties from: \" + propertiesPath);\n        return properties;\n    }\n}", "CodeBleu_score": 50.582072777316945}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Failed to load Zookeeper system properties from content.\", e);\n        showNotification(\"Failed to load Zookeeper system properties from content.\");\n        return;\n    }\n\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), \"\");\n    } catch (IOException e) {\n        log.error(\"Failed to save Zookeeper system properties to file.\", e);\n        showNotification(\"Failed to save Zookeeper system properties to file.\");\n        return;\n    }\n\n    showNotification(\"Zookeeper system properties saved successfully.\");\n}", "CodeBleu_score": 34.14527834977849}, {"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        LOG.error(\"Failed to load Zookeeper system properties from content.\", e);\n        showNotification(\"Failed to load Zookeeper system properties from content.\");\n        return;\n    }\n    try {\n        props.store(new FileOutputStream(SYS_PROP_PATH), \"\");\n    } catch (IOException e) {\n        LOG.error(\"Failed to save Zookeeper system properties to file.\", e);\n        showNotification(\"Failed to save Zookeeper system properties to file.\");\n        return;\n    }\n}", "CodeBleu_score": 32.11234140939687}, {"code": "public void saveZookeeperSystemProperties(String content){\n\tProperties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n        properties.store(new FileOutputStream(SYS_PROP_PATH), \"\");\n    } catch (IOException e) {\n        logger.error(\"Failed to save Zookeeper system properties\", e);\n        showNotification(\"Failed to save Zookeeper system properties\", e);\n    }\n}", "CodeBleu_score": 22.81689552324975}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tStringBuilder sb = new StringBuilder();\n    BufferedReader br = null;\n    try {\n        br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        String line;\n        while ((line = br.readLine()) != null) {\n            sb.append(line + \"\n\");\n        }\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    } finally {\n        cleanup(br);\n    }\n    return sb.toString();\n}", "CodeBleu_score": 58.05217752781938}, {"code": "private String response(Socket client){\n\tBufferedReader reader = null;\n        StringBuilder builder = new StringBuilder();\n        try {\n            reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n            String line;\n            while ((line = reader.readLine()) != null) {\n                builder.append(line);\n            }\n        } catch (IOException e) {\n            throw new IllegalStateException(e);\n        } finally {\n            cleanup(reader);\n            cleanup(client);\n        }\n        return builder.toString();\n    }", "CodeBleu_score": 60.09103448951848}, {"code": "private String response(Socket client){\n\tBufferedReader in = null;\n    StringBuilder sb = new StringBuilder();\n    try {\n        in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        String line;\n        while ((line = in.readLine()) != null) {\n            sb.append(line);\n        }\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    } finally {\n        cleanup(in);\n    }\n    return sb.toString();\n}", "CodeBleu_score": 57.74301444373153}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework client = curatorFramework(params);\n    client.start();\n    try {\n        blockUntilConnected(client, params.getConnectionTimeout());\n        return new CuratorZookeeperConnection(client, params);\n    } catch (Exception e) {\n        client.close();\n        throw new ZookeeperConnectionException(\"Failed to establish Zookeeper connection\", e);\n    }\n}", "CodeBleu_score": 60.40694958350562}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tfinal CuratorFramework curatorFramework = curatorFramework(params);\n    curatorFramework.start();\n    try {\n        blockUntilConnected(curatorFramework, params.getConnectionTimeout());\n    } catch (Exception e) {\n        curatorFramework.close();\n        throw new RuntimeException(e);\n    }\n    return new CuratorZookeeperConnection(curatorFramework, params);\n}", "CodeBleu_score": 50.52531833487682}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework curatorFramework = curatorFramework(params);\n    curatorFramework.start();\n    try {\n        blockUntilConnected(curatorFramework, params.getConnectionTimeout());\n    } catch (Exception e) {\n        close(curatorFramework);\n        throw new RuntimeException(e);\n    }\n    return new CuratorZookeeperConnection(curatorFramework, params);\n}", "CodeBleu_score": 49.03519078693021}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tString connectionString = getCurrentConnectionString();\n    if (isSync.compareAndSet(false, true)) {\n        getLogger().info(\"Synchronizing Zookeeper nodes with connection string: \" + connectionString);\n        try {\n            getListenable().addListener(new CuratorTreeCacheListener(listeners));\n            getTreeCache().start();\n        } catch (Exception e) {\n            getLogger().error(\"Error while synchronizing Zookeeper nodes: \" + e.getMessage(), e);\n            close();\n        }\n    } else {\n        getLogger().info(\"Synchronization already in progress\");\n    }\n}", "CodeBleu_score": 35.801472987531255}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tString connectionString = getCurrentConnectionString();\n    if (!isSync.get()) {\n        isSync.set(true);\n        LOG.info(\"Starting synchronization with Zookeeper nodes at {}\", connectionString);\n        try {\n            getListenable().addListener(new CuratorTreeCacheListener(listeners));\n            getTreeCache().start();\n        } catch (Exception e) {\n            LOG.error(\"Error synchronizing with Zookeeper nodes at {}\", connectionString, e);\n            try {\n                getTreeCache().close();\n            } catch (IOException ioe) {\n                LOG.error(\"Error closing Zookeeper tree cache\", ioe);\n            }\n        }\n    } else {\n        LOG.info(\"Synchronization with Zookeeper nodes at {} already in progress\", connectionString);\n    }\n}", "CodeBleu_score": 43.35831206428223}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tString currentConnectionString = getCurrentConnectionString();\n    if (isSync.compareAndSet(false, true)) {\n        LOGGER.info(\"Starting synchronization for connection string {}\", currentConnectionString);\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            LOGGER.error(\"Error synchronizing connection string {}\", currentConnectionString, e);\n            treeCache.close();\n        }\n    } else {\n        LOGGER.info(\"Synchronization already in progress for connection string {}\", currentConnectionString);\n    }\n}", "CodeBleu_score": 41.920046464603644}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\tPathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 92.2373669030745}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 73.3925166751341}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\tPathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 61.16797316857154}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\tLOG.info(\"Unregistering service...\");\n  for (String path : paths) {\n    try {\n      deletePath(path);\n    } catch (Exception e) {\n      LOG.error(getMessage(e));\n    }\n  }\n  close();\n}", "CodeBleu_score": 44.610147549745605}, {"code": "public void unregisterService(){\n\tlog.info(\"Unregistering services...\");\n    for (String path : paths) {\n        try {\n            deletePath(path);\n        } catch (Exception e) {\n            log.error(getMessage(e));\n        }\n    }\n    close();\n}", "CodeBleu_score": 48.28552453171987}, {"code": "public void unregisterService(){\n\tlog.info(\"Unregistering services...\");\n\n    for (String path : paths) {\n        try {\n            deletePath(path);\n        } catch (Exception e) {\n            log.error(getMessage(e));\n        }\n    }\n\n    close();\n}", "CodeBleu_score": 48.28552453171987}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> makeClientReady(new ZkClient(zkServers, sessionTimeout, connectionTimeout), null))\n            .exceptionally(e -> {\n                makeClientReady(null, e);\n                return null;\n            });\n\n    if (this.client != null) {\n        this.client.subscribeStateChanges(listener);\n    }\n}", "CodeBleu_score": 32.53923535737187}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> makeClientReady(new ZkClient(zkServers, sessionTimeout, connectionTimeout, ZKStringSerializer$.MODULE$), null))\n            .whenComplete((result, e) -> {\n                if (e != null) {\n                    logger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", e);\n                } else {\n                    this.client.subscribeStateChanges(listener);\n                }\n            });\n}", "CodeBleu_score": 44.545709186757776}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> {\n        makeClientReady(new ZkClient(zkServers, sessionTimeout, connectionTimeout), null);\n    }).whenComplete((v, e) -> {\n        if (e != null) {\n            logger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", e);\n        } else {\n            this.client.subscribeStateChanges(listener);\n        }\n    });\n}", "CodeBleu_score": 35.56440451006988}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper();\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.client = CuratorFrameworkFactory.newClient(serverAddr, retryPolicy);\n    if (authority != null) {\n        this.client.getZookeeperClient().setAuthInfo(\"digest\", authority.getBytes());\n    }\n    this.client.getConnectionStateListenable().addListener(this);\n    this.client.start();\n    try {\n        this.client.blockUntilConnected(10, TimeUnit.SECONDS);\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(\"Could not connect to Zookeeper server\", e);\n    }\n}", "CodeBleu_score": 23.328351878249887}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\ttry {\n        this.serverAddr = serverAddr;\n        this.authority = authority;\n        this.curator = CuratorFrameworkFactory.builder()\n                .connectString(serverAddr)\n                .sessionTimeoutMs(sessionTimeout)\n                .connectionTimeoutMs(connectionTimeout)\n                .retryPolicy(new ExponentialBackoffRetry(1000, 3))\n                .build();\n        if (authority != null) {\n            this.curator.getCuratorListenable().addListener(this);\n            this.curator.start();\n            this.curator.getZookeeperClient().getZooKeeper();\n            this.curator.getZookeeperClient().blockUntilConnectedOrTimedOut();\n            this.curator.getZookeeperClient().getZooKeeper().addAuthInfo(\"digest\", authority.getBytes());\n        } else {\n            this.curator.start();\n            this.curator.getZookeeperClient().blockUntilConnectedOrTimedOut();\n        }\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Error initializing Curator client\", e);\n    }\n}", "CodeBleu_score": 44.06506418668626}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis.serverAddr = serverAddr;\n    this.authority = authority;\n\n    // Set up a retry policy with a retry interval of 1000 ms and a max retry count of 5\n    RetryPolicy retryPolicy = new RetryOneTime(1000);\n\n    // Set up a CuratorFramework client\n    client = CuratorFrameworkFactory.builder()\n            .connectString(serverAddr)\n            .connectionTimeoutMs(5000)\n            .retryPolicy(retryPolicy)\n            .build();\n\n    // Set up a connection state listener\n    client.getConnectionStateListenable().addListener(this);\n\n    // Set up any authorization\n    if (authority != null) {\n        client.getAuthable().addAuthInfo(\"digest\", authority.getBytes());\n    }\n\n    // Start the client\n    client.start();\n\n    // Check for exceptions\n    if (!client.getZookeeperClient().blockUntilConnectedOrTimedOut()) {\n        throw new IllegalStateException(\"Could not connect to Zookeeper server\");\n    }\n}", "CodeBleu_score": 29.376347499204513}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\tif (listener == null) {\n    return;\n  }\n  Map<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n  if (listeners != null) {\n    TargetChildListener targetListener = listeners.remove(listener);\n    if (targetListener != null) {\n      removeTargetChildListener(path, targetListener);\n    }\n    if (listeners.isEmpty()) {\n      childListeners.remove(path);\n    }\n  }\n}", "CodeBleu_score": 82.70601166911533}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tsynchronized (childListenerMap) {\n        List<ChildListener> listeners = childListenerMap.get(path);\n        if (listeners != null) {\n            listeners.remove(listener);\n            if (listeners.size() == 0) {\n                childListenerMap.remove(path);\n                removeTargetChildListener(path, targetChildListener);\n            }\n        }\n    }\n}", "CodeBleu_score": 51.72831193314129}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tremoveTargetChildListener(path, targetChildListenerMap.remove(listener));\n}", "CodeBleu_score": 12.61244843040712}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n    string idc, host;\n    string idc_host;\n    string idc_host_str;\n    string idc_host_str_val;\n    string idc_host_str_key;\n    int idc_host_str_key_len;\n    string idc_host_str_val_len;\n    string idc_host_str_val_len_key;\n    int idc_host_str_val_len_key_len;\n    string idc_host_str_key_val;\n    int idc_host_str_key_val_len;\n    string idc_host_str_key_val_key;\n    int idc_host_str_key_val_key_len;\n    string idc_host_str_key_val_val;\n    int idc_host_str_key_val_val_len;\n    string idc_host_str_key_val_val_key;\n    int idc_host_str_key_val_val_key_len;\n    string idc_host_str_key_val_val_val;\n    int idc_host_str_key_val_val_val_len;\n    string idc_host_str_key_val_val_val_key;\n    int idc_host_str_key_val_val_val_key_len;\n    string idc_host_str_key_val_val_val_val;\n    int idc_host_str_key_val_val_val_val_len;\n    string idc_host_str_key_val_val_val_val_key;\n    int idc_host_str_key_val_val_val_val_key_len;\n    string idc_host_str_key_val_val_val_val_val;\n    int idc_host_str_key_val_val_val_val_val_len;\n    string idc_host_str_key_val_val_val_val_val_key;\n    int idc_host_str_key_val", "CodeBleu_score": 11.367666632657263}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n    string idc;\n    string host;\n    string idc_host;\n\n    if (NULL == zh) return QCONF_ERR_PARAM;\n\n    // Get the IDC host information\n    if (QCONF_OK != lock_ht_find(watcher_handle_map, watcher_handle_map_mutex, zh, idc_host))\n    {\n        LOG_FATAL_ERR(\"Failed to find IDC host information for zh:%p\", zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    // Delete the IDC host information from the map\n    lock_ht_delete(watcher_handle_map, watcher_handle_map_mutex, zh);\n\n    // Get the IDC and host\n    if (QCONF_OK != deserialize_from_idc_host(idc_host, idc, host))\n    {\n        LOG_FATAL_ERR(\"Failed to deserialize IDC host information for zh:%p\", zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    // Close the old handle\n    zookeeper_close(zh);\n\n    // Initialize a new ZooKeeper handle\n    zh = zookeeper_init(host.c_str(), watcher_fn, 30000, NULL, NULL, 0);\n    if (NULL == zh)\n    {\n        LOG_FATAL_ERR(\"Failed to initialize a new ZooKeeper handle for zh:%p\", zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    // Initialize the environment for the new handle\n    if (QCONF_OK != init_env_for_zk(zh, idc))\n    {\n        LOG_FATAL_ERR(\"Failed to initialize environment for zh:%p\", zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    // Reset the table watcher\n    if (QCONF_OK != table_watcher_reset(zh))\n    {\n        LOG_FATAL_ERR(\"", "CodeBleu_score": 49.91122506823706}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n    string idc;\n    string host;\n    string idc_host;\n    string idc_host_path;\n    string idc_host_val;\n    int idc_host_val_len = 0;\n    struct String_vector idc_host_list;\n    int idc_host_list_count = 0;\n    struct Stat stat;\n\n    // Check if zh is null\n    if (NULL == zh) {\n        LOG_ERR(\"ZooKeeper handle is null!\");\n        return ret;\n    }\n\n    // Get IDC and host information associated with zh\n    idc_host_path = string(QCONF_IDC_HOST_DIR) + \"/\" + string(zoo_get_current_server(zh));\n    ret = zoo_get(zh, idc_host_path.c_str(), 0, idc_host_val, &idc_host_val_len, &stat);\n    if (QCONF_OK != ret) {\n        LOG_ERR(\"Failed to get IDC host information from %s\", idc_host_path.c_str());\n        return ret;\n    }\n    idc_host_val.append(idc_host_val_len, '\\0');\n    ret = deserialize_from_idc_host(idc_host_val, idc, host);\n    if (QCONF_OK != ret) {\n        LOG_ERR(\"Failed to deserialize IDC host information from %s\", idc_host_val.c_str());\n        return ret;\n    }\n\n    // Delete IDC and host information associated with zh\n    ret = zoo_delete(zh, idc_host_path.c_str(), -1);\n    if (QCONF_OK != ret) {\n        LOG_ERR(\"Failed to delete IDC host information from %s\", idc_host_path.c_str());\n        return ret;\n    }\n\n    // Close old ZooKeeper handle\n    zookeeper_close(zh);\n\n    // Initialize new ZooKeeper handle\n    z", "CodeBleu_score": 47.83260801731105}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\tlock_guard<mutex> lock(g_mutex);\n    g_idc_host_map[zh] = idc_host;\n    g_idc_map[zh] = idc;\n\n    zookeeper_state state = zoo_state(zh);\n    if (state != ZOO_CONNECTED_STATE) {\n        LOG_FATAL_ERR(\"[%s] Zookeeper handle is not connected\", idc_host.c_str());\n        return;\n    }\n\n    int ret = zoo_register_ephemeral(zh, \"/notify\", \"\", 0, &watch_notify_node, NULL);\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"[%s] Failed to register ephemeral node on Zookeeper server, ret = %d\", idc_host.c_str(), ret);\n        return;\n    }\n\n    ret = zoo_exists(zh, \"/notify\", 0, NULL);\n    if (ret == ZNONODE) {\n        LOG_INFO(\"[%s] The notify node does not exist on Zookeeper server\", idc_host.c_str());\n        add_gray_idc(idc);\n    } else if (ret != ZOK) {\n        LOG_FATAL_ERR(\"[%s] Failed to check the existence of the notify node on Zookeeper server, ret = %d\", idc_host.c_str(), ret);\n        return;\n    }\n}", "CodeBleu_score": 49.82184933898496}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t// update the handle to idc mapping\n    lock_ht_update(handle_to_idc, handle_to_idc_mu, zh, idc);\n\n    // check if the handle is connected\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        LOG_INFO(\"Zookeeper handle %p is not connected\", zh);\n        return;\n    }\n\n    // register the current host on the Zookeeper server\n    int ret = zoo_register_ephemeral(zh, \"/hosts/\" + idc_host, NULL, 0);\n    if (ret != ZOK) {\n        LOG_FATAL_ERR(\"zoo_register_ephemeral failed with error code %d\", ret);\n    }\n\n    // set a watcher on the notify node\n    ret = zoo_watch_notify_node(zh);\n    if (ret != ZOK) {\n        // if the operation fails, add the IDC to the gray list\n        add_gray_idc(idc);\n    }\n}", "CodeBleu_score": 43.36252631631608}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\tlock_ht_update(idc_host_zh_ht, idc_host_zh_mu, idc_host, zh);\n    lock_ht_update(idc_zh_ht, idc_zh_mu, idc, zh);\n    if (zoo_state(zh) != ZOO_CONNECTED_STATE) {\n        LOG_INFO(\"zookeeper handle is not connected, idc host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n        return;\n    }\n    if (zk_register_ephemeral(zh, idc_host.c_str()) != ZOK) {\n        LOG_FATAL_ERR(\"register ephemeral node failed, idc host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n        return;\n    }\n    if (watch_notify_node(zh) != ZOK) {\n        add_gray_idc(idc);\n        LOG_FATAL_ERR(\"watch notify node failed, idc host: %s, idc: %s\", idc_host.c_str(), idc.c_str());\n        return;\n    }\n}", "CodeBleu_score": 50.196880611814265}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\timport hashlib, base64\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + base64.b64encode(cred_hash).decode().strip()", "CodeBleu_score": 39.855963692885126}, {"code": "def make_digest_acl_credential(username, password)\n\tcred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()", "CodeBleu_score": 34.716547674041806}, {"code": "def make_digest_acl_credential(username, password)\n\timport hashlib\n    import base64\n\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    cred_b64 = base64.b64encode(cred_hash).decode().strip()\n    credential = username + \":\" + cred_b64\n    return credential", "CodeBleu_score": 54.3509134483666}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\tif self.id is None:\n        return False\n    lock_path = self.path + \"/\" + self.lock\n    try:\n        value = self.zk.get(lock_path)[0]\n        return value == self.id\n    except NoNodeError:\n        return False\n", "CodeBleu_score": 42.491460960338166}, {"code": "def holds_lock(self)\n\tif self.processing_element is None:\n        return False\n\n    lock_path = self.processing_element.get_lock_path()\n    lock_value = self.zk_client.get(lock_path)[0]\n\n    return lock_value == self.processing_element.get_id()\n\n", "CodeBleu_score": 41.01852943653933}, {"code": "def holds_lock(self)\n\tif self.pe is None:\n        return False\n    lock_path = self.pe.lock_path\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.pe.id\n\n", "CodeBleu_score": 35.04063721035394}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\tif self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    self.client.sync(lock_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value != self.id:\n        return False\n    try:\n        self.client.transaction(\n            compare=[\n                self.client.retry(self.client.exists, lock_path),\n                self.client.retry(self.client.exists, entry_path),\n            ],\n            delete=[lock_path, entry_path],\n        )\n    except NoNodeError:\n        return False\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 50.46872439633676}, {"code": "def consume(self)\n\tif self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    self.client.sync(lock_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value != self.id:\n        return False\n    try:\n        self.client.retry(self.client.delete, lock_path)\n        self.client.retry(self.client.delete, entry_path)\n    except NoNodeError:\n        return False\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 51.187505549829545}, {"code": "def consume(self)\n\tif self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    try:\n        self.client.transaction(\n            compare=[self.client.exists(lock_path)],\n            delete=[lock_path, entry_path],\n        )\n        self.processing_element = None\n        return True\n    except Exception:\n        return False\n\n", "CodeBleu_score": 55.09183503703747}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\tbuffer = bytearray()\n    while True:\n        try:\n            header, buffer, offset = self._read_header(read_timeout)\n        except socket.timeout:\n            return\n        except Exception:\n            self.logger.exception(\"Exception reading from socket\")\n            self.close()\n            return\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \"Received ping\")\n            self._outstanding_pings.clear()\n        elif header.xid == AUTH_XID:\n            self.logger.log(BLATHER, \"Received auth response\")\n            if header.err == AuthFailedError.code:\n                self._auth_exception = AuthFailedError()\n                self._auth_cv.notify()\n            else:\n                self._auth_cv.notify()\n        elif header.xid == WATCH_XID:\n            self.logger.log(BLATHER, \"Received event\")\n            self._read_watch_event(buffer, offset)\n        else:\n            self.logger.log(BLATHER, \"Received response header: %r\", header)\n            response = self._read_response(header, buffer, offset)\n            if response == CLOSE_RESPONSE:\n                return\n\n", "CodeBleu_score": 54.96215164062575}, {"code": "def _read_socket(self, read_timeout)\n\ttry:\n        header, buffer, offset = self._read_header(read_timeout)\n    except socket.timeout:\n        return\n    except Exception:\n        self.logger.exception(\"Exception reading socket\")\n        self.close()\n        return\n\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Received PING\")\n        self.outstanding_pings.clear()\n    elif header.xid == AUTH_XID:\n        if header.err == 0:\n            self.logger.log(BLATHER, \"Auth success\")\n            self.auth_data = buffer[offset:]\n            self.event.set()\n        else:\n            self.logger.log(BLATHER, \"Auth failed\")\n            self.auth_data = None\n            self.event.set()\n            self.auth_exception = AuthFailedError(\n                \"Auth failed: %s\" % repr(buffer[offset:])\n            )\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 51.598989515343185}, {"code": "def _read_socket(self, read_timeout)\n\ttry:\n        header, buffer, offset = self._read_header(read_timeout)\n    except Exception as exc:\n        self.logger.exception(\"Exception reading from socket: %s\", exc)\n        self._session_callback(exc)\n        return\n\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Received PING\")\n        self._outstanding_pings.clear()\n    elif header.xid == AUTH_XID:\n        self.logger.log(BLATHER, \"Received AUTH\")\n        if header.err:\n            self._auth_exception = AuthFailedError(header.err)\n        else:\n            self._auth_in_progress = False\n    elif header.xid == WATCH_XID:\n        self.logger.log(BLATHER, \"Received EVENT\")\n        self._read_watch_event(buffer, offset)\n    else:\n        self.logger.log(BLATHER, \"Received header: %r\", header)\n        response = self._read_response(header, buffer, offset)\n        if response is CLOSE_RESPONSE:\n            return\n\n", "CodeBleu_score": 55.63799252324575}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\tself.logger.info(\"Starting zk_loop\")\n    self.connection_stopped.clear()\n    self.logger.info(\"Attempting to connect to Zookeeper\")\n    try:\n        self.connect(self.hosts, self.timeout, self.handler, self.watcher, self.retry_policy)\n    except KazooRetryFailedError:\n        self.logger.warning(\"Connection to Zookeeper failed\")\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED, None)\n    self.logger.info(\"Stopped zk_loop\")\n\n", "CodeBleu_score": 37.155242788057635}, {"code": "def zk_loop(self)\n\tself.log(\"Starting Zookeeper connection loop\")\n    self.clear(\"connection_stopped\")\n    while not self.is_set(\"connection_stopped\"):\n        try:\n            self.retry(self.connect)\n        except Exception as e:\n            self.warning(\"Connection to Zookeeper failed: %s\" % e)\n        else:\n            break\n    self.set(\"connection_stopped\")\n    self.session_callback(self, ZOO_EXPIRED_SESSION_STATE)\n    self.log(\"Stopped Zookeeper connection loop\")\n\n\n\n\n", "CodeBleu_score": 30.53957344625566}, {"code": "def zk_loop(self)\n\tself.log('starting zk_loop')\n    self.connection_stopped.clear()\n    while True:\n        try:\n            self.retry(self.connect)\n        except Exception as e:\n            self.warning('zk_loop: %r' % e)\n        else:\n            break\n    self.connection_stopped.set()\n    self.session_callback(ZK_CONNECTION_CLOSED)\n    self.log('stopping zk_loop')\n\n", "CodeBleu_score": 32.16198325492365}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\tsorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]\n\n", "CodeBleu_score": 35.526810443656586}, {"code": "def _partitioner(self, identifier, members, partitions)\n\tsorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    worker_index = sorted_members.index(identifier)\n    nth_partition = sorted_partitions[worker_index::len(members)]\n    return nth_partition\n\n\n\n\n", "CodeBleu_score": 35.950915614129784}, {"code": "def _partitioner(self, identifier, members, partitions)\n\tsorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    identifier_index = sorted_members.index(identifier)\n    return sorted_partitions[identifier_index::len(members)]", "CodeBleu_score": 35.40983982936371}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\tself._best_effort_cleanup()\n    self.client.retry(self.client.delete, self.create_path)\n    self.participating = False\n\n", "CodeBleu_score": 29.6457752522207}, {"code": "def leave(self)\n\ttry:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self.participating = False\n\n", "CodeBleu_score": 42.88292672921908}, {"code": "def leave(self)\n\tself._best_effort_cleanup()\n    self.client.retry(self.client.delete, self.create_path)\n    self.participating = False\n\n", "CodeBleu_score": 29.6457752522207}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\tResult result = new Result();\n    try {\n        if (!isRunning()) {\n            startServer();\n            result.setStatus(Result.Status.SUCCESS);\n            result.setMessage(\"HDFS over FTP server started successfully\");\n        } else {\n            result.setStatus(Result.Status.ERROR);\n            result.setMessage(\"HDFS over FTP server is already running\");\n        }\n    } catch (Exception e) {\n        result.setStatus(Result.Status.ERROR);\n        result.setMessage(\"Exception occurred while starting HDFS over FTP server\");\n        result.setException(e);\n    }\n    return result;\n}", "CodeBleu_score": 32.36126841221743}, {"code": "public Result start(){\n\treturn startServer();\n}", "CodeBleu_score": 3.264841862806743}, {"code": "public Result start(){\n\tResult result = new Result();\n    try {\n        if (!isRunning()) {\n            Process process = Runtime.getRuntime().exec(\"start.bat\");\n            result.setSuccess(true);\n            result.setMessage(\"Server started successfully.\");\n        } else {\n            result.setSuccess(false);\n            result.setMessage(\"Server is already running.\");\n        }\n    } catch (Exception e) {\n        result.setSuccess(false);\n        result.setMessage(e.getMessage());\n    }\n    return result;\n}", "CodeBleu_score": 29.599793367643045}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\tif (statusServer()) {\n        try {\n            server.stop();\n            return new Result(true, \"Server stopped successfully.\");\n        } catch (Exception e) {\n            log.error(e.getMessage());\n            return new Result(false, \"Server could not be stopped.\");\n        }\n    } else {\n        return new Result(false, \"Server is not running.\");\n    }\n}", "CodeBleu_score": 34.058655838348564}, {"code": "public Result stop(){\n\tif (isRunning()) {\n        try {\n            server.stop();\n            return new Result(true, \"The server was successfully stopped.\");\n        } catch (Exception e) {\n            logger.error(\"An error occurred while stopping the server: \" + e.getMessage());\n            return new Result(false, \"An error occurred while stopping the server: \" + e.getMessage());\n        }\n    } else {\n        return new Result(false, \"The server is not currently running.\");\n    }\n}", "CodeBleu_score": 35.548545959347294}, {"code": "public Result stop(){\n\ttry {\n        if (isRunning()) {\n            server.stop();\n            return new Result(true, \"Server stopped successfully\");\n        } else {\n            return new Result(true, \"Server is not running\");\n        }\n    } catch (Exception e) {\n        log.error(e.getMessage());\n        return new Result(false, e.getMessage());\n    }\n}", "CodeBleu_score": 34.56951651834695}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.92963784073824}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t\t// check for no authorities at all\n\t\tif (authorities == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tboolean someoneCouldAuthorize = false;\n\t\tfor (Authority authority : authorities) {\n\t\t\tif (authority.canAuthorize(request)) {\n\t\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\t\trequest = authority.authorize(request);\n\n\t\t\t\t// authorization failed, return null\n\t\t\t\tif (request == null) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\n\t\tif (someoneCouldAuthorize) {\n\t\t\treturn request;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}", "CodeBleu_score": 79.04373091584561}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t\t// check for no authorities at all\n\t\tif (authorities == null) {\n\t\t\treturn null;\n\t\t}\n\n\t\tboolean someoneCouldAuthorize = false;\n\t\tfor (Authority authority : authorities) {\n\t\t\tif (authority.canAuthorize(request)) {\n\t\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\t\trequest = authority.authorize(request);\n\n\t\t\t\t// authorization failed, return null\n\t\t\t\tif (request == null) {\n\t\t\t\t\treturn null;\n\t\t\t\t}\n\t\t\t}\n\n\t\t}\n\n\t\tif (someoneCouldAuthorize) {\n\t\t\treturn request;\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t}", "CodeBleu_score": 79.04373091584561}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\ttry {\n        getDfs().mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 52.7021648410919}, {"code": "public boolean mkdir(){\n\ttry {\n        getDfs().mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 52.7021648410919}, {"code": "public boolean mkdir(){\n\ttry {\n    getDfs().mkdirs(fullPath);\n    return true;\n  } catch (IOException e) {\n    e.printStackTrace();\n    return false;\n  }\n}", "CodeBleu_score": 52.355895081818005}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17758097021823}, {"code": "public boolean delete(){\n\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17758097021823}, {"code": "public boolean delete(){\n\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17758097021823}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\ttry {\n\t\t\t\tFileSystem fs = FileSystem.get(conf);\n\t\t\t\tfs.rename(path, new Path(ftpFile.getParent(), ftpFile.getName()));\n\t\t\t\treturn true;\n\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t\t\treturn false;\n\t\t}\n}", "CodeBleu_score": 65.36660245831827}, {"code": "public boolean move(FtpFile ftpFile){\n\tboolean success = false;\n\t\ttry {\n\t\t\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\t\t\tPath newPath = new Path(ftpFile.getParent() + \"/\" + ftpFile.getName());\n\t\t\t\tsuccess = fs.rename(path, newPath);\n\t\t} catch (IOException e) {\n\t\t\t\te.printStackTrace();\n\t\t}\n\t\treturn success;\n}", "CodeBleu_score": 46.43526008268187}, {"code": "public boolean move(FtpFile ftpFile){\n\ttry {\n\t\t// Retrieve file system instance\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\t// Rename file\n\t\tfs.rename(path, new Path(ftpFile.getParent() + \"/\" + ftpFile.getName()));\n\t\t// Return true\n\t\treturn true;\n\t} catch (IOException e) {\n\t\t// Print stack trace\n\t\te.printStackTrace();\n\t\t// Return false\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 66.9390299582127}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\tFTPFile[] ftpFiles = null;\n\t\ttry {\n\t\t\tFileStatus[] files = fs.listStatus(path);\n\t\t\tftpFiles = new FTPFile[files.length];\n\t\t\tfor (int i = 0; i < files.length; i++) {\n\t\t\t\tftpFiles[i] = new HdfsFile(files[i], this);\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"IOException\", e);\n\t\t\treturn null;\n\t\t}\n\t\treturn Arrays.asList(ftpFiles);\n\t}", "CodeBleu_score": 24.99511339726602}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\t\tFileStatus[] files = fs.listStatus(path);\n\t\t\tList<FtpFile> fileList = new ArrayList<FtpFile>();\n\n\t\t\tfor (FileStatus file : files) {\n\t\t\t\tString virtualName = file.getPath().getName();\n\t\t\t\tString virtualPath = path.toUri().getPath() + \"/\" + virtualName;\n\t\t\t\tfileList.add(new HdfsFile(virtualPath, file));\n\t\t\t}\n\n\t\t\treturn Collections.unmodifiableList(fileList);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Could not list files in directory: \" + path.toUri().getPath(), e);\n\t\t\treturn null;\n\t\t}\n\t}", "CodeBleu_score": 28.559483702928688}, {"code": "public List<FtpFile> listFiles(){\n\tFTPFileSystem fs = null;\n\t\ttry {\n\t\t\tfs = FTPFileSystem.get(path.toUri(), conf);\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(e);\n\t\t\treturn null;\n\t\t}\n\n\t\tArrayList<FtpFile> fileList = new ArrayList<FtpFile>();\n\t\ttry {\n\t\t\tFileStatus[] fileStatuses = fs.listStatus(path);\n\t\t\tfor (FileStatus fileStatus : fileStatuses) {\n\t\t\t\tfileList.add(new FtpFile(fileStatus.getPath().toString(), fileStatus));\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(e);\n\t\t\treturn null;\n\t\t}\n\n\t\treturn Collections.unmodifiableList(fileList);\n\t}", "CodeBleu_score": 28.202969968249135}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\tif (configured) {\n\t\t\treturn;\n\t\t}\n\n\t\tconfigured = true;\n\n\t\tif (exists()) {\n\t\t\ttry {\n\t\t\t\tload();\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\t\"Failed to load user data file: \" + getAbsolutePath(), e);\n\t\t\t}\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\t}", "CodeBleu_score": 23.898130523976704}, {"code": "public void configure(){\n\tif (configured) {\n\t\t\treturn;\n\t\t}\n\n\t\tconfigured = true;\n\n\t\tif (!exists()) {\n\t\t\treturn;\n\t\t}\n\n\t\ttry {\n\t\t\tload();\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to load user data file \" + getAbsolutePath(), e);\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\t}", "CodeBleu_score": 24.711853589710163}, {"code": "public void configure(){\n\tif (configured) {\n\t\t\treturn;\n\t\t}\n\n\t\tconfigured = true;\n\n\t\ttry {\n\t\t\tif (userDataFile.exists()) {\n\t\t\t\tload();\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to load user data file \" + userDataFile, e);\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\t}", "CodeBleu_score": 27.152504987742134}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\tFile userDataFile = getAbsoluteFile(getUserDataFile());\n    if (!exists(getParentFile(userDataFile))) {\n        if (!mkdirs(getParentFile(userDataFile))) {\n            throw new FtpException(\"Could not create user data directory: \" + getAbsolutePath(getParentFile(userDataFile)));\n        }\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        store(fos, userData);\n    } catch (IOException ex) {\n        log.error(\"Could not write user data to file: \" + getAbsolutePath(userDataFile), ex);\n        throw new FtpException(\"Could not write user data to file: \" + getAbsolutePath(userDataFile));\n    } finally {\n        close(fos);\n    }\n}", "CodeBleu_score": 40.03735455656073}, {"code": "private void saveUserData() throws FtpException{\n\t// Check if the parent directory of the user data file exists and create it if necessary\n\tFile parentFile = getParentFile(userDataFile);\n\tif (!parentFile.exists()) {\n\t\tif (!parentFile.mkdirs()) {\n\t\t\tthrow new FtpException(\"Failed to create parent directory for user data file: \" + userDataFile.getAbsolutePath());\n\t\t}\n\t}\n\t// Write the user data to the user data file\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tstore(fos);\n\t} catch (IOException e) {\n\t\tlog.error(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Failed to write user data to file: \" + userDataFile.getAbsolutePath());\n\t} finally {\n\t\tclose(fos);\n\t}\n}", "CodeBleu_score": 44.048702525697045}, {"code": "private void saveUserData() throws FtpException{\n\t// Check if the parent directory of the user data file exists.\n    // If it doesn't exist, create it.\n    File parentFile = getParentFile(userDataFile);\n    if (parentFile.exists()) {\n        if (!parentFile.isDirectory()) {\n            throw new ConfigurationException(\"Parent directory of user data file is not a directory.\");\n        }\n    } else {\n        if (!parentFile.mkdirs()) {\n            throw new ConfigurationException(\"Unable to create parent directory of user data file.\");\n        }\n    }\n    // Write the user data to the file.\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        store(fos);\n    } catch (IOException ex) {\n        LOG.error(\"Unable to write user data to file.\", ex);\n        throw new FtpException(\"Unable to write user data to file.\", ex);\n    } finally {\n        // Ensure the FileOutputStream is closed properly.\n        close(fos);\n    }\n}", "CodeBleu_score": 43.09091786430264}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\n        HdfsUserManager userManagerFactory = new HdfsUserManager();\n        userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n        userManagerFactory.delete(user);\n        return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    }catch (Exception e) {\n        log.error(e);\n        return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 84.58771483281748}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\n        HdfsUserManager userManagerFactory = new HdfsUserManager();\n        userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n        userManagerFactory.delete(user);\n        return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    }catch (Exception e) {\n        log.error(e);\n        return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 84.58771483281748}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\n        HdfsUserManager userManagerFactory = new HdfsUserManager();\n        userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n        userManagerFactory.delete(user);\n        return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    }catch (Exception e) {\n        log.error(e);\n        return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 84.58771483281748}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tdebug(\"open: \" + path + \" \" + bufferSize);\n    Path qualifiedPath = qualify(path);\n    if (workingDirectory != null) {\n        if (!qualifiedPath.isAbsolute()) {\n            qualifiedPath = new Path(workingDirectory, qualifiedPath);\n        }\n    }\n    try {\n        FSDataInputStream inputStream = store.open(qualifiedPath, bufferSize);\n        return inputStream;\n    } catch (Exception ex) {\n        warn(\"open: \" + ex);\n        return null;\n    }\n}", "CodeBleu_score": 41.55431834946853}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tdebug(\"open \" + path + \" with buffer size \" + bufferSize);\n        Path qualifiedPath = qualify(path);\n        try {\n            FileStatus fileStatus = getFileStatus(qualifiedPath);\n            if (fileStatus.isDirectory()) {\n                throw new FileNotFoundException(\"Path is a directory: \" + path);\n            }\n            return new FSDataInputStream(new BufferedFSInputStream(store.getInputStream(qualifiedPath), bufferSize));\n        } catch (Exception e) {\n            warn(\"Unable to open \" + path, e);\n            return null;\n        }\n    }", "CodeBleu_score": 35.172547058698825}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tdebug(\"open: {}, bufferSize: {}\", path, bufferSize);\n        path = qualify(path);\n        try {\n            return new FSDataInputStream(new BufferedFSInputStream(store.getInputStream(path), bufferSize));\n        } catch (IOException e) {\n            warn(\"open: {}\", path, e);\n            return null;\n        }\n    }", "CodeBleu_score": 33.73213018951887}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    Path adjustedDst = dst;\n\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n    return true;\n}", "CodeBleu_score": 99.77741694401773}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    Path adjustedDst = dst;\n\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n    return true;\n}", "CodeBleu_score": 99.77741694401773}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    Path adjustedDst = dst;\n\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n    return true;\n}", "CodeBleu_score": 99.77741694401773}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t} else if (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 28.18474344244457}, {"code": "public boolean hasCapability(String capability){\n\tcapability = capability.toLowerCase();\n  if (capability.equals(\"hsync\")) {\n    return supportFlush;\n  } else if (capability.equals(\"hflush\")) {\n    return supportFlush;\n  } else {\n    return false;\n  }\n}", "CodeBleu_score": 35.84869451674529}, {"code": "public boolean hasCapability(String capability){\n\tString lowerCaseCapability = capability.toLowerCase();\n  if (lowerCaseCapability.equals(\"hsync\")) {\n    return supportFlush;\n  }\n  if (lowerCaseCapability.equals(\"hflush\")) {\n    return supportFlush;\n  }\n  return false;\n}", "CodeBleu_score": 32.50638617154418}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\tif (offset > lastFlushedPosition) {\n        try {\n            // Write metadata to the filer client\n            writeMeta();\n        } catch (Exception e) {\n            throw new IOException(e);\n        }\n        lastFlushedPosition = offset;\n    }\n}", "CodeBleu_score": 49.539896799104746}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\ttry {\n        flushWrittenBytesToServiceInternalAsync(offset).get();\n    } catch (ExecutionException e) {\n        if (e.getCause() instanceof IOException) {\n            throw (IOException) e.getCause();\n        } else {\n            throw new IOException(e.getCause());\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 42.18259925589969}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\tif (offset == 0) {\n        return;\n    }\n    final long startTime = System.currentTimeMillis();\n    final long startOffset = offset;\n    final long endOffset = offset + writtenBytes.size();\n    try {\n        final FileMetadata fileMetadata = new FileMetadata(\n                getParentDirectory(path),\n                name,\n                writtenBytes.size(),\n                writtenBytes.size(),\n                mtime,\n                atime,\n                ctime,\n                crtime,\n                replication,\n                blockSize,\n                collection,\n                ttlSec,\n                userMetadata,\n                userMetadata.entrySet().stream()\n                        .map(e -> new Pair<>(e.getKey(), e.getValue().getBytes(StandardCharsets.UTF_8)))\n                        .collect(Collectors.toMap(Pair::getKey, Pair::getValue)),\n                mode,\n                gid,\n                uid,\n                xattrs,\n                xattrs.entrySet().stream()\n                        .map(e -> new Pair<>(e.getKey(), e.getValue().getBytes(StandardCharsets.UTF_8)))\n                        .collect(Collectors.toMap(Pair::getKey, Pair::getValue)),\n                null);\n        final FileMetadata[] fileMetadataArr = new FileMetadata[]{fileMetadata};\n        final String[] parentPath = new String[]{getParentDirectory(path)};\n        final String[] fileName = new String[]{name};\n        final byte[][] bytes = new byte[][]{writtenBytes.toByteArray()};\n        final long[] offsets = new long[]{offset};\n        final long[] fileIds = new long[]{fileId};\n        final long[] fileSizes = new long[]{fileSize};\n        final long[] fileModificationTimes = new long[]{mtime};\n        final long[] fileAccessTimes = new long[]{atime};\n        final long[] fileCreationTimes = new long[]{ctime};\n        final long[] fileCreationTimesOnRemote = new long[]{crtime};\n        final int[] replications = new int[]{replication};\n        final int[] blockSizes = new int[]{blockSize};\n        final int[] ttlSecs = new int[]{tt", "CodeBleu_score": 22.261393592252944}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t// Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n\n    // Calculate the byte length\n    final int length = bufferToWrite.remaining();\n\n    // Ensure the task queue is not overloaded\n    shrinkWriteOperationQueue();\n\n    // Submit a write task to the completion service\n    final Future<Integer> future = completionService.submit(new Callable<Integer>() {\n        @Override\n        public Integer call() throws Exception {\n            try {\n                // Write the data\n                final int bytesWritten = writeData(bufferToWrite, writePosition);\n                return bytesWritten;\n            } finally {\n                // Release the buffer\n                bufferToWrite.release();\n            }\n        }\n    });\n\n    // Record the write operation\n    writeOperations.add(new WriteOperation(future, length));\n\n    // Manage the operation queue\n    if (writeOperations.size() > maxConcurrentWrites) {\n        try {\n            // Wait for a task to complete\n            waitForTaskToComplete();\n        } catch (IOException e) {\n            throw e;\n        }\n    }\n\n    return length;\n}", "CodeBleu_score": 42.69653166082147}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tif (writeOperations.size() > maxQueueLength) {\n        throw new IOException(\"Write operation queue is full\");\n    }\n    if (writePosition != lastTotalAppendOffset) {\n        throw new IOException(\"Write position is not the end of the file\");\n    }\n\n    // Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n    final int length = bufferToWrite.limit();\n    final int position = bufferToWrite.position();\n\n    // Submit the write operation to the completion service\n    final Callable<Void> task = new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n            // Write the data\n            service.write(bufferToWrite, writePosition);\n\n            // Release the buffer\n            bufferToWrite.release();\n\n            return null;\n        }\n    };\n    completionService.submit(task);\n\n    // Record the write operation\n    writeOperations.add(new WriteOperation(bufferToWrite, writePosition, length));\n\n    // Return the number of bytes written\n    return length;\n}", "CodeBleu_score": 42.67484421088851}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t// Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n\n    // Calculate the byte length\n    final int byteLength = bufferToWrite.limit();\n\n    // Ensure the task queue is not overloaded\n    if (writeOperations.size() >= MAX_WRITE_OPERATIONS) {\n        shrinkWriteOperationQueue();\n    }\n\n    // Submit a write task to the completion service\n    final Future<Integer> future = completionService.submit(new Callable<Integer>() {\n        @Override\n        public Integer call() throws IOException {\n            // Write the data\n            final int byteCount = writeData(bufferToWrite, writePosition);\n\n            // Release the buffer\n            release(bufferToWrite);\n\n            return byteCount;\n        }\n    });\n\n    // Record the write operation\n    writeOperations.add(new WriteOperation(future, byteLength));\n\n    return byteLength;\n}", "CodeBleu_score": 41.690497289757445}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\n        while (completionService.poll() != null) {\n            // do nothing\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 19.72133869545894}, {"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\n        while (completionService.poll() != null) {\n            //do nothing\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 19.72133869545894}, {"code": "private void waitForTaskToComplete() throws IOException{\n\twhile (true) {\n        try {\n            Future<Void> future = completionService.poll(1, TimeUnit.SECONDS);\n            if (future == null) {\n                continue;\n            }\n            future.get();\n            break;\n        } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted while waiting for task to complete\", e);\n        } catch (ExecutionException e) {\n            throw new IOException(\"Execution exception while waiting for task to complete\", e);\n        }\n    }\n}", "CodeBleu_score": 30.821269273688657}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t// Iterate through the write queue and remove all completed operations\n    Iterator<WriteOperation> iterator = writeOperations.iterator();\n    while (iterator.hasNext()) {\n        WriteOperation writeOperation = iterator.next();\n        if (writeOperation.isDone()) {\n            // If the operation is done, update the total append offset\n            totalAppendOffset += writeOperation.getLength();\n            // Remove the completed operation from the queue\n            iterator.remove();\n        } else {\n            // If the operation is not done, stop iterating\n            break;\n        }\n    }\n}", "CodeBleu_score": 30.723104719523263}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\tfor (int i = 0; i < writeOperationQueue.size(); i++) {\n        WriteOperation writeOperation = writeOperationQueue.get(i);\n        if (writeOperation.isDone()) {\n            if (writeOperation.getException() != null) {\n                throw new IOException(\"Exception occurred during write operation\", writeOperation.getException());\n            }\n            totalAppendOffset += writeOperation.getLength();\n            writeOperationQueue.remove(i);\n            i--;\n        }\n    }\n}", "CodeBleu_score": 33.62193997239974}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\tIterator<WriteOperation> it = writeOperations.iterator();\n    while (it.hasNext()) {\n        WriteOperation op = it.next();\n        if (op.isDone()) {\n            if (op.hasException()) {\n                throw new IOException(op.getException());\n            }\n            totalAppendOffset += op.getLength();\n            it.remove();\n        } else {\n            // The queue is sorted in order of increasing file offset,\n            // so we can stop as soon as we see the first operation\n            // that is not yet done.\n            break;\n        }\n    }\n}", "CodeBleu_score": 30.039953164364498}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\tif (user == null || user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"user and user's home directory cannot be null\");\n\t\t}\n\t\tthis.homePath = user.getHomeDirectory().getAbsolutePath();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 55.66554671378642}, {"code": "protected HdfsFileSystemView(User user){\n\tif (user == null) {\n\t\t\tthrow new IllegalArgumentException(\"User must not be null\");\n\t\t}\n\t\tif (user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"User home directory must not be null\");\n\t\t}\n\t\tthis.homePath = user.getHomeDirectory();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 75.6164583382575}, {"code": "protected HdfsFileSystemView(User user){\n\tif (user == null) {\n\t\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t\t}\n\n\t\tif (user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"user home directory cannot be null\");\n\t\t}\n\n\t\tthis.homePath = user.getHomeDirectory();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 75.6528734699828}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\tif(dir.equals(\"..\")){\n        if(!this.currentPath.getParent().equals(this.rootPath)){\n            this.currentPath = this.currentPath.getParent();\n            return true;\n        }\n    }\n    else{\n        Path newPath = Paths.get(this.currentPath.toString(), dir);\n        if(Files.isDirectory(newPath)){\n            this.currentPath = newPath;\n            return true;\n        }\n    }\n    return false;\n}", "CodeBleu_score": 25.64156629939377}, {"code": "public boolean changeWorkingDirectory(String dir){\n\tif (dir.equals(\"..\")) {\n        if (currentPath.getParent() != null) {\n            currentPath = currentPath.getParent();\n            return true;\n        }\n        return false;\n    }\n    Path newPath = currentPath.resolve(dir);\n    if (newPath.toFile().isDirectory()) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 20.993628432255278}, {"code": "public boolean changeWorkingDirectory(String dir){\n\tif (dir.equals(\"..\")) {\n        if (this.path.getParent() != null) {\n            this.path = this.path.getParent();\n            return true;\n        }\n        return false;\n    }\n    Path newPath = this.path.resolve(dir);\n    if (Files.isDirectory(newPath)) {\n        this.path = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 20.010124860576354}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n    this.accessVolumeServer = conf.getAccessVolumeServer();\n    this.usePublicUrl = conf.getUsePublicUrl();\n}", "CodeBleu_score": 31.36499973807423}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tfilerClient = new FilerClient(host, port, grpcPort, conf);\n    if (conf.getAccessMode().equals(\"direct\")) {\n        accessVolumeServerByFilerProxy = false;\n        accessVolumeServerByPublicUrl = false;\n    } else if (conf.getAccessMode().equals(\"publicUrl\")) {\n        accessVolumeServerByFilerProxy = false;\n        accessVolumeServerByPublicUrl = true;\n    } else {\n        accessVolumeServerByFilerProxy = true;\n        accessVolumeServerByPublicUrl = false;\n    }\n}", "CodeBleu_score": 43.98757855016544}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tthis.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.getAccessMode();\n    this.accessVolumeServerByFilerProxy = conf.isAccessVolumeServerByFilerProxy();\n    this.accessVolumeServerByPublicUrl = conf.isAccessVolumeServerByPublicUrl();\n}", "CodeBleu_score": 38.68985526086012}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tLOG.debug(\"openFileForRead: {}\", path);\n\n        FilerProto.Entry entry = lookupEntry(path);\n        if (entry == null) {\n            throw new FileNotFoundException(\"File \" + path + \" not found.\");\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, entry);\n\n    }", "CodeBleu_score": 64.32660582711726}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tlogger.debug(\"openFileForRead: {}\", path);\n\n        FilerProto.Entry entry = lookupEntry(path);\n        if (entry == null) {\n            throw new FileNotFoundException(\"File \" + path + \" not found.\");\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, path, entry);\n\n    }", "CodeBleu_score": 64.50151889610406}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\tif (LOG.isDebugEnabled()) {\n            LOG.debug(\"openFileForRead: {}\", path);\n        }\n\n        FilerProto.Entry entry = lookupEntry(path);\n\n        if (entry == null) {\n            throw new FileNotFoundException(\"File \" + path + \" not found.\");\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, entry, readBufferSize);\n\n    }", "CodeBleu_score": 68.16621047409413}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\n    try {\n        hostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        hostName = \"localhost\";\n    }\n    numThreadsPerMap = conf.getInt(\"num.threads.per.map\", 1);\n    numFilesPerThread = conf.getInt(\"num.files.per.thread\", 1);\n    threadPool = newFixedThreadPool(numThreadsPerMap, new ThreadFactory() {\n        @Override\n        public Thread newThread(Runnable r) {\n            Thread t = new Thread(r);\n            t.setDaemon(true);\n            return t;\n        }\n    });\n}", "CodeBleu_score": 64.13749785623737}, {"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\n    try {\n        this.hostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        this.hostName = \"localhost\";\n    }\n    this.threadsPerMap = conf.getInt(\"mapreduce.tasktracker.map.tasks.maximum\", 2);\n    this.filesPerThread = conf.getInt(\"mapreduce.tasktracker.map.tasks.filesperthread\", 1);\n    this.threadPool = newFixedThreadPool(this.threadsPerMap);\n    for (int i = 0; i < this.threadsPerMap; i++) {\n        this.threadPool.execute(new MapThread());\n    }\n}", "CodeBleu_score": 37.3593031271466}, {"code": "public void configure(JobConf conf){\n\tthis.conf = conf;\n  try {\n    localHostName = InetAddress.getLocalHost().getHostName();\n  } catch (UnknownHostException e) {\n    localHostName = \"localhost\";\n  }\n  numThreads = conf.getInt(\"mapreduce.tasktracker.http.threads\", 40);\n  filesPerThread = conf.getInt(\"mapreduce.tasktracker.http.files.per.thread\", 2500);\n  threadPool = newFixedThreadPool(numThreads, new ThreadFactory() {\n    public Thread newThread(Runnable r) {\n      Thread t = new Thread(r);\n      t.setDaemon(true);\n      return t;\n    }\n  });\n}", "CodeBleu_score": 59.75186422776031}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\",e);\n    }\n  }", "CodeBleu_score": 98.83865927400906}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\",e);\n    }\n  }", "CodeBleu_score": 98.83865927400906}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\",e);\n    }\n  }", "CodeBleu_score": 98.83865927400906}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\tString currentContext = getCurrent();\n    if (isContextValid(currentContext)) {\n        if (!currentContext.contains(context)) {\n            currentContext += context;\n            build(currentContext);\n        }\n    } else {\n        build(context);\n    }\n}", "CodeBleu_score": 17.626146158711613}, {"code": "public static void setContext(String context) throws Exception{\n\t// Get the current context\n    String currentContext = getContext();\n    // Check if the current context is valid\n    if (!isContextValid(currentContext)) {\n        // If the current context is invalid, create a new context\n        currentContext = build(context);\n    } else {\n        // If the current context is valid, check if it already includes the provided context\n        if (!currentContext.contains(context)) {\n            // If the current context does not include the provided context, append the provided context to the current one\n            currentContext = currentContext.concat(context);\n        }\n    }\n    // Set the new context\n    setCurrent(currentContext);\n}", "CodeBleu_score": 23.825119725453415}, {"code": "public static void setContext(String context) throws Exception{\n\t// Retrieve the current caller context\n    String currentContext = getContext();\n    // Check the validity of the current caller context\n    if (isContextValid(currentContext)) {\n        // The current caller context is valid\n        if (!currentContext.contains(context)) {\n            // The current caller context does not already include the provided context\n            // Append the provided context to the existing one and set it\n            currentContext += \".\" + context;\n            setCurrent(currentContext);\n        }\n    } else {\n        // The current caller context is invalid\n        // Create and set a new caller context using the provided context\n        setCurrent(context);\n    }\n}", "CodeBleu_score": 20.423655828379182}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  if (hdfsDelete(fs, uri.to_path().c_str(), 1) != 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file \" + uri.to_string())));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 56.95908841286532}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  if (hdfsDelete(fs, uri.to_path().c_str(), 0) != 0) {\n    return LOG_STATUS(Status_HDFSError(std::string(\"Cannot delete file '\") +\n                                       uri.to_string() + \"'\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 59.0311649591347}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  if (hdfsDelete(fs, uri.to_path().c_str(), 0) != 0) {\n    return LOG_STATUS(Status_HDFSError(std::string(\"Cannot delete file \") +\n                                       uri.to_string() +\n                                       \" from HDFS; hdfsDelete error\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 57.43932785528029}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!ret) {\n    hdfsFileInfo* fileInfo =\n        libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n    if (fileInfo == NULL) {\n      return LOG_STATUS(Status_HDFSError(\"Cannot get file info\"));\n    } else if ((char)(fileInfo->mKind) == 'F') {\n      libhdfs_->hdfsFreeFileInfo(fileInfo, 1);\n      hdfsFile file = libhdfs_->hdfsOpenFile(\n          fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n      if (file == nullptr) {\n        return LOG_STATUS(Status_HDFSError(\"Cannot open file\"));\n      }\n      int ret = libhdfs_->hdfsHFlush(fs, file);\n      if (ret < 0) {\n        return LOG_STATUS(Status_HDFSError(\"Cannot sync file\"));\n      }\n      ret = libhdfs_->hdfsCloseFile(fs, file);\n      if (ret < 0) {\n        return LOG_STATUS(Status_HDFSError(\"Cannot close file\"));\n      }\n    } else {\n      libhdfs_->hdfsFreeFileInfo(fileInfo, 1);\n      return LOG_STATUS(Status_HDFSError(\"Cannot sync file\"));\n    }\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 55.74616969914942}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!ret) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot sync file; HDFS URI '\") + uri.c_str() +\n        \"' does not exist\"));\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot sync file; HDFS URI '\") + uri.c_str() +\n        \"' cannot be opened for writing\"));\n  }\n  ret = libhdfs_->hdfsHFlush(fs, file);\n  if (ret < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot sync file; HDFS URI '\") + uri.c_str() +\n        \"' cannot be flushed\"));\n  }\n  ret = libhdfs_->hdfsCloseFile(fs, file);\n  if (ret < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot sync file; HDFS URI '\") + uri.c_str() +\n        \"' cannot be closed\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 68.52541708699331}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(std::string(\n        \"Cannot open file \" + uri.to_string() + \" for sync\")));\n  }\n  if (libhdfs_->hdfsHFlush(fs, file) != 0) {\n    return LOG_STATUS(Status_HDFSError(std::string(\n        \"Cannot flush file \" + uri.to_string() + \" for sync\")));\n  }\n  if (libhdfs_->hdfsCloseFile(fs, file) != 0) {\n    return LOG_STATUS(Status_HDFSError(std::string(\n        \"Cannot close file \" + uri.to_string() + \" for sync\")));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 66.15392448443808}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n\n  hdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot retrieve HDFS file size; File does not exist\"));\n  }\n\n  if (!file_info->mKind) {\n    libhdfs_->hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\"Cannot retrieve HDFS file size; Path is not a file\"));\n  }\n\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n  libhdfs_->hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 61.52068819576295}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFileInfo* info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot retrieve HDFS path info; URI: \" + uri.to_string())));\n  }\n  if (info->mKind != kObjectKindFile) {\n    libhdfs_->hdfsFreeFileInfo(info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot retrieve file size; URI is not a file: \" +\n                    uri.to_string())));\n  }\n  *nbytes = static_cast<uint64_t>(info->mSize);\n  libhdfs_->hdfsFreeFileInfo(info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 66.089620894761}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n\n  hdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot retrieve file info for URI '\") +\n        uri.to_string() + \"'\"));\n  }\n\n  if (!file_info->mKind) {\n    libhdfs_->hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"URI '\") + uri.to_string() + \"' is not a file\"));\n  }\n\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n  libhdfs_->hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 72.23480647548358}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString[] hbaseCfg = hbaseCfgString.split(\":\");\n  String quorum = hbaseCfg[0];\n  String port = \"2181\";\n  if (hbaseCfg.length > 1) {\n    port = hbaseCfg[1];\n  }\n  String znode = \"/hbase\";\n  if (hbaseCfg.length > 2) {\n    znode = hbaseCfg[2];\n  }\n  return new Pair<String, String>(quorum + \":\" + port, znode);\n}", "CodeBleu_score": 26.90385738523522}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString[] hbaseCfg = hbaseCfgString.split(\";\");\n    String zkQuorum = \"\";\n    String zkNodeParent = \"\";\n    for (String cfg : hbaseCfg) {\n        String[] cfgPair = cfg.split(\"=\");\n        if (cfgPair[0].trim().equals(\"hbase.zookeeper.quorum\")) {\n            zkQuorum = cfgPair[1].trim();\n            if (!zkQuorum.contains(\":\")) {\n                zkQuorum += \":2181\";\n            }\n        } else if (cfgPair[0].trim().equals(\"zookeeper.znode.parent\")) {\n            zkNodeParent = cfgPair[1].trim();\n        }\n    }\n    if (zkNodeParent.isEmpty()) {\n        zkNodeParent = \"/hbase\";\n    }\n    return Pair.of(zkQuorum, zkNodeParent);\n}", "CodeBleu_score": 32.919278187056}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString[] hbaseCfg = hbaseCfgString.split(\";\");\n  String zookeeperQuorum = null;\n  String znodeParent = null;\n  for (String cfg : hbaseCfg) {\n    if (cfg.startsWith(\"hbase.zookeeper.quorum\")) {\n      zookeeperQuorum = cfg.substring(cfg.indexOf(\"=\") + 1);\n    } else if (cfg.startsWith(\"zookeeper.znode.parent\")) {\n      znodeParent = cfg.substring(cfg.indexOf(\"=\") + 1);\n    }\n  }\n  if (zookeeperQuorum == null) {\n    throw new IllegalArgumentException(\"hbase.zookeeper.quorum not found in HBase configuration string\");\n  }\n  if (!zookeeperQuorum.contains(\":\")) {\n    zookeeperQuorum += \":2181\";\n  }\n  if (znodeParent == null) {\n    znodeParent = \"/hbase\";\n  }\n  return new Pair<String, String>(zookeeperQuorum, znodeParent);\n}", "CodeBleu_score": 27.627904780127505}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tConnection conn = null;\n    try {\n        conn = getJdbcConnection(cfg);\n        String fullTableName = cfg.getTableName();\n        PTable tableSchema = getTableSchema(conn, fullTableName);\n        String namespace = getNamespace(tableSchema);\n        checkTable(conn, namespace, tableSchema.getName().getString(), cfg.isThinClient());\n        List<String> columns = getColumns(tableSchema);\n        for (String column : cfg.getColumns()) {\n            if (!columns.contains(column)) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                        String.format(\"\u60a8\u7684\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u5217\u914d\u7f6e\u4fe1\u606f\u6709\u8bef. \u56e0\u4e3a\u60a8\u914d\u7f6e\u7684\u5217: [%s] \u4e0d\u5b58\u5728\u4e8e Hbase \u7684 [%s] \u8868\u4e2d\uff0c\u8bf7\u68c0\u67e5\u60a8\u7684\u914d\u7f6e\u5e76\u4f5c\u51fa\u4fee\u6539.\",\n                                column, fullTableName));\n            }\n        }\n    }\n    catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                String.format(\"\u60a8\u7684\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u5217\u914d\u7f6e\u4fe1\u606f\u6709\u8bef. \u56e0\u4e3a\u6839\u636e\u60a8\u7684\u914d\u7f6e\u60a8\u7684\u5217\u914d\u7f6e\u4fe1\u606f\u83b7\u53d6\u4e0d\u5230\u6b63\u786e\u7684 Hbase \u8868\u4fe1\u606f: [%s] \u8bf7\u68c0\u67e5\u60a8\u7684\u914d\u7f6e\u5e76\u4f5c\u51fa\u4fee\u6539.\",\n                        cfg.getTableName()), e);\n    }\n    finally {\n        if (conn != null) {\n            try {\n                conn.close();\n            }\n            catch (SQLException e) {\n                LOG.warn(\"\u5173\u95ed JDBC \u8fde\u63a5\u5931\u8d25\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 44.42086229809817}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tConnection conn = null;\n    try {\n        conn = getJdbcConnection(cfg);\n        String fullTableName = getFullTableName(cfg.getNamespace(), cfg.getTableName());\n        PTable tableSchema = getTableSchema(conn, fullTableName);\n        List<String> columnNames = getColumnNames(tableSchema);\n        List<String> configuredColumns = cfg.getColumns();\n        if (configuredColumns.size() == 0) {\n            throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                    \"The configuration contains no columns. Please check the configuration.\");\n        }\n        for (String columnName : configuredColumns) {\n            if (!columnNames.contains(columnName)) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                        \"The column \" + columnName + \" does not exist in the table \" + fullTableName);\n            }\n        }\n        LOG.info(\"Configuration validated successfully.\");\n    }\n    catch (AddaxException e) {\n        throw e;\n    }\n    catch (Exception e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                \"The configuration is invalid. Please check the configuration and try again.\", e);\n    }\n    finally {\n        if (conn != null) {\n            try {\n                conn.close();\n            }\n            catch (SQLException e) {\n                LOG.warn(\"Failed to close JDBC connection.\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 47.825740561087535}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tString connStr = cfg.getConnectionString();\n    LOG.debug(\"Connecting to HBase cluster [{}] ...\", connStr);\n    Connection conn;\n    //\u662f\u5426\u6709Kerberos\u8ba4\u8bc1\n    haveKerberos = cfg.haveKerberos();\n    if (haveKerberos) {\n        kerberosKeytabFilePath = cfg.getKerberosKeytabFilePath();\n        kerberosPrincipal = cfg.getKerberosPrincipal();\n        hadoopConf.set(\"hadoop.security.authentication\", \"Kerberos\");\n    }\n    kerberosAuthentication(kerberosPrincipal, kerberosKeytabFilePath);\n    try {\n        Class.forName(\"org.apache.phoenix.jdbc.PhoenixDriver\");\n        if (cfg.isThinClient()) {\n            conn = getThinClientJdbcConnection(cfg);\n        }\n        else {\n            conn = DriverManager.getConnection(connStr);\n        }\n        conn.setAutoCommit(false);\n    }\n    catch (Throwable e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.GET_HBASE_CONNECTION_ERROR,\n                \"Unable to connect to hbase cluster, please check the configuration and cluster status \", e);\n    }\n    LOG.debug(\"Connected to HBase cluster successfully.\");\n    String fullTableName = cfg.getTableName();\n    String schemaName = cfg.getSchemaName();\n    String tableName = cfg.getTableName();\n    try {\n        // check table\n        checkTable(conn, schemaName, tableName, cfg.isThinClient());\n        // check columns\n        checkColumns(conn, fullTableName, cfg.getColumns());\n    }\n    catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE, e);\n    }\n    finally {\n        try {\n            conn.close();\n        }\n        catch (SQLException e) {\n            throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.C", "CodeBleu_score": 44.2719773019987}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n        Configuration hadoopConf = new Configuration();\n        hadoopConf.set(\"hadoop.security.authentication\", \"kerberos\");\n        UserGroupInformation.setConfiguration(hadoopConf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            error(\"Kerberos login error. Please check if the kerberosPrincipal: \" + kerberosPrincipal + \" and kerberosKeytabFilePath: \" + kerberosKeytabFilePath + \" are correct.\");\n            throw asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 49.48872721069728}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            Configuration conf = new Configuration();\n            conf.set(\"hadoop.security.authentication\", \"Kerberos\");\n            UserGroupInformation.setConfiguration(conf);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            error(\"Kerberos login error: \" + e.getMessage());\n            asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 42.92371101295822}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (kerberosPrincipal != null && kerberosKeytabFilePath != null && !kerberosPrincipal.isEmpty() && !kerberosKeytabFilePath.isEmpty()) {\n        System.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n        System.setProperty(\"sun.security.krb5.debug\", \"true\");\n        System.setProperty(\"java.security.auth.login.config\", \"/etc/jaas.conf\");\n        System.setProperty(\"javax.security.auth.useSubjectCredsOnly\", \"false\");\n        Configuration hadoopConf = new Configuration();\n        hadoopConf.set(\"hadoop.security.authentication\", \"Kerberos\");\n        UserGroupInformation.setConfiguration(hadoopConf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOGGER.error(\"Kerberos login error\", e);\n            throw AddaxException.asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 51.75322876752389}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> columns = new LinkedHashMap<String, ThinClientPTable.ThinClientPColumn>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int numCols = rsmd.getColumnCount();\n        for (int i = 1; i <= numCols; i++) {\n            String name = rsmd.getColumnLabel(i);\n            if (name == null || name.isEmpty()) {\n                throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_NOT_FOUND)\n                        .setColumnName(name).build().buildException();\n            }\n            String type = rsmd.getColumnTypeName(i);\n            if (type == null || type.isEmpty()) {\n                throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_NOT_FOUND)\n                        .setColumnName(name).build().buildException();\n            }\n            columns.put(name, new ThinClientPTable.ThinClientPColumn(name,\n                    ThinClientPDataType.fromSqlTypeName(type), rsmd.getPrecision(i), rsmd.getScale(i),\n                    rsmd.isNullable(i) == ResultSetMetaData.columnNullable, rsmd.isSigned(i), rsmd.getDisplaySize(i)));\n        }\n        return columns;\n    }", "CodeBleu_score": 40.83792236425855}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tResultSetMetaData rsmd = rs.getMetaData();\n    int numCols = rsmd.getColumnCount();\n    Map<String, ThinClientPTable.ThinClientPColumn> columns = Maps.newHashMapWithExpectedSize(numCols);\n    for (int i = 1; i <= numCols; i++) {\n        String columnName = rsmd.getColumnLabel(i);\n        String dataType = rsmd.getColumnTypeName(i);\n        if (columnName == null || dataType == null) {\n            throw new SQLExceptionInfo.Builder(SQLExceptionCode.RESULTSET_METADATA_INVALID)\n                    .setMessage(\"Column name or type is null: \" + columnName + \" \" + dataType).build().buildException();\n        }\n        columns.put(columnName, new ThinClientPTable.ThinClientPColumn(columnName,\n                ThinClientPTable.PColumn.getPDataTypeForTypeName(dataType)));\n    }\n    return columns;\n}", "CodeBleu_score": 42.41844556692721}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> columns = Maps.newHashMap();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int numCols = rsmd.getColumnCount();\n        for (int i = 1; i <= numCols; i++) {\n            String name = rsmd.getColumnLabel(i);\n            String type = rsmd.getColumnTypeName(i);\n            if (name == null || type == null) {\n                throw new SQLException(\"ResultSet column label and type should not be null.\");\n            }\n            columns.put(name, new ThinClientPTable.ThinClientPColumn(name,\n                    PDataType.fromSqlTypeName(type)));\n        }\n        return columns;\n    }", "CodeBleu_score": 37.802384265290065}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n        checkTable(admin, hTableName);\n        // \u6e05\u7a7a\u8868\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // \u6e05\u7a7a\u8868\u5931\u8d25\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 98.789877320245}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // Ensure table exists, is enabled, and is valid\n        checkTable(admin, hTableName);\n        // Truncate table\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // Truncate table failed\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 96.03616766257134}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // Ensure table exists and is enabled\n        checkTable(admin, hTableName);\n        // Truncate table\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // Truncate table failed\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 96.03616766257134}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\tif (checkHdfsFileType(filePath, this.specifiedFileType)) {\n        LOG.info(\"Added File [{}], File type [{}] matches specified file type [{}]\",\n                filePath, this.specifiedFileType, this.specifiedFileType);\n        this.sourceFiles.add(filePath);\n    } else {\n        String message = String.format(\"The File type of [%s] does not match the specified file type [%s].\",\n                filePath, this.specifiedFileType);\n        LOG.error(message);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n    }\n}", "CodeBleu_score": 51.93304387894172}, {"code": "private void addSourceFileByType(String filePath){\n\tboolean isSpecifiedFileType = checkHdfsFileType(filePath, specifiedFileType);\n    if (isSpecifiedFileType) {\n        LOG.info(String.format(\"[%s] The file [%s] format is [%s], add it to source files list.\",\n                taskGroupId, filePath, specifiedFileType));\n        sourceFiles.add(filePath);\n    }\n    else {\n        String message = String.format(\"[%s] The file [%s] format is not [%s], skip it.\",\n                taskGroupId, filePath, specifiedFileType);\n        LOG.error(message);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n    }\n}", "CodeBleu_score": 52.52641471110348}, {"code": "private void addSourceFileByType(String filePath){\n\tString specifiedFileType = this.readerConfig.getFileType();\n    Path file = new Path(filePath);\n    try (FileSystem fs = FileSystem.get(hadoopConf); FSDataInputStream in = fs.open(file)) {\n        if (StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.ORC)) {\n            if (isORCFile(file, fs, in)) {\n                LOG.info(\"Add a orc file [{}] to source files list.\", filePath);\n                sourceFiles.add(filePath);\n                return;\n            }\n        } else if (StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.RC)) {\n            if (isRCFile(filePath, in)) {\n                LOG.info(\"Add a rc file [{}] to source files list.\", filePath);\n                sourceFiles.add(filePath);\n                return;\n            }\n        } else if (StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.SEQ)) {\n            if (isSequenceFile(file, in)) {\n                LOG.info(\"Add a sequence file [{}] to source files list.\", filePath);\n                sourceFiles.add(filePath);\n                return;\n            }\n        } else if (StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.PARQUET)) {\n            if (isParquetFile(file)) {\n                LOG.info(\"Add a parquet file [{}] to source files list.\", filePath);\n                sourceFiles.add(filePath);\n                return;\n            }\n        } else if (StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.CSV)\n                || StringUtils.equalsIgnoreCase(specifiedFileType, HdfsConstant.TEXT)) {\n            LOG.info(\"Add a text file [{}] to source files list.\", filePath);\n            sourceFiles.add(filePath);\n            return;\n        }\n    } catch (Exception e) {\n        String message = String.format(\"Can not get the file format for [%s]\uff0cit only supports [%s].\",\n                filePath, HdfsConstant.SUPPORT_FILE_TYPE);\n        LOG", "CodeBleu_score": 31.991964360908064}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tLOG.info(\"Start Read sequenceFile [{}]...\", sourceSequenceFilePath);\n    Path seqFilePath = new Path(sourceSequenceFilePath);\n    SequenceFile.Reader reader = null;\n    try {\n        FileSystem fs = FileSystem.get(seqFilePath.toUri(), readerSliceConfig);\n        reader = new SequenceFile.Reader(fs, seqFilePath, readerSliceConfig);\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n        while (reader.next(key, value)) {\n            transportOneRecord(recordSender, getTransportResult(key, value));\n        }\n    } catch (Exception e) {\n        LOG.error(\"SequenceFileReader read sequenceFile error\", e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n    } finally {\n        IOUtils.closeStream(reader);\n    }\n}", "CodeBleu_score": 49.84138854139349}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tLOG.info(\"Start to read sequenceFile [{}]...\", sourceSequenceFilePath);\n\n    Path seqFilePath = new Path(sourceSequenceFilePath);\n    SequenceFile.Reader reader = null;\n    try {\n        FileSystem fs = FileSystem.get(seqFilePath.toUri(), readerSliceConfig);\n        reader = new SequenceFile.Reader(fs, seqFilePath, readerSliceConfig);\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n        while (reader.next(key, value)) {\n            transportOneRecord(recordSender, getKeyClass(key), value, taskPluginCollector);\n        }\n    } catch (Exception e) {\n        LOG.error(\"SequenceFileReader read sequence file error, file path: [{}], error info: {}\", sourceSequenceFilePath,\n                e.getMessage());\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n    } finally {\n        IOUtils.closeStream(reader);\n    }\n}", "CodeBleu_score": 51.466977992593854}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\tLOG.info(\"Start Read [{}] ...\", sourceSequenceFilePath);\n        Path seqFilePath = new Path(sourceSequenceFilePath);\n        SequenceFile.Reader reader = null;\n        try {\n            reader = new SequenceFile.Reader(seqFilePath.getFileSystem(readerSliceConfig), seqFilePath, readerSliceConfig);\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                transportOneRecord(recordSender, taskPluginCollector, key, value);\n            }\n        } catch (Exception e) {\n            LOG.error(\"SequenceFileReader read [{}] error:\", sourceSequenceFilePath, e);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n        } finally {\n            IOUtils.closeStream(reader);\n        }\n    }", "CodeBleu_score": 52.89097410295505}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tPath path = new Path(filepath);\n    FileSystem fs = null;\n    FSDataInputStream in = null;\n    try {\n        fs = FileSystem.get(hadoopConf);\n        in = fs.open(path);\n    } catch (IOException e) {\n        LOG.error(\"Failed to open file: \" + filepath, e);\n        throw AddaxException.asAddaxException(HdfsWriterErrorCode.ILLEGAL_VALUE,\n                String.format(\"Failed to open file: %s, %s\", filepath, e.getMessage()));\n    }\n    if (specifiedFileType.equalsIgnoreCase(\"orc\")) {\n        return isORCFile(path, fs, in);\n    } else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\n        return isRCFile(filepath, in);\n    } else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\n        return isSequenceFile(path, in);\n    } else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\n        return isParquetFile(path);\n    } else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\n        return isCsvFile(in);\n    } else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\n        return isTextFile(in);\n    } else {\n        LOG.error(\"Unsupported file type: \" + specifiedFileType);\n        throw AddaxException.asAddaxException(HdfsWriterErrorCode.ILLEGAL_VALUE,\n                String.format(\"Unsupported file type: %s\", specifiedFileType));\n    }\n}", "CodeBleu_score": 51.294524799114974}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tboolean isFileType = false;\n    try {\n        Configuration conf = new Configuration();\n        FileSystem fs = FileSystem.get(conf);\n        Path file = new Path(filepath);\n        if (fs.exists(file)) {\n            FSDataInputStream in = fs.open(file);\n            if (specifiedFileType.equalsIgnoreCase(FileType.ORC.name())) {\n                isFileType = isORCFile(file, fs, in);\n            } else if (specifiedFileType.equalsIgnoreCase(FileType.RC.name())) {\n                isFileType = isRCFile(filepath, in);\n            } else if (specifiedFileType.equalsIgnoreCase(FileType.SEQUENCE.name())) {\n                isFileType = isSequenceFile(file, in);\n            } else if (specifiedFileType.equalsIgnoreCase(FileType.PARQUET.name())) {\n                isFileType = isParquetFile(file);\n            } else if (specifiedFileType.equalsIgnoreCase(FileType.CSV.name())) {\n                isFileType = true;\n            } else if (specifiedFileType.equalsIgnoreCase(FileType.TEXT.name())) {\n                isFileType = true;\n            } else {\n                throw AddaxException.asAddaxException(HdfsReaderErrorCode.ILLEGAL_VALUE,\n                        String.format(\"The file type you configured is not supported : [%s]\", specifiedFileType));\n            }\n            in.close();\n        }\n    } catch (IOException e) {\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR,\n                String.format(\"The file [%s] cannot be opened, please check your configuration.\", filepath), e);\n    }\n    return isFileType;\n}", "CodeBleu_score": 43.87672427373906}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tFileSystem fs = null;\n    FSDataInputStream in = null;\n    try {\n        fs = FileSystem.get(hadoopConf);\n        Path path = new Path(filepath);\n        in = fs.open(path);\n        if (specifiedFileType.equalsIgnoreCase(\"orc\")) {\n            if (isORCFile(path, fs, in)) {\n                return true;\n            }\n        } else if (specifiedFileType.equalsIgnoreCase(\"rc\")) {\n            if (isRCFile(filepath, in)) {\n                return true;\n            }\n        } else if (specifiedFileType.equalsIgnoreCase(\"sequence\")) {\n            if (isSequenceFile(path, in)) {\n                return true;\n            }\n        } else if (specifiedFileType.equalsIgnoreCase(\"parquet\")) {\n            if (isParquetFile(path)) {\n                return true;\n            }\n        } else if (specifiedFileType.equalsIgnoreCase(\"csv\")) {\n            return true;\n        } else if (specifiedFileType.equalsIgnoreCase(\"text\")) {\n            return true;\n        } else {\n            LOG.error(\"The specified file type [{}] is not supported.\", specifiedFileType);\n            throw AddaxException.asAddaxException(\n                    HdfsReaderErrorCode.ILLEGAL_VALUE,\n                    String.format(\"The specified file type [%s] is not supported. Please check your configuration and try again.\", specifiedFileType)\n            );\n        }\n    } catch (IOException e) {\n        LOG.error(\"An error occurred when checking the file type: [{}].\", e.getMessage());\n        throw AddaxException.asAddaxException(\n                HdfsReaderErrorCode.ILLEGAL_VALUE,\n                String.format(\"An error occurred when checking the file type: [%s]. Please check your configuration and try again.\", e.getMessage())\n        );\n    } finally {\n        if (in != null) {\n            try {\n                in.close();\n            } catch (IOException e) {\n                LOG.error(\"An error occurred when closing the file: [{}].\", e.getMessage());\n                throw AddaxException.asAddaxException(", "CodeBleu_score": 39.84648664231049}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AsAddaxException(HBase1xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 55.41664673565096}, {"code": "public static void closeConnection(Connection hConnection){\n\ttry {\n        if (hConnection != null) {\n            hConnection.close();\n        }\n    } catch (IOException e) {\n        throw new HBaseException(HBaseErrorCode.CLOSE_CONNECTION_ERROR, e);\n    }\n}", "CodeBleu_score": 56.59462054440178}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AsAddaxException(Hbase1xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 55.691044622379934}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\tif (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new HbaseException(HbaseErrorCode.HBASE_ADMIN_CLOSE_ERROR, e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 47.5792925606465}, {"code": "public static void closeAdmin(Admin admin){\n\tif (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AsAddaxException(HBaseConstant.HBASE_CLOSE_EXCEPTION, e);\n        }\n    }\n}", "CodeBleu_score": 51.68857201727172}, {"code": "public static void closeAdmin(Admin admin){\n\tif (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AsAddaxException(HBase11xHelperErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 54.52135072668012}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key\n        byte[] rowKey = cell.getRowArray();\n        String rowKeyName = \"rowKey\";\n        String rowKeyType = \"string\";\n        String rowKeyFormat = \"string\";\n        String rowKeyValue = Bytes.toString(rowKey);\n        if (isBlank(rowKeyValue)) {\n            throw new Exception(\"The row key cannot be blank.\");\n        }\n        record.setValue(rowKeyName, convertBytesToAssignType(rowKeyValue, rowKeyType, rowKeyFormat));\n\n        // Get the timestamp\n        String timestampName = \"timestamp\";\n        String timestampType = \"string\";\n        String timestampFormat = \"string\";\n        String timestampValue = getTimestamp(cell);\n        if (isBlank(timestampValue)) {\n            throw new Exception(\"The timestamp cannot be blank.\");\n        }\n        record.setValue(timestampName, convertBytesToAssignType(timestampValue, timestampType, timestampFormat));\n\n        // Get the column family\n        byte[] family = cell.getFamilyArray();\n        String familyName = \"family\";\n        String familyType = \"string\";\n        String familyFormat = \"string\";\n        String familyValue = Bytes.toString(family);\n        if (isBlank(familyValue)) {\n            throw new Exception(\"The family cannot be blank.\");\n        }\n        record.setValue(familyName, convertBytesToAssignType(familyValue, familyType, familyFormat));\n\n        // Get the column qualifier\n        byte[] qualifier = cell.getQualifierArray();\n        String qualifierName = \"qualifier\";\n        String qualifierType = \"string\";\n        String qualifierFormat = \"string\";\n        String qualifierValue = Bytes.toString(qualifier);\n        if (isBlank(qualifierValue)) {\n            throw new Exception(\"The qualifier cannot be blank.\");\n        }\n        record.setValue(qualifierName, convertBytesToAssignType(qualifierValue, qualifierType, qualifierFormat));\n\n        // Get the column value\n        byte[] value = cell.getValueArray();\n        String valueName = \"value\";\n        String valueType = \"string\";\n        String valueFormat = \"string\";", "CodeBleu_score": 28.139232412566262}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key\n        byte[] rowKey = cell.getRowArray();\n        String rowKeyName = getByTypeName(rowKey);\n        if (rowKeyName == null) {\n            throw new Exception(\n                    \"Row key \"\n                            + Bytes.toString(cell.getRowArray())\n                            + \" is not in the list of configured row key types\");\n        }\n        record.setValue(rowKeyName, rowKey);\n\n        // Get the family and qualifier\n        byte[] family = cell.getFamilyArray();\n        byte[] qualifier = cell.getQualifierArray();\n        String familyName = getByTypeName(family);\n        String qualifierName = getByTypeName(qualifier);\n        if (familyName == null) {\n            throw new Exception(\n                    \"Column family \"\n                            + Bytes.toString(cell.getFamilyArray())\n                            + \" is not in the list of configured column family types\");\n        }\n        if (qualifierName == null) {\n            throw new Exception(\n                    \"Column qualifier \"\n                            + Bytes.toString(cell.getQualifierArray())\n                            + \" is not in the list of configured column qualifier types\");\n        }\n\n        // Get the timestamp\n        long timestamp = cell.getTimestamp();\n        String timestampName = getTimestamp();\n        if (timestampName != null) {\n            record.setValue(timestampName, timestamp);\n        }\n\n        // Get the value\n        byte[] value = cell.getValueArray();\n        String valueName = getByTypeName(value);\n        if (valueName == null) {\n            throw new Exception(\n                    \"Column value \"\n                            + Bytes.toString(cell.getValueArray())\n                            + \" is not in the list of configured column value types\");\n        }\n        record.setValue(valueName, value);\n\n        // Add the family and qualifier to the record\n        addColumn(record, familyName, qualifierName, timestamp, value);\n    }", "CodeBleu_score": 26.108211902705026}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t// Get the row key\n        byte[] rowKeyBytes = cell.getRowArray();\n        String rowKey = new String(rowKeyBytes, cell.getRowOffset(),\n                cell.getRowLength(), StandardCharsets.UTF_8);\n\n        // Get the timestamp\n        long timestamp = cell.getTimestamp();\n\n        // Get the family and qualifier\n        byte[] familyBytes = cell.getFamilyArray();\n        String family = new String(familyBytes, cell.getFamilyOffset(),\n                cell.getFamilyLength(), StandardCharsets.UTF_8);\n        byte[] qualifierBytes = cell.getQualifierArray();\n        String qualifier = new String(qualifierBytes, cell.getQualifierOffset(),\n                cell.getQualifierLength(), StandardCharsets.UTF_8);\n\n        // Get the value\n        byte[] valueBytes = cell.getValueArray();\n        String value = new String(valueBytes, cell.getValueOffset(),\n                cell.getValueLength(), StandardCharsets.UTF_8);\n\n        // Get the type name for the row key\n        String rowKeyTypeName = getTypeName(rowKey, rowKeyTypeMapping);\n        // Get the type name for the column value\n        String valueTypeName = getTypeName(value, valueTypeMapping);\n\n        // Add the row key as a column\n        record.setString(rowKeyTypeName, rowKey);\n        // Add the family as a column\n        record.setString(FAMILY_TYPE_NAME, family);\n        // Add the qualifier as a column\n        record.setString(QUALIFIER_TYPE_NAME, qualifier);\n        // Add the timestamp as a column\n        record.setLong(TIMESTAMP_TYPE_NAME, timestamp);\n        // Add the value as a column\n        record.setString(valueTypeName, value);\n    }", "CodeBleu_score": 35.15778750191434}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString userStartRowkey = configuration.get(HBaseConstants.START_ROWKEY);\n    return convertUserRowkey(userStartRowkey, configuration.getBoolean(HBaseConstants.IS_BINARY_ROWKEY, false));\n}", "CodeBleu_score": 33.254107652848155}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.get(HBaseTableInputFormat.SCAN_ROW_START);\n    return convertUserRowkey(startRowkey, configuration);\n}", "CodeBleu_score": 34.87394584334638}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString userStartRowkey = configuration.get(ROWKEY_START_CONFIG_NAME);\n    return convertUserRowkey(userStartRowkey, configuration.getBoolean(ROWKEY_BINARY_CONFIG_NAME, false));\n}", "CodeBleu_score": 22.32390344429951}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.get(START_ROW_KEY);\n  return convertInnerStartRowkey(startRowKey);\n}", "CodeBleu_score": 33.68351549905791}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.get(START_ROW_KEY);\n    if (startRowKey == null) {\n        return new byte[0];\n    }\n    if (startRowKey.trim().isEmpty()) {\n        return new byte[0];\n    }\n    return startRowKey.getBytes(StandardCharsets.UTF_8);\n}", "CodeBleu_score": 43.00864528478166}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.get(START_ROW_KEY_CONF_KEY, \"\");\n    if (startRowKey.isEmpty()) {\n        return new byte[0];\n    } else {\n        return startRowKey.getBytes(StandardCharsets.UTF_8);\n    }\n}", "CodeBleu_score": 42.122856579892705}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\n    this.value = record.value();\n    this.headers = new TbQueueMsgHeaders(record.headers());\n}", "CodeBleu_score": 41.9575740484399}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.57455082261813}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\n    this.headers = new KafkaTbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.179485496319884}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToTransportMsg>> builder = TbKafkaProducerTemplate.builder();\n    builder.settings(kafkaSettings);\n    builder.clientId(buildClientId(serviceInfoProvider.getServiceId()));\n    builder.defaultTopic(getNotificationsTopic());\n    return new TbKafkaProducerTemplate<>(builder.build());\n}", "CodeBleu_score": 53.46129477880447}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToTransportMsg>> templateBuilder = TbKafkaProducerTemplate.builder();\n    templateBuilder.settings(producerConfig);\n    templateBuilder.clientId(getServiceId() + \"-notifications-\" + clientId);\n    templateBuilder.defaultTopic(getNotificationsTopic());\n    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate = templateBuilder.build();\n    producerTemplate.setAdmin(admin);\n    return producerTemplate;\n}", "CodeBleu_score": 57.844536200825644}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToTransportMsg>> templateBuilder = TbKafkaProducerTemplate.builder();\n    templateBuilder.settings(kafkaSettings);\n    templateBuilder.clientId(buildClientId(serviceInfoProvider.getServiceId()));\n    templateBuilder.defaultTopic(getNotificationsTopic());\n    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> template = templateBuilder.build();\n    template.setAdmin(admin);\n    return template;\n}", "CodeBleu_score": 58.72816269102302}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\n    consumerBuilder.settings(this.settings);\n    consumerBuilder.topic(this.getNotificationsTopic());\n    consumerBuilder.clientId(this.getClientId());\n    consumerBuilder.groupId(this.getGroupId());\n    consumerBuilder.decoder(msg -> {\n        try {\n            return new TbProtoQueueMsg<>(UUID.randomUUID(), ToCoreNotificationMsg.parseFrom(msg));\n        } catch (InvalidProtocolBufferException e) {\n            log.warn(\"Failed to decode device attributes response\", e);\n            throw new RuntimeException(\"Failed to decode device attributes response\", e);\n        }\n    });\n    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = consumerBuilder.build();\n    consumer.setAdmin(this.admin);\n    consumer.setStatsService(this.statsService);\n    return consumer;\n}", "CodeBleu_score": 52.48148318520638}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate\n            .builder();\n    consumerBuilder.settings(settings);\n    consumerBuilder.topic(TopicPartitionInfo.getNotificationsTopic(settings));\n    consumerBuilder.clientId(clientId);\n    consumerBuilder.groupId(groupId);\n    consumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData())));\n    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = consumerBuilder.build();\n    consumerTemplate.setAdmin(admin);\n    consumerTemplate.setStatisticsService(statsService);\n    return consumerTemplate.create();\n}", "CodeBleu_score": 56.58758673966029}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate\n            .builder();\n    consumerBuilder.settings(settings);\n    consumerBuilder.topic(TopicPartitionInfo.builder()\n            .topic(getNotificationsTopic())\n            .partition(0)\n            .build());\n    consumerBuilder.clientId(getClientId());\n    consumerBuilder.groupId(getGroupId());\n    consumerBuilder.decoder(msg -> {\n        try {\n            return new TbProtoQueueMsg<>(UUID.randomUUID(), ToCoreNotificationMsg.parseFrom(msg.getData()));\n        } catch (InvalidProtocolBufferException e) {\n            log.warn(\"Failed to decode message\", e);\n            return null;\n        }\n    });\n    consumerBuilder.admin(admin);\n    consumerBuilder.statsService(statsService);\n    return consumerBuilder.build();\n}", "CodeBleu_score": 59.116066621549614}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\n        logger.info(\"No topics provided, unsubscribing from all topics\");\n        consumer.unsubscribe();\n    } else {\n        for (String topicName : topicNames) {\n            logger.info(\"Subscribing to topic {}\", topicName);\n            createTopicIfNecessary(topicName);\n        }\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 56.79234089481548}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\n        logger.info(\"No topics provided, unsubscribing from all topics\");\n        consumer.unsubscribe();\n    } else {\n        logger.info(\"Subscribing to topics: {}\", topicNames);\n        topicNames.forEach(topic -> {\n            try {\n                adminClient.createTopics(Collections.singleton(new NewTopic(topic, 1, (short) 1)));\n            } catch (Exception e) {\n                logger.error(\"Error creating topic: {}\", topic, e);\n            }\n        });\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 52.601660327549226}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\n        log.info(\"No topics to subscribe to.\");\n        consumer.unsubscribe();\n    } else {\n        log.info(\"Subscribing to topics: {}\", topicNames);\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 61.92617105437497}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tStopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling topic '{}' for {} millis\", getTopic(), durationInMillis);\n    ConsumerRecords<String, byte[]> consumerRecords = getConsumer().poll(ofMillis(durationInMillis));\n    stopwatch.stop();\n    log.trace(\"Polled {} records from topic '{}' in {} millis\", consumerRecords.count(), getTopic(),\n            getTotalTimeMillis(stopwatch));\n    if (consumerRecords.isEmpty()) {\n        return emptyList();\n    }\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>(consumerRecords.count());\n    consumerRecords.forEach(records::add);\n    return records;\n}", "CodeBleu_score": 57.99385565054177}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tStopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling {} for {} ms\", getTopic(), durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = emptyList();\n    ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(ofMillis(durationInMillis));\n    stopwatch.stop();\n    log.trace(\"Polled {} records from {} in {} ms\", consumerRecords.count(), getTopic(), stopwatch.elapsed(MILLISECONDS));\n    if (!consumerRecords.isEmpty()) {\n        records = new ArrayList<>(consumerRecords.count());\n        consumerRecords.forEach(records::add);\n    }\n    return records;\n}", "CodeBleu_score": 53.82201821150442}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tStopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling for {} ms from topic {}\", durationInMillis, getTopic());\n    ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(ofMillis(durationInMillis));\n    stopwatch.stop();\n    log.trace(\"Polled {} records from topic {} in {} ms\", consumerRecords.count(), getTopic(), getTotalTimeMillis(stopwatch));\n    if (isEmpty(consumerRecords)) {\n        return emptyList();\n    } else {\n        return consumerRecords.collect(toList());\n    }\n}", "CodeBleu_score": 46.65632600797809}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (error != null) {\n        ctx.tellFailure(msg, error);\n        return;\n    }\n    String topic = getTopicPattern(msg);\n    String key = getKeyPattern(msg);\n    executor.submit(() -> publish(ctx, msg, topic, key));\n}", "CodeBleu_score": 11.732700132785526}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError != null) {\n        ctx.tellFailure(msg, initError);\n        return;\n    }\n    try {\n        String topic = getTopicPattern(ctx, msg).process(msg);\n        String key = getKeyPattern(ctx, msg).process(msg);\n        publish(ctx, msg, topic, key);\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 33.14949968058334}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\ttry {\n        String topic = getTopicPattern(ctx, msg);\n        String key = getKeyPattern(ctx, msg);\n        if (topic == null || key == null) {\n            log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n            return;\n        }\n        publish(ctx, msg, topic, key);\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n    }\n}", "CodeBleu_score": 29.606156505402044}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tProducerRecord<String, byte[]> record;\n    if (addMetadata) {\n        record = new ProducerRecord<>(topic, null, key, msg.getBytes(), createHeaders(msg));\n    } else {\n        record = new ProducerRecord<>(topic, null, key, msg.getBytes());\n    }\n    producer.send(record, (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n}", "CodeBleu_score": 31.596787546914264}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, null, key, msg.getData());\n    if (addMetadata) {\n        record.headers().add(new RecordHeader(MESSAGE_ID_HEADER, msg.getId().getBytes()));\n        record.headers().add(new RecordHeader(ENTITY_TYPE_HEADER, msg.getOriginator().getEntityType().name().getBytes()));\n        record.headers().add(new RecordHeader(ENTITY_ID_HEADER, getKey(msg).getBytes()));\n    }\n    producer.send(record, (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n}", "CodeBleu_score": 35.72714983134547}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tProducerRecord<String, byte[]> record;\n    if (addMetadata) {\n        Map<String, String> metadata = new HashMap<>();\n        msg.getMetaData().getData().forEach((k, v) -> metadata.put(k.toString(), v.toString()));\n        record = new ProducerRecord<>(topic, null, key, msg.getData(), new RecordHeaders().add(new RecordHeader(METADATA, metadata.toString().getBytes())));\n    } else {\n        record = new ProducerRecord<>(topic, null, key, msg.getData());\n    }\n    producer.send(record, (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n}", "CodeBleu_score": 39.59971730681319}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\ttry {\n        if (producer != null) {\n            producer.close();\n        }\n    } catch (Exception e) {\n        logger.error(\"Failed to close producer. Exception: \" + e);\n    }\n}", "CodeBleu_score": 58.72589126979393}, {"code": "public void destroy(){\n\tif (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close the Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 67.97789431687255}, {"code": "public void destroy(){\n\tif (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close the Kafka producer.\", e);\n        }\n    }\n}", "CodeBleu_score": 71.18287907240185}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = TbKafkaProducerTemplate\n            .builder();\n    builder.settings(kafkaSettings);\n    builder.clientId(clientId);\n    builder.defaultTopic(defaultTopic.getTbRuleEngineQueue());\n    builder.admin(admin);\n    return builder.build();\n}", "CodeBleu_score": 59.17811530632451}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplateBuilder = TbKafkaProducerTemplate\n            .builder();\n    ruleEngineProducerTemplateBuilder\n            .settings(kafkaSettings)\n            .clientId(clientId)\n            .defaultTopic(defaultTopic.getTbRuleEngineTopic())\n            .admin(admin);\n    return ruleEngineProducerTemplateBuilder.build();\n}", "CodeBleu_score": 47.13340656420488}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplateBuilder = TbKafkaProducerTemplate\n            .builder();\n\n    ruleEngineProducerTemplateBuilder\n            .settings(kafkaSettings)\n            .clientId(clientId)\n            .defaultTopic(defaultTopic)\n            .admin(admin);\n\n    if (useIotHub) {\n        ruleEngineProducerTemplateBuilder.settings(kafkaSettings);\n    }\n\n    TbKafkaProducerTemplate<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplate = ruleEngineProducerTemplateBuilder.build();\n    return ruleEngineProducerTemplate.create();\n}", "CodeBleu_score": 48.97997326801022}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tlong timeoutDuration = Duration.ofMillis(getKafkaResponseTimeoutMs()).toMillis();\n    scheduleWithFixedDelay(this::logConsumerGroupStats, timeoutDuration, timeoutDuration);\n}", "CodeBleu_score": 6.836738265599795}, {"code": "private void startLogScheduling(){\n\tlong timeoutDuration = TimeUnit.MILLISECONDS.convert(kafkaResponseTimeoutMs, TimeUnit.SECONDS);\n        scheduledExecutor.scheduleWithFixedDelay(this::logConsumerGroupStats, printIntervalMs, printIntervalMs, TimeUnit.MILLISECONDS);\n        log.info(\"Started logging of consumer group statistics with interval {} ms\", printIntervalMs);\n    }", "CodeBleu_score": 5.852765012038296}, {"code": "private void startLogScheduling(){\n\tlong timeoutDuration = getKafkaResponseTimeoutMs();\n        log.info(\"Starting log scheduling for consumer groups with timeout duration {} ms\", timeoutDuration);\n        scheduleWithFixedDelay(this::logConsumerGroups, timeoutDuration, timeoutDuration, TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 7.357211360127399}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.65226058011727}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.65226058011727}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\n\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n\n        return props;\n    }", "CodeBleu_score": 90.14885306759078}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tfinal String scopedName = getScopedName(metricName, group);\n\t\tfinal Map<String, String> tags = getTags(group);\n\n\t\tif (metric instanceof Counter) {\n\t\t\tCounter counter = (Counter) metric;\n\t\t\tthis.counters.put(scopedName, new MetricEvent(counter, scopedName, tags));\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tGauge gauge = (Gauge) metric;\n\t\t\tthis.gauges.put(scopedName, new MetricEvent(gauge, scopedName, tags));\n\t\t} else if (metric instanceof Histogram) {\n\t\t\tHistogram histogram = (Histogram) metric;\n\t\t\tthis.histograms.put(scopedName, new MetricEvent(histogram, scopedName, tags));\n\t\t} else if (metric instanceof Meter) {\n\t\t\tMeter meter = (Meter) metric;\n\t\t\tthis.meters.put(scopedName, new MetricEvent(meter, scopedName, tags));\n\t\t} else {\n\t\t\tLOG.warn(\"Cannot add unknown metric type: {}. This indicates that the metric type is not supported.\", metric.getClass().getName());\n\t\t}\n\t}", "CodeBleu_score": 49.94632419925404}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tif (metric instanceof Counter) {\n\t\t\tCounter counter = (Counter) metric;\n\t\t\tString name = getScopedName(metricName, group);\n\t\t\tString[] tags = getTags(group).entrySet().stream()\n\t\t\t\t.map(e -> e.getKey() + \":\" + e.getValue())\n\t\t\t\t.toArray(String[]::new);\n\t\t\tMetricEvent event = new MetricEvent(counter, name, tags);\n\t\t\tcounters.put(name, event);\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tGauge gauge = (Gauge) metric;\n\t\t\tString name = getScopedName(metricName, group);\n\t\t\tString[] tags = getTags(group).entrySet().stream()\n\t\t\t\t.map(e -> e.getKey() + \":\" + e.getValue())\n\t\t\t\t.toArray(String[]::new);\n\t\t\tMetricEvent event = new MetricEvent(gauge, name, tags);\n\t\t\tgauges.put(name, event);\n\t\t} else if (metric instanceof Histogram) {\n\t\t\tHistogram histogram = (Histogram) metric;\n\t\t\tString name = getScopedName(metricName, group);\n\t\t\tString[] tags = getTags(group).entrySet().stream()\n\t\t\t\t.map(e -> e.getKey() + \":\" + e.getValue())\n\t\t\t\t.toArray(String[]::new);\n\t\t\tMetricEvent event = new MetricEvent(histogram, name, tags);\n\t\t\thistograms.put(name, event);\n\t\t} else if (metric instanceof Meter) {\n\t\t\tMeter meter = (Meter) metric;\n\t\t\tString name = getScopedName(metricName, group);\n\t\t\tString[] tags = getTags(group).entrySet().stream()\n\t\t\t\t.map(e -> e.getKey() + \":\" + e.getValue())\n\t\t\t\t.toArray(String[]::new);\n\t\t\tMetricEvent event =", "CodeBleu_score": 42.40006304424585}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tfinal String scopedName = getScopedName(metricName, group);\n\t\tfinal Map<String, String> tags = getTags(group);\n\n\t\tif (metric instanceof Counter) {\n\t\t\tCounterEvent event = new CounterEvent(scopedName, tags, (Counter) metric);\n\t\t\tcounterEvents.add(event);\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tGaugeEvent event = new GaugeEvent(scopedName, tags, (Gauge) metric);\n\t\t\tgaugeEvents.add(event);\n\t\t} else if (metric instanceof Histogram) {\n\t\t\tHistogramEvent event = new HistogramEvent(scopedName, tags, (Histogram) metric);\n\t\t\thistogramEvents.add(event);\n\t\t} else if (metric instanceof Meter) {\n\t\t\tMeterEvent event = new MeterEvent(scopedName, tags, (Meter) metric);\n\t\t\tmeterEvents.add(event);\n\t\t} else {\n\t\t\tLOG.warn(\"Metric type is not supported: {}\", metric.getClass());\n\t\t}\n\t}", "CodeBleu_score": 45.209415177742365}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tObject value = gauge.getValue();\n    if (value instanceof Number) {\n        return addNumberField(metricEvent, field, (Number) value);\n    } else {\n        return addStringField(metricEvent, field, value.toString());\n    }\n}", "CodeBleu_score": 28.325363801949855}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tdef value = gauge.value\n    if (value instanceof Number) {\n        return metricEvent.addFields([(field): value.doubleValue()])\n    } else {\n        return metricEvent.addFields([(field): value.toString()])\n    }\n}", "CodeBleu_score": 21.70377829669492}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\tNumber value = gauge.getValue();\n    if (value instanceof Integer || value instanceof Long || value instanceof Double || value instanceof Float) {\n        return addField(metricEvent, field, value);\n    } else {\n        return addField(metricEvent, field, value.toString());\n    }\n}", "CodeBleu_score": 25.99040965536399}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\tString[] components = gauge.getValue().toString().split(\",\");\n\t\tString[] currentOffsets = components[0].split(\":\");\n\t\tString[] dataTimestamp = components[1].split(\":\");\n\t\tString[] committedOffsets = components[2].split(\":\");\n\n\t\t// The gauge's value is a string of the form \"currentOffsets:dataTimestamp:committedOffsets\".\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"\n\t\t// The currentOffsets, dataTimestamp, and committedOffsets are each strings of the form \"partition=offset,partition=offset,...\"", "CodeBleu_score": 17.356820448501217}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t// Extract the values from the gauge.\n\t\tString[] values = gauge.getValue().toString().split(\",\");\n\t\t// If the values have changed, update the kafkaLagTimes map.\n\t\tif (!kafkaLagTimes.get(metricEvent.getTags().get(\"topic\")).equals(values[1])) {\n\t\t\tkafkaLagTimes.put(metricEvent.getTags().get(\"topic\"), values[1]);\n\t\t}\n\t\t// Update the MetricEvent's fields with the current offsets, data timestamp, and committed offsets.\n\t\tmetricEvent.getFields().put(\"currentOffset\", values[0]);\n\t\tmetricEvent.getFields().put(\"dataTimestamp\", timestamp);\n\t\tmetricEvent.getFields().put(\"committedOffset\", values[1]);\n\t\t// Set the event's timestamp.\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\treturn metricEvent;\n\t}", "CodeBleu_score": 27.052439828455576}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\tString[] metricNameComponents = metricEvent.getName().split(\"\\\\.\");\n\t\tString topic = metricNameComponents[2];\n\t\tString partition = metricNameComponents[3];\n\t\tString group = metricNameComponents[4];\n\n\t\t// Extract the metric value from the gauge.\n\t\tMap<String, String> metricValue = (Map<String, String>) gauge.getValue();\n\n\t\t// Extract the current offset from the metric value.\n\t\tString currentOffset = metricValue.get(\"currentOffset\");\n\t\tLong currentOffsetLong = Long.parseLong(currentOffset);\n\n\t\t// Extract the committed offset from the metric value.\n\t\tString committedOffset = metricValue.get(\"committedOffset\");\n\t\tLong committedOffsetLong = Long.parseLong(committedOffset);\n\n\t\t// Extract the timestamp from the metric value.\n\t\tString timestampString = metricValue.get(\"timestamp\");\n\t\tLong timestampLong = Long.parseLong(timestampString);\n\n\t\t// Update the metric event's fields with the current offset, data timestamp, and committed offset.\n\t\tmetricEvent.addField(\"topic\", topic);\n\t\tmetricEvent.addField(\"partition\", partition);\n\t\tmetricEvent.addField(\"group\", group);\n\t\tmetricEvent.addField(\"currentOffset\", currentOffsetLong);\n\t\tmetricEvent.addField(\"dataTimestamp\", timestampLong);\n\t\tmetricEvent.addField(\"committedOffset\", committedOffsetLong);\n\n\t\t// Check for changes in the Kafka lag metrics.\n\t\t// If the current offset and committed offset are the same, the Kafka consumer has caught up with the Kafka producer.\n\t\t// If the current offset is greater than the committed offset, the Kafka consumer is lagging behind the Kafka producer.\n\t\tif (currentOffsetLong.equals(committedOffsetLong)) {\n\t\t\tkafkaLagTimes.put(metricEvent.getName(), timestamp);\n\t\t} else if (currentOffsetLong > committedOffsetLong) {\n\t\t\tkafkaLagTimes.put(metricEvent.getName(), timestamp);\n\t\t}\n\n\t\t// Set the metric event's timestamp.\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\treturn metricEvent", "CodeBleu_score": 35.22610503259076}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties kafkaProps = buildKafkaProps(getGlobalJobParameters(env));\n        FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), kafkaProps);\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> partitionOffsets = buildOffsetByTime(kafkaProps, getGlobalJobParameters(env), time);\n            setStartFromSpecificOffsets(consumer, partitionOffsets);\n        }\n        return env.addSource(consumer);\n    }", "CodeBleu_score": 54.42162380862019}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties props = buildKafkaProps(env.getConfig().getGlobalJobParameters());\n        FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n        if (time != null) {\n            setStartFromSpecificOffsets(consumer, time);\n        }\n        return env.addSource(consumer);\n    }", "CodeBleu_score": 50.489571243498645}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties props = buildKafkaProps(env.getConfig().getGlobalJobParameters());\n        FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, env.getConfig().getGlobalJobParameters(), time);\n            setStartFromSpecificOffsets(consumer, partitionOffset);\n        }\n        return env.addSource(consumer);\n    }", "CodeBleu_score": 62.68684059132591}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, parameterTool.getRequired(\"group.id\") + \"-\" + time);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n    Map<KafkaTopicPartition, Long> partitionTimestamps = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        partitionTimestamps.put(new KafkaTopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n    }\n    Map<KafkaTopicPartition, OffsetAndTimestamp> offsetsForTimes = consumer.offsetsForTimes(partitionTimestamps);\n    for (KafkaTopicPartition partition : offsetsForTimes.keySet()) {\n        partitionOffsets.put(partition, offsetsForTimes.get(partition).offset());\n    }\n    consumer.close();\n    return partitionOffsets;\n}", "CodeBleu_score": 57.92331827780317}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tString groupId = parameterTool.getRequired(\"group.id\") + \"-\" + time;\n    props.put(\"group.id\", groupId);\n\n    KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n    Map<Integer, Long> partitionTimestampMap = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        partitionTimestampMap.put(partitionInfo.partition(), time);\n    }\n\n    Map<KafkaTopicPartition, Long> partitionOffsetMap = new HashMap<>();\n    for (Map.Entry<Integer, Long> partitionTimestamp : partitionTimestampMap.entrySet()) {\n        TopicPartition partition = new TopicPartition(parameterTool.getRequired(\"topic\"), partitionTimestamp.getKey());\n        OffsetAndTimestamp offsetAndTimestamp = consumer.offsetsForTimes(Collections.singletonMap(partition, partitionTimestamp.getValue())).get(partition);\n        if (offsetAndTimestamp != null) {\n            partitionOffsetMap.put(new KafkaTopicPartition(parameterTool.getRequired(\"topic\"), partitionTimestamp.getKey()), offsetAndTimestamp.offset());\n        }\n    }\n\n    consumer.close();\n    return partitionOffsetMap;\n}", "CodeBleu_score": 45.8826564043214}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tString groupId = \"kafka-connect-\" + parameterTool.getRequired(\"topic\") + \"-\" + time;\n    props.put(\"group.id\", groupId);\n\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n    Map<Integer, Long> partitionTimestampMap = new HashMap<>();\n    partitionInfos.forEach(pi -> partitionTimestampMap.put(pi.partition(), time));\n    Map<TopicPartition, Long> partitionOffsets = consumer.offsetsForTimes(partitionTimestampMap);\n    Map<KafkaTopicPartition, Long> partitionOffsetsByTopic = new HashMap<>();\n    partitionOffsets.forEach((tp, offset) -> {\n        partitionOffsetsByTopic.put(new KafkaTopicPartition(parameterTool.getRequired(\"topic\"), tp.partition()), offset);\n    });\n    consumer.close();\n    return partitionOffsetsByTopic;\n}", "CodeBleu_score": 48.955312840026885}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setName(\"metric.event\");\n    event.setTags(new HashMap<String, String>());\n    event.setTimestamp(currentTimeMillis());\n    event.setFields(new HashMap<String, Object>());\n    event.getFields().put(\"field\", 1);\n\n    ProducerRecord<String, String> data = new ProducerRecord<String, String>(\"topic\", event.toJson());\n    producer.send(data);\n    producer.flush();\n    println(data.toString());\n}", "CodeBleu_score": 54.98459039741772}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setName(\"my-event\");\n    event.setTags(Collections.singletonMap(\"my-tag\", \"my-value\"));\n    event.setTimestamp(System.currentTimeMillis());\n    event.setFields(Collections.singletonMap(\"my-field\", \"my-value\"));\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my-topic\", event.toJson());\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent data: \" + event.toJson());\n}", "CodeBleu_score": 46.924067280609165}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t// Set producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"broker1:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    // Create the Kafka producer\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    // Create the MetricEvent\n    MetricEvent metricEvent = new MetricEvent();\n    metricEvent.setName(\"test-metric\");\n    metricEvent.setTags(new HashMap<String, String>() {{\n        put(\"test-tag\", \"test-tag-value\");\n    }});\n    metricEvent.setFields(new HashMap<String, Object>() {{\n        put(\"test-field\", \"test-field-value\");\n    }});\n    metricEvent.setTimestamp(currentTimeMillis());\n\n    // Create the ProducerRecord\n    ProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test-topic\", metricEvent.toJson());\n\n    // Send the metric to Kafka\n    producer.send(record);\n    producer.flush();\n\n    // Print the sent data\n    println(String.format(\"Sent data to Kafka: %s\", record.value()));\n}", "CodeBleu_score": 52.65744840168123}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (this.getLevel().isInRange(event.getLevel())) {\n        if (!this.getLoggerName().contains(\"xxx\")) {\n            try {\n                this.send(this.subAppend(event));\n            } catch (Exception e) {\n                log.warn(\"Error appending event to Kafka\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 45.53313621968904}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (this.levels.contains(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            this.producer.send(new ProducerRecord<>(this.topic, this.subAppend(event)));\n        } catch (Exception e) {\n            this.log.warn(\"Error sending log event to Kafka\", e);\n        }\n    }\n}", "CodeBleu_score": 47.886530776255604}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (getLevel() == null || getLevel().contains(event.getLevel().toString())) {\n        if (getLoggerName() == null || !event.getLoggerName().contains(getLoggerName())) {\n            try {\n                send(subAppend(event));\n            } catch (Exception e) {\n                log.warn(\"Error sending log event to Kafka topic({})\", getName(), e);\n            }\n        }\n    }\n}", "CodeBleu_score": 51.45312806373975}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 92.40633567441876}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, m := range validTopicSuffixMethods {\n\t\tif method == m {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method %s\", method)\n}", "CodeBleu_score": 81.16497827873661}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range topicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 88.62735206638955}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tif k.RoutingTag != \"\" {\n        if value, ok := metric.GetTag(k.RoutingTag); ok {\n            return value, nil\n        }\n    }\n\n    if k.RoutingKey == \"random\" {\n        uuid, err := uuid.NewV4()\n        if err != nil {\n            return \"\", err\n        }\n        return uuid.String(), nil\n    }\n\n    return k.RoutingKey, nil\n}", "CodeBleu_score": 82.21277542192351}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.Tags()[k.RoutingTag]; ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.02265721046312}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tif k.RoutingTag != \"\" {\n        if value, ok := metric.Tags()[k.RoutingTag]; ok {\n            return value, nil\n        }\n    }\n    if k.RoutingKey == \"random\" {\n        uuid, err := uuid.NewV4()\n        if err != nil {\n            return \"\", err\n        }\n        return uuid.String(), nil\n    }\n    return k.RoutingKey, nil\n}", "CodeBleu_score": 79.7402219367093}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %s: %s\", regexpStr, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.676362971277086}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %s: %s\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.20404756116404}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", regexpStr, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.34939548994846}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif track.Delivered {\n\t\tmsg.session.MarkMessage(msg.message, \"\")\n\t}\n\n\tdelete(h.undelivered, track.ID)\n\th.sem <- struct{}{}\n}", "CodeBleu_score": 63.71273800440066}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.log.Errorf(\"Delivery report for unknown message: %v\", track)\n\t\treturn\n\t}\n\n\tdelete(h.undelivered, track.ID)\n\th.delivered++\n\th.sem.Release(1)\n\n\tif track.Error != nil {\n\t\th.log.Errorf(\"Delivery failed for message: %v\", track)\n\t\treturn\n\t}\n\n\tmsg.session.MarkMessage(msg.message, msg.partition, msg.offset)\n\th.delivered++\n}", "CodeBleu_score": 57.5871559642682}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.mu.Unlock()\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\tmsg.session.MarkMessage(msg.message, track.Delivered)\n\th.sem.Release(1)\n}", "CodeBleu_score": 51.404343988810865}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Reserve(ctx); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\th.acc.AddError(h.Handle(ctx, msg))\n\t\t\th.Release()\n\t\t}\n\t}\n}", "CodeBleu_score": 68.6737349655824}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Reserve(ctx); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\th.Handle(ctx, msg)\n\t\t\th.acc.AddError(msg.Topic, msg.Partition, msg.Offset, msg.Value)\n\t\t}\n\t}\n}", "CodeBleu_score": 66.49373164902231}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Reserve(ctx); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\th.acc.AddFields(\"kafka_consumer\",\n\t\t\t\tmap[string]interface{}{\n\t\t\t\t\t\"count\":         1,\n\t\t\t\t\t\"topic\":         msg.Topic,\n\t\t\t\t\t\"partition\":     msg.Partition,\n\t\t\t\t\t\"offset\":        msg.Offset,\n\t\t\t\t\t\"highwater_off\": msg.HighWaterMarkOffset,\n\t\t\t\t},\n\t\t\t\tmap[string]string{\n\t\t\t\t\t\"topic\":     msg.Topic,\n\t\t\t\t\t\"partition\": strconv.Itoa(int(msg.Partition)),\n\t\t\t\t},\n\t\t\t)\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 69.90406067514806}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tval max_logkafka_id_length = 255\n    val logkafka_id_regex = \"^[a-zA-Z0-9\\\\.\\\\-_]+$\"\n    val r = new Regex(logkafka_id_regex)\n\n    checkCondition(logkafka_id.length > 0, IllegalCharacterInLogkafkaId)\n    checkCondition(!(logkafka_id == \".\" || logkafka_id == \"..\"), IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.length <= max_logkafka_id_length, IllegalCharacterInLogkafkaId)\n    checkCondition(r.findFirstIn(logkafka_id).isDefined, IllegalCharacterInLogkafkaId)\n  }", "CodeBleu_score": 29.736568351038105}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tval rgx = \"\"\"^[a-zA-Z0-9_\\.\\-]+$\"\"\".r\n    val max_id_length = 255\n    val error = UtilError(\"IllegalCharacterInLogkafkaId\", \"Logkafka ID contains illegal characters\")\n    checkCondition(logkafka_id != \"\", UtilError(\"EmptyLogkafkaId\", \"Logkafka ID is empty\"))\n    checkCondition(logkafka_id != \".\", UtilError(\"CurrentDirectory\", \"Logkafka ID cannot be \\\".\\\"\"))\n    checkCondition(logkafka_id != \"..\", UtilError(\"ParentDirectory\", \"Logkafka ID cannot be \\\"..\\\"\"))\n    checkCondition(logkafka_id.length <= max_id_length, UtilError(\"TooLongLogkafkaId\", s\"Logkafka ID cannot exceed $max_id_length characters\"))\n    checkCondition(rgx.findFirstIn(logkafka_id).isDefined, error)\n  }", "CodeBleu_score": 22.90295995394695}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tval rgx = \"\"\"^[a-zA-Z0-9\\.\\-_]+$\"\"\".r\n    checkCondition(logkafka_id.nonEmpty, IllegalCharacterInLogkafkaId)\n    checkCondition(!logkafka_id.equals(\".\"), IllegalCharacterInLogkafkaId)\n    checkCondition(!logkafka_id.equals(\"..\"), IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.length <= 255, IllegalCharacterInLogkafkaId)\n    checkCondition(rgx.findFirstIn(logkafka_id).isDefined, IllegalCharacterInLogkafkaId)\n  }", "CodeBleu_score": 39.217550119198094}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n    error\n    system.actorSelection(kafkaManagerActor).ask\n    ApiError.from\n    system.actorSelection(kafkaManagerActor).ask(msg).map\n    system.actorSelection\n    ApiError.fromThrowable\n\n", "CodeBleu_score": 75.13453842309457}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n    {\n      case t: Throwable =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 81.44267003075895}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n  }", "CodeBleu_score": 67.52508008250328}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t =>\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 63.7083622913788}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 74.89469154020098}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tsystem.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable =>\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.16095112221555}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\tval command = KMClusterCommandRequest(\n      clusterName,\n      KMClusterCommandRequest.RunPreferredLeaderElection(topics)\n    )\n    val result = ask(kafkaManagerActor, command)(clusterManagerActorTimeout).mapTo[KMClusterCommandResult]\n    result.map(_.result.disjunction).flatMap(Future.fromTry)\n  }", "CodeBleu_score": 24.520027465319856}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\tval command = KMClusterCommandRequest(clusterName, KMClusterCommandRequest.RunPreferredLeaderElection, topics)\n    kafkaManagerActor ? command map {\n      case result: KMClusterCommandResult =>\n        result.result.getOrElse(ApiError(s\"Unknown error while running preferred leader election for topics $topics on cluster $clusterName\"))\n      case result =>\n        ApiError(s\"Unknown error while running preferred leader election for topics $topics on cluster $clusterName : $result\")\n    }\n  }", "CodeBleu_score": 17.642556738389736}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\tval command = KMClusterCommandRequest(clusterName, KMClusterCommandRequest.RunPreferredLeaderElection, topics)\n    val result = ask(clusterManagerActor, command)(TimeoutDuration).mapTo[KMCommandResult]\n    result.map {\n      case result: KMClusterCommandResult => result.result.map(ClusterContext.from)\n      case _ => -\\/(ApiError(s\"Unknown error in Kafka Manager\"))\n    }\n  }", "CodeBleu_score": 21.39908748576473}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap {\n      case -\\/(error) => Future.successful(-\\/(error))\n      case \\/-(topics) => runPreferredLeaderElection(clusterName, topics.map(_.name))\n    }\n  }", "CodeBleu_score": 63.12509223449533}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap {\n      case -\\/(e) => Future.successful(-\\/(e))\n      case \\/-(t) => runPreferredLeaderElection(clusterName, t.list.toSet)\n    }\n  }", "CodeBleu_score": 65.15752581937973}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap { errorOrTopicList =>\n      errorOrTopicList.fold(\n        Future.successful,\n        runPreferredLeaderElection(clusterName, _.toSet)\n      )\n    }\n  }", "CodeBleu_score": 64.92496037237348}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\n  tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    ) { result: KMCommandResult =>\n      result.result.collect { case e: Errors[ApiError] => e.errors }\n    }.map {\n      case -\\/(e) => BadRequest(Json.obj(\"result\" -> s\"Error: ${e.msg}\"))\n      case \\/-(nel) =>\n        if(nel.isEmpty) Ok(Json.obj(\"result\" -> \"success\"))\n        else {\n          val errors = nel.map { error: ApiError =>\n            Json.obj(\n              \"message\" -> error.message,\n              \"errorCode\" -> error.errorCode\n            )\n          }\n          BadRequest(Json.obj(\"result\" -> \"failure\", \"errors\" -> errors))\n        }\n    }.recover {\n      case t: Throwable =>\n        error(s\"Failed to manualPartitionAssignments : $clusterName\", t)\n        InternalServerError(Json.obj(\"result\" -> s\"Error: ${t.getMessage}\"))\n    }\n}", "CodeBleu_score": 39.45160420925645}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\n  val result = tryWithKafkaManagerActor(\n      KMClusterCommandRequest (\n        clusterName,\n        CMManualPartitionAssignments(assignments)\n      )\n    )\n    result.map {\n      case -\\/(e) =>\n        val msg = s\"Failed to manually assign partitions for cluster $clusterName\"\n        error(msg, e)\n        throw e\n      case \\/-(akka.Done) =>\n        debug(s\"Successfully manually assigned partitions for cluster $clusterName\")\n    }\n  result\n}", "CodeBleu_score": 42.62335369389836}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\n  tryWithKafkaManagerActor(\n    KMClusterCommandRequest (\n      clusterName,\n      CMManualPartitionAssignments(assignments)\n    )\n  ) { result: Future[CMCommandResult] =>\n    result.map { cmr =>\n      if(cmr.result.isRight) {\n        \\/-(())\n      } else {\n        val result = cmr.result.swap.toOption.get\n        -\\/(ApiError(result.msg))\n      }\n    }\n  }.recover {\n    case e: Exception =>\n      error(s\"Failed to manualPartitionAssignments : $clusterName\", e)\n      -\\/(ApiError.fromThrowable(e))\n  }\n}", "CodeBleu_score": 41.90601887998386}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n    Collection<Node> nodes = describeClusterResult.nodes().get(10, TimeUnit.SECONDS);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"Could not retrieve Kafka broker configuration. No nodes found.\");\n    }\n    Node node = nodes.iterator().next();\n    ConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n    DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(resource));\n    Map<ConfigResource, Config> configs = describeConfigsResult.all().get(10, TimeUnit.SECONDS);\n    if (configs.isEmpty()) {\n        throw new ConnectException(\"Could not retrieve Kafka broker configuration. No configs found.\");\n    }\n    return configs.get(resource);\n}", "CodeBleu_score": 57.55221427995105}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\n        // Describe the cluster to get the available nodes\n        DescribeClusterResult describeClusterResult = admin.describeCluster();\n        Collection<Node> clusterNodes = describeClusterResult.nodes().get(30, TimeUnit.SECONDS);\n        if (clusterNodes.isEmpty()) {\n            throw new ConnectException(\"No cluster nodes found\");\n        }\n\n        // Select the first node's ID\n        Node node = clusterNodes.iterator().next();\n        int nodeId = node.id();\n\n        // Request the node's configuration\n        DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId.toString())));\n        Map<ConfigResource, Config> configs = describeConfigsResult.all().get(30, TimeUnit.SECONDS);\n        if (configs.isEmpty()) {\n            throw new ConnectException(\"No broker configuration found\");\n        }\n\n        // Return the broker's configuration\n        return configs.get(new ConfigResource(ConfigResource.Type.BROKER, nodeId.toString()));\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        throw new ConnectException(\"Failed to retrieve broker configuration\", e);\n    }\n}", "CodeBleu_score": 54.37428315107427}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\n        var cluster = admin.describeCluster();\n        var nodes = cluster.nodes().get(5, TimeUnit.SECONDS);\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found within 5 seconds.\");\n        }\n        var node = nodes.iterator().next();\n        var configs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString())));\n        var config = configs.values().get(5, TimeUnit.SECONDS);\n        if (config.isEmpty()) {\n            throw new ConnectException(\"No configs found for node \" + node.idString() + \" within 5 seconds.\");\n        }\n        return config.get(node);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        throw new ConnectException(\"Failed to retrieve Kafka broker config.\", e);\n    }\n}", "CodeBleu_score": 53.71233228688559}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n    @Override\n    public void validate(final String name, final Object value) {\n      if (KafkaSchemaHistory.isSchemaHistoryEnabled()) {\n        validator.validate(name, value);\n      }\n    }\n  };\n}", "CodeBleu_score": 21.55850358719836}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n        @Override\n        public void validate(final String name, final Object value) {\n            if (isKafkaSchemaHistory()) {\n                validator.validate(name, value);\n            }\n        }\n\n        @Override\n        public String toString() {\n            return validator.toString();\n        }\n    };\n}", "CodeBleu_score": 26.54994914255142}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n        @Override\n        public void validate(final String name, final Object value) {\n            if (isKafkaSchemaHistory(value)) {\n                validator.validate(name, value);\n            }\n        }\n\n        private boolean isKafkaSchemaHistory(final Object value) {\n            if (value instanceof String) {\n                return ((String) value).equals(\"KafkaSchemaHistory\");\n            }\n            return false;\n        }\n    };\n}", "CodeBleu_score": 20.07700276846905}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tif (kafkaConnectVersion == null) {\n        kafkaConnectVersion = parseVersion(getVersion());\n    }\n    if (topicCreationEnabled == null) {\n        topicCreationEnabled = getBoolean(config, TOPIC_CREATION_ENABLE_CONFIG, true);\n    }\n    return topicCreationEnabled && kafkaConnectVersion.compareTo(TOPIC_CREATION_ENABLE_MIN_VERSION) >= 0;\n}", "CodeBleu_score": 34.362252209900255}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tif (kafkaConnectVersion == null) {\n        kafkaConnectVersion = parseVersion(getVersion());\n        log.debug(\"Kafka Connect version: {}\", kafkaConnectVersion);\n    }\n    if (topicCreationEnabled == null) {\n        topicCreationEnabled = getBoolean(config, \"topic.creation.enable\", true);\n    }\n    return kafkaConnectVersion.compareTo(TOPIC_CREATION_ENABLE_MIN_VERSION) >= 0 && topicCreationEnabled;\n}", "CodeBleu_score": 40.23138754110269}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tif (kafkaConnectVersion == null) {\n            kafkaConnectVersion = parseVersion(getVersion());\n        }\n        if (topicCreationEnabled == null) {\n            topicCreationEnabled = getBoolean(config, \"topic.creation.enable\", true);\n        }\n        return kafkaConnectVersion.compareTo(TOPIC_CREATION_MIN_VERSION) >= 0 && topicCreationEnabled;\n    }", "CodeBleu_score": 40.57939655728069}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tObjects.requireNonNull(config, \"config cannot be null\");\n\n        final String clientId = config.get(CLIENT_ID_CONFIG);\n        if (clientId == null) {\n            throw new IllegalArgumentException(String.format(\"%s cannot be null\", CLIENT_ID_CONFIG));\n        }\n\n        final Map<String, Object> adminProps = new HashMap<>();\n        adminProps.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(BOOTSTRAP_SERVERS_CONFIG));\n        adminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n        final SharedTopicAdmin sharedAdmin = new SharedTopicAdmin(adminProps);\n\n        final KafkaOffsetBackingStore store = new KafkaOffsetBackingStore(sharedAdmin, clientId, converterForOffsetStore());\n\n        return store;\n    }", "CodeBleu_score": 46.86221929015233}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(KafkaConfig.CLIENT_ID_CONFIG);\n        if (clientId == null) {\n            throw new IllegalArgumentException(\"Client ID must be specified.\");\n        }\n\n        final Map<String, Object> adminConfig = new HashMap<>();\n        adminConfig.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaConfig.BOOTSTRAP_SERVERS_CONFIG));\n        adminConfig.put(AdminClientConfig.RETRIES_CONFIG, Integer.MAX_VALUE);\n        adminConfig.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n        final SharedTopicAdmin admin = new SharedTopicAdmin(adminConfig);\n\n        return new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n    }", "CodeBleu_score": 40.64252815797751}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tObjects.requireNonNull(config, \"config cannot be null\");\n        final String clientId = config.get(CLIENT_ID_CONFIG);\n        if (clientId == null || clientId.isEmpty()) {\n            throw new IllegalArgumentException(\"client.id cannot be null or empty\");\n        }\n\n        final Properties adminProps = new Properties();\n        adminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n        for (final Map.Entry<String, String> entry : config.entrySet()) {\n            final String key = entry.getKey();\n            if (key.startsWith(ADMIN_PREFIX)) {\n                final String newKey = key.substring(ADMIN_PREFIX.length());\n                adminProps.put(newKey, entry.getValue());\n            }\n        }\n\n        final String topic = config.get(TOPIC_CONFIG);\n        if (topic == null || topic.isEmpty()) {\n            throw new IllegalArgumentException(\"topic cannot be null or empty\");\n        }\n\n        final String groupId = config.get(GROUP_ID_CONFIG);\n        if (groupId == null || groupId.isEmpty()) {\n            throw new IllegalArgumentException(\"group.id cannot be null or empty\");\n        }\n\n        final String retentionMs = config.get(RETENTION_MS_CONFIG);\n        if (retentionMs == null || retentionMs.isEmpty()) {\n            throw new IllegalArgumentException(\"retention.ms cannot be null or empty\");\n        }\n\n        final String segmentIntervalMs = config.get(SEGMENT_INTERVAL_MS_CONFIG);\n        if (segmentIntervalMs == null || segmentIntervalMs.isEmpty()) {\n            throw new IllegalArgumentException(\"segment.interval.ms cannot be null or empty\");\n        }\n\n        final String keySerde = config.get(KEY_SERDE_CONFIG);\n        if (keySerde == null || keySerde.isEmpty()) {\n            throw new IllegalArgumentException(\"key.serde cannot be null or empty\");\n        }\n\n        final String valueSerde = config.get(VALUE_SERDE_CONFIG);\n        if (valueSerde == null || value", "CodeBleu_score": 30.683327599601274}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t// Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node, keyType);\n            }\n            else if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n                return reader.readValue(node.get(config.sourceField()), keyType);\n            }\n            // Extracted format\n            else {\n                return reader.readValue(node, keyType);\n            }\n        }", "CodeBleu_score": 26.54115165086104}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t// Schema + payload format\n            if (node.has(PAYLOAD_FIELD)) {\n                node = node.get(PAYLOAD_FIELD);\n            }\n            // Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node);\n            }\n            else if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n                node = node.get(config.sourceField());\n            }\n            // Extracted format\n            else {\n                node = node;\n            }\n\n            if (node.isObject()) {\n                if (node.size() == 1) {\n                    String keyFieldName = node.fieldNames().next();\n                    return reader.readValue(node.get(keyFieldName));\n                }\n                else {\n                    return reader.readValue(node);\n                }\n            }\n            else {\n                throw new IOException(\"Key is not a JSON object.\");\n            }\n        }", "CodeBleu_score": 46.09859375869324}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t// Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node);\n            }\n            else if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n                node = node.get(config.sourceField());\n            }\n            // Extracted format\n            else {\n                node = node.get(config.keyField());\n            }\n\n            // Check if it's a simple key or composite key\n            if (node.isObject()) {\n                // Check if it's a simple key\n                if (node.size() == 1) {\n                    String keyField = node.fieldNames().next();\n                    return reader.readValue(node.get(keyField));\n                }\n                // Check if it's a composite key\n                else {\n                    return reader.readValue(node);\n                }\n            }\n            else {\n                return reader.readValue(node);\n            }\n        }", "CodeBleu_score": 48.45999719830666}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tStringBuilder builder = new StringBuilder();\n    builder.append(prefix);\n    builder.append(delimiter);\n    builder.append(id.toString());\n    String topicName = builder.toString();\n    boolean changed = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (!isValidTopicNameCharacter(c)) {\n            changed = true;\n            topicName = topicName.substring(0, i) + replacementCharacter + topicName.substring(i + 1);\n        }\n    }\n    if (changed) {\n        warn(\"Invalid characters were replaced in topic name: \" + topicName);\n    }\n    return topicName;\n}", "CodeBleu_score": 50.86161986734028}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tStringBuilder topicName = new StringBuilder(prefix);\n    topicName.append(delimiter);\n    topicName.append(id);\n\n    boolean changed = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (!isValidTopicNameCharacter(c)) {\n            topicName.setCharAt(i, replacementCharacter);\n            changed = true;\n        }\n    }\n\n    if (changed) {\n        warn(\"Topic name \" + topicName.toString() + \" was sanitized to \" + topicName.toString());\n    }\n\n    return topicName.toString();\n}", "CodeBleu_score": 44.57336044736281}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = generateTopicName(id, prefix, delimiter);\n    StringBuilder sb = new StringBuilder();\n    boolean sanitized = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sb.append(c);\n        } else {\n            sb.append(replacementCharacter);\n            sanitized = true;\n        }\n    }\n    if (sanitized) {\n        warn(topicName, sb.toString());\n    }\n    return sanitized ? sb.toString() : topicName;\n}", "CodeBleu_score": 49.698700622228756}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = new AtomicReference<>();\n        this.maxRetries = connectorConfig.getLong(ConnectorConfig.ERRORS_RETRY_TIMEOUT_CONFIG) > 0\n                ? connectorConfig.getLong(ConnectorConfig.ERRORS_RETRY_TIMEOUT_CONFIG)\n                : -1;\n        if (replacedErrorHandler != null) {\n            this.retries = replacedErrorHandler.retries;\n        }\n    }", "CodeBleu_score": 59.10509513517118}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.producerThrowable = new AtomicReference<>();\n    if (connectorConfig.getInt(ConnectorConfig.ERRORS_RETRY_MAX_DELAY_CONFIG) != null) {\n        this.maxRetries = connectorConfig.getInt(ConnectorConfig.ERRORS_RETRY_MAX_DELAY_CONFIG);\n    } else if (connectorConfig.getInt(ConnectorConfig.ERRORS_RETRY_MAX_DELAY_CONFIG_DEPRECATED) != null) {\n        this.maxRetries = connectorConfig.getInt(ConnectorConfig.ERRORS_RETRY_MAX_DELAY_CONFIG_DEPRECATED);\n    } else {\n        this.maxRetries = -1;\n    }\n    if (replacedErrorHandler != null) {\n        this.retries = replacedErrorHandler.retries;\n    }\n}", "CodeBleu_score": 63.09583645226422}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowableRef = new AtomicReference<>();\n        this.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : 0;\n        this.maxRetries = connectorConfig.getInteger(ConnectorConfig.ERRORS_RETRY_MAX_DELAY_CONFIG);\n        if (maxRetries == null || maxRetries < 0) {\n            this.maxRetries = Integer.MAX_VALUE;\n        }\n    }", "CodeBleu_score": 53.79372270449826}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\n    for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n        if (!entry.getValue().errorMessages().isEmpty()) {\n            final ConfigValue value = entry.getValue();\n            throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n        }\n    }\n}", "CodeBleu_score": 88.50211733615095}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\n    for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n        if (!entry.getValue().errorMessages().isEmpty()) {\n            final ConfigValue value = entry.getValue();\n            throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n        }\n    }\n}", "CodeBleu_score": 88.50211733615095}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\n        for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n            if (!entry.getValue().errorMessages().isEmpty()) {\n                final ConfigValue value = entry.getValue();\n                throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n            }\n        }\n    }", "CodeBleu_score": 87.28369945783665}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        }\n        else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.67429454987865}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        }\n        else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.67429454987865}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        }\n        else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.67429454987865}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.getSchema().getField(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 32.68784528494099}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.getSchema().getField(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n    if (source.getSchema().getField(SNAPSHOT_KEY).schema().type() != Schema.Type.STRING) {\n        return null;\n    }\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 47.38099887244467}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tSchema schema = source.schema();\n    Field field = schema.field(SNAPSHOT_KEY);\n    if (field == null) {\n        return null;\n    }\n    if (field.schema().type() != Schema.Type.STRING) {\n        return null;\n    }\n    String snapshotString = (String) source.get(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 46.54268785014959}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\ttry {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOf(parts, 2);\n        }\n        String[] hyphenParts = parts[0].split(\"-\");\n        return Optional.of(Float.parseFloat(hyphenParts[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 66.86476927303997}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\tString[] parts = version.split(\"\\\\.\");\n    String[] parts2 = parts[0].split(\"-\");\n    return Optional.of(Float.parseFloat(parts2[0]));\n}", "CodeBleu_score": 37.36028405497738}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\ttry {\n        return Optional.of(Float.parseFloat(version.split(\"\\\\.\")[0].split(\"-\")[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 36.4799677366625}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.58555586174032}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.58555586174032}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.58555586174032}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.85009720428593}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.85009720428593}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.85009720428593}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tConnectAction[] connectActions;\n  if (RESTART_ACTIONS.contains(action)) {\n    connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n  } else {\n    connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n  }\n\n  var context = AccessContext.builder()\n      .cluster(clusterName)\n      .connect(connectName)\n      .connectActions(connectActions)\n      .operationName(\"updateConnectorState\")\n      .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n      .build();\n\n  return validateAccess(context).then(\n      kafkaConnectService\n          .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n          .map(ResponseEntity::ok)\n  ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 99.30137884843364}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tConnectAction[] connectActions;\n    if (RESTART_ACTIONS.contains(action)) {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n    } else {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n    }\n\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(connectActions)\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService\n            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 98.10392800143781}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t// 1. \n    ConnectAction[] connectActions;\n    if (RESTART_ACTIONS.contains(action)) {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n    } else {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n    }\n\n    // 2. \n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(connectActions)\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\n    // 3. \n    return validateAccess(context).then(\n        kafkaConnectService\n            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 98.014339310042}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t@Override\n    public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(String clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody, ServerWebExchange exchange) {\n        return kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody).map(ResponseEntity::ok);\n    }\n}", "CodeBleu_score": 77.66550987633674}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\treturn kafkaConnectService\n        .validateConnectorPluginConfig(\n            getCluster(clusterName), connectName, pluginName, requestBody)\n        .map(ResponseEntity::ok);\n  }", "CodeBleu_score": 46.08786320395695}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tString clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody,\n  ServerWebExchange exchange\n}", "CodeBleu_score": 42.751843875316375}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.properties(\"spring.config.name:kafka-ui-application\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.yml\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.properties\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.yaml\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.json\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.yml\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.properties\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.yaml\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.json\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.conf\")\n\t\t\t.properties(\"spring.config.additional-location:/etc/kafka-ui/application.hocon\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.conf\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.hocon\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.conf\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.hocon\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.conf\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.hocon\")\n\t\t\t.properties(\"spring.config.additional-location:${HOME}/.kafka-ui/application.conf\")\n\t\t\t.properties", "CodeBleu_score": 25.65023079351436}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n        .initializers(dynamicConfigPropertiesInitializer())\n        .run(args);\n}", "CodeBleu_score": 43.293697626194536}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n            .initializers(new DynamicConfigPropertiesInitializer())\n            .run(args);\n}", "CodeBleu_score": 43.88170984150765}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\n        return x -> true;\n    }\n    return x -> getStringsForSearch(x).anyMatch(s -> containsIgnoreCase(s, search));\n}", "CodeBleu_score": 61.184094675847554}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\n        return (connector) -> true;\n    }\n\n    final String searchTerm = search.toLowerCase();\n    return connector -> getStringsForSearch(connector)\n        .anyMatch(string -> string.toLowerCase().contains(searchTerm));\n}", "CodeBleu_score": 58.95513338911551}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn search == null ? connector -> true : connector -> getStringsForSearch(connector).anyMatch(string -> containsIgnoreCase(string, search));\n}", "CodeBleu_score": 46.54274762369427}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tMap<String, Object> flattenedMap = new HashMap<>();\n\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newKey = prefix != null ? prefix + \".\" + key : key;\n\n        if (value instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n        } else {\n          flattenedMap.put(newKey, value);\n        }\n      }\n    }\n\n    return flattenedMap;\n  }", "CodeBleu_score": 53.69796576644064}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tMap<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedMap;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 50.28327919014751}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\tMap<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        if (prefix != null) {\n          key = prefix + \".\" + key;\n        }\n        Object value = entry.getValue();\n        if (value instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n        } else {\n          flattenedMap.put(key, value);\n        }\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 53.617571523287836}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\tConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys().values().stream()\n        .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n        .map(configKey -> configKey.name)\n        .collect(Collectors.toSet());\n}", "CodeBleu_score": 65.43823760329653}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\tConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys()\n        .values()\n        .stream()\n        .filter(configKey -> configKey.type() == ConfigDef.Type.PASSWORD)\n        .map(configKey -> configKey.name)\n        .collect(Collectors.toSet());\n}", "CodeBleu_score": 65.4982820871391}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\tConfigDef configDef = new ConfigDef();\n    configDef.addClientSslSupport();\n    configDef.addClientSaslSupport();\n    return configDef.configKeys()\n            .values()\n            .stream()\n            .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n            .map(configKey -> configKey.name)\n            .collect(Collectors.toSet());\n}", "CodeBleu_score": 63.017992134002164}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn aclViewEnabled(adminClient).flatMap(enabled -> {\n        if (enabled) {\n            return just(clusterDescription.getAuthorizedOperations()).filter(operations ->\n                operations.contains(ReactiveAdminClient.AclOperation.ALTER) ||\n                operations.contains(ReactiveAdminClient.AclOperation.ALL)\n            ).map(operations -> ClusterFeature.KAFKA_ACL_EDIT);\n        }\n        return empty();\n    });\n}", "CodeBleu_score": 30.079680495954054}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn aclViewEnabled(adminClient)\n        .filter(enabled -> enabled)\n        .flatMap(enabled -> getAuthorizedOperations(adminClient, clusterDescription))\n        .filter(operations -> operations.contains(AclOperation.ALTER) || operations.contains(AclOperation.ALL))\n        .map(operations -> ClusterFeature.KAFKA_ACL_EDIT)\n        .switchIfEmpty(Mono.empty());\n  }", "CodeBleu_score": 37.55052682532764}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn aclViewEnabled(adminClient).flatMap(aclViewEnabled -> {\n      if (!aclViewEnabled) {\n        return Mono.empty();\n      }\n      return getAuthorizedOperations(clusterDescription).map(authorizedOperations -> {\n        if (authorizedOperations.contains(ACL_OPERATION_ALL) || authorizedOperations.contains(ACL_OPERATION_ALTER)) {\n          return ClusterFeature.KAFKA_ACL_EDIT;\n        } else {\n          return null;\n        }\n      });\n    });\n  }", "CodeBleu_score": 27.434238329441037}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> newRange = new TreeMap<>();\n  for (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n    TopicPartition topicPartition = entry.getKey();\n    FromToOffset fromToOffset = entry.getValue();\n    long startOffset = fromToOffset.fromOffset;\n    long endOffset = fromToOffset.toOffset;\n    long numMessagesToPoll = endOffset - startOffset;\n    if (numMessagesToPoll > 0) {\n      startOffset = seekOperations.getBeginOffsets().getOrDefault(topicPartition, startOffset);\n      endOffset = Math.max(startOffset, endOffset - numMessagesToPoll);\n      newRange.put(topicPartition, new FromToOffset(startOffset, endOffset));\n    }\n  }\n  return newRange;\n}", "CodeBleu_score": 32.906178042842086}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n    for (TopicPartition topicPartition : prevRange.keySet()) {\n        FromToOffset fromToOffset = prevRange.get(topicPartition);\n        // If the previous range is empty, initialize the range to read from the beginning of the partition.\n        if (fromToOffset.fromOffset == null) {\n            fromToOffset = new FromToOffset(seekOperations.getBeginOffsets().get(topicPartition),\n                                            seekOperations.getEndOffsets().get(topicPartition));\n        }\n        // Calculate the number of messages to poll.\n        int numMessagesToPoll = Math.min(fromToOffset.toOffset - fromToOffset.fromOffset,\n                                         maxMessagesPerPoll);\n        // Determine the start offset and adjust it based on the number of messages to poll, ensuring it does not go below the beginning offset.\n        long startOffset = Math.max(fromToOffset.fromOffset,\n                                    fromToOffset.toOffset - numMessagesToPoll);\n        nextRange.put(topicPartition,\n                      new FromToOffset(startOffset,\n                                       fromToOffset.toOffset));\n    }\n    return nextRange;\n}", "CodeBleu_score": 33.8077416484503}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n    if (prevRange.isEmpty()) {\n        // initialize the offsets to read from based on the seek operations\n        seekOperations.forEach((tp, offset) -> {\n            long fromOffset = offset;\n            long toOffset = offset + maxMessagesPerPoll;\n            nextRange.put(tp, new FromToOffset(fromOffset, toOffset));\n        });\n    } else {\n        // initialize the offsets to read from based on the previous range\n        prevRange.forEach((tp, fromToOffset) -> {\n            long fromOffset = fromToOffset.getToOffset();\n            long toOffset = fromOffset + maxMessagesPerPoll;\n            nextRange.put(tp, new FromToOffset(fromOffset, toOffset));\n        });\n    }\n\n    // adjust the start offset for each partition based on the number of messages to poll\n    nextRange.forEach((tp, fromToOffset) -> {\n        long fromOffset = fromToOffset.getFromOffset();\n        long toOffset = fromToOffset.getToOffset();\n        long beginningOffset = getBeginOffsets().get(tp);\n        if (toOffset - fromOffset > maxMessagesPerPoll) {\n            toOffset = fromOffset + maxMessagesPerPoll;\n        } else if (toOffset < beginningOffset) {\n            toOffset = ceil(beginningOffset, maxMessagesPerPoll);\n        }\n        nextRange.put(tp, new FromToOffset(fromOffset, toOffset));\n    });\n\n    return nextRange;\n}", "CodeBleu_score": 37.94541583727761}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\n            if (isNullOrEmpty(configuration.getString(CK_ZOOKEEPER))) {\n                throw new IllegalArgumentException(\"ZooKeeper must be set when using legacy mode.\");\n            }\n            if (isNullOrEmpty(configuration.getString(CK_TOPIC_FILTER))) {\n                throw new IllegalArgumentException(\"Topic filter must be set when using legacy mode.\");\n            }\n            doLaunchLegacy(input);\n        } else {\n            if (isNullOrEmpty(configuration.getString(CK_BOOTSTRAP))) {\n                throw new IllegalArgumentException(\"Bootstrap servers must be set when not using legacy mode.\");\n            }\n            doLaunchConsumer(input);\n        }\n\n        // wait for the server to be running\n        awaitRunning(10, TimeUnit.SECONDS);\n\n        // register for server lifecycle events\n        eventBus.register(this);\n\n        // schedule a task to update the last second bytes read every second\n        executor.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                lastSecBytesRead = lastSecBytesReadTmp.getAndSet(0);\n            }\n        }, 1, 1, TimeUnit.SECONDS);\n    }", "CodeBleu_score": 45.91363924012927}, {"code": "public void doLaunch(final MessageInput input){\n\tfinal boolean legacy = configuration.getBoolean(CK_LEGACY, DEFAULT_LEGACY);\n\n    if (legacy) {\n        if (!configuration.isNullOrEmpty(CK_BOOTSTRAP)) {\n            throw new IllegalArgumentException(\n                    \"Configuration '\" + CK_BOOTSTRAP + \"' is only valid in non-legacy mode.\");\n        }\n        if (configuration.isNullOrEmpty(CK_ZOOKEEPER)) {\n            throw new IllegalArgumentException(\n                    \"Configuration '\" + CK_ZOOKEEPER + \"' is required in legacy mode.\");\n        }\n    } else {\n        if (configuration.isNullOrEmpty(CK_BOOTSTRAP)) {\n            throw new IllegalArgumentException(\n                    \"Configuration '\" + CK_BOOTSTRAP + \"' is required in non-legacy mode.\");\n        }\n        if (!configuration.isNullOrEmpty(CK_ZOOKEEPER)) {\n            throw new IllegalArgumentException(\n                    \"Configuration '\" + CK_ZOOKEEPER + \"' is only valid in legacy mode.\");\n        }\n    }\n\n    LOG.info(\"Launching Kafka input in {} mode.\", legacy ? \"legacy\" : \"non-legacy\");\n\n    awaitRunning();\n    register();\n\n    if (legacy) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n\n    // schedule a task to update the last second bytes read every second\n    executor.scheduleAtFixedRate(\n            new Runnable() {\n                @Override\n                public void run() {\n                    lastSecBytesRead = lastSecBytesReadTmp.getAndSet(0);\n                }\n            },\n            1,\n            1,\n            TimeUnit.SECONDS);\n}", "CodeBleu_score": 43.18881557328359}, {"code": "public void doLaunch(final MessageInput input){\n\tfinal boolean legacy = configuration.getBoolean(CK_LEGACY, false);\n        final boolean useKafka = configuration.getBoolean(CK_USE_KAFKA, false);\n\n        if (legacy && useKafka) {\n            throw new IllegalArgumentException(\"Cannot use legacy mode and new Kafka mode at the same time.\");\n        }\n\n        if (legacy) {\n            doLaunchLegacy(input);\n        } else {\n            doLaunchConsumer(input);\n        }\n\n        // wait for the server to be running\n        awaitRunning();\n\n        // register for lifecycle events\n        lifecycle.register(this);\n\n        // schedule a task to update the last second bytes read every second\n        executor.scheduleAtFixedRate(new Runnable() {\n            @Override\n            public void run() {\n                lastSecBytesRead = lastSecBytesReadTmp.getAndSet(0);\n            }\n        }, 1, 1, TimeUnit.SECONDS);\n    }", "CodeBleu_score": 47.99370763630948}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\tString customProperties = getString(\"customProperties\");\n    if (customProperties != null) {\n        try {\n            Properties customProps = new Properties();\n            customProps.load(new StringReader(customProperties));\n            props.putAll(customProps);\n        } catch (IOException e) {\n            error(\"Unable to load custom properties: \" + e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 45.366061672947325}, {"code": "private void insertCustomProperties(Properties props){\n\ttry {\n        Properties customProps = load(new StringReader(customProperties));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        log.error(\"Failed to load custom properties: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 39.423828982062}, {"code": "private void insertCustomProperties(Properties props){\n\tString customProps = getCustomProperties();\n    if (customProps != null) {\n        try {\n            Properties customPropsObj = new Properties();\n            customPropsObj.load(new StringReader(customProps));\n            props.putAll(customPropsObj);\n        } catch (IOException e) {\n            log.error(\"Failed to load custom properties\", e);\n        }\n    }\n}", "CodeBleu_score": 46.49562819897686}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tfinal List<Journal.Entry> journalEntries = entries.stream()\n            .filter(Objects::nonNull)\n            .map(entry -> new Journal.Entry(entry.getEncodedRawMessage(), entry.getId()))\n            .collect(Collectors.toList());\n\n    final int messageBytes = journalEntries.stream()\n            .mapToInt(entry -> entry.getMessage().length)\n            .sum();\n\n    final int retryCount = 5;\n    final int retryDelayMillis = 100;\n\n    try {\n        for (int i = 0; i < retryCount; i++) {\n            try {\n                writeToJournal(journalEntries);\n                writtenMessages.addAndGet(journalEntries.size());\n                writtenBytes.addAndGet(messageBytes);\n                return;\n            } catch (Exception e) {\n                LOG.error(\"Failed to write to journal, retrying in {} ms.\", retryDelayMillis, e);\n                Thread.sleep(retryDelayMillis);\n            }\n        }\n    } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new MessageQueueException(\"Interrupted while writing to journal\", e);\n    }\n\n    throw new MessageQueueException(\"Failed to write to journal after \" + retryCount + \" retries\");\n}", "CodeBleu_score": 55.560740190284875}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tfinal List<Journal.Entry> journalEntries = entries.stream()\n            .filter(Objects::nonNull)\n            .map(this::toJournalEntry)\n            .collect(Collectors.toList());\n\n    final int totalMessageBytes = journalEntries.stream()\n            .mapToInt(Journal.Entry::getDataSize)\n            .sum();\n\n    final int retries = 5;\n    final long initialBackOff = 100;\n\n    int currentTry = 0;\n    while (currentTry < retries) {\n        try {\n            writeToJournal(journalEntries);\n            writtenMessages.inc(journalEntries.size());\n            writtenBytes.inc(totalMessageBytes);\n            return;\n        } catch (JournalException e) {\n            LOG.error(\"Failed to write to journal, retrying.\", e);\n            currentTry++;\n            try {\n                Thread.sleep(initialBackOff * currentTry);\n            } catch (InterruptedException e1) {\n                LOG.error(\"Thread interrupted while waiting for retry.\", e1);\n                Thread.currentThread().interrupt();\n            }\n        }\n    }\n\n    throw new MessageQueueException(\"Failed to write to journal after \" + retries + \" retries.\");\n}", "CodeBleu_score": 48.3618441251138}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tif (entries.isEmpty()) {\n            return;\n        }\n\n        // Filter out null entries\n        entries = entries.stream()\n                .filter(Objects::nonNull)\n                .collect(Collectors.toList());\n\n        // Map entries to journal entries while calculating total message bytes\n        final List<Journal.Entry> journalEntries = entries.stream()\n                .map(this::toJournalEntry)\n                .collect(Collectors.toList());\n\n        // Attempt to write to journal with exponential back-off\n        final int retries = 10;\n        final int initialDelay = 100;\n        for (int i = 0; i < retries; i++) {\n            try {\n                final long lastOffset = kafkaJournal.write(journalEntries);\n                LOG.debug(\"Processed batch, last journal offset: {}, signalling reader.\", lastOffset);\n                journalFilled.release();\n                break;\n            } catch (JournalException e) {\n                LOG.error(\"Failed to write to journal, retrying\", e);\n                try {\n                    Thread.sleep(initialDelay << i);\n                } catch (InterruptedException e1) {\n                    LOG.error(\"Interrupted while sleeping\", e1);\n                    Thread.currentThread().interrupt();\n                    throw new MessageQueueException(e1);\n                }\n            }\n        }\n\n        // Update metrics\n        writtenMessages.addAndGet(entries.size());\n        writtenBytes.addAndGet(entries.stream()\n                .mapToLong(RawMessageEvent::getEncodedRawMessage)\n                .sum());\n    }", "CodeBleu_score": 39.90135583972457}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\tif (messages != null && messages.size() > 0) {\n        Message message = messages.stream().max(Comparator.comparing(Message::getQueueId)).get();\n        if (message != null) {\n            message.acknowledge();\n            metrics.mark(messages.size());\n        }\n    }\n}", "CodeBleu_score": 36.429664261159836}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages.isEmpty()) {\n        return;\n    }\n    // find the max valid message queue ID\n    OptionalInt maxValidMessageQueueId = messages.stream()\n        .filter(message -> message.getQueueId() != null)\n        .map(Message::getQueueId)\n        .max(Integer::compareTo);\n\n    // acknowledge the message if present\n    maxValidMessageQueueId.ifPresent(messageQueueId -> {\n        try {\n            channel.basicAck(messageQueueId, true);\n        } catch (IOException e) {\n            log.error(\"Could not acknowledge message queue ID {}\", messageQueueId, e);\n        }\n    });\n\n    // update metrics\n    metrics.mark(messages.size());\n}", "CodeBleu_score": 47.045260338937716}, {"code": "public void acknowledge(List<Message> messages){\n\tif (messages.isEmpty()) {\n        return;\n    }\n\n    // Find the maximum valid message queue ID\n    long max = messages.stream()\n        .map(Message::getQueueId)\n        .filter(id -> id >= 0)\n        .max(Long::compareTo)\n        .orElse(-1L);\n\n    // Acknowledge the message if present\n    if (max >= 0) {\n        consumer.acknowledge(consumer.receivedMessages(max));\n    }\n\n    // Update the metrics\n    metrics.mark(messages.size());\n}", "CodeBleu_score": 48.89469687520459}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\tfinal MetricRegistry registry = MetricRegistry.getInstance();\n    final String prefix = this.getClass().getName() + \".\";\n    for (final Map.Entry<String, Metric> entry : registry.getMetrics().entrySet()) {\n        final String name = entry.getKey();\n        if (name.startsWith(prefix)) {\n            final String legacyName = name.replace(prefix, \"\");\n            try {\n                registry.register(legacyName, entry.getValue());\n            } catch (final IllegalArgumentException e) {\n                this.warn(\"Failed to register legacy metric: \" + name + \" as \" + legacyName, e);\n            }\n        }\n    }\n}", "CodeBleu_score": 40.18358982449053}, {"code": "private void registerLegacyMetrics(){\n\tfinal MetricRegistry registry = this.getMetricRegistry();\n    if (registry != null) {\n        registry.getMetrics().keySet().stream().filter(this::startsWith).forEach(this::register);\n    }\n}", "CodeBleu_score": 12.747707608425296}, {"code": "private void registerLegacyMetrics(){\n\tfinal MetricRegistry registry = LocalKafkaJournal.this.getMetricRegistry();\n    final String prefix = LocalKafkaJournal.class.getName() + \".\";\n    final Set<String> names = registry.getNames();\n    for (final String name : names) {\n        if (name.startsWith(prefix)) {\n            final String legacyName = name.substring(prefix.length());\n            try {\n                registry.register(legacyName, registry.getMetrics().get(name));\n            } catch (final IllegalArgumentException e) {\n                LOG.warn(\"Failed to register legacy metric: \" + name + \" -> \" + legacyName, e);\n            }\n        }\n    }\n}", "CodeBleu_score": 41.1170795351232}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\ttry {\n    return metricRegistry.timer(metricName);\n  } catch (IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 20.40619448908669}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\ttry {\n        return metricRegistry.register(metricName, new Timer(new HdrReservoir()));\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.timer(metricName);\n    }\n}", "CodeBleu_score": 22.69490189606242}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\ttry {\n        return metricRegistry.register(metricName, new Timer());\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.timer(metricName);\n    }\n}", "CodeBleu_score": 21.55078160409567}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\tfinal Gauge<Long> gauge = () -> {\n            if (size() == 0) {\n                return 0L;\n            }\n            if (committedOffset == 0) {\n                return getLogEndOffset() - getLogStartOffset();\n            }\n            return getLogEndOffset() - committedOffset;\n        };\n        try {\n            metricRegistry.register(name, gauge);\n        } catch (IllegalArgumentException ignored) {\n        }\n    }", "CodeBleu_score": 61.330276566368546}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(MetricRegistry.name(name, \"uncommitted\"), new Gauge<Long>() {\n                @Override\n                public Long getValue() {\n                    long size = size();\n                    if (size == 0) {\n                        return 0L;\n                    }\n                    long committedOffset = getCommittedOffset();\n                    if (committedOffset == -1) {\n                        return getLogEndOffset() - getLogStartOffset();\n                    }\n                    return getLogEndOffset() - committedOffset;\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // Ignore\n        }\n    }", "CodeBleu_score": 52.31606118912102}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(name, (Gauge<Long>) () -> {\n                final long size = kafkaLog.size();\n                if (size == 0) {\n                    return 0L;\n                }\n                final long logStartOffset = getLogStartOffset();\n                final long logEndOffset = getLogEndOffset();\n                final long committedOffset = getCommittedOffset();\n                if (committedOffset == -1L) {\n                    return logEndOffset - logStartOffset;\n                }\n                return logEndOffset - committedOffset;\n            });\n        } catch (IllegalArgumentException e) {\n            // Ignore\n        }\n    }", "CodeBleu_score": 54.74696949128776}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n            logger.debug(\"No messages to flush for partition {}\", partition);\n            return lastOffset;\n        }\n\n        MessageSet messageSet = new ByteBufferMessageSet(NoCompressionCodec.instance, messages);\n        logger.debug(\"Flushing {} messages for partition {}\", messageSet.sizeInBytes(), partition);\n\n        long lastOffset = kafkaLog.append(messageSet);\n        logger.debug(\"Flushed {} messages for partition {}\", messageSet.sizeInBytes(), partition);\n\n        markMessages(messages.size());\n\n        return lastOffset;\n    }", "CodeBleu_score": 38.84667638075542}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n        logger.debug(\"Skipping empty message set\");\n        return lastOffset;\n    }\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(NoCompressionCodec.instance, messages);\n    logger.debug(\"Writing \" + messages.size() + \" messages of size \" + payloadSize + \" to log \" + kafkaLog.name() + \" at offset \" + lastOffset);\n    long offset = kafkaLog.append(messageSet, assignOffsets = true);\n    logger.debug(\"Completed writing \" + messages.size() + \" messages of size \" + payloadSize + \" to log \" + kafkaLog.name() + \" at offset \" + lastOffset);\n    return offset;\n}", "CodeBleu_score": 39.34946868442438}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\n        logger.debug(\"Skipping empty message set\");\n        return lastOffset;\n    }\n\n    // log the messages\n    ByteBufferMessageSet messageSet = new ByteBufferMessageSet(NoCompressionCodec.instance, messages);\n    logger.debug(\"Writing \" + messages.size() + \" messages to log \" + logName + \" of size \" + messageSet.sizeInBytes());\n\n    // append the messages\n    long offset = kafkaLog.append(messageSet, false).lastOffset;\n\n    // update stats\n    this.lastOffset = offset;\n    this.numMessages += messages.size();\n    this.numBytes += payloadSize;\n\n    // log the offset of the last written message\n    logger.debug(\"Wrote \" + messages.size() + \" messages to log \" + logName + \" with last offset \" + lastOffset);\n\n    return lastOffset;\n}", "CodeBleu_score": 43.33670073552079}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u83b7\u53d6\u9501\n        lock.lock();\n        try {\n            // \u83b7\u53d6\u6307\u5b9a\u96c6\u7fa4\u7684\u5ba2\u6237\u7aef\u5217\u8868\n            List<AdminClient> adminClientList = adminClientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"start close kafka AdminClient, clusterId:{}\", clusterPhyId);\n            // \u5173\u95ed\u5ba2\u6237\u7aef\n            boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterId:{}\", clusterPhyId);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterId:{}\", clusterPhyId, e);\n        } finally {\n            // \u91ca\u653e\u9501\n            lock.unlock();\n        }\n    }", "CodeBleu_score": 73.07304094493783}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9amap\n    lock.lock();\n    try {\n        // \u83b7\u53d6kafkaAdminClientMap\n        List<AdminClient> adminClientList = kafkaAdminClientMap.get(clusterPhyId);\n        if (adminClientList == null) {\n            return;\n        }\n\n        LOGGER.info(\"start close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n        boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n        if (allSuccess) {\n            LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n        }\n    } finally {\n        // \u89e3\u9501\n        lock.unlock();\n    }\n}", "CodeBleu_score": 66.01967378410923}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9amap\n    lock.lock();\n    try {\n        // \u83b7\u53d6kafkaAdminClientList\n        List<AdminClient> kafkaAdminClientList = kafkaAdminClientMap.get(clusterPhyId);\n        if (kafkaAdminClientList == null) {\n            return;\n        }\n\n        LOGGER.info(\"start to close kafka admin client, clusterPhyId:{}\", clusterPhyId);\n        // \u5173\u95edkafkaAdminClientList\n        boolean allSuccess = closeAdminClientList(clusterPhyId, kafkaAdminClientList);\n        if (allSuccess) {\n            LOGGER.info(\"close kafka admin client success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            LOGGER.error(\"close kafka admin client failed, clusterPhyId:{}\", clusterPhyId);\n        }\n    } catch (Exception e) {\n        LOGGER.error(\"close kafka admin client exist failed, clusterPhyId:{}\", clusterPhyId, e);\n    } finally {\n        // \u89e3\u9501\n        lock.unlock();\n    }\n}", "CodeBleu_score": 73.32954808887985}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tif (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            success = false;\n            log.error(\"Failed to close AdminClient for cluster ID {}\", clusterPhyId, e);\n        }\n    }\n    return success;\n}", "CodeBleu_score": 73.03288303268502}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tif (adminClientList == null) {\n        return true;\n    }\n\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOG.error(\"Could not close AdminClient for cluster ID {}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 82.79184101581616}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tboolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(30, TimeUnit.SECONDS);\n        } catch (Exception e) {\n            LOG.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 69.81634848851297}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.80760094260697}, {"code": "public void stop() {\n\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.80760094260697}, {"code": "public void stop() {\n\tif (app != null) {\n\t\t\tapp.stop();\n\t\t\tint attempts = 5;\n\t\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\t\tattempts = attempts - 1;\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException e) {\n\t\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tapp = null;\n\t\t}\n\t}", "CodeBleu_score": 93.77787567660884}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config)\n    eurekaServerRunner.enableTls()\n    eurekaServerRunner.setKeyStore(keyStorePath, keyStorePassword)\n    eurekaServerRunner.setTrustStore(trustStorePath, trustStorePassword)\n    eurekaServerRunner.start()\n    return eurekaServerRunner\n}", "CodeBleu_score": 33.19267205103201}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner eurekaServer = new EurekaServerRunner(config);\n    eurekaServer.enableTls();\n    eurekaServer.setKeyStore(keyStoreFile, keyStorePassword, keyStoreType);\n    eurekaServer.setTrustStore(trustStoreFile, trustStorePassword, trustStoreType);\n    eurekaServer.start();\n    return eurekaServer;\n}", "CodeBleu_score": 44.08450691335858}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\tEurekaServerRunner server = new EurekaServerRunner(config);\n    server.enableTls();\n    server.setKeyStore(keyStoreFile, keyStorePassword);\n    server.setTrustStore(trustStoreFile, trustStorePassword);\n    server.start();\n    return server;\n}", "CodeBleu_score": 55.51800427705395}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.32744437288231}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.32744437288231}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.32744437288231}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\tKeyTool caKeyTool = createCA();\n\t\tKeyAndCert caCert = caKeyTool.createCertificate(CA_SUBJECT, CA_SUBJECT, null);\n\t\tFile caCertFile = saveCert(caCert);\n\t\tFile caKeyAndCertFile = saveKeyAndCert(caCert);\n\n\t\tKeyTool serverKeyTool = caKeyTool.createKey();\n\t\tKeyAndCert serverCert = serverKeyTool.createCertificate(SERVER_SUBJECT, SERVER_SUBJECT, caCert);\n\t\tFile serverCertFile = saveCert(serverCert);\n\t\tFile serverKeyAndCertFile = saveKeyAndCert(serverCert);\n\n\t\tKeyTool clientKeyTool = caKeyTool.createKey();\n\t\tKeyAndCert clientCert = clientKeyTool.createCertificate(CLIENT_SUBJECT, CLIENT_SUBJECT, caCert);\n\t\tFile clientCertFile = saveCert(clientCert);\n\t\tFile clientKeyAndCertFile = saveKeyAndCert(clientCert);\n\n\t\tKeyTool ca2KeyTool = createCA();\n\t\tKeyAndCert ca2Cert = ca2KeyTool.createCertificate(CA2_SUBJECT, CA2_SUBJECT, null);\n\t\tFile ca2CertFile = saveCert(ca2Cert);\n\t\tFile ca2KeyAndCertFile = saveKeyAndCert(ca2Cert);\n\n\t\tKeyTool client2KeyTool = ca2KeyTool.createKey();\n\t\tKeyAndCert client2Cert = client2KeyTool.createCertificate(CLIENT2_SUBJECT, CLIENT2_SUBJECT, ca2Cert);\n\t\tFile client2CertFile = saveCert(client2Cert);\n\t\tFile client2KeyAndCertFile = saveKeyAndCert(client2Cert);\n\n\t\tSystem.out.println(\"CA certificate: \" + caCertFile);\n\t\tSystem.out.println(\"CA key and certificate: \" + caKeyAndCertFile);\n\t\tSystem.out.println(\"Server certificate: \" + serverCertFile);\n\t\tSystem.out.println(\"Server key and certificate: \" + serverKeyAndCertFile);\n\t\tSystem.out.println(\"Client certificate: \" + clientCertFile);\n\t\tSystem.", "CodeBleu_score": 27.802870043161793}, {"code": "static void createCertificates() throws Exception{\n\tKeyAndCert ca = KeyAndCert.createCA();\n\t\tFile caCertFile = saveCert(ca);\n\n\t\tKeyAndCert server = KeyAndCert.createServer(ca);\n\t\tFile serverKeyFile = saveKeyAndCert(server);\n\n\t\tKeyAndCert client = KeyAndCert.createClient(ca);\n\t\tFile clientKeyFile = saveKeyAndCert(client);\n\n\t\tKeyAndCert otherCa = KeyAndCert.createCA();\n\t\tFile otherCaCertFile = saveCert(otherCa);\n\n\t\tKeyAndCert otherClient = KeyAndCert.createClient(otherCa);\n\t\tFile otherClientKeyFile = saveKeyAndCert(otherClient);\n\t}", "CodeBleu_score": 32.12387287317587}, {"code": "static void createCertificates() throws Exception{\n\tKeyTool ca1 = KeyTool.createSelfSignedCA(\"ca1\", \"changeit\", \"changeit\");\n\t\tKeyAndCert ca1Cert = ca1.createCertificate(\"ca1\", \"changeit\", \"changeit\");\n\t\tsaveCert(ca1Cert);\n\t\tsaveKeyAndCert(ca1Cert);\n\n\t\tKeyAndCert server = ca1.createCertificate(\"server\", \"changeit\", \"changeit\");\n\t\tsaveCert(server);\n\t\tsaveKeyAndCert(server);\n\n\t\tKeyAndCert client = ca1.createCertificate(\"client\", \"changeit\", \"changeit\");\n\t\tsaveCert(client);\n\t\tsaveKeyAndCert(client);\n\n\t\tKeyTool ca2 = KeyTool.createSelfSignedCA(\"ca2\", \"changeit\", \"changeit\");\n\t\tKeyAndCert ca2Cert = ca2.createCertificate(\"ca2\", \"changeit\", \"changeit\");\n\t\tsaveCert(ca2Cert);\n\t\tsaveKeyAndCert(ca2Cert);\n\n\t\tKeyAndCert client2 = ca2.createCertificate(\"client2\", \"changeit\", \"changeit\");\n\t\tsaveCert(client2);\n\t\tsaveKeyAndCert(client2);\n\t}", "CodeBleu_score": 29.187603396718714}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tlong timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        yield();\n    }\n    throw new RuntimeException(\"Assertion failed\");\n}", "CodeBleu_score": 45.65386094495521}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tlong timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (System.currentTimeMillis() < timeLimit) {\n        try {\n            if (assertion.getAsBoolean()) {\n                return;\n            }\n        } catch (Exception e) {\n            // Ignore.\n        }\n        Thread.yield();\n    }\n    throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 44.28357582210246}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\tlong timeLimit = System.currentTimeMillis() + (seconds * 1000);\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        Thread.yield();\n    }\n    throw new RuntimeException(\"Assertion failed\");\n}", "CodeBleu_score": 49.288497985747846}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.15\"), true, new JcaX509ExtensionUtils().createAuthorityKeyIdentifier(keyPair.getPublic()));\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.19\"), true, new BasicConstraints(true));\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.17\"), true, new ASN1Enumerated(KeyUsage.digitalSignature));\n\t\treturn signCert(builder, getPrivate(keyPair));\n\t}", "CodeBleu_score": 61.391136050117254}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.15\"), true, new BasicConstraints(true));\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.19\"), true, new BasicConstraints(true));\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.17\"), true, new ASN1Integer(6));\n\n\t\treturn signCert(builder, keyPair.getPrivate());\n\t}", "CodeBleu_score": 63.9976030153785}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.15\"), true, new X509KeyUsage(X509KeyUsage.digitalSignature | X509KeyUsage.keyCertSign));\n\t\tbuilder.addExtension(new ASN1ObjectIdentifier(\"2.5.29.19\"), true, new BasicConstraints(true));\n\n\t\treturn signCert(builder, keyPair.getPrivate());\n\t}", "CodeBleu_score": 70.98247206003776}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\tif (eurekaHttpClient == null) {\n        try {\n            Field registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClient.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            LOGGER.error(\"Error accessing EurekaHttpClient: {}\", e.getMessage());\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 43.685437689766786}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tif (eurekaHttpClient == null) {\n        try {\n            eurekaHttpClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\").get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            logger.error(\"Cannot access EurekaHttpClient instance. EurekaHttpClient will be null.\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 40.05748639833747}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tif (eurekaHttpClient == null) {\n        try {\n            Field registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClient.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            LOG.error(\"Error accessing EurekaHttpClient\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 47.53303992326657}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\tList<Application> apps = this.eurekaClient.getApplications().getRegisteredApplications();\n\tif (apps.isEmpty()) {\n\t\treturn emptyList();\n\t}\n\tList<String> names = new ArrayList<>(apps.size());\n\tfor (Application app : apps) {\n\t\tif (!app.getInstances().isEmpty()) {\n\t\t\tnames.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn names;\n}", "CodeBleu_score": 49.43879455582343}, {"code": "public List<String> getServices(){\n\tList<Application> apps = this.eurekaClient.getApplications().getRegisteredApplications();\n\tif (apps == null || apps.isEmpty()) {\n\t\treturn emptyList();\n\t}\n\tList<String> names = new ArrayList<>();\n\tfor (Application app : apps) {\n\t\tif (!app.getInstances().isEmpty()) {\n\t\t\tnames.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn names;\n}", "CodeBleu_score": 63.16025439198085}, {"code": "public List<String> getServices(){\n\tList<String> services = new ArrayList<>();\n    List<Application> apps = this.eurekaClient.getApplications().getRegisteredApplications();\n    if (apps.isEmpty()) {\n        return services;\n    }\n    for (Application app : apps) {\n        if (!app.getInstances().isEmpty()) {\n            services.add(app.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 53.09285965539612}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (HealthIndicator healthIndicator : discoveryCompositeHealthContributor.getHealthIndicators()) {\n                if (!(healthIndicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(healthIndicator.getClass().getName(), healthIndicator);\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 46.4540938056127}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\thealthContributors.each { String name, HealthContributor healthContributor ->\n        if (healthContributor instanceof DiscoveryCompositeHealthContributor) {\n            healthContributor.getContributors().each { String name, HealthIndicator healthIndicator ->\n                if (!(healthIndicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(name, healthIndicator)\n                }\n            }\n        } else {\n            healthContributors.put(name, healthContributor)\n        }\n    }\n}", "CodeBleu_score": 33.90465909570782}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (HealthIndicator healthIndicator : discoveryCompositeHealthContributor.getContributors()) {\n                if (!(healthIndicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(entry.getKey(), healthIndicator);\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 46.60091863738627}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instance available for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 48.637567227040925}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 48.63235634467296}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances == null || instances.size() == 0) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    String providerApplicationUri = instances.get(0).getUri().toString() + \"/echo\";\n    return restTemplate.postForObject(providerApplicationUri, \"Hello\", String.class);\n}", "CodeBleu_score": 46.23984865911841}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\tServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No service instance found\");\n    }\n    URI uri = UriComponentsBuilder.newInstance()\n        .scheme(instance.isSecure() ? \"https\" : \"http\")\n        .host(instance.getHost())\n        .port(instance.getPort())\n        .path(\"/echo\")\n        .build()\n        .toUri();\n    return restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 57.31501326215247}, {"code": "public String world(){\n\tString result = \"\";\n    try {\n        result = restTemplate.postForObject(lbClient.choose(\"provider-application\") + \"/echo\", \"Hello World\", String.class);\n    } catch (Exception e) {\n        throw new RuntimeException(\"No Provider Application found. Did you forget to start the provider application?\");\n    }\n    return result;\n}", "CodeBleu_score": 38.02860782211115}, {"code": "public String world(){\n\ttry {\n        ServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n        URI uri = URI.create(String.format(\"http://%s:%s/echo\", serviceInstance.getHost(), serviceInstance.getPort()));\n        return restTemplate.postForObject(uri, \"world\", String.class);\n    } catch (Exception e) {\n        throw new RuntimeException(\"No service instance available for provider-application\", e);\n    }\n}", "CodeBleu_score": 58.04953650514757}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\ttry {\n        synchronized (serverMap) {\n            if (!serverMap.containsKey(serviceName)) {\n                serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n            }\n            serverMap.get(serviceName).add(new Server(ip, port));\n        }\n        logger.info(\"Registered \" + serviceName + \" at \" + ip + \":\" + port);\n        return true;\n    } catch (Exception e) {\n        logger.error(\"Failed to register \" + serviceName + \" at \" + ip + \":\" + port + \" due to \" + e);\n        return false;\n    }\n}", "CodeBleu_score": 49.33481157932784}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tsynchronized (serverMap) {\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, new HashSet<Server>());\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n        logger.info(\"Registered \" + serviceName + \" at \" + ip + \":\" + port);\n        return true;\n    }\n}", "CodeBleu_score": 48.36204325154533}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tboolean result = false;\n    if (serviceName != null && ip != null && port != null) {\n        logger.info(\"Registering service \" + serviceName + \" with IP \" + ip + \" and port \" + port);\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n        result = true;\n    }\n    return result;\n}", "CodeBleu_score": 47.95455914771768}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tServer server = new Server(ip, port);\n    if (serverMap.get(serviceName).remove(server)) {\n        logger.info(\"Deregistered server \" + server.toString() + \" from service \" + serviceName);\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 48.43772341476667}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlog.info(\"Deregistering server with name: \" + serviceName + \", IP: \" + ip + \", and port: \" + port);\n    Server server = new Server(ip, port);\n    Set<Server> serverSet = serverMap.get(serviceName);\n    if (serverSet == null) {\n        log.info(\"Server set for service: \" + serviceName + \" is null\");\n        return false;\n    }\n    if (serverSet.remove(server)) {\n        log.info(\"Server with name: \" + serviceName + \", IP: \" + ip + \", and port: \" + port + \" removed from server map\");\n        return true;\n    }\n    log.info(\"Server with name: \" + serviceName + \", IP: \" + ip + \", and port: \" + port + \" was not found in server map\");\n    return false;\n}", "CodeBleu_score": 52.03889345523347}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tServer server = new Server(ip, port);\n    logger.info(\"Deregistering server \" + server + \" from service \" + serviceName);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        logger.error(\"Service \" + serviceName + \" does not exist\");\n        return false;\n    }\n    if (servers.contains(server)) {\n        servers.remove(server);\n        return true;\n    }\n    logger.error(\"Server \" + server + \" does not exist in service \" + serviceName);\n    return false;\n}", "CodeBleu_score": 52.040537189520755}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes == null) {\n        return;\n    }\n    AnnotationAttributes[] annotationAttributes = (AnnotationAttributes[]) attributes.get(\"value\");\n    if (annotationAttributes == null) {\n        return;\n    }\n    for (AnnotationAttributes annotationAttribute : annotationAttributes) {\n        String name = annotationAttribute.getString(\"name\");\n        String[] value = (String[]) annotationAttribute.get(\"value\");\n        String[] configuration = (String[]) annotationAttribute.get(\"configuration\");\n        registerClientConfiguration(registry, name, value);\n        registerClientConfiguration(registry, name, configuration);\n    }\n}", "CodeBleu_score": 43.92975132732451}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata\n                .getAnnotationAttributes(RibbonClients.class.getName());\n\n        if (attributes != null && attributes.containsKey(\"defaultConfiguration\")) {\n            String name = \"com.netflix.loadbalancer.ribbon.RibbonClientConfiguration\";\n            registerClientConfiguration(registry, name,\n                    attributes.get(\"defaultConfiguration\"));\n        }\n\n        AnnotationAttributes[] annotationAttributes = AnnotationAttributes\n                .fromMap(attributes.get(\"clients\"));\n        if (annotationAttributes != null) {\n            for (AnnotationAttributes annotationAttribute : annotationAttributes) {\n                registerClientConfiguration(registry,\n                        annotationAttribute.getString(\"name\"),\n                        annotationAttribute.get(\"configuration\"));\n            }\n        }\n    }", "CodeBleu_score": 49.44887352499143}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName(), true);\n\n        if (attributes != null && attributes.containsKey(\"defaultConfiguration\")) {\n            String name = \"default\";\n            Object configuration = attributes.get(\"defaultConfiguration\");\n            registerClientConfiguration(registry, name, configuration);\n            attributes.remove(\"defaultConfiguration\");\n        }\n\n        AnnotationAttributes[] clients = AnnotationAttributes.fromMap(attributes)\n                .getAnnotationArray(\"value\");\n\n        if (clients.length > 0) {\n            for (AnnotationAttributes client : clients) {\n                registerClientConfiguration(registry, client.getString(\"name\"),\n                        client.get(\"configuration\"));\n            }\n        }\n    }", "CodeBleu_score": 52.721610586430046}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\treturn choose(serviceId, request, new DefaultContext());\n}", "CodeBleu_score": 15.262725029190783}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\treturn choose(serviceId, null, request);\n}", "CodeBleu_score": 11.44702098171371}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 13.372315990061301}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tURI result = null;\n    try {\n        StringBuilder sb = new StringBuilder();\n        sb.append(original.getScheme()).append(\"://\").append(server.getHost()).append(\":\").append(server.getPort());\n        sb.append(original.getRawPath());\n        if (original.getRawQuery() != null) {\n            sb.append(\"?\").append(original.getRawQuery());\n        }\n        result = new URI(sb.toString());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n    return result;\n}", "CodeBleu_score": 65.06721276057148}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\ttry {\n        String scheme = original.getScheme();\n        String host = server.getHost();\n        int port = server.getPort();\n        String path = original.getRawPath();\n        String query = original.getRawQuery();\n        URI reconstructed = new URI(scheme, null, host, port, path, query, null);\n        return reconstructed;\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 40.60334126190135}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tURI uri = null;\n    try {\n        String scheme = original.getScheme() != null ? original.getScheme() : \"http\";\n        String host = server.getHost();\n        String path = original.getRawPath() != null ? original.getRawPath() : \"\";\n        String query = original.getRawQuery() != null ? original.getRawQuery() : \"\";\n        int port = server.getPort();\n        uri = new URI(scheme, null, host, port, path, query, null);\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n    return uri;\n}", "CodeBleu_score": 40.63601463782172}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\tdef serverAddr = getServerAddr()\n    def serviceName = getString(\"serviceName\")\n    def url = serverAddr + \"/list?serviceName=\" + serviceName\n    def resp = get(url)\n    return parseArray(resp.getData())\n}", "CodeBleu_score": 17.0388994413741}, {"code": "private List<TutuServer> getServer(){\n\tdef serverAddr = getServerAddr()\n    def serverList = []\n    def serviceName = getString(\"serviceName\")\n    def url = serverAddr + \"/list?serviceName=\" + serviceName\n    def result = new URL(url).getText()\n    def jsonArray = new JsonSlurper().parseText(result)\n    jsonArray.each {\n        def server = new TutuServer(it.ip, it.port)\n        serverList.add(server)\n    }\n    return serverList\n}", "CodeBleu_score": 29.16621695435188}, {"code": "private List<TutuServer> getServer(){\n\tdef serverAddr = getServerAddr()\n    def serviceName = getString(\"serviceName\")\n    def response = stream(Method.GET, serverAddr + \"/list?serviceName=\" + serviceName, \"\")\n    def serverList = parseArray(response)\n    return serverList.collect {\n        def ip = it.getString(\"ip\")\n        def port = it.getInteger(\"port\")\n        return new TutuServer(ip, port)\n    }\n}", "CodeBleu_score": 32.591650072365795}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\tfor (Route route : routes) {\n        String pattern = route.getPath();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = path.replaceFirst(pattern, route.getServiceId());\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 42.311382348577936}, {"code": "public Route getMatchingRoute(String path){\n\tfor (String pattern : routes.keySet()) {\n        if (pathMatcher.match(pattern, path)) {\n            String serviceId = routes.get(pattern);\n            String targetPath = path.replaceFirst(pattern, \"\");\n            return new Route(pattern, serviceId, targetPath);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 33.2243967839826}, {"code": "public Route getMatchingRoute(String path){\n\tfor (Route route : getRoutes()) {\n        String pattern = route.getPath();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = path.substring(pattern.length());\n            if (targetPath.startsWith(\"/\")) {\n                targetPath = targetPath.substring(1);\n            }\n            return new Route(route.getServiceId(), targetPath);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 45.606117009595}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tClassPathScanningCandidateComponentProvider scanner = getScanner();\n\tscanner.setResourceLoader(this.resourceLoader);\n\n\tAnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n\tscanner.addIncludeFilter(annotationTypeFilter);\n\n\tfor (String basePackage : getBasePackages(importingClassMetadata)) {\n\t\tSet<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n\t\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\t\tif (candidateComponent instanceof AnnotatedBeanDefinition) {\n\t\t\t\t// verify annotated class is an interface\n\t\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n\t\t\t\tAnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n\t\t\t\tAssert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\");\n\n\t\t\t\tMap<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName());\n\n\t\t\t\tString name = getName(attributes);\n\t\t\t\tString contextId = getContextId(attributes);\n\t\t\t\tString[] configuration = getConfiguration(attributes);\n\n\t\t\t\tregisterClientConfiguration(registry, contextId, configuration);\n\n\t\t\t\tregisterFeignClient(registry, annotationMetadata, contextId);\n\n\t\t\t\tregisterFallback(registry, annotationMetadata, contextId);\n\n\t\t\t\tregisterFallbackFactory(registry, annotationMetadata, contextId);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 26.03333953193914}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tClassPathScanningCandidateComponentProvider scanner = getScanner();\n    scanner.setResourceLoader(this.resourceLoader);\n\n    AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n    scanner.addIncludeFilter(annotationTypeFilter);\n\n    for (String basePackage : getBasePackages(importingClassMetadata)) {\n        Set<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n        for (BeanDefinition candidateComponent : candidateComponents) {\n            if (candidateComponent instanceof AnnotatedBeanDefinition) {\n                // verify annotated class is an interface\n                AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n                AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n                Assert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\");\n\n                Map<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName());\n\n                String name = getName(attributes);\n                String contextId = getContextId(attributes);\n                String[] configuration = getConfiguration(attributes);\n\n                registerClientConfiguration(registry, contextId, configuration);\n\n                registerFeignClient(registry, annotationMetadata, attributes);\n            }\n        }\n    }\n}", "CodeBleu_score": 29.690397323278855}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tClassPathScanningCandidateComponentProvider scanner = getScanner();\n    scanner.setResourceLoader(this.resourceLoader);\n\n    AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n    scanner.addIncludeFilter(annotationTypeFilter);\n\n    for (String basePackage : getBasePackages(importingClassMetadata)) {\n        Set<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n        for (BeanDefinition candidateComponent : candidateComponents) {\n            if (candidateComponent instanceof AnnotatedBeanDefinition) {\n                // verify annotated class is an interface\n                AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n                AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n                Assert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\");\n\n                Map<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName());\n\n                String name = getName(attributes);\n                registerClientConfiguration(registry, name, attributes.get(\"configuration\"));\n\n                registerFeignClient(registry, annotationMetadata, attributes);\n            }\n        }\n    }\n}", "CodeBleu_score": 29.97054071387351}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}]}
