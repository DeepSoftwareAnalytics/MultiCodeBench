{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\the original method returns a tuple of two values:\n    #   (connect_timeout, session_timeout)\n    # The first element of the tuple is the amount of time to wait before giving up on a connection attempt.\n    # The second element of the tuple is the amount of time to wait before sending a keep-alive message.\n    # The second element of the tuple is the negotiated session timeout.\n    #\n    # We want to use the first element of the tuple as the wait time,\n    # but we want to make sure it is at least 2.\n    #\n    # The original method has a bug: it returns a tuple of (0, 0) if the connection is successful.\n    # This causes the client to immediately close the connection.\n    #\n    # To fix this, we return a tuple of (1, 0) if the connection is successful.\n    #\n    # We also want to make sure the wait time is not less than 2.\n    # If it is, we return a tuple of (2, 0).\n    #\n    # We also want to make sure the wait time is not greater than the original method's first element.\n    # If it is, we return the original method's first element.\n    #\n    # We also want to make sure the wait time is not less than the original method's first element.\n    # If it is, we return the original method's first element.\n    #\n    # If all of the above conditions are not met, we return the original method's first element.\n    #\n    # The original method's first element is the amount of time to wait before giving up on a connection attempt.\n    # The second element is the amount of time to wait before sending a keep-alive message.\n    # The second element is the negotiated session timeout.\n    #\n    # We want to use the first element of the tuple as the wait time,\n    # but we want to make sure it is at least 2.\n    #\n    # The original method has a bug: it returns a tuple of (0, 0) if the connection is successful.\n    # This causes the client to immediately close the connection.\n    #\n    # To fix this, we return a tuple of (1, 0) if the connection is successful.\n    #\n    # We also want to make sure the wait time is not less than 2.\n    # If it is, we return a tuple of (", "CodeBleu_score": 25.599201083132613}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t:\n        loop_wait, timeout = self._orig_kazoo_connect(*args)\n    except (socket.error, select.error) as e:\n        raise ZooKeeperError(e)\n    return (max(2, loop_wait - 2) * 1000, timeout)\n\n", "CodeBleu_score": 50.98766970717789}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t:\n        return (max(2, self.loop_wait - 2) * 1000, self._orig_kazoo_connect(*args))\n    except Exception as e:\n        logger.exception(e)\n        raise\n\n    def _get_cluster_config(self) -> ClusterConfig:\n        return ClusterConfig(self._client.get_children(self.config.get('scope', 'patroni') + '/config'))\n\n    def _get_cluster_status(self) -> Status:\n        status = Status(self._client.get_children(self.config.get('scope', 'patroni') + '/status'))\n        status.cluster_name = self.config.get('scope', 'patroni')\n        return status\n\n    def _get_cluster_timeline(self) -> TimelineHistory:\n        return TimelineHistory(self._client.get_children(self.config.get('scope', 'patroni') + '/timeline'))\n\n    def _get_cluster_history(self) -> List[Dict[str, Any]]:\n        return json.loads(self._client.get_children(self.config.get('scope', 'patroni') + '/history')[0])\n\n    def _get_cluster_leader(self) -> Leader:\n        return Leader(self._client.get_children(self.config.get('scope', 'patroni') + '/leader'))\n\n    def _get_cluster_members(self) -> List[Member]:\n        return [Member(m, self._client.get_children(self.config.get('scope', 'patroni') + '/members/' + m)[0]) for m in self._client.get_children(self.config.get('scope', 'patroni') + '/members')]\n\n    def _get_cluster_sync_state(self) -> SyncState:\n        return SyncState(self._client.get_children(self.config.get('scope', 'patroni') + '/sync_state'))\n\n    def _get_cluster_failover(self) -> Failover:\n        return Failover(self._client.get_children(self", "CodeBleu_score": 44.235802166207584}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, dict):\n        config = config.to_dict()\n\n    self.config.update(config)\n    if self.retry_timeout!= self.config['retry_timeout']:\n        self.retry_timeout = self.config['retry_timeout']\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self.config['retry_timeout'] / 2)\n\n    if self.loop_wait!= self.config['loop_wait']:\n        self.loop_wait = self.config['loop_wait']\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self.config['retry_timeout'] / 2)\n\n    if self.ttl!= self.config['ttl']:\n        try:\n            self._client.set_session_timeout(self.config['ttl'])\n        except KazooException as e:\n            logger.error('Failed to update TTL to %s: %s', self.config['ttl'], e)\n            self.loop_wait = self.config['loop_wait']\n            if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n                self._client.handler.set_connect_timeout(self.config['retry_timeout'] / 2)\n            self._client.close()\n\n", "CodeBleu_score": 36.34797048819719}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    if isinstance(config, Config):\n        config = config.config\n\n    if'retry_timeout' in config:\n        self.retry_timeout = config['retry_timeout']\n\n    if 'loop_wait' in config:\n        self.loop_wait = config['loop_wait']\n\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self.loop_wait / 2.0)\n\n    if 'ttl' in config:\n        try:\n            self._client.set_ttl(config['ttl'])\n        except KazooException as e:\n            if self.loop_wait!= self._client.handler.loop_wait:\n                self.close()\n                raise e\n\n    if'set_acls' in config:\n        default_acl: List[ACL] = []\n        for principal, permissions in config['set_acls'].items():\n            normalizedPermissions = [p.upper() for p in permissions]\n            default_acl.append(make_acl(scheme='x509',\n                                            credential=principal,\n                                            read='READ' in normalizedPermissions,\n                                            write='WRITE' in normalizedPermissions,\n                                            create='CREATE' in normalizedPermissions,\n                                            delete='DELETE' in normalizedPermissions,\n                                            admin='ADMIN' in normalizedPermissions,\n                                            all='ALL' in normalizedPermissions))\n        self._client.default_acl = default_acl\n\n    if 'auth_data' in config:\n        self._client.auth_data = list(config['auth_data'].items())\n\n    if 'acl_provider' in config:\n        self._client.acl_provider = config['acl_provider']\n\n    if 'auth_providers' in config:\n        self._client.auth_providers = config['auth_providers']\n\n    if 'acl_provider_options' in config:\n        self._client.acl_provider_options = config['acl_provider_options']\n\n    if 'auth_provider_options' in config:\n        self._client.auth_provider_options = config['auth_provider_options']", "CodeBleu_score": 30.791992329403055}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    if not isinstance(config, dict):\n        config = config.to_dict()\n\n    if'retry_timeout' in config:\n        self.retry_timeout = config['retry_timeout']\n        if self._client._handler_type == PatroniSequentialThreadingHandler:\n            self._client._handler.set_connect_timeout(self.retry_timeout / 2.0)\n\n    if 'loop_wait' in config:\n        self.loop_wait = config['loop_wait']\n        if self._client._handler_type == PatroniSequentialThreadingHandler:\n            self._client._handler.set_connect_timeout(self.loop_wait / 2.0)\n\n    if 'ttl' in config:\n        self.ttl = config['ttl']\n        try:\n            self._client.set_session_timeout(self.ttl)\n        except KazooException as e:\n            if self._client._handler_type == PatroniSequentialThreadingHandler:\n                self._client._handler.set_connect_timeout(self.loop_wait / 2.0)\n            raise ZooKeeperError(e)\n\n", "CodeBleu_score": 35.585708580122}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.config, self.config.get('name', os.path.basename(path)))\n    cluster.path = path\n    cluster.name = os.path.basename(path)\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.timeline = self.get_node(path + self._TIMELINE)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.sync_state = self.get_node(path + self._SYNC_STATE)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_node(path + self._LEADER)\n\n    if cluster.leader:\n        cluster.leader = self.member(cluster.leader[0], cluster.leader[1], ZnodeStat(0, 0, 0, 0, 0, 0, 0))\n\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    cluster.initialize = self.get_node(path + self._INITIALIZE)\n    return cluster\n\n", "CodeBleu_score": 20.77640918894066}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.config, self.name, self.logger, self.loop_wait, self.ttl)\n\n        # Initialize the cluster object with the current cluster state\n        if self.config['bootstrap']['dcs']['initial_state'] == 'existing':\n            cluster.load_cluster_state(path)\n\n        # Load the cluster configuration\n        cluster.load_config(path)\n\n        # Load the cluster timeline history\n        cluster.load_timeline_history(path)\n\n        # Load the cluster synchronization state\n        cluster.load_sync_state(path)\n\n        # Load the cluster members\n        cluster.load_members(path)\n\n        # Load the cluster leader information\n        cluster.load_leader(path)\n\n        # Load the cluster status\n        cluster.load_status(path)\n\n        # Load the cluster failover state\n        cluster.load_failover(path)\n\n        # Load the cluster failsafe configuration\n        cluster.load_failsafe(path)\n\n        # Return the cluster object\n        return cluster\n\n\n    def _postgresql_cluster_loader(self, path: str) -> Cluster:\n        \\\"\\\"\\\"This function loads a PostgreSQL cluster configuration from a given path. It retrieves various cluster components such as initialization state, configuration, timeline history, synchronization state, members, leader information, cluster status, failover state, and failsafe configuration. The function checks the existence of these components in the specified path, processes them, and returns a Cluster object containing all the gathered information.\\\"\\\"\\\"\n        cluster = Cluster(self.config, self.name, self.logger, self.loop_wait, self.ttl)\n\n        # Initialize the cluster object with the current cluster state\n        if self.config['bootstrap']['dcs']['initial_state'] == 'existing':\n            cluster.load_cluster_state(path)\n\n        # Load the cluster configuration\n        cluster.load_config(path)\n\n        # Load the cluster timeline history\n        cluster.load_timeline_history(path)\n\n        # Load the cluster synchronization state\n        cluster.load_sync_state(path)\n\n       ", "CodeBleu_score": 17.459517674337963}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # Load cluster status\n    status = self.get_status(path, self.leader)\n\n    # Load cluster configuration\n    config = self.get_node(path + self._CONFIG)\n    if config is None:\n        raise PatroniFatalError('Failed to load cluster configuration')\n    config = Config.from_node(config[0])\n\n    # Load cluster initialization state\n    init_state = self.get_node(path + self._INIT_STATE)\n    if init_state is None:\n        raise PatroniFatalError('Failed to load cluster initialization state')\n    init_state = InitState.from_node(init_state[0])\n\n    # Load cluster timeline history\n    timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    if timeline_history is None:\n        raise PatroniFatalError('Failed to load cluster timeline history')\n    timeline_history = TimelineHistory.from_node(timeline_history[0])\n\n    # Load cluster synchronization state\n    sync_state = self.get_node(path + self._SYNC_STATE)\n    if sync_state is None:\n        raise PatroniFatalError('Failed to load cluster synchronization state')\n    sync_state = SyncState.from_node(sync_state[0])\n\n    # Load cluster members\n    members = self.load_members(path)\n\n    # Load cluster leader information\n    leader = self.get_node(path + self._LEADER)\n    if leader is None:\n        raise PatroniFatalError('Failed to load cluster leader information')\n    leader = Leader.from_node(leader[0])\n\n    # Load cluster failover state\n    failover_state = self.get_node(path + self._FAILOVER_STATE)\n    if failover_state is None:\n        raise PatroniFatalError('Failed to load cluster failover state')\n    failover_state = FailoverState.from_node(failover_state[0])\n\n    # Load cluster failsafe configuration\n    failsafe_config = self.get_node(path + self._FAILSAFE_CONFIG", "CodeBleu_score": 30.590826821577878}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    while True:\n        try:\n            self._client.retry(self._client.create, self._path, b'', makepath=True, ephemeral=True)\n            return True\n        except NodeExistsError:\n            return False\n        except Exception:\n            logger.exception('Failed to acquire leader lock')\n            raise ZooKeeperError('ZooKeeper in not responding properly')\n\n    @property\n    def path(self) -> str:\n        return self._path\n\n    @property\n    def is_leader(self) -> bool:\n        return self._client.exists(self._path) is not None\n\n    def release(self) -> None:\n        try:\n            self._client.delete(self._path)\n        except Exception:\n            logger.exception('Failed to release leader lock')\n\n    def __enter__(self) -> None:\n        self.acquire()\n\n    def __exit__(self, exc_type, exc_val, exc_tb) -> None:\n        self.release()\n\n    def __repr__(self) -> str:\n        return f'{self.__class__.__name__}(path={self.path!r}, is_leader={self.is_leader!r})'\n\n    def __str__(self) -> str:\n        return f'{self.__class__.__name__}(path={self.path!r}, is_leader={self.is_leader!r})'\n\n    def __bool__(self) -> bool:\n        return self.is_leader\n\n    def __eq__(self, other: object) -> bool:\n        return isinstance(other, self.__class__) and self.path == other.path\n\n    def __ne__(self, other: object) -> bool:\n        return not self.__eq__(other)\n\n    def __hash__(self) -> int:\n        return hash(self.path)\n\n", "CodeBleu_score": 46.76943834498065}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self.leader_lock is None:\n        return False\n\n    try:\n        self._client.retry(self._client.create, self.leader_lock, b'', ephemeral=True, sequence=True)\n        return True\n    except NodeExistsError:\n        logger.info('Another instance has the leader lock')\n        return False\n    except Exception:\n        logger.exception('Failed to acquire leader lock')\n        raise ZooKeeperError('ZooKeeper in not responding properly')\n\n    return False\n\n", "CodeBleu_score": 42.33095661170503}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    path = self._path + self._LEADER_LOCK\n\n    for _ in range(self._retry_timeout):\n        try:\n            self._client.create(path, self._name, ephemeral=True)\n            return True\n        except NodeExistsError:\n            return False\n        except Exception:\n            logger.exception('Failed to acquire leader lock')\n\n    raise ZooKeeperError('ZooKeeper in not responding properly')\n\n\n    def _create_node(self, path: str, value: bytes) -> bool:\n        \\\"\\\"\\\"Create a node in ZooKeeper with the specified path and value. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error and returns False.\\\"\\\"\\\"\n        for _ in range(self._retry_timeout):\n            try:\n                self._client.create(path, value, makepath=True)\n                return True\n            except Exception:\n                logger.exception('Failed to create %s', path)\n        return False\n\n\n    def _delete_node(self, path: str) -> bool:\n        \\\"\\\"\\\"Delete a node in ZooKeeper with the specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error and returns False.\\\"\\\"\\\"\n        for _ in range(self._retry_timeout):\n            try:\n                self._client.delete(path)\n                return True\n            except Exception:\n                logger.exception('Failed to delete %s', path)\n        return False\n\n\n    def _set_node(self, path: str, value: bytes) -> bool:\n        \\\"\\\"\\\"Set the value of a node in ZooKeeper with the specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error and returns False.\\\"\\\"\\\"\n        for", "CodeBleu_score": 40.175672958254694}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        try:\n            self._client.create_async(self.leader_path, self._name.encode('utf-8'), makepath=True, ephemeral=True).get(timeout=1)\n            return True\n        except Exception as e:\n            if not isinstance(e, NodeExistsError):\n                logger.exception('Failed to create %s: %r', self.leader_path, e)\n    try:\n        self._client.set_async(self.leader_path, self._name.encode('utf-8')).get(timeout=1)\n        return True\n    except Exception:\n        logger.exception('Failed to update %s', self.leader_path)\n    return False\n\n", "CodeBleu_score": 60.14162804207015}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n\n    if leader:\n        try:\n            self._client.create_async(self.leader_path, self._name.encode('utf-8'), makepath=True, ephemeral=True).get(timeout=1)\n            return True\n        except Exception:\n            logger.exception('Failed to create %s', self.leader_path)\n    return False\n\n    def _write_leader_optime(self, last_lsn: str) -> bool:\n        return self._set_or_create(self.leader_optime_path, last_lsn) is not False\n\n    def _write_status(self, value: str) -> bool:\n        return self._set_or_create(self.status_path, value) is not False\n\n    def _write_failsafe(self, value: str) -> bool:\n        return self._set_or_create(self.failsafe_path, value) is not False\n\n\n\n", "CodeBleu_score": 52.91767937730756}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n\n    try:\n        self._client.create_async(self.leader_path, self._name.encode('utf-8'), makepath=True, ephemeral=True).get(timeout=1)\n        return True\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.exception('Failed to create %s', self.leader_path)\n        return False\n\n", "CodeBleu_score": 46.32632033176093}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\tif self._next_poll is None or self._next_poll <= time.time():\n        self._next_poll = time.time() + self._poll_interval\n        self._poll_exhibitors()\n        return True\n    return False\n\n", "CodeBleu_score": 14.841874010130393}, {"code": "def poll(self) -> bool\n\tif self._next_poll is None or self._next_poll < time.time():\n        self._next_poll = time.time() + self._poll_interval\n        try:\n            response = requests_get(self._exhibitor_url(), timeout=self.TIMEOUT)\n        except Exception as e:\n            logger.error('failed to poll exhibitor: %s', e)\n            return False\n        try:\n            data = json.loads(response.text)\n        except Exception as e:\n            logger.error('failed to parse exhibitor response: %s', e)\n            return False\n        if'servers' not in data:\n            logger.error('failed to parse exhibitor response: no servers field')\n            return False\n        if 'port' not in data:\n            logger.error('failed to parse exhibitor response: no port field')\n            return False\n        if 'host' not in data:\n            logger.error('failed to parse exhibitor response: no host field')\n            return False\n        new_exhibitors = []\n        for server in data['servers']:\n            if 'host' in server and 'port' in server:\n                new_exhibitors.append('%s:%s' % (server['host'], server['port']))\n        if self._exhibitors!= new_exhibitors:\n            self._exhibitors = new_exhibitors\n            self._next_poll = time.time() + self._poll_interval\n            logger.info('exhibitor changed to %s', self._exhibitors)\n            return True\n        return False\n\n    return False\n\n", "CodeBleu_score": 40.20167759908939}, {"code": "def poll(self) -> bool\n\tif self._next_poll is None or time.time() > self._next_poll:\n        self._next_poll = time.time() + self._poll_interval\n        try:\n            for exhibitor in self._exhibitors:\n                if not exhibitor.startswith('http://'):\n                    exhibitor = 'http://' + exhibitor\n                try:\n                    response = requests_get(exhibitor + self._uri_path, timeout=self.TIMEOUT)\n                except Exception as e:\n                    logger.exception('failed to get exhibitor status: %s', e)\n                    continue\n                try:\n                    data = json.loads(response.text)\n                except Exception as e:\n                    logger.exception('failed to parse exhibitor status: %s', e)\n                    continue\n                if'servers' in data and 'port' in data:\n                    zookeeper_hosts = ','.join(server['hostname'] + ':' + str(data['port']) for server in data['servers'])\n                    if zookeeper_hosts!= self._zookeeper_hosts:\n                        logger.info('exhibitor changed zookeeper hosts from %s to %s', self._zookeeper_hosts, zookeeper_hosts)\n                        self._zookeeper_hosts = zookeeper_hosts\n                        return True\n        except Exception as e:\n            logger.exception('failed to poll exhibitor')\n        return False\n\n\n    return False\n\n", "CodeBleu_score": 40.05042603410079}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t self._ensemble_provider:\n        if self._ensemble_provider.poll():\n            self._hosts = self._ensemble_provider.zookeeper_hosts\n            self._client.hosts = self._hosts\n        else:\n            logger.debug('Ensemble provider is not ready yet')\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 71.0034850095261}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t self._ensemble_provider:\n        self._ensemble_provider.poll()\n        self._hosts = self._ensemble_provider.zookeeper_hosts\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 78.0531375524389}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t self._ensemble_provider:\n        self._ensemble_provider.poll()\n        if self._ensemble_provider.zookeeper_hosts!= self.hosts:\n            self.hosts = self._ensemble_provider.zookeeper_hosts\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 72.84872718644652}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\tf (zookeeperListener!= null) {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 81.03856237755045}, {"code": "public void destroy(){\n\tf (zookeeperListener!= null) {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperListener.unsubscribeConfig(group, dataId);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 66.88077517331972}, {"code": "public void destroy(){\n\tf (zookeeperListener == null) {\nreturn;\n}\n\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperListener.unsubscribe();\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n\nlogGetStarted();\n\ntry {\nString config = zookeeperOperation.getConfig(group, dataId);\nif (config!= null) {\ncallbackConfig(config);\n} else {\nlogNotFound();\n}\n} catch (Exception e) {\nlogGetFailed(e);\n}\n}", "CodeBleu_score": 76.61739629842228}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\nreturn zookeeperServer.getMetadata();\n}\n\nreturn Collections.emptyMap();\n}", "CodeBleu_score": 60.32405833312357}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\nreturn zookeeperServer.getMetadata();\n}\n\nreturn Collections.emptyMap();\n}", "CodeBleu_score": 60.32405833312357}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\nreturn zookeeperServer.getPayload();\n}\nreturn Collections.emptyMap();\n}", "CodeBleu_score": 60.11027956277899}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tChildData childData = nodeCache.getCurrentData();\n\t\t\tif (childData == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tbyte[] bytes = childData.getData();\n\t\t\tif (bytes == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tString config = convertConfig(bytes);\n\t\t\tzookeeperSubscribeCallback.onSubscribe(config);\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tzookeeperListenerList.add(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 72.52265714588323}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tChildData childData = nodeCache.getCurrentData();\n\t\t\tif (childData == null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tString config = convertConfig(childData.getPath());\n\t\t\tzookeeperSubscribeCallback.onSubscribe(config);\n\t\t}\n\t};\n\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\taddZookeeperListener(zookeeperListener);\n\n\treturn zookeeperListener;\n}", "CodeBleu_score": 71.26044248154334}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = convertConfig(path);\n\t\t\tzookeeperSubscribeCallback.onSubscribe(config);\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tnodeCache.start(true);\n\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 73.99756680547851}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.initWithDiscovery(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\nreturn serverList;\n}", "CodeBleu_score": 79.46007557480293}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.initFromConfig(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\nreturn serverList;\n}", "CodeBleu_score": 79.55020400000205}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.initWithNiwsConfig(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\n\nreturn serverList;\n}", "CodeBleu_score": 86.84155991881704}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = this.applicationContext.getBean(RegisterListenerExecutor.class);\n\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.error(\"Failed to get RegisterListenerExecutor from application context\", e);\n}\n\nthis.serviceRegistry.register(registration);\n}", "CodeBleu_score": 73.02925425604478}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.error(\"Failed to get RegisterListenerExecutor from application context\", e);\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException be) {\n// LOG.error(\"Failed to invoke the onRegister method of the RegisterListenerExecutor bean\", be);\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 83.09275578743956}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\\\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\\\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\\\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\\\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\\\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\\\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\\\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\\\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = ConfigType.GLOBAL.getGroup();\n\t\tdataId = ConfigType.GLOBAL.getDataId();\n\t} else {\n\t\tgroup = ConfigType.LOCAL.getGroup();\n\t\tdataId = ConfigType.LOCAL.getDataId();\n\t}\n\ttry {\n\t\tlog.info(\"Subscribe to {} config of {}:{}\", globalConfig, group, dataId);\n\t\treturn zookeeperOperation.subscribe(group, dataId, new ZookeeperSubscribeCallback() {\n\t\t\t@Override\n\t\t\tpublic void onConfigUpdate(String config) {\n\t\t\t\tlog.info(\"Config updated to {} of {}:{}\", config, group, dataId);\n\t\t\t\tsetConfig(config);\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlog.error(\"Subscribe to {} config of {}:{} failed\", globalConfig, group, dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 46.40181138570159}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? ConfigType.GLOBAL_CONFIG_GROUP : ConfigType.LOCAL_CONFIG_GROUP;\n\tString dataId = globalConfig? ConfigType.GLOBAL_CONFIG_DATA_ID : ConfigType.LOCAL_CONFIG_DATA_ID;\n\tlogger.info(\"Start subscribing to configuration group: {} dataId: {}\", group, dataId);\n\ttry {\n\t\tZookeeperSubscribeCallback subscribeCallback = new ZookeeperSubscribeCallback(group, dataId);\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, subscribeCallback);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Subscribe configuration group: {} dataId: {} failed\", group, dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 33.691705317055764}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? ConfigType.GLOBAL.getGroup() : ConfigType.LOCAL.getGroup();\n\tString dataId = globalConfig? ConfigType.GLOBAL.getDataId() : ConfigType.LOCAL.getDataId();\n\tlog.info(\"Subscribe to configuration group: {}, dataId: {}\", group, dataId);\n\tZookeeperListener zookeeperListener = null;\n\ttry {\n\t\tzookeeperListener = zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n\t\t\t@Override\n\t\t\tpublic void process(String config) {\n\t\t\t\tlog.info(\"Subscribe to configuration group: {}, dataId: {}\", group, dataId);\n\t\t\t\ttry {\n\t\t\t\t\tupdateConfig(config);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tlog.error(\"Failed to update configuration group: {}, dataId: {}\", group, dataId, e);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to subscribe to configuration group: {}, dataId: {}\", group, dataId, e);\n\t}\n\treturn zookeeperListener;\n}", "CodeBleu_score": 47.41583574952252}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING);\nif (StringUtils.isEmpty(connectionString)) {\nthrow new DiscoveryException(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING + ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING_EMPTY_ERROR);\n}\nint retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.ZOOKEEPER_RETRY_COUNT_DEFAULT);\nint retrySleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_SLEEP_TIME, Integer.class, ZookeeperConstant.ZOOKEEPER_RETRY_SLEEP_TIME_DEFAULT);\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(connectionString)\n.retryPolicy(new ExponentialBackoffRetry(retryCount, retrySleepTime))\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 69.8268751159584}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING);\nif (StringUtils.isEmpty(connectionString)) {\nthrow new DiscoveryException(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING + ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING_EMPTY_ERROR);\n}\n\nint retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.ZOOKEEPER_RETRY_COUNT_DEFAULT);\nint retrySleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_SLEEP_TIME, Integer.class, ZookeeperConstant.ZOOKEEPER_RETRY_SLEEP_TIME_DEFAULT);\n\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(retryPolicy).build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 65.46576246212823}, {"code": "public CuratorFramework curatorFramework(){\n\tString zookeeperConnectionString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING);\nif (StringUtils.isEmpty(zookeeperConnectionString)) {\nthrow new DiscoveryException(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING + ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING_ERROR);\n}\n\nExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, 10), environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_SLEEP_TIME, 1000));\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(zookeeperConnectionString).retryPolicy(retryPolicy).build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 49.56919128737687}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n/**\n * The gatewayStrategyRouteZookeeperProcessor method defines a bean for a new instance of GatewayStrategyRouteZookeeperProcessor.\nThis method is conditional, only executing if the property \"spring.cloud.gateway.discovery.locator.enabled\" is set to \"false\" or is missing.\n */\n@Bean\n@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\n/**\n * The new ZookeeperProcessor constructor is called to create a new instance of GatewayStrategyRouteZookeeperProcessor.\n */\nreturn new GatewayStrategyRouteZookeeperProcessor();\n}\n}", "CodeBleu_score": 72.06432740825706}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The gatewayStrategyRouteZookeeperProcessor method defines a bean, which returns a new instance of GatewayStrategyRouteZookeeperProcessor.\nThis method is conditional, only executing if the property \"spring.cloud.gateway.discovery.locator.enabled\" is set to \"false\" or is missing.\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 72.10362136571081}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The gatewayStrategyRouteZookeeperProcessor method defines a bean for Zookeeper processor.\nIt returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 72.10362136571081}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t//        RetryPolicy retryPolicy = new ExponentialBackoffRetry(zooKeeperClientProperties.getBaseSleepTimeMs(), zooKeeperClientProperties.getMaxRetries());\n//        CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()\n//               .connectString(zooKeeperClientProperties.getConnectString())\n//               .connectionTimeoutMs(zooKeeperClientProperties.getConnectionTimeoutMs())\n//               .sessionTimeoutMs(zooKeeperClientProperties.getSessionTimeoutMs())\n//               .namespace(zooKeeperClientProperties.getNamespace())\n//               .retryPolicy(retryPolicy);\n//        CuratorFramework curatorFramework = builder.build();\n//        curatorFramework.start();\n//        return curatorFramework;\n    }", "CodeBleu_score": 1.8554470505646803}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(zooKeeperClientProperties.getBaseSleepTimeMs(), zooKeeperClientProperties.getMaxRetries());\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zooKeeperClientProperties.getConnectString(), zooKeeperClientProperties.getSessionTimeoutMs(), zooKeeperClientProperties.getConnectionTimeoutMs(), retryPolicy);\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 51.24283982859146}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t", "CodeBleu_score": 1.6531227316461272}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\ttry {\nInterProcessMutex lock = new InterProcessMutex(curatorFrameworkClient.getCuratorFramework(), path);\nlock.acquire();\nlocksMap.put(Thread.currentThread(), lock);\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}", "CodeBleu_score": 25.116359370372315}, {"code": "public void lock(String path) throws DistributedLockException{\n\ttry {\nInterProcessMutex lock = new InterProcessMutex(curatorFrameworkClient.getCuratorFramework(), path);\nlock.acquire();\nThread thread = Thread.currentThread();\nlocksMap.put(thread, lock);\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}", "CodeBleu_score": 27.534461465953463}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = new InterProcessMutex(curatorFrameworkClient.getCuratorFramework(), path);\ntry {\nif (!locksMap.containsKey(Thread.currentThread())) {\nlock.acquire();\nlocksMap.put(Thread.currentThread(), lock);\n} else {\nlock.acquire();\n}\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}", "CodeBleu_score": 30.349125432052578}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nCuratorFramework curatorFramework = CuratorUtil.getCuratorFramework(dtpProperties);\nString nodePath = CuratorUtil.nodePath(dtpProperties);\nif (PROPERTIES.equals(dtpProperties.getConfigFileType())) {\nreturn genPropertiesTypeMap(curatorFramework, nodePath);\n} else if (JSON.equals(dtpProperties.getConfigFileType())) {\nString configKey = dtpProperties.getConfigKey();\nString configValue = new String(curatorFramework.getData().forPath(ZKPaths.makePath(nodePath, configKey)),\nStandardCharsets.UTF_8);\nreturn ConfigHandler.parseJson(configValue);\n}\nreturn Collections.emptyMap();\n}", "CodeBleu_score": 44.50141441789658}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\nString nodePath = nodePath(dtpProperties);\nif (PROPERTIES.equals(dtpProperties.getConfigFileType())) {\nreturn genPropertiesTypeMap(curatorFramework, nodePath);\n}\nString configKey = ZKPaths.makePath(nodePath, dtpProperties.getConfigKey());\nGetDataBuilder getDataBuilder = curatorFramework.getData().forPath(configKey);\nbyte[] bytes = getDataBuilder.withVersion(dtpProperties.getConfigVersion()).usingWatcher(null).start().getData();\nif (bytes == null) {\nreturn Collections.emptyMap();\n}\nreturn ConfigHandler.parse(new String(bytes, StandardCharsets.UTF_8), dtpProperties.getConfigFileType());\n}", "CodeBleu_score": 49.980135719035985}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nCuratorFramework curatorFramework = CuratorUtil.getCuratorFramework(dtpProperties);\nString nodePath = CuratorUtil.nodePath(dtpProperties);\nMap<Object, Object> propertiesMap = null;\nif (PROPERTIES.equals(dtpProperties.getConfigFileType())) {\npropertiesMap = genPropertiesTypeMap(curatorFramework, nodePath);\n} else if (JSON.equals(dtpProperties.getConfigFileType())) {\nString configKey = dtpProperties.getConfigKey();\nString configValue = new String(curatorFramework.getData().forPath(ZKPaths.makePath(nodePath, configKey)), StandardCharsets.UTF_8);\npropertiesMap = ConfigHandler.parse(configValue, dtpProperties.getConfigFileType());\n}\nreturn propertiesMap;\n}", "CodeBleu_score": 46.65287707116901}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = application.getEnvironment().getProperty(DtpProperties.class);\nMap<String, Object> zkProperties = BinderHelper.bind(dtpProperties, Map.class);\nif (!environment.containsProperty(DtpProperties.ZK_CONFIG_PATH)) {\nMutablePropertySources propertySources = environment.getPropertySources();\npropertySources.addLast(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, zkProperties));\nlog.info(\"Zookeeper properties added to the environment.\");\n}\n}", "CodeBleu_score": 42.90239113710794}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = new DtpProperties();\nBinderHelper.bind(environment, dtpProperties);\nMap<String, Object> properties = BinderHelper.getProperties(dtpProperties);\nif (!environment.containsProperty(DtpProperties.ZOOKEEPER_PROPERTY_PREFIX)) {\nMutablePropertySources propertySources = environment.getPropertySources();\npropertySources.addFirst(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));\nlog.info(\"Dynamictp Zookeeper properties added to environment.\");\n}\n}", "CodeBleu_score": 48.951392620164604}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = application.getEnvironment().getProperty(DtpProperties.class);\nMap<String, Object> properties = BinderHelper.bind(dtpProperties, Map.class);\nif (!environment.containsProperty(DtpProperties.DTP_ZK_PROPERTY_SOURCE_NAME)) {\nMutablePropertySources propertySources = environment.getPropertySources();\npropertySources.addLast(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));\n}\n}", "CodeBleu_score": 44.95464514864187}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.Register(c => {\nvar loggerFactory = c.Resolve<ILoggerFactory>();\nvar serializerManager = c.Resolve<ISerializerManager>();\nvar routeFactory = c.Resolve<IServiceRouteFactory>();\nvar zookeeperClientProvider = c.Resolve<IZookeeperClientProvider>();\nvar zookeeperServiceRouteManager = new ZooKeeperServiceRouteManager(configInfo, zookeeperClientProvider, routeFactory, serializerManager, loggerFactory);\nreturn zookeeperServiceRouteManager;\n}).As<IServiceRouteManager>().SingleInstance();\nreturn this;\n}", "CodeBleu_score": 28.408310021648518}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.RegisterAdapter(factory => {\nvar serviceProvider = factory.GetService<IServiceProvider>();\nvar serializerManager = serviceProvider.GetService<ISerializerManager>();\nvar routeFactory = serviceProvider.GetService<IRouteFactory>();\nvar logger = serviceProvider.GetService<ILogger<ZooKeeperRouteManager>>();\nvar zookeeperClientProvider = serviceProvider.GetService<IZookeeperClientProvider>();\nreturn new ZooKeeperRouteManager(serializerManager, routeFactory, logger, zookeeperClientProvider, configInfo);\n}).InstancePerLifetimeScope();\nreturn this;\n}", "CodeBleu_score": 38.877036513247035}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.RegisterAdapter(provider => new ZooKeeperServiceRouteManager(\nprovider.Resolve<ISerializerManager>(),\nprovider.Resolve<IServiceRouteFactory>(),\nprovider.Resolve<ILogger<ZooKeeperServiceRouteManager>>(),\nprovider.Resolve<IZookeeperClientProvider>(),\nconfigInfo.ZookeeperOptions,\nconfigInfo.ServiceOptions.ServiceRouteOptions.RouteOptions)).InstancePerLifetimeScope();\nreturn this;\n}", "CodeBleu_score": 44.54951890212187}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tmandManager(builder, provider => {\n var result = new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandFactory>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>());\n return result;\n });\n return this;\n }", "CodeBleu_score": 69.15656589084026}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tmandManager(builder, provider => {\n var result = new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandFactory>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>());\n return result;\n });\n return this;\n }", "CodeBleu_score": 69.15656589084026}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tandManager(builder, provider =>\n{\nvar result = new ZooKeeperServiceCommandManager(\nGetConfigInfo(configInfo),\nprovider.GetRequiredService<ISerializer<byte[]>>(),\nprovider.GetRequiredService<ISerializer<string>>(),\nprovider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\nprovider.GetRequiredService<IZookeeperClientProvider>());\nreturn result;\n});\nreturn this;\n}", "CodeBleu_score": 65.6396472180126}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\n}", "CodeBleu_score": 8.134950704445524}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null)\n{\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path))\n{\nthrow new ArgumentNullException(nameof(path));\n}\nif (provider == null)\n{\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\nvar source = new ZookeeperConfigurationSource\n{\nFileProvider = provider,\nPath = path,\nOptional = optional,\nReloadOnChange = reloadOnChange\n};\nbuilder.Add(source);\nreturn builder;\n}", "CodeBleu_score": 57.42635925070733}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\n}", "CodeBleu_score": 8.134950704445524}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tait EnterRoutes();\nvar routes = _routes.Select(x => x.Clone()).ToArray();\nforeach (var route in routes) {\nforeach (var address in Address) {\nroute.Addresses.Remove(address);\n}\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 42.341194373875325}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tr routes = await GetRoutesAsync();\nforeach (var route in routes) {\nroute.Addresses.RemoveAll(item => Address.Any(item2 => item2.ToString() == item.ToString()));\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 49.53352112692764}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tr zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nvar routes = await GetRoutesAsync();\nforeach (var serviceRoute in routes) {\nvar nodePath = $\"{path}{serviceRoute.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceRoute);\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nvar onlineRoute = _serializer.Deserialize<ServiceRouteDescriptor>(onlineData);\nvar onlineAddresses = onlineRoute.Addresses.ToList();\nforeach (var address in Address) {\nonlineAddresses.Remove(address);\n}\nonlineRoute.Addresses = onlineAddresses.ToArray();\nnodeData = _serializer.Serialize(onlineRoute);\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\n}", "CodeBleu_score": 49.70730791145444}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nroutes = routes.ToArray();\n\nvar serviceRoutes = await GetRoutes(routes.Select(p => p.ServiceDescriptor.Id));\nforeach (var serviceRoute in serviceRoutes) {\nvar nodePath = $\"{path}{serviceRoute.ServiceDescriptor.Id}\";\nif (serviceRoute.Address.Any(p => p.ToString() == hostAddr.ToString())) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n}\n}", "CodeBleu_score": 47.518700713746945}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nvar routePaths = new List<string>();\nforeach (var route in routes) {\nroutePaths.Add(path + route.ServiceDescriptor.Id);\n}\n\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nvar childData = await zooKeeper.Item2.getDataAsync(childPath);\nvar childRoute = _serializer.Deserialize<ServiceRoute>(childData.Data);\nif (childRoute.Address.Contains(hostAddr)) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 46.334237471558005}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (routes.Any(p => p.ServiceDescriptor.Id == child)) {\nvar data = await zooKeeper.Item2.getDataAsync(childPath);\nif (data!= null) {\nvar route = _serializer.Deserialize<ServiceRoute>(data.Data);\nif (route.Address.Any(p => p.ToString() == hostAddr.ToString())) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\n}\n}\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 48.100207594201464}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\nif (this._logger.IsEnabled(LogLevel.Debug)) {\nthis._logger.LogDebug(data);\n}\nvar route = this._serializer.Deserialize<ServiceRouteDescriptor>(data);\nreturn this._serviceRouteFactory(route.ServiceDescriptor, route.Address);\n}", "CodeBleu_score": 31.83428589778664}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug(\\\"Deserializing route data.\\\");\n}\n\nvar route = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nif (_logger.IsEnabled(LogLevel.Debug)) {\n_logger.LogDebug(route.ToString());\n}\n\nreturn await _serviceRouteFactory.Create(route);\n}", "CodeBleu_score": 41.53767117710678}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null) {\nreturn null;\n}\nif (this.logger.IsEnabled(LogLevel.Debug)) {\nthis.logger.LogDebug(string.Format(\\\"Deserializing route data: {0}\\\", data));\n}\nvar routeDescriptor = this.serializer.Deserialize<ServiceRouteDescriptor>(data);\nreturn await this.serviceRouteFactory.Create(routeDescriptor);\n}", "CodeBleu_score": 37.02358588727526}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData))\nreturn;\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\nvar oldRouteId = oldRoute.ServiceDescriptor.Id;\nvar newRouteId = newRoute.ServiceDescriptor.Id;\nif (oldRouteId!= newRouteId) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"The route id of the node changed from {oldRouteId} to {newRouteId}.\");\nreturn;\n}\nlock (_lock) {\nvar index = _routes.FindIndex(i => i.ServiceDescriptor.Id == oldRouteId);\nif (index >= 0) {\n_routes[index] = newRoute;\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"The route of the node has been changed. The new route is {newRoute}.\");\nOnChanged?.Invoke(this, new ServiceRouteEventArgs(oldRoute, newRoute));\n}", "CodeBleu_score": 40.00928644899043}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\nif (DataEquals(oldData, newData))\nreturn;\n\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\n\nlock (_sync) {\nvar index = _routes.IndexOf(oldRoute);\nif (index >= 0) {\n_routes[index] = newRoute;\n}\n}\n\nOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 27.97996399846533}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8def\u7531\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nif (oldData!= null && DataEquals(oldData, newData))\nreturn;\n\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\n\nlock (_lock) {\nvar index = _routes.FindIndex(p => p.ServiceDescriptor.Id == oldRoute.ServiceDescriptor.Id);\nif (index >= 0)\n_routes[index] = newRoute;\n}\n\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u4fee\u6539\u6210\u529f\u3002\");\n\nOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 39.336288244116446}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\t\tvar path = _configInfo.SubscriberPath;\n\t\tif (!path.EndsWith(\"/\"))\n\t\t\tpath += \"/\";\n\t\tsubscribers = subscribers.ToArray();\n\t\tif (_subscribers!= null) {\n\t\t\tvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\t\tvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\t\tvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\n\t\t\tforeach (var deletedSubscriberId in deletedSubscriberIds) {\n\t\t\t\tvar nodePath = $\"{path}{deletedSubscriberId}\";\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(nodePath);\n\t\t\t}\n\t\t}\n\t\tforeach (var serviceSubscriber in subscribers) {\n\t\t\tvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\n\t\t\tvar nodeData = _serializer.Serialize(serviceSubscriber);\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\t\t\t\tawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t} else {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\t\t\t\tvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\n\t\t\t\tif (!DataEquals(nodeData, onlineData))\n\t\t\t\t\tawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n\t\t\t}\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n\t}\n}", "CodeBleu_score": 37.66866287582308}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nsubscribers = subscribers.ToArray();\nif (_subscribers!= null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 36.26017453998902}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tr zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nsubscribers = subscribers.ToArray();\nif (_subscribers!= null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.38111765882275}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in childrens) {\nvar nodePath = $\"{_configInfo.SubscriberPath}{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u8282\u70b9\uff1a{nodePath}\u3002\");\nvar subscriber = await GetSubscriber(nodePath);\nif (subscriber!= null)\nsubscribers.Add(subscriber);\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 43.88771658322894}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{string.Join(\",\", childrens)}\u3002\");\n\n\tvar subscribers = new List<ServiceSubscriber>();\n\tforeach (var children in childrens) {\n\t\tvar nodePath = $\"{_configInfo.SubscriberPath}{children}\";\n\t\tif (await _zookeeperClientProvider.GetZooKeeper().Item2.existsAsync(nodePath)!= null) {\n\t\t\tvar data = (await _zookeeperClientProvider.GetZooKeeper().Item2.getDataAsync(nodePath)).Data;\n\t\t\tvar subscriber = await GetSubscriber(data);\n\t\t\tif (subscriber!= null)\n\t\t\t\tsubscribers.Add(subscriber);\n\t\t}\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 48.35591170078746}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar path = _configInfo.SubscriberPath;\n\tif (!path.EndsWith(\"/\"))\n\t\tpath += \"/\";\n\tforeach (var child in childrens) {\n\t\tvar nodePath = $\"{path}{child}\";\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t_logger.LogDebug($\"\u51c6\u5907\u83b7\u53d6\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\t\tvar data = (await _zookeeperClientProvider.GetZooKeeper().Item2.getDataAsync(nodePath)).Data;\n\t\tvar subscriber = await GetSubscriber(data);\n\t\tif (subscriber!= null)\n\t\t\tsubscribers.Add(subscriber);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 55.302200039232744}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\tvar zooKeeper = await GetZooKeeper();\n\tif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath) == null) {\n\t\t_logger.LogWarning($\"\u8282\u70b9{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\uff0c\u5c06\u4e0d\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\t\t_subscribers = new ServiceSubscriber[0];\n\t\treturn;\n\t}\n\tvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\n\t_subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 49.38272653431739}, {"code": "private async Task EnterSubscribers(){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeeper = await GetZooKeeper();\nif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath)!= null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u51c6\u5907\u83b7\u53d6\u8ba2\u9605\u8005\u8282\u70b9\u3002\");\nvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\nvar subscribers = new List<ServiceSubscriber>(childrens.Count());\nforeach (var children in childrens) {\nvar subscriber = await GetSubscriber($\"/Subscriber/{children}\");\nif (subscriber!= null)\nsubscribers.Add(subscriber);\n}\n_subscribers = subscribers.ToArray();\n} else {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning(\"\u670d\u52a1\u8ba2\u9605\u8005\u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u5c06\u521d\u59cb\u5316\u4e3a\u7a7a\u3002\");\n_subscribers = new ServiceSubscriber[0];\n}\n}", "CodeBleu_score": 54.89497638390708}, {"code": "private async Task EnterSubscribers(){\n\t\tvar zooKeeper = await GetZooKeeper();\n\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\tif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath)!= null) {\n\t\tvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\n\t\t_subscribers = await GetSubscribers(childrens);\n\t} else {\n\t\t_logger.LogWarning($\\\"\u8282\u70b9\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\u3002\\\");\n\t\t_subscribers = new ServiceSubscriber[0];\n\t}\n}", "CodeBleu_score": 48.285128577363054}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\tvar oldCommand = GetServiceCommand(oldData);\n\tvar newCommand = GetServiceCommand(newData);\n\tif (oldCommand!= null && newCommand!= null && oldCommand.ServiceId == newCommand.ServiceId) {\n\t\tlock (_serviceCommands) {\n\t\t\t_serviceCommands = _serviceCommands\n\t\t\t\t.Where(i => i.ServiceId!= newCommand.ServiceId)\n\t\t\t\t.Concat(new[] { newCommand }).ToArray();\n\t\t}\n\t\tOnChanged(new ServiceCommandChangedEventArgs(newCommand, oldCommand));\n\t}\n}", "CodeBleu_score": 68.30564467097618}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\n}", "CodeBleu_score": 4.681651116799029}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t// Get the old service command.\nvar oldCommand = _serviceCommands.FirstOrDefault(i => i.ServiceId == newCommand.ServiceId);\n\nlock (_serviceCommands) {\n// Delete the old service command and add the new one.\n_serviceCommands = _serviceCommands.Where(i => i.ServiceId!= newCommand.ServiceId).Concat(new[] { newCommand }).ToArray();\n}\n\n// Trigger the OnChanged event with the new and old commands.\nOnChanged(new ServiceCommandChangedEventArgs(newCommand, oldCommand));\n}", "CodeBleu_score": 60.827305002006746}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\n// Get the updated data from the node asynchronously using a ZooKeeper client.\nvar (manualResetEvent, zooKeeper) = await _zooKeeperCall();\nvar data = await zooKeeper.GetDataAsync(Path, Watcher);\n\n// Execute the specified action with the current and new data.\n_action(_currentData, data);\n\n// Update the watcher with the new data.\n_currentData = data;\n\n// Reset the manual reset event.\nmanualResetEvent.Set();\n}", "CodeBleu_score": 45.418984070437915}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\nif (watchedEvent.State == KeeperState.SyncConnected) {\n\n// If the watched event is a NodeDataChanged event, retrieve the updated data asynchronously.\nif (watchedEvent.Type == EventType.NodeDataChanged) {\n\n// Create a ManualResetEvent to wait for the ZooKeeper client to retrieve the updated data.\nManualResetEvent waitHandle = new ManualResetEvent(false);\n\n// Retrieve the updated data from the node asynchronously using a ZooKeeper client.\nValueTask<(ManualResetEvent, ZooKeeper)> zooKeeperTask = _zooKeeperCall();\n\n// Wait for the ZooKeeper client to retrieve the updated data.\nwaitHandle.WaitOne();\n\n// Get the ZooKeeper client from the task.\nZooKeeper zooKeeper = zooKeeperTask.Result.Item2;\n\n// Get the updated data from the node.\nbyte[] newData = await zooKeeper.GetDataAsync(Path, false);\n\n// Execute the specified action with the current and new data.\n_action(_currentData, newData);\n\n// Update the watcher with the new data.\n_currentData = newData;\n}\n}\n}", "CodeBleu_score": 48.21159752707054}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\nvar (manualResetEvent, zooKeeper) = await _zooKeeperCall();\ntry {\nvar data = await zooKeeper.GetDataAsync(watchedEvent.Path);\n_action(_currentData, data);\n_currentData = data;\n}\ncatch (KeeperException ex) {\nif (ex.Code == KeeperException.Code.SessionExpired) {\nawait manualResetEvent.WaitAsync();\n}\nelse {\nthrow;\n}\n}\nfinally {\nzooKeeper.Dispose();\n}\n}\n}", "CodeBleu_score": 52.260756118633786}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t.UseZookeeperClientProvider(provider => new DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>(),\nprovider.GetRequiredService<IZookeeperAddressSelector>(),\nprovider.GetRequiredService<IHealthCheckService>()));\n}", "CodeBleu_score": 56.698440653277316}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tes.RegisterType<DefaultZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nreturn builder;\n}", "CodeBleu_score": 26.763838346372932}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tes.RegisterZookeeperClientProvider(configInfo);\nreturn builder;\n}", "CodeBleu_score": 16.59788414051606}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tr zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\nforeach (var route in routes) {\nvar routePath = $\"{_configInfo.MqttRoutePath}/{route.Id}\";\nvar data = _serializer.Serialize(route);\nif (await zooKeeper.Item2.existsAsync(routePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u6dfb\u52a0\uff1a{routePath}\u3002\");\nawait zooKeeper.Item2.createAsync(routePath, data, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u66f4\u65b0\uff1a{routePath}\u3002\");\nawait zooKeeper.Item2.setDataAsync(routePath, data);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6dfb\u52a0\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 53.49018050637989}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tr zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 44.8197223188527}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\tr zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 44.8197223188527}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tzooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 46.60376822898349}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tzooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 46.60376822898349}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tzooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 46.60376822898349}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tr caches = await GetCaches(cacheDescriptors.Select(p => p.Id));\nawait RemoveCachesAsync(caches);\nawait base.SetCachesAsync(cacheDescriptors);\n}", "CodeBleu_score": 6.867798699091436}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t (Logger.IsEnabled(LogLevel.Information)) {\nLogger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\n}\nvar cacheDescriptorsList = cacheDescriptors.ToList();\nvar cacheDescriptorsCount = cacheDescriptorsList.Count;\nvar zooKeepers = await ZookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = ConfigInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (Logger.IsEnabled(LogLevel.Debug)) {\nLogger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\n}\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (Logger.IsEnabled(LogLevel.Debug)) {\nLogger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\n}\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (Logger.IsEnabled(LogLevel.Information)) {\nLogger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u6dfb\u52a0\u5b8c\u6210\u3002\");\n}\n}\n}", "CodeBleu_score": 49.29914673623942}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t (Logger.IsEnabled(LogLevel.Information))\nLogger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\nvar zooKeepers = await ZookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = ConfigInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (Logger.IsEnabled(LogLevel.Debug))\nLogger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (Logger.IsEnabled(LogLevel.Debug))\nLogger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (Logger.IsEnabled(LogLevel.Information))\nLogger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u6dfb\u52a0\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 47.85195535569936}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t(_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u8282\u70b9\uff1a{path}\u3002\\\");\n\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\\\"{nodePath}/{child}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\\\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\\\");\n}", "CodeBleu_score": 54.61165141370008}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t(path.StartsWith(\\\"/\\\") && path.Length > 1) {\npath = path.Substring(1);\n}\nif (path.EndsWith(\\\"/\\\") && path.Length > 1) {\npath = path.Substring(0, path.Length - 1);\n}\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\\\"{nodePath}/{child}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\\\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\\\");\n}", "CodeBleu_score": 51.5682979590955}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\u8282\u70b9\uff1a{path}\u3002\");\n\n\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\tvar index = 0;\n\twhile (childrens.Count() > 1) {\n\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\tif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\n\t\t\tvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\n\t\t\tif (result?.Children!= null) {\n\t\t\t\tforeach (var child in result.Children) {\n\t\t\t\t\tvar childPath = $\"{nodePath}/{child}\";\n\t\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\n\t\t\t\t\tawait zooKeeper.Item2.deleteAsync(childPath);\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\n\t\t\tawait zooKeeper.Item2.deleteAsync(nodePath);\n\t\t}\n\t\tindex++;\n\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t}\n\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 56.69014374871655}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tresult = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _config.Addresses) {\nif (!await _healthCheckService.IsHealth(address)) {\ncontinue;\n}\nvar connectionWait = new ManualResetEvent(false);\nvar zooKeeper = new ZooKeeper($\\\"{address.Ip}:{address.Port}\\\", (int)_config.SessionTimeout.TotalMilliseconds\n, new ReconnectionWatcher(\n() => {\nconnectionWait.Set();\n},\n() => {\nconnectionWait.Close();\n},\nasync () => {\nconnectionWait.Reset();\nif (result.Any(x => x.Item2.Address.Equals(address))) {\nawait x.Item2.closeAsync();\nx.Item1.Close();\n}\nresult.Add(CreateZooKeeper(address));\n}));\nresult.Add((connectionWait, zooKeeper));\n}\nreturn result;\n}", "CodeBleu_score": 63.18327390931688}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t", "CodeBleu_score": 7.549424158321882}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tresult = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _config.Addresses) {\nif (!await _healthCheckService.IsHealth(address)) {\ncontinue;\n}\nvar connectionWait = new ManualResetEvent(false);\nvar zooKeeper = new ZooKeeper($\"{address.Ip}:{address.Port}\", (int)_config.SessionTimeout.TotalMilliseconds, new ReconnectionWatcher(\n() => {\nconnectionWait.Set();\n},\n() => {\nconnectionWait.Close();\n},\nasync () => {\nconnectionWait.Reset();\nif (result.TryRemove(address, out (ManualResetEvent, ZooKeeper) value)) {\nawait value.Item2.closeAsync();\nvalue.Item1.Close();\n}\nresult.Add(CreateZooKeeper(address));\n}));\nresult.Add((connectionWait, zooKeeper));\n}\nreturn result;\n}", "CodeBleu_score": 62.917091466991025}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\ter!= null)? helper.getZooKeeper() : null;\n}", "CodeBleu_score": 5.370360987792858}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\ter!= null)? helper.getZooKeeper() : null;\n}", "CodeBleu_score": 5.370360987792858}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\ter!= null)? helper.getZooKeeper() : null;\n}", "CodeBleu_score": 5.370360987792858}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t", "CodeBleu_score": 3.816105150353958}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\toKeeper = getZooKeeper();\nif (zooKeeper!= null) {\nif (waitForShutdownTimeoutMs > 0) {\nzooKeeper.register(new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\n// do nothing\n}\n});\n\ntry {\nzooKeeper.close(waitForShutdownTimeoutMs);\n} catch (InterruptedException e) {\nThread.currentThread().interrupt();\nthrow e;\n}\n} else {\nzooKeeper.close();\n}\n}\n}", "CodeBleu_score": 36.13742882935832}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t null) {\nZooKeeper zooKeeper = helper.getZooKeeper();\nif (zooKeeper!= null) {\nif (waitForShutdownTimeoutMs > 0) {\n// register a dummy watcher to clear the default watcher\n// this prevents new events from being processed\nzooKeeper.register(new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\n}\n});\n// wait for the shutdown\ntry {\nzooKeeper.waitUntilConnected(waitForShutdownTimeoutMs);\n} catch (InterruptedException e) {\n// restore the interrupted status\nThread.currentThread().interrupt();\nthrow e;\n}\n}\nzooKeeper.close();\n}\n}\n}", "CodeBleu_score": 37.4315892278191}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlong startTime = System.currentTimeMillis();\n\ttry {\n\t\tstate.blockUntilConnected();\n\t\treturn true;\n\t} finally {\n\t\tlong endTime = System.currentTimeMillis();\n\t\tlog.info(String.format(\"blockUntilConnectedOrTimedOut took [%d] ms\", endTime - startTime));\n\t}\n}", "CodeBleu_score": 36.35628029920253}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (started.get()) {\n\t\treturn state.blockUntilConnectedOrTimedOut(connectionTimeoutMs);\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 8.091156608838526}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlong start = System.currentTimeMillis();\n\tlog.info(\"Waiting for connection to ZooKeeper...\");\n\tboolean connected = state.blockUntilConnectedOrTimedOut();\n\tlog.info(\"Connected to ZooKeeper in {}ms\", System.currentTimeMillis() - start);\n\n\treturn connected;\n}", "CodeBleu_score": 51.28336581758579}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\tlog.info(\"Closing with timeout: \" + waitForShutdownTimeoutMs);\n\t} else {\n\t\tlog.info(\"Closing\");\n\t}\n\n\tif (!started.compareAndSet(true, false)) {\n\t\tlog.warn(\"Already closed\");\n\t\treturn;\n\t}\n\n\tstate.close(waitForShutdownTimeoutMs);\n}", "CodeBleu_score": 35.32367447442176}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t", "CodeBleu_score": 3.4191050759018156}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlog.debug(\"Closing\");\n\n\tOperationTrace trace = startAdvancedTracer(\"close\");\n\n\ttry {\n\t\tinternalClose(waitForShutdownTimeoutMs);\n\t} catch (InterruptedException e) {\n\t\tlog.warn(\"Interrupted while closing\", e);\n\t}\n\n\ttrace.commit();\n}", "CodeBleu_score": 34.95626696920008}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t", "CodeBleu_score": 1.4312056341607657}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\n\tOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\n\tint remainingWaitMs = connectionTimeoutMs;\n\twhile (remainingWaitMs > 0) {\n\t\tif (state.isConnected()) {\n\t\t\ttrace.commit();\n\n\t\t\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + state.isConnected());\n\t\t\treturn;\n\t\t}\n\n\t\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() waiting for connection. remainingWaitMs: \" + remainingWaitMs);\n\n\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\tstate.addParentWatcher(new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() connection event received: \" + event);\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t});\n\n\t\ttry {\n\t\t\tlatch.await(remainingWaitMs, TimeUnit.MILLISECONDS);\n\t\t} catch (InterruptedException e) {\n\t\t\tThreadUtils.checkInterrupted(e);\n\t\t\tthrow e;\n\t\t} finally {\n\t\t\tstate.removeParentWatcher(this);\n\t\t}\n\n\t\tremainingWaitMs -= connectionTimeoutMs;\n\t}\n\n\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + state.isConnected());\n\ttrace.commit();\n}", "CodeBleu_score": 34.5510694523317}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tif (log.isDebugEnabled()) {\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\n}\nOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\nlong startTime = System.currentTimeMillis();\nlong remainingWaitTime = connectionTimeoutMs;\nlong lastWaitTime = startTime;\nwhile (remainingWaitTime > 0) {\nif (state.isConnected()) {\nbreak;\n}\n\n// Add a temporary watcher to monitor connection events.\n// The watcher is removed after each wait cycle, and the remaining wait time is adjusted accordingly.\nWatcher watcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nif (log.isDebugEnabled()) {\nlog.debug(\"Connection event received: \" + event);\n}\n\nif (event.getType() == Event.EventType.None && event.getState() == Event.KeeperState.SyncConnected) {\n// The connection has been established.\n// Remove the temporary watcher and exit the wait loop.\nstate.removeParentWatcher(this);\nbreak;\n}\n}\n};\nstate.addParentWatcher(watcher);\n\n// Wait for either the connection or a timeout.\n// The countdown latch is used to wait for either the connection or a timeout.\nCountDownLatch latch = new CountDownLatch(1);\ntry {\nlatch.await(remainingWaitTime, TimeUnit.MILLISECONDS);\n} catch (InterruptedException e) {\nThreadUtils.checkInterrupted(e);\nthrow e;\n}\n\n// Remove the temporary watcher.\nstate.removeParentWatcher(watcher);\n\n// Calculate the remaining wait time.\nlong currentTime = System.currentTimeMillis();\nlong elapsedTime = currentTime - lastWaitTime;\nlastWaitTime = currentTime;\nremainingWaitTime -= elapsedTime;\n}\n\ntrace.commit();\n\nif (log.isDebugEnabled()) {\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + state.isConnected());\n}\n}", "CodeBleu_score": 41.475002691121766}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (doProtected() && (sessionId!= 0) && createMode.isEphemeral()) {\n\t\tlong newSessionId = client.getZooKeeper().getSessionId();\n\t\tif (newSessionId!= sessionId) {\n\t\t\tlog.warn(\\\"Session ID has changed from {} to {} - deleting old node: {}\\\", sessionId, newSessionId, foundNode);\n\t\t\tclient.getZooKeeper().delete().forPath(foundNode);\n\t\t\tsessionId = newSessionId;\n\t\t}\n\t}\n\treturn foundNode;\n}", "CodeBleu_score": 40.77089268085449}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (doProtected() && (sessionId!= 0) && (sessionId!= client.getZooKeeper().getSessionId())) {\nlog.warn(\\\"Session ID changed.  Deleting old node: {}\\\", foundNode);\nclient.getZooKeeper().delete().forPath(foundNode);\nsessionId = client.getZooKeeper().getSessionId();\n}\nreturn foundNode;\n}", "CodeBleu_score": 28.559237759458423}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (doProtected() && (sessionId!= 0) && createMode.isEphemeral()) {\nlong currentSessionId = client.getZooKeeper().getSessionId();\nif (sessionId!= currentSessionId) {\nlog.info(\\\"Protected mode session ID has changed, deleting old node\\\");\nclient.getZooKeeper().delete().forPath(foundNode);\nsessionId = currentSessionId;\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 37.6900989711638}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\trationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\n\tRetryLoop retryLoop = new RetryLoop(client.getZookeeperClient(), client.getZooKeeper(), client.getRetryPolicy(), trace);\n\tCallable<Stat> callable = new Callable<Stat>() {\n\t\t@Override\n\t\tpublic Stat call() throws Exception {\n\t\t\treturn client.getZooKeeper().setACL(path, aclList, version);\n\t\t}\n\t};\n\treturn retryLoop.call(callable);\n}", "CodeBleu_score": 72.48627468296706}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tl OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\ntry {\nRetryLoop retryLoop = new RetryLoop(client.getZookeeperClient(), client.getZookeeperClient().getZxid(), client.getZookeeperClient().getZxid());\nretryLoop.start(new Callable<Stat>() {\n@Override\npublic Stat call() throws Exception {\nStat stat = client.getZooKeeper().setACL(path, aclList, version);\ntrace.setReturnCode(0).setPath(path).setStat(stat).commit();\nreturn stat;\n}\n});\nreturn retryLoop.getResult();\n} finally {\ntrace.commit();\n}\n}", "CodeBleu_score": 60.756244297180494}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tl OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\ntry {\nRetryLoop retryLoop = new RetryLoop(client.getZookeeperClient().getZooKeeper(), client.getZookeeperClient().getZooKeeperTimeout(), client.getZookeeperClient().getRetryPolicy());\nretryLoop.start(new Callable<Stat>() {\n@Override\npublic Stat call() throws Exception {\nStat stat = new Stat();\nclient.getZooKeeper().setACL(path, aclList, version, stat);\nreturn stat;\n}\n});\nreturn retryLoop.getLastResult();\n} finally {\ntrace.commit();\n}\n}", "CodeBleu_score": 57.10631593903681}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t", "CodeBleu_score": 9.224495547481085}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t", "CodeBleu_score": 9.224495547481085}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tthis(client, membershipPath, thisId, payload, CreateMode.EPHEMERAL);\n}", "CodeBleu_score": 12.170290392892221}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n// create a node at the given path asynchronously\nCompletionStage<String> createStage = async.create().forPath(path);\n\n// set up a watch on the node to handle future events\ncreateStage.thenAccept(name -> async.checkExists().inBackground((event) -> {\nSystem.out.println(\\\"Node exists: \\\" + event.getResultCode());\n}, WatchMode.POST_CHECKIN_OR_DELETE));\n\n// handle exceptions\ncreateStage.exceptionally(exception -> {\nexception.printStackTrace();\nreturn null;\n});\n}", "CodeBleu_score": 46.47670978239185}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); // normally you'd wrap early in your app and reuse the instance\n\n// create a node at the given path asynchronously\nasync.create().forPath(path).whenComplete((name, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Created node name is: \" + name);\n\n// set up a watch on the node to handle future events\nasync.getData().usingWatcher(new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nSystem.out.println(\"Got event: \" + event.getType());\n}\n}).forPath(path);\n}\n});\n}", "CodeBleu_score": 70.38237922294852}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n// create a node at the given path asynchronously\nasync.create().forPath(path).whenComplete((name, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\\\"Created node name is: \\\" + name);\n\n// set up a watch on the node to handle future events\nasync.getData().usingWatcher(new Watcher() {\npublic void process(WatchedEvent event) {\nSystem.out.println(\\\"Got event: \\\" + event);\n}\n}).forPath(path);\n}\n});\n}", "CodeBleu_score": 65.10702676068291}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\tist<OpResult> resultList = client.getZookeeperClient().multi(transaction.getOperations());\n\nif (resultList.size()!= transaction.metadataSize()) {\nthrow new IllegalStateException(String.format(\n\"Result size (%d) doesn't match input size (%d)\", resultList.size(), transaction.metadataSize()));\n}\n\nint error = 0;\nfor (OpResult opResult : resultList) {\nif (opResult.getType() == OpResult.Type.error) {\nOpResult.ErrorResult errorResult = (OpResult.ErrorResult) opResult;\nerror = errorResult.getErr();\nbreak;\n}\n}\n\nif (error!= 0) {\nthrow KeeperException.create(KeeperException.Code.get(error), null);\n}\n\nreturn resultList;\n}", "CodeBleu_score": 40.25572600773189}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tist<OpResult> results = new ArrayList<OpResult>();\nfor (Op op : transaction.getOps()) {\nresults.add(client.getZookeeperClient().multi(op));\n}\nif (results.get(0).getType() == OpResult.Type.error) {\nOpResult.ErrorResult errorResult = (OpResult.ErrorResult) results.get(0);\nKeeperException.Code errorCode = KeeperException.Code.get(errorResult.getErr());\nthrow KeeperException.create(errorCode, errorResult.getPath());\n}\nreturn results;\n}", "CodeBleu_score": 41.544180591425665}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tist<OpResult> resultList = new ArrayList<>();\nList<Op> ops = transaction.getOps();\ntry {\nresultList = client.getZookeeperClient().multi(ops);\n} catch (KeeperException.ConnectionLossException e) {\n// ZK-1189: If the connection is lost, we need to re-execute the transaction\n// and retry the operation.\nresultList = doOperation();\n}\nif (resultList.size()!= transaction.metadataSize()) {\nthrow new IllegalStateException(String.format(\n\"Result size (%d) doesn't match input size (%d)\",\nresultList.size(),\ntransaction.metadataSize()));\n}\nif (resultList.get(0).getType() == OpResult.ErrorResult.class) {\nthrow KeeperException.create(KeeperException.Code.get(resultList.get(0).getErr()),\n\"Transaction failed\");\n}\nreturn resultList;\n}", "CodeBleu_score": 35.92647987285507}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tshows how to use a ServiceDiscovery instance\n\t// in a real application you'd create the ServiceDiscovery instance early for the service(s) you're interested in\n\n\tCollection<String> services = serviceDiscovery.queryForNames();\n\tfor (String serviceName : services) {\n\t\tSystem.out.println(serviceName);\n\t\tCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.107667141507655}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tmethod retrieves and prints the service names and their instances from the given ServiceDiscovery instance.\n\t// It queries for all service names and their corresponding instances, printing each service name and its instances.\n\t// If no instances are registered, it catches the NoNodeException and prints an error message.\n\t// Finally, it closes the ServiceDiscovery instance quietly.\n\n\tCollection<String> services = serviceDiscovery.queryForNames();\n\tif (services.isEmpty()) {\n\t\tSystem.out.println(\\\"No services registered\\\");\n\t} else {\n\t\tfor (String service : services) {\n\t\t\tSystem.out.println(service);\n\t\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\n\t\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\t\toutputInstance(instance);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 49.38811076987715}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tmethod is scaffolding to get the example up and running\n\n\t// This method retrieves and prints the service names and their instances from the given ServiceDiscovery instance.\n\t// It queries for all service names and their corresponding instances, printing each service name and its instances.\n\t// If no instances are registered, it catches the NoNodeException and prints an error message.\n\t// Finally, it closes the ServiceDiscovery instance quietly.\n\n\t// Query for all service names and their corresponding instances.\n\tMap<String, InstanceDetails> instances = serviceDiscovery.queryForInstances(null);\n\n\t// Iterate through the instances and print the service name and its instances.\n\tfor (Map.Entry<String, InstanceDetails> entry : instances.entrySet()) {\n\t\tSystem.out.println(\"Service Name: \" + entry.getKey());\n\t\tSystem.out.println(\"Instances: \" + entry.getValue());\n\t}\n\n\t// Close the ServiceDiscovery instance quietly.\n\tCloseableUtils.closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 30.662601433060438}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\ting> sortedChildren = Lists.newArrayList();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tsortedChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(sortedChildren);\n\treturn sortedChildren;\n}", "CodeBleu_score": 25.194074309100507}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t", "CodeBleu_score": 7.984770309765142}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t", "CodeBleu_score": 7.984770309765142}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 20.518259528243515}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t//    if (zk!= null) {\n//        zk.close();\n//    }\n//    String[] hostAndPort = newHost.split(\":\");\n//    int port = Integer.parseInt(hostAndPort[1]);\n//    host = hostAndPort[0];\n//    zk = new ZooKeeper(host, port, new Watcher() {\n//        public void process(WatchedEvent event) {\n//            if (event.getState() == Event.KeeperState.SyncConnected) {\n//                connected = true;\n//            }\n//        }\n//    });\n//    if (readOnly) {\n//        zk.setReadOnly();\n//    }\n}", "CodeBleu_score": 4.125715113000573}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tString[] hostPort = newHost.split(\":\");\n\tif (hostPort.length!= 2) {\n\t\tthrow new IllegalArgumentException(\"Invalid host:port string: \" + newHost);\n\t}\n\thost = newHost;\n\tzk = new ZooKeeper(hostPort[0], timeout, this);\n\tif (readOnly) {\n\t\tzk.addAuthInfo(\"digest\", \"anyone:anyone\".getBytes());\n\t}\n\tcommandCount = 0;\n\toutputStream.write((\"Connecting to \" + host + \"...\\r\n\").getBytes());\n}", "CodeBleu_score": 38.73309792715294}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acl = new ArrayList<>();\nString[] aclList = aclString.split(\",\");\nfor (String aclSegment : aclList) {\nString[] parts = aclSegment.split(\":\");\nif (parts.length!= 3) {\nthrow new IOException(\\\"Invalid ACL specification \\\" + aclSegment);\n}\nId id = new Id(parts[0], parts[1]);\nint perms = Integer.parseInt(parts[2]);\nacl.add(new ACL(perms, id));\n}\nreturn acl;\n}", "CodeBleu_score": 17.408553182974977}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> aclList = new ArrayList<>();\n\tString[] aclEntries = aclString.split(\",\");\n\tfor (String aclEntry : aclEntries) {\n\t\tString[] parts = aclEntry.split(\":\");\n\t\tif (parts.length!= 3) {\n\t\t\tthrow new IOException(\"ACL entry \" + aclEntry + \" does not have 3 parts\");\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tString perms = parts[2];\n\t\tif (scheme.equals(\"world\")) {\n\t\t\tid = \"anyone\";\n\t\t}\n\t\tif (id.equals(\"anyone\")) {\n\t\t\taclList.add(new ACL(Perms.fromStrings(perms), Id.ANYONE_ID_UNSAFE));\n\t\t} else {\n\t\t\taclList.add(new ACL(Perms.fromStrings(perms), new Id(scheme, id)));\n\t\t}\n\t}\n\treturn aclList;\n}", "CodeBleu_score": 27.53083524119406}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> aclList = new ArrayList<ACL>();\n\tString[] aclStrings = aclString.split(\",\");\n\tfor (String acl : aclStrings) {\n\t\tString[] parts = acl.split(\":\");\n\t\tif (parts.length!= 3) {\n\t\t\tthrow new IOException(\"ACL string \" + acl + \" is not in the expected format.\");\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tString perms = parts[2];\n\t\tint perm = 0;\n\t\tif (perms.contains(\"r\")) {\n\t\t\tperm |= ZooDefs.Perms.READ;\n\t\t}\n\t\tif (perms.contains(\"w\")) {\n\t\t\tperm |= ZooDefs.Perms.WRITE;\n\t\t}\n\t\tif (perms.contains(\"c\")) {\n\t\t\tperm |= ZooDefs.Perms.CREATE;\n\t\t}\n\t\tif (perms.contains(\"d\")) {\n\t\t\tperm |= ZooDefs.Perms.DELETE;\n\t\t}\n\t\tif (perms.contains(\"a\")) {\n\t\t\tperm |= ZooDefs.Perms.ADMIN;\n\t\t}\n\t\tif (perms.contains(\"e\")) {\n\t\t\tperm |= ZooDefs.Perms.ALL;\n\t\t}\n\t\taclList.add(new ACL(perm, new Id(scheme, id)));\n\t}\n\treturn aclList;\n}", "CodeBleu_score": 26.678157836655604}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null || pathList.size() < 1) {\nthrow new IllegalArgumentException(\\\"path list is null\\\");\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).delete(pathList);\n}\n}", "CodeBleu_score": 77.8889743726705}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null) {\nthrow new IllegalArgumentException(\\\"pathList cannot be null\\\");\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).delete(pathList);\n}\n}", "CodeBleu_score": 81.86363050461576}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null || pathList.size() < 20) {\npathList.forEach(path -> {\ntry {\nzookeeperMap.get(serverId).delete(path);\n} catch (Exception e) {\nlog.error(\\\"delete path error \\\" + serverId + \\\" -> \\\" + path, e);\nthrow new IllegalStateException(e);\n}\n});\n} else {\nzookeeperMap.get(serverId).delete(pathList);\n}\n}", "CodeBleu_score": 49.057873943947385}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to Zookeeper at \" + url + \"...\n\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.build();\nvar connection = factory.createAsync(params);\nwriter.write(\"Connected to Zookeeper at \" + url + \"!\n\");\nreturn new Terminal(id, url, connection, new ZooKeeperMain());\n}", "CodeBleu_score": 34.026360004502216}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to \" + url + \"...\");\n\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.build();\n\tvar connection = factory.createAsync(params, List.of());\n\twriter.write(\"Connected.\");\n\tvar zooKeeperMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 30.976905683311372}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t.format(\"Connecting to %s...\n\", url));\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.build();\nvar connection = factory.createAsync(params);\nwriter.write(\"Connected!\n\");\nvar main = new ZooKeeperMain(connection);\nreturn new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 48.55031169752727}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t{\nsshClient.connect(getSshHost(), getSshPort());\nif (getSshPassword()!= null &&!getSshPassword().isBlank()) {\nlog.info(\"use password auth to create ssh-tunnel\");\nsshClient.authPassword(getSshUsername(), getSshPassword());\n} else if (getSshKeyFilePath()!= null &&!getSshKeyFilePath().isBlank()) {\nlog.info(\"use key file {} auth to create ssh-tunnel\", getSshKeyFilePath());\nsshClient.authPublickey(getSshUsername(), getSshKeyFilePath());\n} else {\nlog.info(\"use default key auth to create ssh-tunnel\");\nsshClient.authPublickey(getSshUsername());\n}\n\nParameters param = new Parameters(localhost, localPort, remoteHost, remotePort);\nsshClient.newLocalPortForwarder(param, proxySocket).listen();\n} catch (IOException e) {\nif (e.getClass().getSimpleName().contains(\"Timeout\")) {\nthrow new IllegalStateException(\"SSH connect error by timeout: \" + sshHost, e);\n}\nif (e.getClass().getSimpleName().contains(\"UnknownHost\")) {\nthrow new IllegalStateException(\"SSH connect error by Unknown host \" + sshHost, e);\n}\nlog.error(\"create ssh-tunnel failed\", e);\nthis.close();\nthrow new IllegalStateException(\"create ssh-tunnel failed\", e);\n}\n}", "CodeBleu_score": 21.815221005471674}, {"code": "public void blockUntilConnected(){\n\t{\nsshClient.newLocalPortForwarder(new Parameters(localhost, localPort, remoteHost, remotePort), proxySocket).listen();\n} catch (IOException e) {\nlog.error(\\\"create ssh-tunnel failed\\\", e);\nthis.close();\nthrow new IllegalStateException(\\\"create ssh-tunnel failed\\\", e);\n}\n}", "CodeBleu_score": 20.307253872074686}, {"code": "public void blockUntilConnected(){\n\t{\nint retries = 6;\nwhile (retries > 0) {\ntry {\nsshClient.newLocalPortForwarder(new Parameters(localhost, localPort, remoteHost, remotePort), proxySocket).listen();\nbreak;\n} catch (IOException e) {\nlog.warn(\\\"Failed to establish SSH tunnel connection, retrying ({} retries left)\\\", retries);\nretries--;\nThread.sleep(1000);\n}\n}\nif (retries == 0) {\nlog.error(\\\"Failed to establish SSH tunnel connection after {} retries\\\", retries);\nthis.close();\nthrow new IllegalStateException(\\\"Failed to establish SSH tunnel connection after {} retries\\\", retries);\n}\n} catch (IOException e) {\nlog.error(\\\"create ssh-tunnel failed\\\", e);\nthis.close();\nthrow new IllegalStateException(\\\"create ssh-tunnel failed\\\", e);\n}\n}", "CodeBleu_score": 36.92104107197589}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\nzookeeperDomainService.delete(serverId, pathList);\n} catch (Exception e) {\nlog.error(\"Failed to delete nodes from Zookeeper instance.\", e);\nthrow new IllegalStateException(\"Failed to delete nodes from Zookeeper instance.\");\n}\n}", "CodeBleu_score": 68.56565449222428}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\nzookeeperDomainService.delete(serverId, pathList);\n} catch (Exception e) {\nlog.error(\"Unable to delete node\", e);\nthrow new IllegalStateException(\"Unable to delete node\");\n}\n}", "CodeBleu_score": 71.22966709546363}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\nzookeeperDomainService.delete(serverId, pathList);\n} catch (Exception e) {\nlog.error(\"Failed to delete node\", e);\nthrow new IllegalStateException(\"Failed to delete node\");\n}\n}", "CodeBleu_score": 71.52613891973697}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\ttry {\nvar serverConfig = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfig);\nconfigurationDomainService.decrementConnectTimes(id);\ntreeItemCache.remove(id);\n} catch (Exception e) {\nlog.error(\"disconnect failed\", e);\nthrow new IllegalStateException(e);\n}\n}", "CodeBleu_score": 47.31878569853315}, {"code": "public void disconnect(String id){\n\t", "CodeBleu_score": 3.0412693586377837}, {"code": "public void disconnect(String id){\n\t", "CodeBleu_score": 3.0412693586377837}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\tzookeeperDomainService.startTerminal(serverId, stream);\n}", "CodeBleu_score": 6.1143096581035214}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tfinal ServerConfiguration serverConfiguration = configurationDomainService.getById(serverId).orElseThrow();\n\tfinal String connectionUrl = serverConfiguration.getSshTunnelEnabled()? serverConfiguration.getSshTunnel().getConnectionUrl() : serverConfiguration.getConnectionUrl();\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 45.92993994388039}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// TODO: Implement this method\n\tthrow new UnsupportedOperationException();\n}", "CodeBleu_score": 7.195064860350864}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzookeeperDomainService.executeCommand(id, command);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error executing command {} on server {}\", command, id, e);\n\t\tVToast.error(e.getMessage());\n\t}\n}", "CodeBleu_score": 56.020031796801995}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzookeeperDomainService.executeCommand(id, command);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error executing command {} on server {}: {}\", command, id, e.getMessage());\n\t\tVToast.error(e.getMessage());\n\t}\n}", "CodeBleu_score": 53.98657962943352}, {"code": "public void executeCommand(String id, String command){\n\t\tTry.of(() -> zookeeperDomainService.executeCommand(id, command))\n\t\t.onFailure(e -> {\n\t\t\tlogger.error(\"Failed to execute command: {} on server with ID: {}\", command, id);\n\t\t\tVToast.error(e.getMessage());\n\t\t})\n\t\t.onSuccess(e -> VToast.success(e.getMessage()));\n}", "CodeBleu_score": 39.51322040837827}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\t// Get the file path from the configuration file\n\tString filePath = \"src/main/resources/zookeeper.properties\";\n\n\t// Create an empty Properties object\n\tProperties properties = new Properties();\n\n\t// Check if the file exists\n\tif (Files.exists(Paths.get(filePath))) {\n\t\ttry {\n\t\t\t// Load the properties from the file\n\t\t\tproperties.load(new FileInputStream(filePath));\n\n\t\t\t// Log the loaded properties\n\t\t\tlog.info(\"Loaded ZooKeeper system properties from file: {}\", filePath);\n\t\t} catch (IOException e) {\n\t\t\t// Log an error message if an error occurs\n\t\t\tlog.error(\"Error loading ZooKeeper system properties from file: {}\", filePath, e);\n\t\t}\n\t} else {\n\t\t// Log a message if the file does not exist\n\t\tlog.warn(\"ZooKeeper system properties file not found: {}\", filePath);\n\t}\n\n\t// Return the loaded properties\n\treturn properties;\n}", "CodeBleu_score": 45.272838056022344}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tFile file = new File(\"C:\\\\Users\\\\Administrator\\\\AppData\\\\Roaming\\\\prettyZoo\\\\zookeeper-system.properties\");\n\t\tif (file.exists()) {\n\t\t\tproperties.load(new FileInputStream(file));\n\t\t\tlog.info(\"Loaded Zookeeper system properties from file: \" + file.getAbsolutePath());\n\t\t} else {\n\t\t\tlog.warn(\"Zookeeper system properties file not found: \" + file.getAbsolutePath());\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Failed to load Zookeeper system properties from file\", e);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 46.293388891736434}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t// Create an empty Properties object\nProperties properties = new Properties();\n\n// Get the file path from the configuration\nString filePath = configurationDomainService.get().orElseThrow().getZookeeperSystemPropertiesPath();\n\n// Check if the file exists\nFile file = new File(filePath);\nif (file.exists() && file.isFile()) {\n// Load the properties from the file\ntry (FileInputStream fis = new FileInputStream(file)) {\nproperties.load(fis);\n} catch (IOException e) {\n// Log an error message if an error occurs\nlog.error(\\\"Error loading ZooKeeper system properties from file: {}\\\", e.getMessage(), e);\n}\n} else {\n// Log a message if the file does not exist\nlog.warn(\\\"ZooKeeper system properties file does not exist: {}\\\", filePath);\n}\n\n// Log the loaded properties\nlog.info(\\\"Loaded ZooKeeper system properties: {}\\\", properties);\n\n// Return the Properties object\nreturn properties;\n}", "CodeBleu_score": 40.69865833271741}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\tvar properties = new Properties();\n\ttry (var reader = new StringReader(content)) {\n\t\tproperties.load(reader);\n\t} catch (IOException e) {\n\t\tlog.error(\"load system properties failed\", e);\n\t\tVToast.error(\"load system properties failed\");\n\t\treturn;\n\t}\n\tvar sysPropPath = PrettyZooConfigRepository.SYS_PROP_PATH;\n\ttry {\n\t\tproperties.store(new FileOutputStream(sysPropPath), \"prettyZoo system properties\");\n\t} catch (IOException e) {\n\t\tlog.error(\"save system properties failed\", e);\n\t\tVToast.error(\"save system properties failed\");\n\t}\n}", "CodeBleu_score": 41.14853058089981}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tvar properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tlog.info(\"save system properties success -> {}\", properties);\n\t\tvar sysPropPath = PrettyZooConfigRepository.SYS_PROP_PATH;\n\t\tFiles.createDirectories(Paths.get(sysPropPath).getParent());\n\t\tFiles.write(Paths.get(sysPropPath), properties.toString().getBytes());\n\t} catch (IOException e) {\n\t\tlog.error(\"save system properties failed\", e);\n\t\tVToast.error(\"Save system properties failed\");\n\t}\n}", "CodeBleu_score": 38.48703796124545}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tvar properties = new Properties();\n\ttry {\n\t\tproperties.load(new StringReader(content));\n\t\tlog.info(\"save system properties success -> {}\", properties);\n\t\tvar sysPropPath = PrettyZooConfigRepository.SYS_PROP_PATH;\n\t\tvar file = new File(sysPropPath);\n\t\tif (!file.exists()) {\n\t\t\tfile.createNewFile();\n\t\t}\n\t\tproperties.store(new FileOutputStream(file), null);\n\t} catch (IOException e) {\n\t\t// ignore error and log it\n\t\tlog.error(\"save system properties failed\", e);\n\t\tVToast.error(\"Save system properties failed\");\n\t}\n}", "CodeBleu_score": 36.738458309859915}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\ttry {\nBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nStringBuilder response = new StringBuilder();\nString line;\nwhile ((line = bufferedReader.readLine())!= null) {\nresponse.append(line).append(\"\n\");\n}\nclient.close();\nreturn response.toString();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\n}", "CodeBleu_score": 53.52025706686349}, {"code": "private String response(Socket client){\n\tfinal BufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nfinal StringBuilder builder = new StringBuilder();\nString line;\ntry {\nwhile ((line = reader.readLine())!= null) {\nbuilder.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n} finally {\ntry {\nreader.close();\nclient.close();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\n}\nreturn builder.toString();\n}", "CodeBleu_score": 55.98972751421919}, {"code": "private String response(Socket client){\n\tfinal BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nfinal StringBuilder stringBuilder = new StringBuilder();\ntry {\nString line;\nwhile ((line = bufferedReader.readLine())!= null) {\nstringBuilder.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n} finally {\ntry {\nclient.close();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\n}\nreturn stringBuilder.toString();\n}", "CodeBleu_score": 53.37958823033657}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t", "CodeBleu_score": 3.373706656875291}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t", "CodeBleu_score": 3.373706656875291}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tlog.info(\"Creating Zookeeper connection using Curator\");\n\tCuratorFramework client = null;\n\ttry {\n\t\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\t\tclient = CuratorFrameworkFactory.builder()\n\t\t\t\t.connectString(params.getConnectString())\n\t\t\t\t.sessionTimeoutMs(params.getSessionTimeout())\n\t\t\t\t.connectionTimeoutMs(params.getConnectionTimeout())\n\t\t\t\t.retryPolicy(retryPolicy)\n\t\t\t\t.namespace(params.getNamespace())\n\t\t\t\t.build();\n\t\tclient.start();\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error creating Zookeeper connection using Curator\", e);\n\t\tif (client!= null) {\n\t\t\tclient.close();\n\t\t}\n\t\tthrow new RuntimeException(\"Error creating Zookeeper connection using Curator\", e);\n\t}\n\tlog.info(\"Successfully created Zookeeper connection using Curator\");\n\treturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 38.83815709637124}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tync.compareAndSet(false, true)) {\nlog.info(\\\"Start syncing Zookeeper node data.\\\");\ntreeCache.getListenable().addListener((client, event) -> {\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onEvent(event);\n}\n});\ntry {\ntreeCache.start();\n} catch (Exception e) {\nlog.error(\\\"Error syncing Zookeeper node data.\\\", e);\ntreeCache.close();\nisSync.set(false);\n}\n} else {\nlog.info(\\\"Syncing Zookeeper node data is already in progress.\\\");\n}\n}", "CodeBleu_score": 40.21742843337446}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tync.get()) {\nlog.info(\\\"Sync already in progress.\\\");\nreturn;\n}\nisSync.set(true);\nlog.info(\\\"Sync started.\\\");\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\ntry {\ntreeCache.start();\n} catch (Exception e) {\nlog.error(\\\"Error starting TreeCache.\\\", e);\ntreeCache.close();\n}\n}", "CodeBleu_score": 28.143941364556145}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tync.compareAndSet(false, true)) {\nlog.info(\\\"Syncing Zookeeper nodes for {}\\\", id);\ntreeCache.getListenable().addListener((curatorFramework, curatorEvent) -> {\ntry {\nswitch (curatorEvent.getType()) {\ncase NODE_ADDED:\ncase NODE_UPDATED:\nlisteners.forEach(listener -> {\ntry {\nlistener.nodeChanged(curatorEvent.getData().getPath(), curatorEvent.getData().getData());\n} catch (Exception e) {\nlog.error(\\\"Error while executing listener {}\\\", listener.getClass().getName(), e);\n}\n});\nbreak;\ncase NODE_REMOVED:\nlisteners.forEach(listener -> {\ntry {\nlistener.nodeDeleted(curatorEvent.getData().getPath());\n} catch (Exception e) {\nlog.error(\\\"Error while executing listener {}\\\", listener.getClass().getName(), e);\n}\n});\nbreak;\ndefault:\nbreak;\n}\n} catch (Exception e) {\nlog.error(\\\"Error while executing listener {}\\\", listeners.get(0).getClass().getName(), e);\n}\n});\ntry {\ntreeCache.start();\n} catch (Exception e) {\nlog.error(\\\"Error while starting TreeCache\\\", e);\ntreeCache.close();\nisSync.set(false);\n}\n} else {\nlog.info(\\\"Zookeeper synchronization already in progress for {}\\\", id);\n}\n}", "CodeBleu_score": 44.97124286078156}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\thildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\npathChildrenCache.getListenable().addListener(listener);\npathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 75.40171653329679}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\thildrenCache cache = new PathChildrenCache(client, path, true);\ncache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\ncache.getListenable().addListener(listener);\n}", "CodeBleu_score": 71.1050709136196}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\thildrenCache cache = new PathChildrenCache(client, path, true);\ncache.getListenable().addListener(listener);\ncache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 67.69598000452869}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\tlogger.info(\"Unregister service start\");\nfor (String path : pathList) {\ntry {\ncuratorClient.deletePath(path);\nlogger.info(\"Unregister service success, path: {}\", path);\n} catch (Exception e) {\nlogger.error(\"Unregister service fail, exception: {}\", e.getMessage());\n}\n}\ncuratorClient.close();\n}", "CodeBleu_score": 51.8796917848388}, {"code": "public void unregisterService(){\n\tlogger.info(\"Unregistering service\");\nfor (String path : pathList) {\ntry {\ncuratorClient.deletePath(path);\nlogger.info(\"Successfully unregistered service: {}\", path);\n} catch (Exception e) {\nlogger.error(\"Error unregistering service: {}\", path, e);\n}\n}\ncuratorClient.close();\n}", "CodeBleu_score": 51.62833903100126}, {"code": "public void unregisterService(){\n\tlogger.info(\"Unregistering all services...\");\nfor (String path : pathList) {\ntry {\ncuratorClient.deletePath(path);\nlogger.info(\"Unregistered service: {}\", path);\n} catch (Exception e) {\nlogger.error(\"Failed to unregister service: {}\", path, e);\n}\n}\ncuratorClient.close();\n}", "CodeBleu_score": 50.83107314110815}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\tif (!started) {\ntry {\nclient = completableFuture.get(timeout, TimeUnit.MILLISECONDS);\n} catch (Throwable t) {\nlogger.error(\"Timeout! zookeeper server can not be connected in : \" + timeout + \"ms!\", t);\ncompletableFuture.whenComplete(this::makeClientReady);\n}\nstarted = true;\n} else {\nlogger.warn(\"Zkclient has already been started!\");\n}\nthis.client.subscribeStateChanges(stateListener);\n}", "CodeBleu_score": 22.9994899448367}, {"code": "public void addListener(IZkStateListener listener){\n\tif (started) {\nclient.subscribeStateChanges(listener);\n} else {\ncompletableFuture.whenComplete((zkClient, throwable) -> {\nif (throwable!= null) {\nlogger.error(\\\"Timeout! zookeeper server can not be connected in : \\\" + timeout + \\\"ms!\\\", throwable);\n} else {\nclient.subscribeStateChanges(listener);\n}\n});\n}\n}", "CodeBleu_score": 35.42440774855652}, {"code": "public void addListener(IZkStateListener listener){\n\tif (!started) {\ntry {\nclient = completableFuture.get(timeout, TimeUnit.MILLISECONDS);\nthis.client.subscribeStateChanges(stateListener);\n} catch (Throwable t) {\nlogger.error(\"Timeout! zookeeper server can not be connected in : \" + timeout + \"ms!\", t);\ncompletableFuture.whenComplete(this::makeClientReady);\n}\nstarted = true;\n} else {\nlogger.warn(\"Zkclient has already been started!\");\n}\n}", "CodeBleu_score": 22.9994899448367}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\nthis.client = CuratorFrameworkFactory.builder()\n.connectString(serverAddr)\n.retryPolicy(new RetryNTimes(3, 1000))\n.connectionTimeoutMs(10000)\n.connectionStateListener(new ConnectionStateListener() {\n@Override\npublic void stateChanged(CuratorFramework client, ConnectionState newState) {\nif (newState == ConnectionState.LOST) {\nCuratorZookeeperClient.this.onConnectionLost();\n} else if (newState == ConnectionState.CONNECTED) {\nCuratorZookeeperClient.this.onConnectionEstablished();\n} else if (newState == ConnectionState.RECONNECTED) {\nCuratorZookeeperClient.this.onConnectionReestablished();\n}\n}\n})\n.build();\nif (authority!= null) {\nthis.client.start();\nthis.client.getZookeeperClient().setACL(CreateMode.PERSISTENT.toString(), this.path, this.acl, this.auth);\n} else {\nthis.client.start();\n}\n}", "CodeBleu_score": 47.844631090459735}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\nif (serverAddr == null) {\n\nthrow new IllegalArgumentException(\"serverAddr is null\");\n\n}\n\nthis.serverAddr = serverAddr;\n\nthis.authority = authority;\n\nthis.retryPolicy = new RetryNTimes(3, 5000);\n\nthis.connectionTimeout = 10000;\n\nthis.client = CuratorFrameworkFactory.builder()\n\n.connectString(serverAddr)\n\n.retryPolicy(retryPolicy)\n\n.connectionTimeoutMs(connectionTimeout)\n\n.namespace(namespace)\n\n.build();\n\nif (authority!= null) {\n\nthis.client.start();\n\nthis.client.blockUntilConnected();\n\nthis.client.getACL().addAuthInfo(\"digest\", authority.getBytes());\n\n} else {\n\nthis.client.start();\n\n}\n\nthis.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n\n@Override\n\npublic void stateChanged(CuratorFramework client, ConnectionState newState) {\n\nif (newState == ConnectionState.LOST) {\n\nCuratorZookeeperClient.this.stateListener.stateChanged(StateListener.State.LOST);\n\n} else if (newState == ConnectionState.CONNECTED) {\n\nCuratorZookeeperClient.this.stateListener.stateChanged(StateListener.State.CONNECTED);\n\n} else if (newState == ConnectionState.RECONNECTED) {\n\nCuratorZookeeperClient.this.stateListener.stateChanged(StateListener.State.RECONNECTED);\n\n}\n\n}\n\n});\n\n}", "CodeBleu_score": 49.964332949700825}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis.client = CuratorFrameworkFactory.builder()\n.connectString(serverAddr)\n.retryPolicy(new RetryNTimes(3, 1000))\n.connectionTimeoutMs(10000)\n.authorization(\"digest\", authority.getBytes())\n.connectionStateListener(new ConnectionStateListener() {\n@Override\npublic void stateChanged(CuratorFramework client, ConnectionState newState) {\nswitch (newState) {\ncase LOST:\ncase SUSPENDED:\ncase RECONNECTED:\ncase CONNECTED:\ndefault:\nbreak;\n}\n}\n})\n.build();\nthis.client.start();\n}", "CodeBleu_score": 34.33995853229262}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\tif (childListeners.containsKey(path)) {\nConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener!= null) {\nremoveTargetChildListener(path, targetListener);\n}\n}\n}", "CodeBleu_score": 73.76941690686942}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tif (path == null || listener == null) {\nreturn;\n}\nConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners == null) {\nreturn;\n}\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener!= null) {\nremoveTargetChildListener(path, targetListener);\n}\n}", "CodeBleu_score": 73.48315065196954}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners!= null) {\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener!= null) {\nremoveTargetChildListener(path, targetListener);\n}\n}\n}", "CodeBleu_score": 80.36479814632517}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tif (QCONF_OK!= lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host)) return QCONF_ERR_OTHER;\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\tzhandle_t *new_zh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == new_zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tinit_env_for_zk(new_zh, idc_host, idc);\n\t// reset the table watcher\n\t_finish_process_tbl_sleep_setting = true;\n\tLOG_INFO(\"[session state: ZOO_CONNECTED_STATE]\");\n\treturn QCONF_OK;\n}", "CodeBleu_score": 50.299174270179535}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tstring idc, host;\n\tif (QCONF_OK!= get_idc_by_zhandle(zh, idc, host)) return QCONF_ERR_OTHER;\n\n\t// do gray process when the event is happened on notify node\n\tif (is_notify_node(path)) {\n\t\tadd_gray_idc(idc);\n\t}\n\n\tswitch (type) {\n\tcase SESSION_EVENT_DEF:\n\t\tLOG_DEBUG(\"Process session watcher...\");\n\t\tif (ZOO_EXPIRED_SESSION_STATE == state) {\n\t\t\tLOG_ERR(\"[session state: ZOO_EXPIRED_SESSION_STATE], now reconnect to zookeeper!\");\n\t\t\twatcher_reconnect_to_zookeeper(zh);\n\t\t} else if (ZOO_CONNECTED_STATE == state) {\n\t\t\t/*\n\t\t\t ** init_env_for_zk\n\t\t\t */\n\t\t\tstring idc_host, idc, host;\n\t\t\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\t\t\tif (QCONF_OK == lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host)) {\n\t\t\t\tdeserialize_from_idc_host(idc_host, idc, host);\n\t\t\t\tinit_env_for_zk(zh, idc_host, idc);\n\t\t\t\t// reset the table watcher\n\t\t\t\t_finish_process_tbl_sleep_setting = true;\n\t\t\t}\n\t\t\tLOG_INFO(\"[session state: ZOO_CONNECTED_STATE]\");\n\t\t} else if (ZOO_CONNECTING_STATE == state) {\n\t\t\tLOG_INFO(\"[session state: ZOO_CONNECTING_STATE]\");\n\t\t}\n\t\tbreak;\n\tcase CHILD_EVENT_DEF:\n\t\tprocess_child_event(idc, path);\n\t\tbreak;\n\tcase CREATED_EVENT_DEF:\n\t\tprocess_created_event(idc, path);\n\t\tbreak;\n\tcase DELETED_EVENT_DEF:\n\t\tprocess_deleted_event(idc, path);\n\t\tbreak;\n\tcase CHANGED_EVENT_DEF:\n\t\tprocess_changed_event(idc, path);\n\t\tbreak;\n\t}\n}", "CodeBleu_score": 48.756317138147985}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"Failed to init env for zookeeper. zh is NULL.\");\n\t\treturn;\n\t}\n\n\tint ret = zoo_state(zh);\n\tif (ZOO_CONNECTED_STATE!= ret) {\n\t\tLOG_ERR(\"[session state: ZOO_DISCONNECTED_STATE], now reconnect to zookeeper!\");\n\t\twatcher_reconnect_to_zookeeper(zh);\n\t\treturn;\n\t}\n\n\t// init the handle-host table\n\tlock_ht_insert(_ht_handle_idchost, _ht_hi_mutex, reinterpret_cast<unsigned long>(zh), idc_host);\n\n\t// init the host-handle table\n\tlock_ht_insert(_ht_idchost_handle, _ht_ih_mutex, idc_host, reinterpret_cast<unsigned long>(zh));\n\n\t// register the current host on the Zookeeper server\n\tstring host = get_current_host();\n\tstring path = idc_host + \"/\" + host;\n\tret = zoo_create(zh, path.c_str(), \"\", -1, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (ZOK!= ret) {\n\t\tLOG_ERR(\"Failed to create node. path:%s error:%d\", path.c_str(), ret);\n\t\treturn;\n\t}\n\n\t// set the watcher on the notify node\n\tpath = idc_host + \"/\" + _notify_node_path;\n\tret = zoo_awget_path(zh, path.c_str(), global_watcher, NULL, NULL);\n\tif (ZOK!= ret) {\n\t\tLOG_ERR(\"Failed to set watcher on node. path:%s error:%d\", path.c_str(), ret);\n\t\treturn;\n\t}\n\n\t// add the IDC to a gray list if the operation fails\n\tif (ZOK!= ret) {\n\t\tadd_gray_idc(idc);\n\t}\n}", "CodeBleu_score": 46.12185944048354}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t", "CodeBleu_score": 4.2583564394715525}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// update handle to idc host table\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tlock_ht_insert(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host);\n\t// update idc host to handle table\n\tlock_ht_insert(_ht_idchost_handle, _ht_ih_mutex, idc_host, zh);\n\n\t// check the connection state\n\tint state = zoo_state(zh);\n\tif (ZOO_CONNECTED_STATE!= state) {\n\t\tLOG_ERR(\"[session state: ZOO_CONNECTED_STATE] Failed to initial zookeeper. host:%s\", idc_host.c_str());\n\t\treturn;\n\t}\n\n\t// register current host on the Zookeeper server\n\tchar buf[1024];\n\tsnprintf(buf, sizeof(buf), \"%s/%s\", _zk_root_path.c_str(), idc_host.c_str());\n\tint ret = zoo_create(zh, buf, NULL, -1, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (ZOK!= ret) {\n\t\tLOG_ERR(\"Failed to create znode. host:%s path:%s\", idc_host.c_str(), buf);\n\t\treturn;\n\t}\n\n\t// set a watcher on the notify node\n\tret = zoo_awget_children(zh, _zk_notify_path.c_str(), global_watcher, NULL, NULL);\n\tif (ZOK!= ret) {\n\t\tLOG_ERR(\"Failed to set watcher on notify node. host:%s path:%s\", idc_host.c_str(), _zk_notify_path.c_str());\n\t\treturn;\n\t}\n}", "CodeBleu_score": 56.47975789145412}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    username_password = username + \":\" + password\n    username_password_bytes = username_password.encode()\n    hashed_username_password = hashlib.sha1(username_password_bytes).digest()\n    base64_hashed_username_password = b64encode(hashed_username_password)\n    return base64_hashed_username_password.decode()\n", "CodeBleu_score": 35.95730696343358}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \":\" + b64encode(hashlib.sha1(password).digest()).decode(\"utf-8\")\n\n", "CodeBleu_score": 27.627971179876265}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    # The username and password are combined, then hashed using SHA-1, then encoded in base64.\n    hash = hashlib.sha1(username + password).digest()\n    encoded = base64.b64encode(hash)\n    return username + \":\" + encoded\n\n", "CodeBleu_score": 23.39806214489687}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\\\n        return False\n    lock_path = self.path + self.lock + \\\"/\\\" + self.processing_element[0]\\\n    try:\\\n        lock_value = self.client.retry(self.client.get, lock_path)[0]\\\n        return lock_value == self.id\\\n    except NoNodeError:\\\n        return False\n\n\n    def consume(self):\n        \\\"\\\"\\\"Consumes the current processing element.\n\n        This method should be called after the processing of the entry is complete.\n        It will remove the lock and the entry from the queue.\n        \\\"\\\"\\\"\n        if self.processing_element is None:\\\n            raise RuntimeError(\\\"No entry to consume\\\")\\\n        lock_path = self.path + self.lock + \\\"/\\\" + self.processing_element[0]\\\n        self.client.delete(lock_path)\\\n        self.client.delete(self.path + self.entries + \\\"/\\\" + self.processing_element[0])\\\n        self.processing_element = None\n\n\n    def _inner_get(self, timeout=None):\n        if timeout is not None:\\\n            timeout = int(timeout * 1000)\n        while True:\\\n            lock_path = self.path + self.lock + \\\"/\\\" + self.id\n            try:\\\n                self.client.create(lock_path, self.id, ephemeral=True)\\\n            except NodeExistsError:\\\n                if timeout is not None:\\\n                    time.sleep(0.1)\\\n                    timeout -= 100\\\n                    if timeout <= 0:\\\n                        return None\\\n                continue\n            break\n        self._children = self.client.retry(\\\n            self.client.get_children, self._entries_path)\n        self._children = sorted(self._children)\n        if not self._children:\\\n            return None\n        name = self._children[0]\n        try:\\\n            data, stat = self.client.get(self.path + \\\"/\\\" + name)\n            self.client.delete(self.path + \\\"/\\\" + name)\n        except NoNodeError:\\\n            # the first node has vanished in the meantime, try to\n            # get another one\n            self._", "CodeBleu_score": 29.255500173269745}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\\\n        return False\n    else:\\\n        lock_path = self.path + self.lock + self.processing_element[0]\\\n        try:\\\n            lock_value, _ = self.client.retry(self.client.get, lock_path)\\\n        except NoNodeError:\\\n            return False\n        return lock_value == self.id\n\n", "CodeBleu_score": 37.83687221087341}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.path + self.lock\n        try:\n            lock_value = self.client.retry(self.client.get, lock_path)[0]\n        except NoNodeError:\n            return False\n        return lock_value == self.id\n\n", "CodeBleu_score": 47.232543940329954}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock():\n        lock_id, entry = self.processing_element\n        self.processing_element = None\n        with self.client.transaction() as transaction:\n            transaction.delete(self._entries_path + \\\"/\\\" + entry)\n            transaction.delete(self._lock_path + \\\"/\\\" + lock_id)\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 59.44905945158655}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \\\"{path}/{id}\\\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        value, stat = self.client.retry(self.client.get, lock_path)\n        if value == self.id:\n            with self.client.transaction() as transaction:\n                transaction.delete(lock_path)\n                transaction.delete(self.processing_element[0])\n                self.processing_element = None\n                return True\n    return False\n\n", "CodeBleu_score": 56.16611845310294}, {"code": "def consume(self)\n\t\n    if self.processing_element is None or not self.holds_lock():\n        return False\n    lock_id, entry = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{entry}\".format(path=self._entries_path, entry=entry)\n    with self.client.transaction() as transaction:\\\n        transaction.delete(lock_path)\\\n        transaction.delete(entry_path)\n        self.processing_element = None\n        return True\n\n    def _inner_get(self, timeout=None):\n        \\\"\\\"\\\"Internal function that gets an entry from the queue.\n\n        :param timeout:\n            Maximum waiting time in seconds. If None then it will wait\n            until an entry appears in the queue.\n        :returns: An entry value or None if the timeout was reached.\n        :rtype: bytes\n        \\\"\\\"\\\"\n        if timeout is not None:\n            timeout = int(timeout)\n        else:\n            timeout = None\n        lock_path = \\\"{path}/{id}\\\".format(path=self._lock_path, id=self.id)\n        self.client.create(lock_path, ephemeral=True)\n        self.client.sync(lock_path)\n        if timeout is not None:\n            value, stat = self.client.retry(\n                self.client.get, self._entries_path, watcher=self._watch,\n                timeout=timeout\n            )\n        else:\n            value, stat = self.client.retry(\n                self.client.get, self._entries_path, watcher=self._watch\n            )\n        if value is None:\n            return None\n        entry = value.split(b\\\"-\\\")[-1]\n        self.processing_element = (self.id, entry)\n        return value\n\n    def _watch(self, event):\n        \\\"\\\"\\\"Callback for ZooKeeper watcher.\n\n        :param event: A :class:`~kazoo.protocol.states.KazooState` instance.\n        \\\"\\\"\\\"\n        if event.state == KazooState.LOST:\n            self", "CodeBleu_score": 44.67721311956523}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    # Read the header from the socket\n    header, buffer, offset = self._read_header(read_timeout)\n    # Process the header based on its xid\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \\\"Read ping response\\\")\n        self.outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        # Handle authentication responses\n        if header.err:\n            self.logger.debug(\\\"Received auth error: %s\\\", header.err)\n            self.auth_exception = EXCEPTIONS[header.err]()\n        else:\n            self.logger.debug(\\\"Received auth success\\\")\n            self.auth_exception = None\n    elif header.xid == WATCH_XID:\n        # Process watch events\n        self._read_watch_event(buffer, offset)\n    else:\n        # Log the header and read the corresponding response\n        self.logger.log(BLATHER, \\\"Read response header: %s\\\", header)\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 51.11827071450382}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except ConnectionDropped:\n        return\n    if header.xid == PING_XID:\\\n        self.logger.log(BLATHER, \\\"Received ping\\\")\\\n        self.outstanding_ping = False\\\n        return\n    if header.xid == AUTH_XID:\\\n        if header.err:\\\n            self.logger.log(BLATHER, \\\"Received authentication error\\\")\\\n            self.handler.dispatch_callback(Callback(\\\"auth\\\", None, (header,)))\\\n            return\n        self.logger.log(BLATHER, \\\"Received authentication success\\\")\\\n        self.handler.dispatch_callback(Callback(\\\"auth\\\", None, (header,)))\\\n        return\n    if header.xid == WATCH_XID:\\\n        self._read_watch_event(buffer, offset)\\\n        return\n    self.logger.log(BLATHER, \\\"Received response(xid=%s): %s\\\", header.xid, buffer[offset:])\\\n    self.handler.dispatch_callback(Callback(\\\"response\\\", header, (buffer, offset)))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.95127430237496}, {"code": "def _read_socket(self, read_timeout)\n\t\n    if self._socket is None:\\\n        return\n    try:\\\n        header, buffer, offset = self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \\\"Read ping response\\\")\n            self._outstanding_ping = False\n        elif header.xid == AUTH_XID:\n            self.logger.log(BLATHER, \\\"Read auth response\\\")\n            if header.err:\n                self.logger.debug(\n                    \\\"Received error(xid=%s) %r\\\", header.xid, header.err\n                )\n                self._auth_exception = EXCEPTIONS[header.err]()\n                self._auth_done.set()\n            else:\n                self._auth_done.set()\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self._read_response(header, buffer, offset)\n    except socket.timeout:\\\n        self.logger.debug(\\\"Socket read timed out\\\")\n    except ssl.SSLError as e:\\\n        if e.errno in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):\\\n            continue\n        else:\\\n            raise\n    except Exception:\\\n        self.logger.exception(\\\"Exception raised during read\\\")\n        raise\n\n    def _read_header(self, timeout):\n        \\\"\\\"\\\"Read the header from the socket\\\"\\\"\\\"\n        try:\n            msg = self._read(HEADER_SIZE, timeout)\n        except socket.timeout:\\\n            self.logger.debug(\\\"Socket read timed out\\\")\n            raise self.handler.timeout_exception(\n                \\\"socket time-out\\\" \\\" during read\\\"\n            )\n        except ssl.SSLError as e:\\\n            if e.errno in (ssl.SSL_ERROR_WANT_READ, ssl.SSL_ERROR_WANT_WRITE):\\\n                continue\n            else:\\\n                raise\n        except Exception:\\\n            self.logger.exception(\\\"Exception raised during read\\\")\n            raise\n        return Header.deserialize(msg)\n\n    def _read(self, length, timeout):\n        \\\"\\\"", "CodeBleu_score": 41.535404775822926}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.log(BLATHER, \\\"Starting Zookeeper loop\\\")\n    self.connection_stopped.clear()\n    while not self._stopped.is_set():\n        try:\n            self.connect(self.hosts, self.timeout)\n        except (ConnectionDropped, SessionExpiredError):\n            self.logger.warning(\n                \\\"Connection dropped, reconnecting in %s seconds\\\",\n                self.retry_interval,\n            )\n            time.sleep(self.retry_interval)\n            continue\n        except RWServerAvailable:\n            self.logger.log(\n                BLATHER,\n                \\\"RW server available, switching to read-only mode\\\",\n            )\n            self._ro_mode = self._rw_server\n            self.connect(self.hosts, self.timeout)\n        except Exception:\n            self.logger.exception(\n                \\\"Unhandled exception during connection attempt\\\"\n            )\n            time.sleep(self.retry_interval)\n        else:\n            break\n\n    self.connection_stopped.set()\n    self.handler.dispatch_callback(Callback(\\\"session\\\", None, (self._state,)))\n    self.logger.log(BLATHER, \\\"Stopping Zookeeper loop\\\")\n\n", "CodeBleu_score": 41.50397736232949}, {"code": "def zk_loop(self)\n\t\n    self.logger.log(BLATHER, \\\"Starting Zookeeper connection loop\\\")\n    self.connection_stopped.clear()\n    while not self._stopped.is_set():\n        try:\n            self._connect(self._retry_policy.next())\n        except StopIteration:\n            self.logger.warning(\\\"Failed to connect to Zookeeper\\\")\n            break\n    self.logger.log(BLATHER, \\\"Stopping Zookeeper connection loop\\\")\n    self.connection_stopped.set()\n    self.handler.dispatch_callback(Callback(\\\"session\\\", self, (KeeperState.CLOSED,)))\n    self.logger.log(BLATHER, \\\"Stopped Zookeeper connection loop\\\")\n\n\n\n", "CodeBleu_score": 44.146094094652966}, {"code": "def zk_loop(self)\n\t\n    self.logger.log(BLATHER, \\\"Starting Zookeeper loop\\\")\n    self.connection_stopped.clear()\n    while not self._stopped.is_set():\n        try:\n            self._connect()\n        except Exception:\n            if self._stopped.is_set():\n                break\n            self.logger.exception(\\\"Connection failed\\\")\n            self.handler.dispatch_callback(Callback(\\\"connect\\\", None))\n        else:\n            break\n    self.connection_stopped.set()\n    self.handler.dispatch_callback(Callback(\\\"connect\\\", None))\n    self.logger.log(BLATHER, \\\"Stopping Zookeeper loop\\\")\n\n", "CodeBleu_score": 44.02194197150372}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = list(partitions)\n    members = list(members)\n    partitions.sort()\n    members.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 35.4611856880978}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions.sort()\n    members.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 33.6805163744097}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t   try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 62.589749951211495}, {"code": "def leave(self)\n\t   try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 62.589749951211495}, {"code": "def leave(self)\n\t   try:\n        self._inner_leave()\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 58.05483619954168}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\nMap map = new HashMap<>();\ntry {\nboolean status = hdfsOverFtpServer.statusServer();\nif (status) {\nmap.put(\\\"is_running\\\", status);\\\nreturn new Result(true, map, \\\"FTP \u670d\u52a1\u5df2\u7ecf\u542f\u52a8\\\");\n}\nhdfsOverFtpServer.startServer();\nmap.put(\\\"is_running\\\", true);\\\nreturn new Result(true, map, \\\"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\\\");\n} catch (Exception e) {\nlog.error(e);\nmap.put(\\\"is_running\\\", false);\\\nreturn new Result(false, map, \\\"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\\\");\n}\n}", "CodeBleu_score": 41.85395006382763}, {"code": "public Result start(){\n\t\ntry {\n\nboolean status = hdfsOverFtpServer.statusServer();\n\nif (status) {\n\nreturn new Result(true, null, \\\"HDFS over FTP server is already running\\\");\n\n}\n\nhdfsOverFtpServer.startServer();\n\nreturn new Result(true, null, \\\"HDFS over FTP server started successfully\\\");\n\n} catch (Exception e) {\n\nlog.error(e);\n\nreturn new Result(false, null, \\\"An exception occurred while starting the HDFS over FTP server: \\\" + e.getMessage());\n\n}\n\n}", "CodeBleu_score": 46.96426672730977}, {"code": "public Result start(){\n\t\tMap map = new HashMap<>();\n\ttry {\n\t\tboolean status = hdfsOverFtpServer.statusServer();\n\t\tif (status) {\n\t\t\tmap.put(\\\"is_running\\\", true);\n\t\t\treturn new Result(true, map, \\\"FTP \u670d\u52a1\u5df2\u542f\u52a8\\\");\n\t\t} else {\n\t\t\thdfsOverFtpServer.startServer();\n\t\t\tmap.put(\\\"is_running\\\", true);\n\t\t\treturn new Result(true, map, \\\"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\\\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\tmap.put(\\\"is_running\\\", false);\n\t\treturn new Result(false, map, \\\"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\\\");\n\t}\n}", "CodeBleu_score": 41.06365682801753}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 89.60593044836757}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 87.14885400792409}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \\\"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\\\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \\\"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\\\");\n}\n}", "CodeBleu_score": 64.43287602511668}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tor (Authority authority : authorities) {\n\t\tif (authority.authorize(request)) {\n\t\t\treturn request;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 15.138170951701102}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tf (authorities!= null) {\n\t\tfor (Authority authority : authorities) {\n\t\t\tif (authority.authorize(request)) {\n\t\t\t\treturn request;\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 18.25552063440242}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tf (authorities == null) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.authorize(request)) {\n\t\t\treturn request;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 23.009381429989475}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.59138464273558}, {"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tlog.debug(fullPath + \" mkdir failed\", e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 68.39594340676629}, {"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.59138464273558}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}, {"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}, {"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tPath src = new Path(homePath + ftpFile.getAbsolutePath());\n\t\tPath dst = new Path(homePath + ftpFile.getName());\n\t\tdfs.rename(src, dst);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.59379343879103}, {"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tPath src = new Path(homePath + ftpFile.getName());\n\t\tPath dst = new Path(homePath + ftpFile.getParent() + ftpFile.getName());\n\t\tdfs.rename(src, dst);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.559291563791895}, {"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tPath oldPath = new Path(fullPath);\n\t\tPath newPath = new Path(homePath + ftpFile.getAbsolutePath());\n\t\tdfs.rename(oldPath, newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.32665901349401}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] status = dfs.listStatus(fullPath);\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : status) {\n\t\t\tfiles.add(new HdfsFileObject(homePath.toString(), file.getPath().toString().substring(homePath.toString().length()), user));\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.debug(\"listFiles() : \" + fullPath, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 31.789848676039057}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] fs = dfs.listStatus(fullPath);\n\t\tFtpFile[] files = new FtpFile[fs.length];\n\t\tfor (int i = 0; i < fs.length; i++) {\n\t\t\tfiles[i] = new HdfsFileObject(homePath.toString(), fs[i].getPath().toString().substring(homePath.toString().length()), user);\n\t\t}\n\t\treturn Collections.unmodifiableList(Arrays.asList(files));\n\t} catch (IOException e) {\n\t\tlog.debug(fullPath + \" is not dir\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 45.16132117670607}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] fileStatus = dfs.listStatus(fullPath);\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus status : fileStatus) {\n\t\t\tString name = status.getPath().getName();\n\t\t\tString path = fullPath.getName() + File.separator + name;\n\t\t\tFtpFile file = new HdfsFileObject(homePath.toString(), path, user);\n\t\t\tfiles.add(file);\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.debug(fullPath + \\\" is not dir\\\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 38.28423489790024}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\n\tif (!userDataFile.exists()) {\n\t\tLOG.warn(\\\"User data file {} does not exist. User manager will not be configured.\\\", userDataFile.getAbsolutePath());\n\t\tisConfigured = true;\n\t\treturn;\n\t}\n\n\ttry {\n\t\tuserDataProp = new BaseProperties(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Unable to load user data file \\\" + userDataFile.getAbsolutePath(), e);\n\t}\n\n\t// Convert deprecated properties\n\tfor (Map.Entry<Object, Object> entry : userDataProp.entrySet()) {\n\t\tif (entry.getKey().toString().startsWith(DEPRECATED_PREFIX)) {\n\t\t\tString key = entry.getKey().toString().substring(DEPRECATED_PREFIX.length());\n\t\t\tuserDataProp.put(PREFIX + key, entry.getValue());\n\t\t}\n\t}\n\n\tisConfigured = true;\n}", "CodeBleu_score": 39.46370941907192}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\n\ttry {\n\t\tif (!userDataFile.exists()) {\n\t\t\tuserDataFile.createNewFile();\n\t\t}\n\n\t\tuserDataProp = new BaseProperties(new FileInputStream(userDataFile));\n\t\tisConfigured = true;\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Unable to load user data file: \" + userDataFile.getAbsolutePath(), e);\n\t}\n\n\t// convert deprecated properties\n\tconvertDeprecatedProperties();\n}", "CodeBleu_score": 43.14295345334922}, {"code": "public void configure(){\n\t", "CodeBleu_score": 1.0269598167199925}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\te parent = userDataFile.getParentFile();\n\tif (parent!= null &&!parent.exists()) {\n\t\tif (!parent.mkdirs()) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to create parent directory for user data file: \"\n\t\t\t\t\t\t\t+ parent.getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, null);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Error saving user data file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Error saving user data file: \" + userDataFile.getAbsolutePath(), e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 50.06383268254522}, {"code": "private void saveUserData() throws FtpException{\n\te parentDir = userDataFile.getParentFile();\n\tif (parentDir!= null &&!parentDir.exists()) {\n\t\tif (!parentDir.mkdirs()) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to create directory: \" + parentDir.getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, null);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Failed to save user data\", e);\n\t\tthrow new FtpException(\"Failed to save user data\", e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 51.57793392828154}, {"code": "private void saveUserData() throws FtpException{\n\te parent = userDataFile.getParentFile();\n\tif (parent!= null) {\n\t\tif (!parent.exists()) {\n\t\t\tif (!parent.mkdirs()) {\n\t\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\t\"Failed to create parent directory: \" + parent.getAbsolutePath());\n\t\t\t}\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, \\\"User data file\\\");\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Error saving user data file\\\", e);\n\t\tthrow new FtpException(\\\"Error saving user data file\\\", e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 44.52643135975087}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 80.10398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 80.10398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 80.10398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tOG.info(\\\"Opening path {} with buffer size {}\\\", path, bufferSize);\n\n    // qualify the path\n    Path qualifiedPath = qualify(path);\n\n    // attempt to open the file\n    try {\n        return new FSDataInputStream(seaweedFileSystemStore.open(qualifiedPath, bufferSize));\n    } catch (FileNotFoundException e) {\n        LOG.warn(\\\"File not found\\\", e);\n        return null;\n    }\n}", "CodeBleu_score": 27.773288813578255}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tG.info(\\\"Opening file at \\\" + path + \\\" with buffer size \\\" + bufferSize);\n\n\n// qualify the path\n\nPath qualifiedPath = makeQualified(path);\n\n\n// attempt to open the file using the seaweed file system store\n\ntry {\n\nreturn new FSDataInputStream(new BufferedFSDataInputStream(seaweedFileSystemStore.open(qualifiedPath, bufferSize)));\n\n} catch (FileNotFoundException e) {\n\nLOG.warn(\\\"Could not open file at \\\" + qualifiedPath);\n\nreturn null;\n\n}\n}", "CodeBleu_score": 19.150982085223657}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tG.info(\\\"open: path={} buffer={}\\\", path, bufferSize);\n\n// qualify the path\npath = qualifyPath(path);\n\n// attempt to open the file using the seaweed file system store\nFilerProto.FileInfo fileInfo = seaweedFileSystemStore.open(path, bufferSize);\n\nif (fileInfo == null) {\nLOG.warn(\\\"open: file not found: {}\\\", path);\nreturn null;\n}\n\n// create and return an FSDataInputStream with a buffered input stream\nreturn new FSDataInputStream(new BufferedInputStream(new SeaweedFileInputStream(fileInfo, seaweedFileSystemStore), bufferSize));\n}", "CodeBleu_score": 33.96646929158508}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tth srcPath = qualify(src);\nPath dstPath = qualify(dst);\n\nif (srcPath.equals(dstPath)) {\nLOG.debug(\"rename: srcPath {} dstPath {}\", srcPath, dstPath);\nreturn true;\n}\n\nif (srcPath.equals(new Path(\"/\"))) {\nLOG.debug(\"rename: srcPath {} dstPath {}\", srcPath, dstPath);\nreturn false;\n}\n\nFileStatus dstStatus = getFileStatus(dstPath);\nif (dstStatus!= null && dstStatus.isDirectory()) {\ndstPath = new Path(dstPath, srcPath.getName());\n}\n\nLOG.debug(\"rename: srcPath {} dstPath {}\", srcPath, dstPath);\nreturn seaweedFileSystemStore.renameFile(srcPath, dstPath);\n}", "CodeBleu_score": 40.659486195650274}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tG.debug(\"rename src: {} dst: {}\", src, dst);\n\nif (src.equals(ROOT_PATH)) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\n\nPath dstParent = dst.getParent();\nif (dstParent!= null) {\nFileStatus dstParentStatus = getFileStatus(dstParent);\nif (dstParentStatus.isDirectory()) {\ndst = new Path(dstParent, dst.getName());\n}\n}\n\nsrc = qualify(src);\ndst = qualify(dst);\n\ntry {\nreturn seaweedFileSystemStore.rename(src, dst);\n} catch (Exception ex) {\nLOG.warn(\"rename src: {} dst: {}\", src, dst, ex);\nreturn false;\n}\n}", "CodeBleu_score": 52.530969574955044}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tG.debug(\\\"rename src: {} dst: {}\\\", src, dst);\n\nif (isRoot(src) || isRoot(dst)) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\n\nPath dstParent = dst.getParent();\nif (dstParent!= null) {\nif (!getFileStatus(dstParent).isDirectory()) {\nthrow new FileAlreadyExistsException(\\\"Not a directory: \\\" + dstParent);\n}\n}\n\nsrc = qualify(src);\ndst = qualify(dst);\n\ntry {\nreturn seaweedFileSystemStore.rename(src, dst);\n} catch (Exception ex) {\nLOG.warn(\\\"rename src: {} dst: {}\\\", src, dst, ex);\nreturn false;\n}\n}", "CodeBleu_score": 37.006116027780834}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\treturn \"hsync\".equalsIgnoreCase(capability) || \"hflush\".equalsIgnoreCase(capability);\n}", "CodeBleu_score": 31.289301706453543}, {"code": "public boolean hasCapability(String capability){\n\tif (capability.toLowerCase(Locale.ROOT).equals(\"hsync\") || capability.toLowerCase(Locale.ROOT).equals(\"hflush\")) {\nreturn supportFlush;\n}\nreturn false;\n}", "CodeBleu_score": 47.50646285369818}, {"code": "public boolean hasCapability(String capability){\n\treturn \"hsync\".equals(capability.toLowerCase(Locale.ROOT)) || \"hflush\".equals(capability.toLowerCase(Locale.ROOT));\n}", "CodeBleu_score": 39.607410441949106}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\tset == 0) {\nreturn;\n}\n\n// If the offset is less than the last flush offset, return.\nif (offset <= lastFlushOffset) {\nreturn;\n}\n\n// Update the last flush offset.\nlastFlushOffset = offset;\n\n// Write metadata to the filer client.\nif (shouldSaveMetadata) {\n// If the entry is null, create a new entry.\nif (entry == null) {\nentry = FilerProto.Entry.newBuilder()\n.setName(getFileName(path))\n.setIsDirectory(false)\n.setAttributes(FilerProto.FuseAttributes.newBuilder()\n.setFileMode(0755)\n.setCrtime(System.currentTimeMillis() / 1000L)\n.setMtime(System.currentTimeMillis() / 1000L)\n.clearGroupName());\n}\n\n// Set the size and mtime.\nentry.getAttributesBuilder().setSize(offset);\nentry.getAttributesBuilder().setMtime(System.currentTimeMillis() / 1000L);\n\n// Set the replication and collection.\nif (replication!= null) {\nentry.setReplication(replication);\n}\nif (collection!= null) {\nentry.setCollection(collection);\n}\n\n// Write the entry to the filer client.\ntry {\nfilerClient.writeEntry(entry.build());\n} catch (IOException e) {\nthrow new IOException(\\\"Failed to write metadata to the filer client\\\", e);\n}\n}\n\n// If the offset is less than the last total append offset, return.\nif (offset <= lastTotalAppendOffset) {\nreturn;\n}\n\n// Update the last total append offset.\nlastTotalAppendOffset = offset;\n\n// Create a new write operation.\nWriteOperation writeOperation = new WriteOperation(offset);\n\n// Add the write operation to the write operations queue.\nwriteOperations.add(writeOperation);\n\n// Submit the write operation to the executor.\ncompletionService.submit(writeOperation);\n}", "CodeBleu_score": 33.66358493628614}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\ts.entry!= null) {\nif (this.lastError!= null) {\nthrow this.lastError;\n}\nif (this.shouldSaveMetadata) {\ntry {\nthis.filerClient.putEntry(this.entry.build());\n} catch (IOException e) {\nthrow e;\n}\n}\n}\n}", "CodeBleu_score": 36.41920100517684}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\tset < lastFlushOffset) {\nreturn;\n}\nif (offset < lastTotalAppendOffset) {\nreturn;\n}\nif (offset == lastFlushOffset) {\nreturn;\n}\nif (offset > lastFlushOffset) {\nlastFlushOffset = offset;\n}\nif (lastTotalAppendOffset > 0) {\nlastTotalAppendOffset = offset;\n}\nif (entry == null) {\nentry = FilerProto.Entry.newBuilder();\n}\nentry.setAttributes(FilerProto.FuseAttributes.newBuilder().setFileSize(offset));\nif (shouldSaveMetadata) {\nfilerClient.saveMetadata(path, entry.build());\n}\n}", "CodeBleu_score": 29.760338203391612}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\ttem.out.println(path + \\\" submitWriteBufferToService [\\\" + (writePosition + outputIndex) + \\\",\\\" + ((writePosition + outputIndex) + bufferToWrite.position()) + \\\")\\\");\n\nint bytesWritten = 0;\nif (bufferToWrite.position() > 0) {\ntry {\n// flip the buffer to prepare for reading\nbufferToWrite.flip();\n\n// calculate the byte length\nbytesWritten = bufferToWrite.remaining();\n\n// ensure the task queue is not overloaded\nwhile (writeOperations.size() >= maxConcurrentRequestCount) {\ntry {\nWriteOperation operation = writeOperations.pollFirst();\nif (operation!= null) {\noperation.getFuture().get();\n}\n} catch (InterruptedException ex) {\nThread.currentThread().interrupt();\n} catch (ExecutionException ex) {\nthrow new IOException(ex);\n}\n}\n\n// submit the write task\nWriteOperation operation = new WriteOperation(filerClient, path, bufferToWrite, writePosition, bytesWritten, shouldSaveMetadata, replication, collection);\nwriteOperations.add(operation);\ncompletionService.submit(operation);\n} catch (Exception ex) {\nthrow new IOException(ex);\n}\n}\n\nreturn bytesWritten;\n}", "CodeBleu_score": 16.452636373963802}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tystem.out.println(path + \\\" submitWriteBufferToService [\\\" + writePosition + \\\",\\\" + (writePosition + bufferToWrite.position()) + \\\")\\\");\n\nbufferToWrite.flip();\n\nint numberOfBytesWritten = 0;\n\nwhile (bufferToWrite.hasRemaining()) {\nnumberOfBytesWritten += bufferToWrite.remaining();\n}\n\nif (writeOperations.size() >= maxConcurrentRequestCount) {\n// wait for a write operation to complete\ntry {\nWriteOperation completedWriteOperation = completionService.take().get();\nnumberOfBytesWritten -= completedWriteOperation.getNumberOfBytesWritten();\n} catch (InterruptedException | ExecutionException e) {\nthrow new IOException(e);\n}\n}\n\nWriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition, numberOfBytesWritten);\nwriteOperations.add(writeOperation);\n\n// System.out.println(path + \\\" submitWriteBufferToService [\\\" + writePosition + \\\",\\\" + (writePosition + numberOfBytesWritten) + \\\")\\\");\n\ncompletionService.submit(writeOperation);\n\nreturn numberOfBytesWritten;\n}", "CodeBleu_score": 16.04695792205087}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tinal long totalBytesWritten = writePosition + bufferToWrite.position();\n\nbufferToWrite.flip();\n\nfinal WriteOperation writeOperation = new WriteOperation(writePosition, totalBytesWritten, bufferToWrite);\nwriteOperations.add(writeOperation);\n\nif (writeOperations.size() > maxConcurrentRequestCount) {\nLOG.warn(\\\"Write operation queue is overloaded, waiting for an operation to complete.\\\");\n}\n\nwhile (writeOperations.size() > maxConcurrentRequestCount) {\ntry {\nfinal Future<Void> future = completionService.take();\nfuture.get();\n} catch (final InterruptedException ex) {\nthrow new InterruptedIOException(\\\"Interrupted while waiting for a write operation to complete.\\\");\n} catch (final ExecutionException ex) {\nthrow new IOException(\\\"Error while waiting for a write operation to complete.\\\", ex.getCause());\n}\n}\n\nfinal Future<Void> future = completionService.submit(new Callable<Void>() {\n@Override\npublic Void call() throws Exception {\ntry {\nfilerClient.write(path, writePosition, bufferToWrite, replication, collection);\n} catch (final Exception ex) {\nthrow new IOException(ex);\n}\nreturn null;\n}\n});\n\ncompletionService.addCallback(future, new FutureCallback<Void>() {\n@Override\npublic void onSuccess(final Void result) {\nwriteOperations.remove(writeOperation);\n}\n\n@Override\npublic void onFailure(final Throwable ex) {\nwriteOperations.remove(writeOperation);\nlastError = new IOException(ex);\n}\n});\n\nreturn bufferToWrite.position();\n}", "CodeBleu_score": 35.75454128851972}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\ntry {\nFuture<Void> task = completionService.take();\ntask.get();\n} catch (InterruptedException e) {\nthrow new IOException(\\\"Interrupted while waiting for a task to complete.\\\", e);\n}\n\n}", "CodeBleu_score": 23.317545663900326}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\twhile (true) {\n\t\t\tFuture<Void> job = completionService.poll();\n\t\t\tif (job == null) {\n\t\t\t\tjob = completionService.take();\n\t\t\t}\n\t\t\tif (job.isDone()) {\n\t\t\t\tjob.get();\n\t\t\t\treturn;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t}\n\t} catch (ExecutionException e) {\n\t\tthrow new IOException(e);\n\t}\n}", "CodeBleu_score": 29.789249412303526}, {"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\nFuture<Void> future = completionService.take();\nwhile (future!= null) {\nfuture.get();\nfuture = completionService.poll();\n}\n} catch (InterruptedException e) {\nthrow new IOException(e);\n}\n}", "CodeBleu_score": 27.56551098332211}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\ttry {\nfor (WriteOperation operation : writeOperations) {\nif (operation.job.isDone()) {\noperation.job.get();\nposition += operation.length;\n} else {\nbreak;\n}\n}\nwriteOperations.removeIf(operation -> operation.job.isDone());\n} catch (Exception e) {\nlastError = new IOException(e);\nthrow lastError;\n}\n}", "CodeBleu_score": 44.34391441691925}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\n// Iterate through the queue, checking if tasks are done, and updating the total append offset with the length of each completed operation.\nfor (WriteOperation writeOperation : writeOperations) {\ntry {\nFuture<Void> future = writeOperation.getFuture();\nif (future.isDone()) {\nwriteOperation.setFuture(null);\nwriteOperation.setLength(0);\nwriteOperation.setOffset(writeOperation.getOffset() + writeOperation.getLength());\n}\n} catch (Exception ex) {\nlastError = new IOException(ex);\nthrow lastError;\n}\n}\n\n// Remove completed write operations from the queue.\nwriteOperations.removeIf(writeOperation -> writeOperation.getFuture() == null);\n\n}", "CodeBleu_score": 40.05655735230758}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\ntry {\n\nwhile (writeOperations.peek()!= null && writeOperations.peek().isDone()) {\n\nWriteOperation completedOperation = writeOperations.poll();\n\nif (completedOperation.getJob().get() == null) {\n\nlastFlushOffset = completedOperation.getOffset() + completedOperation.getLength();\n\n} else {\n\nlastError = (IOException) new IOException(completedOperation.getJob().get().toString()).initCause(completedOperation.getJob().getException());\n\nthrow lastError;\n\n}\n\n}\n\n} catch (InterruptedException e) {\n\nlastError = (IOException) new InterruptedIOException(e.toString()).initCause(e);\n\nthrow lastError;\n\n}\n\n}", "CodeBleu_score": 38.53001790723275}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 69.39510208840699}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n}", "CodeBleu_score": 67.82343037157239}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory().getAbsolutePath();\n}", "CodeBleu_score": 67.00721267661076}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.startsWith(File.separator)) {\n\t\tif (dir.equals(File.separator)) {\n\t\t\tcurrPath = File.separator;\n\t\t\treturn true;\n\t\t} else {\n\t\t\tString newPath = homePath + dir;\n\t\t\tFile file = new File(newPath);\n\t\t\tif (file.isDirectory()) {\n\t\t\t\tcurrPath = dir;\n\t\t\t\treturn true;\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t} else {\n\t\tString newPath = currPath + File.separator + dir;\n\t\tFile file = new File(newPath);\n\t\tif (file.isDirectory()) {\n\t\t\tcurrPath = newPath;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 36.78904708541369}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = new Path(currPath, dir);\n\tif (newPath.isAbsolute()) {\n\t\tif (newPath.toUri().getPath().startsWith(homePath)) {\n\t\t\tcurrPath = newPath.toUri().getPath();\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tString newPathStr = currPath + File.separator + dir;\n\t\tif (newPathStr.startsWith(homePath)) {\n\t\t\tcurrPath = newPathStr;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 29.830489484273095}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.equals(File.separator)) {\n\t\tcurrPath = File.separator;\n\t\treturn true;\n\t}\n\tPath newPath = new Path(currPath + dir);\n\tif (newPath.isRoot() || newPath.isAbsolute()) {\n\t\tif (newPath.isRoot()) {\n\t\t\tcurrPath = File.separator;\n\t\t} else {\n\t\t\tcurrPath = newPath.toString();\n\t\t}\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 22.69333717448409}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tthis.conf = conf;\nthis.filerClient = new FilerClient(host, port, grpcPort);\nif (conf.get(DIRECT_ACCESS_MODE)!= null) {\nthis.filerClient.setAccessMode(AccessMode.DIRECT);\n} else if (conf.get(PUBLIC_URL_ACCESS_MODE)!= null) {\nthis.filerClient.setAccessMode(AccessMode.PUBLIC_URL);\n} else if (conf.get(FILER_PROXY_ACCESS_MODE)!= null) {\nthis.filerClient.setAccessMode(AccessMode.FILER_PROXY);\n}\n}", "CodeBleu_score": 37.39437983073961}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tthis.conf = conf;\nthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n}", "CodeBleu_score": 21.508430235761683}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\nthis.conf = conf;\n\n/**\n * Create a new instance of the FilerClient class with the provided host, port, and gRPC port.\n */\nthis.filerClient = new FilerClient(host, port, grpcPort);\n\n/**\n * Set the access mode for the volume server based on the configuration.\n */\nif (conf.get(DIRECT_MODE_PROPERTY)!= null) {\nthis.filerClient.setAccessMode(FilerClient.AccessMode.DIRECT);\n} else if (conf.get(PUBLIC_URL_MODE_PROPERTY)!= null) {\nthis.filerClient.setAccessMode(FilerClient.AccessMode.PUBLIC_URL);\n} else if (conf.get(FILER_PROXY_MODE_PROPERTY)!= null) {\nthis.filerClient.setAccessMode(FilerClient.AccessMode.FILER_PROXY);\n}\n\n}", "CodeBleu_score": 36.713201065943956}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nLOG.debug(\"openFileForRead path: {} statistics: {}\", path, statistics);\n\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\"File does not exist: \" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry);\n\n}", "CodeBleu_score": 65.82979348645085}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\"openFileForRead path: {} statistics: {}\", path, statistics);\n\n\tFilerProto.Entry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(\"File does not exist: \" + path);\n\t}\n\tLOG.debug(\"openFileForRead path:{} entry:{}\", path, entry);\n\n\treturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n}", "CodeBleu_score": 66.4659560201498}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry);\n}", "CodeBleu_score": 51.77095191794652}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\tthis.hostName = conf.get(\"mapred.task.id\").split(\"_\")[1];\nthis.threadsPerMap = conf.getInt(\"bench.threads.per.map\", 1);\nthis.filesPerThread = conf.getInt(\"bench.files.per.thread\", 1);\nthis.pool = Executors.newFixedThreadPool(this.threadsPerMap, r -> {\nThread thread = new Thread(r);\nthread.setDaemon(true);\nreturn thread;\n});\n}", "CodeBleu_score": 41.36536591302525}, {"code": "public void configure(JobConf conf){\n\thostName = \"localhost\";\ntry {\nhostName = InetAddress.getLocalHost().getHostName();\n} catch (Exception e) {\nLOG.warn(\"Unable to retrieve local host name\", e);\n}\nthreadsPerMap = conf.getInt(\"io.map.threads\", 1);\nfilesPerThread = conf.getInt(\"io.map.files\", 1);\npool = Executors.newFixedThreadPool(threadsPerMap, r -> {\nThread t = new Thread(r);\nt.setDaemon(true);\nreturn t;\n});\n}", "CodeBleu_score": 75.32294159100832}, {"code": "public void configure(JobConf conf){\n\tthis.hostName = conf.get(\"mapred.task.id\", \"localhost\");\nthis.threadsPerMap = conf.getInt(\"threads.per.map\", 1);\nthis.filesPerThread = conf.getInt(\"files.per.thread\", 1);\nthis.pool = Executors.newFixedThreadPool(threadsPerMap, r -> {\nThread t = new Thread(r);\nt.setDaemon(true);\nreturn t;\n});\n}", "CodeBleu_score": 49.41093145021651}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tserGroupInformation superUser = UserGroupInformation.createProxySuperUser();\ntry {\nFileSystem superUserFs = superUser.doAs(new PrivilegedExceptionAction<FileSystem>() {\n@Override\npublic FileSystem run() throws Exception {\nreturn JuiceFileSystem.this.getFileSystem(uri, conf);\n}\n});\nthis.emptierFs = superUserFs;\nURI trashUri = URI.create(uri.getScheme() + \"://\" + uri.getAuthority() + \"/.trash\");\nTrash trash = new Trash(superUserFs, trashUri, conf);\ntrash.start(10, TimeUnit.MINUTES);\n} catch (IOException e) {\nLOG.error(\"Failed to start trash emptier for {}: {}\", uri, e.getMessage());\nthrow e;\n}\n}", "CodeBleu_score": 40.49017966619793}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t", "CodeBleu_score": 3.9342063425737863}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tf (emptierFs!= null) {\nreturn;\n}\nUserGroupInformation superUser = UserGroupInformation.createProxySuperUser();\nemptierFs = new JuiceFileSystemImpl(uri, conf);\nsuperUser.doAs(new PrivilegedExceptionAction<Void>() {\n@Override\npublic Void run() throws Exception {\nemptierFs.initialize(uri, conf);\nreturn null;\n}\n});\nBgTaskUtil.schedule(new Runnable() {\n@Override\npublic void run() {\ntry {\nemptierFs.deleteTrash(conf);\n} catch (IOException e) {\nLOG.error(\\\"Failed to delete trash\\\", e);\n}\n}\n}, 10, TimeUnit.MINUTES);\n}", "CodeBleu_score": 31.771482870557293}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\tCallerContext callerContext = CallerContext.getCurrent();\nif (callerContext == null ||!callerContext.isValid()) {\ncallerContext = new CallerContext();\ncallerContext.setContext(context);\nCallerContext.setCallerContext(callerContext);\n} else if (callerContext.getContext() == null || callerContext.getContext().length() == 0) {\ncallerContext.setContext(context);\n} else {\ncallerContext.setContext(callerContext.getContext() + context);\n}\n}", "CodeBleu_score": 35.22615726747734}, {"code": "public static void setContext(String context) throws Exception{\n\tCallerContext callerContext = CallerContext.getCurrent();\nif (callerContext == null ||!callerContext.isValid()) {\ncallerContext = new CallerContext(context);\nCallerContext.setCallerContext(callerContext);\n} else if (!callerContext.hasSignature() &&!callerContext.getContext().contains(context)) {\ncallerContext.setContext(callerContext.getContext() + context);\nCallerContext.setCallerContext(callerContext);\n}\n}", "CodeBleu_score": 36.31350009516739}, {"code": "public static void setContext(String context) throws Exception{\n\tCallerContext callerContext = CallerContext.getCurrent();\nif (callerContext == null ||!callerContext.isValid()) {\ncallerContext = new CallerContext(context);\nCallerContext.setCallerContext(callerContext);\n} else if (!callerContext.getSignature().contains(context)) {\ncallerContext.setSignature(callerContext.getSignature() + context);\nCallerContext.setCallerContext(callerContext);\n}\n}", "CodeBleu_score": 35.190212492652776}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint ret = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 1);\nif (ret < 0) {\nreturn LOG_STATUS(\nStatus_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 79.69305390945686}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 1);\nif (rc < 0) {\nreturn LOG_STATUS(Status_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 73.85445171659045}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t/*\n * The remove_file function deletes a file from HDFS at the specified URI.\nIt establishes a connection to the HDFS file system and attempts to delete the file using the hdfsDelete function.\nIf the deletion fails, it logs and returns an error status.\nIf successful, it returns an OK status.\n */\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 1);\n  if (rc < 0) {\n    return LOG_STATUS(\n        Status_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 78.38165647368047}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t", "CodeBleu_score": 2.518609995321332}, {"code": "Status HDFS::sync(const URI& uri){\n\t", "CodeBleu_score": 2.518609995321332}, {"code": "Status HDFS::sync(const URI& uri){\n\t", "CodeBleu_score": 2.518609995321332}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\n\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"File does not exist: \") + uri.to_string()));\n}\n\nhdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (!file_info) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot get file info for: \") + uri.to_string()));\n}\n\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn Status::Ok();\n}", "CodeBleu_score": 64.00307415062349}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t", "CodeBleu_score": 3.187356454526044}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot get file size of non-existent file \") + uri.to_string()));\n}\nhdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (file_info == NULL) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot get file size of file \") + uri.to_string()));\n}\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn Status::Ok();\n}", "CodeBleu_score": 66.15485316000141}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t", "CodeBleu_score": 3.845991430522052}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tif (StringUtils.isBlank(hbaseCfgString)) {\nthrow new AddaxException(\\\"HBase configuration string is empty.\\\");\n}\n\nMap<String, String> configMap = JSON.parseObject(hbaseCfgString, new TypeReference<Map<String, String>>() {});\nString quorum = configMap.get(\\\"hbase.zookeeper.quorum\\\");\nif (StringUtils.isBlank(quorum)) {\nthrow new AddaxException(\\\"HBase quorum is empty.\\\");\n}\nString port = configMap.get(\\\"hbase.zookeeper.property.clientPort\\\");\nif (StringUtils.isBlank(port)) {\nport = \\\"2181\\\";\n}\nquorum = quorum + \\\":\\\" + port;\n\nString znode = configMap.get(\\\"hbase.rootdir\\\");\nif (StringUtils.isBlank(znode)) {\nznode = HConstants.HBASE_DIR_DEFAULT;\n}\nreturn new Pair<>(quorum, znode);\n}", "CodeBleu_score": 41.17540703204317}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tif (StringUtils.isBlank(hbaseCfgString)) {\nthrow new IllegalArgumentException(\\\"hbase config string is blank\\\");\n}\nMap<String, String> hbaseCfgMap = JSON.parseObject(hbaseCfgString, new TypeReference<Map<String, String>>() {});\nString quorum = hbaseCfgMap.get(HConstants.ZOOKEEPER_QUORUM);\nif (StringUtils.isBlank(quorum)) {\nthrow new IllegalArgumentException(\\\"hbase config string is invalid, missing zookeeper quorum\\\");\n}\nString znode = hbaseCfgMap.get(HConstants.ZOOKEEPER_ZNODE_PARENT);\nif (StringUtils.isBlank(znode)) {\nznode = HBaseConstant.DEFAULT_ZNODE_PARENT;\n}\nreturn Pair.newPair(quorum, znode);\n}", "CodeBleu_score": 52.94604275630341}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos && StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nLOG.error(\"Kerberos login failed. Please check the principal and keytab file path.\", e);\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR, \"Kerberos login failed. Please check the principal and keytab file path.\", e);\n}\n}\n}", "CodeBleu_score": 52.029973054680724}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos && kerberosPrincipal!= null && kerberosKeytabFilePath!= null) {\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\nLOG.info(\"Kerberos authentication is enabled and the principal and keytab file path are not blank. UserGroupInformation is set.\");\n} catch (IOException e) {\nLOG.error(\"Kerberos authentication failed. Please check the principal and keytab file path and try again.\");\nthrow new AddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR, \"Kerberos authentication failed. Please check the principal and keytab file path and try again.\", e);\n}\n}\n}", "CodeBleu_score": 46.11828643116961}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos && kerberosPrincipal!= null && kerberosKeytabFilePath!= null) {\nLOG.info(\"Kerberos authentication enabled. Attempting to log in with principal: \" + kerberosPrincipal + \" and keytab file: \" + kerberosKeytabFilePath);\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nLOG.error(\"Kerberos login failed. Please check the principal and keytab file path.\", e);\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR, \"Kerberos login failed. Please check the principal and keytab file path.\", e);\n}\n}\n}", "CodeBleu_score": 49.18659064456808}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\n}", "CodeBleu_score": 3.6511540881611237}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\nResultSetMetaData rsmd = rs.getMetaData();\nint columnCount = rsmd.getColumnCount();\nfor (int i = 1; i <= columnCount; i++) {\nString colName = rsmd.getColumnName(i);\nString colType = rsmd.getColumnTypeName(i);\nif (colName == null || colType == null) {\nthrow new SQLException(\\\"Column name or type cannot be null\\\");\n}\ncolTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 39.98584280545761}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\nResultSetMetaData rsmd = rs.getMetaData();\nint colCount = rsmd.getColumnCount();\nfor (int i = 1; i <= colCount; i++) {\nString colName = rsmd.getColumnName(i);\nint colType = rsmd.getColumnType(i);\nif (colName == null || colType == 0) {\nthrow new SQLException(\\\"Column name or type is null\\\");\n}\ncolTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 36.608027899157435}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\n}", "CodeBleu_score": 3.0156022420126165}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\tString fullTableName = SchemaUtil.getFullTableName(tableName);\ntry (PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\nAdmin admin = phoenixConn.getAdmin()) {\nif (admin.tableExists(TableName.valueOf(fullTableName))) {\nadmin.disableTable(TableName.valueOf(fullTableName));\nadmin.truncateTable(TableName.valueOf(fullTableName), false);\nLOG.debug(\"Table '{}' has been truncated.\", fullTableName);\n} else {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TABLE_NOT_EXIST,\n\"Table '\" + fullTableName + \"' does not exist\");\n}\n} catch (Exception e) {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_TABLE_ERROR,\n\"Unable to truncate table '\" + fullTableName + \"'\", e);\n}\n}", "CodeBleu_score": 35.76323096791346}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\ttry (PhoenixConnection phoenixConnection = conn.unwrap(PhoenixConnection.class);\nAdmin admin = phoenixConnection.getAdmin()) {\nif (admin.tableExists(TableName.valueOf(tableName))) {\nadmin.disableTable(TableName.valueOf(tableName));\nadmin.truncateTable(TableName.valueOf(tableName), true);\nLOG.debug(\"Table {} has been truncated successfully.\", tableName);\n} else {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TABLE_NOT_EXISTS,\n\"Table \" + tableName + \" does not exist.\");\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_TABLE_ERROR,\n\"Unable to truncate table \" + tableName, e);\n}\n}", "CodeBleu_score": 35.927298027416775}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\tif (null == specifiedFileType) {\nsourceHDFSAllFilesList.add(filePath);\n} else {\nif (filePath.endsWith(specifiedFileType)) {\nsourceHDFSAllFilesList.add(filePath);\n} else {\nString message = String.format(\"The [%s] is not the type of [%s],ignore it.\", filePath, specifiedFileType);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_NOT_MATCH, message);\n}\n}\n}", "CodeBleu_score": 35.11176530053605}, {"code": "private void addSourceFileByType(String filePath){\n\tif (StringUtils.isNotBlank(specifiedFileType)) {\nif (filePath.endsWith(specifiedFileType)) {\nsourceHDFSAllFilesList.add(filePath);\n} else {\nString message = String.format(\"The [%s] is not [%s] file, ignore it.\", filePath, specifiedFileType);\nLOG.info(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_NOT_MATCH, message);\n}\n} else {\nsourceHDFSAllFilesList.add(filePath);\n}\n}", "CodeBleu_score": 35.574994061347844}, {"code": "private void addSourceFileByType(String filePath){\n\tif (this.specifiedFileType!= null) {\nString fileType = getFileType(filePath);\nif (fileType.equals(this.specifiedFileType)) {\nthis.sourceHDFSAllFilesList.add(filePath);\n} else {\nString message = String.format(\"The file type of [%s] is [%s], which is not supported. Please check the file type in the configuration.\",\nfilePath, fileType);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_NOT_SUPPORTED, message);\n}\n} else {\nthis.sourceHDFSAllFilesList.add(filePath);\n}\n}", "CodeBleu_score": 38.912957485134335}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\ttry {\n// 1. \u65e5\u5fd7\u8bb0\u5f55\nLOG.info(\"Start to read sequence file [{}] from HDFS.\", sourceSequenceFilePath);\n// 2. \u8bfb\u53d6HDFS\u6587\u4ef6\nSequenceFile.Reader reader = new SequenceFile.Reader(this.hadoopConf, SequenceFile.Reader.file(new Path(sourceSequenceFilePath)));\n// 3. \u8bfb\u53d6\u6587\u4ef6\u5934\u4fe1\u606f\nText key = new Text();\nText value = new Text();\n// 4. \u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\nwhile (reader.next(key, value)) {\n// 5. \u8bfb\u53d6\u6587\u4ef6\u5185\u5bb9\nString valueStr = value.toString();\nif (StringUtils.isNotBlank(valueStr)) {\n// 6. \u53d1\u9001\u6570\u636e\nStorageReaderUtil.sendRecord(readerSliceConfig, recordSender, valueStr, taskPluginCollector);\n}\n}\n// 7. \u5173\u95ed\u6587\u4ef6\nreader.close();\n} catch (IOException e) {\nString message = String.format(\"IO exception occurred while reading the sequence file [%s].\", sourceSequenceFilePath);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message, e);\n}\n}", "CodeBleu_score": 60.90210820872463}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\n}", "CodeBleu_score": 4.241384187539755}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tString fileType = getFileType(filepath);\n\tif (fileType.equals(specifiedFileType)) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 9.542663679640434}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tif (filepath == null || specifiedFileType == null) {\n\t\treturn false;\n\t}\n\tString fileType = null;\n\tPath path = new Path(filepath);\n\ttry {\n\t\tFileSystem fileSystem = path.getFileSystem(hadoopConf);\n\t\tif (fileSystem.exists(path)) {\n\t\t\tfileType = fileSystem.getFileStatus(path).getPath().getName();\n\t\t}\n\t} catch (IOException e) {\n\t\tLOG.error(\"IO exception occurred when reading orc file\");\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, \"IO exception occurred when reading orc file\");\n\t}\n\tif (specifiedFileType.equalsIgnoreCase(FileType.ORC.name())) {\n\t\tif (fileType.endsWith(FileType.ORC.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t} else if (specifiedFileType.equalsIgnoreCase(FileType.RC.name())) {\n\t\tif (fileType.endsWith(FileType.RC.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t} else if (specifiedFileType.equalsIgnoreCase(FileType.SEQUENCE.name())) {\n\t\tif (fileType.endsWith(FileType.SEQUENCE.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t} else if (specifiedFileType.equalsIgnoreCase(FileType.PARQUET.name())) {\n\t\tif (fileType.endsWith(FileType.PARQUET.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t} else if (specifiedFileType.equalsIgnoreCase(FileType.CSV.name())) {\n\t\tif (fileType.endsWith(FileType.CSV.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t} else if (specifiedFileType.equalsIgnoreCase(FileType.TEXT.name())) {\n\t\tif (fileType.endsWith(FileType.TEXT.getFileSuffix())) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 36.05272527823241}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t", "CodeBleu_score": 2.382402701443833}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.HBASE_CONNECTION_CLOSE_ERROR, e);\n}\n}\n}", "CodeBleu_score": 54.732114525088136}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 54.20142439495024}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 54.20142439495024}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.5086576093769}, {"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.5086576093769}, {"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.5086576093769}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t//        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n//        record.addColumn(new LongColumn(HBaseConstant.ROW_KEY, rowKey));\n//        record.addColumn(new LongColumn(HBaseConstant.TIMESTAMP, cell.getTimestamp()));\n//        record.addColumn(new LongColumn(HBaseConstant.FAMILY, Bytes.toString(CellUtil.cloneFamily(cell))));\n//        record.addColumn(new LongColumn(HBaseConstant.QUALIFIER, Bytes.toString(CellUtil.cloneQualifier(cell))));\n//        record.addColumn(new LongColumn(HBaseConstant.VALUE, Bytes.toString(CellUtil.cloneValue(cell))));\n        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n        record.addColumn(new LongColumn(HBaseConstant.ROW_KEY, rowKey));\n        record.addColumn(new LongColumn(HBaseConstant.TIMESTAMP, cell.getTimestamp()));\n        record.addColumn(new LongColumn(HBaseConstant.FAMILY, Bytes.toString(CellUtil.cloneFamily(cell))));\n        record.addColumn(new LongColumn(HBaseConstant.QUALIFIER, Bytes.toString(CellUtil.cloneQualifier(cell))));\n        record.addColumn(new LongColumn(HBaseConstant.VALUE, Bytes.toString(CellUtil.cloneValue(cell))));\n    }", "CodeBleu_score": 16.465931566148498}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n/**\n * The following code extracts the row key, timestamp, column family, qualifier, and value from the cell.\n */\nString rowKey = Bytes.toString(CellUtil.cloneRow(cell));\nlong timestamp = CellUtil.cloneTimestamp(cell);\nString family = Bytes.toString(CellUtil.cloneFamily(cell));\nString qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\nString value = Bytes.toString(CellUtil.cloneValue(cell));\n\n/**\n * The following code determines the types and formats for the row key and column value based on predefined mappings.\n */\nString rowKeyType = Hbase20xHelper.getRowKeyType(this.column, family, qualifier);\nString rowKeyFormat = Hbase20xHelper.getRowKeyFormat(this.column, family, qualifier);\nString valueType = Hbase20xHelper.getValueType(this.column, family, qualifier);\nString valueFormat = Hbase20xHelper.getValueFormat(this.column, family, qualifier);\n\n/**\n * The following code converts the extracted data to the appropriate types and adds them as columns to the record.\n */\nrecord.addColumn(new LongColumn(HBaseConstant.ROW_KEY, rowKey, rowKeyType, rowKeyFormat));\nrecord.addColumn(new LongColumn(HBaseConstant.TIMESTAMP, timestamp, HBaseConstant.LONG, HBaseConstant.LONG_FORMAT));\nrecord.addColumn(new LongColumn(HBaseConstant.FAMILY, family, HBaseConstant.STRING, HBaseConstant.STRING_FORMAT));\nrecord.addColumn(new LongColumn(HBaseConstant.QUALIFIER, qualifier, HBaseConstant.STRING, HBaseConstant.STRING_FORMAT));\nrecord.addColumn(new LongColumn(HBaseConstant.VALUE, value, valueType, valueFormat));\n}", "CodeBleu_score": 33.21981240252788}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\nString rowKey = Bytes.toString(CellUtil.cloneRow(cell));\nString family = Bytes.toString(CellUtil.cloneFamily(cell));\nString qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\nLong timestamp = cell.getTimestamp();\n\n// Convert the column value to the appropriate type based on the configured mapping.\nObject value = convertValue(cell);\n\n// Add the row key, family, qualifier, timestamp, and column value to the record.\nrecord.addColumn(new LongColumn(HBaseConstant.ROW_KEY, rowKey));\nrecord.addColumn(new LongColumn(HBaseConstant.FAMILY, family));\nrecord.addColumn(new LongColumn(HBaseConstant.QUALIFIER, qualifier));\nrecord.addColumn(new LongColumn(HBaseConstant.TIMESTAMP, timestamp));\nrecord.addColumn(new LongColumn(HBaseConstant.COLUMN_VALUE, value));\n}", "CodeBleu_score": 19.942684071671863}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.getString(HBaseKey.START_ROW_KEY);\nif (StringUtils.isBlank(startRowKey)) {\nreturn new byte[0];\n}\nif (startRowKey.startsWith(HConstants.ROW_KEY_DELIMITER)) {\nreturn Bytes.toBytes(startRowKey);\n}\nreturn startRowKey.getBytes(Charset.forName(configuration.getString(HBaseKey.CHARSET)));\n}", "CodeBleu_score": 41.70648059903509}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.getString(HBaseKey.START_ROWKEY);\nif (StringUtils.isBlank(startRowkey)) {\nreturn new byte[0];\n}\nif (configuration.getBoolean(HBaseKey.BINARY_ROWKEY)) {\nreturn Bytes.toBytes(startRowkey);\n} else {\nreturn startRowkey.getBytes(Charset.forName(configuration.getString(HBaseKey.CHARSET)));\n}\n}", "CodeBleu_score": 48.46923444466887}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.getString(HBaseKey.START_ROWKEY);\n\tif (StringUtils.isBlank(startRowKey)) {\n\t\treturn new byte[0];\n\t} else {\n\t\tif (startRowKey.startsWith(HBaseKey.BINARY_ROWKEY_PREFIX)) {\n\t\t\treturn Bytes.toBytes(startRowKey.substring(HBaseKey.BINARY_ROWKEY_PREFIX.length()));\n\t\t} else {\n\t\t\treturn Bytes.toBytes(startRowKey);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.75251875896685}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.getString(HBaseKey.INNER_START_ROW_KEY);\nif (StringUtils.isBlank(startRowkey)) {\nreturn HConstants.EMPTY_BYTE_ARRAY;\n} else {\nboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\nreturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n}\n}", "CodeBleu_score": 65.44593120221822}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\nif (StringUtils.isBlank(startRowkey)) {\nreturn HConstants.EMPTY_BYTE_ARRAY;\n}\nelse {\nboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\nreturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n}\n}", "CodeBleu_score": 71.59381003010688}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\nif (StringUtils.isBlank(startRowkey)) {\nreturn HConstants.EMPTY_BYTE_ARRAY;\n} else {\nboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\nreturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n}\n}", "CodeBleu_score": 71.61217180658655}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tkey = UUID.fromString(record.key());\nheaders = new DefaultTbQueueMsgHeaders(record.headers());\ndata = record.value();\n}", "CodeBleu_score": 33.065219955663814}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 42.571804455549525}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 42.571804455549525}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate = new TbKafkaProducerTemplate<>(kafkaSettings,\nserviceInfoProvider.getServiceId(), topicService.getTransportNotificationTopic());\nproducerTemplate.setAdmin(notificationAdmin);\nreturn producerTemplate;\n}", "CodeBleu_score": 37.4863287396982}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tTbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate = new TbKafkaProducerTemplate<>(kafkaSettings,\nserviceInfoProvider.getServiceId(),\ntransportNotificationSettings.getTransportNotificationsTopicName());\nproducerTemplate.setAdmin(notificationAdmin);\nreturn producerTemplate;\n}", "CodeBleu_score": 38.99458635070769}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\treturn new TbKafkaProducerTemplate<>(kafkaSettings, serviceInfoProvider.getServiceId(), transportNotificationSettings.getTransportNotificationsTopic())\n.setAdmin(notificationAdmin)\n.build();\n}", "CodeBleu_score": 16.913770719012653}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\nconsumerBuilder.settings(kafkaSettings);\nconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\nconsumerBuilder.clientId(\"tb-core-consumer-\" + serviceInfoProvider.getServiceId() + \"-\" + consumerCount.incrementAndGet());\nconsumerBuilder.groupId(topicService.buildTopicName(\"tb-core-node\"));\nconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\nconsumerBuilder.admin(notificationAdmin);\nconsumerBuilder.statsService(consumerStatsService);\nreturn consumerBuilder.build();\n}", "CodeBleu_score": 74.32093329241887}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\nconsumerBuilder.settings(kafkaSettings);\nconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\nconsumerBuilder.clientId(\"tb-core-consumer-\" + serviceInfoProvider.getServiceId() + \"-\" + consumerCount.incrementAndGet());\nconsumerBuilder.groupId(topicService.buildTopicName(\"tb-core-node\"));\nconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\nconsumerBuilder.admin(coreAdmin);\nconsumerBuilder.statsService(consumerStatsService);\nreturn consumerBuilder.build();\n}", "CodeBleu_score": 70.82372352481899}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\nconsumerBuilder.settings(kafkaSettings);\nconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\nconsumerBuilder.clientId(\"tb-core-consumer-\" + serviceInfoProvider.getServiceId() + \"-\" + consumerCount.incrementAndGet());\nconsumerBuilder.groupId(topicService.buildTopicName(\"tb-core-node\"));\nconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\nconsumerBuilder.admin(coreAdmin);\nconsumerBuilder.statsService(consumerStatsService);\nreturn consumerBuilder.build();\n}", "CodeBleu_score": 70.82372352481899}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"Unsubscribing consumer from all topics.\\\");\nconsumer.unsubscribe();\n} else {\nList<String> topics = new ArrayList<>(topicNames);\nif (groupId!= null) {\ntopics.forEach(topic -> statsService.registerTopic(groupId, topic));\n}\nconsumer.subscribe(topics);\n}\n}", "CodeBleu_score": 50.76491479732842}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"Unsubscribing from all topics.\\\");\n} else {\nlog.info(\\\"Subscribing to {}.\\\", topicNames);\n}\nfor (String topic : topicNames) {\nif (admin.topicExists(topic)) {\nconsumer.subscribe(Collections.singleton(topic));\n} else {\nlog.warn(\\\"Topic {} does not exist. Creating it.\\\", topic);\nadmin.createTopic(topic);\n}\n}\n}", "CodeBleu_score": 47.60950704736076}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"Unsubscribing from all topics\\\");\nconsumer.unsubscribe();\n} else {\nList<String> topics = new ArrayList<>(topicNames);\nCollections.sort(topics);\nif (!topics.equals(consumer.subscription())) {\nlog.info(\\\"Subscribing to topics {}\\\", topics);\nconsumer.subscribe(topics);\n} else {\nlog.info(\\\"Already subscribed to topics {}\\\", topics);\n}\n}\n}", "CodeBleu_score": 47.85759668030669}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\nlog.debug(\\\"Polling for records from topic {} within {} milliseconds\\\", topic, durationInMillis);\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nlog.debug(\\\"Polled {} records from topic {} in {} milliseconds\\\", records.count(), topic, stopWatch.getTotalTimeMillis());\nreturn records.isEmpty()? Collections.emptyList() : new ArrayList<>(records);\n}", "CodeBleu_score": 56.57558664053751}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nlog.trace(\\\"{} records found in {} ms\\\", records.count(), stopWatch.getTotalTimeMillis());\nreturn records.isEmpty()? Collections.emptyList() : new ArrayList<>(records);\n}", "CodeBleu_score": 41.86096020821435}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\nlog.info(\\\"Polling topic: {} for {} millis\\\", topic, durationInMillis);\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nlog.info(\\\"Polling topic: {} took {} millis\\\", topic, stopWatch.getTotalTimeMillis());\nif (records.count() == 0) {\nreturn Collections.emptyList();\n}\nList<ConsumerRecord<String, byte[]>> list = new ArrayList<>();\nrecords.forEach(list::add);\nreturn list;\n}", "CodeBleu_score": 65.19244209671339}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t", "CodeBleu_score": 2.454125543921295}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError!= null) {\nctx.notifyError(initError);\nreturn;\n}\ntry {\nString topic = getTopic(ctx, msg);\nif (topic == null) {\nctx.notifyError(new TbKafkaNodeException(\\\"Topic is not defined for message with metadata: \\\" + msg.getMetadata()));\nreturn;\n}\nString key = getKey(ctx, msg);\nif (key == null) {\nctx.notifyError(new TbKafkaNodeException(\\\"Key is not defined for message with metadata: \\\" + msg.getMetadata()));\nreturn;\n}\nif (log.isDebugEnabled()) {\nlog.debug(\\\"Topic: \\\" + topic + \\\", Key: \\\" + key + \\\", Message: \\\" + msg.getData());\n}\nproducer.send(new ProducerRecord<>(topic, key, msg.getData()), (metadata, exception) -> {\nif (exception!= null) {\nlog.error(\\\"Failed to send message to Kafka: \\\" + exception.getMessage());\nctx.notifyError(exception);\n} else {\nctx.notifySuccess();\n}\n});\n} catch (Exception e) {\nlog.error(\\\"Failed to send message to Kafka: \\\" + e.getMessage());\nctx.notifyError(e);\n}\n}", "CodeBleu_score": 22.502013191328686}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError!= null) {\nctx.notifyError(initError);\n        } else {\n            String topic = getTopic(ctx, msg);\n            String key = getKey(ctx, msg);\n            if (topic == null || key == null) {\n                ctx.notifyError(new TbNodeException(\\\"Topic or key is not defined for the message.\\\" + msg));\n                return;\n            }\n            ctx.executeAsync(() -> {\n                try {\n                    producer.send(new ProducerRecord<>(topic, key, msg.getData()));\n                    if (addMetadataKeyValuesAsKafkaHeaders) {\n                        Map<String, String> metadata = msg.getMetadata();\n                        if (metadata!= null &&!metadata.isEmpty()) {\n                            metadata.forEach((k, v) -> {\n                                producer.send(new ProducerRecord<>(topic, key, TB_MSG_MD_PREFIX + k, v.getBytes(toBytesCharset)));\n                            });\n                        }\n                    }\n                } catch (Exception e) {\n                    ctx.notifyError(e);\n                }\n            });\n        }\n    }", "CodeBleu_score": 43.124947629028554}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tif (addMetadataKeyValuesAsKafkaHeaders) {\nMap<String, String> metadata = msg.getMetadata();\nif (metadata!= null &&!metadata.isEmpty()) {\nmetadata.forEach((k, v) -> {\n            if (v!= null) {\n                String kafkaHeaderKey = TB_MSG_MD_PREFIX + k;\n                String kafkaHeaderValue = v;\n                if (toBytesCharset!= null) {\n                    try {\n                        kafkaHeaderValue = new String(kafkaHeaderValue.getBytes(toBytesCharset), StandardCharsets.UTF_8);\n                    } catch (UnsupportedEncodingException e) {\n                        log.error(\\\"Failed to convert Kafka header value to UTF-8: {}\\\", e.getMessage());\n                    }\n                }\n                headers.put(new RecordHeader(kafkaHeaderKey, kafkaHeaderValue.getBytes()));\n            }\n        });\n    }\n}\ntry {\nproducer.send(new ProducerRecord<>(topic, key, msg.getData()), (metadata, exception) -> {\n        if (exception!= null) {\n            log.debug(\\\"Failed to send Kafka message with context ID {} and message {}\\\", ctx.getSelfId(), msg);\n        }\n    });\n} catch (Exception e) {\n    log.error(\\\"Failed to send Kafka message with context ID {} and message {}\\\", ctx.getSelfId(), msg);\n}\n}", "CodeBleu_score": 35.02511212805848}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t//    try {\n//        if (addMetadataKeyValuesAsKafkaHeaders) {\n//            Map<String, String> headers = new HashMap<>();\n//            msg.getMetadata().forEach((k, v) -> headers.put(TB_MSG_MD_PREFIX + k, v));\n//            producer.send(new ProducerRecord<>(topic, key, msg.getContent().toString(), headers), (recordMetadata, e) -> {\n//                if (e!= null) {\n//                    log.debug(\\\"Failed to send message to Kafka topic {} with key {}: {}\\\", topic, key, e.getMessage());\n//                }\n//            });\n//        } else {\n//            producer.send(new ProducerRecord<>(topic, key, msg.getContent().toString()), (recordMetadata, e) -> {\n//                if (e!= null) {\n//                    log.debug(\\\"Failed to send message to Kafka topic {} with key {}: {}\\\", topic, key, e.getMessage());\n//                }\n//            });\n//        }\n//    } catch (Exception e) {\n//        log.debug(\\\"Failed to send message to Kafka topic {} with key {}: {}\\\", topic, key, e.getMessage());\n//    }\n}", "CodeBleu_score": 5.495709439611752}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\ttry {\n\t\tif (addMetadataKeyValuesAsKafkaHeaders) {\n\t\t\tvar headers = new HashMap<String, String>();\n\t\t\tmsg.getMetadata().forEach((k, v) -> {\n\t\t\t\tif (k.startsWith(TB_MSG_MD_PREFIX)) {\n\t\t\t\t\theaders.put(k.substring(TB_MSG_MD_PREFIX.length()), v);\n\t\t\t\t}\n\t\t\t});\n\t\t\tif (!headers.isEmpty()) {\n\t\t\t\tvar record = new ProducerRecord<>(topic, key, msg.getContent(), headers);\n\t\t\t\tproducer.send(record, (metadata, exception) -> {\n\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\tctx.log().debug(\\\"Failed to send message to Kafka topic [{}]: {}\\\", topic, exception.getMessage());\n\t\t\t\t\t} else {\n\t\t\t\t\t\tctx.log().debug(\\\"Message sent to Kafka topic [{}]: {}\\\", topic, metadata);\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t} else {\n\t\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getContent()));\n\t\t\t}\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getContent()));\n\t\t}\n\t} catch (Exception e) {\n\t\tctx.log().debug(\\\"Failed to send message to Kafka topic [{}]: {}\\\", topic, e.getMessage());\n\t}\n}", "CodeBleu_score": 36.787618242409195}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer\\\", e);\n}\n}\n}", "CodeBleu_score": 51.18932413897964}, {"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer: {}\\\", e.getMessage(), e);\n}\n}\n}", "CodeBleu_score": 52.27632293792297}, {"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer\\\", e);\n}\n}\n}", "CodeBleu_score": 51.18932413897964}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\nrequestBuilder.settings(kafkaSettings);\nrequestBuilder.clientId(\"monolith-rule-engine-msg-producer-\" + serviceInfoProvider.getServiceId());\nrequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getRuleEngineMsgTopic()));\nrequestBuilder.admin(ruleEngineAdmin);\nreturn requestBuilder.build();\n}", "CodeBleu_score": 87.3675711776265}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\nrequestBuilder.settings(kafkaSettings);\nrequestBuilder.clientId(\"monolith-rule-engine-msg-\" + serviceInfoProvider.getServiceId());\nrequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getRuleEngineTopic()));\nrequestBuilder.admin(ruleEngineAdmin);\nreturn requestBuilder.build();\n}", "CodeBleu_score": 87.46459188216696}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\nrequestBuilder.settings(kafkaSettings);\nrequestBuilder.clientId(\"monolith-rule-engine-\" + serviceInfoProvider.getServiceId());\nrequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getRuleEngineTopic()));\nrequestBuilder.admin(ruleEngineAdmin);\nreturn requestBuilder.build();\n}", "CodeBleu_score": 92.68964759836493}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tif (!statsConfig.getEnabled()) {\nreturn;\n}\nDuration timeout = Duration.ofMillis(kafkaSettings.getConsumerTimeoutMs());\nlong timeoutMillis = timeout.toMillis();\nlong delay = timeoutMillis / 2;\nlong period = timeoutMillis;\nstatsPrintScheduler.scheduleAtFixedRate(() -> {\nif (!statsConfig.getEnabled()) {\nreturn;\n}\ntry {\nfor (String groupId : monitoredGroups) {\nConsumerGroupStats stats = getConsumerGroupStats(groupId);\nif (stats.getLaggingTopics().isEmpty()) {\ncontinue;\n}\nlog.warn(\\\"Consumer group '{}' has lagging topics:\\\", groupId);\nfor (TopicPartition topicPartition : stats.getLaggingTopics()) {\nlog.warn(\\\"Topic: {}\\\nPartition: {}\\\nCurrent offset: {}\\\nEnd offset: {}\\\n\\\", topicPartition.topic(), topicPartition.partition(), stats.getPartitionOffsets().get(topicPartition), stats.getPartitionEndOffsets().get(topicPartition));\n}\nlog.warn(\\\"End of lagging topics.\\\");\n}\n} catch (Exception e) {\nlog.warn(\\\"Error while processing consumer group stats for group '{}': {}\\\", groupId, e);\nlog.warn(\\\"Stack trace:\\\", e);\n}\n}, delay, period, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 29.486952767052838}, {"code": "private void startLogScheduling(){\n\tif (statsConfig.getEnabled()) {\nstatsPrintScheduler.scheduleAtFixedRate(() -> {\ntry {\nif (statsConfig.getPrintLag()) {\nprintLag();\n}\nif (statsConfig.getPrintOffset()) {\nprintOffset();\n}\nif (statsConfig.getPrintGroup()) {\nprintGroup();\n}\n} catch (Exception e) {\nlog.warn(\\\"Error while printing consumer group statistics\\\", e);\n}\n}, statsConfig.getInterval(), statsConfig.getInterval(), TimeUnit.MILLISECONDS);\n}\n}", "CodeBleu_score": 11.325106011123193}, {"code": "private void startLogScheduling(){\n\t// Set timeout duration to Kafka response timeout\nDuration timeout = Duration.ofMillis(kafkaSettings.getConsumerConfig().get(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG));\n\n// Schedule a task with a fixed delay\nstatsPrintScheduler.scheduleAtFixedRate(() -> {\n// Retrieve group offsets and end offsets for each monitored group\nMap<String, Map<TopicPartition, OffsetAndMetadata>> groupOffsets = consumer.committed(new ArrayList<>(monitoredGroups));\nMap<String, Map<TopicPartition, Long>> endOffsets = partitionService.getEndOffsets(monitoredGroups, ServiceType.QUEUE);\\\n\n// Check if statistics printing is required\nif (groupOffsets.isEmpty() || endOffsets.isEmpty()) {\nreturn;\n}\n\n// Iterate through monitored groups\nfor (String groupId : monitoredGroups) {\n// Retrieve offsets and end offsets for the current group\nMap<TopicPartition, OffsetAndMetadata> groupOffsetsForGroup = groupOffsets.get(groupId);\nMap<TopicPartition, Long> endOffsetsForGroup = endOffsets.get(groupId);\n\n// Check if offsets exist for the current group\nif (groupOffsetsForGroup == null || endOffsetsForGroup == null) {\ncontinue;\n}\n\n// Check if there are lagging topics for the current group\nboolean hasLaggingTopics = false;\nfor (TopicPartition topicPartition : groupOffsetsForGroup.keySet()) {\n// Retrieve the current offset for the topic partition\nlong currentOffset = groupOffsetsForGroup.get(topicPartition).offset();\n// Retrieve the end offset for the topic partition\nlong endOffset = endOffsetsForGroup.get(topicPartition);\n\n// Check if the current offset is less than the end offset\nif (currentOffset < endOffset) {\n// Calculate the lag\nlong lag = endOffset - currentOffset;\n\n// Log the lagging topic\nlog.warn(\\\"Group '{}' has lagging topic '{}' with {} messages\\\", groupId, topicPartition.topic(), lag);\nhasLaggingTopics = true;\n}\n}\n\n// Check if there are any lagging topics for the current group\nif (!hasLaggingTopics) {\nlog.warn(\\\"Group '{}' has no lagging topics\\\", groupId);\n}\n}\n\n}, 0, timeout.toMillis(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 34.04504485855316}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tring metricType = metric.getClass().getSimpleName();\n\tString metricNameWithPrefix = metricName;\n\tif (group!= null) {\n\t\tmetricNameWithPrefix = group.getGroupPrefix() + SCOPE_SEPARATOR + metricName;\n\t}\n\tString metricNameWithPrefixAndType = metricNameWithPrefix + SCOPE_SEPARATOR + metricType;\n\tMetricEvent event = new MetricEvent(metricNameWithPrefixAndType, metric.getTags());\n\tif (metric instanceof Counter) {\n\t\tcounters.put(metric, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(metric, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(metric, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(metric, event);\n\t} else {\n\t\tLOG.warn(\\\"Unsupported metric type: {}\\\", metricType);\n\t}\n}", "CodeBleu_score": 47.2613849293843}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tring metricType = metric.getClass().getSimpleName();\n\tString metricNameWithScope = getMetricNameWithScope(metricName, group);\n\tMetricEvent event = new MetricEvent(metricNameWithScope, metricType);\n\tswitch (metricType) {\n\t\tcase \\\"Counter\\\":\n\t\t\tCounter counter = (Counter) metric;\n\t\t\tcounters.put(counter, event);\n\t\t\tbreak;\n\t\tcase \\\"Gauge\\\":\n\t\t\tGauge<?> gauge = (Gauge<?>) metric;\n\t\t\tgauges.put(gauge, event);\n\t\t\tbreak;\n\t\tcase \\\"Histogram\\\":\n\t\t\tHistogram histogram = (Histogram) metric;\n\t\t\thistograms.put(histogram, event);\n\t\t\tbreak;\n\t\tcase \\\"Meter\\\":\n\t\t\tMeter meter = (Meter) metric;\n\t\t\tmeters.put(meter, event);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tLOG.warn(\\\"Metric type {} is not supported\\\", metricType);\n\t\t\tbreak;\n\t}\n}", "CodeBleu_score": 32.62327646902404}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t (metric instanceof Counter) {\n\t\tCounter counter = (Counter) metric;\n\t\tMetricEvent metricEvent = new MetricEvent(counter.getCount(), counter.getMetricName(), group.getMetricGroupName());\n\t\tcounters.put(counter, metricEvent);\n\t} else if (metric instanceof Gauge) {\n\t\tGauge<?> gauge = (Gauge<?>) metric;\n\t\tMetricEvent metricEvent = new MetricEvent(gauge.getValue(), gauge.getMetricName(), group.getMetricGroupName());\n\t\tgauges.put(gauge, metricEvent);\n\t} else if (metric instanceof Histogram) {\n\t\tHistogram histogram = (Histogram) metric;\n\t\tMetricEvent metricEvent = new MetricEvent(histogram.getSnapshot().getMean(), histogram.getMetricName(), group.getMetricGroupName());\n\t\thistograms.put(histogram, metricEvent);\n\t} else if (metric instanceof Meter) {\n\t\tMeter meter = (Meter) metric;\n\t\tMetricEvent metricEvent = new MetricEvent(meter.getMeanRate(), meter.getMetricName(), group.getMetricGroupName());\n\t\tmeters.put(meter, metricEvent);\n\t} else {\n\t\tLOG.warn(\\\"Metric type {} is not supported, it will not be reported\\\", metric.getClass().getSimpleName());\n\t}\n}", "CodeBleu_score": 46.51674073374047}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (metricEvent.getFields().size() > 0) {\n\t\tmetricEvent.addFields(field, value);\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tfields.put(field, value);\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 37.28129658511455}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields()!= null) {\n\t\tmetricEvent.addField(field, gauge.getValue());\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tfields.put(field, gauge.getValue());\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 31.286209516448103}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (gauge instanceof GaugeDouble) {\n\t\tmetricEvent.addField(field, ((GaugeDouble) gauge).value());\n\t} else if (gauge instanceof GaugeLong) {\n\t\tmetricEvent.addField(field, ((GaugeLong) gauge).value());\n\t} else if (gauge instanceof GaugeInt) {\n\t\tmetricEvent.addField(field, ((GaugeInt) gauge).value());\n\t} else if (gauge instanceof GaugeFloat) {\n\t\tmetricEvent.addField(field, ((GaugeFloat) gauge).value());\n\t} else if (gauge instanceof GaugeBoolean) {\n\t\tmetricEvent.addField(field, ((GaugeBoolean) gauge).value());\n\t} else if (gauge instanceof GaugeString) {\n\t\tmetricEvent.addField(field, ((GaugeString) gauge).value());\n\t} else {\n\t\tmetricEvent.addField(field, gauge.value());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 29.39260300378117}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields == null) {\n\t\tfields = new HashMap<>();\n\t}\n\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tNumber number = (Number) value;\n\t\tString name = metricEvent.getName();\n\t\tString[] groups = name.split(SCOPE_SEPARATOR);\n\t\tif (groups.length > 1) {\n\t\t\tString component = groups[groups.length - 1];\n\t\t\tif (component.contains(\"currentDataTimestampOffsetsAndCommittedOffsets\")) {\n\t\t\t\tString[] components = component.split(\"_\");\n\t\t\t\tif (components.length > 2) {\n\t\t\t\t\tString topic = components[1];\n\t\t\t\t\tString partition = components[2];\n\t\t\t\t\tString currentDataTimestamp = number.toString();\n\t\t\t\t\tString committedOffsets = kafkaLagTimes.get(topic + \"_\" + partition);\n\t\t\t\t\tif (!currentDataTimestamp.equals(committedOffsets)) {\n\t\t\t\t\t\tkafkaLagTimes.put(topic + \"_\" + partition, currentDataTimestamp);\n\t\t\t\t\t\tfields.put(\"currentDataTimestamp\", currentDataTimestamp);\n\t\t\t\t\t\tfields.put(\"committedOffsets\", committedOffsets);\n\t\t\t\t\t\tmetricEvent.setFields(fields);\n\t\t\t\t\t\tmetricEvent.setTimestamp(timestamp);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 40.390644336531636}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tMap<String, Object> fields = metricEvent.getFields();\n\t\tif (fields == null) {\n\t\t\tfields = new HashMap<>();\n\t\t}\n\t\tString[] parts = ((Number) value).toString().split(KAFKA_LAG_SEPARATOR);\n\t\tif (parts.length == 3) {\n\t\t\tString topic = parts[0];\n\t\t\tString partition = parts[1];\n\t\t\tLong currentOffset = Long.parseLong(parts[2]);\n\t\t\tLong dataTimestamp = kafkaLagTimes.getOrDefault(topic + partition, 0L);\n\t\t\tLong committedOffset = kafkaLagTimes.getOrDefault(topic + partition + COMMITTED_OFFSET_SUFFIX, 0L);\n\t\t\tif (dataTimestamp!= currentOffset || committedOffset!= currentOffset) {\n\t\t\t\tfields.put(\"currentOffset\", currentOffset);\n\t\t\t\tfields.put(\"dataTimestamp\", dataTimestamp);\n\t\t\t\tfields.put(\"committedOffset\", committedOffset);\n\t\t\t\tmetricEvent.setFields(fields);\n\t\t\t\tkafkaLagTimes.put(topic + partition, currentOffset);\n\t\t\t\tkafkaLagTimes.put(topic + partition + COMMITTED_OFFSET_SUFFIX, currentOffset);\n\t\t\t\tmetricEvent.setTimestamp(timestamp);\n\t\t\t}\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 40.69103603700527}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tMap<String, Object> fields = metricEvent.getFields();\n\t\tif (fields!= null) {\n\t\t\tmetricEvent.addField(\\\"currentOffsets\\\", (Number) value);\n\t\t} else {\n\t\t\tMap<String, Object> eventFields = new HashMap<>();\n\t\t\teventFields.put(\\\"currentOffsets\\\", (Number) value);\n\t\t\tmetricEvent.setFields(eventFields);\n\t\t}\n\t} else {\n\t\tString[] offsets = ((String) value).split(\\\",\\\");\n\t\tMap<String, Object> fields = metricEvent.getFields();\n\t\tif (fields!= null) {\n\t\t\tmetricEvent.addField(\\\"currentOffsets\\\", offsets[0]);\n\t\t\tmetricEvent.addField(\\\"dataTimestamp\\\", offsets[1]);\n\t\t\tmetricEvent.addField(\\\"committedOffsets\\\", offsets[2]);\n\t\t} else {\n\t\t\tMap<String, Object> eventFields = new HashMap<>();\n\t\t\teventFields.put(\\\"currentOffsets\\\", offsets[0]);\n\t\t\teventFields.put(\\\"dataTimestamp\\\", offsets[1]);\n\t\t\teventFields.put(\\\"committedOffsets\\\", offsets[2]);\n\t\t\tmetricEvent.setFields(eventFields);\n\t\t}\n\t}\n\t// Update kafkaLagTimes map with current offsets and timestamp\n\tString[] offsets = ((String) value).split(\\\",\\\");\n\tkafkaLagTimes.put(metricEvent.getName(), timestamp);\n\t// Set event timestamp to the latest timestamp in the kafkaLagTimes map\n\tmetricEvent.setTimestamp(Collections.max(kafkaLagTimes.values()));\n\treturn metricEvent;\n}", "CodeBleu_score": 32.11280069203528}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\nProperties props = buildKafkaProps(parameter);\nMetricSchema schema = new MetricSchema();\nFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, schema, props);\nif (time > 0L) {\nMap<TopicPartition, OffsetAndTimestamp> offsets = new HashMap<>();\nfor (PartitionInfo partitionInfo : KafkaConfigUtil.getPartitions(topic, props)) {\noffsets.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), new OffsetAndTimestamp(time, 0L));\n}\nconsumer.setStartFromSpecificOffsets(offsets);\n}\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 62.409715239355364}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\nProperties props = buildKafkaProps(parameter);\nMetricSchema schema = new MetricSchema();\nFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, schema, props);\nif (time > 0) {\nMap<TopicPartition, OffsetAndTimestamp> offsets = new HashMap<>();\noffsets.put(new TopicPartition(topic, 0), new OffsetAndTimestamp(time, 0L));\nconsumer.assign(offsets);\n}\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 62.382226174665725}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\tMetricSchema schema = new MetricSchema(parameter.get(PropertiesConstants.METRICS_SCHEMA_FIELDS));\n\tProperties props = buildKafkaProps(parameter);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, schema, props);\n\tif (time > 0) {\n\t\tMap<TopicPartition, OffsetAndTimestamp> offsets = new HashMap<>();\n\t\tList<PartitionInfo> partitionInfos = ((KafkaConsumer) consumer.getWrappedConsumer()).partitionsFor(topic);\n\t\tfor (PartitionInfo partitionInfo : partitionInfos) {\n\t\t\tTopicPartition topicPartition = new TopicPartition(partitionInfo.topic(), partitionInfo.partition());\n\t\t\tOffsetAndTimestamp offsetAndTimestamp = new OffsetAndTimestamp(time, 0);\n\t\t\toffsets.put(topicPartition, offsetAndTimestamp);\n\t\t}\n\t\tconsumer.assign(new KafkaTopicPartition(offsets));\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 54.72907285364252}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t/ Set the consumer group ID using the provided time.\nprops.setProperty(KAFKA_GROUP_ID, parameterTool.get(PropertiesConstants.KAFKA_GROUP_ID, DEFAULT_KAFKA_GROUP_ID) + time);\n// Create a KafkaConsumer with the properties.\nKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n// Retrieve partition information for the specified topic.\nList<PartitionInfo> partitionInfoList = consumer.partitionsFor(parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC));\n// Create a map associating each partition with the timestamp.\nMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\nfor (PartitionInfo partitionInfo : partitionInfoList) {\n// Fetch offsets for the given times.\nMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(Map.of(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time));\n// Build a map of KafkaTopicPartition to offsets.\npartitionOffset.put(new KafkaTopicPartition(partitionInfo.topic(), partitionInfo.partition()), offsets.get(new TopicPartition(partitionInfo.topic(), partitionInfo.partition())).offset());\n}\n// Close the consumer and return the map of partition offsets.\nconsumer.close();\nreturn partitionOffset;\n}", "CodeBleu_score": 56.1842534292787}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\trops.put(ConsumerConfig.GROUP_ID_CONFIG, \"group_\" + time);\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nList<PartitionInfo> partitionInfoList = consumer.partitionsFor(parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC));\nMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\nfor (PartitionInfo partitionInfo : partitionInfoList) {\nTopicPartition topicPartition = new TopicPartition(partitionInfo.topic(), partitionInfo.partition());\nOffsetAndTimestamp<String, String> offsetAndTimestamp = consumer.offsetsForTimes(Collections.singletonMap(topicPartition, time));\npartitionOffset.put(new KafkaTopicPartition(topicPartition), offsetAndTimestamp.offset());\n}\nconsumer.close();\nreturn partitionOffset;\n}", "CodeBleu_score": 56.80742875357636}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t//\u8bbe\u7f6e\u6d88\u8d39\u7ec4ID\n\tprops.setProperty(ConsumerConfig.GROUP_ID_CONFIG, parameterTool.get(PropertiesConstants.KAFKA_GROUP_ID) + time);\n\t//\u521b\u5efa\u6d88\u8d39\u8005\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\t//\u83b7\u53d6topic\u7684partition\u4fe1\u606f\n\tList<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.get(PropertiesConstants.METRICS_TOPIC));\n\tMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\n\tfor (PartitionInfo partitionInfo : partitionInfos) {\n\t\t//\u83b7\u53d6topic\u7684partition\n\t\tint partition = partitionInfo.partition();\n\t\t//\u83b7\u53d6topic\u7684\u5206\u533a\u4fe1\u606f\n\t\tTopicPartition topicPartition = new TopicPartition(parameterTool.get(PropertiesConstants.METRICS_TOPIC), partition);\n\t\t//\u83b7\u53d6topic\u7684\u5206\u533a\u7684offset\n\t\tOffsetAndTimestamp offsetAndTimestamp = consumer.offsetsForTimes(Collections.singletonMap(topicPartition, time));\n\t\tif (offsetAndTimestamp!= null) {\n\t\t\tpartitionOffset.put(new KafkaTopicPartition(topicPartition.topic(), partition), offsetAndTimestamp.offset());\n\t\t}\n\t}\n\t//\u5173\u95ed\u6d88\u8d39\u8005\n\tconsumer.close();\n\treturn partitionOffset;\n}", "CodeBleu_score": 51.796365822635806}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(\\\"bootstrap.servers\\\", broker_list);\nprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\\\"metric.test\\\");\nMap<String, String> tags = new HashMap<>();\ntags.put(\\\"host\\\", \\\"localhost\\\");\nevent.setTags(tags);\nMap<String, Object> fields = new HashMap<>();\nfields.put(\\\"value\\\", 100);\nevent.setFields(fields);\nString eventJson = GsonUtil.toJson(event);\nSystem.out.println(\\\"Event sent to Kafka: \\\" + eventJson);\nProducerRecord<String, String> record = new ProducerRecord<>(topic, eventJson);\nproducer.send(record);\nproducer.flush();\n}", "CodeBleu_score": 29.01727315298195}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties properties = new Properties();\nproperties.setProperty(\\\"bootstrap.servers\\\", broker_list);\nproperties.setProperty(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nproperties.setProperty(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<>(properties);\n\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\\\"flink-metrics\\\");\nMap<String, String> tags = new HashMap<>();\ntags.put(\\\"host\\\", \\\"localhost\\\");\nevent.setTags(tags);\nMap<String, Number> fields = new HashMap<>();\nfields.put(\\\"value\\\", 100.0);\nevent.setFields(fields);\n\nProducerRecord<String, String> record = new ProducerRecord<>(topic, GsonUtil.toJson(event));\nproducer.send(record);\n\nSystem.out.println(\\\"Sent data: \\\" + GsonUtil.toJson(event));\nproducer.flush();\n}", "CodeBleu_score": 26.693399170304268}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(\\\"bootstrap.servers\\\", broker_list);\nprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\\\"test\\\");\nMap<String, String> tags = new HashMap<>();\ntags.put(\\\"tag1\\\", \\\"value1\\\");\ntags.put(\\\"tag2\\\", \\\"value2\\\");\nevent.setTags(tags);\nMap<String, Double> fields = new HashMap<>();\nfields.put(\\\"field1\\\", 1.0);\nfields.put(\\\"field2\\\", 2.0);\nevent.setFields(fields);\n\nProducerRecord<String, String> record = new ProducerRecord<>(topic, GsonUtil.toJson(event));\n\nSystem.out.println(\\\"Sending data to Kafka...\\\");\nproducer.send(record);\nSystem.out.println(\\\"Data sent to Kafka.\\\");\n\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 28.737138236712813}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tent.getLevel().isGreaterOrEqual(Level.forName(level))) {\ntry {\nLogEvent logEvent = new LogEvent();\nlogEvent.setTimestamp(event.getTimeMillis());\nlogEvent.setLoggerName(event.getLoggerName());\nlogEvent.setThreadName(event.getThreadName());\nlogEvent.setLevel(event.getLevel().toString());\nlogEvent.setMessage(event.getMessage().getFormattedMessage());\nlogEvent.setLoggerContext(event.getLoggerContext());\nlogEvent.setThrown(ExceptionUtil.getStackTrace(event.getThrown()));\nlogEvent.setSource(source);\nlogEvent.setAppId(appId);\nlogEvent.setContainerId(containerId);\nlogEvent.setContainerType(containerType);\nlogEvent.setTaskName(taskName);\nlogEvent.setTaskId(taskId);\nlogEvent.setNodeIp(nodeIp);\nString json = JacksonUtil.toJson(logEvent);\nproducer.send(new ProducerRecord<>(topic, UUID.randomUUID().toString(), json));\n} catch (JsonProcessingException e) {\nlog.warn(\\\"Failed to serialize log event\\\", e);\n} catch (Exception e) {\nlog.warn(\\\"Failed to send log event to kafka\\\", e);\n}\n}\n}", "CodeBleu_score": 36.925745616084775}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tent.getLevel().isGreaterOrEqual(Level.forName(level))) {\ntry {\nString json = JacksonUtil.writeValueAsString(event);\nProducerRecord<String, String> record = new ProducerRecord<>(topic, json);\nproducer.send(record);\n} catch (JsonProcessingException e) {\nlog.error(\\\"Failed to serialize event\\\", e);\n} catch (Exception e) {\nlog.warn(\\\"Failed to send event\\\", e);\n}\n}\n}", "CodeBleu_score": 37.20644473943491}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tif (event.getLevel().isGreaterOrEqual(Level.getLevel(level)) &&!event.getLoggerName().contains(\\\"xxx\\\")) {\nString message = layout.toSerializable(event).toString();\nString key = UUID.randomUUID().toString();\nString value = JacksonUtil.writeValueAsString(new LogEvent(appId, containerId, containerType, taskName, taskId, nodeIp, event.getLoggerName(), event.getLevel().toString(), event.getMessage().getFormattedMessage(), message, event.getThreadName(), event.getThreadId(), event.getMarker(), event.getThrown(), event.getInstant().toString()));\nproducer.send(new ProducerRecord<>(topic, key, value));\n}\n}", "CodeBleu_score": 34.02327336154419}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method: %q\\\", method)\n}", "CodeBleu_score": 77.59677383921586}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method: %q\\\", method)\n}", "CodeBleu_score": 77.59677383921586}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, m := range ValidTopicSuffixMethods {\n\t\tif method == m {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method '%s', valid methods are %s\\\", method, strings.Join(ValidTopicSuffixMethods, \\\", \\\"))\n}", "CodeBleu_score": 67.14275099999097}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \\\"\\\" {\n\t\tif routingValue, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn routingValue, nil\n\t\t}\n\t}\n\tif k.RoutingKey == \\\"random\\\" {\n\t\treturn uuid.Must(uuid.NewV4()).String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 52.54344263112733}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \\\"\\\" {\n\n\t\tif t, ok := metric.GetTag(k.RoutingTag); ok {\n\n\t\t\treturn t, nil\n\n\t\t}\n\n\t}\n\n\tif k.RoutingKey == \\\"random\\\" {\n\n\t\tuuid, err := uuid.NewV4()\n\n\t\tif err!= nil {\n\n\t\t\treturn \\\"\\\", err\n\n\t\t}\n\n\t\treturn uuid.String(), nil\n\n\t}\n\n\treturn k.RoutingKey, nil\n\n}", "CodeBleu_score": 66.96841029947389}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \\\"\\\" {\n\t\tif tagValue, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tagValue, nil\n\t\t}\n\t}\n\tif k.RoutingKey == \\\"random\\\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 51.99600457060879}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\txps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tcompiled, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic regexp %q: %w\\\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = *compiled\n\t}\n\treturn nil\n}", "CodeBleu_score": 47.1564917425724}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\txps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\\\"failed to compile regexp %q: %w\\\", re, err)\n\t\t}\n\t\tk.regexps[i] = *r\n\t}\n\treturn nil\n}", "CodeBleu_score": 47.417738818962576}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t(k.regexps)!= len(k.TopicRegexps) {\n\t\tk.regexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\t}\n\tfor i, re := range k.TopicRegexps {\n\t\tcompiled, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic regexp %q: %w\\\", re, err)\n\t\t}\n\t\tk.regexps[i] = *compiled\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.97498689145049}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.log.Debugf(\\\"message %s not found in undelivered map\\\", track.ID)\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\th.sem <- empty{}\n\n\tif err := msg.session.MarkMessage(msg.message, \\\"delivered\\\"); err!= nil {\n\t\th.log.Errorf(\\\"failed to mark message %s as delivered: %s\\\", track.ID, err)\n\t}\n}", "CodeBleu_score": 60.48136801114157}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.log.Debugf(\\\"onDelivery: message %v not found in undelivered map\\\", track.ID)\n\t\treturn\n\t}\n\n\tdelete(h.undelivered, track.ID)\n\th.log.Debugf(\\\"onDelivery: message %v marked as delivered\\\", track.ID)\n\tmsg.session.MarkMessage(msg.message, \\\"\\\")\n\th.sem <- empty{}\n}", "CodeBleu_score": 57.286455621566404}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.mu.Unlock()\n\t\th.log.Debugf(\\\"onDelivery: delivery ID %v not found in undelivered map\\\", track.ID)\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\n\t// Mark the message as delivered in the session.\n\terr := msg.session.MarkMessage(msg.message, \"\")\n\tif err!= nil {\n\t\th.log.Errorf(\\\"onDelivery: mark message as delivered: %v\\\", err)\n\t\treturn\n\t}\n\n\t// Release a semaphore slot.\n\th.sem <- empty{}\n}", "CodeBleu_score": 52.96735915382873}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx, cancel := context.WithCancel(context.Background())\n\tdefer cancel()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(session, msg); err!= nil {\n\t\t\t\th.log.Errorf(\\\"message handler error: %s\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 55.54817650174202}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tfor {\n\t\tselect {\n\t\tcase <-session.Context().Done():\n\t\t\treturn session.Context().Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.Handle(session, msg)\n\t\t\tif err!= nil {\n\t\t\t\th.log.Errorf(\\\"Failed to process message: %s\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 55.93923320162426}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\tif err := h.Handle(session, msg); err!= nil {\n\t\t\t\th.log.Errorf(\\\"failed to handle message: %s\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 58.997177516666866}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength)\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\ncheckCondition(!logkafka_id.equals(\".\"), LogkafkaIdIsDot)\ncheckCondition(!logkafka_id.equals(\"..\"), LogkafkaIdIsDotDot)\n}", "CodeBleu_score": 82.74806810253763}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength)\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\ncheckCondition(!logkafka_id.equals(\".\"), LogkafkaIdIsDot)\ncheckCondition(!logkafka_id.equals(\"..\"), LogkafkaIdIsDotDot)\n}", "CodeBleu_score": 82.74806810253763}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(logkafka_id!= \".\" && logkafka_id!= \"..\", LogkafkaIdIsDot)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength)\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\n}", "CodeBleu_score": 81.85811517030483}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n    val promise = Promise[ApiError \\/ FOutput]()\n\n    val timeout = apiTimeout\n\n    val future = apiExecutionContext.timeout(timeout, promise.future)\n\n    kafkaManagerActor! msg\n\n    future.onComplete {\n\n      case Success(response) =>\n\n        promise.success(response match {\n\n          case Left(error) => Left(error)\n\n          case Right(output) =>\n\n            try {\n\n              fn(output)\n\n            } catch {\n\n              case NonFatal(t) =>\n\n                warn(s\\\"Error transforming response from Kafka manager actor: $t\\\")\n\n                Left(KafkaManagerError(s\\\"Error transforming response from Kafka manager actor: $t\\\"))\n\n            }\n\n        })\n\n      case Failure(t) =>\n\n        promise.failure(t)\n\n    }\n\n    promise.future\n\n  }", "CodeBleu_score": 25.8629603032356}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n    val future = system.actorSelection(kafkaManagerActor).ask(msg)\n    future.mapTo[ApiError \\/ FOutput].recover { case e =>\n      val error = ApiError(\n        s\\\"Error processing message: ${msg.getClass.getName}\\\",\n        e\n      )\n      error.log\n      Left(error)\n    } map { case Left(e) => Left(e) case Right(v) => Right(fn(v)) }\n  }", "CodeBleu_score": 20.261958079990865}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n    import scala.concurrent.ExecutionContext.Implicits.global\n    val future = apiExecutionContext.execute {\n      val result = Await.result(kafkaManagerActor? msg, apiTimeout)\n      result match {\n        case ApiError(error) =>\n          error.log()\n          Left(error)\n        case output =>\n          try {\n            Right(fn(output))\n          } catch {\n            case e: Throwable =>\n              error(s\\\"Failed to transform output: $output\\\", e)\n              Left(ApiError(e))\n          }\n      }\n    }\n    future.recover { case e: Throwable =>\n      error(s\\\"Failed to process message: $msg\\\", e)\n      Left(ApiError(e))\n    }\n  }", "CodeBleu_score": 25.844478860816466}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\nIt takes an input message and a function to handle the output.\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\nIf an ActorErrorResponse is received, it returns an ApiError.\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n */\n    implicit val ec = apiExecutionContext\n    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) =>\n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover { case t: Throwable =>\n      error(s\"Failed on input : $msg\", t)\n      -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 69.50556099887355}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\nIt takes an input message and a function to handle the output.\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\nIf an ActorErrorResponse is received, it returns an ApiError.\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n */\n    implicit val ec = apiExecutionContext\n    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) =>\n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover { case t: Throwable =>\n      error(s\"Failed on input : $msg\", t)\n      -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 69.50556099887355}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val req = KMClusterCommandRequest(clusterName, topics)\n    withKafkaManagerActor(KMRunPreferredLeaderElection(req)) { result: KMCommandResult =>\n      result.result.map(toDisjunction)\n    }\n  }", "CodeBleu_score": 31.019789509383333}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val request = KMClusterCommandRequest(clusterName, topics, KMClusterCommand.PreferredLeaderElection)\n    withKafkaManagerActor(request) { result: KMClusterCommandResult =>\n      result.result.map(toDisjunction).map {\n        case \\/-(clusterContext) =>\n          \\/-(clusterContext)\n        case -\\/(err) =>\n          -\\/(err)\n      }\n    }\n  }", "CodeBleu_score": 24.18310835769494}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n    implicit val ec = apiExecutionContext\n    system.actorSelection(kafkaManagerActor).ask(KMRunPreferredLeaderElection(clusterName, topics)).map {\n      case err: ActorErrorResponse =>\n        error(s\\\"Failed on input : $clusterName\\\")\n        -\\/(ApiError.from(err))\n      case o: ClusterContext =>\n        \\/-(o)\n    }.recover { case t: Throwable =>\n      error(s\\\"Failed on input : $clusterName\\\", t)\n      -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 44.225066537874866}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMRunPreferredLeaderElection(Set()))) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 46.29481099369258}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMRunPreferredLeaderElectionWithAllTopics)) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 46.55180323067858}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMRunPreferredLeaderElection(Set.empty[String]))) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 48.69824657342767}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMManualPartitionAssignments(assignments))) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 19.32505683647929}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\nDescribeClusterResult describeClusterResult = admin.describeCluster();\nList<Node> nodes = describeClusterResult.nodes().get();\nif (nodes.isEmpty()) {\nthrow new ConnectException(\\\"No Kafka nodes found in cluster at \\\" + producerConfig.getString(BOOTSTRAP_SERVERS));\n}\n\n// Select the first node's ID\nNode node = nodes.get(0);\nint nodeId = node.id();\n\n// Request its configuration\nDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\nMap<ConfigResource, Config> configs = describeConfigsResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\nif (configs.isEmpty()) {\nthrow new ConnectException(\\\"No configuration found for Kafka broker at \\\" + producerConfig.getString(BOOTSTRAP_SERVERS));\n}\n\n// Return the broker's configuration\nreturn configs.values().iterator().next();\n}\ncatch (ExecutionException e) {\nthrow e.getCause();\n}\n}", "CodeBleu_score": 36.029629449193656}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\nDescribeClusterResult clusterResult = admin.describeCluster();\nList<Node> nodes = clusterResult.nodes().get();\nif (nodes.isEmpty()) {\nthrow new ConnectException(\\\"No nodes available in the cluster\\\");\n}\n\n// Select the first node's ID\nint nodeId = nodes.get(0).id();\n\n// Request the node's configuration\nDescribeConfigsResult configsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\nList<Config> configs = configsResult.all().get().get(ConfigResource.Type.BROKER, nodeId);\nif (configs.isEmpty()) {\nthrow new ConnectException(\\\"No configurations available for the node\\\");\n}\n\n// Return the node's configuration\nreturn configs.get(0);\n}\ncatch (ExecutionException ex) {\nthrow ex.getCause();\n}\n}", "CodeBleu_score": 47.99408320893976}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\nDescribeClusterResult clusterResult = admin.describeCluster().all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\nif (clusterResult.nodes().isEmpty()) {\nthrow new ConnectException(\\\"Unable to obtain the broker configuration. No nodes are available.\\\");\n}\n\nString brokerId = clusterResult.nodes().values().iterator().next().id();\n\nDescribeConfigsResult brokerConfigResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, brokerId))).all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\nif (brokerConfigResult.values().isEmpty()) {\nthrow new ConnectException(\\\"Unable to obtain the broker configuration. No configurations are available.\\\");\n}\n\nreturn brokerConfigResult.values().iterator().next();\n}", "CodeBleu_score": 54.808774948344855}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic List<ConfigIssue> all() {\n\t\t\tif (schemaHistory.equals(KafkaSchemaHistory.class)) {\n\t\t\t\treturn validator.all();\n\t\t\t}\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t};\n}", "CodeBleu_score": 15.381417602574507}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic List<ValidationResult> validate(final Map<String, String> props) {\n\t\t\tif (SchemaHistory.isKafkaSchemaHistory(props)) {\n\t\t\t\treturn validator.validate(props);\n\t\t\t}\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t};\n}", "CodeBleu_score": 21.582208761512994}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic List<ValidationResult> validate(final Map<String, String> properties) {\n\t\t\tif (KafkaSchemaHistory.isKafkaSchemaHistory(properties)) {\n\t\t\t\treturn validator.validate(properties);\n\t\t\t}\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t};\n}", "CodeBleu_score": 21.697903378512457}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\ttring topicCreationEnabled = (String) config.getOrDefault(\\\"topic.creation.enable\\\", \\\"true\\\");\nfinal String kafkaVersion = AppInfoParser.getVersion();\nfinal Version kafkaConnectVersion = parseVersion(kafkaVersion);\nreturn TOPIC_CREATION_KAFKA_VERSION.compareTo(kafkaConnectVersion) <= 0 && Boolean.parseBoolean(topicCreationEnabled);\n}", "CodeBleu_score": 24.275339044807648}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tl == this.isTopicCreationEnabled) {\nfinal String topicCreationEnableConfig = (String) config.getOrDefault(\\\"topic.creation.enable\\\", \\\"true\\\");\nfinal Boolean topicCreationEnable = Boolean.parseBoolean(topicCreationEnableConfig);\nfinal Version kafkaVersion = parseVersion(AppInfoParser.parse(context.getServerInfo()).version());\nfinal Boolean topicCreationEnabled = (topicCreationEnable && kafkaVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0);\nthis.isTopicCreationEnabled = topicCreationEnabled;\n}\nreturn this.isTopicCreationEnabled;\n}", "CodeBleu_score": 17.253275470208123}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\ttring topicCreationProperty = (String) config.getOrDefault(\\\"topic.creation.enable\\\", \\\"true\\\");\nfinal Boolean topicCreationEnabled = Boolean.parseBoolean(topicCreationProperty);\nif (topicCreationEnabled) {\nfinal String version = AppInfoParser.parse(context.getServerInfo()).version();\nfinal Version kafkaConnectVersion = parseVersion(version);\nreturn kafkaConnectVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0;\n}\nreturn false;\n}", "CodeBleu_score": 22.813818439405125}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new DebeziumException(\\\"Missing configuration option: 'client.id'\\\");\n}\nfinal Map<String, String> adminProps = new HashMap<>(config);\nadminProps.remove(CLIENT_ID_CONFIG);\nfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\nreturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 32.649620492798334}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new DebeziumException(\\\"The 'client.id' configuration option must be specified\\\");\n}\nMap<String, Object> adminProperties = new HashMap<>(config);\nadminProperties.remove(CLIENT_ID_CONFIG);\nadminProperties.remove(DistributedConfig.GROUP_ID_CONFIG);\nadminProperties.remove(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG);\nSharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\nreturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 37.075864889232705}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t", "CodeBleu_score": 4.242655504045899}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t(node.isObject()) {\nJsonNode payload = node.get(PAYLOAD_FIELD);\nif (payload!= null) {\nnode = payload;\n}\n}\n\nif (node.isObject()) {\nIterator<String> fields = node.fieldNames();\nif (fields.hasNext()) {\nString field = fields.next();\nJsonNode value = node.get(field);\nif (value.isValueNode()) {\nreturn reader.readValue(value);\n}\nelse {\nreturn reader.readValue(node);\n}\n}\n}\n\nthrow new RuntimeException(\\\"Cannot deserialize key from \\\" + node);\n}", "CodeBleu_score": 43.913693951124564}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tator<Map.Entry<String, JsonNode>> fields = node.fields();\n\nif (fields.hasNext()) {\nMap.Entry<String, JsonNode> field = fields.next();\n\nif (field.getValue().isValueNode()) {\nreturn reader.readValue(field.getValue());\n}\nelse {\nreturn reader.readValue(node);\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 34.196074155828185}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\nStringBuilder sb = new StringBuilder(topicName.length());\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isInvalidCharacter(c)) {\nsb.append(REPLACEMENT_CHAR);\nLOGGER.warn(\\\"Invalid character '{}' in topic name '{}', replacing with '{}'\\\", c, topicName, REPLACEMENT_CHAR);\n} else {\nsb.append(c);\n}\n}\nreturn sb.toString();\n}", "CodeBleu_score": 47.686787630506494}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\nStringBuilder sanitizedTopicName = new StringBuilder();\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (Character.isLetterOrDigit(c) || c == '-' || c == '_') {\nsanitizedTopicName.append(c);\n} else {\nsanitizedTopicName.append(REPLACEMENT_CHAR);\nLOGGER.warn(\\\"Topic name \\\" + topicName + \\\" contains invalid character \\\" + c + \\\". Replacing with \\\" + REPLACEMENT_CHAR + \\\".\\\");\n}\n}\nif (sanitizedTopicName.length()!= topicName.length()) {\nLOGGER.warn(\\\"Topic name \\\" + topicName + \\\" contains invalid characters. Replacing with \\\" + sanitizedTopicName + \\\".\\\");\n}\nreturn sanitizedTopicName.toString();\n}", "CodeBleu_score": 46.20234150867791}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\nString sanitizedTopicName = sanitize(topicName);\nif (!topicName.equals(sanitizedTopicName)) {\nLOGGER.warn(\\\"Topic name '{}' contains invalid characters and has been sanitized to '{}'.\\\", topicName, sanitizedTopicName);\n}\nreturn sanitizedTopicName;\n}", "CodeBleu_score": 23.06007940501054}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\nthis.retries = replacedErrorHandler == null? 0 : replacedErrorHandler.retries;\nthis.maxRetries = connectorConfig.maxRetries();\n}", "CodeBleu_score": 56.73703399839829}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\nthis.maxRetries = connectorConfig.getMaxRetries();\nif (maxRetries == RETRIES_UNLIMITED) {\nmaxRetries = Integer.MAX_VALUE;\n}\nif (replacedErrorHandler!= null) {\nretries = replacedErrorHandler.getRetries();\n}\n}", "CodeBleu_score": 68.85306604735747}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t", "CodeBleu_score": 5.012523737021215}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tr (Field field : fields) {\n\t\tConfigValue value = configuration.getConfigValue(field.name());\n\t\tif (value.errorMessages().size() > 0) {\n\t\t\tthrow new ConfigException(value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 30.607347365919768}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tp<String, ConfigValue> values = configuration.values();\n\tfor (Field field : fields) {\n\t\tConfigValue value = values.get(field.name());\n\t\tif (value == null) {\n\t\t\tthrow new ConfigException(\\\"Missing configuration value for \\\" + field.name());\n\t\t}\n\t\tif (value.validationError()!= null) {\n\t\t\tthrow new ConfigException(value.validationError());\n\t\t}\n\t}\n}", "CodeBleu_score": 37.36232892101699}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nSchemaBuilder schemaBuilder = SchemaBuilder.struct();\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nSchema nestedSchema = buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level);\nschemaBuilder.field(field.name(), nestedSchema);\n}\nelse {\nschemaBuilder.field(field.name(), field.schema());\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader!= null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> schemaBuilder.field(s, Schema.STRING_SCHEMA));\n}\n}\n\nreturn schemaBuilder.build();\n}", "CodeBleu_score": 44.54466031417096}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nSchemaBuilder newSchemaBuilder = SchemaBuilder.struct().name(oldSchema.name());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nSchema nestedSchema = requireStruct(oldSchema.field(field.name()).schema(), \"Nested schema\");\nnewSchemaBuilder.field(field.name(), buildNewSchema(field.name(), nestedSchema, headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemaBuilder.field(field.name(), field.schema());\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\nHeader currentHeader = headerToProcess.get(headers.get(i));\nif (currentHeader!= null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> newSchemaBuilder.field(s, Schema.STRING_SCHEMA));\n}\n}\n\nSchema newSchema = newSchemaBuilder.build();\n\nLOGGER.debug(\"Copied fields: {}\", oldSchema.fields());\nLOGGER.debug(\"Added fields: {}\", newSchema.fields());\n\nreturn newSchema;\n}", "CodeBleu_score": 53.734098928338426}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nSchemaBuilder newSchemaBuilder = new SchemaBuilder(SchemaBuilder.STRING_SCHEMA);\n\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nSchema nestedFieldSchema = buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level);\nnewSchemaBuilder.field(field.name(), nestedFieldSchema);\n}\nelse {\nnewSchemaBuilder.field(field.name(), field.schema());\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader!= null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> newSchemaBuilder.field(s, Schema.STRING_SCHEMA));\n}\n}\n\nreturn newSchemaBuilder.build();\n}", "CodeBleu_score": 47.811222587402696}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 26.21092239617402}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\n\nif (source.schema().field(\"snapshot\") == null) {\nreturn null;\n}\n\nString snapshotString = source.getString(\"snapshot\");\nif (snapshotString!= null) {\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}\n\nreturn null;\n}", "CodeBleu_score": 36.99791494071364}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source == null) {\nreturn null;\n}\nString snapshotString = source.getString(SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 26.21092239617402}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\n    if (version == null || version.isEmpty()) {\n\n      return Optional.empty();\n\n    }\n\n    String[] parts = version.split(\"\\\\.\");\n\n    if (parts.length > 2) {\n\n      version = parts[0] + \".\" + parts[1];\n\n    }\n\n    parts = version.split(\"-\");\n\n    if (parts.length > 1) {\n\n      version = parts[0];\n\n    }\n\n    return Optional.of(Float.parseFloat(version));\n\n  }", "CodeBleu_score": 66.18960424888716}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\n  String[] split = version.split(\"-\")[0].split(\"\\\\.\");\n\n  if (split.length > 2) {\n\n    version = version.substring(0, version.indexOf(\"-\"));\n\n  }\n\n  return Optional.of(Float.parseFloat(version));\n\n}", "CodeBleu_score": 44.59537073099996}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\n\n\n  if (version == null || version.isEmpty()) {\n    return Optional.empty();\n  }\n\n  String[] versionParts = version.split(\"\\\\.\");\n  if (versionParts.length > 2) {\n    versionParts = new String[] {versionParts[0], versionParts[1]};\n  }\n\n  String[] hyphenSplit = versionParts[0].split(\"-\");\n  if (hyphenSplit.length > 1) {\n    versionParts[0] = hyphenSplit[0];\n  }\n\n  return Optional.of(Float.parseFloat(versionParts[0]));\n}", "CodeBleu_score": 47.483058313743534}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.CREATE)\n   .operationName(\\\"createConnector\\\")\n   .build();\n\nreturn validateAccess(context)\n   .then(connector.map(newConnector -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, newConnector)))\n   .map(ResponseEntity::ok)\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 67.17293485880542}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connector(connector.block().getName())\n   .connectorActions(ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context)\n   .then(connector.flatMap(newConnector -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, newConnector)))\n   .map(ResponseEntity::ok)\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 69.17514615568125}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.CREATE)\n   .operationName(\\\"createConnector\\\")\n   .build();\n\nreturn validateAccess(context)\n   .then(connector.map(newConnectorDTO -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, newConnectorDTO)))\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 64.16490553623866}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n.connector(connectorName)\n.operationName(\"deleteConnector\")\n.build();\n\nreturn validateAccess(context)\n.then(kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName))\n.map(ResponseEntity::ok)\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 43.75196202088006}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n   .connector(connectorName)\n   .operationName(\"deleteConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::noContent)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 55.146836185929175}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n   .connector(connectorName)\n   .operationName(\"deleteConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::noContent)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 55.146836185929175}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"updateConnectorState\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService\n       .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 58.10821562060819}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(action.getConnectActions())\n   .connector(connectorName)\n   .operationName(\"updateConnectorState\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService\n       .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 57.64969202231206}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n       .connector(connectorName)\n       .operationName(\"updateConnectorState\")\n       .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n       .build();\n\nreturn validateAccess(context)\n       .then(kafkaConnectService\n               .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n               .map(ResponseEntity::ok))\n       .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 57.63192681833822}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder applicationBuilder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tapplicationBuilder.initializers(new DynamicConfigOperations());\n\treturn applicationBuilder.run(args);\n}", "CodeBleu_score": 41.371408844060284}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigOperations());\n\treturn builder.run(args);\n}", "CodeBleu_score": 43.48050838217312}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\nbuilder.initializers(new DynamicConfigOperations());\nreturn builder.run(args);\n}", "CodeBleu_score": 43.4710942715796}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tch == null\n   ? (connector) -> true\n    : (connector) -> connector.getConnector().getName().contains(search, IGNORE_CASE)\n        || connector.getConnector().getType().contains(search, IGNORE_CASE)\n        || connector.getConnector().getConnectorPlugin().getClassName().contains(search, IGNORE_CASE)\n        || connector.getConnector().getConnectorPlugin().getType().contains(search, IGNORE_CASE)\n        || connector.getConnector().getConnectorPlugin().getVersion().contains(search, IGNORE_CASE)\n        || connector.getConnector().getTasks().stream().anyMatch(task ->\n            task.getConnector().getName().contains(search, IGNORE_CASE)\n                || task.getConnector().getType().contains(search, IGNORE_CASE)\n                || task.getConnector().getConnectorPlugin().getClassName().contains(search, IGNORE_CASE)\n                || task.getConnector().getConnectorPlugin().getType().contains(search, IGNORE_CASE)\n                || task.getConnector().getConnectorPlugin().getVersion().contains(search, IGNORE_CASE)\n        )\n        || connector.getTopics().stream().anyMatch(topic -> topic.getName().contains(search, IGNORE_CASE));\n}", "CodeBleu_score": 28.211175426554263}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tch == null\n   ? t -> true\n    : t -> t.getConnector().getName().contains(search) || t.getConnector().getConnectorClass().contains(search);\n  }", "CodeBleu_score": 36.29764193167312}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t", "CodeBleu_score": 7.0787479533471265}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * The validateClusterNames function validates that the names of the clusters in the clusters list are unique.\nIt creates a set of cluster names and checks if the set size is equal to the list size.\nIf the set size is not equal to the list size, it throws an exception indicating that the cluster names are not unique.\n */\n  private void validateClusterNames() {\n\n}\n\n}", "CodeBleu_score": 13.162153268417539}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t", "CodeBleu_score": 11.217587828108096}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t*\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\nIf the value is another map, it recursively flattens it with the new key as the prefix.\nOtherwise, it adds the key-value pair to the flattened map.\nFinally, it returns the flattened map.\n */\n    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = prefix == null? entry.getKey() : prefix + \\\".\\\" + entry.getKey();\n        if (entry.getValue() instanceof Map) {\n          flattenedProperties.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n        } else {\n          flattenedProperties.put(key, entry.getValue());\n        }\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 46.22260314291361}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tAclOperation> authorizedOperations = clusterDescription.getAuthorizedOperations();\n\n// If the cluster description is null, return an empty Mono.\nif (clusterDescription == null) {\nreturn Mono.empty();\n}\n\n// If the user has permissions for all operations, return the KAFKA_ACL_EDIT feature.\nif (authorizedOperations.contains(AclOperation.ALL)) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}\n\n// If the user has permissions for alter operations, return the KAFKA_ACL_EDIT feature.\nif (authorizedOperations.contains(AclOperation.ALTER)) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}\n\n// If the user does not have permissions for alter operations, return an empty Mono.\nreturn Mono.empty();\n}", "CodeBleu_score": 37.312826807145726}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t", "CodeBleu_score": 4.927575001772918}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\trn adminClient.getOperations()\n\t\t.filter(o -> o.getOperation().equals(AclOperation.ALTER.name()))\n\t\t.flatMap(o -> adminClient.isAclViewEnabled()\n\t\t\t? Mono.just(ClusterFeature.KAFKA_ACL_EDIT)\n\t\t\t: Mono.empty())\n\t\t.switchIfEmpty(Mono.empty());\n}", "CodeBleu_score": 29.13690026546464}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> range = new TreeMap<>(Comparator.comparingInt(tp -> tp.partition()));\nif (!prevRange.isEmpty()) {\nrange.putAll(prevRange);\n} else {\nrange.putAll(seekOperations.getOffsets());\n}\nint messagesPerPartition = getMessagesPerPartition(range);\nrange.forEach((tp, offset) -> {\nlong start = offset.from;\nif (start > offset.to) {\nstart = offset.to;\n}\nrange.put(tp, new FromToOffset(start, offset.to));\n});\nrange.replaceAll((tp, offset) -> new FromToOffset(offset.from - messagesPerPartition, offset.to));\nreturn range;\n}", "CodeBleu_score": 31.258947615809983}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t", "CodeBleu_score": 3.709413387662834}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>(Comparator.comparing(TopicPartition::partition));\n\tif (prevRange.isEmpty()) {\n\t\tnextRange.putAll(seekOperations.getOffsets());\n\t} else {\n\t\tnextRange.putAll(prevRange);\n\t}\n\tint messagesToPoll = Math.min(messagesPerPage, pollingSettings.getMaxPollRecords());\n\tfor (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\n\t\tTopicPartition topicPartition = entry.getKey();\n\t\tFromToOffset fromToOffset = entry.getValue();\n\t\tlong fromOffset = fromToOffset.getFrom();\n\t\tlong toOffset = fromToOffset.getTo();\n\t\tlong offset = fromOffset;\n\t\tif (fromOffset > toOffset) {\n\t\t\toffset = toOffset;\n\t\t}\n\t\tlong nextOffset = offset - messagesToPoll;\n\t\tnextRange.put(topicPartition, new FromToOffset(nextOffset, toOffset));\n\t}\n\treturn nextRange;\n}", "CodeBleu_score": 41.55742755843585}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t\t// Validate configuration\n\tif (configuration.getBoolean(CK_LEGACY)) {\n\t\tfinal String zookeeper = configuration.getString(CK_ZOOKEEPER);\n\t\tfinal String bootstrapServer = configuration.getString(CK_BOOTSTRAP);\n\t\tif (Strings.isNullOrEmpty(zookeeper)) {\n\t\t\tthrow new ConfigurationException(\\\"ZooKeeper is required in legacy mode.\\\");\n\t\t}\n\t\tif (Strings.isNullOrEmpty(bootstrapServer)) {\n\t\t\tthrow new ConfigurationException(\\\"Bootstrap server is required in legacy mode.\\\");\n\t\t}\n\t} else {\n\t\tfinal String topicFilter = configuration.getString(CK_TOPIC_FILTER);\n\t\tif (Strings.isNullOrEmpty(topicFilter)) {\n\t\t\tthrow new ConfigurationException(\\\"Topic filter is required in consumer mode.\\\");\n\t\t}\n\t}\n\n\t// Register for server lifecycle events\n\tserverEventBus.register(this);\n\tserverEventBus.register(input);\n\n\t// Schedule task to update last second bytes read every second\n\tscheduler.scheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n\n\t// Launch input\n\tif (configuration.getBoolean(CK_LEGACY)) {\n\t\tlaunchLegacyInput(input);\n\t} else {\n\t\tlaunchConsumerInput(input);\n\t}\n}", "CodeBleu_score": 50.38262298801295}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\tfinal String customPropertiesString = configuration.getString(CK_CUSTOM_PROPERTIES);\nif (customPropertiesString!= null) {\ntry {\nfinal Properties customProperties = new Properties();\ncustomProperties.load(new StringReader(customPropertiesString));\nprops.putAll(customProperties);\n} catch (IOException e) {\nLOG.error(\\\"Failed to load custom properties from string\\\", e);\n}\n}\n}", "CodeBleu_score": 51.38820147474581}, {"code": "private void insertCustomProperties(Properties props){\n\t\tfinal String customProperties = configuration.getString(CK_CUSTOM_PROPERTIES);\n\tif (customProperties!= null) {\n\t\ttry {\n\t\t\tfinal Properties customPropertiesProps = new Properties();\n\t\t\tcustomPropertiesProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customPropertiesProps);\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Failed to load custom properties.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 52.586541175018844}, {"code": "private void insertCustomProperties(Properties props){\n\tfinal String customPropertiesString = configuration.getString(CK_CUSTOM_PROPERTIES);\nif (customPropertiesString!= null) {\ntry {\nfinal Properties customProperties = new Properties();\ncustomProperties.load(new StringReader(customPropertiesString));\nprops.putAll(customProperties);\n} catch (IOException e) {\nLOG.error(\\\"Failed to load custom properties from string: \\\" + customPropertiesString, e);\n}\n}\n}", "CodeBleu_score": 50.30967985762764}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t", "CodeBleu_score": 2.767906284169963}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tentries.isEmpty()) {\nreturn;\n}\n\n// Filter out null entries\nList<Journal.Entry> entriesToWrite = entries.stream().filter(Objects::nonNull).map(this::toJournalEntry).collect(Collectors.toList());\n\n// Calculate total message bytes\nlong totalBytes = entriesToWrite.stream().mapToLong(Journal.Entry::getSize).sum();\n\n// Write to journal\ntry {\nwriteRetryer.call(() -> {\n    journalFilled.acquire();\n    try {\n        kafkaJournal.write(entriesToWrite);\n    } finally {\n        journalFilled.release();\n    }\n});\n    metrics.writtenMessages().inc(entriesToWrite.size());\n    metrics.writtenBytes().inc(totalBytes);\n} catch (InterruptedException | ExecutionException e) {\n    throw new MessageQueueException(\\\"Unable to write to journal\\\", e);\n}\n}", "CodeBleu_score": 42.23560576390618}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t{\n// Filter out null entries\nList<Journal.Entry> journalEntries = entries.stream()\n.filter(Objects::nonNull)\n.map(entry -> new Journal.Entry(entry.getTimestamp(), entry.getUuid(), entry.getPayload()))\n.collect(Collectors.toList());\n\n// Calculate total message bytes\nlong totalBytes = journalEntries.stream()\n.map(Journal.Entry::getPayload)\n.mapToLong(byte[]::length)\n.sum();\n\n// Attempt to write the entries to the journal\nwriteRetryer.call(() -> {\\\njournalFilled.acquire();\\\ntry {\\\nkafkaJournal.write(journalEntries);\\\n} finally {\\\njournalFilled.release();\\\n}\\\n});\n\n// Update metrics\nmetrics.writtenMessages().mark(journalEntries.size());\\\nmetrics.writtenBytes().mark(totalBytes);\\\n} catch (InterruptedException | ExecutionException e) {\\\nthrow new MessageQueueException(\\\"Unable to write to journal\\\", e);\\\n} catch (RetryException e) {\\\nthrow new MessageQueueException(\\\"Unable to write to journal\\\", e.getCause());\\\n}\n}", "CodeBleu_score": 48.581390058329035}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\tOptional<Long> maxValidId = messages.stream()\n.map(Message::getMessageId)\n.max(Long::compareTo);\n\nif (maxValidId.isPresent()) {\nkafkaJournal.acknowledge(maxValidId.get());\nmetrics.acknowledgedMessages.inc(messages.size());\n}\n}", "CodeBleu_score": 33.51720917475621}, {"code": "public void acknowledge(List<Message> messages){\n\tOptional<Long> maxMessageQueueId = messages.stream()\n.map(Message::getMessageQueueId)\n.max(Long::compareTo);\n\n\nif (maxMessageQueueId.isPresent()) {\nkafkaJournal.acknowledge(maxMessageQueueId.get());\nmetrics.incrementMessagesAcknowledged(messages.size());\n}\n}", "CodeBleu_score": 36.13529689692996}, {"code": "public void acknowledge(List<Message> messages){\n\tOptional<Long> max = messages.stream().map(Message::getMessageQueueId).max(Long::compareTo);\nif (max.isPresent()) {\nkafkaJournal.acknowledge(max.get());\nmetrics.acknowledgedMessages.inc(messages.size());\n}\n}", "CodeBleu_score": 34.10398836702839}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\tfinal String legacyMetricPrefix = \"org.graylog2.journal.kafka.LocalKafkaJournal\";\nfor (final MetricName metricName : this.metricRegistry.getNames()) {\nif (metricName.getName().startsWith(LocalKafkaJournal.class.getName())) {\nfinal String legacyMetricName = legacyMetricPrefix + metricName.getName().substring(LocalKafkaJournal.class.getName().length());\ntry {\nthis.metricRegistry.register(legacyMetricName, this.metricRegistry.metric(metricName));\n} catch (IllegalArgumentException e) {\nLOG.warn(\\\"Failed to register legacy metric {}. Original metric: {}\\\", legacyMetricName, metricName.getName());\n}\n}\n}\n}", "CodeBleu_score": 37.239303348601496}, {"code": "private void registerLegacyMetrics(){\n\tfinal Set<String> metrics = metricRegistry.getMetrics().keySet();\nfor (final String metric : metrics) {\nif (metric.startsWith(LocalKafkaJournal.class.getName())) {\nfinal String legacyMetric = metric.replace(LocalKafkaJournal.class.getName(), KafkaJournal.class.getName());\ntry {\nmetricRegistry.register(legacyMetric, metricRegistry.getMetrics().get(metric));\n} catch (IllegalArgumentException e) {\nLOG.warn(\\\"Failed to register metric {} as {}\\\", metric, legacyMetric);\n}\n}\n}\n}", "CodeBleu_score": 35.09818948700026}, {"code": "private void registerLegacyMetrics(){\n\tfinal List<String> metrics = metricRegistry.getNames();\nfor (final String metric : metrics) {\nif (metric.startsWith(LocalKafkaJournal.class.getName())) {\nfinal String legacyMetricName = metric.replace(LocalKafkaJournal.class.getName(), \\\"org.graylog2.journal.kafka.LocalKafkaJournal\\\");\ntry {\nmetricRegistry.register(legacyMetricName, metricRegistry.get(metric));\n} catch (final Exception e) {\nLOG.warn(\\\"Unable to register legacy metric {} as {}\\\", metric, legacyMetricName);\n}\n}\n}\n}", "CodeBleu_score": 25.97875121770197}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tfinal Timer timer = metricRegistry.timer(metricName);\ntry {\nreturn timer;\n} catch (IllegalArgumentException e) {\nreturn metricRegistry.getTimers().get(metricName);\n}\n}", "CodeBleu_score": 24.88803098284425}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tfinal Timer timer = metricRegistry.timer(metricName);\n\ttry {\n\t\tmetricRegistry.register(metricName, timer);\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 29.34527638098958}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\treturn metricRegistry.register(metricName, new HdrTimer());\n}", "CodeBleu_score": 5.985816693671486}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\ttry {\n\t\tmetricRegistry.register(name, new Gauge<Long>() {\n\t\t\t@Override\n\t\t\tpublic Long getValue() {\n\t\t\t\tif (committedOffset.get() == 0) {\n\t\t\t\t\treturn kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n\t\t\t\t} else {\n\t\t\t\t\treturn kafkaLog.logEndOffset() - committedOffset.get();\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} catch (IllegalArgumentException e) {\n\t\tLOG.warn(\"Unable to register metric <{}>.\", name);\n\t}\n}", "CodeBleu_score": 41.14133873437357}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\tfinal Timer timer = registerHdrTimer(metricRegistry, name);\nmetricRegistry.register(name, (Gauge<Long>) () -> {\nif (kafkaLog.size() == 0) {\nreturn 0L;\n} else if (committedOffset.get() == DEFAULT_OFFSET) {\nreturn kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n} else {\nreturn kafkaLog.logEndOffset() - committedOffset.get();\n}\n});\ntimer.update(System.currentTimeMillis(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 44.171966786652774}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\ttry {\n\t\tmetricRegistry.register(name, new Gauge<Integer>() {\n\t\t\t@Override\n\t\t\tpublic Integer getValue() {\n\t\t\t\tif (kafkaLog.size() == 0) {\n\t\t\t\t\treturn 0;\n\t\t\t\t} else if (committedOffset.get() == -1) {\n\t\t\t\t\treturn (int) (kafkaLog.logEndOffset() - kafkaLog.logStartOffset());\n\t\t\t\t} else {\n\t\t\t\t\treturn (int) (kafkaLog.logEndOffset() - committedOffset.get());\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} catch (IllegalArgumentException e) {\n\t\tLOG.warn(\"Unable to register metric <{}>.\", name);\n\t}\n}", "CodeBleu_score": 39.52961530610504}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\ttry (Timer.Context ignored = writeTime.time()) {\nif (messages.isEmpty()) {\nLOG.debug(\\\"No messages to flush\\\");\n} else {\nfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nLOG.debug(\\\"Flushing {} bytes message set with {} messages to avoid overflowing segment with max size of {} bytes\\\",\\\nmessageSetSize, messages.size(), maxSegmentSize);\nfinal long lastOffset = append(messageSet);\nLOG.debug(\\\"Flushed {} bytes message set with {} messages to offset {}\\\", messageSetSize, messages.size(), lastOffset);\nwrittenMessages.mark(messages.size());\n}\nreturn getLogEndOffset() - 1;\n}\n}", "CodeBleu_score": 35.23564856113969}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\ttry (Timer.Context ignored = writeTime.time()) {\nif (messages.isEmpty()) {\nLOG.debug(\\\"Flushing empty message set\\\");\nreturn getLogEndOffset();\n}\n\nfinal MessageSet messageSet = new MessageSet(messages);\nif (LOG.isDebugEnabled()) {\nLOG.debug(\\\"Flushing {} bytes message set with {} messages to avoid overflowing segment with max size of {} bytes\\\",\\\nmessageSetSize, messages.size(), maxSegmentSize);\n}\n\nfinal ByteBuffer buffer = ByteBuffer.wrap(messageSet.serialize());\nfinal long lastWriteOffset = log.append(buffer);\n\nif (LOG.isTraceEnabled()) {\nLOG.trace(\\\"Message set {} contains bytes {}\\\", bytesToHex(messageSet.serialize()), bytesToHex(messageSet.getMessages()));\n}\n\nwrittenMessages.mark(messages.size());\n\nreturn lastWriteOffset;\n}\n}", "CodeBleu_score": 46.51404440950566}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\ttry (Timer.Context ignored = writeTime.time()) {\nif (messages.isEmpty()) {\nLOG.debug(\\\"Flushing empty message set\\\");\nreturn -1;\n}\n\nfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nLOG.debug(\\\"Flushing {} bytes message set with {} messages\\\", messageSet.size(), messages.size());\n\nfinal long lastWriteOffset = append(messageSet);\nwriteMessages.mark(messages.size());\n\nif (LOG.isTraceEnabled()) {\nLOG.trace(\\\"Flushed message set with {} messages at offset {}\\\", messages.size(), lastWriteOffset);\n}\nreturn lastWriteOffset;\n}\n}", "CodeBleu_score": 36.888462351731356}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tist<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\nif (adminClientList == null) {\nreturn;\n}\n\nLOGGER.info(\\\"closing kafka-admin-client for cluster: {}\\\", clusterPhyId);\n\ntry {\nfor (AdminClient adminClient : adminClientList) {\nadminClient.close(Duration.ofSeconds(10));\n}\n} catch (Exception e) {\nLOGGER.error(\\\"failed to close kafka-admin-client for cluster: {}\\\", clusterPhyId, e);\n}\n\nKAFKA_ADMIN_CLIENT_MAP.remove(clusterPhyId);\n}", "CodeBleu_score": 33.47081189937759}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tist<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\nif (adminClientList == null) {\nreturn;\n}\nLOGGER.info(\\\"close kafka admin client, clusterPhyId: {}\\\", clusterPhyId);\nsynchronized (adminClientList) {\ntry {\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close();\n} catch (Exception e) {\nLOGGER.error(\\\"close kafka admin client failed, clusterPhyId: {}\\\", clusterPhyId, e);\n}\n}\n} catch (Exception e) {\nLOGGER.error(\\\"close kafka admin client failed, clusterPhyId: {}\\\", clusterPhyId, e);\n}\n}\n}", "CodeBleu_score": 41.52360509308576}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\n\tif (adminClientList == null) {\n\t\treturn;\n\t}\n\n\tsynchronized (KAFKA_ADMIN_CLIENT_MAP) {\n\t\tLOGGER.info(\\\"closeKafkaAdminClient start, clusterPhyId: {}\\\", clusterPhyId);\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close();\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\\\"closeKafkaAdminClient failed, clusterPhyId: {}, cause: {}\\\", clusterPhyId, e);\n\t\t\t}\n\t\t}\n\n\t\tadminClientList.clear();\n\t\tKAFKA_ADMIN_CLIENT_MAP.remove(clusterPhyId);\n\t\tLOGGER.info(\\\"closeKafkaAdminClient success, clusterPhyId: {}\\\", clusterPhyId);\n\t}\n}", "CodeBleu_score": 42.86859602170768}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tf (adminClientList == null) {\n\t\treturn true;\n\t}\n\n\tboolean allSuccess = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(Duration.ofSeconds(30));\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}, adminClient:{}\", clusterPhyId, adminClient, e);\n\t\t\tallSuccess = false;\n\t\t}\n\t}\n\n\treturn allSuccess;\n}", "CodeBleu_score": 71.17657475585209}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t (adminClientList == null) {\nreturn true;\n}\n\nboolean allSuccess = true;\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nallSuccess = false;\nLOGGER.error(\\\"close kafka AdminClient failed, clusterPhyId:{}\\\", clusterPhyId, e);\n}\n}\n\nreturn allSuccess;\n}", "CodeBleu_score": 66.07978346298172}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t (adminClientList == null) {\nreturn true;\n}\n\nboolean allSuccess = true;\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nallSuccess = false;\nLOGGER.error(\\\"close kafka AdminClient failed, clusterPhyId:{}\\\", clusterPhyId, e);\n}\n}\n\nreturn allSuccess;\n}", "CodeBleu_score": 66.07978346298172}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.close();\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 11.420297729639792}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop();\n\t\ttry {\n\t\t\tapp.close();\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tthrow new IllegalStateException(ex);\n\t\t}\n\t\tfinally {\n\t\t\tapp = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 28.909153260146038}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop();\n\t\ttry {\n\t\t\tapp.close();\n\t\t}\n\t\tcatch (Throwable t) {\n\t\t\t// ignore\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 20.511844445882854}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTls(caCert, serverCert, clientCert, KEY_STORE_PASSWORD, KEY_PASSWORD);\n\treturn runner;\n}", "CodeBleu_score": 37.75295297657192}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner server = new EurekaServerRunner(config);\n\tserver.enableTls(caCert, serverCert, clientCert, KEY_STORE_PASSWORD, KEY_PASSWORD);\n\treturn server;\n}", "CodeBleu_score": 46.65114006968694}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\teurekaServerRunner.enableTls(caCert, serverCert, clientCert, KEY_STORE_PASSWORD, KEY_PASSWORD, KEY_PASSWORD);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 48.89479080847049}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\");\n\tclient.enableTls();\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 63.787546820834585}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner service = new EurekaClientRunner(config, server, \"testservice\");\n\tservice.enableTls();\n\tservice.start();\n\treturn service;\n}", "CodeBleu_score": 77.81144326932356}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\");\n\tclient.enableTls();\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 63.787546820834585}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t", "CodeBleu_score": 1.403125619965593}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a KeyStore to store the CA certificate and private key\n\tKeyStore caKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\tcaKeyStore.load(null, null);\n\tsaveCert(caKeyStore, \"ca\", \"cakey\", \"cakeypassword\");\n\n\t// Create a KeyStore to store the server certificate and private key\n\tKeyStore serverKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\tserverKeyStore.load(null, null);\n\tsaveCert(serverKeyStore, \"server\", \"serverkey\", \"serverkeypassword\");\n\n\t// Create a KeyStore to store the client certificate and private key\n\tKeyStore clientKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\tclientKeyStore.load(null, null);\n\tsaveCert(clientKeyStore, \"client\", \"clientkey\", \"clientkeypassword\");\n\n\t// Create a KeyStore to store the second client certificate and private key\n\tKeyStore secondClientKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\tsecondClientKeyStore.load(null, null);\n\tsaveCert(secondClientKeyStore, \"secondclient\", \"secondclientkey\", \"secondclientkeypassword\");\n\n\t// Create a KeyStore to store the wrong client certificate and private key\n\tKeyStore wrongClientKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\twrongClientKeyStore.load(null, null);\n\tsaveCert(wrongClientKeyStore, \"wrongclient\", \"wrongclientkey\", \"wrongclientkeypassword\");\n\n\t// Create a KeyStore to store the wrong client certificate and private key\n\tKeyStore wrongCaKeyStore = KeyStore.getInstance(KeyStore.getDefaultType());\n\twrongCaKeyStore.load(null, null);\n\tsaveCert(wrongCaKeyStore, \"wrongca\", \"wrongcakey\", \"wrongcakeypassword\");\n\n\t// Save the KeyStores\n\tsaveKeyStore(caKeyStore, \"ca\", \"cakeypassword\");\n\tsaveKeyStore(serverKeyStore, \"server\", \"serverkeypassword\");\n\tsaveKeyStore(clientKeyStore, \"client\", \"clientkeypassword\");\n\tsaveKeyStore(secondClientKeyStore, \"secondclient\", \"secondclientkeypassword\");\n\tsaveKeyStore(wrongClientKeyStore, \"wrongclient\", \"wrongclientkeypassword\");\n\tsaveKeyStore(wrongCaKeyStore, \"wrongca\", \"wrongcakeypassword\");\n}", "CodeBleu_score": 16.21759708715345}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create CA certificate and key\n\tcreateAndSaveCaCertAndKey();\n\n\t// Create server certificate and key\n\tcreateAndSaveServerCertAndKey();\n\n\t// Create client certificate and key\n\tcreateAndSaveClientCertAndKey();\n\n\t// Create second CA certificate and key\n\tcreateAndSaveCaCertAndKey();\n\n\t// Create second client certificate and key\n\tcreateAndSaveClientCertAndKey();\n}", "CodeBleu_score": 5.0041934472917955}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + seconds * 1000;\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\tthrow new RuntimeException(\\\"Condition not met within the specified time limit\\\");\n}", "CodeBleu_score": 43.06057054901116}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + seconds * 1000;\n\twhile (!assertion.getAsBoolean() && System.currentTimeMillis() < timeLimit) {\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\tif (!assertion.getAsBoolean()) {\n\t\tthrow new RuntimeException(String.format(\\\"Timed out after %d seconds\\\", seconds));\n\t}\n}", "CodeBleu_score": 40.33360362543586}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + (seconds * 1000);\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\tthrow new RuntimeException(String.format(\\\"Condition not met within %d seconds\\\", seconds));\n}", "CodeBleu_score": 44.717405460482816}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate certificate = createCert(keyPair.getPublic(), keyPair.getPrivate(), ca, ca);\n\treturn certificate;\n}", "CodeBleu_score": 29.980914539500198}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate certificate = createCert(keyPair.getPublic(), keyPair.getPrivate(), ca, ca);\n\treturn certificate;\n}", "CodeBleu_score": 29.980914539500198}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate certificate = createCert(keyPair.getPublic(), keyPair.getPrivate(), ca, ca);\n\treturn certificate;\n}", "CodeBleu_score": 29.980914539500198}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) this.eurekaTransportField.get(getEurekaTransport());\n\t\t\tthis.eurekaHttpClient.set(eurekaHttpClient);\n\t\t}\n\t\tcatch (IllegalAccessException e) {\n\t\t\tlog.error(\\\"Unable to retrieve EurekaHttpClient\\\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.467863822783855}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\turekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\nif (eurekaHttpClient!= null) {\nreturn eurekaHttpClient;\n}\ntry {\nObject eurekaTransport = this.eurekaTransportField.get(this);\nObject registrationClient = ReflectionUtils.getField(eurekaTransport, \"registrationClient\");\neurekaHttpClient = (EurekaHttpClient) registrationClient;\nthis.eurekaHttpClient.set(eurekaHttpClient);\n}\ncatch (IllegalAccessException e) {\nlog.error(\\\"Unable to retrieve EurekaHttpClient\\\", e);\n}\nreturn eurekaHttpClient;\n}", "CodeBleu_score": 50.53899726834634}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) this.eurekaTransportField.get(this.getEurekaTransport());\n\t\t\tthis.eurekaHttpClient.set(eurekaHttpClient);\n\t\t}\n\t\tcatch (IllegalAccessException ex) {\n\t\t\tlog.error(\\\"Unable to get EurekaHttpClient from eurekaTransport\\\", ex);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 40.34599114238587}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications.size() > 0) {\n\t\tfor (Application application : applications.getRegisteredApplications()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 48.91437732190943}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tif (applications!= null) {\n\t\tfor (Application application : applications.getRegisteredApplications()) {\n\t\t\tif (application.getInstances().size() > 0) {\n\t\t\t\tservices.add(application.getName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 56.568491081674274}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tservices.add(application.getName().toLowerCase());\n\t}\n\treturn services;\n}", "CodeBleu_score": 63.434860470088594}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tString name = entry.getKey();\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tfor (HealthIndicator indicator : ((DiscoveryCompositeHealthContributor) value).getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\tthis.healthContributors.put(name, indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthis.healthContributors.put(name, value);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.25688089509689}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tfor (HealthContributor contributor : ((DiscoveryCompositeHealthContributor) entry.getValue()).getHealthContributors()) {\n\t\t\t\tif (!(contributor instanceof EurekaHealthIndicator)) {\n\t\t\t\t\tthis.healthContributors.put(entry.getKey(), contributor);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthis.healthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 52.07592966353655}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor healthContributor = entry.getValue();\n\t\tif (healthContributor instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) healthContributor;\n\t\t\tfor (HealthIndicator healthIndicator : compositeHealthContributor.getIndicators()) {\n\t\t\t\tif (!(healthIndicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\tthis.healthContributors.put(entry.getKey(), healthIndicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tthis.healthContributors.put(entry.getKey(), healthContributor);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.732513696614696}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances.isEmpty()) {\nthrow new RuntimeException(\\\"No service instance found for 'provider-application'\\\");\n}\nURI uri = instances.get(0).getUri();\nString response = restTemplate.postForObject(uri.resolve(\\\"/echo\\\"), \\\"Hello from consumer-application\\\", String.class);\nreturn response;\n}", "CodeBleu_score": 49.30763724771829}, {"code": "public String hello(){\n\tServiceInstance providerInstance = discoveryClient.getInstances(\"provider-application\").get(0);\nURI providerUri = providerInstance.getUri();\nString response = restTemplate.postForObject(providerUri, \"Hello from provider-application\", String.class);\nreturn \"Response from provider-application: \" + response;\n}", "CodeBleu_score": 38.79185449012088}, {"code": "public String hello(){\n\t", "CodeBleu_score": 1.2903316009083565}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = discoveryClient.getInstances(\"provider-application\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \"/echo\", null, String.class);\nreturn response;\n}\n\nthrow new RuntimeException(\"No service instance for provider-application found\");\n}", "CodeBleu_score": 74.54712621094008}, {"code": "public String world(){\n\tServiceInstance serviceInstance = loadBalancerClient.choose(\\\"provider-application\\\");\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \\\"/echo\\\", null, String.class);\nreturn response;\n}", "CodeBleu_score": 36.91000893074264}, {"code": "public String world(){\n\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \"/echo\", null, String.class);\nreturn response;\n}", "CodeBleu_score": 66.10177388495823}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"register: serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nSet<Server> servers = serverMap.computeIfAbsent(serviceName, k -> Collections.synchronizedSet(new HashSet<>()));\nservers.add(new Server(ip, port));\nreturn true;\n}", "CodeBleu_score": 65.22617053243928}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"registering service {} with ip {} and port {}\", serviceName, ip, port);\n\nSet<Server> serverSet = serverMap.get(serviceName);\nif (serverSet == null) {\nserverSet = Collections.synchronizedSet(new HashSet<>());\nserverMap.put(serviceName, serverSet);\n}\n\nServer server = new Server(ip, port);\nboolean result = serverSet.add(server);\n\nlogger.info(\"registered service {} with ip {} and port {}\", serviceName, ip, port);\n\nreturn result;\n}", "CodeBleu_score": 64.89837878524361}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\\\"register: serviceName={}, ip={}, port={}\\\", serviceName, ip, port);\nSet<Server> servers = serverMap.get(serviceName);\nif (servers == null) {\nsynchronized (serverMap) {\nservers = serverMap.get(serviceName);\nif (servers == null) {\nservers = Collections.synchronizedSet(new HashSet<>());\nserverMap.put(serviceName, servers);\n}\n}\n}\nServer server = new Server(ip, port);\nservers.add(server);\nreturn true;\n}", "CodeBleu_score": 62.08702371323268}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nserverMap.get(serviceName).remove(new Server(ip, port));\nreturn true;\n}", "CodeBleu_score": 46.494470105884986}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nif (serverMap.containsKey(serviceName)) {\nServer server = new Server(ip, port);\nserverMap.get(serviceName).remove(server);\nreturn true;\n}\nreturn false;\n}", "CodeBleu_score": 62.726437335816534}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nserverMap.get(serviceName).remove(new Server(ip, port));\nreturn true;\n}", "CodeBleu_score": 46.494470105884986}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nString defaultConfiguration = (String) attributes.get(\"defaultConfiguration\");\nif (defaultConfiguration!= null) {\nString beanName = \"ribbonClientConfiguration.\" + defaultConfiguration;\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"configuration\", defaultConfiguration);\nregistry.registerBeanDefinition(beanName, builder.getBeanDefinition());\n}\n}", "CodeBleu_score": 44.684187794312045}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nString defaultConfiguration = (String) attributes.get(\"defaultConfiguration\");\nif (defaultConfiguration!= null) {\nString configurationBeanName = \"ribbonClientConfiguration.\" + defaultConfiguration;\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"name\", defaultConfiguration);\nregistry.registerBeanDefinition(configurationBeanName, builder.getBeanDefinition());\n}\n}", "CodeBleu_score": 44.39619624856629}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> annotationAttributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nObject defaultConfiguration = annotationAttributes.get(\"defaultConfiguration\");\nif (defaultConfiguration!= null) {\nString name = generateName(defaultConfiguration);\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"name\", name);\nbuilder.addPropertyValue(\"configuration\", defaultConfiguration);\nregistry.registerBeanDefinition(name, builder.getBeanDefinition());\n}\n}", "CodeBleu_score": 45.12122128693093}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t//    return choose(serviceId, request, null);\n}", "CodeBleu_score": 10.113816973284147}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\nILoadBalancer loadBalancer = clientFactory.getLoadBalancer(serviceId);\n\nServer server = loadBalancer.chooseServer(null);\n\nif (server == null) {\nreturn null;\n}\n\nTutuServiceInstance instance = new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n\nreturn instance;\n}", "CodeBleu_score": 59.53104852481419}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// 1. \u83b7\u53d6\u8d1f\u8f7d\u5747\u8861\u5668\n\tILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n\t// 2. \u83b7\u53d6\u670d\u52a1\u5b9e\u4f8b\n\tServer server = loadBalancer.chooseServer(serviceId);\n\t// 3. \u8f6c\u6362\u4e3a\u670d\u52a1\u5b9e\u4f8b\n\tif (server!= null) {\n\t\treturn new TutuServiceInstance(server.getHost(), server.getPort(), serviceId);\n\t}\n\treturn null;\n}", "CodeBleu_score": 49.214735794818445}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString scheme = original.getScheme();\n\tString path = original.getPath();\n\tString query = original.getQuery();\n\tString fragment = original.getFragment();\n\tStringBuilder sb = new StringBuilder();\n\tsb.append(scheme).append(\"://\").append(host).append(\":\").append(port).append(path);\n\tif (StrUtil.isNotBlank(query)) {\n\t\tsb.append(\"?\").append(query);\n\t}\n\tif (StrUtil.isNotBlank(fragment)) {\n\t\tsb.append(\"#\").append(fragment);\n\t}\n\ttry {\n\t\treturn new URI(sb.toString());\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 51.787921590184816}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString scheme = original.getScheme();\n\tString path = original.getPath();\n\tString query = original.getQuery();\n\tString fragment = original.getFragment();\n\tString uri = null;\n\ttry {\n\t\turi = new URI(scheme, null, host, port, path, query, fragment);\n\t}\n\tcatch (URISyntaxException ex) {\n\t\tthrow new RuntimeException(ex);\n\t}\n\treturn uri;\n}", "CodeBleu_score": 29.839231101110197}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString scheme = original.getScheme();\n\tString path = original.getPath();\n\tString query = original.getQuery();\n\tString fragment = original.getFragment();\n\tif (port == -1) {\n\t\tport = 80;\n\t}\n\ttry {\n\t\treturn new URI(scheme, null, host, port, path, query, fragment);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 36.34983166016503}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\tString serverAddress = discoveryProperties.getServerAddress();\nString serviceName = discoveryProperties.getServiceName();\nString serviceId = discoveryProperties.getServiceId();\nString requestUrl = serverAddress + \"/list?serviceName=\" + serviceName + \"&serviceId=\" + serviceId;\nlogger.info(\"requestUrl:{}\", requestUrl);\nString response = HttpUtil.get(requestUrl);\nlogger.info(\"response:{}\", response);\nList<TutuServer> serverList = null;\nif (response!= null &&!\"\".equals(response)) {\nJSONObject jsonObject = JSON.parseObject(response);\nList<Map<String, Object>> serverInfoList = jsonObject.getJSONArray(\"data\");\nserverList = serverInfoList.stream().map(serverInfo -> {\nString ip = serverInfo.get(\"ip\").toString();\nInteger port = Integer.parseInt(serverInfo.get(\"port\").toString());\nreturn new TutuServer(ip, port, null);\n}).collect(Collectors.toList());\n}\nreturn serverList;\n}", "CodeBleu_score": 40.727574249832955}, {"code": "private List<TutuServer> getServer(){\n\tList<TutuServer> servers = new ArrayList<>();\nString url = \"http://\" + discoveryProperties.getAddress() + \"/list\";\nString result = HttpUtil.get(url);\nif (result!= null) {\nList<Map<String, String>> list = JSON.parseArray(result, Map.class);\nservers = list.stream().map(map -> {\nString ip = map.get(\"ip\");\nString port = map.get(\"port\");\nreturn new TutuServer(ip, Integer.parseInt(port));\n}).collect(Collectors.toList());\n}\nreturn servers;\n}", "CodeBleu_score": 42.53638807227428}, {"code": "private List<TutuServer> getServer(){\n\tMap<String, String> params = new HashMap<>();\nparams.put(\"serviceName\", serviceId);\nString response = HttpUtil.get(discoveryProperties.getDiscoveryAddress() + \"/list\", params);\nList<TutuServer> servers = JSON.parseArray(response, TutuServer.class);\nreturn servers;\n}", "CodeBleu_score": 38.214266830331034}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (Map.Entry<String, ZuulProperties.ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n\t\tif (pathMatcher.match(entry.getKey(), path)) {\n\t\t\tString targetPath = path.substring(entry.getKey().length());\n\t\t\treturn new Route(entry.getValue().getId(), targetPath);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 45.27372731118838}, {"code": "public Route getMatchingRoute(String path){\n\t\tMap<String, ZuulProperties.ZuulRoute> routes = zuulProperties.getRoutes();\n\tfor (Map.Entry<String, ZuulProperties.ZuulRoute> entry : routes.entrySet()) {\n\t\tString routePattern = entry.getKey();\n\t\tif (pathMatcher.match(routePattern, path)) {\n\t\t\tString targetPath = path.replaceFirst(routePattern, entry.getValue().getPath());\n\t\t\treturn new Route(entry.getValue().getId(), targetPath, entry.getValue().getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 51.32815478210638}, {"code": "public Route getMatchingRoute(String path){\n\t\t// \u904d\u5386\u8def\u7531\u5217\u8868\n\tfor (Map.Entry<String, ZuulProperties.ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n\t\t// \u83b7\u53d6\u8def\u7531\u89c4\u5219\n\t\tString routePattern = entry.getKey();\n\t\t// \u83b7\u53d6\u8def\u7531\u5bf9\u5e94\u7684\u670d\u52a1ID\n\t\tString serviceId = entry.getValue().getServiceId();\n\t\t// \u4f7f\u7528Ant-style path matching\u6bd4\u8f83\u8def\u5f84\n\t\tif (pathMatcher.match(routePattern, path)) {\n\t\t\t// \u5982\u679c\u5339\u914d\u6210\u529f\uff0c\u5219\u4ece\u8def\u5f84\u4e2d\u63d0\u53d6\u76ee\u6807\u8def\u5f84\n\t\t\tString targetPath = path.substring(routePattern.length());\n\t\t\t// \u521b\u5efaRoute\u5bf9\u8c61\u5e76\u8fd4\u56de\n\t\t\treturn new Route(serviceId, targetPath);\n\t\t}\n\t}\n\t// \u5982\u679c\u6ca1\u6709\u5339\u914d\u7684\u8def\u7531\uff0c\u5219\u8fd4\u56denull\n\treturn null;\n}", "CodeBleu_score": 49.65071455850148}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tSet<String> packages = ClassUtils.getPackages(importingClassMetadata.getClassName());\nfor (String pkg : packages) {\ntry {\nregisterFeignClients(registry, pkg);\n} catch (Exception e) {\nthrow new RuntimeException(e);\n}\n}\n}", "CodeBleu_score": 12.839470125850227}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\n//\u83b7\u53d6@FeignClient\u6ce8\u89e3\u7684\u7c7b\nSet<String> annotatedClasses = ClassUtils.getNamesForAnnotation(FeignClient.class, importingClassMetadata.getClassName());\n\n//\u904d\u5386@FeignClient\u6ce8\u89e3\u7684\u7c7b\nfor (String annotatedClass : annotatedClasses) {\n\n//\u83b7\u53d6\u7c7b\u540d\nString className = annotatedClass;\n\n//\u83b7\u53d6\u7c7b\nClass<?> annotatedClassClass = ClassUtil.loadClass(className);\n\n//\u83b7\u53d6@FeignClient\u6ce8\u89e3\nFeignClient annotation = annotatedClassClass.getAnnotation(FeignClient.class);\n\n//\u83b7\u53d6@FeignClient\u6ce8\u89e3\u7684value\u503c\nString contextId = annotation.value();\n\n//\u83b7\u53d6@FeignClient\u6ce8\u89e3\u7684type\u503c\nClass<?> type = annotation.type();\n\n//\u521b\u5efaGenericBeanDefinition\nGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\n//\u8bbe\u7f6ebeanDefinition\u7684beanClass\nbeanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\n//\u8bbe\u7f6ebeanDefinition\u7684scope\nbeanDefinition.setScope(\"prototype\");\n\n//\u8bbe\u7f6ebeanDefinition\u7684lazyInit\nbeanDefinition.setLazyInit(false);\n\n//\u8bbe\u7f6ebeanDefinition\u7684autowireMode\nbeanDefinition.setAutowireMode(GenericBeanDefinition.AUTOWIRE_BY_TYPE);\n\n//\u8bbe\u7f6ebeanDefinition\u7684propertyValues\nbeanDefinition.getPropertyValues().addPropertyValue(\"contextId\", contextId);\nbeanDefinition.getPropertyValues().addPropertyValue(\"type\", type);\n\n//\u8bbe\u7f6ebeanDefinition\u7684beanName\nbeanDefinition.setBeanName(annotatedClass);\n\n//\u5c06beanDefinition\u6ce8\u518c\u5230BeanDefinitionRegistry\nregistry.registerBeanDefinition(annotatedClass, beanDefinition);\n}\n}", "CodeBleu_score": 49.75804729713196}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}]}
