{"instance_id": "58936b2a621b", "generation_result": [{"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    if model.fit_intercept:\n        model.coef_ = params[0]\n        model.intercept_ = params[1]\n    else:\n        model.coef_ = params[0]\n    return model\n\n", "CodeBleu_score": 55.87951156710908}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    if model.fit_intercept:\n        model.coef_ = params[0]\n        model.intercept_ = params[1]\n    else:\n        model.coef_ = params[0]\n    return model\n\n", "CodeBleu_score": 55.87951156710908}]}
{"instance_id": "83b142d9d251", "generation_result": [{"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        train_size=support_ratio,\n        shuffle=True,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.43678944599134}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        stratify=label,\n        random_state=42,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}]}
{"instance_id": "5fd02b540f61", "generation_result": [{"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(\n        n_samples=1000, n_features=3, random_state=42, noise=0.1, bias=0.5\n    )\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 37.45448815100365}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.92483101817302}]}
{"instance_id": "ad958cb31a57", "generation_result": [{"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n", "CodeBleu_score": 79.03672928896962}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n", "CodeBleu_score": 79.03672928896962}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n", "CodeBleu_score": 79.03672928896962}]}
{"instance_id": "061d5a5b9d56", "generation_result": [{"code": "def datafiles_fusion(data_paths):\n\t\n\n    # Load the first data file\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n\n    # Load the remaining data files and concatenate the features and labels\n    for path in data_paths[1:]:\n        X_new, Y_new = load_svmlight_file(path)\n        X_new = X_new.toarray()\n\n        # Check if the number of features matches the first file\n        if X_new.shape[1] != X.shape[1]:\n            raise ValueError(\n                f\"Number of features in {path} does not match first file ({X.shape[1]}).\"\n            )\n\n        # Concatenate the features and labels\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n\n    return X, Y\n", "CodeBleu_score": 36.70822130080207}, {"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for i in range(1, len(data_paths)):\n        X_new, Y_new = load_svmlight_file(data_paths[i])\n        X_new = X_new.toarray()\n        assert X.shape[1] == X_new.shape[1], \"Number of features in all files must match.\"\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n    return X, Y\n\n", "CodeBleu_score": 43.95769924375282}, {"code": "def datafiles_fusion(data_paths):\n\t\n    # Load the first data file\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n\n    # Load the remaining data files and concatenate the features and labels\n    for data_path in data_paths[1:]:\n        X_new, Y_new = load_svmlight_file(data_path)\n        X_new = X_new.toarray()\n        assert X_new.shape[1] == X.shape[1], \"Number of features does not match\"\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n\n    return X, Y\n\n", "CodeBleu_score": 39.60503202397822}]}
{"instance_id": "977d3bd5d5a3", "generation_result": [{"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average=\"micro\")\n    precision = precision_score(y_test, y_pred, average=\"micro\")\n    f1 = f1_score(y_test, y_pred, average=\"micro\")\n    return accuracy, recall, precision, f1\n\n\n", "CodeBleu_score": 40.38465881740944}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    acc = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average=\"micro\")\n    precision = precision_score(y_test, y_pred, average=\"micro\")\n    f1 = f1_score(y_test, y_pred, average=\"micro\")\n    return acc, recall, precision, f1\n\n\n", "CodeBleu_score": 42.54908095626211}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average=\"micro\")\n    precision = precision_score(y_test, y_pred, average=\"micro\")\n    f1 = f1_score(y_test, y_pred, average=\"micro\")\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 40.38465881740944}]}
{"instance_id": "f4c838f1f092", "generation_result": [{"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 56.95295890449222}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 56.95295890449222}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            optimizer.zero_grad()\n            output = model(data)\n            loss = criterion(output, target)\n            loss.backward()\n            optimizer.step()\n\n\n", "CodeBleu_score": 56.95295890449222}]}
{"instance_id": "35068c779c02", "generation_result": [{"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == DatasetType.LIBSVM\n    dataset_path = train_dataset_path(cfg)\n    dataset_name = cfg.dataset.name\n    data, labels = load_svmlight_file(dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.float32)\n    print(f\\\"\\\"\\\"\n    Dataset: {dataset_name}\n    Unique labels: {np.unique(labels, return_counts=True)}\n    Shape of features: {data.shape}\n    \\\"\\\"\\\")\n    if dataset_name == LIBSVMDatasetName.MUSHROOMS.value:\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(f\\\"\\\"\\\"\n        Dataset {dataset_name} not supported.\n        Supported datasets: {[e.value for e in LIBSVMDatasetName]}\n        \\\"\\\"\\\")\n    return data_utils.TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n", "CodeBleu_score": 39.70266698765986}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == DatasetType.LIBSVM,\n        f\\\"\\\"\\\"Dataset type must be LIBSVM, but got {cfg.dataset.type}.\\\"\\\"\\\"\n\n    path = train_dataset_path(cfg)\n    name = cfg.dataset.name\n\n    data, labels = load_svmlight_file(path)\n    data = data.todense().astype(np.float32)\n    labels = labels.astype(np.float32)\n\n    print(f\\\"\\\"\\\"\n        Dataset: {name}\n        Number of samples: {len(labels)}\n        Number of features: {data.shape[1]}\n        Number of classes: {len(np.unique(labels))}\n        Unique labels: {np.unique(labels)}\n        \\\"\\\"\\\"\n    )\n\n    if name == LIBSVMDatasetName.MUSHROOMS.value:\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(f\\\"\\\"\\\"Unknown dataset name: {name}\\\"\\\"\\\")\n\n    return data_utils.TensorDataset(torch.tensor(data), torch.tensor(labels))\n\n", "CodeBleu_score": 38.82984036876327}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == DatasetType.LIBSVM\n    path = train_dataset_path(cfg)\n    name = cfg.dataset.name\n    data, labels = load_svmlight_file(path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.float32)\n    print(f\\\"Unique labels: {np.unique(labels, return_counts=True)}\\\")\n    print(f\\\"Shape of features: {data.shape}\\\")\n    if name == LIBSVMDatasetName.MUSHROOMS.value:\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(f\\\"Dataset name {name} not supported.\\\")\n    return data_utils.TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n\n\n", "CodeBleu_score": 34.08377546092101}]}
{"instance_id": "d602a96e571e", "generation_result": [{"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    # if we have a weight for this transformer, multiply output\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    # if we have a weight for this transformer, multiply output\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}]}
{"instance_id": "fcf88a773fd8", "generation_result": [{"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", copy=copy, ensure_2d=False, force_all_finite=False, dtype=FLOAT_DTYPES)\n\n    if selected == \"all\":\n        return transform(X)\n\n    inds = selected if isinstance(selected, list) else selected.get_support(indices=True)\n    if len(inds) == 0:\n        # No features selected.\n        if X.ndim == 1:\n            X_new = np.array([])\n        else:\n            X_new = np.array([]).reshape((X.shape[0], 0))\n        return X_new\n\n    if X.ndim == 1:\n        X_sel = X[inds]\n        X_not_sel = np.delete(X, inds)\n\n        X_trans_sel = transform(X_sel)\n        X_new = np.hstack((X_trans_sel, X_not_sel))\n    else:\n        X_sel = X[:, inds]\n        X_not_sel = np.delete(X, inds, axis=1)\n\n        X_trans_sel = transform(X_sel)\n        X_new = np.hstack((X_trans_sel, X_not_sel))\n\n    return X_new\n\n", "CodeBleu_score": 45.88462559569591}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", copy=copy, dtype=FLOAT_DTYPES,\n                    force_all_finite=False, ensure_2d=True)\n\n    if selected == \"all\":\n        X_new = transform(X)\n        if sparse.issparse(X_new):\n            X_new.sort_indices()\n        return X_new\n\n    if len(selected) == 0:\n        return X\n\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n\n    if n_selected == 0:\n        # No features selected.\n        return X\n    elif n_selected == n_features:\n        # All features selected.\n        return transform(X)\n    else:\n        X_sel = transform(X[:, ind[sel]])\n        X_not_sel = X[:, ind[not_sel]]\n\n        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n            return sparse.hstack((X_sel, X_not_sel))\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 77.81547924226801}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', force_all_finite=False, copy=copy)\n    if selected == \"all\":\n        return transform(X)\n    elif len(selected) == 0:\n        return X\n    else:\n        if len(selected) != X.shape[1]:\n            raise ValueError(\"The length of selected features should match the number of features.\")\n        X_sel = X[:, selected]\n        X_not_sel = X[:, ~selected]\n        X_sel = transform(X_sel)\n        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n            return sparse.hstack((X_sel, X_not_sel))\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 42.4076561315309}]}
{"instance_id": "c9dfb00047d1", "generation_result": [{"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, dtype=None, accept_sparse='csc', force_all_finite=False)\n    n_samples, n_features = X.shape\n    X_int, n_features = _check_X_encoded(X)\n    if self.categories != 'auto':\n        if len(self.categories) != n_features:\n            raise ValueError(\"Shape mismatch: if categories is an array,\"\n                             \" it has to be of shape (n_features,).\")\n\n    X = X_int\n    indices = self._all_indices(X, self.categories)\n    indptr = np.hstack((0, np.cumsum(indices)))\n    data = np.empty_like(indices, dtype=self.dtype)\n    data.fill(1)\n    out = sparse.csr_matrix((data, indices, indptr),\n                            shape=(n_samples, self.n_values_),\n                            dtype=self.dtype)\n    if not self.sparse:\n        out = out.toarray()\n    return out\n\n", "CodeBleu_score": 37.410041706409906}, {"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, dtype=None, accept_sparse='csc', force_all_finite=False)\n    n_samples, n_features = X.shape\n    X_int, X_mask = self._encode(X, uniques=self.categories_,\n                                check_unknown=self.handle_unknown)\n    n_values = [cats.shape[0] for cats in self.categories_]\n    indices = _transform_selected(X_int, self._transform,\n                                 self.categorical_features, copy=True)\n    indptr = np.asarray([0] + list(np.cumsum(n_samples * n_values)),\n                        dtype=np.int32)\n    data = np.empty(indices.shape[0], dtype=self.dtype)\n    data.fill(1)\n    out = sparse.csr_matrix((data, indices, indptr),\n                            shape=(n_samples, sum(n_values)),\n                            dtype=self.dtype)\n    if not self.sparse:\n        out = out.toarray()\n    return out\n\n", "CodeBleu_score": 33.78706455538366}, {"code": "def _transform_new(self, X)\n\t\n    # check input\n    X = check_array(X, dtype=None)\n    n_samples, n_features = X.shape\n\n    # create indices for new categories\n    indices = _make_transform_indices(X, self.categories_)\n\n    # create indptr\n    indptr = np.zeros(n_samples + 1, dtype=np.int32)\n    indptr[1:] = np.cumsum(np.fromiter(\n        (len(idx) for idx in indices),\n        dtype=np.int32,\n    ))\n\n    # transform data to binary format\n    data = np.ones(indptr[-1], dtype=np.int32)\n\n    # return matrix\n    return sparse.csr_matrix(\n        (data, indices, indptr),\n        shape=(n_samples, len(self.categories_)),\n        dtype=self.dtype,\n    )\n\n", "CodeBleu_score": 18.237602014249966}]}
{"instance_id": "fcde391a8972", "generation_result": [{"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper - self.lower)\n\n", "CodeBleu_score": 30.997576913458495}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper - self.lower)\n", "CodeBleu_score": 30.997576913458495}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return uniform(self.lower, self.upper - self.lower).loguniform()\n    return uniform(self.lower, self.upper - self.lower)\n\n", "CodeBleu_score": 33.172167590693604}]}
{"instance_id": "5d5413adcca6", "generation_result": [{"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_args = self.get_additional_args(state)\n    fig_args = self.get_fig_args(state)\n    features = self.features\n\n    if self.headers:\n        self.render_header(state, \"Partial Dependence Plots\")\n\n    fig, axes = plt.subplots(\n        self.MAX_CHARTS_PER_ROW,\n        math.ceil(len(features) / self.MAX_CHARTS_PER_ROW),\n        **fig_args,\n    )\n\n    kwargs = {**self.get_additional_args(state), **self.get_predefined_args()}\n\n    if self.two_way:\n        for ax, f in zip(axes.flat, features):\n            kwargs[\"features\"] = [f]\n            kwargs[\"target\"] = self.target\n            kwargs[\"X\"] = state.pdp_data[f].dropna()\n            kwargs[\"ax\"] = ax\n            PartialDependenceDisplay.from_estimator(state.model, **kwargs)\n    else:\n        for ax, f in zip(axes.flat, features):\n            kwargs[\"features\"] = [f]\n            kwargs[\"target\"] = self.target\n            kwargs[\"X\"] = state.pdp_data[f].dropna()\n            kwargs[\"ax\"] = ax\n            PartialDependenceDisplay.from_estimator(state.model, **kwargs)\n\n    fig.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 41.52863585613208}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_args = self.fig_args if self.fig_args is not None else {}\n    fig_args = self.get_fig_args(state)\n    fig, axes = plt.subplots(**fig_args, **additional_args)\n    if self.headers:\n        self.render_header(state, \"Partial Dependence Plots\")\n    kwargs = {**self.get_additional_args(), **self.get_predefined_kwargs()}\n    if self.two_way:\n        for data in state.pdp_data.values():\n            data.dropna(inplace=True)\n    PartialDependenceDisplay.from_estimator(\n        state.model,\n        state.pdp_data,\n        features=self.features,\n        target=self.target,\n        kind=\"both\",\n        subsample=self.sample,\n        ax=axes,\n        **kwargs,\n    )\n    plt.tight_layout()\n    plt.show()\n", "CodeBleu_score": 41.666173941564715}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_args = self.kwargs.get(\"additional_args\", {})\n    fig_args = self.fig_args\n    features = self.features\n\n    if self.headers:\n        self.render_header_if_needed(state, \"Partial Dependence Plots\")\n\n    fig, axes = plt.subplots(\n        len(features),\n        self.MAX_CHARTS_PER_ROW,\n        figsize=(10, 2 * len(features)),\n        **fig_args,\n    )\n\n    if len(features) == 1:\n        axes = [axes]\n\n    kwargs = {\n        **additional_args,\n        **dict(\n            kind=\"both\",\n            subsample=self.sample,\n            ax=axes,\n            features=features,\n            target=self.target,\n        ),\n    }\n\n    if self.two_way:\n        data = state.pdp_data[self.dataset_name].data\n        data = data[data[features[0]].notnull() & data[features[1]].notnull()]\n        kwargs[\"X\"] = data\n\n    display = PartialDependenceDisplay.from_estimator(\n        state.model[self.dataset_name],\n        state.pdp_data[self.dataset_name].data,\n        **kwargs,\n    )\n\n    fig.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 47.77765174590313}]}
{"instance_id": "db8aac29180b", "generation_result": [{"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X)\n    if self._feature_generator.identified_features is not None:\n        X_transformed = X.copy()\n        X_transformed[self._feature_generator.identified_features] = self._feature_generator.transform(X_transformed[self._feature_generator.identified_features])\n    else:\n        X_transformed = X\n    X_transformed = X_transformed.fillna(0)\n    X_transformed = X_transformed.astype(\"float32\")\n    return X_transformed\n\n", "CodeBleu_score": 49.701418902907065}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X)\n    if self._feature_generator.identified_features:\n        X_pre = X.copy()\n        X_pre[self._feature_generator.identified_features] = self._feature_generator.transform(X_pre[self._feature_generator.identified_features])\n        X = X_pre\n    X = X.fillna(0)\n    X = X.astype(\"float32\")\n    return X\n\n", "CodeBleu_score": 52.9079928413973}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X)\n    if self._feature_generator.identified_features:\n        X = X.copy()\n        X = self._feature_generator.transform(X)\n    X = X.fillna(0)\n    X = X.to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 58.49595470670808}]}
{"instance_id": "d4eb45e6d013", "generation_result": [{"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    min_num_estimators = max(40, num_trees_per_estimator)\n    if self.params_aux.get(\"search_space\", None) is not None:\n        min_num_estimators = 40\n    num_estimators = self.params.get(\"n_estimators\", min_num_estimators)\n    if num_estimators < min_num_estimators:\n        num_estimators = min_num_estimators\n    # TODO: This is very rough guess to size of a single tree before training, should be improved\n    #  This is based on the fact that a single tree uses about 200 bytes of memory\n    #  This is a very rough guess and should be improved\n    bytes_per_estimator = (\n        X.shape[0] * X.shape[1] * 4 * 200\n    )  # 4 bytes per float32, 200 bytes per tree\n    # TODO: This adjustment factor is very rough guess and should be improved\n    #  This is based on the fact that a single tree uses about 200 bytes of memory\n    #  This is a very rough guess and should be improved\n    adjustment_factor = 1.5\n    bytes_per_estimator = bytes_per_estimator * adjustment_factor\n    expected_min_memory_usage = bytes_per_estimator * num_estimators\n    return expected_min_memory_usage\n\n", "CodeBleu_score": 41.69705389133183}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # TODO: Add in documentation that Categorical default is the first index\n    # TODO: enable HPO for RF models\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    params = self._get_model_params()\n    num_estimators = params.get(\"n_estimators\", 100)\n    if self.search_space is not None:\n        num_estimators = 40\n    if num_estimators < 40:\n        num_estimators = 40\n    num_estimators = int(num_estimators / num_trees_per_estimator)\n    bytes_per_estimator = X.nbytes * 0.01 + 1000000\n    expected_min_memory_mb = bytes_per_estimator * num_estimators / 1000000\n    return expected_min_memory_mb\n\n", "CodeBleu_score": 25.87647576367747}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    self._set_default_params()\n    self._set_default_searchspace()\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    if self.params_search is not None:\n        min_estimators = self.params_search[\"n_estimators\"].get_min()\n    else:\n        min_estimators = self.params[\"n_estimators\"]\n    if min_estimators < 40:\n        min_estimators = 40\n    if self.problem_type in [MULTICLASS, SOFTCLASS]:\n        if self.num_classes is None:\n            num_trees_per_estimator = 10  # Guess since it wasn't passed in, could also check y for a better value\n        else:\n            num_trees_per_estimator = self.num_classes\n    else:\n        num_trees_per_estimator = 1\n    # TODO: Better estimate of bytes per estimator?\n    bytes_per_estimator = (\n        X.nbytes * 0.01\n    )  # 1% of bytes used by X, which is a good estimate for most models\n    expected_min_memory_usage = (\n        bytes_per_estimator * min_estimators * num_trees_per_estimator\n    )\n    return expected_min_memory_usage\n\n", "CodeBleu_score": 36.71089947128042}]}
{"instance_id": "6923cb007f4c", "generation_result": [{"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    top_n = Counter(ngram_freq).most_common(vocab_size)\n    top_n_names = [name for name, _ in top_n]\n    top_n_names.sort()\n    vocab = {name: idx for idx, name in enumerate(top_n_names)}\n    vectorizer.vocabulary_ = vocab\n    return vectorizer", "CodeBleu_score": 40.09020669251957}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    top_ngrams = Counter(ngram_freq).most_common(vocab_size)\n    top_ngrams.sort(key=lambda x: x[0])\n    new_vocab = {ngram: idx for idx, (ngram, _) in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = new_vocab\n\n", "CodeBleu_score": 32.987656011912684}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, freq in counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    vocab = {ngram: idx for idx, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = vocab\n    return vectorizer\n\n", "CodeBleu_score": 32.19236826369688}]}
{"instance_id": "0e837b2d8088", "generation_result": [{"code": " def _select_continuous(self, df, features)\n\t\n    types_of_features = dict()\n    skew_threshold = self.params.get('skew_threshold', 0.99)\n    for feature in features:\n        if df[feature].dtype == 'object':\n            continue\n        skew = df[feature].skew()\n        if skew > skew_threshold:\n            types_of_features.setdefault('skewed', []).append(feature)\n        else:\n            types_of_features.setdefault('continuous', []).append(feature)\n    return types_of_features\n\n", "CodeBleu_score": 43.175238000840956}, {"code": " def _select_continuous(self, df, features)\n\t\n    types_of_features = dict()\n    skewness_threshold = self.params.get('skewness_threshold', 1.0)\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            types_of_features.setdefault('skewed', []).append(feature)\n        else:\n            types_of_features.setdefault('continuous', []).append(feature)\n    return types_of_features\n\n\n def _select_bool(self, df, features):\n    \"\"\"This function categorizes features in a DataFrame as either bool or continuous based on their data type.", "CodeBleu_score": 36.69721509273358}, {"code": " def _select_continuous(self, df, features)\n\t\n\n    types_of_features = dict()\n    skewness_threshold = self.params.get('skewness_threshold', 0.99)\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            types_of_features.setdefault('skewed', []).append(feature)\n        else:\n            types_of_features.setdefault('continuous', []).append(feature)\n    return types_of_features\n\n", "CodeBleu_score": 41.91087192153417}]}
{"instance_id": "bb569c10f975", "generation_result": [{"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        with np.errstate(divide=\"ignore\"):\n            dist = 1.0 / dist\n        inf_mask = np.isinf(dist)\n        inf_row = np.any(inf_mask, axis=1)\n        dist[inf_row] = inf_mask[inf_row]\n        return dist\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"weights not recognized: should be 'uniform', 'distance', or a callable function\")\n\n", "CodeBleu_score": 83.33236322834935}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        with np.errstate(divide=\"ignore\"):\n            dist = 1.0 / dist\n        inf_mask = np.isinf(dist)\n        inf_row = np.any(inf_mask, axis=1)\n        dist[inf_row] = inf_mask[inf_row]\n        return dist\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"weights not recognized: should be 'uniform', 'distance', or a callable function\")\n\n", "CodeBleu_score": 83.33236322834935}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        with np.errstate(divide=\"ignore\"):\n            dist = 1.0 / dist\n        inf_mask = np.isinf(dist)\n        inf_row = np.any(inf_mask, axis=1)\n        dist[inf_row] = inf_mask[inf_row]\n        return dist\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"weights not recognized: should be 'uniform', 'distance', or a callable function\")\n\n", "CodeBleu_score": 94.1724899714777}]}
{"instance_id": "12aaa9c78402", "generation_result": [{"code": "def predict_loo(self)\n\t\n    neigh_dist, neigh_ind = self.kneighbors()\n    _y = self._y\n    if self._y.ndim == 1:\n        _y = self._y.reshape((-1, 1))\n    weights = _get_weights(neigh_dist, self.weights)\n    if weights is None:\n        weights = np.ones_like(neigh_ind)\n    all_rows = np.arange(len(_y))\n    y_pred = np.zeros_like(_y)\n    for i, idx in enumerate(neigh_ind.T):\n        y_pred[all_rows] += _y[idx] * weights[:, i]\n    y_pred /= weights.sum(axis=1)[:, np.newaxis]\n    if self._y.ndim == 1:\n        y_pred = y_pred.ravel()\n    return y_pred\n\n", "CodeBleu_score": 49.49364724387982}, {"code": "def predict_loo(self)\n\t\n    neigh_dist, neigh_ind = self.kneighbors()\n    _y = self._y\n    if _y.ndim == 1:\n        _y = _y.reshape((-1, 1))\n    n_queries = _y.shape[0]\n    weights = _get_weights(neigh_dist, self.weights)\n    y_pred = np.empty(n_queries)\n    for i in range(n_queries):\n        if weights is None:\n            y_pred[i] = np.mean(_y[neigh_ind[i]])\n        else:\n            y_pred[i] = np.sum(_y[neigh_ind[i]] * weights[i]) / np.sum(weights[i])\n    if _y.ndim == 1:\n        y_pred = y_pred.ravel()\n    return y_pred\n\n", "CodeBleu_score": 50.42597753798134}, {"code": "def predict_loo(self)\n\t\n    neigh_dist, neigh_ind = self.kneighbors()\n    classes_ = self.classes_\n    _y = self._y\n    if not self.outputs_2d_:\n        _y = self._y.reshape((-1, 1))\n        classes_ = [self.classes_]\n\n    n_outputs = len(classes_)\n    n_queries = len(neigh_dist)\n    weights = _get_weights(neigh_dist, self.weights)\n\n    y_pred = np.empty((n_queries, n_outputs), dtype=classes_[0].dtype)\n    for k, classes_k in enumerate(classes_):\n        if weights is None:\n            mode, _ = stats.mode(_y[neigh_ind, k], axis=1)\n        else:\n            mode, _ = weighted_mode(_y[neigh_ind, k], weights, axis=1)\n\n        mode = np.asarray(mode.ravel(), dtype=np.intp)\n        y_pred[:, k] = classes_k.take(mode)\n\n    if not self.outputs_2d_:\n        y_pred = y_pred.ravel()\n\n    return y_pred\n\n", "CodeBleu_score": 45.69791938453136}]}
{"instance_id": "b316687d9e9b", "generation_result": [{"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.size()[0]\n    transformed_data = []\n    for i in range(batch_size):\n        row = input_data[i]\n        ir = IsotonicRegression(y_min=0.0, y_max=1.0, out_of_bounds='clip')\n        y_ = ir.fit_transform(quantile_list, row)\n        transformed_data.append(y_)\n    return torch.from_numpy(np.stack(transformed_data))\n\n", "CodeBleu_score": 35.115520825670345}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.size(0)\n    output = []\n    for i in range(batch_size):\n        data = input_data[i]\n        ir = IsotonicRegression(out_of_bounds=\"clip\")\n        y_ = ir.fit_transform(quantile_list, data.cpu().numpy())\n        output.append(y_)\n    output = np.stack(output)\n    return torch.from_numpy(output).to(input_data.device)\n\n", "CodeBleu_score": 38.110281373583646}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        row = input_data[i]\n        ir = IsotonicRegression(out_of_bounds=\"clip\")\n        y_values = np.array([(i + 1) / batch_size for i in range(batch_size)])\n        y_values = y_values[np.argsort(row)]\n        x_values = np.sort(row)\n        ir.fit(x_values, y_values)\n        transformed_row = ir.transform(row)\n        transformed_data.append(transformed_row)\n    transformed_data = np.stack(transformed_data)\n    return transformed_data\n\n", "CodeBleu_score": 38.11604746038095}]}
{"instance_id": "17566e088b4e", "generation_result": [{"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer_fit = vectorizer.fit(text_data)\n    vectorizer_fit.stop_words_ = None\n    transform_matrix = vectorizer_fit.transform(text_data)\n    return vectorizer_fit, transform_matrix\n\n", "CodeBleu_score": 46.94891011061505}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    transform_matrix = vectorizer.transform(text_data)\n    return vectorizer, transform_matrix\n\n", "CodeBleu_score": 50.020838445437356}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    transform_matrix = vectorizer.transform(text_data)\n    return vectorizer, transform_matrix\n\n", "CodeBleu_score": 50.020838445437356}]}
{"instance_id": "6a82997a8c59", "generation_result": [{"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n\n    configuration_space = classifier.get_hyperparameter_search_space(\n        dataset_properties={\"sparse\": sparse}\n    )\n    default_config = configuration_space.get_default_configuration()\n\n    classifier = classifier(random_state=0, **default_config)\n\n    # Fit the classifier iteratively\n    for i in range(2):\n        classifier.iterative_fit(X_train, Y_train, n_iter=1, refit=True)\n\n    while not classifier.configuration_fully_fitted:\n        classifier.iterative_fit(X_train, Y_train, n_iter=2 ** i, refit=False)\n        i += 1\n\n    predictions = classifier.predict(X_test)\n    return predictions, Y_test, classifier\n\n", "CodeBleu_score": 52.87917099397025}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset=dataset, make_sparse=sparse)\n\n    configuration_space = classifier.get_hyperparameter_search_space(\n        dataset_properties={\"sparse\": sparse}\n    )\n    default_config = configuration_space.get_default_configuration()\n\n    classifier = classifier(random_state=0, **default_config)\n\n    if hasattr(classifier, \"iterative_fit\"):\n\n        class counter(object):\n            def __init__(self, func):\n                self.n_calls = 0\n                self.func = func\n\n            def __call__(self, *args, **kwargs):\n                self.n_calls += 1\n                return self.func(*args, **kwargs)\n\n        classifier.iterative_fit = counter(classifier.iterative_fit)\n\n    predictor = classifier.fit(X_train, Y_train)\n\n    if hasattr(classifier, \"iterative_fit\"):\n        n_calls = classifier.iterative_fit.n_calls\n    else:\n        n_calls = None\n\n    predictions = predictor.predict(X_test)\n    return predictions, Y_test, n_calls\n\n\n", "CodeBleu_score": 42.82296504071357}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n\n    configuration_space = classifier.get_hyperparameter_search_space(\n        dataset_properties={\"sparse\": sparse}\n    )\n    default_config = configuration_space.get_default_configuration()\n\n    classifier = classifier(random_state=0, **default_config)\n\n    if hasattr(classifier, \"iterative_fit\"):\n\n        class counter(object):\n            def __init__(self, func):\n                self.n_calls = 0\n                self.func = func\n\n            def __call__(self, *args, **kwargs):\n                self.n_calls += 1\n                return self.func(*args, **kwargs)\n\n        classifier.iterative_fit = counter(classifier.iterative_fit)\n\n    predictor = classifier.fit(X_train, Y_train)\n\n    if hasattr(classifier, \"iterative_fit\"):\n        n_calls = classifier.iterative_fit.n_calls\n    else:\n        n_calls = None\n\n    predictions = predictor.predict(X_test)\n    return predictions, Y_test, n_calls\n\n", "CodeBleu_score": 40.82226425981656}]}
{"instance_id": "d0d8450c4c17", "generation_result": [{"code": "def _load_models(self)\n\tself):\n    \"\"\"# This function loads models based on the specified ensemble class and resampling strategy.", "CodeBleu_score": 0.26021191062026466}, {"code": "def _load_models(self)\n\tself):\n    \"\"\"# This function loads models based on the specified ensemble class and resampling strategy.", "CodeBleu_score": 0.26021191062026466}, {"code": "def _load_models(self)\n\tself):\n    \"\"\"# This function loads models based on the specified ensemble class and resampling strategy.", "CodeBleu_score": 0.26021191062026466}]}
{"instance_id": "ef71b1cddb50", "generation_result": [{"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    dataset = task.get_dataset()\n    categorical_indicator = [\n        dataset.get_feat_type(feature) == \"categorical\"\n        for feature in range(dataset.get_num_features())\n    ]\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 29.2780540388905}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    dataset = task.get_dataset()\n    _, categorical_indicator = dataset.get_data(\n        dataset_format=\"dataframe\", target=task.target_name\n    )\n    categorical_indicator = categorical_indicator.values.tolist()\n    categorical_indicator = [\"Categorical\" if x else \"Numerical\" for x in categorical_indicator]\n    unique_labels = np.unique(y)\n    label_mapping = {label: i for i, label in enumerate(unique_labels)}\n    y_train = np.array([label_mapping[label] for label in y_train])\n    y_test = np.array([label_mapping[label] for label in y_test])\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 47.25551348145252}, {"code": "def load_task(task_id)\n\t\n\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n\n    train_indices, test_indices = task.get_train_test_split_indices()\n\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n\n    dataset = task.get_dataset()\n    _, _, categorical_indicator = dataset.get_data(\n        dataset_format=\"array\",\n        target=task.target_name,\n    )\n\n    y_train = np.array([int(y) for y in y_train])\n    y_test = np.array([int(y) for y in y_test])\n\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 35.92498873131248}]}
{"instance_id": "90bd6edbcc9e", "generation_result": [{"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if spmatrix.issparse(y):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 53.11788738755181}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if spmatrix.issparse(y):\n        y = y.toarray()\n        if y.shape[1] == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 56.63069740013977}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, spmatrix):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 57.20031380903361}]}
{"instance_id": "5728e3d4f914", "generation_result": [{"code": "def _calculate_weights(self) -> None\n\t\n    self.weights_ = np.zeros(\n        [\n            self.num_input_models_,\n        ],\n        dtype=np.float64,\n    )\n    for i in range(self.ensemble_size):\n        self.weights_[self.indices_[i]] += 1\n\n    self.weights_ /= self.ensemble_size\n\n    if np.sum(self.weights_) < 1:\n        self.weights_ /= np.sum(self.weights_)\n\n", "CodeBleu_score": 26.446062023626748}, {"code": "def _calculate_weights(self) -> None\n\t\n    self.weights_ = np.zeros(\n        (self.num_input_models_),\n        dtype=np.float64,\n    )\n    for index in self.indices_:\n        self.weights_[index] += 1\n    self.weights_ /= len(self.indices_)\n    if np.sum(self.weights_) < 1:\n        self.weights_ /= np.sum(self.weights_)\n\n", "CodeBleu_score": 24.768242274517675}, {"code": "def _calculate_weights(self) -> None\n\t\n    weights = np.zeros(self.num_input_models_)\n    for i in range(self.ensemble_size):\n        weights[self.indices_[i]] += 1\n    weights /= self.ensemble_size\n    if sum(weights) < 1:\n        weights /= sum(weights)\n    self.weights_ = weights\n\n", "CodeBleu_score": 23.648582005483892}]}
{"instance_id": "4f9c4799fd8f", "generation_result": [{"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\tthe predicted probabilities.", "CodeBleu_score": 7.363959305928505}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\tthe predicted probabilities.", "CodeBleu_score": 7.363959305928505}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\tthe predicted probabilities.", "CodeBleu_score": 7.363959305928505}]}
{"instance_id": "a9a13150aebe", "generation_result": [{"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if len(Ybin.shape) == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n\n", "CodeBleu_score": 37.384962417873545}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n", "CodeBleu_score": 32.043052488809614}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n", "CodeBleu_score": 32.043052488809614}]}
{"instance_id": "e97d38e62f81", "generation_result": [{"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(random_state=self.random_state)\n        classifier_weight, feature_preprocessor_weight = balancing.fit_transform(X, y)\n        self.config.update({\"classifier:__choice__\": \"weighting\", \"classifier:weighting:__choice__\": \"weighting\", \"classifier:weighting:weights\": classifier_weight, \"feature_preprocessor:__choice__\": \"weighting\", \"feature_preprocessor:weighting:__choice__\": \"weighting\", \"feature_preprocessor:weighting:weights\": feature_preprocessor_weight})\n    self.init_params = self.get_hyperparameter_search_space(feat_type=self.feat_type).sample_configuration(1).get_dictionary()\n    self.set_hyperparameters(self.config, init_params=self.init_params)\n    fit_params = {**self.init_params, **fit_params}\n    return super(SimpleClassificationPipeline, self).fit_transformer(X, y, fit_params=fit_params)", "CodeBleu_score": 49.447803610287075}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n    if self.config.get(\"balancing:strategy\") == \"weighting\":\n        balancing = Balancing(self.config, self.random_state)\n        choice_weights = balancing.get_weights(y)\n        self.config.update({\"classifier:__choice__\": choice_weights[0]})\n        self.config.update({\"feature_preprocessor:__choice__\": choice_weights[1]})\n    self.init_params = self.get_hyperparameter_search_space(\n        dataset_properties=self.dataset_properties,\n    ).get_default_configuration()\n    self.set_hyperparameters(self.config, init_params=self.init_params)\n    fit_params = self.get_fit_params(self.config, self.init_params, fit_params)\n    return super(SimpleClassificationPipeline, self).fit_transformer(\n        X, y, fit_params\n    )\n\n", "CodeBleu_score": 46.993651037318855}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = dict()\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(self.config)\n        self.config[\"classifier:__choice__\"], self.config[\"classifier:__choice__:weight\"] = balancing.get_class_weight(X, y)\n        self.config[\"feature_preprocessor:__choice__\"], self.config[\"feature_preprocessor:__choice__:weight\"] = balancing.get_feature_weight(X, y)\n    self._init_params = self._get_params()\n    self.set_hyperparameters(self.config, init_params=self._init_params)\n    fit_params_update = self.get_hyperparameter_search_space(feat_type=self.feat_type).sample_configuration(1)\n    fit_params_update.update(self._init_params)\n    if fit_params is not None:\n        fit_params_update.update(fit_params)\n    return super(SimpleClassificationPipeline, self).fit_transformer(X, y, fit_params=fit_params_update)\n\n", "CodeBleu_score": 49.867683600103184}]}
{"instance_id": "b1aaad80a9c4", "generation_result": [{"code": "def test_glm_identity_link_func()\n\t\n    estimator = utils.StatsmodelsSklearnLikeWrapper(\n        sm.GLM,\n        dict(\n            init=dict(\n                family=sm.families.Tweedie(sm.families.links.Power(1))),\n            fit=dict(maxiter=1),\n        ),\n    )\n    estimator = estimator.fit([[1], [2]], [0.1, 0.2])\n\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(estimator)\n    actual = assembler.assemble()\n\n    expected = ast.BinNumExpr(\n        ast.NumVal(0.0),\n        ast.BinNumExpr(\n            ast.FeatureRef(0),\n            ast.NumVal(0.0154915480),\n            ast.BinNumOpType.MUL,\n        ),\n        ast.BinNumOpType.ADD,\n    )\n\n    assert utils.cmp_exprs(actual, expected)\n\n", "CodeBleu_score": 55.749325596561604}, {"code": "def test_glm_identity_link_func()\n\t\n    estimator = utils.StatsmodelsSklearnLikeWrapper(\n        sm.GLM,\n        dict(\n            init=dict(\n                family=sm.families.Tweedie(sm.families.links.Power(1))),\n            fit=dict(maxiter=1),\n        ),\n    )\n    estimator = estimator.fit([[1], [2]], [0.1, 0.2])\n\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(estimator)\n    actual = assembler.assemble()\n\n    expected = ast.BinNumExpr(\n        ast.NumVal(0.0),\n        ast.BinNumExpr(\n            ast.FeatureRef(0),\n            ast.NumVal(0.0020808009),\n            ast.BinNumOpType.MUL,\n        ),\n        ast.BinNumOpType.ADD,\n    )\n\n    assert utils.cmp_exprs(actual, expected)\n\n", "CodeBleu_score": 55.72141597134734}, {"code": "def test_glm_identity_link_func()\n\t\n    estimator = utils.StatsmodelsSklearnLikeWrapper(\n        sm.GLM,\n        dict(init=dict(family=sm.families.Tweedie(sm.families.links.Identity())), fit=dict(maxiter=1)),\n    )\n    estimator = estimator.fit([[1], [2]], [0.1, 0.2])\n\n    assembler = assemblers.StatsmodelsModelAssemblerSelector(estimator)\n    actual = assembler.assemble()\n\n    expected = ast.BinNumExpr(\n        ast.BinNumExpr(\n            ast.NumVal(0.0),\n            ast.FeatureRef(0),\n            ast.BinNumOpType.MUL,\n        ),\n        ast.NumVal(0.00154915480),\n        ast.BinNumOpType.ADD,\n    )\n\n    assert utils.cmp_exprs(actual, expected)\n\n", "CodeBleu_score": 51.107032294846675}]}
{"instance_id": "bcab63e592d0", "generation_result": [{"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n\n    new_col_name = f\"{col.name} ({agg_name})\"\n    return self.group_by[col.name].aggregate(agg_func).rename(new_col_name)\n\n", "CodeBleu_score": 59.8933231584406}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n\n    new_col_name = f\"{col.name}_{agg_name}\"\n    return self.group_by[col.name].agg(agg_func).rename(new_col_name)\n\n", "CodeBleu_score": 61.57008177024408}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n\n    agg_col_name = f\"{col.name} ({agg_name})\"\n    return self.group_by[col.name].agg(agg_func).rename(agg_col_name)\n\n", "CodeBleu_score": 60.26429734147274}]}
{"instance_id": "114d623dae7b", "generation_result": [{"code": "def _corrfunc(self, x, y, **kws)\n\t\n    r, p = stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r), xy=(0.1, 0.9), xycoords=ax.transAxes, fontsize=12)\n    if self.hue:\n        hue_names = self.hue_names\n        hue_idx = hue_names.index(ax.get_title().split(\" = \")[1])\n        if hue_idx == 0:\n            ax.annotate(\"r = {:.2f}\".format(r), xy=(0.1, 0.9), xycoords=ax.transAxes, fontsize=12)\n        else:\n            ax.annotate(\"r = {:.2f}\".format(r), xy=(0.1, 0.7), xycoords=ax.transAxes, fontsize=12)\n\n", "CodeBleu_score": 21.555773861854426}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    r, p = stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r), xy=(.1, .9), xycoords=ax.transAxes)\n    if self.hue:\n        hue_groups = self.df[self.hue].unique()\n        hue_group_indices = [np.where(self.df[self.hue] == hue_group)[0] for hue_group in hue_groups]\n        for i, hue_group_index in enumerate(hue_group_indices):\n            r, p = stats.pearsonr(x[hue_group_index], y[hue_group_index])\n            ax.annotate(\"r = {:.2f}\".format(r), xy=(.1, .9 - i * .05), xycoords=ax.transAxes)\n\n", "CodeBleu_score": 25.008855875912023}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    r, p = stats.pearsonr(x, y)\n    ax = plt.gca()\n    ax.annotate(\"r = {:.2f}\".format(r), xy=(.1, .9), xycoords=ax.transAxes, fontsize=12)\n    if self.hue is not None:\n        hue_idx = np.unique(self.hue, return_inverse=True)[1]\n        if len(self.hue_names) > 1:\n            for i, hue_name in enumerate(self.hue_names):\n                ax = plt.gca()\n                ax.annotate(\"r = {:.2f}\".format(r), xy=(.1, .9), xycoords=ax.transAxes, fontsize=12)\n        else:\n            ax = plt.gca()\n            ax.annotate(\"r = {:.2f}\".format(r), xy=(.1, .9), xycoords=ax.transAxes, fontsize=12)\n\n", "CodeBleu_score": 26.961527536155792}]}
{"instance_id": "b6106e079dc0", "generation_result": [{"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    # create DataFrame from x and y values\n    df = pd.DataFrame({x_name: x, y_name: y})\n    # add hue data to DataFrame if provided\n    if hue_data is not None:\n        df[hue_name] = hue_data\n    # plot scatter plot using Seaborn\n    sns.scatterplot(data=df, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    # set legend title if not specified\n    if legend_kws.get('title') is None:\n        legend_kws['title'] = hue_name\n    # add legend to plot\n    ax.legend(**legend_kws)\n\n", "CodeBleu_score": 34.23664986617811}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    df = pd.DataFrame(np.column_stack((x, y)), columns=[x_name, y_name])\n    if hue_data is not None:\n        df['hue'] = hue_data\n        hue_name = 'hue'\n    sns.scatterplot(data=df, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if 'title' not in legend_kws:\n            legend_kws['title'] = hue_name\n        ax.legend(**legend_kws)\n\n", "CodeBleu_score": 44.506720487291076}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    df = pd.DataFrame(np.column_stack((x, y)), columns=[x_name, y_name])\n    if hue_data is not None:\n        df['hue'] = hue_data\n    sns.scatterplot(data=df, x=x_name, y=y_name, hue='hue', ax=ax, **scatter_kws)\n    if legend_kws.get('title') is None:\n        legend_kws['title'] = hue_name\n    ax.legend(**legend_kws)\n\n", "CodeBleu_score": 35.16724848033524}]}
{"instance_id": "257e0aa5dd4d", "generation_result": [{"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    endog = self.node.get_endog_data()\n    exog = self.node.get_exog_data()\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)\n        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n        self.model = self.model_class(endog=endog, exog=exog, **fit_args)\n        self.model = self.model.fit()\n    return self\n\n", "CodeBleu_score": 40.21448672340158}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    endog = self.node.get_data()\n    exog = self.node.get_exog()\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning)\n        warnings.simplefilter(\"ignore\", ConvergenceWarning)\n        self.model = self.model_cls(endog=endog, exog=exog, **fit_args)\n        self.model = self.model.fit()\n\n    return self\n\n", "CodeBleu_score": 39.92503304777453}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    data = self.node.get_data()\n    endog = data[self.node.key]\n    exog = None\n    if self.node.exog:\n        exog = data[self.node.exog]\n\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", category=UserWarning)\n        warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n        self.model = auto_arima(endog, exogenous=exog, **fit_args)\n\n    return self\n\n", "CodeBleu_score": 46.35129171019548}]}
{"instance_id": "6446de2223e8", "generation_result": [{"code": "def create_model(self, **kwargs)\n\t\n    if self.kind == \"holt_winters\":\n        y = self._get_transformed_data(as_series=True)\n        return ExponentialSmoothing(\n            y,\n            trend=kwargs.get(\"trend\", \"add\"),\n            damped_trend=kwargs.get(\"damped_trend\", False),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n        )\n    elif self.kind == \"auto_arima\":\n        try:\n            from pmdarima.arima import AutoARIMA\n\n            return AutoARIMA(**kwargs)\n        except ImportError:\n            logger.error(\n                \"pmdarima is not installed. Please install it with: pip install pmdarima\"\n            )\n            exit(1)\n    elif self.kind == \"sarimax\":\n        y = self._get_transformed_data(as_series=True)\n        exog = self.node.exogenous_variables\n        if exog is not None:\n            exog = self.node.exogenous_variables.values\n        return SARIMAX(\n            y,\n            exog=exog,\n            order=kwargs.get(\"order\", (1, 0, 0)),\n            seasonal_order=kwargs.get(\"seasonal_order\", (0, 0, 0, 0)),\n        )\n    else:\n        raise ValueError(f\"Model {self.kind} not implemented\")\n\n", "CodeBleu_score": 40.028322417639295}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.kind == \"holt_winters\":\n        transformed = self._get_transformed_data()\n        return ExponentialSmoothing(\n            transformed,\n            trend=kwargs.get(\"trend\", \"add\"),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n        )\n    elif self.kind == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError as e:\n            logger.error(\n                \"`pmdarima` is required for auto_arima. Please install it with `pip install pmdarima`\"\n            )\n            raise e\n\n        transformed = self._get_transformed_data(as_series=True)\n        return AutoARIMA(**kwargs).fit(transformed)\n    elif self.kind == \"sarimax\":\n        transformed = self._get_transformed_data()\n        exogenous = kwargs.get(\"exogenous\", None)\n        if exogenous is not None:\n            exogenous = self._get_transformed_data(as_series=True)\n        return SARIMAX(\n            transformed,\n            exog=exogenous,\n            order=kwargs.get(\"order\", (1, 0, 0)),\n            seasonal_order=kwargs.get(\"seasonal_order\", (0, 0, 0, 0)),\n        )\n    else:\n        raise ValueError(f\"Model {self.kind} not recognized\")\n\n", "CodeBleu_score": 38.607537138666}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.kind == \"holt_winters\":\n        data = self._get_transformed_data()\n        return ExponentialSmoothing(\n            data[self.node.key],\n            trend=kwargs.get(\"trend\", \"add\"),\n            seasonal=kwargs.get(\"seasonal\", \"add\"),\n            seasonal_periods=kwargs.get(\"seasonal_periods\", 12),\n            initialization_method=kwargs.get(\"initialization_method\", \"estimated\"),\n        )\n    elif self.kind == \"auto_arima\":\n        try:\n            from pmdarima.arima import AutoARIMA\n        except ImportError:\n            logger.error(\n                \"`pmdarima` is not installed. Please install it to use AutoARIMA model\"\n            )\n            sys.exit(1)\n        data = self._get_transformed_data()\n        return AutoARIMA(\n            data[self.node.key],\n            start_p=kwargs.get(\"start_p\", 1),\n            start_q=kwargs.get(\"start_q\", 1),\n            max_p=kwargs.get(\"max_p\", 3),\n            max_q=kwargs.get(\"max_q\", 3),\n            m=kwargs.get(\"m\", 12),\n            seasonal=kwargs.get(\"seasonal\", True),\n            stepwise=kwargs.get(\"stepwise\", True),\n            suppress_warnings=kwargs.get(\"suppress_warnings\", True),\n            error_action=kwargs.get(\"error_action\", \"ignore\"),\n            trace=kwargs.get(\"trace\", False),\n            random_state=kwargs.get(\"random_state\", 2020),\n            n_fits=kwargs.get(\"n_fits\", 5),\n        )\n    elif self.kind == \"sarimax\":\n        data = self._get_transformed_data()\n        if self.node.exogenous is not None:\n            exog = self.node.exogenous[self.node.exogenous_key]\n            return SARIMAX(\n                data[self.node.key],\n                exog=", "CodeBleu_score": 32.9963589459291}]}
{"instance_id": "b2f67820e27f", "generation_result": [{"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 78.00236077045142}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy is not None and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 88.40913031500585}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n\n", "CodeBleu_score": 78.00236077045142}]}
{"instance_id": "b96f7d9bcc95", "generation_result": [{"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if _numpy_split_ok:\n        return ys\n\n    # Calculate the expected shape for each segment\n    expected_shapes = numpy.split(numpy.zeros_like(x), indices_or_sections, axis=axis)\n\n    # Reshape each segment if necessary\n    for i, y in enumerate(ys):\n        if y.ndim != x.ndim:\n            expected_shape = expected_shapes[i].shape\n            ys[i] = y.reshape(expected_shape)\n\n    return ys\n\n", "CodeBleu_score": 36.98513999657958}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if _numpy_split_ok:\n        return ys\n\n    # Calculate the expected shapes for the split segments\n    shape = x.shape\n    split_sizes = numpy.array_split(numpy.zeros(shape[axis], numpy.intp), indices_or_sections)\n    expected_shapes = [tuple(s if i != axis else s.size for i, s in enumerate(shape)) for s in split_sizes]\n\n    # Reshape the segments if necessary\n    for i, y in enumerate(ys):\n        if y.shape != expected_shapes[i]:\n            ys[i] = y.reshape(expected_shapes[i])\n\n    return ys\n\n\n\n", "CodeBleu_score": 38.53961134615014}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if _numpy_split_ok:\n        return ys\n\n    if not isinstance(ys, collections_abc.Sequence):\n        raise ValueError('ys must be a sequence')\n    if not all(isinstance(y, numpy.ndarray) for y in ys):\n        raise ValueError('all elements in ys must be numpy.ndarray')\n    if not isinstance(x, numpy.ndarray):\n        raise ValueError('x must be a numpy.ndarray')\n    if x.ndim != ys[0].ndim:\n        # numpy < 1.11 does not preserve number of dimensions in some cases.\n        # We need to fix it here.\n        # See:\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L60-L67\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L285-L295\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L456-L482\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L532-L537\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L616-L623\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L662-L667\n        # https://github.com/numpy/numpy/blob/v1.11.0/numpy/lib/shape_base.py#L729-L734\n        # https://github.com", "CodeBleu_score": 23.985913557242135}]}
{"instance_id": "cf39fb123842", "generation_result": [{"code": "def to_device_batch(batch):\n\t\n    if device is not None and device >= 0:\n        xp = cuda.get_array_module(*batch)\n        concat_example = xp.concatenate(batch, axis=0)\n        sections = numpy.cumsum([len(x)\n                                 for x in batch[:-1]], dtype=numpy.int32)\n        concat_dev = cuda.to_gpu(concat_example, device)\n        batch = cuda.cupy.split(concat_dev, sections)\n    elif device is not None:\n        batch = chainer.dataset.to_device(device, batch)\n    return batch\n\n", "CodeBleu_score": 64.75968121097304}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return chainer.dataset.to_device(device, batch)\n    else:\n        xp = cuda.cupy if device >= 0 else numpy\n        concat_example = []\n        for example in batch:\n            concat_example.append(xp.array(example, dtype=xp.int32))\n        concat_example_x = xp.concatenate(concat_example, axis=0)\n        sections = numpy.cumsum([len(x) for x in concat_example[:-1]], dtype=numpy.int32)\n        concat_dev = chainer.dataset.to_device(device, concat_example_x)\n        batch_dev = cuda.cupy.split(concat_dev, sections)\n        return batch_dev\n\n", "CodeBleu_score": 63.04686210522035}, {"code": "def to_device_batch(batch):\n\t\n    if device is not None:\n        x_device = chainer.get_device(device)\n        if device >= 0:\n            xp = cuda.cupy\n            x_len = [len(x) for x in batch]\n            x_section = numpy.cumsum(x_len[:-1])\n            ex = xp.concatenate(batch, axis=0)\n            exs = cuda.cupy.split(ex, x_section, axis=0)\n            return [chainer.dataset.to_device(device, x) for x in exs]\n        else:\n            return [chainer.dataset.to_device(device, x) for x in batch]\n    else:\n        return batch\n\n", "CodeBleu_score": 55.544854289428656}]}
{"instance_id": "845c744d897c", "generation_result": [{"code": "def make_image(trainer)\n\t\n    np.random.seed(seed)  # fix random\n    n_images = rows * cols\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config(\"train\", False):\n        x = gen(z)\n    x = chainer.backends.cuda.to_cpu(x.data)\n    np.random.seed()\n\n    x = np.asarray(np.clip(x * 127.5 + 127.5, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((rows, cols, 3, H, W))\n    x = x.transpose(0, 3, 1, 4, 2)\n    x = x.reshape((rows * H, cols * W, 3))\n\n    preview_dir = \"{}/preview\".format(dst)\n    preview_path = preview_dir + \"/image{:0>8}.png\".format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x).save(preview_path)\n\n", "CodeBleu_score": 86.78174070079628}, {"code": "def make_image(trainer)\n\t\n    np.random.seed(seed)\n    n_images = rows * cols\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config(\"train\", False):\n        x = gen(z)\n    x = chainer.backends.cuda.to_cpu(x.data)\n    np.random.seed()\n\n    x = np.asarray(np.clip(x * 127.5 + 127.5, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((rows, cols, 3, H, W))\n    x = x.transpose(0, 3, 1, 4, 2)\n    x = x.reshape((rows * H, cols * W, 3))\n\n    preview_dir = \"{}/preview\".format(dst)\n    preview_path = preview_dir + \"/image{:0>8}.png\".format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x).save(preview_path)\n\n", "CodeBleu_score": 87.06029705893134}, {"code": "def make_image(trainer)\n\t\n    np.random.seed(seed)\n    n_images = rows * cols\n    xp = gen.xp\n    z = Variable(xp.asarray(gen.make_hidden(n_images)))\n    with chainer.using_config('train', False):\n        x = gen(z)\n    x = chainer.backends.cuda.to_cpu(x.data)\n    np.random.seed()\n\n    x = np.asarray(np.clip(x * 255, 0.0, 255.0), dtype=np.uint8)\n    _, _, H, W = x.shape\n    x = x.reshape((rows, cols, 3, H, W))\n    x = x.transpose(0, 3, 1, 4, 2)\n    x = x.reshape((rows * H, cols * W, 3))\n\n    preview_dir = '{}/preview'.format(dst)\n    preview_path = preview_dir + '/image{:0>8}.png'.format(trainer.updater.iteration)\n    if not os.path.exists(preview_dir):\n        os.makedirs(preview_dir)\n    Image.fromarray(x).save(preview_path)\n\n", "CodeBleu_score": 86.34922562221502}]}
{"instance_id": "fc2162d43aee", "generation_result": [{"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = numpy.dtype(from_dtype)\n    to_dtype = numpy.dtype(to_dtype)\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos <= to_pos\n\n", "CodeBleu_score": 59.512736518171735}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = numpy.dtype(from_dtype)\n    to_dtype = numpy.dtype(to_dtype)\n    return _typechars.index(from_dtype.char) <= _typechars.index(to_dtype.char)\n\n", "CodeBleu_score": 65.35402012285344}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = numpy.dtype(from_dtype)\n    to_dtype = numpy.dtype(to_dtype)\n    return _typechars.index(from_dtype.char) <= _typechars.index(to_dtype.char)\n\n", "CodeBleu_score": 65.35402012285344}]}
{"instance_id": "5b8e2d5e6e12", "generation_result": [{"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    ax = g.ax if hasattr(g, \"ax\") else g\n    if ax is None:\n        raise YellowbrickValueError(\"could not determine the axis for this Visualizer\")\n\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"cannot create legend with {} labels and {} colors\".format(\n                len(labels), len(colors)\n            )\n        )\n\n    # Create a manual legend\n    handles = [patches.Patch(color=color, label=label) for label, color in zip(labels, colors)]\n    return ax.legend(handles=handles, **legend_kwargs)\n\n", "CodeBleu_score": 50.64694624997319}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    ax = get_ax(g)\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"Cannot create legend with {} labels and {} colors\".format(\n                len(labels), len(colors)\n            )\n        )\n    handles = [patches.Patch(color=color, label=label) for label, color in zip(labels, colors)]\n    return ax.legend(handles=handles, **legend_kwargs)\n\n", "CodeBleu_score": 48.5870812343514}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    # Get the axes object from the input\n    ax = g.ax if isinstance(g, Visualizer) else g or plt.gca()\n\n    # Ensure that the labels and colors match\n    if len(labels) != len(colors):\n        raise YellowbrickValueError(\n            \"Cannot generate a legend with {} labels and {} colors\".format(\n                len(labels), len(colors)\n            )\n        )\n\n    # Create legend handles by pairing labels with colors\n    handles = [patches.Patch(color=color, label=label) for label, color in zip(labels, colors)]\n\n    # Create the legend\n    return ax.legend(handles=handles, **legend_kwargs)\n\n", "CodeBleu_score": 50.794525309539026}]}
{"instance_id": "494e7f719eb6", "generation_result": [{"code": "def pcoords_time(X, y, fast=True)\n\t\n    fig, ax = plt.subplots()\n    visualizer = ParallelCoordinates(fast=fast, ax=ax)\n    start = time.time()\n    visualizer.fit_transform(X, y)\n    elapsed = time.time() - start\n    plt.close()\n    return elapsed\n\n", "CodeBleu_score": 43.29390478372798}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    plt.figure()\n    ax = plt.gca()\n    visualizer = ParallelCoordinates(fast=fast, ax=ax)\n    start = time.time()\n    visualizer.fit_transform(X, y)\n    elapsed = time.time() - start\n    plt.close()\n    return elapsed\n\n", "CodeBleu_score": 31.229384945883222}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    fig, ax = plt.subplots()\n    visualizer = ParallelCoordinates(fast=fast, ax=ax)\n    start = time.time()\n    visualizer.fit_transform(X, y)\n    elapsed = time.time() - start\n    plt.close()\n    return elapsed\n\n", "CodeBleu_score": 43.29390478372798}]}
{"instance_id": "db4143bc029f", "generation_result": [{"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the transparency\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    if alpha is None:\n        alpha = 0.25 if self.fast else 0.5\n\n    # Iterate through instances and plot each individually\n    for idx, x in enumerate(X):\n        label = y[idx]\n        color = self.colors[label]\n        self.ax.plot(self._increments, x, color=color, alpha=alpha)\n\n    return self.ax\n\n", "CodeBleu_score": 46.06010706016368}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n\n    # Get the transparency\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    if alpha is None:\n        alpha = 0.25 if self.fast else 0.5\n\n    # Get the color for each instance\n    self._colors = resolve_colors(\n        n_colors=len(y), colors=self.colors, colormap=self.colormap\n    )\n\n    # Iterate through each instance, plot a line for each feature\n    for idx, x in enumerate(X):\n        label = y[idx]\n        color = self._colors[label]\n        self.ax.plot(self._increments, x, color=color, alpha=alpha)\n\n    return self.ax\n\n", "CodeBleu_score": 40.817918805752825}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the transparency\n    alpha = kwargs.get(\"alpha\", self.alpha)\n    if alpha is None:\n        alpha = 0.25 if self.fast else 0.5\n\n    # Plot each instance\n    for i, (label, x) in enumerate(zip(y, X)):\n        self.ax.plot(\n            self._increments,\n            x,\n            color=self.colors[label],\n            alpha=alpha,\n            label=label if i == 0 else None,\n        )\n\n    return self.ax\n\n", "CodeBleu_score": 31.91254683857102}]}
{"instance_id": "676433312ffe", "generation_result": [{"code": "def draw_classes(self, X, y, **kwargs):\n\t\n\n    # Get alpha from param or default\n    alpha = self.alpha or 0.5\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.c_[X, np.ones(len(X))]\n    self._increments.append(None)\n\n    # Iterate through the unique labels\n    for label in self.classes_:\n        # Determine the color of the class\n        color = self.get_colors([label])[0]\n\n        # Select the instances of X belonging to the class\n        Xi = X[y == label, :]\n\n        # Plot the instances of X belonging to the class\n        self.ax.plot(self._increments, Xi.T, color=color, alpha=alpha, **kwargs)\n\n    return self.ax\n\n\n", "CodeBleu_score": 31.673730466870666}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Get alpha from param or default\n    alpha = self.alpha or 0.5\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.column_stack((X, np.ones(len(X))))\n    self._increments.append(None)\n\n    # Iterate over each class and plot\n    for idx, label in enumerate(self.classes_):\n        color = self.get_colors([label])[0]\n        instances = X[y == label]\n        self.ax.plot(self._increments, instances.T, color=color, alpha=alpha, **kwargs)\n\n    return self.ax\n\n", "CodeBleu_score": 32.14150681953387}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Get alpha from param or default\n    alpha = self.alpha or 0.5\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.c_[X, np.ones(len(X))]\n\n    # Append None to the increments list to create breaks between instances\n    self._increments.append(None)\n\n    # Identify unique class labels\n    classes = np.unique(y)\n\n    for idx, cls in enumerate(classes):\n        # Determine the color\n        color = self.get_colors([cls])[0]\n\n        # Select the instances belonging to the current class\n        Xi = X[y == cls]\n\n        # Plot the instances as a single line plot\n        self.ax.plot(self._increments, Xi.T, color=color, alpha=alpha, **kwargs)\n\n    return self.ax\n\n", "CodeBleu_score": 34.177529287521544}]}
{"instance_id": "9d297b12a673", "generation_result": [{"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Create a side-by-side subplot grid\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n    # Create the RadViz visualizer\n    radviz = RadViz(ax=axes[0], features=[\"temperature\", \"relative humidity\", \"light\", \"C02\", \"humidity\"])\n    occupancy = load_occupancy()\n    radviz.fit(occupancy.X, occupancy.y)\n    radviz.finalize()\n\n    # Create the Rank2D visualizer\n    rank2d = Rank2D(ax=axes[1], algorithm=\"pearson\")\n    concrete = load_concrete()\n    rank2d.fit(concrete.X, concrete.y)\n    rank2d.transform(concrete.X)\n    rank2d.finalize()\n\n    # Save the figure\n    fig.savefig(os.path.join(FIGURES, fname))\n\n", "CodeBleu_score": 27.23807074466383}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n\n    # Load the data\n    occupancy = load_occupancy()\n    concrete = load_concrete()\n\n    # Create the figure and subplots\n    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 6))\n\n    # Perform RadViz analysis on the occupancy data\n    viz = RadViz(ax=ax1)\n    viz.fit(occupancy.X, occupancy.y)\n    viz.transform(occupancy.X)\n    viz.finalize()\n\n    # Perform Rank2D analysis on the concrete data\n    viz = Rank2D(ax=ax2)\n    viz.fit(concrete.X, concrete.y)\n    viz.transform(concrete.X)\n    viz.finalize()\n\n    # Save the figure\n    fig.savefig(fname)\n\n", "CodeBleu_score": 23.10921720049704}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Load the data\n    occupancy = load_occupancy()\n    concrete = load_concrete()\n\n    # Create the figure and subplots\n    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n\n    # Perform RadViz analysis on the occupancy data\n    radviz = RadViz(ax=axes[0])\n    radviz.fit(occupancy.X, occupancy.y)\n    radviz.transform(occupancy.X)\n    radviz.finalize()\n\n    # Perform Rank2D analysis on the concrete data\n    rank2d = Rank2D(ax=axes[1])\n    rank2d.fit(concrete.X, concrete.y)\n    rank2d.transform(concrete.X)\n    rank2d.finalize()\n\n    # Save the figure\n    fig.savefig(fname)\n\n", "CodeBleu_score": 26.029865957250355}]}
{"instance_id": "fd1b4b9cd7ef", "generation_result": [{"code": "def regression(fname=\"regression.png\")\n\t\n\n    # Create side-by-side axes grid\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    # Create a range of alpha values for regularization\n    alphas = np.logspace(-10, 1, 400)\n\n    # Load the concrete dataset and split into training and testing sets\n    data = load_concrete(split=True)\n\n    # Plot the prediction error using LassoCV\n    oz = PredictionError(\n        LassoCV(alphas=alphas),\n        ax=axes[0],\n        param_name=\"alpha\",\n        color=\"green\",\n        alpha=0.7,\n        is_fitted=True,\n    )\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Plot the residuals using RidgeCV\n    oz = ResidualsPlot(\n        RidgeCV(alphas=alphas),\n        ax=axes[1],\n        param_name=\"alpha\",\n        color=\"green\",\n        alpha=0.7,\n        is_fitted=True,\n    )\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Adjust the layout and save the figure\n    plt.tight_layout()\n    path = os.path.join(FIGURES, fname)\n    plt.savefig(path)\n    return path\n\n", "CodeBleu_score": 62.574743401421294}, {"code": "def regression(fname=\"regression.png\")\n\t\n    # Create side-by-side axes grid\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    # Create range of alphas\n    alphas = np.logspace(-10, 1, 400)\n\n    # Load concrete dataset\n    data = load_concrete(split=True)\n\n    # Plot prediction error\n    model = LassoCV(alphas=alphas)\n    oz = PredictionError(model, ax=axes[0], alpha=0.2, is_fitted=True)\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Plot residuals\n    model = RidgeCV(alphas=alphas)\n    oz = ResidualsPlot(model, ax=axes[1], alpha=0.2, is_fitted=True)\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Save figure\n    path = os.path.join(FIGURES, fname)\n    plt.tight_layout()\n    plt.savefig(path)\n    return path\n\n", "CodeBleu_score": 63.06453765274276}, {"code": "def regression(fname=\"regression.png\")\n\t\n    # Create side-by-side axes grid\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    # Create a range of alphas to try\n    alphas = np.logspace(-10, 1, 400)\n\n    # Draw the prediction error, which will be the training score\n    data = load_concrete(split=True)\n    oz = PredictionError(LassoCV(alphas=alphas), ax=axes[0])\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Draw the residuals\n    oz = ResidualsPlot(RidgeCV(alphas=alphas), ax=axes[1])\n    oz.fit(data.train.X, data.train.y)\n    oz.score(data.test.X, data.test.y)\n    oz.finalize()\n\n    # Save figure\n    path = os.path.join(FIGURES, fname)\n    plt.tight_layout()\n    plt.savefig(path)\n    return path\n\n", "CodeBleu_score": 71.58600358760327}]}
{"instance_id": "627126918f88", "generation_result": [{"code": "def classification(fname=\"classification.png\")\n\t\n    # Create side-by-side axes grid\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    # Draw classification report on the left\n    data = load_spam(split=True)\n    oz = ClassificationReport(MultinomialNB(), ax=axes[0])\n    oz.fit(data.X.train, data.y.train)\n    oz.score(data.X.test, data.y.test)\n    oz.finalize()\n\n    # Draw discrimination threshold on the right\n    data = load_spam(split=False)\n    oz = DiscriminationThreshold(LogisticRegression(), ax=axes[1])\n    oz.fit(data.X, data.y)\n    oz.finalize()\n\n    # Save figure\n    path = os.path.join(FIGURES, fname)\n    plt.tight_layout()\n    plt.savefig(path)\n\n", "CodeBleu_score": 55.277565768170234}, {"code": "def classification(fname=\"classification.png\")\n\t\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    data = load_spam(split=True)\n    oz = ClassificationReport(MultinomialNB(), ax=axes[0])\n    oz.fit(data.X.train, data.y.train)\n    oz.score(data.X.test, data.y.test)\n    oz.finalize()\n\n    data = load_spam(split=False)\n    oz = DiscriminationThreshold(LogisticRegression(), ax=axes[1])\n    oz.fit(data.X, data.y)\n    oz.finalize()\n\n    path = os.path.join(FIGURES, fname)\n    plt.tight_layout()\n    plt.savefig(path)\n\n", "CodeBleu_score": 55.277565768170234}, {"code": "def classification(fname=\"classification.png\")\n\t\n    # Create side-by-side axes grid\n    _, axes = plt.subplots(ncols=2, figsize=(18, 6))\n\n    # Plot classification report on the left\n    data = load_spam(split=True)\n    oz = ClassificationReport(MultinomialNB(), ax=axes[0])\n    oz.fit(data.X.train, data.y.train)\n    oz.score(data.X.test, data.y.test)\n    oz.finalize()\n\n    # Plot discrimination threshold on the right\n    data = load_spam(split=False)\n    oz = DiscriminationThreshold(LogisticRegression(), ax=axes[1])\n    oz.fit(data.X, data.y)\n    oz.finalize()\n\n    # Save figure\n    path = os.path.join(FIGURES, fname)\n    plt.tight_layout()\n    plt.savefig(path)\n\n", "CodeBleu_score": 55.277565768170234}]}
{"instance_id": "318d3a674694", "generation_result": [{"code": "def get_color_cycle()\n\t\n    if mpl_ge_150:\n        try:\n            return [c[\"color\"] for c in mpl.rcParams[\"axes.prop_cycle\"]]\n        except KeyError:\n            pass\n\n    return copy(mpl.rcParams[\"axes.color_cycle\"])\n\n", "CodeBleu_score": 53.926399189691345}, {"code": "def get_color_cycle()\n\t\n    if mpl_ge_150:\n        try:\n            return [color[\"color\"] for color in mpl.rcParams[\"axes.prop_cycle\"]]\n        except KeyError:\n            pass\n\n    return copy(mpl.rcParams[\"axes.color_cycle\"])\n\n", "CodeBleu_score": 54.135134625666396}, {"code": "def get_color_cycle()\n\t\n    if mpl_ge_150:\n        try:\n            return [c[\"color\"] for c in mpl.rcParams[\"axes.prop_cycle\"]]\n        except KeyError:\n            pass\n    return copy(mpl.rcParams[\"axes.color_cycle\"])\n\n", "CodeBleu_score": 53.926399189691345}]}
{"instance_id": "f3fac557334c", "generation_result": [{"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized, \"bx-\")\n    plt.plot(self.x_difference, self.y_difference, \"r\")\n    plt.xlabel(\"Normalized X\")\n    plt.ylabel(\"Normalized Y\")\n    plt.xticks(\n        np.arange(0, 1.1, 0.1),\n        np.arange(\n            self.x_normalized.min(), self.x_normalized.max() + 0.1, 0.1\n        ),\n    )\n    plt.yticks(\n        np.arange(0, 1.1, 0.1),\n        np.arange(\n            self.y_normalized.min(), self.y_normalized.max() + 0.1, 0.1\n        ),\n    )\n    plt.vlines(\n        x=self.norm_knee,\n        ymin=self.y_normalized.min(),\n        ymax=self.y_normalized.max(),\n        linestyles=\"dashed\",\n    )\n    plt.show()\n\n", "CodeBleu_score": 49.15930083843594}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized, \"r-\")\n    plt.plot(self.x_difference, self.y_difference, \"b-\")\n    plt.xlabel(\"Normalized X\")\n    plt.ylabel(\"Normalized Y\")\n    plt.xticks(\n        np.arange(\n            min(self.x_normalized), max(self.x_normalized) + 0.1, 0.1\n        )\n    )\n    plt.yticks(\n        np.arange(\n            min(self.y_normalized), max(self.y_normalized) + 0.1, 0.1\n        )\n    )\n    if self.knee is not None:\n        plt.vlines(\n            x=self.norm_knee,\n            ymin=min(self.y_normalized),\n            ymax=max(self.y_normalized),\n            linestyles=\"dashed\",\n            colors=\"k\",\n        )\n    plt.show()\n\n", "CodeBleu_score": 42.54377043682466}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    # Import matplotlib.pyplot for plotting\n    import matplotlib.pyplot as plt\n\n    # Create a figure with a size of 8x8 inches\n    plt.figure(figsize=(8, 8))\n\n    # Plot the normalized x and y values\n    plt.plot(self.x_normalized, self.y_normalized, \"bx-\")\n\n    # Plot the distance curve in red\n    plt.plot(self.x_difference, self.y_difference, \"r\")\n\n    # Set the x and y ticks at intervals of 0.1 based on the minimum and maximum values of the respective data\n    plt.xticks(\n        np.arange(\n            np.floor(self.x_normalized.min()),\n            np.ceil(self.x_normalized.max()) + 1,\n            0.1,\n        )\n    )\n    plt.yticks(\n        np.arange(\n            np.floor(self.y_normalized.min()),\n            np.ceil(self.y_normalized.max()) + 1,\n            0.1,\n        )\n    )\n\n    # Draw a vertical line at the knee point to highlight it on the plot\n    plt.axvline(x=self.norm_knee, color=\"k\", linestyle=\"--\")\n\n", "CodeBleu_score": 52.54193626298088}]}
{"instance_id": "b2d48aae4fce", "generation_result": [{"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1])\n    plt.show()\n\n", "CodeBleu_score": 66.8691627037635}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1])\n    plt.show()\n\n", "CodeBleu_score": 66.8691627037635}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1])\n\n", "CodeBleu_score": 69.02973240571076}]}
{"instance_id": "4450ba2384c9", "generation_result": [{"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_digits([data[i]])\n        barlist = plt.bar(range(n_components), pca.components_[i])\n        plt.ylim(ymax=1.1)\n        plt.xticks(())\n        plt.xlim(-0.5, n_components)\n        plt.yticks(())\n        plt.title('Weights')\n        plt.show()\n\n    interact(show_decomp, i=(0, data.shape[0] - 1))\n\n", "CodeBleu_score": 72.71349915977055}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plt.figure(figsize=(8, 5))\n        plt.subplot(1, 2, 1)\n        plt.plot(data[i], label='data')\n        plt.plot(Xproj[i], label='projected')\n        plt.xlabel('Basis functions')\n        plt.ylabel('- Log Probability')\n        plt.legend()\n\n        plt.subplot(1, 2, 2)\n        plt.plot(pca.components_[i])\n        plt.xlabel('Basis functions')\n        plt.ylabel('PCA coefficients')\n\n    interact(show_decomp, i=(0, len(data) - 1))\n\n", "CodeBleu_score": 61.61109276130405}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from IPython.html.widgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_PCA_2D(data, Xproj, i)\n\n    slider = interact(show_decomp, i=(0, data.shape[0] - 1))\n    return slider\n\n", "CodeBleu_score": 65.81609993626702}]}
{"instance_id": "b09a163f3ff1", "generation_result": [{"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Plot also the training points\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n    pl.xlabel('sepal length (cm)')\n    pl.ylabel('sepal width (cm)')\n    pl.axis('tight')\n\n    pl.show()\n\n", "CodeBleu_score": 81.0659828077176}, {"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                         np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Plot also the training points\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n    pl.xlabel('sepal length (cm)')\n    pl.ylabel('sepal width (cm)')\n    pl.axis('tight')\n\n    pl.show()\n\n\n\n", "CodeBleu_score": 79.65424732695685}, {"code": "def plot_iris_knn()\n\t\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]\n    y = iris.target\n\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n    knn.fit(X, y)\n\n    x_min, x_max = X[:, 0].min() - .1, X[:, 0].max() + .1\n    y_min, y_max = X[:, 1].min() - .1, X[:, 1].max() + .1\n    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100),\n                             np.linspace(y_min, y_max, 100))\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Put the result into a color plot\n    Z = Z.reshape(xx.shape)\n    pl.figure()\n    pl.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Plot also the training points\n    pl.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold)\n    pl.xlabel('sepal length (cm)'\n                )\n    pl.ylabel('sepal width (cm)'\n                 )\n    pl.axis('tight')\n\n", "CodeBleu_score": 79.24742956461931}]}
{"instance_id": "8eaee3207c09", "generation_result": [{"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    plt.contour(X1, X2, Z, levels, colors=\"k\", linestyles=linestyles)\n    plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n\n    plt.axis(\"tight\")\n\n", "CodeBleu_score": 57.229625086322855}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = ['dashed', 'solid', 'dashed']\n    colors = 'k'\n\n    ax = plt.axes()\n    ax.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n\n    ax.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired)\n\n    ax.axis('tight')\n\n\n\n", "CodeBleu_score": 66.55895388527911}, {"code": "def plot_sgd_separator()\n\t\n    # we create 50 separable points\n    X, Y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, Y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = \"k\"\n    plt.contour(\n        X1,\n        X2,\n        Z,\n        levels,\n        colors=colors,\n        linestyles=linestyles,\n    )\n    plt.scatter(X[:, 0], X[:, 1], c=Y, cmap=plt.cm.Paired, edgecolor=\"black\", s=20)\n\n    plt.axis(\"tight\")\n\n", "CodeBleu_score": 60.14696093340943}]}
{"instance_id": "8b54f999b4c0", "generation_result": [{"code": "def dump_svmlight_file(self, file)\n\t\n    # Convert the data to a NumPy array\n    data = np.array(self.data)\n\n    # Separate the features (X) and labels (y)\n    X = data[:, :2]\n    y = data[:, 2]\n\n    # Save the features and labels to the specified file\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 48.87749021711913}, {"code": "def dump_svmlight_file(self, file)\n\t\n    X = np.array(self.data)\n    y = X[:, 2]\n    X = X[:, :2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 30.29354181628772}, {"code": "def dump_svmlight_file(self, file)\n\t\n    X = np.array(self.data)[:, :2]\n    y = np.array(self.data)[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 50.35937578545625}]}
{"instance_id": "2419013adc6e", "generation_result": [{"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    data = np.array(self.model.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel = self.kernel_type.get()\n    # check for all positive or all negative labels\n    if np.all(y > 0) or np.all(y < 0):\n        self.class_min = 1\n        self.class_max = 1\n        clf = svm.OneClassSVM(kernel=kernel, degree=degree, gamma=gamma, coef0=coef0)\n    else:\n        self.class_min = -1\n        self.class_max = +1\n        clf = svm.SVC(kernel=kernel, C=C, degree=degree, gamma=gamma, coef0=coef0)\n    clf.fit(X, y)\n    if hasattr(clf, \"score\"):\n        print(\"Accuracy:\", clf.score(X, y))\n    r = np.linspace(x_min, x_max, 50 * 2 + 1)\n    xx, yy = np.meshgrid(r, r)\n    self.model.surface = self.decision_surface(clf, xx, yy,\n                                              self.class_min, self.class_max,\n                                              self.surface_type.get())\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 62.47203185684381}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    data = np.array(self.model.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel = self.kernel_type_var.get()\n    # different classifiers are needed depending on problem\n    if np.all(y == y[0]):\n        # XXX: we use a one-class SVM\n        self.classifier = svm.OneClassSVM(kernel=kernel, gamma=gamma, coef0=coef0, degree=degree)\n        self.classifier.fit(X)\n    else:\n        self.classifier = svm.SVC(kernel=kernel, C=C, gamma=gamma, coef0=coef0, degree=degree)\n        self.classifier.fit(X, y)\n    if hasattr(self.classifier, \"score\"):\n        print(\"Accuracy:\", self.classifier.score(X, y) * 100)\n    r = np.linspace(x_min, x_max, 50 * 50)\n    xx, yy = np.meshgrid(r, r)\n    grid = np.c_[xx.ravel(), yy.ravel()]\n    if hasattr(self.classifier, \"decision_function\"):\n        z = self.classifier.decision_function(grid)\n    else:\n        z = self.classifier.predict_proba(grid)[:, 1]\n    z = z.reshape(xx.shape)\n    # interpolate\n    from scipy.ndimage import zoom\n    z = zoom(z, 50)\n    z = z.reshape(xx.shape)\n    # plot\n    CS = self.ax.contour(xx, yy, z, levels=[-1.0, 0.0, 1.0], colors=('r', 'g", "CodeBleu_score": 55.74636170908131}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    data = np.array(self.model.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel = self.kernel_type.get()\n    # different classifiers require different vector presentation\n    # for ease of programming we require a 2d-array\n    if np.alen(X) == 0 or np.alen(y) == 0:\n        print(\"you must provide at least 1 example\")\n        return\n    if self.model.cls is None:\n        self.model.cls = svm.OneClassSVM(kernel=kernel, gamma=gamma, coef0=coef0, degree=degree)\n        self.model.cls.fit(X)\n    else:\n        self.model.cls = svm.SVC(kernel=kernel, C=C, gamma=gamma, coef0=coef0, degree=degree)\n        self.model.cls.fit(X, y)\n    if hasattr(self.model.cls, \"score\"):\n        print(\"accuracy:\", self.model.cls.score(X, y) * 100, \"%\")\n    self.plot_surface()\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 62.38189336982393}]}
{"instance_id": "e887fd2a8513", "generation_result": [{"code": "def source_decode(sourcecode, verbose=0)\n\t\n    if verbose > 2:\n        print(sourcecode)\n    import_string, object_string = sourcecode.rsplit('.', 1)\n    if import_string == 'tpot':\n        import_string = object_string\n        object_string = None\n    try:\n        obj = getattr(import_module(import_string), object_string)\n    except (ImportError, AttributeError) as e:\n        if verbose > 2:\n            raise ImportError(e)\n        else:\n            print('Warning: %s' % e)\n            obj = None\n    return import_string, object_string, obj\n\n", "CodeBleu_score": 32.63255252174426}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n\n    import_string, object_string = sourcecode.split(\".\")\n    if import_string.startswith(\"tpot\"):\n        import_string = import_string[5:]\n\n    try:\n        imported_object = import_string_to_object(import_string, object_string)\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        else:\n            print(\"Warning: Could not import {}\".format(sourcecode))\n            return import_string, object_string, None\n\n    return import_string, object_string, imported_object\n\n", "CodeBleu_score": 28.999537168853685}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    if sourcecode.startswith(\"tpot.\"):\n        import_string = sourcecode[5:]\n    else:\n        import_string = sourcecode\n\n    module_string = import_string.split(\".\")[0]\n    object_string = \".\".join(import_string.split(\".\")[1:])\n\n    try:\n        if module_string in sys.modules:\n            module = sys.modules[module_string]\n        else:\n            module = importlib.import_module(module_string)\n\n        imported_object = getattr(module, object_string)\n    except Exception as e:\n        if verbose > 2:\n            raise ImportError(\n                \"Import of %s failed with the following error: %s\" % (sourcecode, e)\n            )\n        else:\n            warnings.warn(\"Import of %s failed with the following error: %s\" % (sourcecode, e))\n            imported_object = None\n\n    return import_string, object_string, imported_object\n\n", "CodeBleu_score": 44.18699927406274}]}
{"instance_id": "5d6f629c3363", "generation_result": [{"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step_obj in pipeline_steps:\n            if hasattr(step_obj, \"fit\"):\n                if \"sample_weight\" in inspect.signature(step_obj.fit).parameters:\n                    key = \"{}_sample_weight\".format(step_name)\n                    sample_weight_dict[key] = sample_weight\n\n    if len(sample_weight_dict) > 0:\n        return sample_weight_dict\n    else:\n        return None\n\n\n", "CodeBleu_score": 48.0693937894792}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step_value in pipeline_steps:\n            fit_method = getattr(step_value, \"fit\", None)\n            if fit_method is not None:\n                args = inspect.getfullargspec(fit_method).args\n                if \"sample_weight\" in args:\n                    key = \"{}_sample_weight\".format(step_name)\n                    sample_weight_dict[key] = sample_weight\n    if len(sample_weight_dict) > 0:\n        return sample_weight_dict\n    else:\n        return None\n\n", "CodeBleu_score": 41.38087933707869}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if \"sample_weight\" in inspect.getargspec(step.fit).args:\n                    sample_weight_dict[step_name + \"__sample_weight\"] = sample_weight\n\n    return sample_weight_dict if sample_weight_dict else None\n\n", "CodeBleu_score": 41.078632340326294}]}
{"instance_id": "cae17d519818", "generation_result": [{"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._optimized_pipeline:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    sklearn_pipeline = self._toolbox.compile(expr=self._optimized_pipeline)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        sklearn_pipeline.fit(features, target)\n\n    if self.verbosity >= 1:\n        print(\"", "CodeBleu_score": 22.190291070665104}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._optimized_pipeline:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    sklearn_pipeline = self._toolbox.compile(expr=self._optimized_pipeline)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        sklearn_pipeline.fit(features, target)\n\n    if self.verbosity >= 1:\n        if self.verbosity == 2:\n            self._pbar.write(\"\", file=self.log_file_)\n        self._pbar.write(\n            \"Best pipeline: {}\".format(sklearn_pipeline), file=self.log_file_\n        )\n\n    self._fitted_pipelines = []\n    for pipeline, pipeline_scores in zip(\n        self._pareto_front.items, reversed(self._pareto_front.keys)\n    ):\n        sklearn_pipeline = self._toolbox.compile(expr=pipeline)\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            sklearn_pipeline.fit(features, target)\n        self._fitted_pipelines.append(sklearn_pipeline)\n\n", "CodeBleu_score": 44.39088597889562}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._optimized_pipeline:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    sklearn_pipeline = self._toolbox.compile(expr=self._optimized_pipeline)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        sklearn_pipeline.fit(features, target)\n\n    if self.verbosity >= 1:\n        print(\"", "CodeBleu_score": 22.190291070665104}]}
{"instance_id": "638683d78167", "generation_result": [{"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.fitted_pipeline_:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target, sample_weight=None\n    )\n\n    if isinstance(self.scoring_function, str):\n        try:\n            scorer = SCORERS[self.scoring_function]\n        except KeyError:\n            raise ValueError(\n                \"The scoring function {} is not available. Please refer to the documentation for a list of available scoring functions.\".format(\n                    self.scoring_function\n                )\n            )\n    else:\n        scorer = self.scoring_function\n\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n", "CodeBleu_score": 61.39980982345455}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.fitted_pipeline_:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target, sample_weight=None\n    )\n\n    if self.scoring_function in SCORERS:\n        scorer = SCORERS[self.scoring_function]\n    else:\n        scorer = self.scoring_function\n\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n", "CodeBleu_score": 49.23064083735689}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.fitted_pipeline_:\n        raise RuntimeError(\n            \"A pipeline has not yet been optimized. Please call fit() first.\"\n        )\n\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target, sample_weight=None\n    )\n\n    if callable(self.scoring_function):\n        scorer = self.scoring_function\n    else:\n        scorer = SCORERS[self.scoring_function]\n\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n", "CodeBleu_score": 51.48477307341156}]}
{"instance_id": "a04382560333", "generation_result": [{"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if self.imputer is None:\n        self.imputer = SimpleImputer(strategy=\"median\")\n        self.imputer.fit(features)\n    return self.imputer.transform(features)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 73.93042169190348}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if self.imputer is None:\n        self.imputer = SimpleImputer(strategy=\"median\")\n        self.imputer.fit(features)\n    return self.imputer.transform(features)\n\n\n\n\n", "CodeBleu_score": 73.93042169190348}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if self._imputer is None:\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n\n", "CodeBleu_score": 74.61402275071829}]}
{"instance_id": "0043d411c332", "generation_result": [{"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    # Generate the pipeline code string\n    pipeline_code = export_pipeline(\n        expr,\n        self.operators,\n        self._pset,\n        self._imputed,\n        self._optimized_pipeline_score,\n        self.random_state,\n    )\n\n    # Evaluate the pipeline code string within a specific context\n    context = {\"random_state\": self.random_state}\n    exec(pipeline_code, context)\n    pipeline = context[\"pipeline\"]\n\n    # Set the pipeline's memory attribute\n    pipeline.memory = self.memory\n\n    # If a random state is specified, set the random_state parameter for each step in the pipeline\n    if self.random_state is not None:\n        for step in pipeline.steps:\n            if hasattr(step[1], \"random_state\"):\n                step[1].random_state = self.random_state\n\n    # Return the configured scikit-learn pipeline\n    return pipeline\n\n", "CodeBleu_score": 38.07816295729347}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    # Generate the pipeline code string from the expression and a predefined set of operators\n    sklearn_pipeline_str = export_pipeline(expr, self.operators, self._pset)\n\n    # Evaluate the pipeline code string within a specific context to obtain the scikit-learn pipeline object\n    context = {\"np\": np, \"pd\": pd, \"sp\": sp, \"sklearn\": sklearn}\n    exec(sklearn_pipeline_str, context)\n    pipeline = context[\"pipeline\"]\n\n    # Set the pipeline's memory attribute\n    pipeline.memory = self.memory\n\n    # If a random state is specified, set the random_state parameter for each step in the pipeline\n    if self.random_state is not None:\n        for step in pipeline.steps:\n            if hasattr(step[1], \"random_state\"):\n                step[1].random_state = self.random_state\n\n    # Return the configured scikit-learn pipeline\n    return pipeline\n\n", "CodeBleu_score": 44.67050512970178}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    sklearn_pipeline_str = export_pipeline(expr, self.operators, self._pset, self._imputed, self._optimized_pipeline_score, self.random_state)\n    # Compile the pipeline string\n    try:\n        # Compile the pipeline string\n        sklearn_pipeline = eval(sklearn_pipeline_str, self._context, self._context)\n    except Exception as e:\n        raise RuntimeError(\"Failed to compile pipeline: {}\".format(str(e)))\n    # Set the memory attribute\n    sklearn_pipeline.memory = self.memory\n    # Set the random state\n    if self.random_state is not None:\n        for step in sklearn_pipeline.steps:\n            if hasattr(step[1], \"random_state\"):\n                step[1].random_state = self.random_state\n    return sklearn_pipeline\n\n", "CodeBleu_score": 43.94899733320442}]}
{"instance_id": "ca0ce462aa76", "generation_result": [{"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    primitive_sets = [set(individual.primitive_nodes) for individual in population]\n\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = [\n        (i, j)\n        for i in range(len(population))\n        for j in range(i + 1, len(population))\n        if len(primitive_sets[i].intersection(primitive_sets[j])) > 0\n        and individual_strings[i] != individual_strings[j]\n    ]\n\n    # Consider eligible pairs in both possible orders\n    eligible_pairs += [(j, i) for i, j in eligible_pairs]\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n\n    # Return the corresponding individuals from the population\n    return population[i], population[j]\n\n", "CodeBleu_score": 30.273435174251883}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    primitive_sets = [set(node.name for node in individual.primitives) for individual in population]\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = [(i, j) for i in range(len(population)) for j in range(i + 1, len(population)) if len(primitive_sets[i].intersection(primitive_sets[j])) > 0 and individual_strings[i] != individual_strings[j]]\n    # Consider eligible pairs in both possible orders\n    eligible_pairs += [(j, i) for i, j in eligible_pairs]\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n    # Randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n    # Return the corresponding individuals from the population\n    return population[i], population[j]\n\n", "CodeBleu_score": 30.829450318071178}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # create sets of primitive nodes for each individual\n    primitives_by_individual = [set(ind.primitives) for ind in population]\n    # convert each individual to a string representation\n    str_by_individual = [str(ind) for ind in population]\n    # identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i, ind1 in enumerate(population):\n        for j, ind2 in enumerate(population):\n            if i != j and primitives_by_individual[i] & primitives_by_individual[j] and str_by_individual[i] != str_by_individual[j]:\n                eligible_pairs.append((i, j))\n                eligible_pairs.append((j, i))\n    # if no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n    # randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n    # return the corresponding individuals from the population\n    return population[i], population[j]\n\n", "CodeBleu_score": 29.636519884516954}]}
{"instance_id": "4b03c843f506", "generation_result": [{"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n    if num_steps > 1:\n        pipeline_text = \"make_pipeline(", "CodeBleu_score": 15.720330391266845}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n    if num_steps > 1:\n        pipeline_text = \"make_pipeline(", "CodeBleu_score": 15.720330391266845}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n\n    if num_steps > 1:\n        pipeline_text = \"make_pipeline(", "CodeBleu_score": 15.720330391266845}]}
{"instance_id": "e9aec2ee39a4", "generation_result": [{"code": "def _process_operator(operator, operators, depth=0)\n\t\n    op_name = operator[0]\n    if op_name == \"CombineDFs\":\n        steps = [operator[1]]\n    else:\n        tpot_op = get_by_name(op_name, operators)\n        steps = [op_name]\n        for i in range(1, len(operator)):\n            if isinstance(operator[i], list):\n                steps.append(_process_operator(operator[i], operators, depth + 1))\n            else:\n                steps.append(operator[i])\n        if tpot_op.root and depth > 0:\n            steps = [\"StackingEstimator(estimator={})\".format(steps[0])] + steps[1:]\n    return steps\n\n", "CodeBleu_score": 49.88276554681331}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    # operator name\n    op_name = operator[0]\n    if op_name == \"CombineDFs\":\n        # combine two dataframes\n        return [\"combineDFs([titanic_train, titanic_test], axis=0)\"]\n    else:\n        # get operator object\n        tpot_op = get_by_name(op_name, operators)\n\n        # process input operators recursively\n        input_ops = [\n            _process_operator(op, operators, depth + 1) for op in operator[1:]\n        ]\n\n        # if root operator and depth > 0, wrap in StackingEstimator\n        if tpot_op.root and depth > 0:\n            input_ops = [\n                \"StackingEstimator(estimator={})\".format(op) for op in input_ops\n            ]\n\n        # build list of steps\n        steps = [\n            \"{}(\".format(op_name) + \", \".join(input_ops) + \")\"\n        ]\n\n        return steps\n\n", "CodeBleu_score": 44.08372406195902}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    operator_name = operator[0]\n    if operator_name == \"CombineDFs\":\n        return [\"CombineDFs(stack_method='auto')\"]\n    else:\n        tpot_op = get_by_name(operator_name, operators)\n        if tpot_op.root and depth > 0:\n            return [\n                \"StackingEstimator(estimator={})\".format(\n                    _process_operator(operator[1], operators, depth + 1)\n                )\n            ]\n        else:\n            return [\n                \"{}({})\".format(\n                    operator_name,\n                    \", \".join(\n                        [\n                            _process_operator(op, operators, depth + 1)[0]\n                            if op[0] != \"CombineDFs\"\n                            else \"CombineDFs(stack_method='auto')\"\n                            for op in operator[1:]\n                        ]\n                    ),\n                )\n            ]\n\n", "CodeBleu_score": 36.58669664320495}]}
{"instance_id": "0513bf969510", "generation_result": [{"code": "def transform(self, X)\n\t\n    X = check_array(X, accept_sparse='csr')\n    if not hasattr(self, 'selected_features_'):\n        self.selected_features_ = auto_select_categorical_features(X, self.threshold, self.minimum_fraction)\n    if len(self.selected_features_) == 0:\n        raise ValueError('No categorical features found.')\n    X_selected = _X_selected(X, self.selected_features_)\n    self.encoder_ = OneHotEncoder(categorical_features=self.selected_features_)\n    X_selected = self.encoder_.fit_transform(X_selected)\n    return X_selected\n\n\n", "CodeBleu_score": 43.42690759445795}, {"code": "def transform(self, X)\n\t\n    X = check_array(X, accept_sparse='csr')\n    if self.threshold == 'all':\n        return X\n    if self.minimum_fraction is not None:\n        if self.minimum_fraction < 0 or self.minimum_fraction > 1:\n            raise ValueError('minimum_fraction must be a float between 0 and 1')\n    if self.threshold == 'auto':\n        self.threshold = auto_select_categorical_features(X, self.minimum_fraction)\n    if self.threshold < 0:\n        raise ValueError('threshold must be a non-negative integer or \"all\" or \"auto\"')\n    selected_features = _X_selected(X, self.threshold)\n    if len(selected_features) == 0:\n        raise ValueError('No categorical features found')\n    X_selected = X[:, selected_features]\n    self.one_hot_encoder_ = OneHotEncoder(categories='auto', sparse=False)\n    X_selected_encoded = self.one_hot_encoder_.fit_transform(X_selected)\n    X_transformed = np.hstack((X[:, ~selected_features], X_selected_encoded))\n    return X_transformed\n\n", "CodeBleu_score": 38.429998881247926}, {"code": "def transform(self, X)\n\t\n    X = check_array(X, accept_sparse='csr')\n    self.selected_ = auto_select_categorical_features(X, self.threshold, self.minimum_fraction)\n    if len(self.selected_) == 0:\n        raise ValueError('No categorical features found.')\n    self.one_hot_encoder_ = OneHotEncoder(categorical_features=self.selected_)\n    return self.one_hot_encoder_.fit_transform(X)\n\n", "CodeBleu_score": 38.0226483790317}]}
{"instance_id": "5b1bcf42ca9e", "generation_result": [{"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    all_classes = np.unique(np.concatenate([y_true, y_pred]))\n    class_accuracies = []\n\n    for this_class in all_classes:\n        true_for_this_class = y_true == this_class\n        pred_for_this_class = y_pred == this_class\n        true_positives = np.sum(true_for_this_class & pred_for_this_class)\n        false_negatives = np.sum(true_for_this_class & ~pred_for_this_class)\n        false_positives = np.sum(~true_for_this_class & pred_for_this_class)\n        true_negatives = np.sum(~true_for_this_class & ~pred_for_this_class)\n\n        sensitivity = true_positives / float(true_positives + false_negatives)\n        specificity = true_negatives / float(true_negatives + false_positives)\n\n        if np.isnan(sensitivity):\n            sensitivity = 0\n\n        if np.isnan(specificity):\n            specificity = 1\n\n        class_accuracies.append(np.mean([sensitivity, specificity]))\n\n    return np.mean(class_accuracies)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.04030950448613}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    all_classes = np.unique(np.concatenate([y_true, y_pred]))\n    class_accuracies = []\n    for class_ in all_classes:\n        true_positives = np.sum((y_true == class_) & (y_pred == class_))\n        true_negatives = np.sum((y_true != class_) & (y_pred != class_))\n        false_positives = np.sum((y_true != class_) & (y_pred == class_))\n        false_negatives = np.sum((y_true == class_) & (y_pred != class_))\n        sensitivity = true_positives / float(true_positives + false_negatives)\n        specificity = true_negatives / float(true_negatives + false_positives)\n        if len(all_classes) == 1:\n            specificity = 1\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n    return np.mean(class_accuracies)\n\n", "CodeBleu_score": 27.439608718436432}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    all_classes = np.unique(np.concatenate((y_true, y_pred)))\n    class_accuracies = []\n    for this_class in all_classes:\n        true_for_this_class = y_true == this_class\n        pred_for_this_class = y_pred == this_class\n        true_positives = np.sum(true_for_this_class & pred_for_this_class)\n        false_negatives = np.sum(true_for_this_class & ~pred_for_this_class)\n        false_positives = np.sum(~true_for_this_class & pred_for_this_class)\n        true_negatives = np.sum(~true_for_this_class & ~pred_for_this_class)\n        sensitivity = true_positives / float(true_positives + false_negatives)\n        specificity = true_negatives / float(true_negatives + false_positives)\n        if true_positives + false_negatives == 0:\n            sensitivity = 0.0\n        if true_negatives + false_positives == 0:\n            specificity = 0.0\n        if this_class in y_true:\n            class_accuracies.append(np.mean([sensitivity, specificity]))\n        else:\n            class_accuracies.append(specificity)\n    return np.mean(class_accuracies)\n\n", "CodeBleu_score": 28.742100929642067}]}
{"instance_id": "19a9ad39de0a", "generation_result": [{"code": "def transform(self, X, y=None)\n\t\n\n    X = check_array(X, accept_sparse='csr')\n\n    if X.shape[1] == 0:\n        return X\n\n    non_zero_count = X.astype(bool).sum(axis=1)\n    zero_count = X.shape[1] - non_zero_count\n    return np.hstack((non_zero_count.reshape(-1, 1), zero_count.reshape(-1, 1), X))\n", "CodeBleu_score": 18.326224274022984}, {"code": "def transform(self, X, y=None)\n\t\n\n    X = check_array(X, accept_sparse=True)\n    X_new = np.zeros((X.shape[0], X.shape[1] + 2))\n    X_new[:, 0] = (X == 0).sum(axis=1)\n    X_new[:, 1] = (X != 0).sum(axis=1)\n    X_new[:, 2:] = X\n    return X_new\n\n\n", "CodeBleu_score": 13.559750299809068}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    non_zero_count = X.astype(bool).sum(axis=1)\n    zero_count = X.shape[1] - non_zero_count\n    return np.column_stack((non_zero_count, zero_count, X))", "CodeBleu_score": 9.919733927374107}]}
{"instance_id": "5e8db0b5d447", "generation_result": [{"code": "def _init_pretest(self, features, target)\n\t\n    self.target_classes = np.unique(target)\n    self.pretest_size = max(self.target_classes.shape[0], self.cv)\n\n    pretest_X, pretest_y = train_test_split(\n        features,\n        target,\n        train_size=self.pretest_size,\n        random_state=self.random_state,\n    )\n\n    # Ensure that each target class is included in the pretest set\n    if self.target_classes.shape[0] < pretest_y.shape[0]:\n        pretest_X = _safe_indexing(pretest_X, self.target_classes)\n        pretest_y = _safe_indexing(pretest_y, self.target_classes)\n\n    return pretest_X, pretest_y\n\n", "CodeBleu_score": 22.928553585110464}, {"code": "def _init_pretest(self, features, target)\n\t\n    unique_target_classes = np.unique(target)\n    self.pretest_size = max(self.pretest_size, len(unique_target_classes))\n\n    if self.pretest_size > len(features):\n        self.pretest_size = len(features)\n\n    pretest_X, pretest_y = train_test_split(\n        features,\n        target,\n        test_size=self.pretest_size,\n        random_state=self.random_state,\n    )\n\n    # Ensure that all target classes are included in pretest_y\n    unique_target_classes = np.unique(target)\n    if len(unique_target_classes) > len(np.unique(pretest_y)):\n        for target_class in unique_target_classes:\n            if target_class not in np.unique(pretest_y):\n                # Index the first instance of the target class\n                target_class_index = np.where(target == target_class)[0][0]\n                pretest_X = np.concatenate(\n                    (pretest_X, features[target_class_index].reshape(1, -1))\n                )\n                pretest_y = np.concatenate((pretest_y, target[target_class_index].reshape(1)))\n\n    return pretest_X, pretest_y\n\n", "CodeBleu_score": 35.64338827140216}, {"code": "def _init_pretest(self, features, target)\n\t\n\n    # Check if target has more than 2 classes\n    if np.unique(target).shape[0] < 2:\n        raise ValueError(\n            \"Target has less than 2 classes. This is not a classification problem.\"\n        )\n\n    # Calculate the number of unique target classes\n    num_unique_classes = np.unique(target).shape[0]\n\n    # Ensure the training size is at least this number\n    if self.train_size_ is None:\n        self.train_size_ = num_unique_classes\n    elif self.train_size_ < num_unique_classes:\n        self.train_size_ = num_unique_classes\n\n    # Split the features and target into pretest_X and pretest_y\n    self.pretest_X_, self.pretest_y_ = train_test_split(\n        features,\n        target,\n        train_size=self.train_size_,\n        random_state=self.random_state,\n    )\n\n    # If all target classes are not included in pretest_y, adjust pretest_y\n    if np.unique(self.pretest_y_).shape[0] < num_unique_classes:\n        # Get unique target values\n        unique_target_values = np.unique(target)\n\n        # Get indices of unique target values in pretest_y\n        indices = [\n            np.where(self.pretest_y_ == value)[0][0] for value in unique_target_values\n        ]\n\n        # Index unique target values in pretest_X and pretest_y\n        self.pretest_X_ = _safe_indexing(self.pretest_X_, indices)\n        self.pretest_y_ = _safe_indexing(self.pretest_y_, indices)\n\n", "CodeBleu_score": 34.32578841884767}]}
{"instance_id": "5e3d48667396", "generation_result": [{"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.DType):\n        return dtype.as_numpy_dtype\n    return dtype\n\n", "CodeBleu_score": 49.19748004987954}, {"code": "def _to_numpy_type(dtype)\n\t\n    return dtypes.to_numpy_type(dtype)\n\n", "CodeBleu_score": 32.79498691971226}, {"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.DType):\n        return dtype.as_numpy_dtype\n    elif isinstance(dtype, np.dtype):\n        return dtype\n    else:\n        return np.dtype(dtype)\n\n", "CodeBleu_score": 71.70109018822171}]}
{"instance_id": "8f1120fdd463", "generation_result": [{"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size:\n            ds = ds.batch(batch_size)\n        ds_numpy = tfds.as_numpy(ds)\n    except AttributeError:\n        ds_numpy = map(_to_numpy, ds)\n    return ds_numpy", "CodeBleu_score": 16.348819693110016}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size is None:\n            return np.stack(list(ds.as_numpy_iterator()))\n        else:\n            return np.concatenate([batch for batch in ds.batch(batch_size).as_numpy_iterator()], axis=0)\n    except AttributeError:\n        return np.stack([batch for batch in ds.batch(batch_size).as_numpy_iterator()], axis=0)\n\n", "CodeBleu_score": 17.677288198214647}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size is None:\n            return np.stack([_to_numpy(x) for x in ds])\n        else:\n            return np.concatenate([_to_numpy(x) for x in ds.batch(batch_size)], axis=0)\n    except:\n        return np.concatenate([_to_numpy(x) for x in ds], axis=0)\n\n", "CodeBleu_score": 16.06616800059415}]}
{"instance_id": "282271955871", "generation_result": [{"code": "def get_prng(seed)\n\t\n    if not isinstance(seed, int):\n        raise TypeError(f'Trax PRNG requires integer seeds, got {type(seed)}')\n    seed = np.uint32(seed)\n    key = np.uint32(np.random.randint(np.iinfo(np.uint32).max, size=2))\n    key = np.bitwise_xor(key, np.left_shift(seed, np.uint32(32)))\n    return key\n\n", "CodeBleu_score": 33.70346246080349}, {"code": "def get_prng(seed)\n\t\n    if isinstance(seed, (int, float)):\n        seed = int(seed)\n    else:\n        raise TypeError(f'seed must be convertible to int, got {type(seed)}')\n    seed1 = (seed >> 32) & 0xFFFFFFFF\n    seed0 = seed & 0xFFFFFFFF\n    return np.array([0, seed0, seed1, 0], dtype=np.uint32)\n\n", "CodeBleu_score": 21.498788135930987}, {"code": "def get_prng(seed)\n\t\n    if seed is None:\n        seed = np.random.randint(0, 2 ** 32)\n    if not isinstance(seed, int):\n        raise ValueError(f'seed must be an integer, got {seed}.')\n    seed = np.uint32(seed)\n    key = np.array([seed >> 32, seed % 2 ** 32], dtype=np.uint32)\n    return key\n\n\n\n\n", "CodeBleu_score": 29.96512908767035}]}
{"instance_id": "42234dccce9a", "generation_result": [{"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.timezone)\n    elif pdt.is_datetime64_any_dtype(s.dtype):\n        return s.dt.tz_localize(dtype.timezone)\n    elif pdt.is_numeric_dtype(s.dtype):\n        return s.map(pd.to_datetime, unit='ns', utc=True).dt.tz_localize(dtype.timezone)\n    else:\n        return pd.to_datetime(s, utc=True).dt.tz_localize(dtype.timezone)\n\n", "CodeBleu_score": 74.54391953570713}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.timezone)\n    elif pdt.is_datetime64_any_dtype(s.dtype):\n        return s.dt.tz_localize(\"UTC\").dt.tz_convert(dtype.timezone)\n    elif pdt.is_numeric_dtype(s.dtype):\n        return s.map(dt.Timestamp).dt.tz_localize(dtype.timezone)\n    else:\n        return s.astype(\"datetime64[ns]\").dt.tz_localize(\"UTC\").dt.tz_convert(\n            dtype.timezone\n        )\n\n", "CodeBleu_score": 60.712379323977316}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.timezone).dt.tz_localize(None)\n    elif pdt.is_datetime64_any_dtype(s.dtype):\n        return s.dt.tz_localize(dtype.timezone)\n    elif pdt.is_numeric_dtype(s.dtype):\n        return dd.to_datetime(s, unit=\\\"ns\\\").dt.tz_localize(dtype.timezone)\n    else:\n        return dd.to_datetime(s).dt.tz_localize(dtype.timezone)\n\n", "CodeBleu_score": 68.23645495414269}]}
{"instance_id": "9cee7388879b", "generation_result": [{"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is not None:\n        arg = arg.dt.tz_convert(\"UTC\")\n\n    lower_bound = lower_bound.astype(\"datetime64[ns]\")\n    upper_bound = upper_bound.astype(\"datetime64[ns]\")\n\n    indexer = (arg >= lower_bound) & (arg <= upper_bound)\n\n    return dd.from_dask_array(indexer, index=arg.index)\n\n", "CodeBleu_score": 31.18206106731835}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if isinstance(arg, dd.DataFrame):\n        if arg.index.tz is None:\n            arg = arg.tz_localize(\"UTC\")\n        else:\n            arg = arg.tz_convert(\"UTC\")\n\n    lower_bound = lower_bound.astype(f\"datetime64[{arg.index.freq}]\")\n    upper_bound = upper_bound.astype(f\"datetime64[{arg.index.freq}]\")\n\n    indexer = (arg.index >= lower_bound) & (arg.index <= upper_bound)\n    return arg[indexer]\n\n", "CodeBleu_score": 30.368501567229906}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtypes[0] == \"datetime64[ns]\":\n        arg = arg.dt.tz_localize(\"UTC\")\n    return cls.serieswise(\n        lambda arg, lower_bound, upper_bound: arg.dt.time.between(\n            lower_bound, upper_bound\n        ),\n        kwargs={\n            \"arg\": arg,\n            \"lower_bound\": lower_bound,\n            \"upper_bound\": upper_bound,\n        },\n        dtype=bool,\n        name=op.name,\n    )\n\n", "CodeBleu_score": 23.77401900713947}]}
{"instance_id": "0ab1cc8ccf71", "generation_result": [{"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    if isinstance(value, dd.Scalar):\n        value = da.from_array(value.compute(), chunks=value.dask.chunks)\n        return dd.from_dask_array(value, npartitions=1)\n    if isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    if like is not None:\n        if isinstance(like, dd.Series):\n            return cls.asseries(value, like=like.compute())\n        if isinstance(like, dd.DataFrame):\n            return cls.asseries(value, like=like.index)\n        if isinstance(like, tuple):\n            return cls.asseries(value, like=pd.Series(like))\n        if isinstance(like, list):\n            return cls.asseries(value, like=pd.Series(like))\n        if isinstance(like, dict):\n            return cls.asseries(value, like=pd.Series(like.keys()))\n    return dd.from_pandas(pd.Series(value), npartitions=1)\n\n", "CodeBleu_score": 44.82347159415108}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, da.Series):\n        return value\n    elif isinstance(value, da.Array):\n        return value.to_dask_dataframe().iloc[:, 0]\n    elif isinstance(value, pd.Series):\n        return da.from_pandas(value, npartitions=1)\n    elif like is not None:\n        if isinstance(like, da.Series):\n            return cls.asseries(value, like=like.compute())\n        elif isinstance(like, da.Array):\n            return cls.asseries(value, like=like.compute())\n        elif isinstance(like, pd.Series):\n            return cls.asseries(value, like=like)\n        elif isinstance(like, pd.DataFrame):\n            return cls.asseries(value, like=like.iloc[:0])\n        elif isinstance(like, tuple):\n            return cls.asseries(value, like=pd.Series(like))\n        elif isinstance(like, list):\n            return cls.asseries(value, like=pd.Series(like))\n        elif isinstance(like, dict):\n            return cls.asseries(value, like=pd.Series(like))\n        else:\n            raise TypeError(f'Unable to create Series from {like}')\n    else:\n        return da.from_array(np.array([value]), chunks=1)\n\n", "CodeBleu_score": 34.445918940510744}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, da.Series):\n        return value\n    if isinstance(value, da.Array):\n        return value.to_dask_dataframe().iloc[:, 0]\n    if isinstance(value, pd.Series):\n        return da.from_pandas(value, npartitions=1)\n    if isinstance(value, (tuple, list)):\n        return da.from_array(value, npartitions=1)\n    if isinstance(value, dict):\n        return da.from_array(list(value.items()), npartitions=1)\n    if like is not None:\n        if isinstance(like, da.Series):\n            return da.from_array(value, like.dtype, npartitions=1)\n        if isinstance(like, da.Array):\n            return da.from_array(value, like.dtype, npartitions=1)\n        if isinstance(like, pd.Series):\n            return da.from_array(value, like.dtype, npartitions=1)\n        if isinstance(like, (tuple, list)):\n            return da.from_array(value, np.array(like).dtype, npartitions=1)\n        if isinstance(like, dict):\n            return da.from_array(list(value.items()), np.array(list(like.items())).dtype, npartitions=1)\n    return da.from_array(value, npartitions=1)\n", "CodeBleu_score": 34.57833412990774}]}
{"instance_id": "926220a06a0c", "generation_result": [{"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for key, value in dictionary.items():\n        if not isinstance(value, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected a Dask or Pandas DataFrame for table {key}, got {type(value)}\"\n            )\n\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 69.40457244689344}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n    else:\n        for k, v in dictionary.items():\n            if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n                raise TypeError(\n                    f\"Dask backend only supports dask or pandas DataFrames, got {type(v)}\"\n                )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 58.795150271972055}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for key, value in dictionary.items():\n        if not isinstance(value, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Value {value} for key {key} is not a valid DataFrame.\"\n            )\n\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 66.76536228745358}]}
{"instance_id": "95afc38c9125", "generation_result": [{"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    try:\n        classes = get_module_members(library_name)\n    except PackageNotFoundError:\n        logger.warning(f\"Could not find library {library_name}\")\n        return None\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} not found in module {library_name}\")\n    classes_names = [cls_name for cls_name, cls in classes.items() if cls_name.lower() == estimator_name.lower()]\n    if len(classes_names) > 1:\n        logger.debug(f\"Multiple classes found: {classes_names}\")\n        logger.warning(f\"Multiple classes found for estimator {estimator_name}. Using first one: {classes_names[0]}\")\n    estimator_class = classes[classes_names[0]]\n    if not inspect.isclass(estimator_class) or not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"Estimator {estimator_name} is not a subclass of sklearn's BaseEstimator\")\n    return estimator_class\n\n", "CodeBleu_score": 40.69821444514278}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} could not be found in {library_name} module.\")\n    matching_estimators = [\n        estimator for estimator in classes if estimator.lower() == estimator_name.lower()\n    ]\n    if len(matching_estimators) > 1:\n        logger.debug(f\"Multiple estimators found: {matching_estimators}\")\n        logger.warning(\n            f\"Multiple classes found for {estimator_name}. Using the first one: {matching_estimators[0]}\"\n        )\n    estimator_class = classes[matching_estimators[0]]\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"{estimator_class} is not a subclass of sklearn.BaseEstimator.\")\n    return estimator_class\n\n", "CodeBleu_score": 39.46370938243307}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    try:\n        classes = get_module_members(library_name)\n    except ModuleNotFoundError as e:\n        raise ValueError(f\"The library {library_name} is not found. {e}\")\n\n    selected_estimator = None\n    for class_name, class_ in classes.items():\n        if estimator_name == class_name:\n            if selected_estimator is not None:\n                logger.debug(f\"Multiple classes found for {estimator_name}: {selected_estimator} and {class_}\")\n                logger.warning(f\"Using the first one: {selected_estimator}\")\n            else:\n                selected_estimator = class_\n\n    if selected_estimator is None:\n        raise ValueError(f\"The estimator {estimator_name} is not found in the module {library_name}\")\n\n    if not inspect.isclass(selected_estimator) or not issubclass(selected_estimator, BaseEstimator):\n        logger.info(f\"The class {selected_estimator} is not a subclass of sklearn's BaseEstimator\")\n\n    return selected_estimator\n\n", "CodeBleu_score": 37.387902222137996}]}
{"instance_id": "9562a9cc043b", "generation_result": [{"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(os.path.join(os.path.dirname(__file__), \"estimator_to_task_mapping.json\")) as f:\n        mapping = json.load(f)\n        for task, estimators in mapping.items():\n            for estimator in estimators:\n                if estimator_name.endswith(estimator):\n                    return task\n    return \"unknown\"\n\n", "CodeBleu_score": 47.85910856688477}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    with open(os.path.join(os.path.dirname(__file__), \"estimator_to_task.json\")) as f:\n        estimator_to_task_map = json.load(f)\n    for task, estimators in estimator_to_task_map.items():\n        for estimator in estimators:\n            if estimator_name.endswith(estimator):\n                return task\n    return \"unknown\"\n\n", "CodeBleu_score": 48.66924261721688}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    # Read the mapping from a JSON file\n    with open(\"estimator_to_task_mapping.json\", \"r\") as f:\n        mapping = json.load(f)\n\n    # Check if the estimator name ends with any of the postfixes in the mapping\n    for postfix, task in mapping.items():\n        if estimator_name.endswith(postfix):\n            return task\n\n    # If no match is found, return \"unknown\"\n    return \"unknown\"\n\n", "CodeBleu_score": 33.21532597517148}]}
{"instance_id": "2f50195d043a", "generation_result": [{"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache)\n    data_dict = {}\n    for filename in os.listdir(data_cache):\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.split(\".\")[0].split(\"_\")[1:]\n        filepath = os.path.join(data_cache, filename)\n        data_dict[component] = load_data_file(filepath, extension)\n    return data_dict\n\n", "CodeBleu_score": 40.208576166496414}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache)\n    assert data_name in os.listdir(data_cache)\n    data_path = os.path.join(data_cache, data_name)\n    data_dict = {}\n    for filename in os.listdir(data_path):\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.split(\".\")[0].rsplit(\"_\", 1)\n        data = load_data_file(os.path.join(data_path, filename), extension)\n        data_dict[component] = data\n    return data_dict\n\n", "CodeBleu_score": 43.7065984203938}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache), f\"Directory {data_cache} does not exist\"\n    assert os.path.isfile(\n        os.path.join(data_cache, f\"{data_name}.json\")\n    ), f\"{data_name}.json not found in {data_cache}\"\n\n    with open(os.path.join(data_cache, f\"{data_name}.json\"), \"r\") as f:\n        data_info = json.load(f)\n\n    data_dict = {}\n    for filename in os.listdir(data_cache):\n        if filename.endswith(\".json\"):\n            continue\n\n        component, extension = filename.split(\".\")[0].split(\"_\")[-2:]\n        data_dict[component] = load_data_file(\n            os.path.join(data_cache, filename), extension\n        )\n\n    return data_dict\n\n", "CodeBleu_score": 39.05556894359241}]}
{"instance_id": "e0281206029e", "generation_result": [{"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        print(\"File already exists.\")\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(\n                f\"Failed to download dataset from {url}. Response code {response.status_code}.\"\n            )\n        total_size_in_bytes = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        wrote = 0\n        with open(filename, \"wb\") as fout:\n            for data in response.iter_content(block_size):\n                wrote = wrote + len(data)\n                fout.write(data)\n        if total_size_in_bytes != 0 and wrote != total_size_in_bytes:\n            raise AssertionError(\n                \"Something went wrong while downloading the dataset. Please try again.\"\n            )\n\n", "CodeBleu_score": 68.61447540899107}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(f\"Failed to download from {url} with status code {response.status_code}\")\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written = 0\n        with open(filename, \"wb\") as f:\n            for data in response.iter_content(block_size):\n                written += len(data)\n                f.write(data)\n        if total_size != 0 and written != total_size:\n            raise AssertionError(\n                f\"Incomplete download: expected {total_size} bytes but received {written} bytes\"\n            )\n    else:\n        raise AssertionError(f\"Unsupported URL: {url}\")\n\n", "CodeBleu_score": 68.48329459980793}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        with requests.get(url, stream=True) as r:\n            if not r.ok:\n                raise AssertionError(\n                    \"Download failed: status code {}", "CodeBleu_score": 16.345603906192625}]}
{"instance_id": "a69a71cc2fe8", "generation_result": [{"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    x, y = fetch_covtype(return_X_y=True)\n    y = y - 1\n    if dataset_params.get(\"binary_covtype\", False):\n        y = (y == 0).astype(np.int32)\n    data_desc = {\n        \"n_classes\": 2 if dataset_params.get(\"binary_covtype\", False) else 7,\n        \"default_split\": {\"train_size\": 0.2, \"random_state\": 42},\n    }\n    return {\"x\": x, \"y\": y}, data_desc\n\n", "CodeBleu_score": 58.06428481818158}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    x, y = fetch_covtype(return_X_y=True)\n    y = y - 1\n    if dataset_params.get(\"binary_classification\", False):\n        y = (y > 2).astype(np.int32)\n    data_desc = {\n        \"n_classes\": 2 if dataset_params.get(\"binary_classification\", False) else 7,\n        \"default_split\": {\"test_size\": 0.2, \"random_state\": 77},\n    }\n    return {\"x\": x, \"y\": y}, data_desc\n\n", "CodeBleu_score": 62.74424692543656}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    data = fetch_covtype(data_home=raw_data_cache)\n    x, y = data.data, data.target\n    y -= 1\n    if dataset_params.get(\"binary\", False):\n        y[y > 0] = 1\n    data_desc = {\"n_classes\": 2, \"default_split\": {\"train_size\": 0.2, \"random_state\": 42}}\n    return {\"x\": x, \"y\": y}, data_desc\n\n", "CodeBleu_score": 44.33100237489271}]}
{"instance_id": "129cbd2529ef", "generation_result": [{"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = []\n    for element in input_list:\n        if isinstance(element, list):\n            output_list.extend(flatten_list(element))\n        else:\n            output_list.append(element)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 41.300490207417845}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for el in input_list:\n        if isinstance(el, list):\n            output_list.extend(flatten_list(el))\n        else:\n            output_list.append(el)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 46.78161761391475}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for el in input_list:\n        if isinstance(el, list):\n            flattened_inner_list = flatten_list(el)\n            output_list.extend(flattened_inner_list)\n        else:\n            output_list.append(el)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 55.19468723459025}]}
{"instance_id": "2d38c2c60b59", "generation_result": [{"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(np.logical_and(x >= 0, x <= 1), x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x)))\n    elif complex_mode == \"jax\":\n        return np.log(x / (1 - x))\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'split', 'magnitude', or 'jax', but got \"\n            + str(complex_mode)\n        )\n\n", "CodeBleu_score": 50.50782766441397}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(np.logical_and(x >= 0, x <= 1), x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n\n    if complex_mode == \"jax\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"split\":\n        return np.log(x / (1 - x)) + 1j * np.log(1j * x / (1 - 1j * x))\n    elif complex_mode == \"magnitude\":\n        return np.log(x / (1 - x)) + 1j * np.log(np.abs(x) / np.abs(1 - x))\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'jax', 'split', or 'magnitude'.\"\n        )\n\n", "CodeBleu_score": 50.69848248518976}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    if eps is None:\n        x = np.where(np.logical_and(x >= 0, x <= 1), x, np.nan)\n    else:\n        x = np.clip(x, eps, 1 - eps)\n    if complex_mode == \"split\":\n        return np.log(x / (1 - x))\n    elif complex_mode == \"magnitude\":\n        return np.log(np.abs(x) / (1 - np.abs(x)))\n    elif complex_mode == \"jax\":\n        return np.log(x / (1 - x)) + 1j * np.log(1 - x / (1 - np.conj(x)))\n    else:\n        raise ValueError(\n            \"complex_mode must be one of 'split', 'magnitude', or 'jax', but got \"\n            + str(complex_mode)\n        )\n\n", "CodeBleu_score": 50.47307441902953}]}
{"instance_id": "205e296f8621", "generation_result": [{"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    ret = np.where(np.logical_and(x > -lambd, x < lambd), 0, x)\n    if ivy.exists(out):\n        return ivy.inplace_update(out, ret).astype(x.dtype)\n    return ivy.astype(ret, x.dtype)\n\n", "CodeBleu_score": 63.02825572496478}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    ret = np.where(np.abs(x) > lambd, x, 0)\n    if ivy.exists(out):\n        return ivy.inplace_update(out, ret).astype(x.dtype)\n    return ivy.astype(ret, x.dtype)\n\n", "CodeBleu_score": 61.74507171837443}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    ret = np.where(x > lambd, x, np.where(x < -lambd, x, 0))\n    if ivy.exists(out):\n        return ivy.inplace_update(out, ret).astype(x.dtype)\n    return ivy.astype(ret, x.dtype)\n\n", "CodeBleu_score": 83.72577475370882}]}
{"instance_id": "5b133f6ebe2d", "generation_result": [{"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.array(\n        [\n            round(\n                np.sin(\n                    (ivy.pi / 2)\n                    * (ivy.sin(ivy.pi / (2 * window_length)) ** 2 * i) ** 2\n                ),\n                8,\n            )\n            for i in range(1, window_length * 2)[0::2]\n        ],\n        dtype=dtype,\n    )\n\n", "CodeBleu_score": 39.811984437266105}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.array(\n        [\n            round(\n                (\n                    np.sin(\n                        (ivy.pi / 2) * (np.abs(ivy.arange(0, window_length) * 2 + 1 - window_length))\n                        / (window_length + 1)\n                    )\n                    ** 2\n                ).item(),\n                8,\n            )\n            for i in range(window_length)\n        ],\n        dtype=dtype,\n    )\n\n", "CodeBleu_score": 30.11302751623312}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.array(\n        [\n            round(\n                np.sin(\n                    (ivy.pi / 2)\n                    * (np.sin(ivy.pi / (2 * window_length)) ** 2 * i) ** 2\n                ),\n                8,\n            )\n            for i in range(1, window_length * 2)[0::2]\n        ],\n        dtype=dtype,\n    )\n\n", "CodeBleu_score": 40.376093896235595}]}
{"instance_id": "473296f771a9", "generation_result": [{"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.array(np.polyval(coeffs, x), dtype=np.promote_types(coeffs.dtype, x.dtype))\n\n", "CodeBleu_score": 17.584907134390058}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.array(np.polyval(coeffs, x), dtype=x.dtype)\n\n", "CodeBleu_score": 14.105694907701174}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.polyval(coeffs, x)\n\n", "CodeBleu_score": 13.70552496491311}]}
{"instance_id": "b8455221cb2a", "generation_result": [{"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        num_dims = len(x.shape)\n        axis = tuple(range(num_dims))\n    elif isinstance(axis, list):\n        axis = tuple(axis)\n    return np.amax(a=x, axis=axis, keepdims=keepdims, out=out)\n\n", "CodeBleu_score": 50.10316053474416}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.amax(\n        x,\n        axis=axis,\n        keepdims=keepdims,\n        out=out,\n    )\n\n", "CodeBleu_score": 31.28875416183059}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.amax(a=x, axis=axis, keepdims=keepdims, out=out)\n\n", "CodeBleu_score": 28.061054500005646}]}
{"instance_id": "f72489f434a3", "generation_result": [{"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 32.625925040171246}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 32.625925040171246}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = promote_types_of_inputs(x1, x2)\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 32.625925040171246}]}
{"instance_id": "55c0d77e4dc2", "generation_result": [{"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    a = np.asarray(a)\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.asarray(np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype), dtype=dtype)\n\n", "CodeBleu_score": 51.692107711779656}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    a = np.asarray(a)\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    if dtype is None:\n        return np.asarray(np.count_nonzero(a, axis=axis, keepdims=keepdims, out=out))\n    else:\n        return np.asarray(\n            np.count_nonzero(a, axis=axis, keepdims=keepdims, out=out, dtype=dtype)\n        )\n\n", "CodeBleu_score": 48.88818412177981}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.asarray(\n        np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out),\n        dtype=dtype,\n    )\n\n", "CodeBleu_score": 52.915778020489135}]}
{"instance_id": "784bf7d24fc2", "generation_result": [{"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if isinstance(spacing, int):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    else:\n        return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 71.0574149881516}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if isinstance(spacing, int):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    else:\n        spacing = list(spacing)\n        return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 77.99049223060528}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if isinstance(spacing, int):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    else:\n        return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 71.0574149881516}]}
{"instance_id": "efa0a51af6bc", "generation_result": [{"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.all(x == 0):\n        return ivy.zeros_like(x)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 58.2916344396612}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.all(x == 0):\n        return ivy.zeros_like(x)\n    return x * ivy.log(y)\n\n", "CodeBleu_score": 61.67428822001825}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if np.all(x == 0):\n        return np.array(0.0, dtype=x.dtype)\n    return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 56.31352663998304}]}
{"instance_id": "ac1645284260", "generation_result": [{"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _get_depth_max_pooling_kernel_and_strides(\n        x, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = ivy.permute_dims(x, axes=(*range(dims), dims + 1, dims))\n    return x, kernel, strides, depth_pooling\n\n\n\n", "CodeBleu_score": 47.068838942835235}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _get_depth_pooling_dims(x, kernel, strides, dims, data_format)\n    if depth_pooling:\n        x = ivy.permute_dims(x, axes=(0, *dims, 2))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 44.58703807489318}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _get_depth_pooling_dims(\n        x, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = ivy.permute_dims(x, (0, *dims, 2, 3))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 46.934435130966975}]}
{"instance_id": "18ff0a4f7550", "generation_result": [{"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif data_format != \"NWC\":\n            raise NotImplementedError(\n                \"Only 'NCW' and 'NWC' data formats are supported for dropout1d.\"\n            )\n        mask = np.random.binomial(1, prob, size=x.shape)\n        scaled_x = x * mask\n        if data_format == \"NCW\":\n            scaled_x = np.transpose(scaled_x, (0, 2, 1))\n        return scaled_x\n    else:\n        return x\n\n", "CodeBleu_score": 43.2485146546097}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif data_format != \"NWC\":\n            raise ivy.utils.exceptions.IvyException(\n                \"Invalid data_format. Should be one of ['NCW', 'NWC']\"\n            )\n        mask = np.random.binomial(1, prob, size=x.shape)\n        scaled_x = np.where(mask, x * (1 - prob), 0)\n        if data_format == \"NCW\":\n            scaled_x = np.transpose(scaled_x, (0, 2, 1))\n        return scaled_x\n    else:\n        return x\n\n", "CodeBleu_score": 50.2612686308094}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif data_format != \"NWC\":\n            raise ivy.utils.exceptions.IvyException(\n                \"Invalid data_format, expecting one of 'NCW' or 'NWC'\"\n            )\n        mask = np.random.binomial(1, prob, size=x.shape)\n        scaled_x = x * mask / (1 - prob)\n        if data_format == \"NCW\":\n            scaled_x = np.transpose(scaled_x, (0, 2, 1))\n        return scaled_x\n    else:\n        return x\n\n", "CodeBleu_score": 44.24101593054955}]}
{"instance_id": "0ce45eb7cbd9", "generation_result": [{"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    if not largest:\n        indices = np.argsort(x, axis=axis)\n        indices = np.take(indices, np.arange(k), axis=axis)\n    else:\n        x *= -1\n        indices = np.argsort(x, axis=axis)\n        indices = np.take(indices, np.arange(k), axis=axis)\n        x *= -1\n    if sorted:\n        if largest:\n            indices = np.flip(indices, axis=axis)\n        else:\n            indices = np.take(indices, np.arange(k), axis=axis)\n    topk_res = NamedTuple(\"top_k\", [(\"values\", np.ndarray), (\"indices\", np.ndarray)])\n    val = np.take_along_axis(x, indices, axis=axis)\n    return topk_res(val, indices)\n\n", "CodeBleu_score": 73.39809907247653}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return np.top_k(x, k, axis=axis, largest=largest, sorted=sorted, out=out)\n\n", "CodeBleu_score": 16.705540897022033}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    if not largest:\n        indices = np.argsort(x, axis=axis)\n        indices = np.take(indices, np.arange(k), axis=axis)\n    else:\n        x *= -1\n        indices = np.argsort(x, axis=axis)\n        indices = np.take(indices, np.arange(k), axis=axis)\n        x *= -1\n    if sorted:\n        if largest:\n            indices = np.flip(indices, axis=axis)\n        else:\n            indices = np.take(indices, np.arange(k), axis=axis)\n    topk_res = NamedTuple(\n        \"top_k\", [(\"values\", np.ndarray), (\"indices\", np.ndarray)]\n    )\n    val = np.take_along_axis(x, indices, axis=axis)\n    return topk_res(val, indices)\n\n", "CodeBleu_score": 69.44536437991434}]}
{"instance_id": "1424f9541998", "generation_result": [{"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    denorm = np.linalg.norm(x, 1, axis, keepdims=True)\n    denorm = denorm + np.finfo(x.dtype).eps\n    return np.divide(x, denorm, out=out)", "CodeBleu_score": 26.02948835369101}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        norm = np.sum(np.abs(x))\n        denorm = np.full(x.shape, norm)\n    else:\n        norm = np.sum(np.abs(x), axis=axis, keepdims=True)\n        denorm = norm + np.finfo(x.dtype).eps\n    return np.divide(x, denorm, out=out).astype(x.dtype)", "CodeBleu_score": 64.4183195817915}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    denorm = np.linalg.norm(x.flatten(), 1)\n    if axis is None:\n        denorm = np.reshape(np.asarray(denorm), (1,))\n    else:\n        denorm = np.expand_dims(denorm, axis)\n    denorm = denorm + np.finfo(x.dtype).eps\n    return np.divide(x, denorm, out=out)", "CodeBleu_score": 47.9636322192051}]}
{"instance_id": "4c3a386a1f05", "generation_result": [{"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape)\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, size=shape), dtype=dtype)\n\n", "CodeBleu_score": 80.94575993545362}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if seed is not None:\n        np.random.seed(seed)\n    return np.random.beta(alpha, beta, size=shape).astype(dtype)\n\n", "CodeBleu_score": 61.169371613295255}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape)\n    _check_shapes_broadcastable(shape, alpha, beta)\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, size=shape), dtype=dtype)\n\n", "CodeBleu_score": 78.14989564564966}]}
{"instance_id": "271200a8b261", "generation_result": [{"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 53.67721297299843}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return np.argsort(inverse)\n\n", "CodeBleu_score": 58.236116048303955}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse[np.argsort(inverse)]\n\n", "CodeBleu_score": 58.995904881049256}]}
{"instance_id": "040d73b37229", "generation_result": [{"code": "def plot_medical_charts() -> None\n\t\n    # Set plotting style\n    plt.style.use(\\\"seaborn-whitegrid\\\")\n\n    # Create a figure with subplots\n    fig, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axes[0, 0], misc_data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axes[0, 1], misc_data)\n\n    # Plot days in daycare\n    plot_daycare_days(axes[1, 0], misc_data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axes[1, 1], misc_data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export figure\n    export_figure(fig, config.medical_charts_file_name)\n", "CodeBleu_score": 28.562653996389287}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set plotting style\n    plt.style.use(config.plotting.style)\n\n    # Create figure with subplots\n    fig, axs = plt.subplots(\n        config.plotting.rows,\n        config.plotting.cols,\n        figsize=(config.plotting.width, config.plotting.height),\n        dpi=config.plotting.dpi,\n    )\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axs[0, 0], misc_data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axs[0, 1], misc_data)\n\n    # Plot days in daycare\n    plot_daycare_days(axs[1, 0], misc_data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axs[1, 1], misc_data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export figure\n    export_figure(fig, config.plotting.export_file)\n", "CodeBleu_score": 29.001720965858556}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set plotting style\n    plt.style.use(\\\"seaborn-whitegrid\\\")\n\n    # Create figure and subplots\n    fig, axs = plt.subplots(2, 2, figsize=(15, 10))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axs[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axs[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(axs[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axs[1, 1], data)\n\n    # Adjust layout\n    plt.tight_layout()\n\n    # Export figure\n    export_figure(fig, config.medical_charts_file)", "CodeBleu_score": 26.377384340480937}]}
{"instance_id": "7061f4d0c3fc", "generation_result": [{"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    bottle_data = parse_raw_data(feeding_bottle_data, [\"Date\"])\n    solid_data = parse_raw_data(feeding_solid_data, [\"Date\"])\n\n    # Set up plot with dark grid style\n    sns.set(style=\"darkgrid\")\n    figure = plt.figure()\n    fig_ax = figure.add_subplot(111)\n\n    # Plot bottle feeding times in red\n    fig_ax.scatter(\n        bottle_data[\"day_number\"],\n        bottle_data[\"timestamp_hour\"],\n        s=100,\n        color=\"red\",\n        label=\"Bottle\",\n    )\n\n    # Plot solid feeding times in blue\n    fig_ax.scatter(\n        solid_data[\"day_number\"],\n        solid_data[\"timestamp_hour\"],\n        s=100,\n        color=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend to distinguish between bottle and solid feedings\n    fig_ax.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date(\n        bottle_data[\"day_number\"],\n        first_year_only=config[\"output_format\"][\"output_year_one_only\"],\n    )\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    if config[\"output_format\"][\"output_feeding_viz_orientation\"] == \"vertical\":\n        format_24h_week_plot_vertical(fig_ax, end_date)\n    else:\n        format_24h_week_plot_horizontal(fig_ax, end_date, \"Feeding\")\n\n    # Export figure\n    export_figure(figure, config[\"output_data\"][\"output_feeding_viz\"])\n\n", "CodeBleu_score": 36.14093508130542}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    data = parse_raw_data(feeding_bottle_data, [\"Time\"])\\\n        | parse_raw_data(feeding_solid_data, [\"Time\"])\n\n    # Set up a plot with a dark grid style\n    sns.set(style=\"darkgrid\")\n    figure = plt.figure()\n    fig_ax = figure.add_subplot(111)\n\n    # Compute the offset from the birthday based on the last solid feeding date\n    offset = (data[\"Time\"].iloc[-1] - data[\"Time\"].iloc[0]).days\n\n    # Create a scatter plot of feeding times, using red for bottle feedings and blue for solid feedings\n    fig_ax.scatter(\n        data[\"Time\"].dt.dayofyear - offset,\n        data[\"Time\"].dt.hour + data[\"Time\"].dt.minute / 60,\n        c=np.where(data[\"Type\"] == \"Bottle\", \"red\", \"blue\"),\n        label=\"Bottle\" if data[\"Type\"].iloc[0] == \"Bottle\" else \"Solid\",\n    )\n\n    # Add a legend to distinguish between the two\n    fig_ax.legend()\n\n    # Calculate the end date for the plot\n    end_date = get_end_date(\n        data[\"Time\"].dt.dayofyear - offset,\n        first_year_only=config[\"output_format\"][\"output_year_one_only\"],\n    )\n\n    # Format plot - vertical or horizontal\n    if config[\"output_format\"][\"output_feeding_viz_orientation\"] == \"vertical\":\n        format_24h_week_plot_vertical(fig_ax, end_date)\n    else:\n        format_24h_week_plot_horizontal(fig_ax, end_date, \"Feeding\")\n\n    # Export figure\n    export_figure(figure, config[\"output_data\"][\"output_feeding_viz\"])\n\n", "CodeBleu_score": 37.272225890041874}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    data = parse_raw_data(feeding_bottle_data, [\"Date\"])\n    data_solid = parse_raw_data(feeding_solid_data, [\"Date\"])\n\n    # Plot setup\n    sns.set(style=\"darkgrid\")\n    figure = plt.figure()\n    fig_ax = figure.add_subplot(111)\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = (\n        data_solid[\"day_number\"].iloc[-1] - data[\"day_number\"].iloc[-1]\n    ) / 365\n\n    # Create a scatter plot of feeding times\n    plt.scatter(\n        data[\"day_number\"],\n        data[\"timestamp_hour\"],\n        c=\"red\",\n        label=\"Bottle\",\n        marker=\".\",\n        s=100,\n    )\n    plt.scatter(\n        data_solid[\"day_number\"] + offset,\n        data_solid[\"timestamp_hour\"],\n        c=\"blue\",\n        label=\"Solid\",\n        marker=\".\",\n        s=100,\n    )\n\n    # Add legend\n    plt.legend(loc=\"upper left\")\n\n    # End date - one year or full\n    end_date = get_end_date(\n        data[\"day_number\"],\n        first_year_only=config[\"output_format\"][\"output_year_one_only\"],\n    )\n\n    # Format plot - vertical or horizontal\n    if config[\"output_format\"][\"output_feeding_viz_orientation\"] == \"vertical\":\n        format_24h_week_plot_vertical(fig_ax, end_date)\n    else:\n        format_24h_week_plot_horizontal(fig_ax, end_date, \"Feeding\")\n\n    # Export figure\n    export_figure(figure, config[\"output_data\"][\"output_feeding_viz\"])\n\n", "CodeBleu_score": 43.50571952930011}]}
{"instance_id": "6c1ffa63d122", "generation_result": [{"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task=task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'Target Counts ({task.name})')\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n    ax.tick_params(axis='x', rotation=45)\n\n", "CodeBleu_score": 43.450008409530554}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    counts, names = self._get_target_counts(task=task)\n\n    sns.barplot(x=names, y=counts, ax=ax, **kwargs)\n    ax.set_title(f'Target Counts: {task.name}')\n\n\n", "CodeBleu_score": 47.784777953801125}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    counts, names = self._get_target_counts(task=task)\n    sns.barplot(x=names, y=counts, ax=ax, **kwargs)\n    ax.set_title(task.name)\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n", "CodeBleu_score": 46.314172539078704}]}
{"instance_id": "2f81a906bad5", "generation_result": [{"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.backends.backend_agg as plt_backend_agg\n    except ModuleNotFoundError:\n        print('please install matplotlib')\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = plt_backend_agg.FigureCanvasAgg(fig)\n            canvas.draw()\n            data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n            w, h = canvas.get_width_height()\n            image_hwc = data.reshape([h, w, 4])[:, :, 0:3]\n            images.append(image_hwc)\n        return np.stack(images, axis=0)\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n        w, h = canvas.get_width_height()\n        image_hwc = data.reshape([h, w, 4])[:, :, 0:3]\n        if close:\n            plt.close(figure)\n        return image_hwc.transpose(2, 0, 1)", "CodeBleu_score": 51.68052133163998}, {"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.backends.backend_agg as plt_backend_agg\n    except ModuleNotFoundError:\n        print('please install matplotlib')\n    if not isinstance(figure, list):\n        figure = [figure]\n    images = []\n    for fig in figure:\n        canvas = plt_backend_agg.FigureCanvasAgg(fig)\n        canvas.draw()\n        width, height = fig.get_size_inches() * fig.get_dpi()\n        image = np.frombuffer(canvas.buffer_rgba(), dtype='uint8')\n        image = image.reshape(int(height), int(width), 4)\n        image = image[:, :, :3]\n        images.append(image)\n        plt.close(fig)\n    if len(images) == 1:\n        return images[0]\n    return np.stack(images, axis=0)\n\n", "CodeBleu_score": 34.84539799060398}, {"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    try:\n        import matplotlib.pyplot as plt\n        import matplotlib.backends.backend_agg as plt_backend_agg\n    except ModuleNotFoundError:\n        print('please install matplotlib')\n\n    def render_to_rgb_single(figure):\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n        w, h = figure.canvas.get_width_height()\n        image_hwc = data.reshape([h, w, 4])[:, :, 0:3]\n        image_chw = np.moveaxis(image_hwc, 2, 0)\n        if close:\n            plt.close(figure)\n        return image_chw\n\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb_single(f) for f in figure], axis=0)\n    else:\n        return render_to_rgb_single(figure)\n\n", "CodeBleu_score": 64.0565479808177}]}
{"instance_id": "c3037b01569c", "generation_result": [{"code": "def beholder_pytorch()\n\t\n    beholder = beholder_lib.Beholder(LOG_DIRECTORY)\n    for i in range(1000):\n        tensors = [tensor_and_name(np.random.randn(100, 100), 't1'), tensor_and_name(np.random.randn(100, 100), 't2')]\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't3'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't4'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't5'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't6'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't7'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't8'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't9'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't10'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't11'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't12'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't13'))\n        tensors.append(tensor_and_name(np.random.randn(100, 100), 't14'))\n        tensors.append(tensor_and_name(np.random.randn", "CodeBleu_score": 19.895018309016248}, {"code": "def beholder_pytorch()\n\t\n    for i in range(1000):\n        time.sleep(0.1)\n        print(i)\n        tensors = [tensor_and_name(np.random.random((10, 10)), 'random_image')]\n        beholder = beholder_lib.Beholder(logdir=LOG_DIRECTORY)\n        beholder.update(frame=np.random.random((10, 10)),\n                        frame_name='frame',\n                        tensors=tensors)\n", "CodeBleu_score": 32.07009324198917}, {"code": "def beholder_pytorch()\n\t\n    for i in range(1000):\n        random_tensors = [tensor_and_name(np.random.random((100, 100, 3)), 'random_tensor') for _ in range(10)]\n        random_tensors += [tensor_and_name(np.random.random((100, 100, 3)), 'random_tensor') for _ in range(10)]\n        beholder = beholder_lib.Beholder(LOG_DIRECTORY)\n        beholder.update(tensor_list=random_tensors, frame=np.random.random((100, 100, 3)))\n        time.sleep(0.5)\n        print('Iteration: {}'.format(i))\n", "CodeBleu_score": 38.4623520021327}]}
{"instance_id": "cd57b5de8a88", "generation_result": [{"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.data\n    tensor_data = tensor_data.reshape((-1, 1))\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n    (TP, FP, TN, FN, precision, recall) = (\n        tensor_data[:, 0],\n        tensor_data[:, 1],\n        tensor_data[:, 2],\n        tensor_data[:, 3],\n        tensor_data[:, 4],\n        tensor_data[:, 5],\n    )\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"TP\": TP.tolist(),\n        \"FP\": FP.tolist(),\n        \"TN\": TN.tolist(),\n        \"FN\": FN.tolist(),\n        \"precision\": precision.tolist(),\n        \"recall\": recall.tolist(),\n    }\n    self.log_asset_data(pr_data, tag, step=step)\n\n", "CodeBleu_score": 30.26267190954522}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.data\n    tensor_data = tensor_data.reshape(len(tensor_data), -1)\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n    (TP, FP, TN, FN, precision, recall) = tensor_data\n    pr_data = {}\n    pr_data['tag'] = tag\n    pr_data['thresholds'] = thresholds\n    pr_data['TP'] = TP.tolist()\n    pr_data['FP'] = FP.tolist()\n    pr_data['TN'] = TN.tolist()\n    pr_data['FN'] = FN.tolist()\n    pr_data['precision'] = precision.tolist()\n    pr_data['recall'] = recall.tolist()\n    pr_data['asset_type'] = 'pr_curve'\n    self.log_asset_data(pr_data, tag, step=step)\n", "CodeBleu_score": 22.349714420575637}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.data\n    tensor_data = tensor_data.reshape(tensor_data.shape[1], tensor_data.shape[2])\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n    tp = tensor_data[0].flatten().tolist()\n    fp = tensor_data[1].flatten().tolist()\n    tn = tensor_data[2].flatten().tolist()\n    fn = tensor_data[3].flatten().tolist()\n    precision = tensor_data[4].flatten().tolist()\n    recall = tensor_data[5].flatten().tolist()\n    pr_data = {'tag': tag, 'thresholds': thresholds, 'tp': tp, 'fp': fp, 'tn': tn, 'fn': fn, 'precision': precision, 'recall': recall}\n    self.log_asset_data(pr_data, tag, step=step)\n", "CodeBleu_score": 32.08152543712705}]}
{"instance_id": "7c4ea9beecc9", "generation_result": [{"code": "def load_mnist(images, labels, num)\n\t\n    data = np.empty((num, dim), dtype=np.uint8)\n    target = np.empty((num,), dtype=np.int8)\n\n    with gzip.open(images, 'rb') as imgpath:\n        imgpath.read(16)\n        for i in six.moves.range(num):\n            tmp_img = np.frombuffer(imgpath.read(dim), dtype=np.uint8, offset=0)\n            data[i] = tmp_img\n\n    with gzip.open(labels, 'rb') as lbpath:\n        lbpath.read(8)\n        for i in six.moves.range(num):\n            tmp_label = np.frombuffer(lbpath.read(1), dtype=np.uint8, offset=0)\n            target[i] = tmp_label\n\n    return data, target\n\n", "CodeBleu_score": 45.30244673750114}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = np.empty((num, dim), dtype=np.uint8)\n    target = np.empty((num,), dtype=np.uint8)\n    with gzip.open(images, 'rb') as imgpath:\n        imgpath.read(16)\n        for i in range(num):\n            data[i] = np.frombuffer(imgpath.read(dim), dtype=np.uint8, offset=0).reshape(dim)\n    with gzip.open(labels, 'rb') as lbpath:\n        lbpath.read(8)\n        for i in range(num):\n            target[i] = np.frombuffer(lbpath.read(1), dtype=np.uint8, offset=0)\n    return (data, target)\n\n\n", "CodeBleu_score": 41.74631608627985}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = np.empty((num, dim), dtype=np.uint8)\n    target = np.empty((num,), dtype=np.int8)\n    with gzip.open(images, 'rb') as imgpath:\n        imgpath.read(16)\n        for i in six.moves.range(num):\n            tmp_img = np.frombuffer(imgpath.read(dim), dtype=np.uint8, offset=0)\n            data[i] = tmp_img\n    with gzip.open(labels, 'rb') as lbpath:\n        lbpath.read(8)\n        for i in six.moves.range(num):\n            tmp_label = np.frombuffer(lbpath.read(1), dtype=np.uint8, offset=0)\n            target[i] = tmp_label\n    return (data, target)\n\n", "CodeBleu_score": 45.124729964716195}]}
{"instance_id": "bf4f1c828b25", "generation_result": [{"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    # Initialize the dictionary of unique values and cardinality\n    ldf._unique_values = {}\n    ldf._cardinality = {}\n    ldf._min_max = {}\n    ldf._nunique = len(ldf)\n    # Compute the unique values and cardinality for each attribute\n    for attr in list(ldf.columns):\n        if attr in ldf._type_override:\n            ldf._unique_values[attr] = list(ldf[attr].unique())\n            ldf._cardinality[attr] = len(ldf._unique_values[attr])\n        else:\n            ldf._unique_values[attr] = list(ldf[attr].unique())\n            ldf._cardinality[attr] = len(ldf._unique_values[attr])\n            if pd.api.types.is_numeric_dtype(ldf.dtypes[attr]):\n                ldf._min_max[attr] = (ldf[attr].min(), ldf[attr].max())\n    # Compute the unique values and cardinality for the index if it is not of integer type\n    if not pd.api.types.is_integer_dtype(ldf.index):\n        ldf._unique_values[ldf.index.name] = list(ldf.index.unique())\n        ldf._cardinality[ldf.index.name] = len(ldf._unique_values[ldf.index.name])\n\n", "CodeBleu_score": 43.088420591013715}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    ldf.unique_values = dict()\n    ldf.cardinality = dict()\n    ldf.min_max = dict()\n    ldf.len = len(ldf)\n    for attr in list(ldf.columns):\n        ldf.unique_values[attr] = list(ldf[attr].unique())\n        ldf.cardinality[attr] = len(ldf.unique_values[attr])\n        if pd.api.types.is_numeric_dtype(ldf.dtypes[attr]):\n            ldf.min_max[attr] = (ldf[attr].min(), ldf[attr].max())\n    if not pd.api.types.is_integer_dtype(ldf.index):\n        ldf.unique_values[ldf.index.name] = list(ldf.index.unique())\n        ldf.cardinality[ldf.index.name] = len(ldf.unique_values[ldf.index.name])\n        if pd.api.types.is_numeric_dtype(ldf.index):\n            ldf.min_max[ldf.index.name] = (ldf.index.min(), ldf.index.max())\n\n", "CodeBleu_score": 36.13213603485329}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max = {}\n    self.cardinality = {}\n    self.len = len(ldf)\n    for attr in list(ldf.columns):\n        self.unique_values[attr] = list(ldf.unique_values(attr))\n        self.cardinality[attr] = len(self.unique_values[attr])\n        if ldf.data_type[attr] == \"quantitative\":\n            self.min_max[attr] = (ldf.min_max(attr)[0], ldf.min_max(attr)[1])\n\n    if not pd.api.types.is_integer_dtype(ldf.index):\n        self.unique_values[ldf.index.name] = list(ldf.unique_values(ldf.index.name))\n        self.cardinality[ldf.index.name] = len(self.unique_values[ldf.index.name])\n\n", "CodeBleu_score": 30.09527115212192}]}
{"instance_id": "3e6fc3d2f47c", "generation_result": [{"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    query = tbl.preview_query(preview_size)\n    df = pd.read_sql(query, lux.config.SQLConnection)\n    return df\n\n", "CodeBleu_score": 16.433989602731206}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    query = f\"SELECT * FROM {tbl.table_name} LIMIT {preview_size}\"\n    return pd.read_sql(query, lux.config.SQLConnection)\n\n", "CodeBleu_score": 19.12670068937418}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    # TODO: add a check for the type of the input table\n    query = \"SELECT * FROM {} LIMIT {}\"\n    query = query.format(tbl.tableName, preview_size)\n    df = tbl._conn.execute_and_fetchall(query)\n    return df\n\n", "CodeBleu_score": 19.204370343940873}]}
{"instance_id": "b3dee87be4b8", "generation_result": [{"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if not tbl.sampled:\n        sampling_config = lux.config.sampling\n        sample_flag = sampling_config.sample_flag\n        sample_start = sampling_config.sample_start\n        sample_cap = sampling_config.sample_cap\n        sample_frac = sampling_config.sample_frac\n        if sample_flag:\n            if sample_start:\n                tbl._sampled = SQLExecutor.execute_sampling_start(tbl, sample_start)\n            elif sample_cap:\n                tbl._sampled = SQLExecutor.execute_sampling_cap(tbl, sample_cap)\n            elif sample_frac:\n                tbl._sampled = SQLExecutor.execute_sampling_frac(tbl, sample_frac)\n        else:\n            tbl._sampled = SQLExecutor.execute_sampling_none(tbl)\n\n", "CodeBleu_score": 26.332131136491586}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if lux.config.SAMPLE_FLAG:\n        if lux.config.SAMPLE_START is not None:\n            start = lux.config.SAMPLE_START\n        else:\n            start = 0\n        if lux.config.SAMPLE_CAP is not None:\n            cap = lux.config.SAMPLE_CAP\n        else:\n            cap = tbl.length()\n        if lux.config.SAMPLE_FRAC is not None:\n            limit = min(tbl.length(), math.ceil(tbl.length() * lux.config.SAMPLE_FRAC))\n        else:\n            limit = min(tbl.length(), 50)\n        query = lux.config.query_templates[\"sample_query\"].format(\n            table_name=tbl.table_name, limit=limit, offset=start\n        )\n        sampled = pandas.read_sql(query, lux.config.SQLconnection)\n        tbl._sampled = sampled\n\n", "CodeBleu_score": 39.79701972806045}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    sample_flag = lux.config.sampling.SAMPLE_FLAG\n    sample_start = lux.config.sampling.SAMPLE_START\n    sample_cap = lux.config.sampling.SAMPLE_CAP\n    sample_frac = lux.config.sampling.SAMPLE_FRAC\n    if sample_flag:\n        if sample_start == \"\":\n            sample_start = 0\n        if sample_cap == \"\":\n            sample_cap = \"10000\"\n        if sample_frac == \"\":\n            sample_frac = 0.1\n        query = lux.config.query_templates[\"sample_query\"]\n        query = query.format(table_name=tbl.table_name, limit=sample_cap)\n        length = pandas.read_sql(query, lux.config.SQLconnection).iloc[0][0]\n        limit = math.floor(sample_frac * length)\n        query = lux.config.query_templates[\"sample_query\"].format(\n            table_name=tbl.table_name, limit=limit\n        )\n        tbl._sampled = pandas.read_sql(query, lux.config.SQLconnection)\n\n", "CodeBleu_score": 41.55408171652416}]}
{"instance_id": "485253b1088a", "generation_result": [{"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    # Override default text settings\n    text_params = {\n        \"fontsize\": 12,\n        \"fontname\": \"DejaVu Sans\",\n        \"fontweight\": \"bold\",\n        \"color\": \"black\",\n        \"ha\": \"center\",\n        \"va\": \"center\",\n    }\n    text_params = override_params(text_params, params)\n\n    # Extract text, x, and y values\n    text = text_params.pop(\"text\")\n    x = text_params.pop(\"x\")\n    y = text_params.pop(\"y\")\n\n    # Get bounds\n    xmin, ymin, xmax, ymax = background.bounds\n\n    # Interpolate x and y values\n    x = np.interp(x, [0, 1], [xmin, xmax])\n    y = np.interp(y, [0, 1], [ymin, ymax])\n\n    # Draw text\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 28.203207074702043}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    # Override default text settings\n    text_params = {\n        \"fontsize\": 12,\n        \"fontweight\": \"bold\",\n        \"fontfamily\": \"sans-serif\",\n        \"color\": \"black\",\n        \"ha\": \"center\",\n        \"va\": \"center\",\n    }\n    text_params = override_params(text_params, params)\n\n    # Extract text, x, and y values\n    text = text_params.pop(\"text\")\n    x = text_params.pop(\"x\")\n    y = text_params.pop(\"y\")\n\n    # Get bounds\n    xmin, ymin, xmax, ymax = background.bounds\n\n    # Interpolate x and y values to fit within bounds\n    x = np.interp(x, [0, 1], [xmin, xmax])\n    y = np.interp(y, [0, 1], [ymin, ymax])\n\n    # Draw text\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 28.371665324807005}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    # Override default text settings\n    text_params = {\n        \"text\": \"\",\n        \"x\": 0.5,\n        \"y\": 0.5,\n        \"fontsize\": 12,\n        \"ha\": \"center\",\n        \"va\": \"center\",\n        \"color\": \"black\",\n        \"bbox\": {\n            \"boxstyle\": \"round\",\n            \"facecolor\": \"white\",\n            \"edgecolor\": \"black\",\n            \"linewidth\": 0.5,\n            \"alpha\": 0.8,\n        },\n    }\n    text_params.update(params)\n    text, x, y = text_params.pop(\"text\"), text_params.pop(\"x\"), text_params.pop(\"y\")\n\n    # Get background bounds\n    xmin, ymin, xmax, ymax = background.bounds\n\n    # Interpolate x and y to fit within background bounds\n    x = xmin + (xmax - xmin) * x\n    y = ymin + (ymax - ymin) * y\n\n    # Draw text\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 28.04041964787541}]}
{"instance_id": "5f70a88b6b72", "generation_result": [{"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    days = np.diff(mdates.date2num(dates))\n    if np.max(days) < 0.33:\n        if mdates.num2date(dates[0]).date() != mdates.num2date(dates[-1]).date():\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        if mdates.num2date(dates[0]).year != mdates.num2date(dates[-1]).year:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n\n", "CodeBleu_score": 45.25467167296831}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    if len(dates) < 2:\n        return \"%Y-%b-%d\"\n    # Calculate the average number of days between consecutive points\n    avg_days = (dates[-1] - dates[0]).total_seconds() / (len(dates) - 1) / 86400\n    if avg_days < 0.33:\n        # Intraday data\n        if (dates[-1] - dates[0]).days > 0:\n            return \"%b %d, %H:%M\"\n        else:\n            return \"%H:%M\"\n    else:\n        # Daily or less frequent data\n        if (dates[-1] - dates[0]).days > 365:\n            return \"%Y-%b-%d\"\n        else:\n            return \"%b %d\"\n\n", "CodeBleu_score": 40.28440308174793}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n\n    if datetime_format is not None:\n        return datetime_format\n\n    # Calculate the average number of days between consecutive dates\n    delta_days = np.diff(mdates.date2num(dates)) / (24 * 60 * 60)\n    avg_delta_days = np.mean(delta_days)\n\n    if avg_delta_days < 0.33:\n        # Intraday data\n        if len(dates) > 1 and dates[0].date() != dates[-1].date():\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        # Daily or less frequent data\n        if len(dates) > 1 and dates[0].year != dates[-1].year:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n\n\n", "CodeBleu_score": 44.29964777979101}]}
{"instance_id": "f9589bf4666d", "generation_result": [{"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 3:\n            c = c + (1.0,)\n        c = np.array(c) / 255.0\n        c = tuple(c)\n    if alpha is not None:\n        c = mcolors.to_rgba(c, alpha)\n    else:\n        c = mcolors.to_rgba(c)\n    return c\n\n", "CodeBleu_score": 32.7218798016386}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 3:\n            r, g, b = c\n            a = 1.0\n        elif len(c) == 4:\n            r, g, b, a = c\n        else:\n            raise ValueError(\"_mpf_to_rgba() does not understand inputs of length {}\".format(len(c)))\n        if r > 1 or g > 1 or b > 1:\n            r, g, b = r / 255.0, g / 255.0, b / 255.0\n        return mcolors.to_rgba((r, g, b, a), alpha)\n    else:\n        return mcolors.to_rgba(c, alpha)\n\n", "CodeBleu_score": 23.941538132226732}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 3:\n            c = [v / 255.0 for v in c]\n            if alpha is not None:\n                c.append(alpha)\n            return tuple(c)\n        elif len(c) == 4:\n            c = [v / 255.0 for v in c]\n            if alpha is not None:\n                c[-1] = alpha\n            return tuple(c)\n    return mcolors.to_rgba(c, alpha)\n\n", "CodeBleu_score": 21.908288025515947}]}
{"instance_id": "4202e378ab0b", "generation_result": [{"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    subplots = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(subplots,mpl_axes.Axes):\n        subplots.mpfstyle = style\n\n    elif isinstance(subplots,np.ndarray):\n        for ax in subplots.flatten():\n            ax.mpfstyle = style\n\n    else:\n        raise TypeError('Unexpected type for subplots')\n\n    return subplots", "CodeBleu_score": 63.657533169089334}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axes = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axes,mpl_axes.Axes):\n        axes.mpfstyle = style\n    elif isinstance(axes,np.ndarray):\n        for ax in axes:\n            ax.mpfstyle = style\n    else:\n        raise TypeError('Unexpected type for axes')\n\n    return axes", "CodeBleu_score": 60.84123231432329}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    result = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(result,mpl_axes.Axes):\n        result.mpfstyle = style\n\n    elif isinstance(result,np.ndarray):\n        for ax in result.flatten():\n            ax.mpfstyle = style\n\n    else:\n        raise TypeError('Unexpected type of result from matplotlib.figure.Figure.subplots()')\n\n    return result\n\n", "CodeBleu_score": 65.27608197933088}]}
{"instance_id": "3e2b6dfe4753", "generation_result": [{"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None: return\n    if 'figsize' not in config:\n        figratio = config['figratio']\n        if isinstance(figratio,tuple):\n            figratio = figratio[0]/figratio[1]\n        if figratio < 0.5:\n            figratio = 1.0/figratio\n        if figratio > 2.0:\n            figratio = 2.0/figratio\n        w,h = fig.get_size_inches()\n        if w/h > figratio:\n            w = h*figratio\n        else:\n            h = w/figratio\n        fig.set_size_inches(w,h)\n    else:\n        fig.set_size_inches(config['figsize'])\n\n", "CodeBleu_score": 36.54504064533169}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None: return\n    if 'figsize' in config:\n        figsize = config['figsize']\n    else:\n        figratio = config['figratio']\n        figratio = (figratio[0]/figratio[1])**0.5\n        figsize = (figratio,1)\n        if figratio < 0.5 or figratio > 2:\n            figsize = (1,1/figratio)\n    fig.set_size_inches(figsize)\n\n", "CodeBleu_score": 32.541313688760425}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n\n    if config['figsize'] is None:\n        #print('_adjust_figsize: figsize is None')\n        fig_ratio = config['figratio']\n        if fig_ratio is None:\n            fig_ratio = (5,3)\n        fig_ratio = fig_ratio[0]/fig_ratio[1]\n        #print('_adjust_figsize: fig_ratio=',fig_ratio)\n        if config['figscale'] < 1:\n            scale = config['figscale']\n        else:\n            scale = 1\n        #print('_adjust_figsize: scale=',scale)\n        fig_width_inch, fig_height_inch = fig.get_size_inches()\n        #print('_adjust_figsize: fig_width_inch=',fig_width_inch)\n        #print('_adjust_figsize: fig_height_inch=',fig_height_inch)\n        if fig_width_inch / fig_height_inch < fig_ratio:\n            fig_width_inch  = fig_height_inch * fig_ratio\n        else:\n            fig_height_inch = fig_width_inch / fig_ratio\n        fig_width_inch  *= scale\n        fig_height_inch *= scale\n        #print('_adjust_figsize: fig_width_inch=',fig_width_inch)\n        #print('_adjust_figsize: fig_height_inch=',fig_height_inch)\n        fig.set_size_inches(fig_width_inch, fig_height_inch)\n    else:\n        fig.set_size_inches(config['figsize'])\n\n", "CodeBleu_score": 38.05580008738292}]}
{"instance_id": "986e5804b941", "generation_result": [{"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t\n    if isinstance(apmav,dict):\n        shift_dict = apmav['shift']\n        periods_dict = apmav['periods']\n        mav_list = []\n        for key in shift_dict:\n            shift = shift_dict[key]\n            periods = periods_dict[key]\n            if periods > 0 and periods < len(prices):\n                mav = prices.rolling(periods).mean()\n                if shift > 0:\n                    mav = mav.shift(shift)\n                mav_list.append(mav)\n        if len(mav_list) > 7:\n            mav_list = mav_list[:7]\n        for mav in mav_list:\n            ax.plot(xdates,mav,linewidth=apwidth,color=next(config['_color_cycle']))\n        return mav_list\n    else:\n        mav_list = []\n        for periods in apmav:\n            if periods > 0 and periods < len(prices):\n                mav = prices.rolling(periods).mean()\n                mav_list.append(mav)\n        if len(mav_list) > 7:\n            mav_list = mav_list[:7]\n        for mav in mav_list:\n            ax.plot(xdates,mav,linewidth=apwidth,color=next(config['_color_cycle']))\n        return mav_list\n", "CodeBleu_score": 37.0372736873149}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t['shift']\n        periods = apmav['periods']\n    else:\n        shift = None\n        periods = apmav\n    if isinstance(periods,dict):\n        shift = periods['shift']\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n    if isinstance(periods,dict):\n        periods = periods['periods']\n   ", "CodeBleu_score": 17.22945516019873}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t = apmav['period']\n    else:\n        shift_list = [0,]\n        period_list = apmav\n    if len(shift_list) > 7:\n        print('WARNING: 7 or less moving averages are supported.')\n        print('         The first 7 will be plotted.')\n        shift_list = shift_list[0:7]\n        period_list = period_list[0:7]\n    apmavprices = []\n    for (shift,period) in zip(shift_list,period_list):\n        if period > 1:\n            y_mav = prices.rolling(window=period,center=False).mean()\n            y_mav = y_mav.shift(shift)\n            apmavprices.append(y_mav)\n            if apwidth is None:\n                apwidth = config['_width_config']['mav_width']\n            ax.plot(xdates,y_mav,color=config['_color_cycle'].next(),linewidth=apwidth)\n    return apmavprices\n", "CodeBleu_score": 30.150870199091052}]}
{"instance_id": "5308e20f3c90", "generation_result": [{"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kh, kw = inputs[0].shape[2:4]\n    ic = inputs[0].shape[1]\n    oh, ow = outputs[0].shape[2:4]\n    f = np.prod([oh, ow])\n    if len(inputs) == 3:\n        f += np.prod(outputs[0].shape)\n    return f * ic * kh * kw\n\n", "CodeBleu_score": 24.085385778046508}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    assert len(inputs[0].shape) == 4\n    assert len(outputs[0].shape) == 4\n    kh, kw = opnode.params[\"kernel_h\"], opnode.params[\"kernel_w\"]\n    nr_ic = inputs[0].shape[1]\n    oh, ow = outputs[0].shape[2], outputs[0].shape[3]\n    flops = np.prod([oh, ow]) * nr_ic * kh * kw\n    if len(inputs) == 3:\n        flops += np.prod([oh, ow])\n    return flops\n\n", "CodeBleu_score": 35.47023536435559}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    assert len(inputs[0].shape) == 4\n    kh, kw = opnode.params[\"kernel_h\"], opnode.params[\"kernel_w\"]\n    ic = inputs[0].shape[1]\n    ops = np.prod(outputs[0].shape)\n    ops *= ic * kh * kw\n    if len(inputs) == 3:\n        ops += np.prod(outputs[0].shape)\n    return ops\n\n", "CodeBleu_score": 33.42058775953721}]}
{"instance_id": "70811d3cf578", "generation_result": [{"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype]()\n\n", "CodeBleu_score": 20.149569944707952}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype]()\n\n", "CodeBleu_score": 20.149569944707952}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype]()\n\n", "CodeBleu_score": 20.149569944707952}]}
{"instance_id": "a108c9ba2c22", "generation_result": [{"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = canonicalize_dtype(x)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.uint8)\n    elif x.dtype == dtype.bfloat16:\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    elements = ir.DenseElementsAttr.get(np.reshape(x, (x.size,)), type=ir_type)\n    return [ir.ConstantOp(elements, ir_type).result]\n\n", "CodeBleu_score": 46.05517234608402}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype), copy=False)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if ir_type.is_bool():\n        x = x.astype(np.uint8, copy=False)\n    if ir_type.is_bf16():\n        x = x.astype(np.uint16, copy=False)\n    x = np.ascontiguousarray(x)\n    elements = DenseElementsAttr.get(x.ravel(), ir_type)\n    return ConstantOp.create(elements).results\n\n", "CodeBleu_score": 37.82321140997341}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype))\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.uint8)\n    elif x.dtype == np.bfloat16:\n        x = x.astype(np.float16)\n    x = np.ascontiguousarray(x)\n    elements = ir.DenseElementsAttr.get(x, ir_type)\n    return [ir.ConstantOp(elements, ir_type)]\n\n", "CodeBleu_score": 41.635191561981195}]}
{"instance_id": "3345fe4d008b", "generation_result": [{"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if not val.size:\n        return ()\n    if val.strides:\n        zero_stride_axes = [i for i, stride in enumerate(val.strides) if stride == 0]\n        non_zero_stride_axes = [\n            i for i, stride in enumerate(val.strides) if stride != 0\n        ]\n        val = val.transpose(non_zero_stride_axes)\n        val = np.broadcast_to(val, val.shape[: len(non_zero_stride_axes)] + val.shape[1:])\n        val = val.transpose(\n            [\n                non_zero_stride_axes.index(i)\n                for i in range(len(non_zero_stride_axes))\n            ]\n        )\n        broadcast_shape = val.shape[: len(zero_stride_axes)] + val.shape[\n            len(zero_stride_axes) :\n        ]\n        broadcast_op = hlo.BroadcastInDimOp(\n            hlo.ConstantOp(ir.DenseElementsAttr.get(val, type=val.dtype)).result,\n            broadcast_shape,\n            broadcast_dimensions=[i for i in range(len(zero_stride_axes))],\n        ).result\n        return (broadcast_op,)\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 42.23231337682483}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if np.any(val.strides == 0) and val.size > 0:\n        zero_stride_axes = np.where(val.strides == 0)[0]\n        non_zero_stride_axes = np.where(val.strides != 0)[0]\n        val = np.broadcast_to(val, val.shape[non_zero_stride_axes])\n        if canonicalize_types:\n            val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n        element_type = mge_dtype_to_ir_type(val.dtype)\n        shape = val.shape\n        if val.dtype == np.bool_:\n            nelems = val.size\n            val = np.packbits(val, bitorder=\"little\")\n            if nelems == 1:\n                val = np.array(0 if val.item() == 0 else 0xFF, np.uint8)\n        elif val.dtype == dtype.bfloat16:\n            val = val.view(np.uint16)\n        val = np.ascontiguousarray(val)\n        attr = ir.DenseElementsAttr.get(val, type=element_type, shape=shape)\n        broadcast_op = hlo.BroadcastInDimOp(\n            ir.ArrayAttr.get(list(zero_stride_axes)),\n            hlo.ConstantOp(attr).result,\n            dimensions=list(non_zero_stride_axes),\n        )\n        return (broadcast_op.outputs[0],)\n    return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 48.21636912480747}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.strides != (0,) * val.ndim and val.size > 0:\n        zero_stride_axes = [\n            axis for axis in range(val.ndim) if val.strides[axis] == 0\n        ]\n        collapsed_axes = [\n            axis for axis in range(val.ndim) if val.strides[axis] != 0\n        ]\n        collapsed_shape = tuple(val.shape[axis] for axis in collapsed_axes)\n        collapsed_val = val[tuple(slice(None) if axis in collapsed_axes else 0 for axis in range(val.ndim))]\n        if canonicalize_types:\n            collapsed_val = np.asarray(\n                collapsed_val, dtype.canonicalize_dtype(collapsed_val.dtype)\n            )\n        collapsed_val = np.broadcast_to(collapsed_val, collapsed_shape)\n        broadcast_op = hlo.BroadcastInDimOp(\n            _numpy_array_constant(collapsed_val, canonicalize_types)[0],\n            np.array(zero_stride_axes, np.int64),\n            np.array(val.shape, np.int64),\n        )\n        return broadcast_op.results\n    return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 51.44575925755812}]}
{"instance_id": "91b298678351", "generation_result": [{"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    xs = np.packbits(xs, bitorder=\"little\")\n    if len(xs) == 1:\n        xs = np.array(0 if xs.item() == 0 else 0xFF, np.uint8)\n    return ir.DenseElementsAttr.get(xs, type=ir.IntegerType.get_signless(1))\n\n", "CodeBleu_score": 56.274002858418356}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    if len(xs) == 1:\n        xs = np.array(0 if xs[0] else 0xFF, np.uint8)\n    else:\n        xs = np.packbits(xs, bitorder=\"little\")\n    return ir.DenseElementsAttr.get(xs, type=ir.IntegerType.get_signless(1))\n\n", "CodeBleu_score": 50.764347195331915}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    xs = np.array(xs, np.uint8)\n    if xs.size == 1:\n        xs = np.array(0 if xs.item() == 0 else 0xFF, np.uint8)\n    else:\n        xs = np.packbits(xs, bitorder=\"little\")\n    return ir.DenseElementsAttr.get(xs, type=ir.IntegerType.get_signless(1))\n\n", "CodeBleu_score": 57.14047677364049}]}
{"instance_id": "06ebabf1e0ff", "generation_result": [{"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1, f\"{len(args)}\"\n    assert len(ctx.vars_in) == 1, f\"{len(ctx.vars_in)}\"\n    assert len(ctx.vars_out) == 1, f\"{len(ctx.vars_out)}\"\n    inp = ctx.vars_in[0]\n    out = ctx.vars_out[0]\n    if inp.has_bound_data():\n        ctx.module_context.set_value(inp, inp.bound_data)\n        ctx.module_context.set_value(out, inp.bound_data)\n    assert _check_shape(inp.shape, out.shape), f\"{inp.shape} != {out.shape}\"\n    if out.has_bound_data():\n        data = np.array(out.bound_data, dtype=out.dtype)\n    elif inp.has_bound_data():\n        data = np.array(inp.bound_data, dtype=inp.dtype)\n    else:\n        assert False, \\\"Only tensor creation from constants is supported.\\\"\n    return HLOTensor(data, dtype=out.dtype, shape=out.shape)\n\n", "CodeBleu_score": 53.240615882241556}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1, f\"{len(args)}\"\n    assert len(ctx.vars_in) == 1, f\"{len(ctx.vars_in)}\"\n    assert len(ctx.vars_out) == 1, f\"{len(ctx.vars_out)}\"\n\n    inp = ctx.vars_in[0]\n    out = ctx.vars_out[0]\n\n    if inp.bound_data is not None:\n        ctx.module_context.set_value(inp, inp.bound_data.numpy())\n        ctx.module_context.set_value(out, inp.bound_data.numpy())\n    else:\n        assert out.bound_data is not None, \"Only tensor creation from constants is supported\"\n        ctx.module_context.set_value(out, out.bound_data.numpy())\n\n    assert _check_shape(inp.shape, out.shape), f\"{inp.shape}, {out.shape}\"\n    data = out.bound_data.numpy().astype(out.dtype)\n    return HLOTensor(data)\n\n", "CodeBleu_score": 48.11420273707772}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1 and len(ctx.vars_in) == 1 and len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n\n    if input_var.bound_data is not None:\n        ctx.module_context.set_value(input_var, input_var.bound_data)\n        ctx.module_context.set_value(output_var, input_var.bound_data)\n    else:\n        assert output_var.bound_data is not None, \"Only tensor creation from constants is supported\"\n        ctx.module_context.set_value(output_var, np.array(output_var.bound_data, dtype=output_var.dtype))\n\n    _check_shape(output_var.shape, input_var.shape)\n\n    return HLOTensor(output_var.bound_data)\n\n", "CodeBleu_score": 44.921808876577416}]}
{"instance_id": "6cd750fa0c8d", "generation_result": [{"code": "def _device_put_scalar(x, device)\n\t\n    dtype = _scalar_type_to_dtype(x)\n    return _device_put_nparray(np.array(x, dtype=dtype), device)\n\n", "CodeBleu_score": 13.408079612488773}, {"code": "def _device_put_scalar(x, device)\n\t\n    backend = xb.get_device_backend(device)\n    if not np.issubdtype(type(x), _np_types):\n        x = np.array(x, dtype=_scalar_type_to_dtype(type(x)))\n    return (backend.buffer_from_pyval(x, device),)\n\n", "CodeBleu_score": 38.62865256326206}, {"code": "def _device_put_scalar(x, device)\n\t\n    backend = xb.get_device_backend(device)\n    return (backend.buffer_from_pyval(np.array(x), device),)\n\n", "CodeBleu_score": 10.24194167332632}]}
{"instance_id": "140de7c2b6a8", "generation_result": [{"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list)\n        ), f\"lhs_shape must be tuple or list, but got {type(lhs_shape)}\"\n    assert isinstance(rhs_shape, (tuple, list)\n        ), f\"rhs_shape must be tuple or list, but got {type(rhs_shape)}\"\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int), f\"lhs_shape[0] must be int, but got {type(lhs_shape[0])}\"\n    if len(rhs_shape) > 0:\n        assert isinstance(rhs_shape[0], int), f\"rhs_shape[0] must be int, but got {type(rhs_shape[0])}\"\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for i in range(len(lhs_shape)):\n        if lhs_shape[i] != rhs_shape[i]:\n            return False\n    return True\n\n", "CodeBleu_score": 51.15096597748031}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0 and len(rhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int)\n        assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 50.47587083633051}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list)), \"lhs_shape must be tuple or list\"\n    assert isinstance(rhs_shape, (tuple, list)), \"rhs_shape must be tuple or list\"\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int), \"lhs_shape must be integer\"\n    if len(rhs_shape) > 0:\n        assert isinstance(rhs_shape[0], int), \"rhs_shape must be integer\"\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for i in range(len(lhs_shape)):\n        if lhs_shape[i] != rhs_shape[i]:\n            return False\n    return True\n\n", "CodeBleu_score": 50.42876933635626}]}
{"instance_id": "55d0c71a259b", "generation_result": [{"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    test_meta_target = test_meta.pop(\"target\")\n    return (train, test, train_meta, test_meta)\n\n", "CodeBleu_score": 34.44941614379584}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    del meta_dtypes[\"target\"]\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 36.012143078046186}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    train = pd.read_csv(training_set_filename, dtype=dtypes)\n    test = pd.read_csv(test_set_filename, dtype=dtypes)\n    train_meta = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes[\"target\"] = \"int32\"\n    test_meta = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    del meta_dtypes[\"target\"]\n    return train, test, train_meta, test_meta\n\n", "CodeBleu_score": 39.029481031953864}]}
{"instance_id": "9e5e02cd73e0", "generation_result": [{"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcmod\n    with rcmod.axes_style(\"white\"):\n        fig, ax = plt.subplots(1, 1, figsize=(6, 1))\n        ax.set_axis_off()\n        x, y = np.meshgrid(np.linspace(0, 1, 256), [0, 1])\n        ax.pcolormesh(x, y, cmap(np.linspace(0, 1, 256).reshape(-1, 1)))\n        plt.show()\n\n", "CodeBleu_score": 42.998330967532155}, {"code": "def _show_cmap(cmap)\n\t\n    from matplotlib.style import axes_style\n    fig, ax = plt.subplots(figsize=(6, 1))\n    ax.set_axis_off()\n    x, y = np.meshgrid(np.linspace(0, 1, 256), np.linspace(0, 1, 6))\n    ax.pcolormesh(x, y, np.linspace(0, 1, 256).reshape(1, -1), cmap=cmap)\n\n", "CodeBleu_score": 45.07308355771934}, {"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcmod\n    with rcmod.axes_style(\"white\"):\n        fig, ax = plt.subplots(1, 1, figsize=(6, 1), dpi=200)\n        ax.set_axis_off()\n        x, y = np.meshgrid(np.linspace(0, 1, 256), [0, 1])\n        ax.pcolormesh(x, y, cmap(np.linspace(0, 1, 256).reshape(-1, 1)))\n        plt.show()\n\n", "CodeBleu_score": 42.56799798134316}]}
{"instance_id": "ad0781b5cc38", "generation_result": [{"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return xdata, ydata\n\n    if obj.get_transform() != obj.axes.transData:\n        points = np.hstack((xdata[:, np.newaxis], ydata[:, np.newaxis]))\n        transform = obj.get_transform() + obj.axes.transData.inverted()\n        points = transform.transform(points)\n        return points[:, 0], points[:, 1]\n\n    return xdata, ydata\n\n", "CodeBleu_score": 58.8667012622321}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return (xdata, ydata)\n\n    if obj.get_transform() != obj.axes.transData:\n        transform = obj.get_transform() + obj.axes.transData.inverted()\n        points = transform.transform(np.column_stack((xdata, ydata)))\n        return points[:, 0], points[:, 1]\n\n    return (xdata, ydata)\n\n", "CodeBleu_score": 52.712241782696665}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is not None and obj.get_transform() != obj.axes.transData:\n        trans = obj.get_transform() + obj.axes.transData.inverted()\n        return trans.transform(np.column_stack([xdata, ydata]))\n    else:\n        return np.column_stack([xdata, ydata])\n\n", "CodeBleu_score": 51.92935782126773}]}
{"instance_id": "bf776cadef8d", "generation_result": [{"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key=\"data\")\n    if data2 is not None and not pd.api.types.is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)\n\n", "CodeBleu_score": 63.34867826527475}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n    if data2 is not None and not pd.api.types.is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)\n\n", "CodeBleu_score": 67.69055557411838}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n    if data2 is not None and not pd.api.types.is_list_like(data2):\n        data2 = self._df[data2]\n    return self._module.kdeplot(data, data2, *args, **kwargs)\n\n", "CodeBleu_score": 67.69055557411838}]}
{"instance_id": "fb44964174d9", "generation_result": [{"code": "def plot_most_used_words(df)\n\t\n    # Small fix for programa and programar.\n    df.loc[df['lemma_lower'] == \"programa\", \"lemma_lower\"] = \"programar\"\n\n    words = df[df[\"is_alphabet\"] == True]\n    words = words[words[\"text_lower\"].str.len() > 1]\n    words = words[~words[\"is_stopword\"]]\n    words = words.groupby(\\\"lemma_lower\\\").size().reset_index(name=\\\"count\\\")\n    words = words.sort_values(\\\"count\\\", ascending=False)\n    words = words.head(20)\n\n    plt.figure(figsize=(10, 5))\n    ax = sns.barplot(x=\\\"lemma_lower\\\", y=\\\"count\\\", data=words)\n    ax.set_title(\\\"Most used words\\\")\n    ax.set_xlabel(\\\"Word\\\")\n    ax.set_ylabel(\\\"Frequency\\\")\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=40, ha=\\\"right\\\")\n    plt.savefig(\\\"most_used_words.png\\\", bbox_inches=\\\"tight\\\", dpi=300)\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 22.799754758584363}, {"code": "def plot_most_used_words(df)\n\t\n    df.loc[df['lemma_lower'] == \"programa\", \"lemma_lower\"] = \"programar\"\n\n    df_words = df[(df[\"is_alphabet\"] == True) & (df[\"text_lower\"].str.len() > 1) & (~df[\"is_stop\"])]\n    word_counts = df_words[\"lemma_lower\"].value_counts()\n    top_words = word_counts.head(20)\n\n    fig, ax = plt.subplots()\n    top_words.plot(kind='barh', ax=ax)\n    ax.set_title('Top 20 Most Used Words')\n    ax.set_xlabel('Frequency')\n    ax.set_ylabel('Word')\n    plt.tight_layout()\n    plt.savefig('top_20_words.png')\n\n", "CodeBleu_score": 33.78107505154438}, {"code": "def plot_most_used_words(df)\n\t\n    # Small fix for programa and programar.", "CodeBleu_score": 0.35714285714285715}]}
{"instance_id": "13414a7eb4e3", "generation_result": [{"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n\n    dtype, fill_value = dtypes.maybe_promote(a.dtype)\n    a = a.astype(dtype)\n    depth = {None: 0, \"trim\": 0, \"pad\": 0, \"nearest\": 0}[moving_func.boundary]\n    boundary = {None: \"none\", \"trim\": \"none\", \"pad\": \"none\", \"nearest\": \"none\"}[moving_func.boundary]\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    res = da.map_blocks(moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype)\n    res = da.overlap.trim_internal(res, depth)\n    return res", "CodeBleu_score": 45.70859828966133}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    if a.dtype == dtypes.get_dtype(float):\n        a = a.astype(dtypes.get_dtype(\"float64\"))\n    if a.dtype == dtypes.get_dtype(int):\n        a = a.astype(dtypes.get_dtype(\"int64\"))\n    if min_count is None:\n        min_count = window\n    depth = {d: 0 for d in range(a.ndim)}\n    depth[axis] = 1\n    boundary = {d: fill_value for d in range(a.ndim)}\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    res = da.map_blocks(moving_func, ag, window, min_count=min_count, axis=axis)\n    return da.overlap.trim_internal(res, depth)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 56.52872243559288}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    a = da.from_array(a, chunks=(a.shape[0], a.shape[1]))\n    dtype, fill_value = dtypes.maybe_promote(a.dtype)\n    a = a.astype(dtype)\n    depth = {0: 0, 1: 0, -1: 0}[axis]\n    boundary = {0: fill_value, 1: fill_value, -1: fill_value}[axis]\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    out = da.map_blocks(moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype)\n    return da.overlap.trim_internal(out, depth)\n\n", "CodeBleu_score": 46.3827821371017}]}
{"instance_id": "68ce25d325d4", "generation_result": [{"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import dask.array as da\n    import numpy as np\n\n    if not isinstance(lhs, da.Array):\n        lhs = da.from_array(lhs, chunks=(lhs.shape[0], 1))\n    if not isinstance(rhs, da.Array):\n        rhs = da.from_array(rhs, chunks=(rhs.shape[0], 1))\n\n    if skipna:\n        if rhs.ndim > 1:\n            rhs = rhs.reshape((rhs.shape[0], -1))\n        rhs = da.apply_along_axis(\n            lambda x: np.polynomial.polynomial.polyfit(lhs, x, 1, rcond=rcond),\n            axis=1,\n            arr=rhs,\n        )\n        coeffs = rhs[:, 0]\n        residuals = rhs[:, 1]\n    else:\n        coeffs, residuals, _, _ = da.linalg.lstsq(lhs, rhs)\n\n    return coeffs, residuals\n", "CodeBleu_score": 46.05591385590091}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import dask.array as da\n    from dask.array.linalg import lstsq\n\n    lhs = da.asarray(lhs)\n    rhs = da.asarray(rhs)\n    if skipna:\n        if rhs.ndim > 1:\n            rhs = rhs.reshape(-1, rhs.shape[-1])\n        if lhs.ndim > 2:\n            lhs = lhs.reshape(-1, lhs.shape[-2], lhs.shape[-1])\n        coeffs, resids = da.apply_along_axis(\n            nputils._nanpolyfit_1d, -1, rhs, lhs, 1, rcond=rcond\n        )\n    else:\n        coeffs, resids, rank, s = lstsq(lhs, rhs)\n    return coeffs, resids\n\n\n", "CodeBleu_score": 31.600589368836147}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import dask.array as da\n    import numpy as np\n    from dask.array.linalg import inv, solve\n\n    if rcond is None:\n        rcond = np.finfo(np.float64).eps * max(lhs.shape)\n\n    if skipna:\n        # reshape right-hand side\n        rhs = rhs.reshape((rhs.shape[0], -1))\n        # apply polynomial fit\n        coeffs, residuals, rank, s = da.linalg.lstsq(lhs, rhs)\n        # extract coefficients and residuals\n        coeffs = coeffs[:lhs.shape[1]]\n        residuals = residuals[:rhs.shape[1]]\n    else:\n        # compute least squares solution\n        s = da.linalg.svd(lhs, full_matrices=False)\n        s_inv = inv(s[1])\n        coeffs = da.dot(s_inv, s[2])\n        residuals = da.dot(lhs, coeffs) - rhs\n\n    return coeffs, residuals\n\n", "CodeBleu_score": 38.78068156476974}]}
{"instance_id": "c0c2c53b76e0", "generation_result": [{"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        kwargs[\"meta\"] = np.ndarray\n    return da.from_array(data, chunks, **kwargs)\n\n", "CodeBleu_score": 70.27898286466454}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        kwargs.setdefault(\"meta\", np.ndarray)\n\n    return da.from_array(data, chunks, **kwargs)\n\n", "CodeBleu_score": 56.7921307517903}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        kwargs[\"meta\"] = np.ndarray\n    return da.from_array(data, chunks, **kwargs)\n\n", "CodeBleu_score": 70.27898286466454}]}
{"instance_id": "6559019d09a0", "generation_result": [{"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        array_func, array_args = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n", "CodeBleu_score": 70.20927071036714}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        func, args = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n\n        return self._dask_finalize, (func,) + args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n", "CodeBleu_score": 62.834841516731885}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        return self._data.__dask_postpersist__()  # type: ignore[no-any-return]\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n", "CodeBleu_score": 48.703486526095084}]}
{"instance_id": "4a2801bb3851", "generation_result": [{"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    f.__name__ = name\n    return f\n\n", "CodeBleu_score": 62.10381968884977}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            return getattr(dask_module, name)(*args, **kwargs)\n        else:\n            return getattr(eager_module, name)(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 51.730322369092505}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(a) for a in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    f.__name__ = name\n    return f\n\n", "CodeBleu_score": 62.10381968884977}]}
{"instance_id": "eef8d746d01e", "generation_result": [{"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask and (is_dask_collection(arr1) or is_dask_collection(arr2)):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 66.95963321176872}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask_available and isinstance(arr1, dask.array.Array) and isinstance(arr2, dask.array.Array):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 61.51712513179328}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask_array_type is not None and isinstance(arr1, dask_array_type) and isinstance(\n        arr2, dask_array_type\n    ):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 61.698364904208546}]}
{"instance_id": "15e830ff5fcb", "generation_result": [{"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is None:\n        xp = np\n    else:\n        xp = da.Array\n    rs = np.random.RandomState(seed)\n    x = rs.randn(*shape)\n    if frac_nan is not None:\n        inds = rs.choice(range(x.size), int(x.size * frac_nan), replace=False)\n        x.flat[inds] = np.nan\n    if chunks is not None:\n        x = da.from_array(x, chunks=chunks)\n    return x\n\n", "CodeBleu_score": 56.406488475733916}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        import dask.array as da\n\n        x = da.random.RandomState(seed).normal(size=shape, chunks=chunks)\n    else:\n        rs = np.random.RandomState(seed)\n        x = rs.standard_normal(shape)\n    if frac_nan is not None:\n        inds = tuple(\n            slice(None, None, rs.randint(10)) for _ in range(x.ndim)\n        )\n        x[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 54.79083960502212}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        import dask.array as da\n        x = da.random.RandomState(seed).standard_normal(shape, chunks=chunks)\n    else:\n        np.random.seed(seed)\n        x = np.random.standard_normal(shape)\n    if frac_nan is not None:\n        inds = np.random.RandomState(seed + 1).choice(\n            np.prod(shape), int(np.prod(shape) * frac_nan), replace=False\n        )\n        x.flat[inds] = np.nan\n    return x\n\n", "CodeBleu_score": 62.372222204401375}]}
{"instance_id": "5b57abbbe38b", "generation_result": [{"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n", "CodeBleu_score": 90.57611571255117}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n", "CodeBleu_score": 90.57611571255117}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n", "CodeBleu_score": 90.57611571255117}]}
{"instance_id": "592e414671e9", "generation_result": [{"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    name = name.lower()\n    if name not in const.FINANCIALS_ALLOWED_FINANCIAL_STATS:\n        raise ValueError(\n            f\"Invalid name. Valid names are: {', '.join(const.FINANCIALS_ALLOWED_FINANCIAL_STATS)}\"\n        )\n    if timescale not in const.FINANCIALS_ALLOWED_PERIODS:\n        raise ValueError(\n            f\"Invalid timescale. Valid timescales are: {', '.join(const.FINANCIALS_ALLOWED_PERIODS)}\"\n        )\n    try:\n        financials_table = self._create_financials_table(name, timescale, proxy)\n    except YFException as e:\n        self._data.logger.error(\n            f\"Error while creating financials table: {e}. Returning empty DataFrame.\"\n        )\n        financials_table = pd.DataFrame()\n    return financials_table\n\n", "CodeBleu_score": 42.2799828735053}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    try:\n        if name not in const.FINANCIAL_STATEMENTS:\n            raise ValueError(\n                f\"Invalid financial statement name: {name}. Valid options are: {', '.join(const.FINANCIAL_STATEMENTS)}\"\n            )\n        if timescale not in const.TIME_SCALES:\n            raise ValueError(\n                f\"Invalid timescale: {timescale}. Valid options are: {', '.join(const.TIME_SCALES)}\"\n            )\n    except ValueError as e:\n        raise YFException(str(e)) from e\n\n    try:\n        financials_table = self._create_financials_table(name, timescale, proxy)\n        return financials_table\n    except Exception as e:\n        self._data._logger.error(f\"Error fetching {name} time series: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 39.0008739405068}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.FINANCIALS_ALLOWED_STATEMENTS:\n        raise ValueError(f\"{name} is not a valid financial statement\")\n    if timescale not in const.FINANCIALS_ALLOWED_PERIODS:\n        raise ValueError(f\"{timescale} is not a valid period\")\n    try:\n        table = self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        logger.error(f\"Error creating financials table for {self._symbol} {name} {timescale}\")\n        logger.error(e)\n        return pd.DataFrame()\n    return table\n\n", "CodeBleu_score": 38.61882046193628}]}
{"instance_id": "af01d9bae091", "generation_result": [{"code": "def _parse_fund_ownership(self, data)\n\t\n    holders = data[\"ownershipList\"]\n    for owner in holders:\n        for k, v in owner.items():\n            owner[k] = self._parse_raw_values(v)\n        del owner[\"maxAge\"]\n    df = pd.DataFrame(holders)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"], unit=\"s\")\n        df.rename(\n            columns={\n                \"reportDate\": \"Date Reported\",\n                \"organization\": \"Holder\",\n                \"pctHeld\": \"% Out\",\n                \"value\": \"Value\",\n            },\n            inplace=True,\n        )\n    self._mutualfund = df\n\n", "CodeBleu_score": 68.9449221537124}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    holders = data[\"ownershipList\"]\n    for owner in holders:\n        for k, v in owner.items():\n            owner[k] = self._parse_raw_values(v)\n        del owner[\"maxAge\"]\n    df = pd.DataFrame(holders)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"], unit=\"s\")\n        df.rename(\n            columns={\n                \"reportDate\": \"Date Reported\",\n                \"organization\": \"Holder\",\n                \"position\": \"Shares\",\n                \"value\": \"Value\",\n            },\n            inplace=True,\n        )  # \"pctHeld\": \"% Out\"\n    self._mutualfund = df\n\n", "CodeBleu_score": 70.47392515555522}, {"code": "def _parse_fund_ownership(self, data)\n\t\n\n    holders = data[\"ownershipList\"]\n    for owner in holders:\n        for k, v in owner.items():\n            owner[k] = self._parse_raw_values(v)\n        del owner[\"maxAge\"]\n    df = pd.DataFrame(holders)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"], unit=\"s\")\n        df.rename(columns={\"reportDate\": \"Date Reported\", \"organization\": \"Holder\", \"position\": \"Shares\", \"value\": \"Value\"}, inplace=True)  # \"pctHeld\": \"% Out\"\n    self._mutualfund = df\n\n", "CodeBleu_score": 79.23219848150065}]}
{"instance_id": "2b5c6f1253db", "generation_result": [{"code": "def currency(self)\n\t\n    if self._currency is not None:\n        return self._currency\n\n    md = self._get_exchange_metadata()\n    self._currency = md[\\\"currency\\\"]\n    return self._currency\n\n", "CodeBleu_score": 61.23492470559957}, {"code": "def currency(self)\n\t\n    if self._currency is not None:\n        return self._currency\n\n    md = self._get_exchange_metadata()\n    self._currency = md[\\\"currency\\\"]\n    return self._currency\n\n", "CodeBleu_score": 61.23492470559957}, {"code": "def currency(self)\n\t\n    if self._currency is not None:\n        return self._currency\n    md = self._get_exchange_metadata()\n    self._currency = md[\\\"currency\\\"]\n    return self._currency\n\n", "CodeBleu_score": 61.23492470559957}]}
{"instance_id": "16b80be60e3b", "generation_result": [{"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch_recommendations(self.proxy)\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = self._recommendations[\"recommendationTrend\"][\"trend\"]\n            except Exception as e:\n                raise YFDataException(f\"Error parsing recommendations data: {str(e)}\")\n\n    return self._recommendations\n\n", "CodeBleu_score": 43.89878983790555}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._fetch_info(self.proxy)\n        self._fetch_complementary(self.proxy)\n\n    return self._recommendations\n", "CodeBleu_score": 12.309563735539623}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._fetch_recommendations(self.proxy)\n        self._fetch_complementary(self.proxy)\n\n    return self._recommendations\n\n", "CodeBleu_score": 12.805964744398906}]}
{"instance_id": "abaf8c2a3ecc", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have the instance variable \"\n                        \"'n_clusters' for the optimal number of clusters.\")\n\n    if cluster_ranges is None:\n        cluster_ranges = np.arange(2, 15)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    if show_cluster_time:\n        times = []\n\n    for k in cluster_ranges:\n        clf = clone(clf)\n        clf.n_clusters = k\n        t0 = time.time()\n        clf.fit(X)\n        times.append(time.time() - t0)\n\n    ax2 = ax.twinx()\n    ax.plot(cluster_ranges, clf.elbow_score_, 'b*-')\n    ax.set_ylabel('Sum of Squared Errors', color='b',\n                  fontsize=text_fontsize)\n    ax.tick_params('y', colors='b', labelsize=text_fontsize)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if show_cluster_time:\n        ax2.plot(cluster_ranges, times, 'r*-')\n        ax2.set_ylabel('Clustering Time (seconds)', color='r',\n                       fontsize=text_fontsize)\n        ax2.tick_params('y', colors='r', labelsize=text_fontsize)\n\n    return ax", "CodeBleu_score": 53.94220408095507}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"Cannot generate elbow plot for {} object. \"\n                        \"It does not have 'n_clusters' \"\n                        \"attribute\".format(clf.__class__.__name__))\n    if cluster_ranges is None:\n        cluster_ranges = range(1, min(10, len(X)))\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n    start = time.time()\n    sse = Parallel(n_jobs=n_jobs)(delayed(\n        _fit_and_score)(clone(clf), X, k) for k in cluster_ranges)\n    end = time.time()\n    ax.plot(cluster_ranges, sse, 'b*-')\n    ax.set_ylim([0, max(sse) * 1.05])\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors (SSE)', fontsize=text_fontsize)\n    if show_cluster_time:\n        cluster_time = end - start\n        ax2 = ax.twinx()\n        ax2.set_ylim([0, cluster_time * 1.05])\n        ax2.set_ylabel('Clustering Time (seconds)', fontsize=text_fontsize)\n        ax2.plot(cluster_ranges, [cluster_time for _ in cluster_ranges], 'r--')\n    return ax\n\n", "CodeBleu_score": 56.285295326159236}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\n            \"plot_elbow_curve expects clf to have the attribute 'n_clusters'\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 10)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    start = time.time()\n    if n_jobs == 1:\n        scores = [clf.set_params(n_clusters=k).fit(X).score(X)\n                  for k in cluster_ranges]\n    else:\n        clfs = [clone(clf).set_params(n_clusters=k) for k in cluster_ranges]\n        scores = Parallel(n_jobs=n_jobs)(\n            delayed(lambda x: x.fit(X).score(X))(x) for x in clfs)\n    end = time.time()\n\n    ax.plot(cluster_ranges, scores, 'b*-')\n    ax.set_ylim((0, 1))\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if show_cluster_time:\n        cluster_time = end - start\n        ax2 = ax.twinx()\n        ax2.set_ylim((0, cluster_time))\n        ax2.set_ylabel('Clustering time (seconds)', fontsize=text_fontsize)\n        ax2.tick_params(labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 57.60841126755043}]}
{"instance_id": "8a90815c4ee1", "generation_result": [{"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    clf = clone(clf)\n    clf.set_params(n_clusters=n_clusters)\n    clf.fit(X)\n    score = clf.score(X)\n    end_time = time.time()\n    return score, end_time - start_time\n", "CodeBleu_score": 39.06505904732874}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start = time.time()\n    clf = clone(clf)\n    clf.set_params(n_clusters=n_clusters)\n    clf.fit(X)\n    duration = time.time() - start\n    return clf.score(X), duration\n", "CodeBleu_score": 50.783316973225844}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    clf = clone(clf)\n    clf.set_params(n_clusters=n_clusters)\n    clf.fit(X)\n    elapsed_time = time.time() - start_time\n    return clf.score(X), elapsed_time\n", "CodeBleu_score": 45.60999198566058}]}
{"instance_id": "da40bd5dd81a", "generation_result": [{"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('\"clf\" is not a valid clusterer instance.')\n\n    def _plot_silhouette(self, X, **kwargs):\n        return plot_silhouette(X, self.fit_predict(X), **kwargs)\n\n    def _plot_elbow_curve(self, X, **kwargs):\n        return plot_elbow_curve(X, self.fit_predict(X), **kwargs)\n\n    additional_methods = {\n        'plot_silhouette': _plot_silhouette,\n        'plot_elbow_curve': _plot_elbow_curve\n    }\n    for method_name, method in six.iteritems(additional_methods):\n        if hasattr(clf, method_name):\n            warnings.warn('\"{}\" already has method \"{}\", so skipping.'.format(\n                clf.__class__.__name__, method_name))\n        else:\n            setattr(clf, method_name, types.MethodType(method, clf))\n    return clf", "CodeBleu_score": 44.9023232715906}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('\"clf\" is not a valid clusterer instance. ' 'It does not have the required methods fit and fit_predict.')\n\n    def plot_silhouette(X, **kwargs):\n        return plotters.plot_silhouette(X, clf.fit_predict(X), **kwargs)\n\n    def plot_elbow_curve(X, **kwargs):\n        return plotters.plot_elbow_curve(X, clf, **kwargs)\n\n    additional_methods = [plot_silhouette, plot_elbow_curve]\n    for method in additional_methods:\n        if hasattr(clf, method.__name__):\n            warnings.warn('\"{}\" already has a method named \"{}\". ' 'The method will be overridden.'.format(clf.__class__.__name__, method.__name__))\n        setattr(clf, method.__name__, types.MethodType(method, clf))\n\n    return clf\n\n", "CodeBleu_score": 32.954827615513096}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('The clustering object should have the following methods: fit, fit_predict.')\n\n    def plot_silhouette(self, X, **kwargs):\n        \"\"\"\n        Plots the silhouette plot of the clustering object.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        **kwargs : keyword arguments\n            Keyword arguments for the silhouette plot.\n\n        Returns\n        -------\n        ax : matplotlib Axes object\n            The silhouette plot.\n        \"\"\"\n        return plot_silhouette(self, X, **kwargs)\n\n    def plot_elbow_curve(self, X, **kwargs):\n        \"\"\"\n        Plots the elbow curve of the clustering object.\n\n        Parameters\n        ----------\n        X : array-like, shape (n_samples, n_features)\n            Data to cluster, where n_samples is the number of samples and\n            n_features is the number of features.\n\n        **kwargs : keyword arguments\n            Keyword arguments for the elbow curve plot.\n\n        Returns\n        -------\n        ax : matplotlib Axes object\n            The elbow curve plot.\n        \"\"\"\n        return plot_elbow_curve(self, X, **kwargs)\n\n    additional_methods = {\n        'plot_silhouette': plot_silhouette,\n        'plot_elbow_curve': plot_elbow_curve\n    }\n\n    for method_name, method in six.iteritems(additional_methods):\n        if hasattr(clf, method_name):\n            warnings.warn('The clustering object already has a method named {}. The method will be overridden.'.format(method_name))\n        setattr(clf, method_name, types.MethodType(method, clf))\n\n    return clf", "CodeBleu_score": 44.2034118454047}]}
{"instance_id": "b8d8ba3c0b1b", "generation_result": [{"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n\n    train_sizes, train_scores, test_scores = \\\n        learning_curve(clf, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 74.21459768250844}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n\n    train_sizes, train_scores, test_scores = \\\n        learning_curve(clf, X, y, cv=cv, n_jobs=n_jobs,\n                       train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 74.1275384885235}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 79.31740369089935}]}
{"instance_id": "e6e76eb35945", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('\"n_clusters\" attribute not in classifier. Cannot plot elbow method.')\n\n    clfs = [clone(clf) for _ in range(len(cluster_ranges))]\n    for i, k in enumerate(cluster_ranges):\n        clfs[i].n_clusters = k\n\n    clfs = [clf.fit(X) for clf in clfs]\n    scores = [clf.score(X) for clf in clfs]\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.plot(cluster_ranges, np.abs(scores), 'o-', color=\"g\", label=\"score\")\n    ax.grid(True, alpha=0.3)\n\n    ax.set_xticks(cluster_ranges)\n    ax.set_xlabel(\"Number of clusters\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 61.835848249482616}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('\"n_clusters\" attribute not in classifier. Cannot plot elbow method.'\n                        'Cannot generate elbow plot for {}'.format(clf))\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    clfs = [clone(clf).set_params(n_clusters=n_clusters)\n            for n_clusters in cluster_ranges]\n\n    scores = [np.abs(clf.fit(X).score(X))\n              for clf in clfs]\n\n    ax.plot(cluster_ranges, scores, 'bo-', color='black')\n    ax.grid(True)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Score', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 63.13537249225784}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('\\'clf\\' object has no attribute \\'n_clusters\\'')\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.grid(True)\n\n    scores = [abs(clf.set_params(n_clusters=k).fit(X).score(X))\n              for k in cluster_ranges]\n\n    ax.plot(cluster_ranges, scores, 'o-')\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Score', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 56.78072624536803}]}
{"instance_id": "6f4530c8a20f", "generation_result": [{"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'fit_transform'):\n        raise TypeError('\"clf\" does not have fit_transform method.')\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    X_pca = clf.fit_transform(X)\n\n    classes = np.unique(y)\n\n    colors = plt.cm.get_cmap(cmap)(np.linspace(0.0, 1.0, len(classes)))\n\n    for label, color in zip(classes, colors):\n        ax.scatter(X_pca[y == label, 0],\n                   X_pca[y == label, 1],\n                   c=color.reshape(1, -1),\n                   label=label,\n                   alpha=0.6,\n                   edgecolors='k')\n\n    ax.set_xlabel('First principal component', fontsize=text_fontsize)\n    ax.set_ylabel('Second principal component', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 61.627152159678175}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'fit_transform'):\n        raise TypeError('\"clf\" does not have fit_transform method.')\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    X_pca = clf.fit_transform(X)\n\n    classes = np.unique(y)\n\n    if len(classes) == 2:\n        ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap, lw=0)\n    else:\n        for i, class_ in enumerate(classes):\n            ax.scatter(X_pca[y == class_, 0], X_pca[y == class_, 1], c=cmap(i),\n                       label=class_, lw=0)\n\n    ax.set_xlabel('First principal component', fontsize=text_fontsize)\n    ax.set_ylabel('Second principal component', fontsize=text_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 49.7524598434332}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'fit_transform'):\n        raise TypeError('\"clf\" does not have fit_transform method. Has the PCA been fitted?')\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n\n    X_pca = clf.fit_transform(X)\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, edgecolor='none', alpha=0.7, cmap=cmap)\n    ax.set_xlabel('Component 1', fontsize=text_fontsize)\n    ax.set_ylabel('Component 2', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 41.802042162696154}]}
{"instance_id": "e7c2775d024c", "generation_result": [{"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    X = np.arange(16)\n    Y1 = np.random.uniform(0.5, 1.0, len(X))\n    Y2 = np.random.uniform(0.5, 1.0, len(X))\n\n    ax.bar(X, +Y1, 1, facecolor=\"#cccccc\", edgecolor=\"white\", clip_path=clip1)\n    ax.bar(X, -Y2, 1, facecolor=\"#999999\", edgecolor=\"white\", clip_path=clip1)\n    ax.bar(X, +Y1, 1, facecolor=\"#ffaaaa\", edgecolor=\"white\", clip_path=clip2)\n    ax.bar(X, -Y2, 1, facecolor=\"#ff7777\", edgecolor=\"white\", clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.0, -0.08, \"Bar plot\", color=\"k\", ha=\"left\", size=8, transform=ax.transAxes)\n    ax.text(\n        1.0,\n        -0.08,\n        \"ax.bar()\",\n        color=\"blue\",\n        ha=\"right\",\n        size=8,\n        transform=ax.transAxes,\n        family=\"monospace\",\n    )\n\n", "CodeBleu_score": 49.16306986334249}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    x = np.arange(16)\n    y1 = np.random.randint(25, 50, 16)\n    y2 = np.random.randint(10, 25, 16)\n\n    ax.bar(x, y1, color='#999999', clip_path=clip1)\n    ax.bar(x, y1, color='#cccccc', clip_path=clip2)\n    ax.bar(x, y2, bottom=y1, color='#ffaaaa', clip_path=clip1)\n    ax.bar(x, y2, bottom=y1, color='#ffdddd', clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.0, -0.08, 'Bar plot',\n            color='k',\n            ha='left',\n            size=8,\n            transform=ax.transAxes)\n    ax.text(1.0, -0.08, 'ax.bar()',\n            color='blue',\n            ha='right',\n            size=8,\n            transform=ax.transAxes,\n            family=\"monospace\")\n\n", "CodeBleu_score": 46.262223217929474}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    X = np.arange(1, 17)\n    Y1 = np.random.uniform(0.5, 0.7, len(X))\n    Y2 = np.random.uniform(0.3, 0.6, len(X))\n    ax.bar(X, +Y1, 1, facecolor='#cccccc', edgecolor='white', clip_path=clip1)\n    ax.bar(X, -Y2, 1, facecolor='#999999', edgecolor='white', clip_path=clip1)\n    ax.bar(X, +Y1, 1, facecolor='#ffaaaa', edgecolor='white', clip_path=clip2)\n    ax.bar(X, -Y2, 1, facecolor='#ff7777', edgecolor='white', clip_path=clip2)\n\n    ax.set_xlim(-1, 17)\n\n    ax.text(0.0, -0.08, 'Bar plot',\n            color='k',\n            ha='left',\n            size=8,\n            transform=ax.transAxes)\n    ax.text(1.0, -0.08, 'ax.bar()',\n            color='blue',\n            ha='right',\n            size=8,\n            transform=ax.transAxes,\n            family=\"monospace\")\n\n", "CodeBleu_score": 64.091133490179}]}
{"instance_id": "0ec1d146a32b", "generation_result": [{"code": "def split(n_segment)\n\t\n    width = (11-10*n_segment)/(n_segment+1)\n    padding = width*n_segment+1\n    X0 = np.linspace(0,11-padding,n_segment)+0.5*width+0.5*padding\n    X1 = X0+width\n    return X0, X1\n\n\n", "CodeBleu_score": 36.203671792830505}, {"code": "def split(n_segment)\n\t\n    width = (11 - 10) / n_segment\n    padding = (11 - width * n_segment) / (n_segment + 1)\n    X0 = np.linspace(0, 11 - width, n_segment) + padding\n    X1 = X0 + width\n    return X0, X1\n\n", "CodeBleu_score": 32.97774998447544}, {"code": "def split(n_segment)\n\t\n    dx = 10.0/n_segment\n    xpad0 = 0.1*dx\n    xpad1 = 0.1*dx\n    X0 = np.linspace(xpad0,10.0-dx-xpad1,n_segment)\n    X1 = X0 + dx\n    return X0, X1\n", "CodeBleu_score": 29.15497920198459}]}
{"instance_id": "604a3e93ac0d", "generation_result": [{"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n    ax.text(0.5, 0.5, \"a\", ha=\"center\", va=\"center\", fontsize=75)\n    ax.set_xlim(0, 1), ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n    canvas.draw()\n    I = np.frombuffer(canvas.tostring_argb(), dtype=\"uint8\")\n    I = I.reshape(dpi, dpi, 4)\n    I = np.roll(I, 1, axis=-1)\n    return I[::-1]\n\n", "CodeBleu_score": 51.403655949523596}, {"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n    ax.text(0.5, 0.5, \"a\", fontsize=75, ha=\"center\", va=\"center\")\n    ax.set_xlim(0, 1), ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n    canvas.draw()\n    I = np.array(canvas.buffer_rgba())\n    I = I[::-1]\n    L, M, N = I.shape\n    I = I.reshape(M, N, L)\n    I = np.roll(I, 3, axis=-1)\n    return I\n\n", "CodeBleu_score": 49.266702967196366}, {"code": "def pixelated_text(dpi=100)\n\t\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvasAgg(fig)\n    ax = fig.add_axes([0, 0, 1, 1], frameon=False)\n    ax.text(0.5, 0.5, \"a\", fontsize=75, ha=\"center\", va=\"center\")\n    ax.set_xlim(0, 1), ax.set_ylim(0, 1)\n    ax.set_xticks([]), ax.set_yticks([])\n    canvas.draw()\n    s, (width, height) = canvas.print_to_buffer()\n    X = np.frombuffer(s, np.uint8).reshape((height, width, 4))\n    X = np.roll(X, 3, axis=2)\n    return X.reshape((height, width, 4))\n\n", "CodeBleu_score": 46.78708789018348}]}
{"instance_id": "2a7fc7d560ea", "generation_result": [{"code": "def curve()\n\t\n    n = np.random.randint(3, 7)\n    x = np.linspace(0, 1, 1000)\n    y = np.zeros(len(x))\n    scales = np.random.rand(n)\n    scales /= scales.sum()\n    scales *= 0.75\n    widths = np.maximum(np.random.rand(n), 0.1)\n    widths /= widths.sum()\n    widths *= 0.5\n    centers = np.random.rand(n)\n    for i in range(n):\n        y += scales[i] * np.exp(-(x - centers[i]) ** 2 / widths[i])\n    return x, y\n\n", "CodeBleu_score": 35.935985563277654}, {"code": "def curve()\n\t\n    n = 1000\n    t = np.linspace(-10, 10, n)\n    x = np.zeros(n)\n    y = np.zeros(n)\n    for i in range(1, 10):\n        c = np.random.uniform(-10, 10)\n        w = np.random.uniform(0.1, 1.0)\n        f = np.random.uniform(0.1, 1.0)\n        x += f * np.exp(-0.5 * ((t - c) / w) ** 2)\n        y += f * np.exp(-0.5 * ((t - c) / w) ** 2)\n    return x, y\n\n", "CodeBleu_score": 27.339738320258956}, {"code": "def curve()\n\t\n    n_components = np.random.randint(1, 4)\n    centers = np.random.uniform(-1, 1, n_components)\n    widths = np.random.uniform(0.1, 0.5, n_components)\n    scales = np.random.uniform(0.5, 1.5, n_components)\n    widths = widths / np.sum(widths) * 0.8\n    scales = scales / np.sum(scales) * 0.8\n    X = np.linspace(-1, 1, 1000)\n    Y = np.zeros_like(X)\n    for center, width, scale in zip(centers, widths, scales):\n        Y += scale * np.exp(-((X - center) / width) ** 2)\n    return X, Y\n\n", "CodeBleu_score": 44.67775012083278}]}
{"instance_id": "be694335ebfc", "generation_result": [{"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = int(np.ceil(derivative + accuracy / 2))\n    points = np.arange(-radius, radius + 1)\n    matrix = np.vander(points, derivative + radius, True)\n    return np.linalg.pinv(matrix)[:, derivative], points\n\n", "CodeBleu_score": 45.227516941723124}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = int(np.ceil((derivative + 1) / 2) + accuracy - 1)\n    points = np.arange(-radius, radius + 1)\n    coefficients = np.linalg.inv(np.vander(points, len(points))).T[derivative]\n    return coefficients / factorial(derivative - 1), points\n\n", "CodeBleu_score": 51.195088306123935}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative = derivative + 1\n    radius = (accuracy + 1) // 2\n    points = np.arange(-radius, radius + 1)\n    vandermonde = np.vander(points)\n    inverse = np.linalg.inv(vandermonde)\n    return inverse[derivative] * factorial(derivative - 1), points\n\n", "CodeBleu_score": 53.642462042962116}]}
{"instance_id": "fa3fb47f33fa", "generation_result": [{"code": "def interpolate(X, Y, T)\n\t\n    X = np.asarray(X)\n    Y = np.asarray(Y)\n    T = np.asarray(T)\n    # Compute the distances between consecutive points\n    distances = np.sqrt((X[1:] - X[:-1])**2 + (Y[1:] - Y[:-1])**2)\n    # Compute the cumulative distances\n    cumulative_distances = np.concatenate(([0], np.cumsum(distances)))\n    # Compute the total distance covered by the original coordinates\n    total_distance = cumulative_distances[-1]\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interp = np.interp(T, cumulative_distances, X)\n    Y_interp = np.interp(T, cumulative_distances, Y)\n    return X_interp, Y_interp, total_distance\n\n", "CodeBleu_score": 26.207756574450304}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute the distances between consecutive points\n    D = np.cumsum(np.sqrt(np.sum(np.diff(X, axis=0) ** 2, axis=1) + np.sum(np.diff(Y, axis=0) ** 2, axis=1)))\n    D = np.insert(D, 0, 0)\n    # Compute the cumulative distance at each target point\n    T = np.cumsum(T)\n    T = np.insert(T, 0, 0)\n    # Compute the total distance covered by the original coordinates\n    total_distance = T[-1]\n    # Interpolate the X and Y coordinates at the target points\n    Xi = np.interp(T, D, X[:, 0])\n    Yi = np.interp(T, D, Y[:, 0])\n    return Xi, Yi, total_distance\n\n", "CodeBleu_score": 23.41943244073047}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute the distances between consecutive points\n    D = np.cumsum(np.sqrt(np.sum(np.diff(X, axis=0) ** 2 + np.diff(Y, axis=0) ** 2, axis=1)))\n    D = np.insert(D, 0, 0) / D[-1]  # Normalize the distances\n\n    # Compute the cumulative distances\n    T = np.cumsum(T)\n    T -= T[0]\n    T /= T[-1]\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X = np.interp(T, D, X[:, 0])\n    Y = np.interp(T, D, Y[:, 0])\n\n    # Compute the total distance covered by the original coordinates\n    d = scipy.integrate.simps(np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2))\n\n    return X, Y, d\n\n", "CodeBleu_score": 33.996275485676364}]}
{"instance_id": "870a2dad3c66", "generation_result": [{"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    Xi, Yi = np.mgrid[0:xn, 0:yn]\n    Xi, Yi = Xi.astype(np.float32), Yi.astype(np.float32)\n    Xi, Yi = Xi / (xn - 1), Yi / (yn - 1)\n    X, Y = xmin + (xmax - xmin) * Xi, ymin + (ymax - ymin) * Yi\n    C = X + Y * 1j\n    N_ = np.zeros(C.shape, dtype=np.int64)\n    Z_ = np.zeros(C.shape, np.complex64)\n    Xi, Yi, C = np.atleast_1d(Xi, Yi, C)\n    for i in range(maxiter):\n        if not len(Z_):\n            break\n        np.multiply(Z_, Z_, Z_)\n        np.add(Z_, C, Z_)\n        rem = abs(Z_) > horizon\n        N_[rem] = i + 1\n        rem = ~rem\n        N_[rem] = 0\n        Z_ = Z_[rem]\n        C = C[rem]\n    return Z_.T, N_.T\n\n", "CodeBleu_score": 34.69750005258212}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    Xi, Yi = np.mgrid[0:xn, 0:yn]\n    Xi = Xi.astype(np.float32)\n    Yi = Yi.astype(np.float32)\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    Xi, Yi = np.mgrid[0:xn, 0:yn]\n    Xi = Xi.astype(np.float32)\n    Yi = Yi.astype(np.float32)\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter - 1] = 0\n    return Z, N\n\n\n\n", "CodeBleu_score": 71.88528004694558}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter - 1] = 0\n    return Z, N\n\n", "CodeBleu_score": 76.74202113537902}]}
{"instance_id": "e1a908945acf", "generation_result": [{"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = max(int(sigma), 3) * 2 + 1\n    A = np.array(A)\n    A_smooth = np.apply_along_axis(lambda x: smooth1d(x, window_len), 0, A)\n    A_smooth = np.apply_along_axis(lambda x: smooth1d(x, window_len), 0, A_smooth.T).T\n    return A_smooth\n\n", "CodeBleu_score": 42.589353557887335}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = max(int(sigma), 3) * 2 + 1\n    A = np.array(A)\n    A_smooth = np.apply_along_axis(lambda x: smooth1d(x, window_len), axis=0, arr=A)\n    A_smooth = np.apply_along_axis(lambda x: smooth1d(x, window_len), axis=0, arr=A_smooth.T).T\n    return A_smooth\n\n", "CodeBleu_score": 43.6500893990886}, {"code": "def smooth2d(A, sigma=3)\n\t\n\n    window_len = int(2 * sigma) + 1\n    A = np.apply_along_axis(smooth1d, 0, A, window_len)\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    A = np.apply_along_axis(smooth1d, 0, A, window_len)\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    return A\n\n", "CodeBleu_score": 21.92961749689692}]}
{"instance_id": "94563c54b483", "generation_result": [{"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.offsets\n    tgt_image = np.zeros_like(padded_src)\n    tgt_image = np.roll(padded_src, int(ox / 72.0 * dpi), axis=1)\n    tgt_image = np.roll(tgt_image, -int(oy / 72.0 * dpi), axis=0)\n    return tgt_image\n\n", "CodeBleu_score": 40.5290432148819}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.offsets\n    tgt_image = np.zeros_like(padded_src)\n    tgt_image = np.roll(padded_src, int(ox / 72.0 * dpi), axis=1)\n    tgt_image = np.roll(tgt_image, -int(oy / 72.0 * dpi), axis=0)\n    return tgt_image\n\n", "CodeBleu_score": 40.5290432148819}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.offsets\n    tgt_image = np.zeros_like(padded_src)\n    tgt_image = np.roll(padded_src, int(ox / 72.0 * dpi), axis=1)\n    tgt_image = np.roll(tgt_image, -int(oy / 72.0 * dpi), axis=0)\n    return tgt_image\n\n", "CodeBleu_score": 40.5290432148819}]}
{"instance_id": "d71d232872fe", "generation_result": [{"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = np.array(shape)\n    center = np.array(center)\n    width = np.array(width)\n    return np.exp(-0.5 * np.sum(((np.mgrid[tuple(slice(0, s) for s in shape)] - center) / width) ** 2, axis=0))\n\n", "CodeBleu_score": 12.044623710915287}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape, shape) if isinstance(shape, int) else shape\n    width = (width, width) if isinstance(width, (int, float)) else width\n    center = (center, center) if isinstance(center, (int, float)) else center\n\n    def distance(x, y):\n        return ((x - center[0]) ** 2 + (y - center[1]) ** 2) / width[0] ** 2 + width[1] ** 2\n\n    D = np.fromfunction(distance, shape)\n    return np.exp(-0.5 * D)\n\n", "CodeBleu_score": 21.785987100472877}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape, ) * 2 if isinstance(shape, int) else shape\n    width = (width, ) * 2 if isinstance(width, (int, float)) else width\n    center = (center, ) * 2 if isinstance(center, (int, float)) else center\n\n    def gaussian_function(x, y):\n        return np.exp(-((x - center[0]) ** 2 + (y - center[1]) ** 2) / (2 * width[0] * width[1]))\n\n    grid = np.mgrid[0:shape[0], 0:shape[1]]\n    return gaussian_function(*grid)\n\n", "CodeBleu_score": 22.292209659500845}]}
{"instance_id": "7bbd08c987bc", "generation_result": [{"code": "def stimulus(position, size, intensity)\n\t\n    x, y = position\n    x = (x + 1) / 2.0\n    y = (y + 1) / 2.0\n    x = x * size[0]\n    y = y * size[1]\n    x = x - size[0] / 2.0\n    y = y - size[1] / 2.0\n    x = x + size[0] / 2.0\n    y = y + size[1] / 2.0\n    x = x / size[0]\n    y = y / size[1]\n    x = x * 2.0 - 1.0\n    y = y * 2.0 - 1.0\n    x = x * size[0]\n    y = y * size[1]\n    x = x + size[0] / 2.0\n    y = y + size[1] / 2.0\n    x = x - size[0] / 2.0\n    y = y - size[1] / 2.0\n    x = x / size[0]\n    y = y / size[1]\n    x = x * 2.0 - 1.0\n    y = y * 2.0 - 1.0\n    x = x * size[0]\n    y = y * size[1]\n    x = x + size[0] / 2.0\n    y = y + size[1] / 2.0\n    x = x - size[0] / 2.0\n    y = y - size[1] / 2.0\n    x = x / size[0]\n    y = y / size[1]\n    x = x * 2.0 - 1.0\n    y = y * 2.0 - 1.0\n    x = x * size[0]\n    y = y * size[1]\n    x = x + size[0] / 2.0\n    y = y + size[1] / 2.0\n    x = x - size[0] / 2.0\n    y = y - size[1] / 2.0\n    x = x / size", "CodeBleu_score": 13.142004686162112}, {"code": "def stimulus(position, size, intensity)\n\t\n    x = (position[0] + 1) * 0.5 * size[0]\n    y = (position[1] + 1) * 0.5 * size[1]\n    x = x - 0.5 * size[0]\n    y = y - 0.5 * size[1]\n    x = x / size[0]\n    y = y / size[1]\n    grid = np.mgrid[0:size[0], 0:size[1]].astype(np.float)\n    grid[0] = grid[0] / size[0] - x\n    grid[1] = grid[1] / size[1] - y\n    R = grid[0] ** 2 + grid[1] ** 2\n    return np.exp(-R / (2 * size[0] * size[1])) * intensity\n\n", "CodeBleu_score": 28.640114305970744}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = position\n    x = (x / size) * 2 - 1\n    y = (y / size) * 2 - 1\n    x, y = np.meshgrid(x, y)\n    R = x ** 2 + y ** 2\n    return intensity * np.exp(-R / (size / 12) ** 2)\n\n", "CodeBleu_score": 20.80284709081994}]}
{"instance_id": "2b5806238d5d", "generation_result": [{"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.text(0.5, 0.5, text,\n            verticalalignment=\\\"center\\\", horizontalalignment=\\\"center\\\",\n            fontfamily=\\\"Roboto Condensed\\\", fontsize=24, fontweight=\\\"light\\\")\n    ax.set_title(text, fontfamily=\\\"Roboto Condensed\\\", fontsize=12)\n\n", "CodeBleu_score": 34.680422146974564}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([0, 0.5, 1])\n    ax.set_yticks([0, 0.5, 1])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\\\"center\\\",\n        verticalalignment=\\\"center\\\",\n        fontsize=24,\n        fontweight=\\\"bold\\\",\n        fontfamily=\\\"Roboto Condensed\\\",\n    )\n    ax.set_title(text, fontdict={\\\"fontsize\\\": 12, \\\"fontweight\\\": \\\"light\\\"})\n\n", "CodeBleu_score": 28.308507003277093}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_xticklabels([])\n    ax.set_yticklabels([])\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\\\"center\\\",\n        verticalalignment=\\\"center\\\",\n        fontfamily=\\\"Roboto Condensed\\\",\n        fontsize=24,\n        fontweight=\\\"light\\\",\n    )\n    ax.set_title(text, fontfamily=\\\"Roboto Condensed\\\", fontweight=\\\"normal\\\", fontsize=16)\n\n", "CodeBleu_score": 27.642784010507}]}
{"instance_id": "0b42aac61e21", "generation_result": [{"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 74.030392732948}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 74.030392732948}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, step in self.steps[:-1]:\n        Xt = step.transform(Xt)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 51.14425551787354}]}
{"instance_id": "c8439e4918ad", "generation_result": [{"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, _, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 77.31008827671275}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, _, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 77.31008827671275}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, _, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n", "CodeBleu_score": 77.31008827671275}]}
{"instance_id": "216662ca7db4", "generation_result": [{"code": "def _check_success(self, results)\n\t\n    if results[\"info\"][\"exitflag\"] == self.EXIT_OPTIMAL:\n        pass\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_PINF:\n        pass\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_DINF:\n        pass\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_MAXIT:\n        warnings.warn(\n            (\"ECOS solver did not converge: {results.info.status}\"),\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_NUMERICS:\n        pass\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_OUTCONE:\n        pass\n    elif results[\"info\"][\"exitflag\"] == self.EXIT_INACC_OFFSET:\n        pass\n    else:\n        raise RuntimeError(f\"ECOS solver failed: {results.info.status}\")\n\n", "CodeBleu_score": 25.750259224355922}, {"code": "def _check_success(self, results)\n\t\n    exit_flag = results[\"info\"][\"exitFlag\"]\n    if exit_flag == self.EXIT_OPTIMAL:\n        return\n    if exit_flag == self.EXIT_MAXIT:\n        warnings.warn(\n            (f\"ECOS solver did not converge: {results['info']['exitFlagValue']}\"),\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n    if exit_flag in (self.EXIT_PINF, self.EXIT_DINF):\n        raise RuntimeError(f\"ECOS solver failed: {results['info']['exitFlagValue']}\")\n    if exit_flag < self.EXIT_INACC_OFFSET:\n        raise RuntimeError(f\"ECOS solver failed: {results['info']['exitFlagValue']}\")\n\n", "CodeBleu_score": 33.365438873033696}, {"code": "def _check_success(self, results)\n\t\n    status = results[\"info\"][\"exitFlag\"]\n    if status == self.EXIT_OPTIMAL:\n        return\n    elif status == self.EXIT_PINF:\n        raise RuntimeError(\"ECOS solver failed: primal infeasibility\")\n    elif status == self.EXIT_DINF:\n        raise RuntimeError(\"ECOS solver failed: dual infeasibility\")\n    elif status == self.EXIT_MAXIT:\n        warnings.warn(\n            \"ECOS solver did not converge: maximum iterations reached\",\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n    elif status == self.EXIT_NUMERICS:\n        raise RuntimeError(\"ECOS solver failed: numeric problems\")\n    elif status == self.EXIT_OUTCONE:\n        raise RuntimeError(\"ECOS solver failed: out of cone\")\n    elif status >= self.EXIT_INACC_OFFSET:\n        raise RuntimeError(f\"ECOS solver failed: inaccurate solution, status = {status}\")\n    else:\n        raise RuntimeError(f\"ECOS solver failed: unknown status = {status}\")\n\n", "CodeBleu_score": 41.648788752120915}]}
{"instance_id": "1fe2e379fca0", "generation_result": [{"code": "def _decompose(self, P)\n\t\n    eigval, eigvec = linalg.eigh(P)\n    eigval = eigval[::-1]\n    eigvec = eigvec[:, ::-1]\n    max_eigval = eigval[0]\n    condition_number = max_eigval / (np.linalg.norm(P, ord=2) * np.finfo(float).eps)\n    if condition_number > 1e12:\n        warnings.warn(\n            \"Matrix is ill-conditioned, leading to large numerical errors in ECOS. \"\n            \"Consider adding a regularization term. See https://github.com/embotech/ecos-python#ill-conditioned-problems.\",\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n    negative_cutoff = -1e-12 * max_eigval\n    positive_cutoff = 1e-12 * max_eigval\n    eigval = eigval[eigval > negative_cutoff]\n    eigvec = eigvec[:, eigval > negative_cutoff]\n    eigval[eigval < positive_cutoff] = 0.0\n    eigval /= max_eigval\n    L = eigvec * np.sqrt(eigval)\n    return L.T, max_eigval\n\n", "CodeBleu_score": 22.15900416731061}, {"code": "def _decompose(self, P)\n\t\n    eigvals, eigvecs = linalg.eigh(P)\n    max_eigval = eigvals[-1]\n    cond = max_eigval * P.shape[0] / np.finfo(P.dtype).eps\n    if cond > 1e15:\n        warnings.warn(\n            f\"Matrix is close to singular or badly scaled. Results may be inaccurate. \"\n            f\"Condition number: {cond:.2e}.\",\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n\n    # filter out eigenvalues\n    eigvals = eigvals[eigvals > -np.finfo(P.dtype).eps]\n    eigvecs = eigvecs[:, eigvals.shape[0] :]\n    eigvals = eigvals[eigvals < np.finfo(P.dtype).eps]\n    eigvecs = eigvecs[:, : eigvals.shape[0]]\n\n    # normalize\n    eigvals /= max_eigval\n    eigvals = np.sqrt(eigvals)\n\n    return eigvecs.T, max_eigval\n\n", "CodeBleu_score": 28.665530851100474}, {"code": "def _decompose(self, P)\n\t\n    eigvals, eigvecs = linalg.eigh(P)\n    max_eigval = eigvals.max()\n    cond = max_eigval / (P.shape[0] * np.finfo(float).eps)\n    if cond > 1e15:\n        warnings.warn(\n            \"Matrix is ill-conditioned and solution may be inaccurate.\",\n            category=ConvergenceWarning,\n            stacklevel=2,\n        )\n\n    # identify eigenvalues close to zero to avoid numerical problems\n    eps = np.finfo(float).eps\n    eigvals = eigvals[eigvals > -eps * max_eigval]\n    eigvecs = eigvecs[:, eigvals > -eps * max_eigval]\n    eigvals = eigvals[eigvals < eps * max_eigval]\n    eigvecs = eigvecs[:, eigvals < eps * max_eigval]\n\n    # normalize eigenvalues\n    eigvals = eigvals / max_eigval\n    return eigvecs.T, max_eigval\n\n", "CodeBleu_score": 24.050433639896273}]}
{"instance_id": "20c3f5d05d79", "generation_result": [{"code": "def _update_coef(self, coef, D)\n\t\n    self.coef_ = np.zeros(self.n_features_in_)\n        coef = coef.ravel()\n        coef[coef < 1e-10] = 0\n        self.coef_[:] = coef.dot(D)\n\n\n", "CodeBleu_score": 24.056959038668456}, {"code": "def _update_coef(self, coef, D)\n\t\n    self.coef_ = coef[np.abs(coef) > np.finfo(float).eps] * D\n\n", "CodeBleu_score": 19.50473966313967}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef = np.where(np.abs(coef) > 1e-15, coef, 0)\n    self.coef_ = np.multiply(coef, D)\n\n", "CodeBleu_score": 18.13426315479926}]}
{"instance_id": "37c347d00d35", "generation_result": [{"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    # TODO add support for sample weights\n    return coxph_negative_gradient(y_true[\"event\"].astype(np.uint8), y_true[\"time\"], raw_prediction.ravel())\n\n", "CodeBleu_score": 19.23455684722917}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    # TODO add support for sample weights\n    # TODO add support for kwargs\n    event, time = y_true[\"event\"], y_true[\"time\"]\n    grad = coxph_negative_gradient(event, time, raw_prediction.ravel())\n    if sample_weight is not None:\n        grad *= sample_weight\n    return grad\n\n", "CodeBleu_score": 43.729977086110004}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    # TODO add support for sample weights\n    return coxph_negative_gradient(y_true[\"event\"].astype(np.uint8), y_true[\"time\"], raw_prediction.ravel())\n\n", "CodeBleu_score": 19.23455684722917}]}
{"instance_id": "6be432d27e52", "generation_result": [{"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if not np.isfinite(X).all():\n            raise ValueError(\n                \"Input contains NaN, infinity or a value too large for \"\n                \"dtype('float64').\"\n            )\n        return None\n\n    if self.max_features == \"auto\":\n        if estimator_name == \"RandomForestRegressor\":\n            self.max_features = int(np.sqrt(X.shape[1]))\n        else:\n            self.max_features = int(np.log2(X.shape[1]))\n\n    if self.max_features == \"sqrt\":\n        self.max_features = int(np.sqrt(X.shape[1]))\n    elif self.max_features == \"log2\":\n        self.max_features = int(np.log2(X.shape[1]))\n    elif self.max_features is None:\n        self.max_features = X.shape[1]\n\n    if self.min_samples_split == \"auto\":\n        self.min_samples_split = 2\n    elif isinstance(self.min_samples_split, float):\n        self.min_samples_split = int(np.ceil(self.min_samples_split * X.shape[0]))\n\n    if self.min_samples_leaf == \"auto\":\n        self.min_samples_leaf = 1\n    elif isinstance(self.min_samples_leaf, float):\n        self.min_samples_leaf = int(np.ceil(self.min_samples_leaf * X.shape[0]))\n\n    if self.min_weight_fraction_leaf == 0.0:\n        self.min_weight_fraction_leaf = 0.0\n\n    if self.max_leaf_nodes is None:\n        self.max_leaf_nodes = np.iinfo(np.int32).max\n\n    if self.random_state is None:\n        self.random_state = np.random.mtrand._rand\n\n    if self.random_state is np.random.mtrand._rand:\n        self.", "CodeBleu_score": 34.075807212790885}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if np.isfinite(X.data).all():\n            return None\n\n        # If we reach here, we have a dataset with NaNs and we need to find the\n        # features with NaNs.\n        # We can't use np.isnan(X) as it will not work if X is a sparse matrix.\n        # We need to use the following trick:\n        # https://stackoverflow.com/questions/26256284/find-nan-values-in-a-scipy-sparse-matrix-dataset\n        # We use a sparse matrix with the same shape as X and set the diagonal to 1.\n        # We then multiply X by the sparse matrix and if there are any non-zero\n        # elements in the result, it means that there are NaNs in the corresponding\n        # columns of X.\n        # Note that this approach is faster than using np.isnan(X).any(axis=0)\n        # because it only computes the sum for the columns with NaNs.\n        # Also, we use np.isfinite to check for overflow errors.\n        n_samples, n_features = X.shape\n        if issparse(X):\n            missing_values_mask = np.zeros(n_features, dtype=bool)\n            for i in range(n_samples):\n                missing_values_mask |= np.isfinite(X[i].data)\n        else:\n            missing_values_mask = np.isfinite(X).any(axis=0)\n\n        if missing_values_mask.any():\n            if estimator_name is None:\n                estimator_name = self.__class__.__name__\n            raise ValueError(\n                f'Input contains NaN, infinity or a value too large for '\n                f'{estimator_name}.'\n            )\n\n        return missing_values_mask\n\n    return None\n\n", "CodeBleu_score": 40.1735836905307}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if self._get_tags()[\"allow_nan\"]:\n        return None\n\n    if not np.isfinite(X).all():\n        raise ValueError(\n            \"Input contains NaN, infinity or a value too large for \"\n            f\"{estimator_name}. For more information, see \"\n            \"https://scikit-learn.org/stable/modules/preprocessing.html\"\n            \"#imputation-of-missing-values\"\n        )\n\n    try:\n        with np.errstate(invalid=\"ignore\"):\n            X_sum = X.sum(axis=0)\n    except FloatingPointError as e:\n        raise ValueError(\n            \"Input contains infinity or a value too large for \"\n            f\"{estimator_name}. For more information, see \"\n            \"https://scikit-learn.org/stable/modules/preprocessing.html\"\n            \"#imputation-of-missing-values\"\n        ) from e\n\n    if np.isnan(X_sum).any():\n        return np.isnan(X).any(axis=0)\n\n    return None\n\n", "CodeBleu_score": 29.69379982839809}]}
{"instance_id": "dc5bda895a07", "generation_result": [{"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n\n    self._check_low_memory(\"predict_survival_function\")\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n\n    pred = self.tree_.predict(X)\n    arr = pred[..., 1]\n    if return_array:\n        return arr\n    return _array_to_step_function(self.unique_times_, arr)\n\n", "CodeBleu_score": 94.90018669592166}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._check_low_memory(\"predict_survival_function\")\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n\n    pred = self.tree_.predict(X)\n    arr = pred[..., 1]\n    if return_array:\n        return arr\n    return _array_to_step_function(self.unique_times_, arr)\n\n", "CodeBleu_score": 94.90018669592166}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._check_low_memory(\"predict_survival_function\")\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n\n    pred = self.tree_.predict(X)\n    arr = pred[..., 1]\n    if return_array:\n        return arr\n    return _array_to_step_function(self.unique_times_, arr)\n\n", "CodeBleu_score": 94.90018669592166}]}
{"instance_id": "84ae915b5933", "generation_result": [{"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y, dtype=[np.float64, np.float64], ensure_min_samples=2)\n    event, time = y[:, 0], y[:, 1]\n\n    if self.normalize:\n        X_mean = X.mean(0)\n        X_std = X.std(0)\n        X_std[X_std == 0] = 1.0\n        X = (X - X_mean) / X_std\n    else:\n        X_mean = np.zeros(X.shape[1])\n        X_std = np.ones(X.shape[1])\n\n    X = np.asfortranarray(X, dtype=np.float64)\n    time = np.asfortranarray(time, dtype=np.float64)\n    event = np.asfortranarray(event, dtype=np.float64)\n    order = np.argsort(-time, kind=\"mergesort\")\n    X = X[order, :]\n    time = time[order]\n    event = event[order]\n    return X, event, time, X_mean, X_std\n\n", "CodeBleu_score": 29.90973261242017}, {"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y, accept_sparse=[\"csr\", \"csc\"], dtype=np.float64)\n    if y.shape[0] < 2:\n        raise ValueError(\"Need at least 2 samples to train a Cox model.\")\n    event, time = check_array_survival(y)\n    if self.normalize:\n        X = self._center_and_normalize(X)\n    else:\n        X = self._center(X)\n\n    X = np.asfortranarray(X)\n    y = np.asfortranarray(y)\n\n    if self.fit_baseline_model:\n        self._baseline_models = self._fit_baseline_models(X, y)\n\n    return X, event, time\n\n", "CodeBleu_score": 26.4517858258498}, {"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y, dtype=[np.float64, np.float64], ensure_min_samples=2)\n\n    event, time = check_y_survival(y)\n    X = check_array(X, dtype=np.float64, ensure_min_samples=2)\n\n    if self.normalize:\n        X_mean = X.mean(axis=0)\n        X_std = X.std(axis=0)\n        X_std[X_std == 0.0] = 1.0\n        X = (X - X_mean) / X_std\n    else:\n        X_mean = np.zeros(X.shape[1])\n        X_std = np.ones(X.shape[1])\n\n    X = np.asfortranarray(X)\n    time, event = np.broadcast_arrays(time, event)\n\n    order = np.argsort(-time, kind=\"mergesort\")\n    X = X[order]\n    event = event[order]\n    time = time[order]\n\n    return X, event, time, X_mean, X_std\n\n", "CodeBleu_score": 30.377953956323577}]}
{"instance_id": "c70bb013f85f", "generation_result": [{"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if self.n_alphas <= 0 or not isinstance(self.n_alphas, numbers.Integral):\n            raise ValueError(\n                f\"n_alphas must be a positive integer; got (n_alphas={self.n_alphas}).\"\n            )\n        alphas = np.logspace(\n            np.log10(self.alpha_min_ratio_), 0, self.n_alphas, base=10\n        )\n        self.alphas_ = alphas\n        return alphas, True\n\n    alphas = column_or_1d(self.alphas, warn=True)\n    if alphas.ndim > 1:\n        raise ValueError(\n            f\"alphas must be 1D. Got {alphas.ndim}D with shape={alphas.shape}\"\n        )\n    check_non_negative(alphas, \"alphas\")\n    self.alphas_ = alphas\n    return alphas, False\n\n", "CodeBleu_score": 45.3127222102815}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        n_alphas = self.n_alphas\n        if n_alphas < 1 or not isinstance(n_alphas, numbers.Integral):\n            raise ValueError(\n                f\"n_alphas must be a positive integer; got (n_alphas={n_alphas}).\"\n            )\n        alphas = np.empty(n_alphas, dtype=np.float64)\n        alphas[0] = np.max(np.abs(self.coef_.T))\n        if self.alpha_min_ratio == \"auto\":\n            log_alpha_min = np.log(alphas[0])\n            log_alpha_max = np.log(np.max(np.abs(self.coef_)))\n            alphas[1:] = np.geomspace(\n                log_alpha_min, log_alpha_max, num=n_alphas - 1, endpoint=True\n            )\n        else:\n            alpha_min = alphas[0] * self.alpha_min_ratio\n            alphas[1:] = np.geomspace(alpha_min, alphas[0], num=n_alphas - 1)\n        self.alphas_ = alphas\n        return self.alphas_, True\n    else:\n        alphas = column_or_1d(self.alphas, warn=True)\n        check_non_negative(alphas, \"alphas\")\n        self.alphas_ = alphas\n        return self.alphas_, False\n\n", "CodeBleu_score": 42.91892208939895}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        n_alphas = self.n_alphas\n        if n_alphas < 1 or not isinstance(n_alphas, numbers.Integral):\n            raise ValueError(\n                f\"n_alphas must be a positive integer; got {n_alphas}.", "CodeBleu_score": 17.960841593602005}]}
{"instance_id": "7b54a0554ba4", "generation_result": [{"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n    uniq_times = np.unique(time)\n    n_events = np.zeros(uniq_times.shape[0])\n    n_at_risk = np.zeros(uniq_times.shape[0])\n    for i, t in enumerate(uniq_times):\n        n_events[i] = event[time == t].sum()\n        n_at_risk[i] = (time >= t).sum()\n    # account for 0/0 = nan\n    ratio = np.divide(n_events, n_at_risk, out=np.zeros(uniq_times.shape[0], dtype=float), where=n_events != 0)\n    return uniq_times, np.cumsum(ratio)\n\n", "CodeBleu_score": 34.34398638491959}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n    uniq_times = np.unique(time)\n    n_events = np.sum(event, dtype=int)\n    n_at_risk = len(time)\n    n_events = np.cumsum(np.cumsum(event))\n    n_at_risk = np.cumsum(np.ones(n_events.shape))\n    values = np.divide(n_events, n_at_risk)\n    return uniq_times, values\n\n", "CodeBleu_score": 37.465554958428}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n    uniq_times = np.unique(time)\n    n_events = np.sum(event, dtype=int)\n    n_at_risk = len(event)\n    n_events = np.cumsum(np.cumsum(event, axis=0), axis=0)\n    n_at_risk = n_at_risk - np.arange(n_at_risk)\n    assert n_at_risk.shape[0] == n_events.shape[0]\n    assert uniq_times.shape[0] == n_events.shape[0]\n    assert np.all(n_at_risk >= 0)\n    cum_hazard = np.empty(n_events.shape[0], dtype=float)\n    for i in range(n_events.shape[0]):\n        if n_at_risk[i] > 0:\n            cum_hazard[i] = n_events[i] / n_at_risk[i]\n        else:\n            cum_hazard[i] = 0\n    return uniq_times, cum_hazard\n\n", "CodeBleu_score": 33.041419506307165}]}
{"instance_id": "35af806300cc", "generation_result": [{"code": "def ipc_weights(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n    if not np.all(event):\n        uniq_times, prob_survival = kaplan_meier_estimator(~event, time, reverse=True)\n        ix = np.searchsorted(uniq_times, time[event == 1])\n        prob_survival = prob_survival[ix]\n        weights = 1.0 / np.clip(prob_survival, a_min=1e-30, a_max=None)\n    else:\n        weights = np.ones(event.shape[0])\n    return weights\n", "CodeBleu_score": 42.91648630043065}, {"code": "def ipc_weights(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n    if np.all(event):\n        return np.ones(event.shape[0], dtype=float)\n\n    uniq_times, prob_survival = kaplan_meier_estimator(event, time, reverse=True)\n\n    # find index positions of all events\n    km_idx = np.searchsorted(uniq_times, time[event == 1])\n    ipcw = prob_survival[km_idx]\n    ipcw = np.clip(ipcw, a_min=np.finfo(ipcw.dtype).eps, a_max=None)\n\n    weights = np.ones(event.shape[0], dtype=float)\n    weights[event == 1] = ipcw\n    return weights\n", "CodeBleu_score": 44.01309528825957}, {"code": "def ipc_weights(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n\n    if not np.all(event):\n        uniq_times, prob_survival = kaplan_meier_estimator(~event, time, reverse=True)\n        ix = np.searchsorted(uniq_times, time)\n        prob_survival = prob_survival[ix]\n        prob_survival = np.clip(prob_survival, a_min=np.finfo(float).eps, a_max=None)\n        weights = 1.0 / prob_survival\n    else:\n        weights = np.ones_like(event, dtype=float)\n\n    return weights\n\n\n", "CodeBleu_score": 38.72424789021653}]}
{"instance_id": "72b19985ea11", "generation_result": [{"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame) or isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n\n    dfs_list = []\n\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            dfs_list.append(PandasConnector(df))\n        elif isinstance(df, BaseConnector):\n            dfs_list.append(df)\n        elif isinstance(df, modin.pandas.DataFrame):\n            dfs_list.append(PandasConnector(df))\n        elif isinstance(df, pl.DataFrame):\n            dfs_list.append(PandasConnector(df))\n        else:\n            raise ValueError(\n                f\"Invalid data type {type(df)}. Expected pandas, modin, or polars dataframe.\"\n            )\n\n    return dfs_list\n\n", "CodeBleu_score": 33.720405349660936}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if not isinstance(dfs, list):\n        dfs = [dfs]\n\n    connector_list = []\n\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, BaseConnector):\n            connector_list.append(df)\n        elif isinstance(df, pd.io.parsers.TextFileReader):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.io.formats.style.Styler):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.groupby.generic.DataFrameGroupBy):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.groupby.DataFrameGroupBy):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.RollingGroupby):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.Rolling):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.ExpandingGroupby):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.Expanding):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.Window):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.ExponentialMovingWindow):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.ExponentialMovingWindowGroupby):\n            connector_list.append(PandasConnector(df))\n        elif isinstance(df, pd.core.window.ExponentialMoving", "CodeBleu_score": 45.6687111488663}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if not isinstance(dfs, list):\n        dfs = [dfs]\n\n    connectors = []\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            connectors.append(PandasConnector(df))\n        elif isinstance(df, BaseConnector):\n            connectors.append(df)\n        elif isinstance(df, pd.io.parsers.TextFileReader):\n            connectors.append(PandasConnector(df.read()))\n        elif isinstance(df, pd.io.parsers.readers.TextParser):\n            connectors.append(PandasConnector(df.read()))\n        elif isinstance(df, pd.io.parsers.readers.StringIO):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringParser):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringIO):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringParser):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringIO):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringParser):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringIO):\n            connectors.append(PandasConnector(pd.read_csv(df)))\n        elif isinstance(df, pd.io.parsers.readers.StringParser):\n            connectors.append(PandasConnector(pd.read_", "CodeBleu_score": 46.077360703390845}]}
{"instance_id": "cf22fb696e90", "generation_result": [{"code": "def execute(self) -> pd.DataFrame\n\t\n    cached = self._cached()\n    if cached is not None:\n        return pd.read_parquet(cached)\n\n    cached_with_filters = self._cached(include_additional_filters=True)\n    if cached_with_filters is not None:\n        return pd.read_parquet(cached_with_filters)\n\n    if isinstance(self._instance, pd.DataFrame):\n        return self._instance\n\n    self._instance = self._fetch_data()\n    return self._instance\n\n", "CodeBleu_score": 62.10008715819285}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._instance is not None and isinstance(self._instance, pd.DataFrame):\n        return self._instance\n\n    cached_path = self._cached()\n    if cached_path is not None:\n        return pd.read_parquet(cached_path)\n\n    if self._additional_filters is not None and len(self._additional_filters) > 0:\n        cached_path = self._cached(include_additional_filters=True)\n        if cached_path is not None:\n            return pd.read_parquet(cached_path)\n\n    if self._instance is None:\n        self._instance = self._fetch_data()\n        self._save_cache(self._instance)\n\n    return self._instance\n\n", "CodeBleu_score": 58.40610498354195}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    # Check if there is a cached version of the data\n    if self._cached():\n        return pd.read_parquet(self._cached())\n    elif self._cached(include_additional_filters=True):\n        return pd.read_parquet(self._cached(include_additional_filters=True))\n    # If the instance variable is already a DataFrame, return it\n    elif isinstance(self._instance, pd.DataFrame):\n        return self._instance\n    # Otherwise, fetch the data\n    else:\n        self._instance = self.fetch()\n        return self._instance\n\n", "CodeBleu_score": 63.02412530887773}]}
{"instance_id": "21df5ecea95f", "generation_result": [{"code": "def column_hash(self)\n\t\n    if isinstance(self._instance, pd.DataFrame):\n        cols = \"|\".join(self._instance.columns)\n        formula = \"|\".join(self._formula) if self._formula else \"\"\n        return sha256(f\"{cols}|{formula}\".encode()).hexdigest()\n    else:\n        self._instance = self.execute()\n        return self.column_hash\n\n", "CodeBleu_score": 46.09280287600357}, {"code": "def column_hash(self)\n\t\n    if isinstance(self._instance, pd.DataFrame):\n        columns_string = \"|\".join(self._instance.columns)\n        formula_string = self._formula or \"\"\n        combined_string = columns_string + formula_string\n        return hashlib.sha256(combined_string.encode()).hexdigest()\n    else:\n        data = self.execute()\n        columns_string = \"|\".join(data.columns)\n        formula_string = self._formula or \"\"\n        combined_string = columns_string + formula_string\n        return hashlib.sha256(combined_string.encode()).hexdigest()\n\n", "CodeBleu_score": 39.06784974988706}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self.execute()\n    column_names = \"|\".join(self._instance.columns)\n    formula_string = self._build_formula()\n    combined_string = f\"{column_names}|{formula_string}\"\n    return sha256(combined_string.encode(\"utf-8\")).hexdigest()\n\n", "CodeBleu_score": 70.97546615597267}]}
{"instance_id": "27ee5f415000", "generation_result": [{"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        self.df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        self.df = df\n    elif isinstance(df, list):\n        self.df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        self.df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        self.df = FileImporter(df).get_df()\n    else:\n        raise ValueError(\n            f\"Unsupported type for df: {type(df)}. Supported types are: pandas.DataFrame, pandas.Series, str, list, dict.\"\n        )\n\n", "CodeBleu_score": 50.151725196397855}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        self.pandas_df = pd.DataFrame(df)\n    elif isinstance(df, pd.DataFrame):\n        self.pandas_df = df\n    elif isinstance(df, list):\n        self.pandas_df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        self.pandas_df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        self.pandas_df = FileImporter.import_file(df)\n    else:\n        raise ValueError(f\"Unsupported data type: {type(df)}\")\n\n", "CodeBleu_score": 47.055833399336755}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.DataFrame):\n        self.df = df\n    elif isinstance(df, pd.Series):\n        self.df = df.to_frame()\n    elif isinstance(df, list):\n        self.df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        self.df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        self.df = FileImporter.load_file(df)\n    else:\n        raise ValueError(\n            \"The input data must be a pandas DataFrame, pandas Series, list, or dict.\"\n        )\n\n", "CodeBleu_score": 51.94083272546221}]}
{"instance_id": "38f48a358606", "generation_result": [{"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if len(self.df) <= n:\n            return self.df.sample(frac=1).reset_index(drop=True)\n\n        # Sample each column individually\n        samples = []\n        for col in self.df.columns:\n            if self.df[col].dtype == 'object':\n                samples.append(self.sample_column(col, n))\n            else:\n                samples.append(self.sample_numeric_column(col, n))\n\n        # Combine the samples into a new DataFrame\n        sampled_df = pd.concat(samples, axis=1)\n\n        # Anonymize the first few rows of the sampled DataFrame\n        anonymizer = Anonymizer()\n        anonymized_df = anonymizer.anonymize_df(sampled_df)\n        return anonymized_df.head(n)\n\n\n    def sample_column(self, col: str, n: int) -> pd.Series:\n        \\\"\\\"\\\"\n        Args:\n            col (str): The name of the column to sample.\n            n (int): The number of samples to generate.\n        Returns:\n            pd.Series: A new Series containing the sampled values.\n        \\\"\\\"\\\"\n        # Get the unique values in the column\n        unique_values = self.df[col].unique()\n\n        # Calculate the probabilities for each unique value\n        probs = [len(self.df[self.df[col] == val]) / len(self.df) for val in unique_values]\n\n        # Sample n values from the unique values with the calculated probabilities\n        sampled_values = np.random.choice(unique_values, size=n, p=probs)\n\n        # Return the sampled values as a new Series\n        return pd.Series(sampled_values)\n\n\n    def sample_numeric_column(self, col: str, n: int) -> pd.Series:\n        \\\"\\\"\\\"\n        Args:\n            col (str): The name of the column to sample.\n            n (int): The number of samples", "CodeBleu_score": 37.98695057558874}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if len(self.df) <= n:\n            return self.df.sample(frac=1).reset_index(drop=True)\n\n        # sample each column individually\n        sampled_columns = []\n        for col in self.df.columns:\n            if self.df[col].dtype == object:\n                # sample categorical column\n                sampled_columns.append(self.sample_categorical_column(col, n))\n            elif self.df[col].dtype in [np.int64, np.float64]:\n                # sample numerical column\n                sampled_columns.append(self.sample_numerical_column(col, n))\n            else:\n                # sample other column\n                sampled_columns.append(self.df[col].sample(n))\n\n        # combine sampled columns into a new DataFrame\n        sampled_df = pd.concat(sampled_columns, axis=1)\n\n        # anonymize first few rows of sampled DataFrame\n        anonymizer = Anonymizer()\n        sampled_df = anonymizer.anonymize(sampled_df.head(n))\n\n        return sampled_df\n\n    def sample_categorical_column(self, col: str, n: int) -> pd.Series:\n        \\\"\\\"\\\"\n        Args:\n            col (str): column name to sample from.\n            n (int): number of rows to sample.\n        \\\"\\\"\\\"\n        # get unique values in column\n        unique_values = self.df[col].unique()\n\n        # sample values from column\n        sampled_values = random.sample(list(unique_values), k=n)\n\n        # create new Series with sampled values\n        sampled_series = pd.Series(sampled_values, name=col)\n\n        return sampled_series\n\n    def sample_numerical_column(self, col: str, n: int) -> pd.Series:\n        \\\"\\\"\\\"\n        Args:\n            col (str): column name to sample from.\n            n (int): number of rows to sample.\\", "CodeBleu_score": 37.23811928959144}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    if len(self.df) <= n:\n        return self.df.sample(frac=1).reset_index(drop=True)\n    else:\n        sample_df = pd.DataFrame()\n        for col in self.df.columns:\n            if self.df[col].dtype == 'object':\n                sample_df[col] = self.sample_column(self.df[col], n)\n            else:\n                sample_df[col] = self.sample_numeric_column(self.df[col], n)\n        sample_df = Anonymizer(sample_df).anonymize()\n        return sample_df.head(n)\n\n", "CodeBleu_score": 46.07228076307616}]}
{"instance_id": "8bddad2e31ca", "generation_result": [{"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    if not extras:\n        extras = {}\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    result = f\"<DataFrame name='{name}' description='{description}'>", "CodeBleu_score": 27.781283183545852}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    df_str = df.to_csv(index=False)\n    df_str = df_str.replace(\"", "CodeBleu_score": 21.11268110079213}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    if extras is None:\n        extras = {}\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    result = f\"<DataFrame name='{name}' description='{description}'>", "CodeBleu_score": 28.084376906310602}]}
{"instance_id": "5380bb60fd39", "generation_result": [{"code": "def convert_df_sql_connector_to_str\n\t\n    table_html = f\"<table name=\\\"{df.name}\\\"\"\n    if df.description is not None:\n        table_html += f\" description=\\\"{df.description}\\\"\"\n    table_html += \">", "CodeBleu_score": 19.09574081387566}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Construct the opening table tag with the table name and optional description\n    html = f\"<table name=\\\"{df.name}\\\"\"\n    if df.description is not None:\n        html += f\" description=\\\"{df.description}\\\"\"\n    html += \">\"\n\n    # Add the CSV representation of the DataFrame's head\n    html += df.head().to_csv(index=False)\n\n    # Close the table tag\n    html += \"</table>\"\n\n    return html\n\n", "CodeBleu_score": 37.933163211252015}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Initialize an empty string to store the HTML table\n    html_table = \"\"\n\n    # Add the opening table tag with the table name and optional description\n    html_table += f\"<table name=\\\"{df.name}\\\" \"\n    if df.description is not None:\n        html_table += f\"description=\\\"{df.description}\\\" \"\n    html_table += \">", "CodeBleu_score": 20.801625432777115}]}
{"instance_id": "0afd995716c5", "generation_result": [{"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_data = self.convert_df_to_json(df, extras)\n    yaml_data = yaml.dump(json_data, default_flow_style=False)\n\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return f\"<table>", "CodeBleu_score": 70.19030345513929}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_data = self.convert_df_to_json(df, extras)\n    yml_data = yaml.dump(json_data)\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return yml_data\n    return f\"<dataframe>", "CodeBleu_score": 63.49537427367737}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    df_json = self.convert_df_to_json(df, extras)\n    df_yaml = yaml.dump(df_json)\n\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return df_yaml\n\n    return f\"<table>", "CodeBleu_score": 62.43895653114053}]}
{"instance_id": "e2b90ebd4e5d", "generation_result": [{"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    if expected_type == \"number\":\n        return isinstance(self, (int, float))\n    if expected_type == \"string\":\n        return isinstance(self, str)\n    if expected_type == \"dataframe\":\n        return isinstance(self, (pd.DataFrame, pd.Series))\n    if expected_type == \"plot\":\n        return isinstance(self, str) and re.match(r\"^plots\\/.+\\.png$\", self) or isinstance(self, dict)\n    raise InvalidOutputValueMismatch(expected_type, self)", "CodeBleu_score": 67.54037106153378}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self, str) and re.match(r\"^plots/.*\\.png$\", self) or isinstance(self, dict)\n    else:\n        return False\n\n", "CodeBleu_score": 73.39103849263732}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self, (str, dict)) and (\n            re.match(r\"^filepath:.*\", self) or isinstance(self, dict)\n        )\n    else:\n        raise InvalidOutputValueMismatch(\n            f\"Invalid expected_type value: {expected_type}. Expected one of 'number', 'string', 'dataframe', 'plot'.\"\n        )\n\n", "CodeBleu_score": 74.05186255992139}]}
{"instance_id": "d95828fdcbcb", "generation_result": [{"code": " def _distance(self, X, X2=None)\n\t\n    if self.distance_params is None:\n        self.distance_params = {}\n\n    if isinstance(self.distance, str):\n        metric = pairwise_distance(metric=self.distance, **self.distance_params)\n    else:\n        metric = self.distance\n\n    if X2 is None:\n        if len(signature(metric).parameters) == 1:\n            return metric(X)\n        else:\n            return metric(X, X)\n    else:\n        return metric(X, X2)\n\n", "CodeBleu_score": 29.534944805594606}, {"code": " def _distance(self, X, X2=None)\n\t\n    if self.distance_params is None:\n        self.distance_params = {}\n\n    if isinstance(self.distance, str):\n        metric = pairwise_distance(metric=self.distance, **self.distance_params)\n    else:\n        metric = self.distance\n\n    if X2 is None:\n        if len(signature(metric).parameters) == 1:\n            return metric(X)\n        else:\n            return metric(X, X)\n    else:\n        return metric(X, X2)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.534944805594606}, {"code": " def _distance(self, X, X2=None)\n\t\n    if self.distance_params is None:\n        self.distance_params = {}\n\n    if isinstance(self.distance, str):\n        metric = pairwise_distance(metric=self.distance, **self.distance_params)\n    else:\n        metric = self.distance\n\n    if X2 is None:\n        # if the distance function can handle a single dataset,\n        # we don't need to pass X2\n        if \"X\" in signature(metric).parameters:\n            return metric(X=X)\n        else:\n            return metric(X)\n    else:\n        return metric(X, X2)\n\n\n", "CodeBleu_score": 28.373221939996785}]}
{"instance_id": "497d73b298ee", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, np.ndarray):\n        X = X.reset_index(drop=True)\n        X = X.pivot(columns=\"dim_0\", values=\"value\")\n        X = X.fillna(0)\n        X = X.to_numpy()\n    else:\n        if self.is_equal_length:\n            if X.ndim == 2:\n                X = X.flatten()\n            else:\n                X = X.flatten()\n        else:\n            lengths = X.shape[1]\n            X = np.concatenate((np.full((X.shape[0], 1), lengths), X), axis=1)\n            X = X.flatten()\n    return X\n\n", "CodeBleu_score": 41.78537069220667}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.is_equal_length:\n        # if equal length, we can just convert to numpy array\n        if isinstance(X, np.ndarray):\n            return X.flatten()\n        elif isinstance(X, pd.DataFrame):\n            return X.to_numpy().flatten()\n        else:\n            raise ValueError(\n                \"X must be a numpy array or pandas DataFrame, \"\n                \"but found: {}\".format(type(X))\n            )\n    else:\n        # if unequal length, we need to reset the index, pivot, fill missing values, convert to numpy array, and concatenate the lengths as the first column\n        X = X.reset_index(drop=True)\n        X = X.pivot(index=\"index\", columns=\"dim_0\", values=\"value\")\n        X = X.fillna(0)\n        X = X.to_numpy()\n        X_len = X.shape[0]\n        X = np.concatenate((np.array([X_len]), X.flatten()))\n        return X\n\n", "CodeBleu_score": 38.82972670186973}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.is_equal_length:\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy()\n        elif isinstance(X, pd.Series):\n            X = X.to_numpy().reshape(-1, 1)\n        elif isinstance(X, np.ndarray):\n            if X.ndim == 3:\n                X = X.reshape(X.shape[0], -1)\n            elif X.ndim == 2:\n                pass\n            else:\n                raise ValueError(\n                    \"X must be a 2D or 3D numpy array or a pandas DataFrame or Series.\"\n                )\n        else:\n            raise ValueError(\n                \"X must be a 2D or 3D numpy array or a pandas DataFrame or Series.\"\n            )\n    else:\n        if isinstance(X, pd.DataFrame):\n            X = X.copy()\n            X.index = X.index.set_levels(X.index.levels[1].astype(int), level=1)\n            X = X.pivot(columns=X.index.names[0], values=X.columns[0]).fillna(0)\n            X = X.to_numpy()\n        elif isinstance(X, pd.Series):\n            X = X.copy()\n            X.index = X.index.set_levels(X.index.levels[1].astype(int), level=1)\n            X = X.reset_index()\n            X = X.pivot(columns=X.columns[0], values=X.columns[1]).fillna(0)\n            X = X.to_numpy()\n        elif isinstance(X, np.ndarray):\n            if X.ndim == 3:\n                X = X.reshape(X.shape[0], -1)\n            elif X.ndim == 2:\n                pass\n            else:\n                raise ValueError(\n                    \"X must be a 2D or 3D numpy array or a pandas DataFrame or Series.\"\n                )\n        else:\n           ", "CodeBleu_score": 33.895836177561655}]}
{"instance_id": "8798260a6f12", "generation_result": [{"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n", "CodeBleu_score": 21.783043010906173}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n", "CodeBleu_score": 21.783043010906173}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isclass(obj):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n", "CodeBleu_score": 21.783043010906173}]}
{"instance_id": "2ab2596d8520", "generation_result": [{"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return SklearnRegressorPipeline(\n            regressor=self.regressor,\n            transformers=[other] + self.transformers,\n        )\n    else:\n        return NotImplemented\n", "CodeBleu_score": 26.796140754007897}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return SklearnRegressorPipeline(\n            regressor=self.regressor,\n            transformers=other * self.transformers,\n        )\n    else:\n        return NotImplemented\n\n", "CodeBleu_score": 28.066438045535584}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return SklearnRegressorPipeline(\n            regressor=self.regressor,\n            transformers=[other] + self.transformers_,\n        )\n    else:\n        return NotImplemented\n\n", "CodeBleu_score": 26.84104832655438}]}
{"instance_id": "5c1c6d14ca93", "generation_result": [{"code": "def prep_skl_df(df, copy_df=False)\n\t\n    df = df.copy() if copy_df else df\n    df.columns = df.columns.astype(str)\n    assert all([isinstance(x, str) for x in df.columns])\n    return df\n\n", "CodeBleu_score": 25.840390703899622}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    df = df.copy() if copy_df else df\n    col_names = df.columns\n    col_names = [str(col) for col in col_names]\n    df.columns = col_names\n    if not np.all([isinstance(col, str) for col in df.columns]):\n        raise ValueError(\"Column names must be strings\")\n    return df\n", "CodeBleu_score": 31.25831293218197}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    col_names = df.columns\n    col_names = [str(x) for x in col_names]\n    if not np.all([isinstance(x, str) for x in col_names]):\n        if copy_df:\n            df = df.copy()\n        df.columns = col_names\n    return df", "CodeBleu_score": 50.644161647571664}]}
{"instance_id": "d5e567c20361", "generation_result": [{"code": "def predict(self, X)\n\t\n    check_is_fitted(self, \"_is_fitted\")\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif isinstance(X, pd.DataFrame) and len(X.shape) == 2:\n        X = X.to_numpy()\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"RotationForest is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required. \"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False)\n\n    if X.shape[1] != self.n_atts:\\\n        raise ValueError(\n            \"Number of attributes in the train set does not match that in test set\"\n        )\n\n    rng = check_random_state(self.random_state)\n\n    # normalise attributes\n    X = (X - self._min) / self._ptp\n\n    # initialise predictions\n    y_pred = np.zeros(X.shape[0])\n\n    # make predictions\n    for i in range(X.shape[0]):\n        # obtain predictions\n        preds = np.zeros((self.n_estimators, self.n_classes_))\n        for j in range(self.n_estimators):\n            preds[j] = self.estimators_[j].predict_proba(\n                self._transform(X[i].reshape(1, -1), self._pcas[j], self._groups[j])\n            )\n\n        # obtain max preds\n        max_preds_idx = np.argmax(preds, axis=1)\n        unq, cts = np.unique(max_preds_idx, return_counts=True)\n\n        # randomly choose one if more than one index has max prediction\n        if unq.shape", "CodeBleu_score": 38.122647357292344}, {"code": "def predict(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f'This {self.__class__.__name__} instance is not fitted yet. Call `fit` before calling `predict`.'\n        )\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif isinstance(X, pd.DataFrame) and len(X.shape) == 2:\n        X = X.to_numpy()\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            'RotationForest is not a time series classifier. '\n            'A valid sklearn input such as a 2d numpy array is required. '\n            'Sparse input formats are currently not supported.'\n        )\n\n    rng = check_random_state(self.random_state)\n\n    X = X[:, self._useful_atts]\n    X = (X - self._min) / self._ptp\n\n    probs = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(self._n_estimators):\n        preds = self.estimators_[i].predict_proba(X)\n        probs += preds\n\n        if self.save_transformed_data:\n            self.transformed_data_.append(X)\n\n        preds = np.argmax(probs, axis=1)\n        return np.array([self._class_dictionary[x] for x in preds])\n\n    def _fit_estimator(self, X, X_cls_split, y, i):\n        \\\"\\\"\\\"Fit a single estimator on the input data X and target y. The estimator is fitted on a randomly selected subset of the data, and its predictions are used to update the weights of the samples in the input data. The function returns the fitted estimator, the PCA object used for dimensionality reduction, the selected group size, and the transformed data.\n", "CodeBleu_score": 37.043648321922156}, {"code": "def predict(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f'This instance of {self.__class__.__name__} has not '\n            f'been fitted yet; please call `fit` before calling '\n            f'`predict`.'\n        )\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif isinstance(X, pd.DataFrame) and len(X.shape) == 2:\n        X = X.to_numpy()\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            'RotationForest is not a time series classifier. '\n            'A valid sklearn input such as a 2d numpy array is required.'\n            'Sparse input formats are currently not supported.'\n        )\n    X = self._validate_data(X=X, reset=False)\n\n    rng = check_random_state(self.random_state)\n\n    # normalise attributes\n    X = (X - self._min) / self._ptp\n    X = X[:, self._useful_atts]\n\n    # predict\n    preds = np.zeros(X.shape[0], dtype=int)\n    for i in range(self._n_estimators):\n        preds += self.estimators_[i].predict(self.transformed_data_[i])\n    preds /= self._n_estimators\n\n    # select the most probable class label\n    for i in range(preds.shape[0]):\n        max_indices = np.argwhere(preds[i] == np.amax(preds[i])).flatten()\n        preds[i] = rng.choice(max_indices)\n\n    # map to class labels\n    preds = np.array([self.classes_[i] for i in preds])\n\n    return preds\n\n", "CodeBleu_score": 38.346445160386565}]}
{"instance_id": "210b60dffd55", "generation_result": [{"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_t = np.concatenate(\n        [pcas[i].transform(X[:, group]) for i, group in enumerate(groups)], axis=1\n    )\n    X_t = np.nan_to_num(X_t, False, 0, 0, 0)\n    y_probas = clf.predict_proba(X_t)\n\n    # adjust for missing values\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas_new = np.zeros((len(X), self.n_classes_))\n        for i in range(len(y_probas)):\n            y_probas_new[i, : y_probas.shape[1]] = y_probas[i]\n        y_probas = y_probas_new\n\n    return y_probas\n\n", "CodeBleu_score": 45.04086024450758}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_t = np.concatenate(\n        [pcas[i].transform(X[:, group]) for i, group in enumerate(groups)], axis=1\n    )\n    X_t = np.nan_to_num(X_t, False, 0, 0, 0)\n    y_proba = clf.predict_proba(X_t)\n\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba = np.zeros((y_proba.shape[0], self.n_classes_))\n        for i in range(y_proba.shape[0]):\n            y_proba[i, : y_proba.shape[1]] = y_proba[i]\n\n    return y_proba\n\n", "CodeBleu_score": 42.30332276045571}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_t = np.concatenate(\n        [pcas[i].transform(X[:, group]) for i, group in enumerate(groups)], axis=1\n    )\n    X_t = np.nan_to_num(X_t, False, 0, 0, 0)\n    y_proba = clf.predict_proba(X_t)\n\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba = np.zeros((X.shape[0], self.n_classes_))\n        for i, group in enumerate(groups):\n            for j in range(self.n_classes_):\n                y_proba[:, j] += np.sum(\n                    y_proba[:, self._class_dictionary[j]] * X[:, group], axis=1\n                )\n\n    return y_proba\n\n", "CodeBleu_score": 48.87754493741618}]}
{"instance_id": "9436ee0860bb", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    if self.n_classes_ == 1:\n        return np.ones((X.shape[0], 1))\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required. \"\n            \"Sparse input formats are currently not supported.\"\n        )\n\n    X = self._validate_data(\n        X=X, ensure_min_samples=1, force_all_finite=\"allow-nan\"\n    )\n\n    rng = check_random_state(self.random_state)\n    return np.array(\n        [\n            self._root.predict_proba(X[i, :], rng)\n            for i in range(X.shape[0])\n        ]\n    )\n\n", "CodeBleu_score": 73.99557941068392}, {"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    if self.n_classes_ == 1:\n        return np.ones(shape=(len(X), 1))\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required. \"\n            \"Sparse input formats are currently not supported.\"\n        )\n\n    X = self._validate_data(X=X, ensure_min_samples=1, force_all_finite=\"allow-nan\")\n\n    rng = check_random_state(self.random_state)\n    return np.array(\n        [\n            self._root.predict_proba(X[i, :], rng)\n            for i in range(X.shape[0])\n        ]\n    )\n\n", "CodeBleu_score": 74.1602512519732}, {"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(f\"This instance of {self.__class__.__name__} has not \" f\"been fitted yet; please call `fit` first.\")\n    if self.n_classes_ == 1:\n        return np.ones(shape=(len(X), 1))\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required. \"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    rng = check_random_state(self.random_state)\n    distributions = []\n    for i in range(len(X)):\n        distributions.append(self._root.predict_proba(X[i]))\n\n    return np.array(distributions)\n\n", "CodeBleu_score": 73.3459603427551}]}
{"instance_id": "d7cb1cb66840", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    Xt = self.transformers_.fit_transform(X)\n    scitype = scitype(Xt)\n    if scitype == \"Primitives\":\n        return convert(Xt, \"Table\")\n    elif scitype == \"Series\":\n        return convert(Xt, \"Panel\")\n    else:\n        raise TypeError(\n            \"unexpected output type from transformers, should be Primitives or Series\"\n        )\n\n", "CodeBleu_score": 21.697685767595026}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    Xt = self.transformers_.fit_transform(X)\n    Xt = convert(Xt, from_type=\"nested_univ\", to_type=\"numpyflat\")\n    return Xt\n\n", "CodeBleu_score": 8.073695454079774}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    Xt = self.transformers_.transform(X)\n    scitype = scitype(Xt)\n    if scitype == \"Primitives\":\n        Xt = convert(Xt, \"Table\")\n    elif scitype == \"Series\":\n        Xt = convert(Xt, \"Panel\")\n    else:\n        raise TypeError(\n            f\"unexpected output type: {scitype}, expected Series or Primitives\"\n        )\n    return Xt\n\n", "CodeBleu_score": 31.467502565150113}]}
{"instance_id": "497cb75f2b4d", "generation_result": [{"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    new_params = {}\n    for param in estimator.get_params():\n        if param.endswith('random_state'):\n            new_params[param] = random_state.randint(np.iinfo(np.int32).max)\n    if new_params:\n        estimator.set_params(**new_params)\n    return estimator\n", "CodeBleu_score": 42.77609468842128}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params_to_update = {}\n    for param in estimator.get_params():\n        if param.endswith(\"random_state\"):\n            params_to_update[param] = random_state.randint(np.iinfo(np.int32).max)\n    if params_to_update:\n        estimator.set_params(**params_to_update)\n    return estimator", "CodeBleu_score": 42.535519726307555}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    params = dict()\n    for key in estimator.get_params(deep=True):\n        if key == 'random_state':\n            params['random_state'] = random_state.randint(np.iinfo(np.int32).max)\n        elif key.endswith('__random_state'):\n            nested_key = key.replace('__random_state', '')\n            if (nested_key in estimator.get_params(deep=True)) and (estimator.get_params(deep=True)[nested_key] is not None):\n                params[key] = random_state.randint(np.iinfo(np.int32).max)\n    if len(params) > 0:\n        estimator.set_params(**params)\n", "CodeBleu_score": 42.8892884504822}]}
{"instance_id": "59ffd1d596a1", "generation_result": [{"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = intervals.shape[0]\n    transformed = np.zeros((n_instances, n_intervals * 3))\n    for interval_index in range(n_intervals):\n        start = intervals[interval_index, 0]\n        end = intervals[interval_index, 1]\n        size = end - start\n        x_mean = X[:, start:end].mean(axis=1)\n        x_std = X[:, start:end].std(axis=1)\n        x_slope = (\n            (X[:, start + 1 : end + 1] - X[:, start : end - 1]).sum(axis=1) / size\n        )\n        transformed[:, interval_index * 3] = x_mean\n        transformed[:, interval_index * 3 + 1] = x_std\n        transformed[:, interval_index * 3 + 2] = x_slope\n    return transformed.T\n\n", "CodeBleu_score": 27.862925815418656}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = intervals.shape[0]\n    transformed = np.zeros((n_instances, n_intervals * 3))\n    for interval_index in range(n_intervals):\n        start = intervals[interval_index, 0]\n        end = intervals[interval_index, 1]\n        size = end - start\n        X_slice = X[:, start:end]\n        means = np.mean(X_slice, axis=1)\n        std_devs = np.std(X_slice, axis=1)\n        slope = np.apply_along_axis(lambda x: _slope(x, size), 1, X_slice)\n        transformed[:, interval_index * 3] = means\n        transformed[:, interval_index * 3 + 1] = std_devs\n        transformed[:, interval_index * 3 + 2] = slope\n    return transformed.T\n\n", "CodeBleu_score": 38.45569758047665}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, _ = X.shape\n    n_intervals = intervals.shape[0]\n    transformed = np.zeros((n_instances, n_intervals * 3))\n    for interval_index in range(n_intervals):\n        start = intervals[interval_index, 0]\n        end = intervals[interval_index, 1]\n        X_slice = X[:, start:end]\n        means = np.mean(X_slice, axis=1)\n        stds = np.std(X_slice, axis=1)\n        slope = np.apply_along_axis(lambda x: _fit_slope(x, x), 1, X_slice)\n        transformed[:, 3 * interval_index] = means\n        transformed[:, 3 * interval_index + 1] = stds\n        transformed[:, 3 * interval_index + 2] = slope\n    return transformed.T\n\n", "CodeBleu_score": 41.084236450685694}]}
{"instance_id": "5a01594eebfb", "generation_result": [{"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n\n    # Initialize annotation and operation parameters if they are not provided\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    plot_func = getattr(sns, plot)\n    ax = plot_func(**plot_params)\n    for ax_op in ax_op_before:\n        self._apply_axis_operation(ax, ax_op)\n\n    # Configure and annotate the plot based on provided configuration and annotation functions\n    self._configure_plot(ax, configuration)\n    annotate_func = getattr(self, annotation_func)\n    annotate_func(ax, *args, **annotation_params, **annotate_params)\n\n    # Apply post-plot axis operations\n    for ax_op in ax_op_after:\n        self._apply_axis_operation(ax, ax_op)\n\n    # Return the output of the plotting process\n    return ax\n\n", "CodeBleu_score": 49.71074923194255}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n\n    if annotate_params is None:\n        annotate_params = {}\n\n    if ax_op_before is None:\n        ax_op_before = []\n\n    if ax_op_after is None:\n        ax_op_after = []\n\n    if annotation_params is None:\n        annotation_params = {}\n\n    if self._verbose >= 1:\n        print(f\\\"Plotting {plot} with {plot_params}\\\")\n\n    self._maybe_warn_about_configuration()\n\n    if self._plotter is None:\n        self._plotter = self._get_plotter(self._engine, self.fig, self.ax,\n                                          self._plot_engine_kwargs)\n\n    if self._plotter.is_plot_created():\n        self._plotter.reset_plot()\n\n    self._plotter.plot(plot, plot_params)\n\n    if ax_op_before:\n        self._plotter.apply_ax_ops(ax_op_before)\n\n    if configuration:\n        self._plotter.configure(configuration)\n\n    if annotation_func is not None:\n        self._plotter.annotate(annotation_func, *args,\n                               annotation_params=annotation_params,\n                               annotate_params=annotate_params, **kwargs)\n\n    if ax_op_after:\n        self._plotter.apply_ax_ops(ax_op_after)\n\n    return self._plotter.get_output()\n\n", "CodeBleu_score": 45.481599395961695}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n\n    self.plot(plot, plot_params, *args, **kwargs)\n\n    for ax_op in ax_op_before:\n        self.apply_ax_op(ax_op)\n\n    self.configure(configuration)\n    self.annotate(annotation_func, annotation_params)\n\n    for ax_op in ax_op_after:\n        self.apply_ax_op(ax_op)\n\n    return self.output\n\n", "CodeBleu_score": 46.186421557374864}]}
{"instance_id": "b5b17d312c74", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('Cannot predict before fit.')\n    X = check_array(X)\n    if X.shape[1] != self._n_features_in:\n        raise ValueError(\n            'X has %d features per sample; expecting %d.' %\n            (X.shape[1], self._n_features_in))\n    scores = self._execute_program(X)\n    scores = self._transform_scores(scores)\n    return np.array([1 - scores, scores]).T\n\n", "CodeBleu_score": 37.621926211280595}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('The model has not been fitted.')\n    X = check_array(X)\n    if X.shape[1] != self._n_features_in:\n        raise ValueError('The input data has a different number of features than the model.')\n    scores = self._program.execute(X)\n    scores = self._transformer.transform(scores)\n    scores = np.array([1 - scores, scores]).T\n    return scores\n\n", "CodeBleu_score": 47.35227471813786}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('Cannot predict class probabilities. The model has not been fitted.')\n    X = check_array(X)\n    if X.shape[1] != self._n_features_in:\n        raise ValueError(f'X has {X.shape[1]} features per sample; expected {self._n_features_in}')\n    scores = self._execute_program(X)\n    scores = self._transformer(scores)\n    probs = np.zeros((X.shape[0], 2))\n    probs[:, 1] = scores\n    probs[:, 0] = 1 - scores\n    return probs\n\n", "CodeBleu_score": 45.48964058068127}]}
{"instance_id": "83f71c959df7", "generation_result": [{"code": "def point_mutation(self, random_state)\n\t\n    program = self.reproduce()\n    # Identify nodes to modify\n    mutation_probability = 1. / self.max_height\n    mutation_mask = random_state.uniform(size=len(program)) < mutation_probability\n    mutation_points = np.where(mutation_mask)[0]\n    # Replace nodes\n    for point in mutation_points:\n        node = program[point]\n        if isinstance(node, _Function):\n            arity = node.arity\n            # Find a function with the same arity\n            candidates = [f for f in self.functions if f.arity == arity]\n            # Choose a replacement uniformly at random\n            replacement = random_state.choice(candidates)\n            # Update the node\n            program[point] = replacement\n        else:\n            # Replace terminals with constants or variables\n            if random_state.choice([True, False]):\n                # Replace with a constant\n                program[point] = random_state.uniform(self.constant_range[0],\n                                                     self.constant_range[1])\n            else:\n                # Replace with a variable\n                program[point] = random_state.randint(0, self.n_features)\n    return program, mutation_points.tolist()\n\n", "CodeBleu_score": 36.23010435254109}, {"code": "def point_mutation(self, random_state)\n\t\n\n    # Create a copy of the program\n    program = self.reproduce()\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    nodes_to_modify = [i for i in range(len(program)) if random_state.uniform() < self.point_mutation_probability]\n    # For each node to be mutated\n    for node_index in nodes_to_modify:\n        node = program[node_index]\n        # If it is a function, find a valid replacement function with the same arity\n        if isinstance(node, _Function):\n            replacement = self.random_function(random_state, node.arity)\n            # Update the node\n            program[node_index] = replacement\n        # If it is a terminal, replace it with either a constant or a variable\n        else:\n            if random_state.uniform() < self.point_mutation_constant_probability:\n                program[node_index] = self.random_constant(random_state)\n            else:\n                program[node_index] = self.random_variable(random_state)\n    # Return the mutated program and the list of modified node indices\n    return program, nodes_to_modify\n\n", "CodeBleu_score": 21.195080369155825}, {"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    program = self.reproduce()\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    nodes_to_modify = [i for i, node in enumerate(program) if isinstance(node, _Function) and random_state.uniform() < self.mutation_probability]\n    # For each node to be modified, replace it with a valid replacement\n    for i in nodes_to_modify:\n        node = program[i]\n        if isinstance(node, _Function):\n            # Find a valid replacement function with the same arity\n            replacement_function = random_state.choice(self.functions[node.arity])\n            # Update the node with the new function\n            program[i] = replacement_function\n        else:\n            # Replace the terminal with either a constant or a variable\n            if random_state.uniform() < self.constant_probability:\n                # Replace with a constant within the defined constant range\n                program[i] = random_state.uniform(self.constant_range[0], self.constant_range[1])\n            else:\n                # Replace with a variable from the available features\n                program[i] = random_state.choice(self.features)\n    # Return the mutated program and the list of modified node indices\n    return program, nodes_to_modify\n\n", "CodeBleu_score": 22.742399189597744}]}
{"instance_id": "f1853251e671", "generation_result": [{"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode if isinstance(mamode, str) else \"sma\"\n    close = verify_series(close, length)\n    offset = get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    ma_ = ma(mamode, close, length=length, **kwargs)\n    bias = (close / ma_) - 1\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}\"\n    bias.category = \"momentum\"\n\n    return bias\n\n", "CodeBleu_score": 64.47426858746736}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    close = verify_series(close, length)\n    offset = get_offset(offset)\n\n    if close is None: return\n\n    # Calculate Result\n    ma_ = ma(mamode, close, length=length, **kwargs)\n    bias = (close / ma_) - 1\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}\"\n    bias.category = \"momentum\"\n\n    return bias", "CodeBleu_score": 63.07905649757812}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate Arguments\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode if isinstance(mamode, str) else \"sma\"\n    offset = get_offset(offset)\n\n    # Calculate Result\n    if close is not None:\n        if mamode == \"sma\":\n            bias = (close - ma(\"close\", length=length, **kwargs)) / ma(\n                \"close\", length=length, **kwargs\n            )\n        elif mamode == \"ema\":\n            bias = (close - ma(\"close\", length=length, mamode=\"ema\", **kwargs)) / ma(\n                \"close\", length=length, mamode=\"ema\", **kwargs\n            )\n        elif mamode == \"wma\":\n            bias = (close - ma(\"close\", length=length, mamode=\"wma\", **kwargs)) / ma(\n                \"close\", length=length, mamode=\"wma\", **kwargs\n            )\n        elif mamode == \"hma\":\n            bias = (close - ma(\"close\", length=length, mamode=\"hma\", **kwargs)) / ma(\n                \"close\", length=length, mamode=\"hma\", **kwargs\n            )\n        elif mamode == \"zlsma\":\n            bias = (close - ma(\"close\", length=length, mamode=\"zlsma\", **kwargs)) / ma(\n                \"close\", length=length, mamode=\"zlsma\", **kwargs\n            )\n\n    # Offset\n    if offset != 0:\n        bias = bias.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        bias.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        bias.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    bias.name = f\"BIAS_{length}_{mamode}\"\n    bias.category = \"momentum\"\n\n    return", "CodeBleu_score": 49.07045409027955}]}
{"instance_id": "25e0a134c45b", "generation_result": [{"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_head()\n    text = urlopen(url, timeout=10).read()\n    text = text.decode('gbk')\n    org_js = json.loads(text)\n\n    status_code = int(org_js['result']['status']['code'])\n    if status_code != 0:\n        status = str(org_js['result']['status']['msg'])\n        raise ValueError(status)\n\n    data = org_js['result']['data']\n    fund_df = pd.DataFrame(data, columns=ct.FUND_DATA_COLS)\n\n    if fund_type == 'open':\n        fund_df = fund_df.fillna(0)\n    elif fund_type == 'close':\n        fund_df = fund_df.fillna(0)\n    elif fund_type == 'grading':\n        fund_df = fund_df.fillna(0)\n    else:\n        raise ValueError('fund_type error')\n\n    return fund_df\n\n", "CodeBleu_score": 27.58712551748017}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_head()\n    try:\n        text = urlopen(url, timeout=10).read()\n        text = text.decode('gbk')\n        org_js = json.loads(text)\n        data = org_js['result']['data']\n\n        fund_df = pd.DataFrame(data, columns=ct.FUND_OPEN_COLS, index=[0])\n        fund_df = fund_df.set_index('symbol')\n\n        if fund_type == 'open':\n            fund_df['nav_rate'] = fund_df['nav_rate'].apply(lambda x: x.replace('%', ''))\n            fund_df['discount_rate'] = fund_df['discount_rate'].apply(lambda x: x.replace('%', ''))\n            fund_df['nav_rate'] = fund_df['nav_rate'].astype(float)\n            fund_df['discount_rate'] = fund_df['discount_rate'].astype(float)\n            fund_df['nav_date'] = fund_df['nav_date'].apply(lambda x: x.replace('-', ''))\n            fund_df['nav_date'] = fund_df['nav_date'].astype(int)\n            fund_df['nav_date'] = fund_df['nav_date'].astype(str)\n            fund_df['nav_date'] = fund_df['nav_date'].apply(lambda x: x[:4] + '-' + x[4:6] + '-' + x[6:])\n\n            fund_df['start_date'] = fund_df['start_date'].apply(lambda x: x.replace('-', ''))\n            fund_df['start_date'] = fund_df['start_date'].astype(int)\n            fund_df['start_date'] = fund_df['start_date'].astype(str)\n            fund_df['start_date'] = fund_df['start_date'].apply(lambda x: x[:4] + '-' + x[4:6] + '-' + x[6:])\n\n            fund_df['end_date'] = fund_df['", "CodeBleu_score": 38.698377390514885}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    ct._write_head()\n    text = urlopen(url, timeout=10).read()\n    text = text.decode('gbk')\n    org_js = json.loads(text)\n    status_code = int(org_js['result']['status']['code'])\n    if status_code != 0:\n        status = str(org_js['result']['status']['msg'])\n        raise ValueError(status)\n    data = org_js['result']['data']\n    fund_df = pd.DataFrame(data, columns=ct.FUND_COLS, index=[0])\n    fund_df = fund_df.set_index('symbol')\n    if fund_type == 'open':\n        fund_df = fund_df.fillna(0)\n    elif fund_type == 'close':\n        fund_df = fund_df.fillna(0)\n    elif fund_type == 'grading':\n        fund_df = fund_df.fillna(0)\n    else:\n        fund_df = fund_df.fillna(0)\n    return fund_df\n\n", "CodeBleu_score": 30.97271072009659}]}
{"instance_id": "401d18e122d8", "generation_result": [{"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    start = ct.convert_date(start) if start is not None else datetime.date.today()\n    end = ct.convert_date(end) if end is not None else datetime.date.today()\n    if market == 'CFFEX':\n        func = get_cffex_daily\n    elif market == 'CZCE':\n        func = get_czce_daily\n    elif market == 'DCE':\n        func = get_dce_daily\n    elif market == 'INE':\n        func = get_ine_daily\n    elif market == 'SHFE':\n        func = get_shfe_daily\n    else:\n        print('invalid market:' + market + ', should be one of CFFEX, CZCE, DCE, INE or SHFE.')\n        return\n    data = []\n    for day in ct.date_range(start, end):\n        df = func(day)\n        if df is not None:\n            data.append(df)\n    return pd.concat(data) if data else None\n\n", "CodeBleu_score": 49.394106615696074}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    start = ct.convert_date(start) if start is not None else datetime.date.today()\n    end = ct.convert_date(end) if end is not None else start\n    data = []\n    for day in pd.date_range(start, end):\n        if market == 'CFFEX':\n            df = get_cffex_daily(day)\n        elif market == 'CZCE':\n            df = get_czce_daily(day)\n        elif market == 'DCE':\n            df = get_dce_daily(day)\n        elif market == 'INE':\n            df = get_ine_daily(day)\n        elif market == 'SHFE':\n            df = get_shfe_daily(day)\n        else:\n            print('Invalid market:', market)\n            return\n        if df is not None:\n            data.append(df)\n    return pd.concat(data) if data else None\n\n", "CodeBleu_score": 43.5383864661977}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    start = ct.convert_date(start) if start is not None else datetime.date.today()\n    end = ct.convert_date(end) if end is not None else datetime.date.today()\n    if market == 'CFFEX':\n        func = get_cffex_daily\n    elif market == 'CZCE':\n        func = get_czce_daily\n    elif market == 'DCE':\n        func = get_dce_daily\n    elif market == 'INE':\n        func = get_ine_daily\n    elif market == 'SHFE':\n        func = get_shfe_daily\n    else:\n        print('invalid market: ' + market)\n        return\n    data = list()\n    while start <= end:\n        df = func(start)\n        if df is not None:\n            data.append(df)\n        start += datetime.timedelta(1)\n    return pd.concat(data) if data else None\n", "CodeBleu_score": 56.73173895531123}]}
{"instance_id": "697779825988", "generation_result": [{"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    for _ in range(retry_count):\n        time.sleep(pause)\n        try:\n            request = Request(ct.REALTIME_BOXOFFICE_URL)\n            lines = urlopen(request, timeout=10).read()\n            result = json.loads(lines.decode('utf-8'))\n            if len(result['data2']) == 0:\n                continue\n            df = pd.DataFrame(result['data2'])\n            df.drop(['MovieImg', 'mId'], axis=1, inplace=True)\n            df.insert(0, 'time', du.get_now_string('%Y-%m-%d %H:%M:%S'))\n            return df\n        except:\n            pass\n    return None\n\n", "CodeBleu_score": 42.861270349383084}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    for _ in range(retry_count):\n        time.sleep(pause)\n        try:\n            request = Request(ct.REALTIME_BOXOFFICE_URL)\n            lines = urlopen(request, timeout=10).read()\n            result = json.loads(lines.decode('utf-8'))\n            if (result['data2'] != []):\n                return _parse_data(result)\n        except:\n            pass\n\n    return pd.DataFrame()\n\n", "CodeBleu_score": 32.99356159572483}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    for _ in range(retry_count):\n        time.sleep(pause)\n        try:\n            url = ct.BOXOFFICE_URL\n            headers = {\n                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/89.0.4389.90 Safari/537.36'\n            }\n            request = Request(url=url, headers=headers)\n            response = urlopen(request, timeout=10)\n            data = response.read()\n            if not data:\n                continue\n            data = json.loads(data.decode('utf-8'))\n            df = pd.DataFrame(data['data2'])\n            df.drop(['MovieImg', 'mId'], axis=1, inplace=True)\n            df['time'] = du.get_now_str()\n            return df\n        except:\n            pass\n    return None\n\n", "CodeBleu_score": 40.43859015014334}]}
{"instance_id": "be23c0afc2d6", "generation_result": [{"code": "def preprocess(df, test_size, shuffle)\n    import pandas as pd\n    from sklearn.model_selection import train_test_split\n\n    # Remove rows with missing entries marked by \"--\"\n    df = df[df.ne('--').all(axis=1)]\n\n    # Drop columns with unique values less than or equal to one or containing \"id\" in their name\n    df = df.drop([col for col in df.columns if df[col].nunique() <= 1 or 'id' in col.lower()], axis=1)\n\n    # Drop shortcut columns like \"days_to_death\" and \"year_of_death\"\n    df = df.drop([col for col in df.columns if 'days_to_death' in col.lower() or 'year_of_death' in col.lower()], axis=1)\n\n    # Split the dataframe into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n    return train_df, test_df\n\n", "CodeBleu_score": 41.27619801595815}, {"code": "def preprocess(df, test_size, shuffle)\n    # Drop rows with missing entries\n    df = df.replace('--', pd.NA)\n    df = df.dropna()\n\n    # Drop columns with unique values less than or equal to 1\n    for col in df.columns:\n        if len(df[col].unique()) <= 1:\n            df = df.drop(col, axis=1)\n\n    # Drop columns with \"id\" in their name\n    df = df.drop([col for col in df.columns if 'id' in col], axis=1)\n\n    # Drop shortcut columns\n    df = df.drop(['days_to_death', 'year_of_death'], axis=1)\n\n    # Split the data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n    return train_df, test_df\n\n", "CodeBleu_score": 36.68855281075347}, {"code": "def preprocess(df, test_size, shuffle)\n    # Remove rows with missing entries marked by \"--\"\n    df = df[df.ne('--').all(axis=1)]\n    # Drop columns with unique values less than or equal to 1\n    df = df.drop(columns=[col for col in df.columns if df[col].nunique() <= 1])\n    # Drop columns with \"id\" in their name\n    df = df.drop(columns=[col for col in df.columns if \"id\" in col])\n    # Drop shortcut columns like \"days_to_death\" and \"year_of_death\"\n    df = df.drop(columns=[col for col in df.columns if \"days_to_death\" in col or \"year_of_death\" in col])\n    # Split the data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n    return train_df, test_df\n", "CodeBleu_score": 31.86735697594742}]}
{"instance_id": "4c1ade308953", "generation_result": [{"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n    if rounddigit is None:\n        return src\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        import decimal\n        return float(decimal.Decimal(src).quantize(decimal.Decimal(f'1E-{rounddigit}'), rounding=decimal.ROUND_HALF_UP))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError('method must be one of \"decimal\", \"sig\", or \"format\"')\n\n", "CodeBleu_score": 56.5306608062807}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        from decimal import Decimal\n        return float(Decimal(src).quantize(Decimal(f'1.{\"0\" * rounddigit}'), rounding='ROUND_HALF_UP'))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError('Invalid method. Choose either \"decimal\", \"sig\", or \"format\".')\n\n", "CodeBleu_score": 56.37105356984284}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n    if rounddigit is None:\n        return src\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        import decimal\n        with decimal.localcontext() as ctx:\n            ctx.rounding = decimal.ROUND_HALF_UP\n            ctx.prec = rounddigit\n            return ctx.create_decimal_from_float(src)\n    elif method == 'format':\n        return float(f'%.{rounddigit}g' % src)\n    else:\n        raise ValueError(\"Invalid rounding method. Choose 'decimal', 'sig', or 'format'.\")\n", "CodeBleu_score": 68.94558888825875}]}
{"instance_id": "a9923e678320", "generation_result": [{"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n    if rounddigit is None:\n        return srcdict\n    dstdict = dict()\n    for k, v in srcdict.items():\n        if isinstance(v, float):\n            if method == 'decimal':\n                dstdict[k] = cls._round_digits(v, rounddigit)\n            elif method == 'sig':\n                dstdict[k] = cls._round_sigdigits(v, rounddigit)\n            elif method == 'format':\n                dstdict[k] = cls._round_formatdigits(v, rounddigit)\n            else:\n                raise ValueError(f\"Invalid rounding method: {method}\")\n        else:\n            dstdict[k] = v\n    return dstdict\n", "CodeBleu_score": 44.62931363844035}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n    if rounddigit is None:\n        return srcdict\n    if method == 'decimal':\n        return {k: _round_digits(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    elif method == 'sig':\n        return {k: _round_sigdigits(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    elif method == 'format':\n        return {k: _round_format(v, rounddigit) if isinstance(v, float) else v for k, v in srcdict.items()}\n    else:\n        raise ValueError(f\"Invalid method: {method}\")\n\n", "CodeBleu_score": 30.854393396555658}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n    if rounddigit is None:\n        return srcdict\n    else:\n        return {k: cls._round_digits(v, rounddigit, method) if isinstance(v, float) else v for k, v in srcdict.items()}\n\n", "CodeBleu_score": 31.910233957459468}]}
{"instance_id": "77825be37c24", "generation_result": [{"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n    import requests\n    import pandas as pd\n    import datetime\n    import traceback\n\n    # Define the URL based on the broker, cryptocurrency code, kline type, and size\n    url = f'https://api.binance.com/api/v3/klines?symbol={code.upper()}USDT&interval={ktype}&limit={size}'\n    if broker == 'hb':\n        url = f'https://api.huobi.pro/market/history/kline?period={ktype}&size={size}&symbol={code.lower()}usdt'\n    elif broker == 'okx':\n        url = f'https://www.okx.com/api/v5/market/candles?instId={code.upper()}-USDT&bar={ktype}&limit={size}'\n    elif broker == 'kucoin':\n        url = f'https://api.kucoin.com/api/v1/market/candles?type={ktype}&symbol={code.upper()}-USDT&startAt=null&endAt=null&limit={size}'\n\n    # Fetch the data\n    try:\n        data = requests.get(url).json()\n    except Exception as e:\n        print(f'Error fetching data: {e}')\n        return None\n\n    # Handle any broker-specific data structures\n    if broker == 'hb':\n        data = data['data']\n    elif broker == 'okx':\n        data = data['data']\n    elif broker == 'kucoin':\n        data = data['data']\n\n    # Convert the data into a pandas DataFrame\n    df = pd.DataFrame(data, columns=['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count', 'volume', 'vwap', 'last_close'])\n\n    # Adjust the date formatting based on the broker and kline type\n    if broker == 'hb':\n        df['date'] = pd.to_datetime(df['date'], unit='s')\n    elif broker == 'okx':\n        df['date'] =", "CodeBleu_score": 30.032039846784564}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n    import requests\n    import pandas as pd\n    from datetime import datetime\n    import traceback\n\n    # Define the base URL for the broker\n    if broker == 'hb':\n        url = 'https://api.huobi.pro/market/history/kline'\n    elif broker == 'binance':\n        url = 'https://api.binance.com/api/v3/klines'\n    elif broker == 'okx':\n        url = 'https://www.okx.com/api/v5/market/candles'\n    else:\n        print('Invalid broker')\n        return None\n\n    # Define the parameters for the request\n    params = {\n        'symbol': code.upper(),\n        'period': ktype,\n        'size': size\n    }\n\n    # Make the request to the broker's API\n    response = requests.get(url, params=params)\n\n    # Handle any errors that may occur\n    if response.status_code != 200:\n        print(f'Error: {response.status_code}')\n        return None\n\n    # Parse the response data based on the broker\n    if broker == 'hb':\n        data = response.json()['data']\n    elif broker == 'binance':\n        data = response.json()\n    elif broker == 'okx':\n        data = response.json()['data']\n\n    # Convert the data into a pandas DataFrame\n    df = pd.DataFrame(data, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n\n    # Format the date column based on the broker and kline type\n    if broker == 'hb':\n        if ktype == 'D':\n            df['timestamp'] = df['timestamp'].apply(lambda x: datetime.fromtimestamp(x / 1000).strftime('%Y-%m-%d'))\n        else:\n            df['timestamp'] = df['timestamp'].apply(lambda x: datetime.fromtimestamp(x / 1000).strftime('%Y-%m-%d %H:%M:%S'))\n    elif broker == 'binance':", "CodeBleu_score": 37.705607889881705}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n    try:\n        url = f'https://www.binance.com/fapi/v1/klines?symbol={code.upper()}&interval={ktype}&limit={size}'\n        if broker == 'hb':\n            url = f'https://api.hbdm.com/market/history/kline?period={ktype}&size={size}&symbol={code}'\n        if broker == 'b':\n            url = f'https://api.binance.com/api/v3/klines?symbol={code.upper()}&interval={ktype}&limit={size}'\n        data = requests.get(url)\n        if broker == 'hb':\n            data = data.json()['data']\n        if broker == 'b':\n            data = data.json()\n        df = pd.DataFrame(data)\n        if broker == 'hb':\n            df = df.iloc[:, 0:6]\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n            df['date'] = pd.to_datetime(df['date'], unit='s')\n            df['date'] = df['date'] + pd.Timedelta(hours=8)\n        if broker == 'b':\n            df = df.iloc[:, 0:6]\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n            df['date'] = pd.to_datetime(df['date'], unit='ms')\n            df['date'] = df['date'] + pd.Timedelta(hours=8)\n        return df\n    except Exception as e:\n        print(traceback.format_exc())\n\n", "CodeBleu_score": 36.033588531736434}]}
{"instance_id": "c6552851da8a", "generation_result": [{"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n    import pandas as pd\n    import traceback\n    from datetime import datetime\n    from .helpers import get_snapshot\n\n    try:\n        snapshot = get_snapshot(broker, code, size)\n\n        if broker == 'hb':\n            timestamp = datetime.fromtimestamp(snapshot['timestamp'] / 1000)\n        else:\n            timestamp = datetime.fromtimestamp(snapshot['timestamp'])\n\n        ask_df = pd.DataFrame(snapshot['asks']).rename(columns={0: 'price', 1: 'size'})\n        ask_df['timestamp'] = timestamp\n\n        bid_df = pd.DataFrame(snapshot['bids']).rename(columns={0: 'price', 1: 'size'})\n        bid_df['timestamp'] = timestamp\n\n        data = {'ask': ask_df, 'bid': bid_df}\n\n        return pd.Panel(data)\n\n    except:\n        traceback.print_exc()\n\n", "CodeBleu_score": 38.58809458925619}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n    import pandas as pd\n    import numpy as np\n    import traceback\n    from datetime import datetime\n\n    # Retrieve data from helper function\n    try:\n        data = get_coins_snapshot(broker, code, size)\n    except Exception as e:\n        print(f\"Error retrieving data from {broker}: {e}\")\n        traceback.print_exc()\n        return None\n\n    # Process data\n    try:\n        if broker == 'hb':\n            # Process timestamp for Huobi\n            timestamp = datetime.fromtimestamp(data['ts'] / 1000)\n            ask_df = pd.DataFrame(data['asks'], columns=['price', 'amount'])\n            bid_df = pd.DataFrame(data['bids'], columns=['price', 'amount'])\n        else:\n            # Process timestamp for other brokers\n            timestamp = datetime.fromtimestamp(data['timestamp'])\n            ask_df = pd.DataFrame(data['asks'], columns=['price', 'amount', 'count'])\n            bid_df = pd.DataFrame(data['bids'], columns=['price', 'amount', 'count'])\n\n        # Add timestamp to each dataframe\n        ask_df['timestamp'] = timestamp\n        bid_df['timestamp'] = timestamp\n\n        # Create panel\n        panel = pd.Panel({'ask': ask_df, 'bid': bid_df})\n\n        return panel\n    except Exception as e:\n        print(f\"Error processing data from {broker}: {e}\")\n        traceback.print_exc()\n        return None\n\n", "CodeBleu_score": 39.219618878925075}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n    import pandas as pd\n    import traceback\n\n    def fetch_data(url):\n        import requests\n        import json\n        response = requests.get(url)\n        data = json.loads(response.text)\n        return data\n\n    if broker == 'hb':\n        url = f'https://api.huobi.pro/market/depth?symbol={code}usdt&type=step0'\n        data = fetch_data(url)\n        timestamp = pd.to_datetime(data['ts'], unit='ms')\n        ask = pd.DataFrame(data['tick']['asks'], columns=['price', 'quantity'])\n        bid = pd.DataFrame(data['tick']['bids'], columns=['price', 'quantity'])\n    elif broker == 'bh':\n        url = f'https://api.binance.com/api/v3/depth?symbol={code}USDT&limit={size}'\n        data = fetch_data(url)\n        timestamp = pd.to_datetime(data['E'], unit='ms')\n        ask = pd.DataFrame(data['asks'], columns=['price', 'quantity'])\n        bid = pd.DataFrame(data['bids'], columns=['price', 'quantity'])\n    else:\n        raise ValueError(\"Invalid broker. Supported brokers are 'hb' and 'bh'.\")\n\n    ask['timestamp'] = timestamp\n    bid['timestamp'] = timestamp\n\n    data = {'ask': ask, 'bid': bid}\n\n    panel = pd.Panel(data)\n\n    return panel\n\n", "CodeBleu_score": 40.486105694592304}]}
{"instance_id": "8b5fee723398", "generation_result": [{"code": "def coins_trade(broker='hb', code='btc')\n    import pandas as pd\n    import requests\n    import json\n    import datetime\n\n    # Set the URL based on the broker and cryptocurrency code\n    url = f'https://api.hbdm.com/market/history/trade?symbol={code.upper()}usdt&size=1000'\n    if broker == 'ok':\n        url = f'https://www.okx.com/api/v5/market/trades?instId={code.upper()}-USDT'\n    if broker == 'chbtc':\n        url = f'https://api.chbtc.com/data/v1/trades?symbol={code.upper()}_USDT'\n\n    # Retrieve the data from the URL\n    response = requests.get(url)\n    data = response.json()\n\n    # If the data is not None, process it\n    if data is not None:\n        # For 'hb', select and rename specific columns and convert timestamps\n        if broker == 'hb':\n            df = pd.DataFrame(data['data'])\n            df = df[['trade-id', 'ts', 'trade-price', 'trade-volume', 'direction']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = pd.to_datetime(df['datetime'], unit='ms')\n            df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d %H:%M:%S')\n\n        # For 'ok' and 'chbtc', select, rename columns, and convert timestamps\n        if broker == 'ok':\n            df = pd.DataFrame(data['data'])\n            df = df[['trade-id', 'ts', 'px', 'sz', 'side']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = pd.to_datetime(df['datetime'], unit='ms')\n            df['datetime'] = df['datetime'].dt.strftime('%Y-%m-%d", "CodeBleu_score": 44.20897235535939}, {"code": "def coins_trade(broker='hb', code='btc')\n    import pandas as pd\n    import requests\n    import json\n    import datetime\n    import time\n    import numpy as np\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n\n    # Define the API URL based on the broker and cryptocurrency code\n    if broker == 'hb':\n        url = f\"https://api.huobi.pro/market/history/trade?symbol={code.upper()}usdt&size=2000\"\n    elif broker == 'ok':\n        url = f\"https://www.okx.com/api/v5/market/history-trades?instId={code.upper()}-USDT\"\n    elif broker == 'chbtc':\n        url = f\"https://api.chbtc.com/data/v1/trades?symbol={code.upper()}_USDT\"\n\n    # Send a GET request to the API and retrieve the data\n    data = requests.get(url).json()\n\n    # If the data is not None, process it based on the broker\n    if data:\n        if broker == 'hb':\n            # Select and rename specific columns\n            df = pd.DataFrame(data['data'])\n            df = df[['id', 'ts', 'data']]\n            df.columns = ['tid', 'datetime', 'price_amount']\n            # Convert timestamps to datetime format\n            df['datetime'] = pd.to_datetime(df['datetime'], unit='s')\n            df['datetime'] = df['datetime'].dt.tz_localize('utc').dt.tz_convert('Asia/Shanghai').dt.strftime('%Y-%m-%d %H:%M:%S')\n            # Split price and amount into separate columns\n            df[['price', 'amount']] = df['price_amount'].apply(pd.Series)\n            df = df[['tid', 'datetime', 'price', 'amount']]\n        elif broker in ['ok', 'chbtc']:\n            # Select and rename specific columns\n            df = pd.DataFrame(data['data'])\n            df = df[['trade_id", "CodeBleu_score": 36.662166383991455}, {"code": "def coins_trade(broker='hb', code='btc')\n    import pandas as pd\n    import numpy as np\n    import requests\n    import time\n    import datetime\n    import warnings\n    warnings.filterwarnings('ignore')\n\n    # Define the URLs for the data sources\n    urls = {'hb': f'https://api.hbdm.com/market/history/trade?symbol={code.upper()}',\n            'ok': f'https://www.okx.com/api/v5/market/trades?instId={code.upper()}-USDT',\n            'chbtc': f'https://api.chbtc.com/data/v1/trades?currency={code.lower()}'}\n\n    # Retrieve the data from the specified broker\n    data = requests.get(urls[broker]).json()\n\n    # If the data is not None, process it differently depending on the broker\n    if data is not None:\n        if broker == 'hb':\n            df = pd.DataFrame(data['data'])\n            df = df[['id', 'ts', 'price', 'amount', 'direction']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n            df['type'] = df['type'].apply(lambda x: 'buy' if x == 'buy' else 'sell')\n        elif broker in ['ok', 'chbtc']:\n            df = pd.DataFrame(data['data'])\n            df = df[['trade-id', 'ts', 'px', 'sz', 'side']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(lambda x: datetime.datetime.fromtimestamp(x/1000))\n            df['type'] = df['type'].apply(lambda x: 'buy' if x == 'buy' else 'sell')\n\n    # Standardize the column names\n    df.columns = ['tid', 'datetime', 'price', '", "CodeBleu_score": 44.01496121082179}]}
