{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\tf._connection_lock.acquire()\n    try:\n        self._connection_lock.release()\n        self._connection_lock.acquire()\n        try:\n            if self._state == KeeperState.CONNECTED:\n                self._connection_lock.release()\n                return 0.0, self._orig_kazoo_connect(*args)\n            else:\n                self._connection_lock.release()\n                wait_time = self._loop_wait - 2\n                if wait_time < 2:\n                    wait_time = 2\n                return wait_time / 1000.0, self._orig_kazoo_connect(*args)\n        finally:\n            self._connection_lock.release()\n    finally:\n        self._connection_lock.release()\n\n", "CodeBleu_score": 43.612663435335655}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\tp_wait = self.loop_wait - 2\n    if loop_wait < 2:\n        loop_wait = 2\n    return (loop_wait * 1000, self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 46.14466592677015}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\tt = self.loop_wait - 2\n    return (wait * 1000, self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 47.95644047280126}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        self.retry_timeout = config.retry_timeout\n        self.loop_wait = config.loop_wait\n        self.ttl = config.ttl\n        if isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n            self.client_handler.set_connect_timeout(config.loop_wait)\n    else:\n        self.retry_timeout = config['retry_timeout']\n        self.loop_wait = config['loop_wait']\n        self.ttl = config['ttl']\n        if isinstance(self.client_handler, PatroniSequentialThreadingHandler):\n            self.client_handler.set_connect_timeout(config['loop_wait'])\n    self.client.stop()\n    self.client.start()\n", "CodeBleu_score": 39.48035521451391}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, Config):\n        config = Config(config)\n    self.retry_timeout = config.retry_timeout\n    self.loop_wait = config.loop_wait\n    self.ttl = config.ttl\n    if isinstance(self.client.handler, PatroniSequentialThreadingHandler):\n        self.client.handler.set_connect_timeout(config.loop_wait / 2)\n\n", "CodeBleu_score": 39.95587506941971}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    self._client.stop()\n    self._client.close()\n    self._client = PatroniKazooClient(self.hosts, handler=PatroniSequentialThreadingHandler(config['retry_timeout']), timeout=config['ttl'], connection_retry=KazooRetry(max_delay=1, max_tries=-1, sleep_func=time.sleep), command_retry=KazooRetry(max_delay=1, max_tries=-1, deadline=config['retry_timeout'], sleep_func=time.sleep), auth_data=list(config.get('auth_data', {}).items()), **config)\n    self._client.start()\n    self.loop_wait = config['loop_wait']\n    if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n        self._client.handler.set_connect_timeout(self.loop_wait / 2)\n\n", "CodeBleu_score": 42.51382738431999}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.config['name'], self.config['scope'], self.config['postgresql'])\n    cluster.initialize(path)\n\n    cluster.configuration(path)\n\n    cluster.timeline(path)\n\n    cluster.sync(path)\n\n    cluster.members(path)\n\n    cluster.leader(path)\n\n    cluster.status(path)\n\n    cluster.failover(path)\n\n    cluster.failsafe(path)\n\n    return cluster\n\n\n", "CodeBleu_score": 6.357606477200594}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.config, self.mpp)\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.timeline = self.get_node(path + self._TIMELINE)\n    cluster.members = self.get_children(path + self._MEMBERS)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.status = self.get_node(path + self._STATUS)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    cluster.initialize = self.get_node(path + self._INITIALIZE)\n    cluster.initialize_timestamp = self.get_node(path + self._INITIALIZE_TIMESTAMP)\n    cluster.initialize_timeout = self.get_node(path + self._INITIALIZE_TIMEOUT)\n    return cluster\n", "CodeBleu_score": 14.198727919397719}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self.config, self.mpp)\n\n    cluster.init_state = self.get_node(path + self._INIT_STATE, self._watcher)\n\n    cluster.config = self.get_node(path + self._CONFIG, self._watcher)\n\n    cluster.timeline = self.get_node(path + self._TIMELINE, self._watcher)\n\n    cluster.sync = self.get_node(path + self._SYNC, self._watcher)\n\n    cluster.members = self.load_members(path + self._MEMBERS)\n\n    cluster.leader = self.get_leader(path + self._LEADER)\n\n    cluster.status = self.get_status(path + self._STATUS, cluster.leader)\n\n    cluster.failover = self.get_node(path + self._FAILOVER, self._watcher)\n\n    cluster.failsafe = self.get_node(path + self._FAILSAFE, self._watcher)\n\n    cluster.is_unlocked = cluster.failover is None\n\n    return cluster\n\n", "CodeBleu_score": 15.088323574831763}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    lock_path = self._lock_path\n    try:\n        self._client.create_async(lock_path, b'', makepath=True, ephemeral=True).get(timeout=1)\n        return True\n    except NodeExistsError:\n        return False\n    except Exception:\n        logger.exception('Failed to acquire leader lock')\n        raise ZooKeeperError('ZooKeeper in not responding properly') from None\n\n\n\n", "CodeBleu_score": 31.425270679588223}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    path = self._leader_path\n    try:\n        self._client.retry(self._client.create, path, b'', ephemeral=True)\n        return True\n    except NodeExistsError:\n        logger.info('Leader lock already acquired')\n        return False\n    except Exception:\n        logger.exception('Failed to acquire leader lock')\n        raise ZooKeeperError('Failed to acquire leader lock')\n\n\n\n", "CodeBleu_score": 39.92669074188389}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self._leader_lock is None:\n        return False\n    try:\n        self._leader_lock.acquire(blocking=False)\n        return True\n    except ZooKeeperError as e:\n        if e.code!= NodeExistsError.code:\n            logger.exception('Failed to acquire leader lock')\n        return False\n\n    def _release_leader(self) -> None:\n        if self._leader_lock is not None:\n            self._leader_lock.release()\n\n    def _create_leader_lock(self, path: str) -> None:\n        self._leader_lock = threading.Lock()\n        self._leader_lock.acquire()  # acquire the lock\n        self._leader_lock.release()  # release the lock\n        self._leader_lock = None\n\n    def _create_leader_lock_if_needed(self, path: str) -> None:\n        if self._leader_lock is None:\n            self._create_leader_lock(path)\n\n    def _create_leader_lock_if_needed_or_acquire(self, path: str) -> bool:\n        if self._leader_lock is None:\n            self._create_leader_lock(path)\n        return self._leader_lock.acquire(blocking=False)\n\n    def _create_leader_lock_if_needed_or_acquire_for_timeout(self, path: str, timeout: float) -> bool:\n        if self._leader_lock is None:\n            self._create_leader_lock(path)\n        return self._leader_lock.acquire(blocking=False, timeout=timeout)\n\n    def _release_leader_lock_if_needed(self) -> None:\n        if self._leader_lock is not None:\n            self._leader_lock.release()\n            self._leader_lock = None\n\n    def _create_leader_lock_if_needed_or_acquire_for_timeout_and_release_on_exit(self, path: str, timeout: float) -> bool:\n        if self._leader_lock is None:\n            self._create_leader_lock(path)\n        with ExitStack()", "CodeBleu_score": 42.13355739264045}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n    if leader is None:\n        return self._client.delete_async(self.leader_path).get(timeout=1) is not False\n    else:\n        try:\n            self._client.create_async(self.leader_path, leader.encode(), makepath=True, ephemeral=True).get(timeout=1)\n            return True\n        except Exception:\n            logger.exception('update_leader')\n        return False\n\n", "CodeBleu_score": 45.90572378942731}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n    encoded_leader = leader.to_node()\n    if leader is None:\n        try:\n            self._client.create_async(self.leader_path, encoded_leader, makepath=True, ephemeral=True).get(timeout=1)\n            return True\n        except Exception:\n            logger.exception('Failed to create %s', self.leader_path)\n    try:\n        self._client.set_async(self.leader_path, encoded_leader).get(timeout=1)\n        return True\n    except Exception:\n        logger.exception('Failed to update %s', self.leader_path)\n    return False\n\n", "CodeBleu_score": 51.431982800687116}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is None:\n        return False\n    if leader.session!= self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = Leader(leader.version, leader.session, None)\n    try:\n        self._client.create_async(self.leader_path, leader.encode(), makepath=True, ephemeral=True).get(timeout=1)\n        return True\n    except Exception:\n        logger.exception('Failed to create %s', self.leader_path)\n        return False\n\n", "CodeBleu_score": 46.186556124543785}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\tif not self._next_poll or self._next_poll <= time.time():\n        self._next_poll = time.time() + self._poll_interval\n        logger.debug('polling exhibitor ensemble')\n        try:\n            response = requests_get(\n                self._exhibitors[0],\n                self._uri_path,\n                timeout=self.TIMEOUT,\n            )\n            response.raise_for_status()\n            data = response.json()\n            if not isinstance(data, dict):\n                logger.warning('invalid response from exhibitor ensemble')\n                return False\n            if not data.get('members'):\n                logger.warning('no exhibitors available')\n                return False\n            if data.get('exhibitorVersion')!= '1.5.7':\n                logger.warning('exhibitor ensemble version not supported')\n                return False\n            self._exhibitors = [\n                f'{host}:{self._exhibitor_port}'\n                for host in data['members']\n            ]\n            if self._exhibitors!= self._boot_exhibitors:\n                logger.info(\n                    'exhibitor ensemble changed, updating zookeeper hosts'\n                )\n                self._zookeeper_hosts = ','.join(self._exhibitors)\n            return True\n        except Exception as e:\n            logger.warning('exhibitor ensemble unavailable: %s', e)\n            return False\n\n", "CodeBleu_score": 36.687839193899855}, {"code": "def poll(self) -> bool\n\tif self._next_poll is None or self._next_poll < time.time():\n        self._next_poll = time.time() + self._poll_interval\n        return self._poll_exhibitor_status()\n    return False\n\n", "CodeBleu_score": 13.701478261592351}, {"code": "def poll(self) -> bool\n\tif not self._next_poll or self._next_poll < time.time():\n        self._next_poll = time.time() + self._poll_interval\n        logger.info('polling exhibitors')\n        try:\n            response = requests_get(self._exhibitors[0], self._uri_path, port=self._exhibitor_port)\n            if response.status_code!= 200:\n                logger.error('exhibitors returned status code %s', response.status_code)\n                return False\n            data = json.loads(response.text)\n            if not data:\n                logger.error('exhibitors returned empty data')\n                return False\n            if self._zookeeper_hosts!= data['zookeeper_hosts']:\n                logger.info('exhibitor changed zookeeper hosts to %s', data['zookeeper_hosts'])\n                self._zookeeper_hosts = data['zookeeper_hosts']\n                self._zookeeper.update_hosts(self._zookeeper_hosts)\n                return True\n        except Exception as e:\n            logger.error('error polling exhibitors: %s', e)\n            return False\n    return False\n\n", "CodeBleu_score": 42.101986959961}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t not self._ensemble_provider.poll():\n        return loader(path)\n\n    hosts = self._ensemble_provider.zookeeper_hosts\n    if not hosts:\n        return loader(path)\n\n    return super(ZooKeeper, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 63.86641796616076}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t not self._ensemble_provider.poll():\n        raise Exception('Exhibitor ensemble provider is not available')\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 73.26084337316375}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t self._ensemble_provider.poll():\n        self.hosts = self._ensemble_provider.zookeeper_hosts\n    return super(ZooKeeper, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 68.45610783092158}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\tf (zookeeperListener == null) {\nreturn;\n}\n\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n\nlogUnsubscribeFinished();\n}", "CodeBleu_score": 87.39175700382343}, {"code": "public void destroy(){\n\tf (zookeeperListener!= null) {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperOperation.unsubscribeConfig(zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 67.50615277251384}, {"code": "public void destroy(){\n\tf (zookeeperListener!= null) {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\ntry {\nzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 81.03856237755045}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\nreturn zookeeperServer.getMetadata();\n}\nreturn null;\n}", "CodeBleu_score": 59.01527596061338}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\nreturn zookeeperServer.getPayload();\n}\nreturn null;\n}", "CodeBleu_score": 58.81707376954307}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nreturn ((ZookeeperServer) server).getMetadata();\n}\nreturn null;\n}", "CodeBleu_score": 33.55774079445623}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = getPath(group, serviceId);\n\nboolean hasPath = hasPath(path);\nif (!hasPath) {\nreturn null;\n}\n\nNodeCache nodeCache = new NodeCache(curatorFramework, path, true);\nnodeCache.start();\n\nZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\nnodeCache.getListenable().addListener(zookeeperListener);\n\nreturn zookeeperListener;\n}", "CodeBleu_score": 46.69940395646914}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = getPath(group, serviceId);\n\nboolean hasPath = hasPath(path);\nif (!hasPath) {\nreturn null;\n}\n\nNodeCache nodeCache = new NodeCache(curatorFramework, path);\nnodeCache.start();\n\nNodeCacheListener nodeCacheListener = new NodeCacheListener() {\npublic void nodeChanged() throws Exception {\nString config = convertConfig(path);\nif (config!= null) {\nzookeeperSubscribeCallback.onConfigChanged(config);\n}\n}\n};\n\nZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\nzookeeperListener.add();\n\nreturn zookeeperListener;\n}", "CodeBleu_score": 71.38405153417528}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\tString path = getPath(group, serviceId);\n\nboolean hasPath = hasPath(path);\nif (!hasPath) {\nreturn null;\n}\n\nNodeCache nodeCache = new NodeCache(curatorFramework, path);\nnodeCache.start();\n\nnodeCache.getListenable().addListener(new NodeCacheListener() {\n@Override\npublic void nodeChanged() throws Exception {\nChildData childData = nodeCache.getCurrentData();\nString config = convertConfig(childData.getPath());\nif (config == null) {\nreturn;\n}\n\nzookeeperSubscribeCallback.callback(config);\n}\n});\n\nZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, zookeeperSubscribeCallback);\ncuratorFramework.getCuratorListenable().addListener(zookeeperListener);\n\nreturn zookeeperListener;\n}", "CodeBleu_score": 63.049896495939386}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n\tserverList.init(config);\n\tserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\n\tserverList.setServiceId(config.getClientName());\n\n\treturn serverList;\n}", "CodeBleu_score": 77.22204822986747}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n\tserverList.init(config);\n\tserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\n\tserverList.setServiceId(config.getClientName());\n\n\treturn serverList;\n}", "CodeBleu_score": 77.22204822986747}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n\tserverList.init(config);\n\tserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\n\tserverList.setServiceId(config.getClientName());\n\n\treturn serverList;\n}", "CodeBleu_score": 77.22204822986747}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Could not invoke onRegister method on RegisterListenerExecutor\", e);\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Failed to invoke register listener\", e);\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.debug(\"Error invoking register listener\", e);\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tString group = config.getGroup();\nString dataId = config.getDataId();\n\nif (StringUtils.isEmpty(group) || StringUtils.isEmpty(dataId)) {\nreturn null;\n}\n\nif (globalConfig) {\nlogger.info(\"Start to subscribe global config: \" + dataId);\n} else {\nlogger.info(\"Start to subscribe partial config: \" + dataId);\n}\n\nZookeeperListener listener = null;\ntry {\nlistener = zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n@Override\npublic void onConfigChange(String config) {\nlogger.info(\"Receive config change: \" + config);\n\nif (globalConfig) {\nglobalConfigListener.onConfigChange(config);\n} else {\npartialConfigListener.onConfigChange(config);\n}\n}\n});\n} catch (Exception e) {\nlogger.error(\"Subscribe config failure: \" + e.getMessage(), e);\n}\n\nreturn listener;\n}", "CodeBleu_score": 47.3484559153338}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tString group = getGroup();\nString dataId = getDataId();\n\nif (group == null || dataId == null) {\nreturn null;\n}\n\nlogger.info(\\\"[Subscribe Config] group = \\\" + group + \\\", dataId = \\\" + dataId);\n\ntry {\nif (globalConfig) {\nreturn zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n@Override\npublic void handleConfigChange(String group, String dataId, String config) {\nsuper.handleConfigChange(group, dataId, config);\n\ntry {\nupdateConfig(group, dataId, config);\n} catch (Exception e) {\nlogger.error(\\\"[Subscribe Config] group = \\\" + group + \\\", dataId = \\\" + dataId + \\\", config = \\\" + config, e);\n}\n}\n});\n} else {\nreturn zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n@Override\npublic void handleConfigChange(String group, String dataId, String config) {\nsuper.handleConfigChange(group, dataId, config);\n\ntry {\nupdateConfig(group, dataId, config);\n} catch (Exception e) {\nlogger.error(\\\"[Subscribe Config] group = \\\" + group + \\\", dataId = \\\" + dataId + \\\", config = \\\" + config, e);\n}\n}\n});\n}\n} catch (Exception e) {\nlogger.error(\\\"[Subscribe Config] group = \\\" + group + \\\", dataId = \\\" + dataId, e);\n}\n\nreturn null;\n}", "CodeBleu_score": 33.9037033064165}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = getGlobalGroup();\n\t\tdataId = getGlobalDataId();\n\t} else {\n\t\tgroup = getPartialGroup();\n\t\tdataId = getPartialDataId();\n\t}\n\tlogger.info(\"subscribeConfig: group: \" + group + \", dataId: \" + dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n\t\t\t@Override\n\t\t\tpublic void handleConfigUpdate(String group, String dataId, String config) {\n\t\t\t\tlogger.info(\"handleConfigUpdate: group: \" + group + \", dataId: \" + dataId + \", config: \" + config);\n\t\t\t\ttry {\n\t\t\t\t\tupdateConfig(group, dataId, config);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tlogger.error(\"handleConfigUpdate error\", e);\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlogger.error(\"subscribeConfig error\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 43.20333908700484}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING);\n\tif (StringUtils.isBlank(connectionString)) {\n\t\tthrow new DiscoveryException(\"The Zookeeper connection string is empty.\");\n\t}\n\n\tint retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class);\n\tint sleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_TIME, Integer.class);\n\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(new ExponentialBackoffRetry(retryCount, sleepTime)).build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 60.331416084380386}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectionString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING);\nif (StringUtils.isBlank(connectionString)) {\nthrow new DiscoveryException(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING + \" is empty\");\n}\n\nint retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class);\nint sleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_TIME, Integer.class);\n\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectionString).retryPolicy(new ExponentialBackoffRetry(retryCount, sleepTime)).build();\ncuratorFramework.start();\n\nreturn curatorFramework;\n}", "CodeBleu_score": 65.52174947510875}, {"code": "public CuratorFramework curatorFramework(){\n\tif (StringUtils.isEmpty(environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING))) {\nthrow new DiscoveryException(\"Zookeeper connection string is empty.\");\n}\n\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_STRING))\n.retryPolicy(new ExponentialBackoffRetry(Integer.parseInt(environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT)), Integer.parseInt(environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_TIME))))\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 41.15506783308685}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 72.10890884244438}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\nreturn new GatewayStrategyRouteZookeeperProcessor();\n}\n}", "CodeBleu_score": 72.07180280101966}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 72.10890884244438}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\tcuratorFramework = CuratorFrameworkFactory.newClient(zooKeeperClientProperties.getHosts(), zooKeeperClientProperties.getSessionTimeout(), zooKeeperClientProperties.getNamespace(), new ExponentialBackoffRetry(zooKeeperClientProperties.getBaseSleepTimeMs(), zooKeeperClientProperties.getMaxRetries()));\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 42.24548332185278}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(zooKeeperClientProperties.getRetryPolicyBaseSleepTimeMs(), zooKeeperClientProperties.getRetryPolicyMaxRetries());\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(zooKeeperClientProperties.getConnectString())\n.sessionTimeoutMs(zooKeeperClientProperties.getSessionTimeoutMs())\n.retryPolicy(retryPolicy)\n.namespace(zooKeeperClientProperties.getNamespace())\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 60.60397394152898}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(zooKeeperClientProperties.getHosts())\n.sessionTimeoutMs(zooKeeperClientProperties.getSessionTimeout())\n.retryPolicy(retryPolicy)\n.namespace(zooKeeperClientProperties.getNamespace())\n.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 64.17429052838803}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(Thread.currentThread())) {\nInterProcessMutex mutex = locksMap.get(Thread.currentThread());\ntry {\nmutex.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n} else {\nInterProcessMutex mutex = new InterProcessMutex(curatorFrameworkClient.getCuratorZookeeperClient(), path);\ntry {\nmutex.acquire();\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\nlocksMap.put(Thread.currentThread(), mutex);\n}\n}", "CodeBleu_score": 46.132663367602845}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\n}", "CodeBleu_score": 3.201363766529465}, {"code": "public void lock(String path) throws DistributedLockException{\n\tif (locksMap.containsKey(Thread.currentThread())) {\nlocksMap.get(Thread.currentThread()).acquire();\n} else {\ntry {\nInterProcessMutex mutex = new InterProcessMutex(curatorFrameworkClient.getCuratorFramework(), path);\nmutex.acquire();\nlocksMap.put(Thread.currentThread(), mutex);\n} catch (Exception e) {\nthrow new DistributedLockException(e);\n}\n}\n}", "CodeBleu_score": 31.606030050949457}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tMap<Object, Object> propertiesMap = Maps.newHashMap();\nif (PROPERTIES.equals(dtpProperties.getConfigType())) {\npropertiesMap = genPropertiesTypeMap(dtpProperties);\n} else if (JSON.equals(dtpProperties.getConfigType())) {\npropertiesMap = ConfigHandler.parseJson(curatorFramework.getData().forPath(nodePath(dtpProperties) + \\\"/\\\" + dtpProperties.getConfigKey()));\n}\nreturn propertiesMap;\n}", "CodeBleu_score": 26.943904474554053}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nCuratorFramework curatorFramework = CuratorUtil.getCuratorFramework(dtpProperties);\nString nodePath = CuratorUtil.nodePath(dtpProperties);\nif (PROPERTIES.equals(dtpProperties.getConfigType())) {\nreturn genPropertiesTypeMap(curatorFramework, nodePath);\n} else if (JSON.equals(dtpProperties.getConfigType())) {\nString configKey = dtpProperties.getConfigKey();\nString configValue = curatorFramework.getData().forPath(nodePath + configKey);\nreturn ConfigHandler.genMap(configValue);\n} else {\nthrow new IllegalArgumentException(\\\"unknown config type\\\");\n}\n}", "CodeBleu_score": 38.66355170389584}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nString nodePath = ZKPaths.makePath(ZKPaths.makePath(zookeeper.getRootNode(), zookeeper.getConfigVersion()), zookeeper.getNode());\nCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\nMap<Object, Object> resultMap = Maps.newHashMap();\nif (dtpProperties.getConfigType().equals(PROPERTIES)) {\nresultMap = genPropertiesTypeMap(curatorFramework, nodePath);\n} else if (dtpProperties.getConfigType().equals(JSON)) {\nString configKey = dtpProperties.getConfigKey();\nString configValue = curatorFramework.getData().forPath(nodePath + \"/\" + configKey).toString();\nresultMap = ConfigHandler.parseJson(configValue, dtpProperties.getConfigKey());\n}\nreturn resultMap;\n}", "CodeBleu_score": 50.91417903920943}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = BinderHelper.bind(DtpProperties.class, environment);\n\nif (dtpProperties!= null) {\nMap<String, Object> properties = CuratorUtil.generateProperties(dtpProperties);\nif (properties.containsKey(DtpProperties.DTP_ZK_ADDRESS)) {\nMutablePropertySources propertySources = environment.getPropertySources();\npropertySources.addFirst(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));\nlog.info(\\\"[DtpStarter] Zookeeper properties source has been added to the environment.\\\");\n} else {\nlog.warn(\\\"[DtpStarter] Zookeeper properties source has not been added to the environment.\\\");\n}\n} else {\nlog.warn(\\\"[DtpStarter] Zookeeper properties source has not been added to the environment.\\\");\n}\n}", "CodeBleu_score": 44.95348832210742}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = BinderHelper.bind(DtpProperties.class, environment);\nMap<String, String> zkProperties = CuratorUtil.getZkProperties(dtpProperties);\nif (zkProperties == null || zkProperties.isEmpty()) {\nreturn;\n}\nMutablePropertySources propertySources = environment.getPropertySources();\nOriginTrackedMapPropertySource zkPropertySource = new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, zkProperties);\npropertySources.addFirst(zkPropertySource);\nlog.info(\\\"Dtp Zookeeper Property Source added\\\");\n}", "CodeBleu_score": 45.71215348312991}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = BinderHelper.bind(DtpProperties.class, environment);\nif (dtpProperties == null) {\nlog.warn(\\\"DtpProperties is not found in the environment, skipping Zookeeper configuration.\\\");\nreturn;\n}\nMap<String, String> zkProperties = CuratorUtil.generateZkProperties(dtpProperties);\nif (zkProperties == null) {\nlog.warn(\\\"DtpProperties is not found in the environment, skipping Zookeeper configuration.\\\");\nreturn;\n}\nMutablePropertySources propertySources = environment.getPropertySources();\nOriginTrackedMapPropertySource zkPropertySource = new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, zkProperties);\npropertySources.addFirst(zkPropertySource);\n}", "CodeBleu_score": 46.38544103951771}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.RegisterAdapter(c => new ZooKeeperServiceRouteManager(c.Resolve<IServiceRouteFactory>(), c.Resolve<ISerializer>(), c.Resolve<ILogger<ZooKeeperServiceRouteManager>>(), c.Resolve<IZookeeperClientProvider>(), configInfo))\n.InstancePerLifetimeScope();\nreturn this;\n}", "CodeBleu_score": 35.49923388244458}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.RegisterAdapter(provider => {\nvar loggerFactory = provider.GetRequiredService<ILoggerFactory>();\nvar routeFactory = provider.GetRequiredService<IServiceRouteFactory>();\nvar serializer = provider.GetRequiredService<ISerializer>();\nvar zookeeperClientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\nreturn new ZooKeeperServiceRouteManager(configInfo, loggerFactory, routeFactory, serializer, zookeeperClientProvider);\n}).InstancePerLifetimeScope();\nreturn builder;\n}", "CodeBleu_score": 37.75529573554823}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t.RegisterAdapter(provider => new ZooKeeperRouteManager(provider.GetRequiredService<IServiceRouteFactory>(), provider.GetRequiredService<ILogger<ZooKeeperRouteManager>>(), provider.GetRequiredService<IZookeeperClientProvider>()))\n.InstancePerLifetimeScope();\nreturn this;\n}", "CodeBleu_score": 33.01415473847887}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tr.RegisterAdapter(provider => {\n var result = new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandFactory>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>());\n return result;\n });\n return this;\n }", "CodeBleu_score": 63.82249309196304}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tr.RegisterAdapter(provider => new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandFactory>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n }", "CodeBleu_score": 56.91964398692583}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tmandManager(builder, provider => new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandFactory>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n }", "CodeBleu_score": 61.22427845491409}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentNullException(nameof(path));\n}\nif (provider == null) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\nvar source = new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange);\nbuilder.Add(source);\nreturn builder.Build();\n}", "CodeBleu_score": 43.57616885725657}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (path == null) {\nthrow new ArgumentNullException(nameof(path));\n}\nif (provider == null) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\nif (!Path.IsPathRooted(path)) {\npath = Path.Combine(Directory.GetCurrentDirectory(), path);\n}\nvar source = new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange);\nbuilder.Add(source);\nreturn builder.Build();\n}", "CodeBleu_score": 50.06660100223822}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null)\n{\nthrow new ArgumentNullException(nameof(builder));\n}\nif (path == null)\n{\nthrow new ArgumentNullException(nameof(path));\n}\nif (string.IsNullOrEmpty(path))\n{\nthrow new ArgumentException(Resources.Error_StringCannotBeNullOrEmpty, nameof(path));\n}\nif (path.Length == 0)\n{\nthrow new ArgumentException(Resources.Error_StringCannotBeEmpty, nameof(path));\n}\nif (path.Length > 256)\n{\nthrow new ArgumentException(Resources.Error_StringTooLong, nameof(path));\n}\nif (path[0] == '/' && path.Length > 1)\n{\nthrow new ArgumentException(Resources.Error_StringCannotStartWithSlash, nameof(path));\n}\nif (path[0] == '\\\\' && path.Length > 1)\n{\nthrow new ArgumentException(Resources.Error_StringCannotStartWithBackslash, nameof(path));\n}\nif (path.IndexOfAny(Path.GetInvalidPathChars())!= -1)\n{\nthrow new ArgumentException(Resources.Error_StringContainsInvalidPathChars, nameof(path));\n}\nif (provider == null)\n{\nif (Path.IsPathRooted(path))\n{\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n}\n}\nif (provider == null)\n{\nthrow new ArgumentException(Resources.Error_StringDoesNotSpecifyAFile, nameof(path));\n}\nvar source = new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange);\nbuilder.Add(source);\nreturn builder.Build();\n}", "CodeBleu_score": 45.142757143147975}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tar routes = await GetRoutesAsync();\n\nforeach (var route in routes) {\n\nvar newAddresses = route.Addresses.Where(x =>!Address.Any(y => y.Address == x.Address)).ToArray();\n\nif (newAddresses.Any())\nroute.Addresses = newAddresses;\n\n}\n\nawait SetRoutesAsync(routes);\n\n}", "CodeBleu_score": 48.57837562737569}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tf (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u79fb\u9664\u8def\u7531\u3002\");\n\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.RoutePath);\n\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nroutes = routes.ToArray();\n\nforeach (var serviceRoute in routes) {\nvar nodePath = $\"{path}{serviceRoute.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceRoute);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u79fb\u9664\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 36.05276939134242}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u5220\u9664\u670d\u52a1\u8def\u7531\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.RoutePath);\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nvar routes = await GetRoutesAsync();\nforeach (var route in routes) {\nvar nodePath = $\"{path}{route.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(route);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n} else {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u5220\u9664\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 52.93401733338092}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t routePath = _configInfo.RoutePath;\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar nodePath = routePath + \"/\" + zooKeeper.Item1;\nvar children = await zooKeeper.Item2.getChildrenAsync(nodePath);\nvar nodeRoutes = children.Children.Select(p => new ServiceRoute {\nServiceDescriptor = new ServiceDescriptor {\nId = p,\nName = p,\nVersion = \\\"1.0.0.0\\\"\n}\n});\nvar currentRoutes = await GetRoutes(nodeRoutes.Select(p => p.ServiceDescriptor.Id));\nvar removeRoutes = currentRoutes.Except(routes).ToArray();\nif (removeRoutes.Count() > 0) {\nforeach (var removeRoute in removeRoutes) {\nvar removeAddress = removeRoute.Address.Where(p => p.ToString() == hostAddr.ToString()).FirstOrDefault();\nif (removeAddress!= null) {\nawait zooKeeper.Item2.deleteAsync(nodePath + \"/\" + removeRoute.ServiceDescriptor.Id);\n}\n}\n}\n}\n}", "CodeBleu_score": 43.66463766899924}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t routePaths = routes.Select(p => p.ServiceDescriptor.Id).ToArray();\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 48.80238041802819}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t routePath = _configInfo.RoutePath;\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nif (!routePath.EndsWith(\\\"/\\\"))\nroutePath += \\\"/\\\";\n\nvar childrens = routePath.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\\\"{nodePath}/{child}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 43.51428410435968}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\\\"\u670d\u52a1\u8def\u7531\u6570\u636e\uff1a{0}\u3002\\\", data);\nif (data == null)\nreturn null;\nvar route = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nvar serviceRoute = await _serviceRouteFactory.CreateAsync(route);\nreturn serviceRoute;\n}", "CodeBleu_score": 42.311189436508535}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u670d\u52a1\u8def\u7531\u6570\u636e\uff1a{data}\u3002\\\");\nif (data == null)\nreturn null;\nvar serviceRouteDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nreturn await _serviceRouteFactory.CreateServiceRouteAsync(serviceRouteDescriptor);\n}", "CodeBleu_score": 40.527987926903144}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"Route data: {data}\\\");\nif (data == null)\nreturn null;\nvar route = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nreturn await _serviceRouteFactory.CreateRouteAsync(route);\n}", "CodeBleu_score": 38.02474140493031}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (DataEquals(oldData, newData))\nreturn;\n\nvar newRoute = await GetRoute(newData);\nvar oldRoute = _routes.Where(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id).FirstOrDefault();\n\nif (oldRoute!= null) {\nlock (_lock) {\n_routes[_routes.IndexOf(oldRoute)] = newRoute;\n}\n}\n\nOnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 40.04376916047108}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8def\u7531\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\\\");\n\nif (oldData == null && newData == null)\nreturn;\n\nvar descriptor = _serializer.Deserialize<byte[], ServiceRouteDescriptor>(newData);\nvar route = await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor });\n\nif (oldData == null)\n{\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\\\"\u670d\u52a1\u8def\u7531\u6dfb\u52a0\u6210\u529f\u3002\\\");\nreturn;\n}\n\nif (DataEquals(oldData, newData))\nreturn;\n\nvar oldRoute = await GetRoute(oldData);\n\nlock (_routes)\n{\n_routes.Remove(oldRoute);\n_routes.Add(route.First());\n}\n\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\\\"\u670d\u52a1\u8def\u7531\u66f4\u65b0\u6210\u529f\u3002\\\");\n\nOnChanged(oldRoute, route.First());\n}", "CodeBleu_score": 38.34646403349067}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8def\u7531\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\\\");\n\nif (newData == null)\nreturn;\n\nvar route = await GetRoute(newData);\nif (route == null)\nreturn;\n\nvar oldRoute = _routes.Where(p => p.ServiceDescriptor.Id == route.ServiceDescriptor.Id).FirstOrDefault();\nif (oldRoute == null)\nreturn;\n\nif (DataEquals(newData, oldData))\nreturn;\n\nawait SetRoutesAsync(new[] { route });\n\nOnChanged(oldRoute, route);\n}", "CodeBleu_score": 34.66387163445327}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t(_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers!= null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n} else {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.068914209484404}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t(_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers)\n{\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers!= null)\n{\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds)\n{\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers)\n{\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null)\n{\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse\n{\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.06082679362903}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t(_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers!= null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n} else {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.068914209484404}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\\\"/\\\"))\npath += \\\"/\\\";\nforeach (var children in childrens) {\nvar nodePath = $\\\"{path}{children}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff1a{nodePath}\u3002\\\");\nvar result = await GetSubscriber(nodePath);\nif (result!= null)\nsubscribers.Add(result);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 48.505398181404736}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u5b50\u8282\u70b9\uff1a{string.Join(\\\",\\\", childrens.ToArray())}\u3002\\\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\\\"/\\\"))\npath += \\\"/\\\";\nforeach (var children in childrens) {\nvar nodePath = $\\\"{path}{children}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u8def\u5f84\uff1a{nodePath}\u3002\\\");\nvar subscriber = await GetSubscriber(nodePath);\nif (subscriber!= null)\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 61.08793995219736}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\n\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers)\n{\nvar path = _configInfo.SubscriberPath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1)\n{\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null)\n{\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null)\n{\nforeach (var child in result.Children)\n{\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(data)}\u3002\");\n\nif (data == null)\nreturn null;\n\nvar descriptor = _serializer.Deserialize<byte[], ServiceSubscriberDescriptor>(data);\nreturn (await _serviceSubscriberFactory.CreateServiceSubscribersAsync(new[] { descriptor })).First();\n}\n}\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 33.37159966816522}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) {\nreturn;\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.SubscriberPath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u83b7\u53d6\u8282\u70b9\uff1a{childPath}\u7684\u6570\u636e\u3002\");\nvar data = (await zooKeeper.Item2.getDataAsync(childPath)).Data;\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{childPath}\u7684\u6570\u636e\u4e3a\uff1a{Encoding.UTF8.GetString(data)}\u3002\");\nvar subscriber = await GetSubscriber(data);\nif (subscriber!= null) {\n_subscribers.Add(subscriber);\n}\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\u8282\u70b9\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u83b7\u53d6\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 36.4315375970774}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null)\nreturn;\n\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\\\"/\\\"))\npath += \\\"/\\\";\n\nif (await zooKeeper.Item2.existsAsync(path) == null) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\\\"\u8282\u70b9\uff1a{path}\u4e0d\u5b58\u5728\u3002\\\");\n_subscribers = new ServiceSubscriber[0];\nreturn;\n}\n\nvar childrens = (await zooKeeper.Item2.getChildrenAsync(path)).Children;\nif (childrens == null) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\\\"\u8282\u70b9\uff1a{path}\u4e0b\u6ca1\u6709\u5b50\u8282\u70b9\u3002\\\");\n_subscribers = new ServiceSubscriber[0];\nreturn;\n}\n\n_subscribers = await GetSubscribers(childrens);\n}\n}", "CodeBleu_score": 52.53099506783428}, {"code": "private async Task EnterSubscribers(){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u51c6\u5907\u521d\u59cb\u5316\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\n\nif (_subscribers!= null)\nreturn;\n\n_subscribers = new List<ServiceSubscriber>();\n\nvar zooKeeper = await GetZooKeeper();\n\nvar path = _configInfo.SubscriberPath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u4ece\u8282\u70b9\uff1a{childPath}\u4e2d\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\nvar subscriber = await GetSubscriber(childPath);\nif (subscriber!= null)\n_subscribers.Add(subscriber);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n\nif (_subscribers.Count == 0) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"\u670d\u52a1\u8ba2\u9605\u8005\u8282\u70b9\uff1a{path}\u4e0d\u5b58\u5728\u3002\");\n}\n}", "CodeBleu_score": 47.66418249704194}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(oldData)}\u3002\\\");\n\nif (oldData == null)\nreturn;\n\nvar oldCommand = GetServiceCommand(oldData);\nif (newData == null)\n{\nlock (_serviceCommands)\n{\n//\u5220\u9664\u65e7\u670d\u52a1\u547d\u4ee4\uff0c\u5e76\u6dfb\u52a0\u4e0a\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\n_serviceCommands =\n_serviceCommands\n.Where(i => i.ServiceId!= oldCommand.ServiceId)\n.ToArray();\n}\n\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(new ServiceCommandChangedEventArgs(null, oldCommand));\nreturn;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\\\");\n\nvar newCommand = GetServiceCommand(newData);\n\nlock (_serviceCommands)\n{\n//\u5220\u9664\u65e7\u670d\u52a1\u547d\u4ee4\uff0c\u5e76\u6dfb\u52a0\u4e0a\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\n_serviceCommands =\n_serviceCommands\n.Where(i => i.ServiceId!= newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(new ServiceCommandChangedEventArgs(newCommand, oldCommand));\n}", "CodeBleu_score": 71.72996730513356}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t//\u5f97\u5230\u65e7\u7684\u670d\u52a1\u547d\u4ee4\u3002\nvar oldCommand = _serviceCommands.FirstOrDefault(i => i.ServiceId == GetServiceCommand(oldData).ServiceId);\n\nlock (_serviceCommands) {\n//\u5220\u9664\u65e7\u670d\u52a1\u547d\u4ee4\uff0c\u5e76\u6dfb\u52a0\u4e0a\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\n_serviceCommands =\n_serviceCommands\n.Where(i => i.ServiceId!= GetServiceCommand(oldData).ServiceId)\n.Concat(new[] { GetServiceCommand(newData) }).ToArray();\n}\n\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(new ServiceCommandChangedEventArgs(GetServiceCommand(newData), oldCommand));\n}", "CodeBleu_score": 57.34594351596286}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t//\u5f97\u5230\u65e7\u7684\u670d\u52a1\u547d\u4ee4\u3002\nvar oldCommand = _serviceCommands.FirstOrDefault(i => i.ServiceId == GetServiceCommand(oldData).ServiceId);\n\nlock (_serviceCommands) {\n//\u5220\u9664\u65e7\u670d\u52a1\u547d\u4ee4\uff0c\u5e76\u6dfb\u52a0\u4e0a\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\n_serviceCommands =\n_serviceCommands\n.Where(i => i.ServiceId!= GetServiceCommand(oldData).ServiceId)\n.Concat(new[] { GetServiceCommand(newData) }).ToArray();\n}\n\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(new ServiceCommandChangedEventArgs(GetServiceCommand(newData), oldCommand));\n}", "CodeBleu_score": 57.34594351596286}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\nif (watchedEvent.Type == EventType.NodeDataChanged) {\n\n// Get the ZooKeeper client\nvar (resetEvent, zooKeeper) = await _zooKeeperCall();\n\n// Retrieve the updated data from the node\nvar (data, stat) = await zooKeeper.GetDataAsync(Path, false, resetEvent);\n\n// Execute the specified action with the current and new data\n_action(_currentData, data);\n\n// Update the watcher with the new data\n_currentData = data;\n}\n}", "CodeBleu_score": 46.32782532076561}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\nvar (eventResetEvent, zooKeeper) = await _zooKeeperCall();\nvar data = await zooKeeper.GetDataAsync(Path, null, watchedEvent.State);\nif (_currentData!= null && _currentData.Equals(data)) {\nreturn;\n}\n_currentData = data;\n_action(data, watchedEvent.State);\n}\n}", "CodeBleu_score": 49.77744068550686}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\nvar (manualResetEvent, zooKeeper) = await _zooKeeperCall();\n\nvar nodeData = await zooKeeper.GetDataAsync(Path, watchedEvent.State.HasFlag(WatcherChangeOption.None), null);\n_action(nodeData, _currentData);\n_currentData = nodeData;\n}\n}", "CodeBleu_score": 49.3342931038005}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tes.RegisterType<DefaultZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nreturn builder;\n}", "CodeBleu_score": 26.763838346372932}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tes.RegisterType<DefaultZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nreturn builder;\n}", "CodeBleu_score": 26.763838346372932}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tes.RegisterType<DefaultZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nreturn builder;\n}", "CodeBleu_score": 26.763838346372932}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u8bbe\u7f6emqtt\u8def\u7531\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6e05\u7a7a\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 50.48603314039386}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0mqtt\u8def\u7531\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.createAsync(nodePath, null, CreateMode.Persistent);\n}\n\nforeach (var route in routes) {\nvar nodePath = $\"{path}/{route.Name}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.createAsync(nodePath, _serializer.Serialize(route), CreateMode.Persistent);\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u6dfb\u52a0\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 56.638196025341735}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\troutePath = _configInfo.MqttRoutePath;\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = routePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 43.6811191451374}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\troutePaths = routes.Select(p => p.MqttDescriptor.Topic).ToArray();\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\n}", "CodeBleu_score": 52.029323627295845}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t", "CodeBleu_score": 5.074934513241618}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u66f4\u65b0\u5b8c\u6210\u3002\");\n}", "CodeBleu_score": 50.79405132297763}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tr caches = await GetCaches(cacheDescriptors.Select(p => p.Id));\nawait RemoveCachesAsync(cacheDescriptors);\nawait base.SetCachesAsync(cacheDescriptors);\n}", "CodeBleu_score": 8.119579467143796}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u66f4\u65b0\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 50.63785223569779}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u5b50\u76ee\u5f55\uff1a{path}\u3002\\\");\n\nvar result = await zooKeeper.Item2.existsAsync(path);\nif (result!= null)\nreturn;\n\nvar children = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (children.Count() > 1) {\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", children);\n\nif (await zooKeeper.Item2.existsAsync(nodePath)!= null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children!= null) {\nforeach (var child in result.Children) {\nvar childPath = $\\\"{nodePath}/{child}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u5b50\u76ee\u5f55\uff1a{childPath}\u3002\\\");\nawait zooKeeper.Item2.createAsync(childPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u5b50\u76ee\u5f55\uff1a{nodePath}\u3002\\\");\nawait zooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nindex++;\nchildren = children.Take(children.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u5b50\u76ee\u5f55\uff1a{path}\u3002\\\");\nawait zooKeeper.Item2.createAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}", "CodeBleu_score": 56.09713996851197}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t eventWaitHandle = zooKeeper.Item1;\nvar zkClient = zooKeeper.Item2;\n\nif (await zkClient.existsAsync(path) == null) {\nawait eventWaitHandle.WaitOne();\nif (await zkClient.existsAsync(path) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"Creating path: {path}\");\nawait zkClient.createAsync(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\n}\n}", "CodeBleu_score": 37.325725505007426}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t(_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u8282\u70b9\uff1a{path}\u3002\\\");\nvar exists = await zooKeeper.Item2.existsAsync(path);\n\nif (exists == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{path}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\\\");\nawait zooKeeper.Item2.createAsync(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n} else {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{path}\u5df2\u7ecf\u5b58\u5728\u3002\\\");\n}\n}", "CodeBleu_score": 42.78056381483667}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t result = new List<(ManualResetEvent, ZooKeeper)>();\nvar address = new List<AddressModel>();\nforeach (var addressModel in _config.Addresses) {\n_healthCheckService.Monitor(addressModel);\nvar task = _healthCheckService.IsHealth(addressModel);\nif (!(task.IsCompletedSuccessfully? task.Result : await task)) {\ncontinue;\n}\naddress.Add(addressModel);\n}\nif (address.Count == 0) {\nif (_logger.IsEnabled(Level.Warning))\n_logger.LogWarning($\"\u627e\u4e0d\u5230\u53ef\u7528\u7684\u6ce8\u518c\u4e2d\u5fc3\u5730\u5740\u3002\\\");\nreturn default(List<(ManualResetEvent, ZooKeeper)>);\n}\n\nvar vt = _zookeeperAddressSelector.SelectAsync(new AddressSelectContext {\nDescriptor = new ServiceDescriptor { Id = nameof(DefaultZookeeperClientProvider) },\nAddress = address\n});\nvar addr = vt.IsCompletedSuccessfully? vt.Result : await vt;\nif (addr!= null) {\nvar ipAddress = addr as IpAddressModel;\nresult.Add(CreateZooKeeper(ipAddress));\n}\nreturn result;\n}", "CodeBleu_score": 61.0934939980834}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t result = new List<(ManualResetEvent, ZooKeeper)>();\nvar address = new List<AddressModel>();\nforeach (var addressModel in _config.Addresses) {\n_healthCheckService.Monitor(addressModel);\nvar task = _healthCheckService.IsHealth(addressModel);\nif (!(task.IsCompletedSuccessfully? task.Result : await task)) {\ncontinue;\n}\naddress.Add(addressModel);\n}\nif (address.Count == 0) {\nif (_logger.IsEnabled(Level.Warning))\n_logger.LogWarning($\\\"\u627e\u4e0d\u5230\u53ef\u7528\u7684\u6ce8\u518c\u4e2d\u5fc3\u5730\u5740\u3002\\\");\nreturn default(IEnumerable<(ManualResetEvent, ZooKeeper)>);\n}\n\nvar vt = _zookeeperAddressSelector.SelectAsync(new AddressSelectContext {\nDescriptor = new ServiceDescriptor { Id = nameof(DefaultZookeeperClientProvider) },\nAddress = address\n});\nvar addr = vt.IsCompletedSuccessfully? vt.Result : await vt;\nif (addr!= null) {\nvar ipAddress = addr as IpAddressModel;\nresult.Add(CreateZooKeeper(ipAddress));\n}\nreturn result;\n}", "CodeBleu_score": 61.02808752969382}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tresult = new List<(ManualResetEvent, ZooKeeper)>();\nvar address = new List<AddressModel>();\nforeach (var addressModel in _config.Addresses) {\n_healthCheckService.Monitor(addressModel);\nvar task = _healthCheckService.IsHealth(addressModel);\nif (!(task.IsCompletedSuccessfully? task.Result : await task)) {\ncontinue;\n}\naddress.Add(addressModel);\n}\nif (address.Count == 0) {\nif (_logger.IsEnabled(Level.Warning))\n_logger.LogWarning($\"\u627e\u4e0d\u5230\u53ef\u7528\u7684\u6ce8\u518c\u4e2d\u5fc3\u5730\u5740\u3002\");\nreturn default(IEnumerable<(ManualResetEvent, ZooKeeper)>);\n}\n\nvar vt = _zookeeperAddressSelector.SelectAsync(new AddressSelectContext {\nDescriptor = new ServiceDescriptor { Id = nameof(DefaultZookeeperClientProvider) },\nAddress = address\n});\nvar addr = vt.IsCompletedSuccessfully? vt.Result : await vt;\nif (addr!= null) {\nvar ipAddress = addr as IpAddressModel;\nresult.Add(CreateZooKeeper(ipAddress));\n}\nreturn result;\n}", "CodeBleu_score": 61.02349133052633}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t", "CodeBleu_score": 1.6721771161767558}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t (this) {\nif (helper == null) {\nhelper = new Helper(new Helper.Data() {\n@Override\npublic ZooKeeper createZooKeeper(String connectionString, int sessionTimeout, Watcher watcher) throws Exception {\nreturn zookeeperFactory.create(connectionString, sessionTimeout, watcher);\n}\n\n@Override\npublic void close() {\n}\n});\n}\nreturn helper.getZooKeeper();\n}\n}", "CodeBleu_score": 36.49650795072444}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t null) {\nreturn helper.getZooKeeper();\n}\n\n//noinspection SynchronizationOnLocalVariableOrMethodParameter\nsynchronized (this) {\nif (helper == null) {\nHelper.Data data = new Helper.Data(); // data shared between initial Helper and the un-synchronized Helper\n// first helper is synchronized when getZooKeeper is called. Subsequent calls\n// are not synchronized.\n//noinspection NonAtomicOperationOnVolatileField\nhelper = new Helper(data) {\n@Override\nsynchronized void connect() throws Exception {\nif (helper == this) {\nif (data.zooKeeper == null) {\ndata.zooKeeper = new ZooKeeper(data.connectionString, data.sessionTimeout, data.watcher);\n}\n}\n}\n\n@Override\nsynchronized void close() throws InterruptedException {\nif (helper == this) {\nif (data.zooKeeper!= null) {\ndata.zooKeeper.close();\ndata.zooKeeper = null;\n}\n}\n}\n\n@Override\nsynchronized void resetConnectionString(String connectionString) {\nif (helper == this) {\ndata.connectionString = connectionString;\n}\n}\n\n@Override\nsynchronized int getNegotiatedSessionTimeoutMs() {\nif (helper == this) {\nreturn data.sessionTimeout;\n}\n\nreturn 0;\n}\n\n@Override\nsynchronized String getConnectionString() {\nif (helper == this) {\nreturn data.connectionString;\n}\n\nreturn null;\n}\n\n@Override\nsynchronized ZooKeeper getZooKeeper() {\nif (helper == this) {\nreturn data.zooKeeper;\n}\n\nreturn null;\n}\n\n@Override\nsynchronized void registerWatcher(Watcher watcher) {\nif (helper == this) {\ndata.watcher = watcher;\n}\n}\n\n@Override\nsynchronized void registerWatcher(Watcher watcher, WatchedEvent event) {\nif (helper == this) {\ndata.watcher = watcher;\ndata.watchedEvent = event;\n}\n}\n\n@Override\nsynchronized WatchedEvent getWatchedEvent() {\nif (helper == this) {\nreturn data.watchedEvent;\n}\n\nreturn null;\n}\n};\n}\n}\n\nreturn helper.getZooKeeper();\n}", "CodeBleu_score": 35.664446974466664}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t null) {\nfinal ZooKeeper zooKeeper = helper.getZooKeeper();\nif (zooKeeper!= null) {\nfinal Watcher dummyWatcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\n}\n};\nzooKeeper.register(dummyWatcher);\nif (waitForShutdownTimeoutMs > 0) {\nzooKeeper.close();\nzooKeeper.close(waitForShutdownTimeoutMs);\n} else {\nzooKeeper.close();\n}\n}\n}\n}", "CodeBleu_score": 41.87604907422365}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t null) {\nZooKeeper zooKeeper = helper.getZooKeeper();\nif (zooKeeper!= null) {\ntry {\nzooKeeper.register(new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\n// Do nothing.\n}\n});\nif (waitForShutdownTimeoutMs > 0) {\nzooKeeper.close();\nThread.sleep(waitForShutdownTimeoutMs);\n} else {\nzooKeeper.close();\n}\n} catch (InterruptedException e) {\nThread.currentThread().interrupt();\n}\n}\n}\n}", "CodeBleu_score": 41.71961493720831}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t null) {\nfinal ZooKeeper zooKeeper = helper.getZooKeeper();\nif (zooKeeper!= null) {\nfinal Watcher dummyWatcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\n}\n};\n\ntry {\nif (waitForShutdownTimeoutMs > 0) {\nzooKeeper.close(waitForShutdownTimeoutMs);\n} else {\nzooKeeper.close();\n}\n} catch (InterruptedException e) {\nThread.currentThread().interrupt();\n}\n}\n}\n}", "CodeBleu_score": 48.44298998892159}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (started.get()) {\n\t\tif (state.isConnected()) {\n\t\t\treturn true;\n\t\t}\n\t}\n\tlog.info(\"Waiting for connection\");\n\tlong startTime = System.currentTimeMillis();\n\tlong endTime = startTime + connectionTimeoutMs;\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (state.isConnected()) {\n\t\t\tlog.info(\"Connected to Zookeeper\");\n\t\t\treturn true;\n\t\t}\n\t\tThreadUtils.sleepMs(100);\n\t}\n\tlog.info(\"Timed out waiting for connection\");\n\treturn false;\n}", "CodeBleu_score": 39.652109784691916}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\tif (started.get()) {\nreturn true;\n}\n\nfinal CountDownLatch latch = new CountDownLatch(1);\nfinal AtomicBoolean result = new AtomicBoolean(false);\nfinal AtomicBoolean timedOut = new AtomicBoolean(false);\n\nfinal RetryLoop retryLoop = newRetryLoop();\nretryLoop.callWithRetry(new RetryLoop.CallWithRetry() {\n@Override\npublic void call(RetryLoop.CallWithRetry.Context context) throws Exception {\nresult.set(state.isConnected());\nlatch.countDown();\n}\n});\n\nfinal ThreadUtils.Timeout timeout = new ThreadUtils.Timeout(connectionTimeoutMs);\n\nif (!latch.await(connectionTimeoutMs, TimeUnit.MILLISECONDS)) {\ntimedOut.set(true);\n}\n\nif (timedOut.get()) {\nreturn false;\n}\n\nreturn result.get();\n}", "CodeBleu_score": 30.027411112830617}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlong start = System.currentTimeMillis();\n\tlog.info(\"blockUntilConnectedOrTimedOut: starting\");\n\tboolean connected = false;\n\ttry {\n\t\tconnected = state.blockUntilConnectedOrTimedOut(connectionTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (InterruptedException e) {\n\t\tlog.warn(\"blockUntilConnectedOrTimedOut: interrupted\", e);\n\t\tthrow e;\n\t}\n\tlong end = System.currentTimeMillis();\n\tlog.info(\"blockUntilConnectedOrTimedOut: done, connected={}\", connected);\n\ttracer.get().trace(OperationTrace.Type.CONNECT, start, end, connected);\n\treturn connected;\n}", "CodeBleu_score": 51.37098971865291}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\tif (started.compareAndSet(true, false)) {\nlog.debug(\\\"Closing\\\");\n\ntry {\nif (waitForShutdownTimeoutMs > 0) {\nlog.debug(\\\"Waiting for resources to be released\\\");\nstate.waitForShutdown(waitForShutdownTimeoutMs);\n}\n} catch (InterruptedException e) {\nlog.debug(\\\"Interrupted while waiting for resources to be released\\\", e);\nThread.currentThread().interrupt();\n}\n} else {\nlog.debug(\\\"Already closed\\\");\n}\n}", "CodeBleu_score": 43.4299801036697}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tlog.debug(\\\"Shutting down\\\");\n\nif (started.compareAndSet(true, false)) {\ntry {\nif (waitForShutdownTimeoutMs > 0) {\nstate.close(waitForShutdownTimeoutMs);\n} else {\nstate.close();\n}\n} catch (InterruptedException e) {\nlog.debug(\\\"Interrupted while waiting for shutdown\\\", e);\n} catch (IOException e) {\nlog.error(\\\"Error during shutdown\\\", e);\n}\n} else {\nlog.debug(\\\"Already shutdown\\\");\n}\n}", "CodeBleu_score": 55.319586769040626}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\tlog.debug(\\\"Shutting down\\\");\n\nif (!started.compareAndSet(true, false)) {\nthrow new IllegalStateException(\\\"Already shutdown\\\");\n}\n\nOperationTrace trace = startAdvancedTracer(\\\"close\\\");\n\ntry {\nstate.close(waitForShutdownTimeoutMs);\n} catch (InterruptedException e) {\nlog.debug(\\\"Interrupted while waiting for shutdown\\\", e);\n} catch (IOException e) {\nlog.debug(\\\"IOException while waiting for shutdown\\\", e);\n}\n\ntrace.commit();\n\nlog.debug(\\\"Shutdown complete\\\");\n}", "CodeBleu_score": 54.52966912325385}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tPreconditions.checkState(started.get(), \"Client is not started\");\n\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\nOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\n// A temporary watcher is added to monitor connection events, and a countdown latch is used to wait for either the connection or a timeout.\nWatcher watcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nif (event.getState() == Watcher.Event.KeeperState.SyncConnected) {\ntry {\n// If the connection is established, the watcher is removed and the countdown latch is released.\nlatch.countDown();\n} catch (InterruptedException e) {\nThreadUtils.checkInterrupted(e);\nlog.error(\"\", e);\n}\n}\n}\n};\n\ntry {\nstate.addWatcher(watcher);\n\n// The remaining wait time is adjusted accordingly.\nlong remaining = waitTimeMs;\nwhile (remaining > 0) {\ntry {\n// Wait for either the connection or a timeout.\nremaining = latch.await(remaining, TimeUnit.MILLISECONDS);\n} catch (InterruptedException e) {\nThreadUtils.checkInterrupted(e);\nlog.error(\"\", e);\n}\n}\n\n// If the connection is not established, the client is not connected.\n} finally {\nstate.removeWatcher(watcher);\n}\n\ntrace.commit();\n\nboolean localIsConnected = state.isConnected();\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + localIsConnected);\n}", "CodeBleu_score": 39.703437255488964}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tPreconditions.checkState(started.get(), \"Client is not started\");\n\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\nOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\nfinal CountDownLatch latch = new CountDownLatch(1);\nfinal AtomicBoolean connected = new AtomicBoolean(false);\nfinal AtomicBoolean timedOut = new AtomicBoolean(false);\n\nfinal Watcher watcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nif (event.getState() == Event.KeeperState.SyncConnected) {\nconnected.set(true);\n} else if (event.getState() == Event.KeeperState.Expired) {\ntimedOut.set(true);\n}\n\nlatch.countDown();\n}\n};\n\nstate.addParentWatcher(watcher);\n\ntry {\nlong startTime = System.currentTimeMillis();\nlong endTime = startTime + connectionTimeoutMs;\n\nwhile (!connected.get() &&!timedOut.get()) {\nlong remainingTime = endTime - System.currentTimeMillis();\nif (remainingTime <= 0) {\nbreak;\n}\n\nlong waitTime = Math.min(remainingTime, 1000);\n\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() sleeping for {} ms\", waitTime);\nThread.sleep(waitTime);\n}\n\n} finally {\nstate.removeParentWatcher(watcher);\n}\n\ntrace.commit();\n\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: {}\", connected.get());\n}", "CodeBleu_score": 41.937630406116824}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\tPreconditions.checkState(started.get(), \"Client is not started\");\n\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\nOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\ntry {\n// Create a temporary watcher that will be removed when the countdown latch is decremented.\n// The watcher is used to detect connection events.\nWatcher watcher = new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nif (event.getState() == KeeperState.SyncConnected) {\n// The connection is established.\n// The countdown latch is decremented to signal the waiter that the connection is established.\nlatch.countDown();\n} else if (event.getState() == KeeperState.Expired) {\n// The session has expired.\n// The countdown latch is decremented to signal the waiter that the connection is lost.\nlatch.countDown();\n}\n}\n};\n\n// Add the temporary watcher to the ZooKeeper client.\nstate.getZooKeeper().addWatch(Watcher.Event.KeeperState.SyncConnected, watcher);\n\n// Wait until the connection is established or the connection timeout is reached.\nlatch.await(connectionTimeoutMs, TimeUnit.MILLISECONDS);\n\n// Remove the temporary watcher.\nstate.getZooKeeper().removeWatch(Watcher.Event.KeeperState.SyncConnected, watcher);\n} catch (KeeperException | InterruptedException e) {\nThreadUtils.checkInterrupted(e);\nlog.error(\"\", e);\n}\n\ntrace.commit();\n\nboolean localIsConnected = state.isConnected();\nlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + localIsConnected);\n}", "CodeBleu_score": 34.0504767745782}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (doProtected() && (sessionId!= 0) && createMode.isEphemeral()) {\nlong newSessionId = client.getZooKeeper().getSessionId();\nif (newSessionId!= sessionId) {\nlog.info(\"Session ID changed from {} to {}\", sessionId, newSessionId);\nclient.getZooKeeper().delete(foundNode, -1);\nsessionId = newSessionId;\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 36.65816129190988}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (doProtected() && createMode.isEphemeral()) {\nlong newSessionId = client.getZooKeeper().getSessionId();\nif (newSessionId!= sessionId) {\nlog.warn(\"Session ID changed from {} to {} - deleting node {} and updating session ID\", sessionId, newSessionId, foundNode);\nclient.getZooKeeper().delete().deletingChildrenIfNeeded().forPath(foundNode);\nsessionId = newSessionId;\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 43.71479755850627}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (doProtected() && (sessionId!= 0) && createMode.isEphemeral()) {\nlong currentSessionId = client.getZooKeeper().getSessionId();\nif (currentSessionId!= sessionId) {\nlog.info(\"Session ID changed from {} to {}\", sessionId, currentSessionId);\nclient.getZooKeeper().delete(foundNode, sessionId);\nsessionId = currentSessionId;\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 38.24088702628201}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tl OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\nfinal RetryLoop retryLoop = client.getRetryLoop();\n\ntry {\nfinal Stat result = retryLoop.callWithRetry(\nnew Callable<Stat>() {\n@Override\npublic Stat call() throws Exception {\nfinal Stat stat = client.getZooKeeper().setACL(path, aclList, version);\ntrace.setReturnCode(0)\n.setPath(path)\n.setStat(stat)\n.commit();\nreturn stat;\n}\n},\nclient.getRetryPolicy(),\nclient.getZookeeperClient().getWatcher());\n\ntrace.setReturnCode(0)\n.setPath(path)\n.setStat(result)\n.commit();\nreturn result;\n} catch (Throwable e) {\ntrace.setReturnCode(1)\n.setPath(path)\n.commit();\nthrow e;\n}\n}", "CodeBleu_score": 62.264814547585566}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tl OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\nfinal Stat stat = new Stat();\nRetryLoop.callWithRetry(client.getZooKeeper(),\nnew Callable<Stat>() {\n@Override\npublic Stat call() throws Exception {\nclient.getSchemaSet().getSchema(path).validateGeneral(path, null, aclList);\nclient.getZooKeeper().setACL(path, aclList, version, stat);\nreturn stat;\n}\n},\nclient.getRetryPolicy(),\nclient.getZookeeperClient().getWatcher(),\nclient.getZookeeperClient().getExecutor());\ntrace.setReturnCode(0)\n.setPath(path)\n.setStat(stat)\n.commit();\nreturn stat;\n}", "CodeBleu_score": 52.44019302161267}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tl OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\nfinal RetryLoop retryLoop = new RetryLoop(client.getZookeeperClient().getZooKeeper(), client.getZookeeperClient().getRetryPolicy(), client.getZookeeperClient().getConnectionStateListenable(), client.getZookeeperClient().getWatcher(), client.getZookeeperClient().getCuratorWatcher());\nfinal Callable<Stat> callable = new Callable<Stat>() {\n@Override\npublic Stat call() throws Exception {\nStat stat = null;\ntry {\nstat = client.getZooKeeper().setACL(path, aclList, version);\n} catch (Exception e) {\ntrace.setReturnCode(e.hashCode())\n.setPath(path)\n.setStat(null)\n.commit();\nthrow e;\n}\ntrace.setReturnCode(0)\n.setPath(path)\n.setStat(stat)\n.commit();\nreturn stat;\n}\n};\nreturn retryLoop.callWithRetry(callable);\n}", "CodeBleu_score": 61.40192778592595}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tPreconditions.checkNotNull(client, \"client\");\nPreconditions.checkNotNull(membershipPath, \"membershipPath\");\nPreconditions.checkNotNull(thisId, \"thisId\");\nPreconditions.checkNotNull(payload, \"payload\");\nPreconditions.checkArgument(thisId.length() > 0, \"thisId must be non-empty\");\n\nthis.pen = new PersistentNode(client, membershipPath, payload, CreateMode.EPHEMERAL);\nthis.membershipPath = membershipPath;\nthis.thisId = thisId;\n\nCuratorCache cache = new CuratorCache(client, membershipPath, parentPathFilter());\nthis.cache = new CuratorCacheBridge(cache);\n}", "CodeBleu_score": 42.70101069396717}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\tPreconditions.checkNotNull(client, \"client\");\nPreconditions.checkNotNull(membershipPath, \"membershipPath\");\nPreconditions.checkNotNull(thisId, \"thisId\");\nPreconditions.checkNotNull(payload, \"payload\");\nthis.membershipPath = membershipPath;\nthis.thisId = thisId;\nthis.pen = new PersistentNode(client, membershipPath + \"/\" + thisId, payload);\nthis.cache = new CuratorCache(client, membershipPath, parentPathFilter());\n}", "CodeBleu_score": 40.31859884453855}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tPreconditions.checkNotNull(client, \"client cannot be null\");\n\tPreconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n\tPreconditions.checkNotNull(thisId, \"thisId cannot be null\");\n\tPreconditions.checkArgument(thisId.length() > 0, \"thisId cannot be empty\");\n\tPreconditions.checkNotNull(payload, \"payload cannot be null\");\n\n\tthis.pen = new PersistentNode(client, membershipPath, payload, CreateMode.EPHEMERAL);\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\n\tMap<String, String> data = ImmutableMap.of(GroupMemberConstants.MEMBER_ID, thisId);\n\tcache = new CuratorCache(client, membershipPath, data, parentPathFilter(membershipPath));\n}", "CodeBleu_score": 47.48860122009043}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = wrap(client);\n\n// create a node at the given path asynchronously\nasync.create().forPath(path).whenComplete((name, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Created node name is: \" + name);\n}\n});\n\n// set up a watch on the node to handle future events\nasync.getData().usingWatcher(new Watcher() {\n@Override\npublic void process(WatchedEvent event) throws Exception {\nif (event.getType() == Event.EventType.NodeDataChanged) {\nSystem.out.println(\"Node data changed event received for node: \" + event.getPath());\n}\n}\n}).forPath(path).whenComplete((data, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Node data is: \" + new String(data));\n}\n});\n}", "CodeBleu_score": 55.38422264002475}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = wrap(client);\n\n// create a node at the given path asynchronously\nasync.create().forPath(path).whenComplete((name, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Created node name is: \" + name);\n}\n});\n\n// set up a watch on the node to handle future events\nasync.setData().forPath(path).withMode(WatchMode.PERSISTENT).whenComplete((data, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Node data is: \" + new String(data));\n}\n});\n}", "CodeBleu_score": 58.63803087434795}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tsyncCuratorFramework async = wrap(client);\n\n// create a node at the given path asynchronously\nasync.create().forPath(path)\n.whenComplete((name, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Created node name is: \" + name);\n}\n});\n\n// set up a watch on the node to handle future events\nasync.setData().watched().forPath(path)\n.whenComplete((data, exception) -> {\nif (exception!= null) {\n// there was a problem\nexception.printStackTrace();\n} else {\nSystem.out.println(\"Data is: \" + new String(data));\n}\n});\n}", "CodeBleu_score": 59.275775256850295}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> resultList = client.getZookeeperClient().multi(transaction.getOps());\n\tif (resultList.size() > 0) {\n\t\tOpResult firstResult = resultList.get(0);\n\t\tif (firstResult.getType() == Op.Type.error) {\n\t\t\tOpResult.ErrorResult errorResult = (OpResult.ErrorResult) firstResult;\n\t\t\tthrow new KeeperException.Code(errorResult.getErr());\n\t\t}\n\t}\n\treturn resultList;\n}", "CodeBleu_score": 44.485358591115755}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> resultList = new ArrayList<>();\n\ttry {\n\t\tresultList = client.getZookeeperClient().multi(transaction.getOps());\n\t} catch (KeeperException e) {\n\t\tif (e.code() == KeeperException.Code.NONODE) {\n\t\t\t// This is the case where a path was created by another client in the same transaction.\n\t\t\t// The path may not exist yet, so we need to ignore the error.\n\t\t\tresultList = new ArrayList<>();\n\t\t} else {\n\t\t\tthrow e;\n\t\t}\n\t}\n\treturn resultList;\n}", "CodeBleu_score": 26.85209753668392}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tist<OpResult> resultList = new ArrayList<>();\n\nList<Op> opList = transaction.getOps();\n\nfor (Op op : opList) {\nOpResult opResult = client.getZookeeperClient().multi(op);\nresultList.add(opResult);\n}\n\nif (resultList.get(0).getType() == Op.OpType.error) {\nOpResult.ErrorResult errorResult = (OpResult.ErrorResult) resultList.get(0);\nthrow new KeeperException.Code(errorResult.getErr());\n}\n\nreturn resultList;\n}", "CodeBleu_score": 38.33642531967969}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tString> serviceNames = serviceDiscovery.queryForNames();\nfor (String serviceName : serviceNames) {\nIterable<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\nSystem.out.println(\\\"Service: \\\" + serviceName);\nfor (ServiceInstance<InstanceDetails> instance : instances) {\noutputInstance(instance);\n}\n}\n}", "CodeBleu_score": 36.872880454522736}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tn<String> services = serviceDiscovery.queryForNames();\nfor (String serviceName : services) {\nSystem.out.println(\\\"Service: \\\" + serviceName);\n\nfor (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(serviceName)) {\noutputInstance(instance);\n\n}\n}\n}", "CodeBleu_score": 25.781967421539182}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\ton<String> services = serviceDiscovery.queryForNames();\nif (services.isEmpty()) {\nSystem.err.println(\\\"No services registered\\\");\n} else {\nfor (String serviceName : services) {\nSystem.out.println(\\\"Service: \\\" + serviceName);\n\nCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\nif (instances.isEmpty()) {\nSystem.err.println(\\\"No instances for service: \\\" + serviceName);\n} else {\nfor (ServiceInstance<InstanceDetails> instance : instances) {\noutputInstance(instance);\n}\n}\n}\n}\n}", "CodeBleu_score": 41.41655877219964}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\tildren.stream().filter(c ->!c.equals(READY_NODE)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 13.97123064422517}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\ting> filteredChildren = new ArrayList<>();\n\nfor (String child : children) {\nif (!child.equals(READY_NODE)) {\nfilteredChildren.add(child);\n}\n}\n\nCollections.sort(filteredChildren);\n\nreturn filteredChildren;\n}", "CodeBleu_score": 27.489991036261756}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\ting> filteredChildren = new ArrayList<>(children);\n\nfilteredChildren.remove(READY_NODE);\n\nCollections.sort(filteredChildren);\n\nreturn filteredChildren;\n\n}", "CodeBleu_score": 22.713958724014027}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t", "CodeBleu_score": 4.002539703279978}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tif (newHost == null) {\n\t\tnewHost = host;\n\t}\n\tif (newHost.equals(host)) {\n\t\treturn;\n\t}\n\thost = newHost;\n\tif (readOnly) {\n\t\tzk = new ZooKeeper(host, sessionTimeout, new Watcher() {\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tif (event.getState() == Event.KeeperState.SyncConnected) {\n\t\t\t\t\tif (printWatches) {\n\t\t\t\t\t\tSystem.out.println(\\\"Sync connected event received\\\");\n\t\t\t\t\t}\n\t\t\t\t\treadOnly = false;\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t} else {\n\t\tzk = new ZooKeeper(host, sessionTimeout, this);\n\t}\n\tif (printWatches) {\n\t\tSystem.out.println(\\\"Connecting to \\\" + host + \\\" with session timeout \\\" + sessionTimeout);\n\t}\n}", "CodeBleu_score": 39.23461777332846}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk!= null) {\nzk.close();\n}\n\nif (newHost.equals(host)) {\nreturn;\n}\n\nhost = newHost;\n\nif (readOnly) {\nzk = new ZooKeeper(host, sessionTimeout, new Watcher() {\n@Override\npublic void process(WatchedEvent event) {\nif (event.getState() == KeeperState.SyncConnected) {\nreadOnly = false;\n}\n}\n});\n} else {\nzk = new ZooKeeper(host, sessionTimeout, this);\n}\n\n}", "CodeBleu_score": 40.95917794150937}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<>();\nif (aclString == null || aclString.length() == 0)\nreturn aclList;\nStringTokenizer tokenizer = new StringTokenizer(aclString, \\\",\\\");\nwhile (tokenizer.hasMoreTokens()) {\nString aclStringSegment = tokenizer.nextToken();\nStringTokenizer aclTokenizer = new StringTokenizer(aclStringSegment, \\\":\\\");\nif (aclTokenizer.countTokens()!= 3) {\nSystem.err.println(\\\"Invalid ACL format: \\\" + aclStringSegment);\ncontinue;\n}\nString scheme = aclTokenizer.nextToken();\nString id = aclTokenizer.nextToken();\nint perms = 0;\ntry {\nperms = Integer.parseInt(aclTokenizer.nextToken());\n} catch (NumberFormatException e) {\nSystem.err.println(\\\"Invalid ACL format: \\\" + aclStringSegment);\ncontinue;\n}\nif (scheme.equals(\\\"world\\\")) {\nif (id.equals(\\\"anyone\\\")) {\naclList.add(new ACL(perms, ZooDefs.Ids.ANYONE_ID_UNSAFE));\n} else {\nSystem.err.println(\\\"Invalid ACL format: \\\" + aclStringSegment);\ncontinue;\n}\n} else if (scheme.equals(\\\"auth\\\")) {\naclList.add(new ACL(perms, ZooDefs.Ids.AUTH_IDS));\n} else if (scheme.equals(\\\"digest\\\")) {\nif (id.length() == 0) {\nSystem.err.println(\\\"Invalid ACL format: \\\" + aclStringSegment);\ncontinue;\n}\naclList.add(new ACL(perms, ZooDefs.Ids.CREATOR_ALL_ACL));\n} else {\nSystem.err.println(\\\"Invalid ACL format: \\\" + aclStringSegment);\ncontinue;\n}\n}\nreturn aclList;\n}", "CodeBleu_score": 11.963564538503894}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\nStringTokenizer st = new StringTokenizer(aclString, \\\",\\\");\nwhile (st.hasMoreTokens()) {\nString acl = st.nextToken();\nStringTokenizer st2 = new StringTokenizer(acl, \\\" \\\");\nif (st2.countTokens()!= 3) {\nthrow new IOException(\\\"Invalid ACL format: \\\" + acl);\n}\nString scheme = st2.nextToken();\nString id = st2.nextToken();\nString perms = st2.nextToken();\ntry {\naclList.add(new ACL(getScheme(scheme), new Id(scheme, id), getPerm(perms)));\n} catch (IllegalArgumentException e) {\nthrow new IOException(\\\"Invalid ACL format: \\\" + acl);\n}\n}\nreturn aclList;\n}", "CodeBleu_score": 16.110432291464416}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\nString[] aclStrings = aclString.split(\\\", \\\");\nfor (String acl : aclStrings) {\nString[] aclParts = acl.split(\\\" \\\");\nif (aclParts.length!= 3) {\nthrow new IOException(\\\"Invalid ACL string: \\\" + aclString);\n}\nACL aclObj = new ACL();\naclObj.setId(new Id(aclParts[0], Integer.parseInt(aclParts[1])));\naclObj.setPerms(getPermInt(aclParts[2]));\naclList.add(aclObj);\n}\nreturn aclList;\n}", "CodeBleu_score": 15.508327062997013}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nList<String> subList = new ArrayList<>();\nfor (int i = 0; i < pathList.size(); i++) {\nsubList.add(pathList.get(i));\nif ((i + 1) % 20 == 0) {\nzookeeperMap.get(serverId).delete(subList);\nsubList = new ArrayList<>();\n}\n}\nif (!subList.isEmpty()) {\nzookeeperMap.get(serverId).delete(subList);\n}\n}\n}", "CodeBleu_score": 69.59144597011105}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ndelete(serverId, path);\n}\n} else {\nExecutorService executorService = Executors.newFixedThreadPool(pathList.size());\nfor (String path : pathList) {\nexecutorService.submit(() -> {\ntry {\ndelete(serverId, path);\n} catch (Exception e) {\nlog.error(\\\"delete error \\\" + serverId + \\\" -> \\\" + path, e);\n}\n});\n}\nexecutorService.shutdown();\nwhile (!executorService.isTerminated()) {\nThread.sleep(100);\n}\n}\n}", "CodeBleu_score": 58.860625905718656}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null) {\nthrow new IllegalArgumentException(\\\"pathList is null\\\");\n}\nif (pathList.size() < 20) {\npathList.forEach(path -> delete(serverId, path));\n} else {\nList<String> subPathList = new ArrayList<>();\nfor (String path : pathList) {\nsubPathList.add(path);\nif (subPathList.size() == 20) {\ndelete(serverId, subPathList);\nsubPathList.clear();\n}\n}\nif (!subPathList.isEmpty()) {\ndelete(serverId, subPathList);\n}\n}\n}", "CodeBleu_score": 53.06338568711644}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to \" + url + \"...\");\n\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(null)\n\t\t\t.maxRetries(3)\n\t\t\t.connectionTimeout(3000)\n\t\t\t.retryIntervalTime(1000)\n\t\t\t.sessionTimeout(30000)\n\t\t\t.build();\n\tvar connection = factory.createAsync(params, null);\n\twriter.write(\"Connected to \" + url + \"!\");\n\tvar zooKeeperMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, zooKeeperMain);\n}", "CodeBleu_score": 35.1679936850177}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to \" + url + \"...\n\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(aclList)\n.maxRetries(maxRetries)\n.connectionTimeout(connectionTimeout)\n.retryIntervalTime(retryIntervalTime)\n.sessionTimeout(sessionTimeout)\n.build();\nvar connection = factory.createAsync(params, serverListeners);\nwriter.write(\"Connected to \" + url + \"\n\");\nvar zooKeeperMain = new ZooKeeperMain(connection, tunnel, nodeListeners, serverListeners);\nreturn new Terminal(id, url, zooKeeperMain, writer);\n}", "CodeBleu_score": 36.8829014752387}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to \" + url + \"...\");\n\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(null)\n\t\t\t.maxRetries(5)\n\t\t\t.connectionTimeout(30000)\n\t\t\t.retryIntervalTime(1000)\n\t\t\t.sessionTimeout(30000)\n\t\t\t.build();\n\tvar connection = factory.createAsync(params, null);\n\twriter.write(\"Success\n\");\n\tvar zooKeeperMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 37.68661951448061}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t{\nsshClient = new SSHClient();\nsshClient.addHostKeyVerifier(new PromiscuousVerifier());\nsshClient.connect(getSshHost(), getSshPort());\nif (getSshPassword()!= null &&!getSshPassword().isBlank()) {\nlog.info(\"use password auth to create ssh-tunnel\");\nsshClient.authPassword(getSshUsername(), getSshPassword());\n} else if (getSshKeyFilePath()!= null &&!getSshKeyFilePath().isBlank()) {\nlog.info(\"use key file {} auth to create ssh-tunnel\", getSshKeyFilePath());\nsshClient.authPublickey(getSshUsername(), getSshKeyFilePath());\n} else {\nlog.info(\"use default key auth to create ssh-tunnel\");\nsshClient.authPublickey(getSshUsername());\n}\n\nproxySocket = new ServerSocket();\nproxySocket.setReuseAddress(true);\nproxySocket.bind(new InetSocketAddress(localhost, localPort));\nnew Thread(() -> {\ntry {\nParameters param = new Parameters(localhost, localPort, remoteHost, remotePort);\nsshClient.newLocalPortForwarder(param, proxySocket).listen();\n} catch (IOException e) {\nthrow new IllegalStateException(e.getMessage(), e);\n}\n}).start();\n} catch (IOException e) {\nif (e.getClass().getSimpleName().contains(\"Timeout\")) {\nthrow new IllegalStateException(\"SSH connect error by timeout: \" + sshHost, e);\n}\nif (e.getClass().getSimpleName().contains(\"UnknownHost\")) {\nthrow new IllegalStateException(\"SSH connect error by Unknown host \" + sshHost, e);\n}\nlog.error(\"create ssh-tunnel failed\", e);\nthis.close();\nthrow new IllegalStateException(\"create ssh-tunnel failed\", e);\n}\n}", "CodeBleu_score": 20.560793289954177}, {"code": "public void blockUntilConnected(){\n\t{\nsshClient = new SSHClient();\nsshClient.addHostKeyVerifier(new PromiscuousVerifier());\nsshClient.connect(getSshHost(), getSshPort());\nif (getSshPassword()!= null &&!getSshPassword().isBlank()) {\nlog.info(\"use password auth to create ssh-tunnel\");\nsshClient.authPassword(getSshUsername(), getSshPassword());\n} else if (getSshKeyFilePath()!= null &&!getSshKeyFilePath().isBlank()) {\nlog.info(\"use key file {} auth to create ssh-tunnel\", getSshKeyFilePath());\nsshClient.authPublickey(getSshUsername(), getSshKeyFilePath());\n} else {\nlog.info(\"use default key auth to create ssh-tunnel\");\nsshClient.authPublickey(getSshUsername());\n}\n\nproxySocket = new ServerSocket();\nproxySocket.setReuseAddress(true);\nproxySocket.bind(new InetSocketAddress(localhost, localPort));\nnew Thread(() -> {\ntry {\nParameters param = new Parameters(localhost, localPort, remoteHost, remotePort);\nsshClient.newLocalPortForwarder(param, proxySocket).listen();\n} catch (IOException e) {\nthrow new IllegalStateException(e.getMessage(), e);\n}\n}).start();\n} catch (IOException e) {\nif (e.getClass().getSimpleName().contains(\"Timeout\")) {\nthrow new IllegalStateException(\"SSH connect error by timeout: \" + sshHost, e);\n}\nif (e.getClass().getSimpleName().contains(\"UnknownHost\")) {\nthrow new IllegalStateException(\"SSH connect error by Unknown host \" + sshHost, e);\n}\nlog.error(\"create ssh-tunnel failed\", e);\nthis.close();\nthrow new IllegalStateException(\"create ssh-tunnel failed\", e);\n}\n}", "CodeBleu_score": 20.560793289954177}, {"code": "public void blockUntilConnected(){\n\t{\nint retries = 0;\nwhile (retries < 6) {\ntry {\nlog.info(\"Attempting to connect to {}:{}\", getSshHost(), getSshPort());\nsshClient.connect(getSshHost(), getSshPort());\nif (getSshPassword()!= null &&!getSshPassword().isBlank()) {\nlog.info(\"use password auth to create ssh-tunnel\");\nsshClient.authPassword(getSshUsername(), getSshPassword());\n} else if (getSshKeyFilePath()!= null &&!getSshKeyFilePath().isBlank()) {\nlog.info(\"use key file {} auth to create ssh-tunnel\", getSshKeyFilePath());\nsshClient.authPublickey(getSshUsername(), getSshKeyFilePath());\n} else {\nlog.info(\"use default key auth to create ssh-tunnel\");\nsshClient.authPublickey(getSshUsername());\n}\n\nParameters param = new Parameters(localhost, localPort, remoteHost, remotePort);\nsshClient.newLocalPortForwarder(param, proxySocket).listen();\nbreak;\n} catch (IOException e) {\nif (e.getClass().getSimpleName().contains(\"Timeout\")) {\nthrow new IllegalStateException(\"SSH connect error by timeout: \" + sshHost, e);\n}\nif (e.getClass().getSimpleName().contains(\"UnknownHost\")) {\nthrow new IllegalStateException(\"SSH connect error by Unknown host \" + sshHost, e);\n}\nlog.error(\"create ssh-tunnel failed\", e);\nthis.close();\nthrow new IllegalStateException(\"create ssh-tunnel failed\", e);\n}\nretries++;\n}\n} catch (IOException e) {\nif (e.getClass().getSimpleName().contains(\"Timeout\")) {\nthrow new IllegalStateException(\"SSH connect error by timeout: \" + sshHost, e);\n}\nif (e.getClass().getSimpleName().contains(\"UnknownHost\")) {\nthrow new IllegalStateException(\"SSH connect error by Unknown host \" + sshHost, e);\n}\nlog.error(\"create ssh-tunnel failed\", e);\nthis.close();\nthrow new IllegalStateException(\"create ssh-tunnel failed\", e);\n}\n}", "CodeBleu_score": 33.023758630049436}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\ttry {\nzookeeperDomainService.delete(serverId, pathList);\n} catch (Exception e) {\nlog.error(\"An error occurred while deleting nodes from Zookeeper: {}\", e.getMessage());\nthrow new IllegalStateException(\"An error occurred while deleting nodes from Zookeeper\", e);\n}\n}", "CodeBleu_score": 63.70784434397563}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node(s) from Zookeeper instance: {}\", serverId, e);\n\t\tthrow new IllegalStateException(\"Error deleting node(s) from Zookeeper instance: \" + serverId, e);\n\t}\n}", "CodeBleu_score": 63.159726787198466}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to delete node(s) from Zookeeper instance {}: {}\", serverId, e.getMessage());\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 68.47055432242854}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t\ttry {\n\t\tvar serverConfig = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfig);\n\t\tconfigurationDomainService.decrementConnectTimes(id);\n\t\ttreeItemCache.remove(id);\n\t} catch (Exception e) {\n\t\tlog.error(\"disconnect failed\", e);\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 44.837988116944075}, {"code": "public void disconnect(String id){\n\t\ttry {\n\t\tconfigurationDomainService.disconnect(id);\n\t\ttreeItemCache.remove(id);\n\t} catch (Exception e) {\n\t\tlog.error(\"disconnect server failed\", e);\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 23.011226273387056}, {"code": "public void disconnect(String id){\n\t\ttry {\n\t\tvar serverConfig = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfig);\n\t\tconfigurationDomainService.decrementConnectTimes(id);\n\t\tTreeItemCache.getInstance().remove(id);\n\t} catch (Exception e) {\n\t\tlog.error(\"disconnect server failed\", e);\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 45.152514145763064}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\n        final ServerConfiguration serverConfiguration = getServerConfigurationById(serverId);\n        final String connectionUrl = getConnectionUrl(serverConfiguration);\n        zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n    }", "CodeBleu_score": 24.3867612143535}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\n//        final ServerConfiguration serverConfiguration = configurationDomainService.getServerConfigurationById(serverId);\n//        final String connectionUrl = serverConfiguration.getZkConnectionUrl();\n//        zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n//    }", "CodeBleu_score": 3.866487938725357}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t//        final ServerConfiguration serverConfiguration = serverConfigurationService.getServerConfigurationById(serverId);\n        final String connectionUrl = serverConfiguration.getSSHTunnelEnabled()\n               ? serverConfiguration.getSSHTunnel().getConnectionUrl()\n                : serverConfiguration.getConnectionUrl();\n//        zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n    }", "CodeBleu_score": 26.8462968523449}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzookeeperDomainService.executeCommand(id, command);\n\t} catch (Exception e) {\n\t\tVToast.error(String.format(\\\"Failed to execute command on server \\\"%s\\\": \\\"%s\\\"\\\", id, command));\n\t}\n}", "CodeBleu_score": 43.39092563772715}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tzookeeperDomainService.executeCommand(id, command);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error executing command on server {}: {}\", id, command, e);\n\t\tVToast.error(\"Command execution failed, please retry\");\n\t}\n}", "CodeBleu_score": 59.25128812585776}, {"code": "public void executeCommand(String id, String command){\n\t\tvar server = configurationDomainService.getById(id).orElseThrow();\n\tvar urlToConnect;\n\tif (server.getSshTunnelEnabled()) {\n\t\turlToConnect = \"localhost:\" + server.getPort();\n\t} else {\n\t\turlToConnect = server.getHost() + \":\" + server.getPort();\n\t}\n\tzookeeperDomainService.executeCommand(id, urlToConnect, command);\n}", "CodeBleu_score": 29.63539307101064}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\ntry {\nvar file = new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE);\nif (file.exists()) {\nproperties.load(new FileInputStream(file));\nlog.info(\\\"loaded system properties from \\\" + file.getAbsolutePath());\n} else {\nlog.info(\\\"system properties file not found at \\\" + file.getAbsolutePath());\n}\n} catch (IOException e) {\nlog.error(\\\"error loading system properties from \\\" + ZOOKEEPER_SYSTEM_PROPERTIES_FILE, e);\n}\nreturn properties;\n}", "CodeBleu_score": 32.67501827843007}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tString path = System.getProperty(\"user.home\") + \"/.prettyZoo/conf/zookeeper.properties\";\n\tFile file = new File(path);\n\tif (file.exists()) {\n\t\ttry {\n\t\t\tProperties properties = new Properties();\n\t\t\tproperties.load(new FileInputStream(file));\n\t\t\tlog.info(\"Zookeeper system properties loaded from file: {}\", path);\n\t\t\treturn properties;\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Error loading Zookeeper system properties from file: {}\", path, e);\n\t\t}\n\t}\n\tlog.info(\"No Zookeeper system properties found in file: {}\", path);\n\treturn new Properties();\n}", "CodeBleu_score": 46.38292587141733}, {"code": "public Properties loadZookeeperSystemProperties(){\n\tProperties properties = new Properties();\nString path = System.getProperty(\\\"user.home\\\") + \\\"/.prettyZoo/conf/zoo.cfg\\\";\nif (new File(path).exists()) {\ntry {\nproperties.load(new FileInputStream(path));\nlog.info(\\\"Loaded zookeeper system properties from \\\" + path);\n} catch (IOException e) {\nlog.error(\\\"Failed to load zookeeper system properties from \\\" + path, e);\n}\n} else {\nlog.warn(\\\"Zookeeper system properties file \\\" + path + \\\" does not exist. Using default properties\\\");\n}\nreturn properties;\n}", "CodeBleu_score": 25.468023217068325}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\ttry {\nvar properties = new Properties();\nproperties.load(new StringReader(content));\nlog.info(\\\"load system properties success ->\n {}\\\", properties);\nproperties.store(new FileOutputStream(PrettyZooConfigRepository.SYS_PROP_PATH), null);\n} catch (IOException e) {\n// ignore error and log it\nlog.error(\\\"load system properties failed\\\", e);\nVToast.error(\\\"load system properties failed\\\");\n}\n}", "CodeBleu_score": 22.269355842154347}, {"code": "public void saveZookeeperSystemProperties(String content){\n\ttry {\nvar properties = new Properties();\nproperties.load(new StringReader(content));\nlog.info(\\\"load system properties success ->\n {}\\\", properties);\nproperties.store(new FileOutputStream(PrettyZooConfigRepository.SYS_PROP_PATH), \\\"system properties\\\");\nlog.info(\\\"save system properties success ->\n {}\\\", properties);\n} catch (IOException e) {\n// ignore error and log it\nlog.error(\\\"load system properties failed\\\", e);\n}\n}", "CodeBleu_score": 18.01356178050291}, {"code": "public void saveZookeeperSystemProperties(String content){\n\ttry {\nvar properties = new Properties();\nproperties.load(new StringReader(content));\nlog.info(\\\"load system properties success ->\n {}\\\", properties);\nproperties.store(new FileOutputStream(PrettyZooConfigRepository.SYS_PROP_PATH), \\\"update system properties\\\");\n} catch (IOException e) {\n// ignore error and log it\nlog.error(\\\"load system properties failed\\\", e);\n}\n}", "CodeBleu_score": 16.538170229452223}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\ttry (BufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()))) {\nStringBuilder response = new StringBuilder();\nfor (String line = reader.readLine(); line!= null; line = reader.readLine()) {\nresponse.append(line).append(\"\\\n\");\n}\nclient.close();\nreturn response.toString();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\n}", "CodeBleu_score": 43.1526349109353}, {"code": "private String response(Socket client){\n\ttry {\nBufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nStringBuilder builder = new StringBuilder();\nString line;\nwhile ((line = reader.readLine())!= null) {\nbuilder.append(line);\n}\nclient.close();\nreturn builder.toString();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\n}", "CodeBleu_score": 54.58588500512609}, {"code": "private String response(Socket client){\n\tStringBuilder response = new StringBuilder();\ntry {\nBufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\nString line;\nwhile ((line = reader.readLine())!= null) {\nresponse.append(line);\n}\nreader.close();\nclient.close();\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n}\nreturn response.toString();\n}", "CodeBleu_score": 51.9995232537359}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework client = CuratorFrameworkFactory.builder()\n   .connectString(params.getServers())\n   .sessionTimeoutMs(params.getSessionTimeout())\n   .connectionTimeoutMs(params.getConnectionTimeout())\n   .retryPolicy(new ExponentialBackoffRetry(params.getBaseSleepTime(), params.getMaxRetries()))\n   .build();\n\nif (params.getAuthInfo()!= null) {\nclient.setACLProvider(new ACLProvider() {\n    @Override\n    public List<ACL> getDefaultAcl() {\n        return ZooDefs.Ids.CREATOR_ALL_ACL;\n    }\n\n    @Override\n    public List<ACL> getAclForPath(String path) {\n        return ZooDefs.Ids.CREATOR_ALL_ACL;\n    }\n});\n}\n\nclient.start();\n\nclient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n    @Override\n    public void stateChanged(CuratorFramework client, ConnectionState newState) {\n        if (newState == ConnectionState.LOST) {\n            log.error(\\\"Connection to Zookeeper lost. Closing Curator client.\\\");\n            client.close();\n        }\n    }\n});\n\ntry {\n    client.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (Exception e) {\n    log.error(\\\"Failed to establish connection to Zookeeper. Closing Curator client.\\\");\n    client.close();\n    throw new RuntimeException(e);\n}\n\nreturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 37.226917397417175}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\nCuratorFramework client = CuratorFrameworkFactory.builder().connectString(params.getServerAddress())\n\n.retryPolicy(new ExponentialBackoffRetry(params.getConnectionTimeout(), params.getRetryCount()))\n\n.connectionTimeoutMs(params.getConnectionTimeout())\n\n.sessionTimeoutMs(params.getSessionTimeout())\n\n.namespace(params.getNamespace())\n\n.authorization(params.getAuthInfo())\n\n.aclProvider(params.getAclProvider())\n\n.build();\n\nclient.start();\n\ntry {\nclient.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (Exception e) {\nlog.error(\"Failed to connect to Zookeeper\", e);\nclient.close();\nthrow new RuntimeException(\"Failed to connect to Zookeeper\", e);\n}\n\nreturn new CuratorZookeeperConnection(client);\n}", "CodeBleu_score": 42.911471775313835}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework client = CuratorFrameworkFactory.builder()\n.connectString(params.getConnectString())\n.sessionTimeoutMs(params.getSessionTimeoutMs())\n.connectionTimeoutMs(params.getConnectionTimeoutMs())\n.retryPolicy(new ExponentialBackoffRetry(1000, 3))\n.build();\nclient.start();\ntry {\nclient.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (Exception e) {\nclient.close();\nthrow new RuntimeException(\"Could not connect to Zookeeper\", e);\n}\nreturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 48.974620660508606}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tync.get()) {\nlog.info(\\\"Sync already in progress.\\\");\nreturn;\n}\nisSync.set(true);\nlog.info(\\\"Starting sync of Zookeeper nodes.\\\");\ntry {\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\ntreeCache.start();\n} catch (Exception e) {\nlog.error(\\\"Error starting TreeCache: \\\" + e.getMessage(), e);\ntreeCache.close();\n}\n}", "CodeBleu_score": 30.5759099973052}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tync.get()) {\nlog.info(\\\"Synchronization is already in progress.\\\");\nreturn;\n}\nlog.info(\\\"Starting synchronization.\\\");\ntry {\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\ntreeCache.start();\nisSync.set(true);\n} catch (Exception e) {\nlog.error(\\\"Failed to start synchronization.\\\", e);\ntreeCache.close();\nisSync.set(false);\n}\n}", "CodeBleu_score": 33.21131991098466}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tSync.get()) {\nlog.info(\\\"Starting synchronization of Zookeeper nodes...\\\");\nisSync.set(true);\ntry {\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\ntreeCache.start();\n} catch (Exception e) {\nlog.error(\\\"Error occurred during synchronization of Zookeeper nodes:\\\", e);\ntreeCache.close();\nisSync.set(false);\n}\n} else {\nlog.info(\\\"Zookeeper nodes are already being synchronized.\\\");\n}\n}", "CodeBleu_score": 37.71696805246151}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\thildrenCache cache = new PathChildrenCache(client, path, true);\ncache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\ncache.getListenable().addListener(listener);\n}", "CodeBleu_score": 71.1050709136196}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\tChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 71.31256554899097}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\thildrenCache cache = new PathChildrenCache(client, path, true);\ncache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\ncache.getListenable().addListener(listener);\n}", "CodeBleu_score": 71.1050709136196}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\tlogger.info(\"Unregister service start\");\nfor (String path : pathList) {\ntry {\ncuratorClient.deletePath(path);\n} catch (Exception e) {\nlogger.error(\"Unregister service fail, exception: {}\", e.getMessage());\n}\n}\nlogger.info(\"Unregister service end\");\ncuratorClient.close();\n}", "CodeBleu_score": 51.52617221860052}, {"code": "public void unregisterService(){\n\tlogger.info(\\\"Start to unregister service\\\");\nfor (String path : pathList) {\ntry {\nthis.curatorClient.deletePath(path);\n} catch (Exception e) {\nlogger.error(\\\"Unregister service fail, path: {}, exception: {}\\\", path, e.getMessage());\n}\n}\nlogger.info(\\\"Unregister service success\\\");\nthis.curatorClient.close();\n}", "CodeBleu_score": 56.06012394126457}, {"code": "public void unregisterService(){\n\tlogger.info(\"Unregister all services\");\ntry {\nfor (String path : pathList) {\ncuratorClient.delete(path);\n}\n} catch (Exception e) {\nlogger.error(\"Unregister service fail, exception: {}\", e.getMessage());\n}\ncuratorClient.close();\n}", "CodeBleu_score": 49.50093262330162}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\tif (completableFuture.isDone()) {\nmakeClientReady();\n}\nclient.subscribeStateChanges(listener);\n}", "CodeBleu_score": 14.17902070668342}, {"code": "public void addListener(IZkStateListener listener){\n\tif (completableFuture.isDone()) {\ntry {\nclient.subscribeStateChanges(listener);\n} catch (Throwable t) {\nlogger.error(\"Error subscribing state listener\", t);\n}\n} else {\ncompletableFuture.whenComplete(this::makeClientReady);\n}\n}", "CodeBleu_score": 28.781723847815698}, {"code": "public void addListener(IZkStateListener listener){\n\ttry {\nclient.subscribeStateChanges(listener);\n} catch (Exception e) {\nlogger.error(\"Add listener failed!\", e);\n}\n}", "CodeBleu_score": 22.754616757368936}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis.client = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(new RetryNTimes(10, 1000)).connectionTimeoutMs(5000).authorization(\"digest\", authority.getBytes()).build();\nthis.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n@Override\npublic void stateChanged(CuratorFramework client, ConnectionState newState) {\nif (newState == ConnectionState.LOST) {\nthis.stateListener.connectionStateChanged(CuratorZookeeperClient.this, StateListener.State.LOST);\n} else if (newState == ConnectionState.CONNECTED) {\nthis.stateListener.connectionStateChanged(CuratorZookeeperClient.this, StateListener.State.CONNECTED);\n} else if (newState == ConnectionState.RECONNECTED) {\nthis.stateListener.connectionStateChanged(CuratorZookeeperClient.this, StateListener.State.RECONNECTED);\n}\n}\n});\nthis.client.start();\n}", "CodeBleu_score": 49.94413755763058}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis(serverAddr, authority, 30000, 30000);\n}", "CodeBleu_score": 3.4102573674902965}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis(serverAddr, authority, 30000, 30000);\n}", "CodeBleu_score": 3.4102573674902965}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners!= null) {\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener!= null) {\nremoveTargetChildListener(path, targetListener);\n}\n}\n}", "CodeBleu_score": 80.36479814632517}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners == null) {\nreturn;\n}\nTargetChildListener targetListener = listeners.get(listener);\nif (targetListener == null) {\nreturn;\n}\nlisteners.remove(listener);\nif (listeners.isEmpty()) {\nchildListeners.remove(path);\n}\nremoveTargetChildListener(path, targetListener);\n}", "CodeBleu_score": 65.87785518899561}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners!= null) {\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener!= null) {\nremoveTargetChildListener(path, targetListener);\n}\n}\n}", "CodeBleu_score": 80.36479814632517}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"Failed to get zookeeper handle!\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tstring idc_host;\n\tif (QCONF_OK!= lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host)) {\n\t\tLOG_ERR(\"Failed to get idc host!\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\n\tlock_ht_remove(_ht_handle_idchost, _ht_hi_mutex, htkey);\n\tzhandle_t *new_zh = NULL;\n\tnew_zh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == new_zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tinit_env_for_zk(new_zh, idc_host, idc);\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 59.78012250583535}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"The handle is null.\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tstring idc_host;\n\tif (QCONF_OK!= lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host)) {\n\t\tLOG_ERR(\"Failed to get idc host by handle.\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\n\tlock_ht_remove(_ht_handle_idchost, _ht_hi_mutex, htkey);\n\tlock_ht_remove(_ht_idchost_handle, _ht_ih_mutex, idc_host);\n\n\tzhandle_t *new_zh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == new_zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tinit_env_for_zk(new_zh, idc_host, idc);\n\treturn QCONF_OK;\n}", "CodeBleu_score": 61.04319722446019}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"The zhandle is null\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tstring idc_host;\n\tif (QCONF_OK!= lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host))\n\t\treturn QCONF_ERR_OTHER;\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\n\tlock_ht_remove(_ht_handle_idchost, _ht_hi_mutex, htkey);\n\tzhandle_t *new_zh = NULL;\n\tnew_zh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == new_zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tinit_env_for_zk(new_zh, idc_host, idc);\n\t_finish_process_tbl_sleep_setting = true;\n\treturn QCONF_OK;\n}", "CodeBleu_score": 60.68346803462414}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tLOG_TRACE(\"init_env_for_zk, idc_host:%s, idc:%s\", idc_host.c_str(), idc.c_str());\n\tlock_ht_insert(_ht_handle_idchost, _ht_hi_mutex, reinterpret_cast<unsigned long>(zh), idc_host);\n\tlock_ht_insert(_ht_idchost_handle, _ht_ih_mutex, idc_host, reinterpret_cast<unsigned long>(zh));\n\tif (QCONF_OK == zookeeper_add_auth(zh, \"digest\", _auth.c_str())) {\n\t\tif (QCONF_OK == zookeeper_set_watcher(zh, global_watcher)) {\n\t\t\tif (QCONF_OK == zookeeper_exists(zh, _notify_node.c_str(), 1, NULL)) {\n\t\t\t\tLOG_INFO(\"register current host on zookeeper server, idc:%s\", idc.c_str());\n\t\t\t\tif (QCONF_OK == zookeeper_register_host(zh, idc_host.c_str())) {\n\t\t\t\t\tLOG_INFO(\"set watcher on notify node, idc:%s\", idc.c_str());\n\t\t\t\t\tif (QCONF_OK == zookeeper_set_watcher(zh, global_watcher)) {\n\t\t\t\t\t\tLOG_INFO(\"init_env_for_zk success, idc:%s\", idc.c_str());\n\t\t\t\t\t\treturn;\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tLOG_ERR(\"init_env_for_zk failed, idc:%s\", idc.c_str());\n}", "CodeBleu_score": 46.15377231610493}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tlock_ht_insert(_ht_handle_idchost, _ht_hi_mutex, reinterpret_cast<unsigned long>(zh), idc_host);\n\tlock_ht_insert(_ht_idchost_handle, _ht_ih_mutex, idc_host, reinterpret_cast<unsigned long>(zh));\n\n\t// register current host\n\tint ret = zk_register_host(zh, idc_host);\n\tif (QCONF_OK!= ret) {\n\t\tLOG_ERR(\"Failed to register host to zk. idc_host:%s ret:%d\", idc_host.c_str(), ret);\n\t\treturn;\n\t}\n\n\t// set watcher for notify node\n\tret = zk_set_watcher(zh, idc_host);\n\tif (QCONF_OK!= ret) {\n\t\tLOG_ERR(\"Failed to set watcher for notify node. idc_host:%s ret:%d\", idc_host.c_str(), ret);\n\t\treturn;\n\t}\n\n\t// check connection state\n\tint state = zookeeper_state(zh);\n\tif (ZOO_CONNECTED_STATE!= state) {\n\t\tLOG_ERR(\"Failed to get zookeeper state. idc_host:%s state:%d\", idc_host.c_str(), state);\n\t\treturn;\n\t}\n\n\t// add gray idc\n\tadd_gray_idc(idc);\n}", "CodeBleu_score": 52.8683841057235}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t", "CodeBleu_score": 4.2583564394715525}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    digest = hashlib.sha1(password).digest()\n    return \"%s:%s\" % (username, b64encode(digest))\n", "CodeBleu_score": 12.276522225764685}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return \"%s:%s\" % (username, b64encode(hashlib.sha1(password).digest()))\n\n", "CodeBleu_score": 17.59254147280018}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + ':' + b64encode(hashlib.sha1(password).digest()).decode('utf-8')\n\n", "CodeBleu_score": 22.774517971117607}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.path + self.lock\n    with self.client.retry(self.client.transaction) as transaction:\n        try:\n            _, stat = transaction.get(lock_path)\n        except NoNodeError:\n            return False\n        return stat.data == self.id.encode()\n\n", "CodeBleu_score": 41.49414586382404}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.path + self.lock\n        with self.client.transaction() as transaction:\n            _, stat = transaction.get(lock_path)\n            if stat is None:\n                return False\n            else:\n                return stat.data == self.id\n\n", "CodeBleu_score": 38.88700332699607}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.path + self.lock\n    with self.client.transaction() as transaction:\n        _, stat = transaction.get(lock_path)\n        if stat.data!= self.id:\n            return False\n        return True\n\n", "CodeBleu_score": 39.861235038659515}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    self._ensure_paths()\n    with self.client.transaction() as transaction:\n        if self.processing_element is None:\n            return False\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        transaction.delete(lock_path)\n        transaction.delete(\"{path}/{id}\".format(path=self._entries_path, id=lock_id))\n        self.processing_element = None\n        return True\n\n", "CodeBleu_score": 57.137080545413085}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        with self.client.transaction() as transaction:\n            transaction.delete(lock_path)\n            transaction.delete(\"{path}/{id}\".format(path=self._entries_path, id=lock_id))\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 66.85846220026266}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        with self.client.transaction() as transaction:\n            transaction.delete(lock_path)\n            transaction.delete(\"{path}/{id}\".format(path=self._entries_path, id=lock_id))\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 68.47157364612934}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    self._outstanding_ping = False\n    self._outstanding_auth = False\n    self._outstanding_watch = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self._outstanding_txn = False\n    self._outstanding_txn_watch = False\n    self._outstanding_txn_data_child_watch = False\n    self._outstanding_txn_data_child = False\n    self._outstanding_txn_data = False\n    self._outstanding_txn_child = False\n    self", "CodeBleu_score": 10.122801307064453}, {"code": "def _read_socket(self, read_timeout)\n\t\n    self.logger.debug(\\\"_read_socket\\\")\n    header, buffer, offset = self._read_header(read_timeout)\n    self.logger.log(BLATHER, \\\"Read header %s\\\", header)\n    if header.xid == PING_XID:\n        self.logger.debug(\\\"Received ping\\\")\n        self._outstanding_pings.clear()\n        return\n    elif header.xid == AUTH_XID:\n        self.logger.debug(\\\"Received auth response\\\")\n        if header.err == 0:\n            self._auth_response = True\n            self.logger.debug(\\\"Authentication success\\\")\n            return\n        else:\n            self.logger.debug(\\\"Authentication failed\\\")\n            raise AuthFailed(\\\"authentication failed\\\")\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n        return\n    else:\n        self.logger.debug(\\\"Received response %s\\\", header)\n        self._read_response(header, buffer, offset)\n        return\n    raise RuntimeError(\\\"unreachable\\\")\n\n\n", "CodeBleu_score": 44.79914540052984}, {"code": "def _read_socket(self, read_timeout)\n\t\n    if read_timeout is not None:\n        self.handler.set_socket_timeout(read_timeout)\n    self.logger.debug(\\\"Reading from socket\\\")\n    header = self._read_header(read_timeout)\n    if header.xid == PING_XID:\n        self.logger.debug(\\\"Received PING\\\")\n        self._outstanding_pings.clear()\n    elif header.xid == AUTH_XID:\n        if header.err == 0:\n            self.logger.debug(\\\"Authentication successful\\\")\n            self._auth_successful = True\n        else:\n            self.logger.debug(\\\"Authentication failed\\\")\n            self.logger.debug(\\\"Received error: %s\\\", EXCEPTIONS[header.err]())\n            self._auth_successful = False\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(self.buffer, self.buffer_offset)\n    else:\n        self.logger.debug(\\\"Received response(xid=%s): %s\\\", header.xid, header)\n        self.buffer, self.buffer_offset = self._read_response(\n            header, self.buffer, self.buffer_offset\n        )\n    self.handler.set_socket_timeout(None)\n\n", "CodeBleu_score": 43.14356204374583}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.log(BLATHER, \\\"Starting connection loop\\\")\n    self._stopped.clear()\n    while not self._stopped.is_set():\n        try:\n            self._connect(self._connection_timeout)\n        except (ConnectionDropped, SessionExpiredError, ConnectionLossError):\n            self.logger.warn(\\\"Connection to Zookeeper failed\\\")\n            self._stopped.set()\n            self._session_callback(KeeperState.DISCONNECTED)\n            self.logger.log(BLATHER, \\\"Stopping connection loop\\\")\n            return\n        except Exception as exc:\n            self.logger.exception(\\\"Exception during connection loop\\\")\n            self._stopped.set()\n            self._session_callback(KeeperState.DISCONNECTED)\n            self.logger.log(BLATHER, \\\"Stopping connection loop\\\")\n            return\n        self._stopped.set()\n        self._session_callback(KeeperState.CONNECTED)\n        self.logger.log(BLATHER, \\\"Stopping connection loop\\\")\n        return\n", "CodeBleu_score": 42.25903078532148}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\\\"Starting Zookeeper connection loop\\\")\n    self._stopped.clear()\n    self._session_callback(KeeperState.DISCONNECTED)\n\n    # Attempt to connect to Zookeeper\n    while not self._stopped.is_set():\n        try:\n            self._connect(self._session_timeout)\n            break\n        except (ConnectionDropped, SessionExpiredError):\n            # These exceptions are expected, and are not errors\n            pass\n        except Exception as exc:\n            self.logger.exception(\n                \\\"Exception raised during connection\\\" \\\"attempt\\\", exc\n            )\n            self._session_callback(KeeperState.DISCONNECTED)\n            self._stopped.wait(self._session_timeout)\n\n    self._stopped.set()\n    self._session_callback(KeeperState.CLOSED)\n    self.logger.info(\\\"Stopped Zookeeper connection loop\\\")\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    # Set the connection_stopped event\n    self._stopped.set()\n\n    # Clear the connection_stopped event\n    self._stopped.clear()\n\n    #", "CodeBleu_score": 39.82469941366297}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\\\"Starting Zookeeper connection loop\\\")\n    self._stopped.clear()\n    self._connect()\n    while not self._stopped.is_set():\n        try:\n            self._connect()\n        except (ConnectionDropped, SessionExpiredError) as exc:\n            self.logger.warn(\n                \\\"Connection lost: %s\\\", exc\n            )\n            self._stopped.set()\n            self._session_callback(KeeperState.DISCONNECTED)\n            self.logger.warn(\\\"Stopping Zookeeper connection loop\\\")\n            return\n        except Exception as exc:\n            self.logger.exception(\n                \\\"Exception raised during connection: %s\\\", exc\n            )\n            self._stopped.set()\n            self._session_callback(KeeperState.DISCONNECTED)\n            self.logger.warn(\\\"Stopping Zookeeper connection loop\\\")\n            return\n        self._stopped.set()\n        self._session_callback(KeeperState.CONNECTED)\n        self.logger.info(\\\"Zookeeper connection established\\\")\n        self._read_loop()\n    self.logger.info(\\\"Stopping Zookeeper connection loop\\\")\n\n\n", "CodeBleu_score": 40.99753384131202}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t   try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 62.589749951211495}, {"code": "def leave(self)\n\t   try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 62.589749951211495}, {"code": "def leave(self)\n\t   try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n", "CodeBleu_score": 62.589749951211495}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\tMap map = new HashMap();\ntry {\nboolean status = hdfsOverFtpServer.statusServer();\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u72b6\u6001\u83b7\u53d6\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nmap.put(\"is_running\", false);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u72b6\u6001\u83b7\u53d6\u6210\u529f\");\n}\n}", "CodeBleu_score": 46.446117849137245}, {"code": "public Result start(){\n\tMap map = new HashMap();\ntry {\nboolean status = hdfsOverFtpServer.startServer();\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nmap.put(\"is_running\", false);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\");\n}\n}", "CodeBleu_score": 46.850604177749524}, {"code": "public Result start(){\n\tMap map = new HashMap<>();\ntry {\nboolean status = hdfsOverFtpServer.startServer();\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nmap.put(\"is_running\", false);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\");\n}\n}", "CodeBleu_score": 49.637474710210036}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 89.60593044836757}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 89.60593044836757}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 89.60593044836757}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tf (authorities == null || authorities.size() == 0) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.authorize(request)) {\n\t\t\treturn request;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 23.900569251359354}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tor (Authority authority : authorities) {\n\t\tif (authority.authorize(request)!= null) {\n\t\t\treturn request;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 15.148187352578123}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tor (Authority authority : authorities) {\n\t\trequest = authority.authorize(request);\n\t\tif (request == null) {\n\t\t\treturn null;\n\t\t}\n\t}\n\treturn request;\n}", "CodeBleu_score": 29.00916479898595}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.59138464273558}, {"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.59138464273558}, {"code": "public boolean mkdir(){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.59138464273558}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}, {"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}, {"code": "public boolean delete(){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 72.98458301107836}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.rename(fullPath, ftpFile.getAbsolutePath());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.594535823365824}, {"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.rename(path, ftpFile.getPath());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 52.23228630207124}, {"code": "public boolean move(FtpFile ftpFile){\n\try {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tString newPath = ftpFile.getParent().getAbsolutePath() + ftpFile.getName();\n\t\tfs.rename(fullPath, new Path(newPath));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 58.34855836794826}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] fileStatuses = dfs.listStatus(fullPath);\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (FileStatus fileStatus : fileStatuses) {\n\t\t\tString name = fileStatus.getPath().getName();\n\t\t\tFtpFile file = new HdfsFileObject(homePath.toString(), fileStatus.getPath().toString(), user);\n\t\t\tfiles.add(file);\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.debug(fullPath + \" is not a directory\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 38.48602640251684}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] files = dfs.listStatus(fullPath);\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tString virtualPath = fullPath.toString();\n\t\t\tString virtualName = virtualPath.substring(homePath.toString().length() + 1);\n\t\t\tif (virtualName.startsWith(File.separator)) {\n\t\t\t\tvirtualName = virtualName.substring(1);\n\t\t\t}\n\t\t\tif (virtualName.endsWith(File.separator)) {\n\t\t\t\tvirtualName = virtualName.substring(0, virtualName.length() - 1);\n\t\t\t}\n\t\t\tlist.add(new HdfsFileObject(homePath.toString(), virtualName, user));\n\t\t}\n\t\treturn Collections.unmodifiableList(list);\n\t} catch (IOException e) {\n\t\tlog.debug(fullPath + \" is not dir\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 42.213937822403494}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] files = dfs.listStatus(fullPath);\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tlist.add(new HdfsFileObject(homePath.toString(), file.getPath().toString(), user));\n\t\t}\n\t\treturn Collections.unmodifiableList(list);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error listing files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 29.730706834350727}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\tthrow new IllegalStateException(\\\"Configure can only be called once\\\");\n\t}\n\tisConfigured = true;\n\tuserDataProp = new BaseProperties();\n\ttry {\n\t\tif (userDataFile.exists()) {\n\t\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Could not load user data file: \\\" + userDataFile.getAbsolutePath(), e);\n\t}\n\tconvertDeprecatedProperties();\n}", "CodeBleu_score": 43.74193699481595}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\tthrow new IllegalStateException(\\\"Must be called before configure()\\\");\n\t}\n\tisConfigured = true;\n\tuserDataProp = new BaseProperties();\n\ttry {\n\t\tif (userDataFile.exists()) {\n\t\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Error loading user data file: \\\" + userDataFile.getAbsolutePath(), e);\n\t}\n\tconvertDeprecatedProperties();\n}", "CodeBleu_score": 37.4612016093461}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\tthrow new IllegalStateException(\\\"User manager already configured\\\");\n\t}\n\n\tisConfigured = true;\n\n\tuserDataProp = new BaseProperties();\n\n\tif (userDataFile.exists()) {\n\t\ttry {\n\t\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\\\"Error loading user data file: \\\" + userDataFile.getAbsolutePath(), e);\n\t\t}\n\t}\n\n\t// convert deprecated property names\n\tconvertDeprecatedProperties();\n}", "CodeBleu_score": 44.85257445138374}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\te parentDir = userDataFile.getParentFile();\n\tif (parentDir!= null &&!parentDir.exists()) {\n\t\tif (!parentDir.mkdirs()) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Unable to create parent directory of user data file: \"\n\t\t\t\t\t\t\t+ parentDir.getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, \"User data file\");\n\t} catch (IOException e) {\n\t\tLOG.error(\"Failed to save user data\", e);\n\t\tthrow new FtpException(\"Failed to save user data\", e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 54.59169774820315}, {"code": "private void saveUserData() throws FtpException{\n\te parentDir = userDataFile.getParentFile();\n\tif (parentDir!= null &&!parentDir.exists()) {\n\t\tif (!parentDir.mkdirs()) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Unable to create parent directory for user data file: \"\n\t\t\t\t\t\t\t+ userDataFile.getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, \"FTP Server User Data\");\n\t} catch (IOException e) {\n\t\tLOG.error(\"Failed to save user data\", e);\n\t\tthrow new FtpException(\"Failed to save user data\", e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 55.41847071640641}, {"code": "private void saveUserData() throws FtpException{\n\te parentDir = userDataFile.getParentFile();\n\tif (parentDir!= null &&!parentDir.exists()) {\n\t\tif (!parentDir.mkdirs()) {\n\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\"Failed to create parent directory of \" + userDataFile.getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, null);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Failed to save user data\", e);\n\t\tthrow new FtpException(\"Failed to save user data\", e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 51.83287688856778}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t/ log the path and buffer size\nLOG.info(\\\"open() - path: \\\" + path + \\\", bufferSize: \\\" + bufferSize);\n\n\n// qualify the path\nPath qPath = getQualifiedPath(path);\n\n\n// attempt to open the file\nFSDataInputStream fsDataInputStream = null;\n\ntry {\n\nfsDataInputStream = seaweedFileSystemStore.open(qPath, bufferSize);\n\n} catch (IOException e) {\n\nLOG.warn(\\\"open() - exception: \\\" + e.getMessage(), e);\n\n}\n\n\n// return the FSDataInputStream\nreturn fsDataInputStream;\n\n}", "CodeBleu_score": 21.468079755150356}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t get path and buffer size\nString pathName = path.toString();\nLOG.info(\\\"Opening file {} with buffer size {}\\\", pathName, bufferSize);\n\n// qualify path\npath = seaweedFileSystemStore.qualify(path);\n\n// open file\nFSDataInputStream fsDataInputStream = null;\n\ntry {\n\nfsDataInputStream = seaweedFileSystemStore.open(path, bufferSize);\n\n} catch (Exception e) {\n\nLOG.warn(\\\"Failed to open file {} with buffer size {}\\\", pathName, bufferSize, e);\n\n}\nreturn fsDataInputStream;\n}", "CodeBleu_score": 38.8298362832026}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\try {\n\nLOG.info(\\\"Opening \\\" + path + \\\" with buffer size \\\" + bufferSize);\n\n\nPath qualifiedPath = getQualifiedPath(path);\n\n\nFSDataInputStream fsDataInputStream = seaweedFileSystemStore.open(qualifiedPath, bufferSize);\n\n\nreturn fsDataInputStream;\n\n\n} catch (IOException e) {\n\nLOG.warn(\\\"Error opening \\\" + path + \\\": \\\" + e.getMessage());\n\n\nreturn null;\n\n\n}\n\n}", "CodeBleu_score": 16.431754305390143}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t", "CodeBleu_score": 3.957500776646815}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tth src = qualify(src);\nPath dst = qualify(dst);\n\nif (src.equals(dst)) {\nreturn true;\n}\n\nif (src.equals(workingDirectory)) {\nreturn false;\n}\n\nif (dst.equals(workingDirectory)) {\nreturn false;\n}\n\nPath dstDir = dst.getParent();\nif (dstDir!= null) {\ntry {\nFileStatus dstStatus = getFileStatus(dstDir);\nif (dstStatus.isDirectory()) {\ndst = new Path(dstDir, dst.getName());\n}\n} catch (FileNotFoundException e) {\nLOG.debug(\\\"Destination directory not found: \\\" + dstDir, e);\n}\n}\n\nLOG.debug(\\\"Rename from {} to {}\\\", src, dst);\n\nreturn seaweedFileSystemStore.rename(src, dst);\n}", "CodeBleu_score": 47.57538850076026}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tG.debug(\\\"rename source: {} destination: {}\\\", src, dst);\n\nif (src.equals(dst)) {\nreturn true;\n}\n\nif (src.equals(new Path(\\\"/\\\"))) {\nreturn false;\n}\n\nPath dstPath = dst;\n\nif (dst.getParent()!= null) {\ndstPath = dst.getParent();\n}\n\ndstPath = qualify(dstPath);\n\ntry {\nreturn seaweedFileSystemStore.rename(src, dstPath);\n} catch (Exception ex) {\nLOG.warn(\\\"rename source: {} destination: {}\\\", src, dst, ex);\nreturn false;\n}\n}", "CodeBleu_score": 37.93391252015132}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\treturn capability.toLowerCase(Locale.ROOT).equals(HSYNC) || capability.toLowerCase(Locale.ROOT).equals(HFLUSH) || capability.toLowerCase(Locale.ROOT).equals(HSYNC_HFLUSH);\n}", "CodeBleu_score": 42.42337705316534}, {"code": "public boolean hasCapability(String capability){\n\treturn capability.toLowerCase(Locale.ROOT).equals(\"hsync\") || capability.toLowerCase(Locale.ROOT).equals(\"hflush\") || capability.toLowerCase(Locale.ROOT).equals(\"hflush\");\n}", "CodeBleu_score": 41.73957417289578}, {"code": "public boolean hasCapability(String capability){\n\treturn capability.toLowerCase(Locale.ROOT).equals(\"hsync\") || capability.toLowerCase(Locale.ROOT).equals(\"hflush\") || capability.toLowerCase(Locale.ROOT).equals(\"hsync,hflush\");\n}", "CodeBleu_score": 41.79180320137306}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t.isDebugEnabled()) {\nLOG.debug(\\\"Flushing {} bytes from offset {} to service\\\", buffer.position(), offset);\n}\nif (shouldSaveMetadata) {\nentry.setOffset(offset);\nentry.setSize(buffer.position());\nif (LOG.isDebugEnabled()) {\nLOG.debug(\\\"Flushing entry to service\\\", entry);\n}\ntry {\nfilerClient.updateEntry(entry.build());\n} catch (FilerException e) {\nthrow new IOException(e.getMessage());\n}\n}\nlastFlushOffset = offset + buffer.position();\nbuffer.position(0);\n}", "CodeBleu_score": 34.65589641570775}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t.isDebugEnabled()) {\nLOG.debug(\\\"Flushing \\\" + (offset - lastFlushOffset) + \\\" bytes to the service\\\");\n}\n\nif (offset > lastFlushOffset) {\n// write metadata\nlastError = null;\ntry {\nfilerClient.writeMetadata(path, entry.build(), offset);\n} catch (Exception e) {\nlastError = new IOException(\\\"Failed to write metadata to the service\\\", e);\nthrow lastError;\n}\n\n// update last flush offset\nlastFlushOffset = offset;\n}\n}", "CodeBleu_score": 21.413150743713953}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\ttError!= null) {\nreturn;\n}\nif (offset > lastFlushOffset) {\ntry {\nif (shouldSaveMetadata) {\nentry.setOffset(offset);\nentry.setLength(lastTotalAppendOffset - offset);\nfilerClient.updateEntry(entry.build());\n}\nlastFlushOffset = offset;\n} catch (IOException e) {\nlastError = e;\nthrow e;\n}\n}\n}", "CodeBleu_score": 36.7568034872637}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tferToWrite.position() == 0) {\nreturn 0;\n}\n\nbufferToWrite.flip();\n\nfinal int byteLength = bufferToWrite.limit();\nfinal long offset = writePosition + byteLength;\n\n// System.out.println(path + \\\" write [\\\" + (outputIndex + byteLength) + \\\")\\\");\n\n// System.out.println(path + \\\"     [\\\" + (outputIndex + byteLength) + \\\") \\\" + bufferToWrite.capacity());\n\n// write to service\nfinal WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition, byteLength, offset);\nwriteOperations.add(writeOperation);\ncompletionService.submit(writeOperation);\n\n// System.out.println(path + \\\" write [\\\" + (outputIndex + byteLength) + \\\")\\\");\n\nreturn byteLength;\n}", "CodeBleu_score": 26.2137557225128}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tesWritten = 0;\n\nif (bufferToWrite.position() == 0) {\nreturn bytesWritten;\n}\n\nbufferToWrite.flip();\n\nint byteLength = bufferToWrite.limit();\n\nif (writeOperations.size() >= maxConcurrentRequestCount) {\ntry {\nThread.sleep(100);\n} catch (InterruptedException e) {\nthrow new IOException(e);\n}\n}\n\nWriteOperation writeOperation = new WriteOperation(writePosition, byteLength, bufferToWrite);\nwriteOperations.add(writeOperation);\n\ncompletionService.submit(new WriteTask(writeOperation));\n\nbytesWritten = byteLength;\n\nreturn bytesWritten;\n}", "CodeBleu_score": 32.4663023972612}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tem.out.println(\\\"[\\\" + writePosition + \\\",\\\" + ((writePosition + bufferToWrite.position()) + \\\") \\\" + buffer.capacity());\n\nfinal long bytesToWrite = bufferToWrite.position();\nfinal long writeOffset = writePosition;\n\nbufferToWrite.flip();\n\nfinal WriteOperation writeOperation = new WriteOperation(writeOffset, bufferToWrite, bytesToWrite, replication, collection);\n\n\nwriteOperations.add(writeOperation);\n\n\nif (writeOperations.size() >= maxConcurrentRequestCount) {\n\n// System.out.println(\\\"submitWriteBufferToService: queue is full, waiting for a slot to be freed\\\");\n\n\ncompletionService.submit(new Runnable() {\n\n@Override\n\npublic void run() {\n\ntry {\n\nwriteOperation.run();\n\n} catch (Exception ex) {\n\n// TODO: handle exception\n\n}\n\n}\n\n});\n\n}\n\n\nreturn bytesToWrite;\n\n}", "CodeBleu_score": 19.34401208029925}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\nwhile (true) {\ntry {\ncompletionService.take();\n} catch (InterruptedException e) {\nthrow new IOException(e);\n}\n}\n} catch (ExecutionException e) {\nthrow new IOException(e);\n}\n}", "CodeBleu_score": 23.94952592111517}, {"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\nwhile (true) {\ntry {\ncompletionService.take().get();\n} catch (InterruptedException e) {\nthrow new IOException(e);\n}\n}\n} catch (ExecutionException e) {\nthrow new IOException(e);\n}\n}", "CodeBleu_score": 20.319711536964537}, {"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\nwhile (true) {\ntry {\ncompletionService.take().get();\n} catch (InterruptedException e) {\nthrow new IOException(e);\n} catch (ExecutionException e) {\nthrow new IOException(e);\n}\n}\n} catch (InterruptedException e) {\nthrow new IOException(e);\n}\n}", "CodeBleu_score": 22.69211289273873}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\nfor (Iterator<WriteOperation> it = writeOperations.iterator(); it.hasNext();) {\nWriteOperation writeOperation = it.next();\n\nif (writeOperation.getJob().isDone()) {\ntry {\nwriteOperation.getJob().get();\nit.remove();\n} catch (InterruptedException e) {\nlastError = (IOException) new InterruptedIOException(e.toString()).initCause(e);\nthrow lastError;\n} catch (ExecutionException e) {\nlastError = new IOException(e.toString()).initCause(e);\nthrow lastError;\n}\n}\n}\n\n}", "CodeBleu_score": 32.82695049507693}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t", "CodeBleu_score": 1.7963923232153831}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t", "CodeBleu_score": 1.7963923232153831}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\\\"User cannot be null\\\");\n\t}\n\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n\tif (homePath == null) {\n\t\tthrow new IllegalArgumentException(\\\"User's home directory cannot be null\\\");\n\t}\n}", "CodeBleu_score": 47.513546531144335}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User home directory cannot be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory().getPath();\n\tthis.user = user;\n}", "CodeBleu_score": 70.25629972991865}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory().getAbsolutePath();\n}", "CodeBleu_score": 66.25043131672345}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = new Path(dir);\n\tif (newPath.isAbsolute()) {\n\t\tif (newPath.getParent()!= null) {\n\t\t\tcurrPath = newPath.getParent();\n\t\t} else {\n\t\t\tcurrPath = File.separator;\n\t\t}\n\t} else {\n\t\tcurrPath = newPath.toString();\n\t}\n\treturn true;\n}", "CodeBleu_score": 18.697137080060134}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be null\\\");\n\t}\n\tPath newPath = new Path(dir);\n\tif (newPath.isAbsolute()) {\n\t\tif (newPath.getParent() == null) {\n\t\t\treturn false;\n\t\t}\n\t\tcurrPath = newPath.getParent();\n\t} else {\n\t\tcurrPath = currPath + newPath;\n\t}\n\treturn true;\n}", "CodeBleu_score": 18.946990660327987}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null) {\n\t\treturn false;\n\t}\n\n\tif (dir.equals(File.separator)) {\n\t\tcurrPath = File.separator;\n\t\treturn true;\n\t}\n\n\tif (dir.equals(File.separator + \".\")) {\n\t\treturn true;\n\t}\n\n\tif (dir.equals(File.separator + \"..\")) {\n\t\tif (currPath.equals(File.separator)) {\n\t\t\treturn false;\n\t\t}\n\n\t\tint index = currPath.lastIndexOf(File.separator);\n\t\tcurrPath = currPath.substring(0, index);\n\t\treturn true;\n\t}\n\n\tif (dir.startsWith(File.separator)) {\n\t\tcurrPath = dir;\n\t\treturn true;\n\t}\n\n\tif (currPath.equals(File.separator)) {\n\t\tcurrPath = dir;\n\t\treturn true;\n\t}\n\n\tif (currPath.endsWith(File.separator)) {\n\t\tcurrPath += dir;\n\t\treturn true;\n\t}\n\n\tcurrPath += File.separator + dir;\n\treturn true;\n}", "CodeBleu_score": 29.63327424021425}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tthis.conf = conf;\nthis.filerClient = new FilerClient(host, port, grpcPort);\nthis.accessMode = getAccessMode(conf);\n}", "CodeBleu_score": 28.296829104139753}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.conf = conf;\n\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(ACCESS_MODE);\n}", "CodeBleu_score": 27.80936868626297}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t", "CodeBleu_score": 9.364506810909306}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n}\nLOG.debug(\\\"openFileForRead path: {} entry: {}\\\", path, entry);\n\nreturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n\n}", "CodeBleu_score": 54.5110639985453}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n}", "CodeBleu_score": 52.364375310315715}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n}\nLOG.debug(\\\"openFileForRead path:{} entry:{}\\\", path, entry);\n\nreturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n\n}", "CodeBleu_score": 54.54824460970381}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\tsuper.configure(conf);\ntry {\nhostName = InetAddress.getLocalHost().getHostName();\n} catch (Exception e) {\nhostName = \"localhost\";\n}\nthreadsPerMap = conf.getInt(\"io.juicefs.bench.threads.per.map\", 1);\nfilesPerThread = conf.getInt(\"io.juicefs.bench.files.per.thread\", 1);\npool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 56.57144200133235}, {"code": "public void configure(JobConf conf){\n\tsuper.configure(conf);\ntry {\nhostName = InetAddress.getLocalHost().getHostName();\n} catch (IOException e) {\nhostName = \"localhost\";\n}\nthreadsPerMap = conf.getInt(\"mapred.threads.per.map\", 1);\nfilesPerThread = conf.getInt(\"mapred.files.per.thread\", 1);\npool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 54.86186797761042}, {"code": "public void configure(JobConf conf){\n\tsuper.configure(conf);\ntry {\nhostName = InetAddress.getLocalHost().getHostName();\n} catch (Exception e) {\nhostName = \"localhost\";\n}\nthreadsPerMap = conf.getInt(\"io.threads.per.map\", 1);\nfilesPerThread = conf.getInt(\"io.files.per.thread\", 1);\npool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 56.6706827421016}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tf (emptierFs!= null) {\nreturn;\n}\n\n// Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser\nUserGroupInformation superuser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"juicefs\"));\nsuperuser.doAs(new PrivilegedExceptionAction<Void>() {\n@Override\npublic Void run() throws Exception {\nemptierFs = FileSystem.newInstance(uri, conf);\nreturn null;\n}\n});\n\n// Start the trash emptier task using the initialized file system and the trash configuration\nfinal JuiceFileSystemImpl juiceFs = (JuiceFileSystemImpl) emptierFs;\nfinal String trashPath = getConf(conf, \"trash\", \"/juicefs/trash\");\nfinal int interval = Integer.parseInt(getConf(conf, \"trash-emptier-interval\", \"10\"));\n\n// Schedule the trash emptier task to run every 10 minutes\nBgTaskUtil.scheduleTask(new Runnable() {\n@Override\npublic void run() {\ntry {\njuiceFs.emptyTrash(trashPath);\n} catch (IOException e) {\nLOG.error(\"Failed to empty trash: {}\", e.getMessage());\n}\n}\n}, interval, TimeUnit.MINUTES);\n}", "CodeBleu_score": 43.51688671579822}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tf (emptierFs!= null) {\nreturn;\n}\ntry {\nemptierFs = new JuiceFileSystemImpl(uri, conf, UserGroupInformation.getCurrentUser(),\nnew Configuration(conf));\n} catch (IOException e) {\nLOG.error(\\\"Failed to initialize trash emptier for URI \\\" + uri, e);\nthrow e;\n}\nfinal JuiceFileSystemImpl juiceFs = (JuiceFileSystemImpl) emptierFs;\nJuiceFsTrashEmptier trashEmptier = new JuiceFsTrashEmptier(juiceFs, conf);\nBgTaskUtil.scheduleAtFixedRate(\\\"TrashEmptier\\\", trashEmptier, 10, 10, TimeUnit.MINUTES);\n}", "CodeBleu_score": 29.67363890158337}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tf (emptierFs!= null)\nreturn;\n\nfinal String host = uri.getHost();\nif (BgTaskUtil.isTaskRunning(host, JuiceFileSystem.class.getName(), \\\"trashEmptier\\\"))\nreturn;\n\ntry {\nemptierFs = new JuiceFileSystemImpl(conf);\n} catch (IOException e) {\nthrow new IOException(\\\"Failed to initialize JuiceFileSystemImpl for trash emptier\\\", e);\n}\n\ntry {\nUserGroupInformation.createRemoteUser(host).doAs(new PrivilegedExceptionAction<Void>() {\n@Override\npublic Void run() throws Exception {\nemptierFs.initialize(uri, conf);\nreturn null;\n}\n});\n} catch (Exception e) {\nthrow new IOException(\\\"Failed to initialize JuiceFileSystemImpl for trash emptier\\\", e);\n}\n\nBgTaskUtil.scheduleTask(new Runnable() {\n@Override\npublic void run() {\ntry {\nemptierFs.delete(emptierFs.getTrashRoot(), true);\n} catch (IOException e) {\nLOG.warn(\\\"Failed to empty trash root\\\", e);\n}\n}\n}, 10, TimeUnit.MINUTES);\n}", "CodeBleu_score": 26.170566348987983}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\n}", "CodeBleu_score": 3.1494709380915578}, {"code": "public static void setContext(String context) throws Exception{\n\tif (context == null) {\nthrow new IllegalArgumentException(\\\"context is null\\\");\n}\nCallerContext callerContext = CallerContext.get();\nif (callerContext == null) {\nthrow new IllegalArgumentException(\\\"caller context is null\\\");\n}\nif (callerContext.isInvalid()) {\ncallerContext = new CallerContext(context);\n} else if (!callerContext.isCallerContextValid()) {\nthrow new IllegalArgumentException(\\\"caller context is invalid\\\");\n} else if (!callerContext.isCallerContextValid(context)) {\ncallerContext.setCallerContext(context);\n}\n}", "CodeBleu_score": 29.68315231385073}, {"code": "public static void setContext(String context) throws Exception{\n\t\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final org.apache.hadoop.ipc.CallerContext callerContext = org.apache.hadoop.ipc.CallerContext.get();\nCallerContext callerContext = CallerContext.get();\nif (callerContext == null) {\nthrow new Exception(\"CallerContext is not set\");\n}\n\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final java.util.Set<String> currentContext = callerContext.get();\nSet<String> currentContext = callerContext.get();\n\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final boolean valid = currentContext!= null && currentContext.contains(context);\nbool valid = currentContext!= null && currentContext.contains(context);\nif (valid) {\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final boolean hasSignature = callerContext.hasSignature();\nbool hasSignature = callerContext.hasSignature();\nif (hasSignature) {\nreturn;\n}\n\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final boolean contains = currentContext.contains(context);\nbool contains = currentContext.contains(context);\nif (contains) {\nreturn;\n}\n}\n\n//JAVA TO C# CONVERTER WARNING: The original Java variable was marked 'final':\n//ORIGINAL LINE: final java.util.Set<String> newContext = new java.util.HashSet<>(currentContext);\nSet<String> newContext = new HashSet<String>(currentContext);\nnewContext.add(context);\ncallerContext.set(newContext);\n}", "CodeBleu_score": 36.111076511505914}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint ret = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\nif (ret < 0) {\nreturn LOG_STATUS(\nStatus_HDFSError(std::string(\"Cannot remove path: \") + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 91.91928398626979}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\n\tif (rc < 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 75.89970246609485}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 1);\n\tif (rc < 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\n\t\t\t\t\"Cannot remove path: \" + uri.to_string()));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 73.95443879702526}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn Status::Ok();\n}\nhdfsFile write_file = libhdfs_->hdfsOpenFile(\nfs, uri.to_path().c_str(), O_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\nif (!write_file) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot write to file \") + uri.to_string() +\n\"; File opening error\"));\n}\n// Flush the data to HDFS\nif (libhdfs_->hdfsFlush(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot write to file \") + uri.to_string() +\n\"; File flushing error\"));\n}\n// Close file\nif (libhdfs_->hdfsCloseFile(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot write to file \") + uri.to_string() +\n\"; File closing error\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 80.3966966771497}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn Status::Ok();\n}\nhdfsFile write_file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(),\nO_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\nif (!write_file) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") +\nuri.to_string() +\n\"; File opening error\"));\n}\n// Flush file\nif (libhdfs_->hdfsFlush(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") +\nuri.to_string() +\n\"; File flushing error\"));\n}\n// Close file\nif (libhdfs_->hdfsCloseFile(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") +\nuri.to_string() +\n\"; File closing error\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 79.90558747991501}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tbool file_exists = false;\n\tRETURN_NOT_OK(is_file(uri, &file_exists));\n\tif (!file_exists) {\n\t\treturn Status::Ok();\n\t}\n\thdfsFile write_file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\n\tif (!write_file) {\n\t\treturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") + uri.to_string() + \"; File opening error\"));\n\t}\n\t// Flush data to HDFS\n\tif (libhdfs_->hdfsFlush(fs, write_file)) {\n\t\treturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") + uri.to_string() + \"; File flushing error\"));\n\t}\n\t// Close file\n\tif (libhdfs_->hdfsCloseFile(fs, write_file)) {\n\t\treturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot sync file \") + uri.to_string() + \"; File closing error\"));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 80.24182868667515}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\n\thdfsFileInfo* fileInfo = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n\tif (fileInfo == NULL) {\n\t\tif (errno) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(std::string(\"Cannot get file size for \") + uri.to_string()));\n\t\t}\n\t}\n\n\t*nbytes = fileInfo->mSize;\n\tlibhdfs_->hdfsFreeFileInfo(fileInfo, 1);\n\treturn Status::Ok();\n}", "CodeBleu_score": 56.074762328579496}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t/*\n * The file_size function retrieves the size of a file in HDFS specified by a URI.\nIt connects to the HDFS file system and obtains the file information.\nIf the file information cannot be retrieved or the path is not a file, it logs an error and returns a failure status.\nIf the path is a file, it sets the size in bytes and frees the file information.\nFinally, it returns an Ok status if successful.\n */\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n\n  bool file_exists = false;\n  RETURN_NOT_OK(is_file(uri, &file_exists));\n  if (!file_exists) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot get file size for path '\") + uri.to_string() +\n        \"'; path does not exist\"));\n  }\n\n  // Obtain file information\n  hdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == NULL) {\n    if (errno) {\n      return LOG_STATUS(Status_HDFSError(\n          std::string(\"Cannot get file size for path '\") + uri.to_string() +\n          \"'; cannot get file information\"));\n    }\n  }\n\n  // Set size in bytes and free file information\n  *nbytes = file_info->mSize;\n  libhdfs_->hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 59.65965825728811}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\n\thdfsFileInfo* fileInfo = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\n\tif (fileInfo == NULL) {\n\t\tif (errno) {\n\t\t\treturn LOG_STATUS(Status_HDFSError(\n\t\t\t\tstd::string(\"Cannot get file information for \") + uri.to_string()\n\t\t\t));\n\t\t}\n\t}\n\n\t*nbytes = fileInfo->mSize;\n\tlibhdfs_->hdfsFreeFileInfo(fileInfo, 1);\n\treturn Status::Ok();\n}", "CodeBleu_score": 55.61195967299339}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\tString hbaseQuorum = null;\nString hbaseZnodeParent = null;\nif (hbaseCfgString!= null) {\ntry {\nMap<String, String> hbaseCfg = JSON.parseObject(hbaseCfgString, new TypeReference<HashMap<String, String>>() {\n});\nhbaseQuorum = hbaseCfg.get(HBaseKey.HBASE_ZOOKEEPER_QUORUM);\nhbaseZnodeParent = hbaseCfg.get(HBaseKey.HBASE_ZOOKEEPER_ZNODE_PARENT);\n} catch (Exception e) {\nLOG.warn(\\\"Failed to parse HBase config string\\\", e);\n}\n}\nif (hbaseQuorum == null) {\nhbaseQuorum = \\\"hbase.zookeeper.quorum\\\";\n}\nif (hbaseZnodeParent == null) {\nhbaseZnodeParent = \\\"hbase.zookeeper.znode.parent\\\";\n}\nreturn Pair.of(hbaseQuorum, hbaseZnodeParent);\n}", "CodeBleu_score": 41.159267575905744}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\n}", "CodeBleu_score": 3.9183993588835753}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\n}", "CodeBleu_score": 3.9183993588835753}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\ty {\n// 1. \u5efa\u7acb\u8fde\u63a5\nConnection conn = getConnection(cfg);\n// 2. \u5efa\u7acbstatement\nStatement stmt = conn.createStatement();\n// 3. \u6821\u9a8c\u8868\u662f\u5426\u5b58\u5728\nString tableName = cfg.getTableName();\nString namespace = cfg.getNamespace();\nString sql = \"SELECT * FROM \" + namespace + \".\" + tableName + \" LIMIT 1\";\nResultSet rs = stmt.executeQuery(sql);\nif (!rs.next()) {\nthrow new AddaxException(\"Table \" + tableName + \" does not exist in namespace \" + namespace + \".\");\n}\n// 4. \u6821\u9a8c\u5217\u662f\u5426\u5b58\u5728\nString[] columns = cfg.getColumns();\nfor (String column : columns) {\nsql = \"SELECT \" + column + \" FROM \" + namespace + \".\" + tableName + \" LIMIT 1\";\nrs = stmt.executeQuery(sql);\nif (!rs.next()) {\nthrow new AddaxException(\"Column \" + column + \" does not exist in table \" + tableName + \".\");\n}\n}\n} catch (SQLException e) {\nthrow new AddaxException(e.getMessage());\n}\n}", "CodeBleu_score": 31.132109493737563}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\ttry {\nif (kerberosPrincipal == null || kerberosPrincipal.isEmpty() || kerberosKeytabFilePath == null || kerberosKeytabFilePath.isEmpty()) {\nreturn;\n}\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nLOG.error(\\\"Kerberos login failed\\\", e);\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR, \\\"Kerberos login failed\\\", e);\n}\n}", "CodeBleu_score": 38.4234184322179}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (kerberosPrincipal!= null && kerberosKeytabFilePath!= null) {\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nLOG.error(\\\"Kerberos authentication failed, please check the configuration and cluster status.\\\");\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_AUTHENTICATION_ERROR, \\\"Kerberos authentication failed, please check the configuration and cluster status.\\\", e);\n}\n}\n}", "CodeBleu_score": 42.395673715112345}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos) {\nif (StringUtils.isBlank(kerberosPrincipal) || StringUtils.isBlank(kerberosKeytabFilePath)) {\nthrow new RuntimeException(\\\"Kerberos authentication is enabled but the kerberosPrincipal or kerberosKeytabFilePath is not set.\\\");\n}\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n} catch (IOException e) {\nthrow new RuntimeException(\\\"Kerberos login failed with principal \\\" + kerberosPrincipal + \\\" and keytab file path \\\" + kerberosKeytabFilePath, e);\n}\n}\n}", "CodeBleu_score": 41.073905179354426}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\nMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n\nwhile (rs.next()) {\nString colName = rs.getString(\"COLUMN_NAME\");\nString colType = rs.getString(\"TYPE_NAME\");\nif (colName == null) {\nthrow new SQLException(\\\"Column name is null\\\");\n}\nif (colType == null) {\nthrow new SQLException(\\\"Column type is null\\\");\n}\ncolTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 27.396709310481903}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\nMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n\nResultSetMetaData metaData = rs.getMetaData();\nint columnCount = metaData.getColumnCount();\nfor (int i = 1; i <= columnCount; i++) {\nString columnName = metaData.getColumnName(i);\nif (columnName == null) {\nthrow new SQLException(String.format(\"Column name at position %d is null\", i));\n}\nString columnType = metaData.getColumnTypeName(i);\nif (columnType == null) {\nthrow new SQLException(String.format(\"Column type at position %d is null\", i));\n}\nThinClientPTable.ThinClientPColumn col = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\ncolTypeMap.put(columnName, col);\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 43.902866647267814}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\nMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n\nwhile (rs.next()) {\nString colName = rs.getString(4);\nString colType = rs.getString(5);\n\nif (colName == null || colType == null) {\nthrow new SQLException(String.format(\\\"Column name or type is null for column %s\\\", colName));\n}\n\ncolTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colType));\n}\n\nreturn colTypeMap;\n}", "CodeBleu_score": 25.58014415232137}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection phoenixConnection = conn.unwrap(PhoenixConnection.class);\n\tHBaseAdmin admin = phoenixConnection.getAdmin();\n\ttry {\n\t\tif (!admin.tableExists(TableName.valueOf(tableName))) {\n\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TABLE_NOT_EXISTS,\n\t\t\t\t\t\"The table \" + tableName + \" does not exist in the target cluster\");\n\t\t}\n\t\tadmin.disableTable(TableName.valueOf(tableName));\n\t\tadmin.truncateTable(TableName.valueOf(tableName), true);\n\t\tLOG.debug(\"The table \" + tableName + \" has been truncated\");\n\t} catch (IOException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_TABLE_ERROR,\n\t\t\t\t\"Unable to truncate the table \" + tableName, e);\n\t} finally {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Unable to close the Admin instance\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.98781962806988}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n\tAdmin admin = phoenixConn.getAdmin();\n\ttry {\n\t\tif (!phoenixConn.getTable(tableName).exists()) {\n\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TABLE_NOT_EXIST,\n\t\t\t\t\t\"The table \" + tableName + \" does not exist.\");\n\t\t}\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName);\n\t\tLOG.debug(\"Table \" + tableName + \" has been truncated.\");\n\t} catch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_TABLE_ERROR,\n\t\t\t\t\"Unable to truncate table \" + tableName, e);\n\t} finally {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Unable to close admin instance.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.51998757144105}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tLOG.debug(\"Start to truncate table {}\", tableName);\n\tPhoenixConnection hconn = conn.unwrap(PhoenixConnection.class);\n\tAdmin admin = hconn.getAdmin();\n\ttry {\n\t\tif (!admin.tableExists(tableName)) {\n\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TABLE_NOT_EXIST,\n\t\t\t\t\t\"Table \" + tableName + \" does not exist\");\n\t\t}\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, true);\n\t\tLOG.debug(\"Table {} has been truncated successfully.\", tableName);\n\t} catch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_TABLE_ERROR,\n\t\t\t\t\"Failed to truncate table \" + tableName, e);\n\t} finally {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (SQLException e) {\n\t\t\tLOG.error(\"Failed to close the Admin instance.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 48.21009343360786}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\nif (null == specifiedFileType || StringUtils.isBlank(specifiedFileType)) {\n// \u5982\u679c\u7528\u6237\u6ca1\u6709\u6307\u5b9a\u6587\u4ef6\u7c7b\u578b\uff0c\u5219\u5c06\u8be5\u6587\u4ef6\u6dfb\u52a0\u5230sourceHDFSAllFilesList\u4e2d\nsourceHDFSAllFilesList.add(filePath);\n} else {\n// \u5982\u679c\u7528\u6237\u6307\u5b9a\u4e86\u6587\u4ef6\u7c7b\u578b\uff0c\u5219\u68c0\u67e5\u8be5\u6587\u4ef6\u662f\u5426\u4e3a\u6307\u5b9a\u7c7b\u578b\nString fileExtension = FilenameUtils.getExtension(filePath);\nif (Objects.equals(specifiedFileType, fileExtension)) {\n// \u5982\u679c\u8be5\u6587\u4ef6\u7c7b\u578b\u4e0e\u7528\u6237\u6307\u5b9a\u7684\u7c7b\u578b\u5339\u914d\uff0c\u5219\u5c06\u8be5\u6587\u4ef6\u6dfb\u52a0\u5230sourceHDFSAllFilesList\u4e2d\nsourceHDFSAllFilesList.add(filePath);\n} else {\n// \u5982\u679c\u8be5\u6587\u4ef6\u7c7b\u578b\u4e0e\u7528\u6237\u6307\u5b9a\u7684\u7c7b\u578b\u4e0d\u5339\u914d\uff0c\u5219\u629b\u51fa\u5f02\u5e38\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.UNSUPPORTED_FILE_TYPE,\nString.format(\\\"The file type of file [%s] does not match the specified file type [%s].\\\", filePath, specifiedFileType));\n}\n}\n}", "CodeBleu_score": 34.147327929248654}, {"code": "private void addSourceFileByType(String filePath){\n\tString fileType = getFileType(filePath);\nif (Objects.equals(fileType, this.specifiedFileType)) {\nLOG.info(\\\"The file [{}] matches the specified file type [{}], adding it to the source files list.\\\", filePath, this.specifiedFileType);\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nString message = String.format(\\\"The file [{}] does not match the specified file type [{}], ignoring it.\\\", filePath, this.specifiedFileType);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_ERROR, message);\n}\n}", "CodeBleu_score": 48.39221354874527}, {"code": "private void addSourceFileByType(String filePath){\n\tif (specifiedFileType == null) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nif (filePath.endsWith(specifiedFileType)) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nString message = String.format(\n\"The file [%s] is not a %s file. The file type is not supported.\",\nfilePath,\nspecifiedFileType\n);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.UNSUPPORTED_FILE_TYPE, message);\n}\n}\n}", "CodeBleu_score": 34.00814237406317}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\n//        String sequenceFilePath = sourceSequenceFilePath.replace(HdfsConstant.HDFS_DEFAULT_KEY, HdfsConstant.HDFS_LOCAL_KEY);\n        String sequenceFilePath = sourceSequenceFilePath;\n        LOG.info(\"sequenceFilePath:{}\", sequenceFilePath);\n        SequenceFile.Reader reader = null;\n        try {\n            FileSystem fs = FileSystem.get(hadoopConf);\n            Path path = new Path(sequenceFilePath);\n            reader = new SequenceFile.Reader(fs, path, hadoopConf);\n            LOG.info(\"Start reading sequence file: {}\", sequenceFilePath);\n            long startTime = System.currentTimeMillis();\n            long totalCount = 0;\n            while (true) {\n                Text key = new Text();\n                Writable value = new Writable();\n                // Read the next key-value pair from the sequence file\n                boolean hasNext = reader.next(key, value);\n                if (!hasNext) {\n                    break;\n                }\n                totalCount++;\n                // If the value is blank, skip it\n                if (value.toString().trim().length() == 0) {\n                    continue;\n                }\n                // Read the value and transport it to the RecordSender\n                String record = StorageReaderUtil.read(value);\n                // Send the record to the RecordSender\n                recordSender.sendRecord(record);\n            }\n            long endTime = System.currentTimeMillis();\n            long costTime = endTime - startTime;\n            LOG.info(\"Finish reading sequence file: {}, total count: {}, cost time: {} ms\", sequenceFilePath, totalCount, costTime);\n        }\n        catch (Exception e) {\n            String message = String.format(\"IO exception occurred while reading the sequence file [%s].\", sequenceFilePath);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCE_FILE_ERROR, message, e);\n        }\n        finally {\n            if (reader!= null) {\n                try {\n                    reader.close();\n                }\n                catch (IOException e) {\n                    LOG.error(\"IO exception occurred while closing the sequence file reader.\", e);\n                }\n            }\n        }\n    }", "CodeBleu_score": 47.93480865103553}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\n//        // \u8bfb\u53d6sequence\u6587\u4ef6\uff0c\u5e76\u5c06\u5176\u4e2d\u7684\u6570\u636e\u53d1\u9001\u5230RecordSender\u4e2d\n//        InputStream inputStream = null;\n//        SequenceFile.Reader reader = null;\n//        try {\n//            inputStream = getInputStream(sourceSequenceFilePath);\n//            reader = new SequenceFile.Reader(hadoopConf, SequenceFile.Reader.file(new Path(sourceSequenceFilePath)),\n//                    inputStream);\n//\n//            LOG.info(\\\"Start reading sequence file [{}].\\\", sourceSequenceFilePath);\n//\n//            // \u8bfb\u53d6sequence\u6587\u4ef6\u4e2d\u7684\u6bcf\u4e00\u4e2akey-value\u5bf9\n//            while (reader.next(null, null)) {\n//                Object key = reader.getKey();\n//                Object value = reader.getValue();\n//\n//                // \u8df3\u8fc7\u7a7a\u503c\n//                if (value == null) {\n//                    continue;\n//                }\n//\n//                // \u5c06\u8bfb\u53d6\u7684value\u8f6c\u6362\u4e3aRecord\uff0c\u5e76\u5c06\u5176\u53d1\u9001\u5230RecordSender\u4e2d\n//                Record record = StorageReaderUtil.convertValueToRecord(value, readerSliceConfig);\n//                recordSender.sendToWriter(record);\n//            }\n//        } catch (IOException e) {\n//            String message = String.format(\\\"IO exception occurred while reading the sequence file [{}].\\\", sourceSequenceFilePath);\n//            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message, e);\n//        } finally {\n//            try {\n//                if (reader!= null) {\n//                    reader.close();\n//                }\n//                if (inputStream!= null) {\n//                    inputStream.close();\n//                }\n//            } catch (IOException e) {\n//                LOG.error(\\\"IO exception occurred while closing the sequence file [{}].\\\", sourceSequenceFilePath);\n//            }\n//        }\n//    }", "CodeBleu_score": 4.1920025933337515}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tboolean isFileTypeSupported = false;\n\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), hadoopConf);\n\t\tswitch (specifiedFileType) {\n\t\tcase \"ORC\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tcase \"RC\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tcase \"SEQUENCE\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tcase \"PARQUET\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tcase \"CSV\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tcase \"TEXT\":\n\t\t\tisFileTypeSupported = fs.isFile(new Path(filepath)) && fs.getFileStatus(new Path(filepath)).getLen() > 0;\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tisFileTypeSupported = false;\n\t\t\tbreak;\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, \"IO exception occurred when reading file\");\n\t}\n\treturn isFileTypeSupported;\n}", "CodeBleu_score": 28.622004008486208}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(filepath), hadoopConf);\n\t\tPath path = new Path(filepath);\n\t\tif (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n\t\t\treturn OrcFile.fileIsORC(fs.open(path));\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n\t\t\treturn RCFile.fileIsRCFile(fs.open(path));\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"SEQUENCE\")) {\n\t\t\treturn SequenceFile.isSequenceFile(fs.open(path));\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"PARQUET\")) {\n\t\t\treturn ParquetFileReader.hasValidParquetFooter(HadoopInputFile.fromPath(path, hadoopConf));\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n\t\t\treturn CSVReader.hasCSVHeader(fs.open(path));\n\t\t}\n\t\telse if (specifiedFileType.equalsIgnoreCase(\"TEXT\")) {\n\t\t\treturn TextInputFormat.hasTextInputFormat(path, hadoopConf);\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tLOG.error(String.format(\"Error occurred when checking the file type of [%s].\", filepath), e);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, String.format(\"Error occurred when checking the file type of [%s].\", filepath));\n\t}\n}", "CodeBleu_score": 37.3320836293728}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), hadoopConf);\n\t\tif (fs.getFileStatus(new Path(filepath)).isDir()) {\n\t\t\tLOG.error(\"The specified file [{}] is a directory.\", filepath);\n\t\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_IS_DIRECTORY, \"The specified file is a directory.\");\n\t\t}\n\t\telse {\n\t\t\tswitch (specifiedFileType.toUpperCase()) {\n\t\t\t\tcase \"ORC\":\n\t\t\t\t\treturn checkOrcFileType(fs, filepath);\n\t\t\t\tcase \"RC\":\n\t\t\t\t\treturn checkRCFileType(fs, filepath);\n\t\t\t\tcase \"SEQUENCE\":\n\t\t\t\t\treturn checkSequenceFileType(fs, filepath);\n\t\t\t\tcase \"PARQUET\":\n\t\t\t\t\treturn checkParquetFileType(fs, filepath);\n\t\t\t\tcase \"CSV\":\n\t\t\t\t\treturn checkCSVFileType(fs, filepath);\n\t\t\t\tcase \"TEXT\":\n\t\t\t\t\treturn checkTextFileType(fs, filepath);\n\t\t\t\tdefault:\n\t\t\t\t\tLOG.error(\"The specified file type [{}] is not supported.\", specifiedFileType);\n\t\t\t\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.NOT_SUPPORT_FILE_TYPE, \"The specified file type is not supported.\");\n\t\t\t}\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tLOG.error(\"IO exception occurred when checking the file type.\", e);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.CHECK_FILE_TYPE_ERROR, \"IO exception occurred when checking the file type.\");\n\t}\n}", "CodeBleu_score": 33.06850084761902}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 59.73991959163707}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 54.20142439495024}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection!= null) {\ntry {\nhConnection.close();\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 59.79543341317518}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.44920902312519}, {"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.5086576093769}, {"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null!= admin) {\nadmin.close();\n}\n} catch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 79.5086576093769}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\nbyte[] rowKey = cell.getRow();\nbyte[] family = CellUtil.cloneFamily(cell);\nbyte[] qualifier = CellUtil.cloneQualifier(cell);\nbyte[] value = cell.getValue();\n\nString rowKeyString = Bytes.toString(rowKey);\nString familyString = Bytes.toString(family);\nString qualifierString = Bytes.toString(qualifier);\nString valueString = Bytes.toString(value);\n\nrecord.set(HBaseConstant.ROW_KEY, new LongColumn(rowKeyString, rowKeyString));\nrecord.set(HBaseConstant.FAMILY, new LongColumn(familyString, familyString));\nrecord.set(HBaseConstant.QUALIFIER, new LongColumn(qualifierString, qualifierString));\nrecord.set(HBaseConstant.VALUE, new LongColumn(valueString, valueString));\nrecord.set(HBaseConstant.TIMESTAMP, new LongColumn(String.valueOf(cell.getTimestamp()), String.valueOf(cell.getTimestamp())));\n}", "CodeBleu_score": 27.43471885540634}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t//        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n        String family = Bytes.toString(CellUtil.cloneFamily(cell));\n        String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n        long timestamp = cell.getTimestamp();\n        byte[] value = CellUtil.cloneValue(cell);\n//        String value = Bytes.toString(value);\n        String valueStr = new String(value, StandardCharsets.UTF_8);\n        String[] valueArr = valueStr.split(HBaseConstant.HBASE_VALUE_SPLIT);\n        if (valueArr.length > 1) {\n            value = Bytes.toBytes(valueArr[0]);\n        }\n        String columnName = Hbase20xHelper.getColumnName(family, qualifier);\n        String version = Hbase20xHelper.getVersion(timestamp);\n        if (record.getColumn(columnName) == null) {\n            record.addColumn(columnName, version, value);\n        } else {\n            record.addColumn(columnName, version, value, record.getColumn(columnName));\n        }\n    }", "CodeBleu_score": 41.373529680408794}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t//        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n//        Long timestamp = cell.getTimestamp();\n//        String family = Bytes.toString(CellUtil.cloneFamily(cell));\n//        String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n//        String value = Bytes.toString(CellUtil.cloneValue(cell));\n//        record.set(HBaseConstant.ROW_KEY, new LongColumn(rowKey));\n//        record.set(HBaseConstant.TIMESTAMP, new LongColumn(timestamp));\n//        record.set(HBaseConstant.FAMILY, new LongColumn(family));\n//        record.set(HBaseConstant.QUALIFIER, new LongColumn(qualifier));\n//        record.set(HBaseConstant.VALUE, new LongColumn(value));\n    }", "CodeBleu_score": 2.1029777907619387}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString startRowKey = configuration.getString(HBaseKey.START_ROW_KEY);\nif (StringUtils.isBlank(startRowKey)) {\nreturn new byte[0];\n}\nif (HBaseKey.BINARY_ROW_KEY.equals(configuration.getString(HBaseKey.ROW_KEY_TYPE))) {\nreturn Bytes.toBytes(startRowKey);\n}\nreturn startRowKey.getBytes(Charset.forName(\"UTF-8\"));\n}", "CodeBleu_score": 42.81492913968491}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString userStartRowkey = configuration.getString(HBaseKey.STARTROWKEY);\nif (StringUtils.isBlank(userStartRowkey)) {\nreturn new byte[0];\n}\nboolean isBinary = configuration.getBoolean(HBaseKey.STARTROWKEY_BINARY, false);\nif (isBinary) {\nreturn Bytes.toBytes(userStartRowkey);\n}\nelse {\nreturn Bytes.toBytes(userStartRowkey, Charset.forName(\"UTF-8\"));\n}\n}", "CodeBleu_score": 53.05239148746064}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY);\nif (StringUtils.isBlank(userStartRowkey)) {\nreturn new byte[0];\n}\nif (HBaseUtils.isBinary(userStartRowkey)) {\nreturn Bytes.toBytes(userStartRowkey);\n}\nreturn Bytes.toBytes(userStartRowkey, Charset.forName(\"UTF-8\"));\n}", "CodeBleu_score": 41.20030734342497}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn HConstants.EMPTY_BYTE_ARRAY;\n\t} else {\n\t\tboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\n\t\treturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 73.02391194494}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn HConstants.EMPTY_BYTE_ARRAY;\n\t} else {\n\t\tboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\n\t\treturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 73.02391194494}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn HConstants.EMPTY_BYTE_ARRAY;\n\t} else {\n\t\tboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\n\t\treturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 73.02391194494}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tkey = UUID.fromString(record.key());\nheaders = new DefaultTbQueueMsgHeaders(record.headers());\ndata = record.value();\n}", "CodeBleu_score": 30.922362812806668}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tkey = UUID.fromString(record.key());\nheaders = new DefaultTbQueueMsgHeaders(record.headers());\ndata = record.value();\n}", "CodeBleu_score": 30.922362812806668}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 42.571804455549525}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\tString producerClientId = serviceInfoProvider.getServiceId() + \"-transport-notifications-msg-producer\";\nString topic = transportNotificationSettings.getTopic();\nTbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate = new TbKafkaProducerTemplate<>(\nkafkaSettings,\nproducerClientId,\ntopic,\nTbProtoQueueMsg.class);\nproducerTemplate.setAdmin(coreAdmin);\nreturn producerTemplate;\n}", "CodeBleu_score": 40.23334878368073}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\treturn createTransportMsgProducer(transportNotificationSettings.getTopic(), TbProtoQueueMsg::new);\n}", "CodeBleu_score": 11.375134040832613}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\nfinal String producerId = serviceInfoProvider.getServiceId() + \"-transport-notifications-msg-producer\";\n\nfinal TbQueueProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate =\nnew TbKafkaProducerTemplate<>(\nkafkaSettings,\nproducerId,\ntransportNotificationSettings.getTopicName(),\nTbProtoQueueMsg.class);\n\nproducerTemplate.setAdmin(notificationAdmin);\n\nreturn producerTemplate;\n}", "CodeBleu_score": 39.46406760176989}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t//        TbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\n//        consumerBuilder.settings(kafkaSettings);\n//        consumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\n//        consumerBuilder.clientId(\"tb-core-consumer-\" + serviceInfoProvider.getServiceId() + \"-\" + consumerCount.incrementAndGet());\n//        consumerBuilder.groupId(topicService.buildTopicName(\"tb-core-node\"));\n//        consumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\n//        consumerBuilder.admin(coreAdmin);\n//        consumerBuilder.statsService(consumerStatsService);\n//        return consumerBuilder.build();\n//    }", "CodeBleu_score": 3.1900019824609216}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t", "CodeBleu_score": 3.1900019824609216}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t", "CodeBleu_score": 3.1900019824609216}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"No topics provided for consumer group \\\" + groupId + \\\". Unsubscribing consumer from all topics.\\\");\nconsumer.unsubscribe();\nreturn;\n}\n\nList<String> topics = new ArrayList<>(topicNames);\nfor (String topic : topics) {\nif (!admin.topicExists(topic)) {\ntry {\nadmin.createTopic(topic);\n} catch (IOException e) {\nlog.error(\\\"Failed to create topic \\\" + topic, e);\n}\n}\n}\n\nconsumer.subscribe(topics);\n}", "CodeBleu_score": 17.514628735650355}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"No topics provided, consumer unsubscribed from all topics\\\");\nconsumer.unsubscribe();\n} else {\nlog.info(\\\"Subscribing to topics: {}\\\", topicNames);\ntry {\nadmin.ensureTopics(topicNames);\nconsumer.subscribe(topicNames);\n} catch (IOException e) {\nlog.error(\\\"Failed to subscribe to topics: {}\\\", topicNames, e);\n}\n}\n}", "CodeBleu_score": 48.95655803558046}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t (topicNames.isEmpty()) {\nlog.info(\\\"Consumer {} is unsubscribed from all topics\\\", consumer.clientId());\nconsumer.unsubscribe();\n} else {\nlog.info(\\\"Consumer {} is subscribed to topics: {}\\\", consumer.clientId(), topicNames);\nconsumer.subscribe(topicNames);\n}\n}", "CodeBleu_score": 51.49446827554639}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nif (statsService!= null) {\nstatsService.updatePollStats(groupId, topic, records.count(), stopWatch.getTotalTimeMillis());\n}\nlog.debug(\\\"Poll {} records from topic {} in {} ms\\\", records.count(), topic, stopWatch.getTotalTimeMillis());\nif (records.count() == 0) {\nreturn Collections.emptyList();\n}\nList<ConsumerRecord<String, byte[]>> list = new ArrayList<>();\nrecords.forEach(list::add);\nreturn list;\n}", "CodeBleu_score": 57.332821453055594}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nlog.debug(\\\"poll [{}], duration [{}], records [{}]\\\", topic, durationInMillis, records.count());\nif (records.count() == 0) {\nreturn Collections.emptyList();\n}\nList<ConsumerRecord<String, byte[]>> result = new ArrayList<>();\nrecords.forEach(result::add);\nreturn result;\n}", "CodeBleu_score": 54.50025124620408}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\topWatch stopWatch = new StopWatch();\nstopWatch.start();\n\nConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n\nstopWatch.stop();\nlog.info(\\\"{}: poll time: {}\\\", topic, stopWatch.getTotalTimeMillis());\n\nif (records.count() > 0) {\nList<ConsumerRecord<String, byte[]>> list = new ArrayList<>(records.count());\nlist.addAll(records);\nreturn list;\n} else {\nreturn Collections.emptyList();\n}\n}", "CodeBleu_score": 54.34923125776593}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError!= null) {\n\nctx.getLogger().error(\\\"Failed to initialize Kafka producer\\\", initError);\n\nctx.notifyError(initError);\n\nreturn;\n\n}\n\nString topic = null;\n\nString key = null;\n\ntry {\n\ntopic = getTopic(msg);\n\nkey = getKey(msg);\n\n} catch (Exception e) {\n\nctx.getLogger().error(\\\"Failed to get topic and key from message\\\", e);\n\nctx.notifyError(e);\n\nreturn;\n\n}\n\nif (topic == null) {\n\nctx.getLogger().warn(\\\"Topic is not specified, message will be dropped\\\");\n\nreturn;\n\n}\n\nif (key == null) {\n\nctx.getLogger().warn(\\\"Key is not specified, message will be dropped\\\");\n\nreturn;\n\n}\n\nif (topic.isEmpty()) {\n\nctx.getLogger().warn(\\\"Topic is empty, message will be dropped\\\");\n\nreturn;\n\n}\n\nif (key.isEmpty()) {\n\nctx.getLogger().warn(\\\"Key is empty, message will be dropped\\\");\n\nreturn;\n\n}\n\ntry {\n\npublish(topic, key, msg);\n\n} catch (Exception e) {\n\nctx.getLogger().error(\\\"Failed to publish message to Kafka\\\", e);\n\nctx.notifyError(e);\n\nreturn;\n\n}\n\n}", "CodeBleu_score": 34.95454369243613}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError!= null) {\n\nctx.getTbLogger().error(\\\"Failed to initialize the Kafka producer: \\\" + initError.getMessage());\n\nctx.notifyError(initError);\n\nreturn;\n\n}\n\n\nString topic = config.getTopic();\nString key = config.getKey();\nif (topic == null || topic.isEmpty()) {\n\nctx.getTbLogger().error(\\\"Topic is not configured for the Kafka producer node\\\");\n\nctx.notifyError(new TbNodeException(\\\"Topic is not configured for the Kafka producer node\\\"));\n\nreturn;\n\n}\n\n\nif (key == null || key.isEmpty()) {\n\nctx.getTbLogger().error(\\\"Key is not configured for the Kafka producer node\\\");\n\nctx.notifyError(new TbNodeException(\\\"Key is not configured for the Kafka producer node\\\"));\n\nreturn;\n\n}\n\n\ntry {\n\nproducer.send(new ProducerRecord<>(topic, key, msg.getPayload().toString()), (recordMetadata, e) -> {\n\nif (e!= null) {\n\nctx.getTbLogger().error(\\\"Failed to publish the message to Kafka: \\\" + e.getMessage());\n\nctx.notifyError(e);\n\n}\n\n});\n\n} catch (Exception e) {\n\nctx.getTbLogger().error(\\\"Failed to publish the message to Kafka: \\\" + e.getMessage());\n\nctx.notifyError(e);\n\n}\n\n}", "CodeBleu_score": 20.652305417341164}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\tif (initError!= null) {\n\nctx.getLogger().error(\\\"Initialization failed: \\\" + initError.getMessage());\n\nctx.notifyError(initError);\n\nreturn;\n\n}\n\nString topic = config.getTopic();\nString key = config.getKey();\n\nif (topic == null || key == null) {\n\nctx.getLogger().error(\\\"Topic and key patterns are not specified in the configuration\\\");\n\nctx.notifyError(new TbNodeException(\\\"Topic and key patterns are not specified in the configuration\\\"));\n\nreturn;\n\n}\n\nString message = msg.getMsg();\nif (message == null) {\n\nctx.getLogger().error(\\\"Message is null\\\");\n\nctx.notifyError(new TbNodeException(\\\"Message is null\\\"));\n\nreturn;\n\n}\n\ntry {\n\nproducer.send(new ProducerRecord<>(topic, key, message));\n\n} catch (Exception e) {\n\nctx.getLogger().error(\\\"Failed to publish message to Kafka: \\\" + e.getMessage());\n\nctx.notifyError(e);\n\nreturn;\n\n}\n\nif (addMetadataKeyValuesAsKafkaHeaders) {\n\nMap<String, String> metadata = msg.getMetadata();\n\nif (metadata!= null &&!metadata.isEmpty()) {\n\ntry {\n\nmetadata.forEach((k, v) -> {\n\nproducer.send(new ProducerRecord<>(topic, key, message, toBytes(k, toBytesCharset), toBytes(v, toBytesCharset)));\n\n});\n\n} catch (Exception e) {\n\nctx.getLogger().error(\\\"Failed to publish metadata as Kafka headers: \\\" + e.getMessage());\n\nctx.notifyError(e);\n\nreturn;\n\n}\n\n}\n\n}\n\n}", "CodeBleu_score": 19.420633842764428}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\ttry {\nif (addMetadataKeyValuesAsKafkaHeaders) {\nMap<String, String> headers = new HashMap<>();\nheaders.put(TbKafkaNode.TOPIC, topic);\nheaders.put(TbKafkaNode.PARTITION, String.valueOf(msg.getPartition()));\nheaders.put(TbKafkaNode.OFFSET, String.valueOf(msg.getOffset()));\nif (msg.getError()!= null) {\nheaders.put(TbKafkaNode.ERROR, msg.getError().getMessage());\n}\nctx.getExternalCallExecutor().executeAsync(() -> {\ntry {\nproducer.send(new ProducerRecord<>(topic, key, msg.getData().toString(toBytesCharset)),\n(metadata, exception) -> {\nif (exception!= null) {\nlog.debug(\\\"[TB-KAFKA-NODE-{}-{}] Failed to send message to Kafka topic: \\\" + exception.getMessage(), ctx.getSelfId().getId(), ctx.getServiceId(), exception);\n}\n});\n} catch (Exception e) {\nlog.debug(\\\"[TB-KAFKA-NODE-{}-{}] Failed to send message to Kafka topic: \\\" + e.getMessage(), ctx.getSelfId().getId(), ctx.getServiceId(), e);\n}\n});\n} else {\nctx.getExternalCallExecutor().executeAsync(() -> {\ntry {\nproducer.send(new ProducerRecord<>(topic, key, msg.getData().toString(toBytesCharset)),\n(metadata, exception) -> {\nif (exception!= null) {\nlog.debug(\\\"[TB-KAFKA-NODE-{}-{}] Failed to send message to Kafka topic: \\\" + exception.getMessage(), ctx.getSelfId().getId(), ctx.getServiceId(), exception);\n}\n});\n} catch (Exception e) {\nlog.debug(\\\"[TB-KAFKA-NODE-{}-{}] Failed to send message to Kafka topic: \\\" + e.getMessage(), ctx.getSelfId().getId(), ctx.getServiceId(), e);\n}\n});\n}\n} catch (Exception e) {\nlog.debug(\\\"[TB-KAFKA-NODE-{}-{}] Failed to send message to Kafka topic: \\\" + e.getMessage(), ctx.getSelfId().getId(), ctx.getServiceId(), e);\n}\n}", "CodeBleu_score": 32.1521364297799}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\ttry {\nif (addMetadataKeyValuesAsKafkaHeaders) {\nList<Header> headers = new ArrayList<>();\nfor (Map.Entry<String, String> entry : msg.getMetadata().entrySet()) {\nheaders.add(new RecordHeader(entry.getKey().getBytes(toBytesCharset), entry.getValue().getBytes(toBytesCharset)));\n}\nproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n@Override\npublic void onCompletion(RecordMetadata metadata, Exception exception) {\nif (exception!= null) {\nctx.getExternalCallExecutor().executeAsync(() -> {\nctx.tellFailure(msg, exception);\nreturn null;\n});\n} else {\nctx.tellSuccess(msg);\n}\n}\n});\n} else {\nproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback() {\n@Override\npublic void onCompletion(RecordMetadata metadata, Exception exception) {\nif (exception!= null) {\nctx.getExternalCallExecutor().executeAsync(() -> {\nctx.tellFailure(msg, exception);\nreturn null;\n});\n} else {\nctx.tellSuccess(msg);\n}\n}\n});\n}\n} catch (Exception e) {\nctx.getExternalCallExecutor().executeAsync(() -> {\nctx.tellFailure(msg, e);\nreturn null;\n});\n}\n}", "CodeBleu_score": 35.65362269332906}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\ttry {\nif (addMetadataKeyValuesAsKafkaHeaders) {\nMap<String, String> headers = new HashMap<>();\nif (msg.getMetadata()!= null) {\nfor (Map.Entry<String, String> entry : msg.getMetadata().entrySet()) {\nheaders.put(entry.getKey(), entry.getValue());\n}\n}\nif (key!= null) {\nheaders.put(TbKafkaNode.KEY, key);\n}\nProducerRecord<String, String> record = new ProducerRecord<>(topic, null, msg.getPayload(), headers);\nproducer.send(record, (recordMetadata, e) -> {\nif (e!= null) {\nctx.logDebug(\\\"Failed to send message to Kafka topic \\\" + topic + \\\": \\\" + e.getMessage());\n}\n});\n} else {\nproducer.send(new ProducerRecord<>(topic, key, msg.getPayload()), (recordMetadata, e) -> {\nif (e!= null) {\nctx.logDebug(\\\"Failed to send message to Kafka topic \\\" + topic + \\\": \\\" + e.getMessage());\n}\n});\n}\n} catch (Exception e) {\nctx.logDebug(\\\"Failed to send message to Kafka topic \\\" + topic + \\\": \\\" + e.getMessage());\n}\n}", "CodeBleu_score": 34.0945802179233}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"[{}] Failed to close Kafka producer\\\", ctx.getSelfId(), e);\n}\n}\n}", "CodeBleu_score": 52.14696654649019}, {"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer: \\\" + e.getMessage());\n}\n}\n}", "CodeBleu_score": 42.10384435538822}, {"code": "public void destroy(){\n\tif (producer!= null) {\ntry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer: \\\" + e.getMessage());\n}\n}\n}", "CodeBleu_score": 42.10384435538822}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\nTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\nrequestBuilder.settings(kafkaSettings);\nrequestBuilder.clientId(\"monolith-rule-engine-\" + serviceInfoProvider.getServiceId());\nrequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getRuleEngineTopic()));\nrequestBuilder.admin(ruleEngineAdmin);\nreturn requestBuilder.build();\n}", "CodeBleu_score": 92.68810475286874}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tlog.info(\\\"Starting consumer group statistics logging\\\");\n\nDuration timeout = Duration.ofMillis(kafkaSettings.getTimeout());\n\nstatsPrintScheduler.scheduleAtFixedRate(() -> {\ntry {\nif (monitoredGroups.isEmpty()) {\nreturn;\n}\n\nMap<String, Long> consumerOffsets = consumer.endOffsets(monitoredGroups);\nMap<String, Long> consumerGroupOffsets = consumer.position(monitoredGroups);\n\nfor (Map.Entry<String, Long> entry : consumerOffsets.entrySet()) {\nString groupId = entry.getKey();\nString topic = groupId.substring(groupId.lastIndexOf(\\\"-\\\") + 1);\n\n\nif (consumerOffsets.get(groupId) == consumerGroupOffsets.get(groupId)) {\ncontinue;\n}\n\nlog.warn(\\\"Consumer group {} is lagging on topic {} with offsets: consumer: {}, group: {}\\\", groupId, topic, consumerOffsets.get(groupId), consumerGroupOffsets.get(groupId));\n}\n} catch (Exception e) {\nlog.warn(\\\"Error occurred during consumer group statistics logging\\\", e);\n}\n}, timeout.toMillis(), statsConfig.getInterval(), TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 28.72309026218673}, {"code": "private void startLogScheduling(){\n\tstatsPrintScheduler.scheduleAtFixedRate(() -> {\nif (statsConfig.getTimeout() == null) {\nreturn;\n}\ntry {\nList<String> monitoredGroupsList = new ArrayList<>(monitoredGroups);\nfor (String groupId : monitoredGroupsList) {\nMap<TopicPartition, Long> offsets = consumer.endOffsets(consumer.assignment());\nfor (Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\nTopicPartition tp = entry.getKey();\nLong endOffset = entry.getValue();\nString topic = tp.topic();\nint partition = tp.partition();\nLong offset = consumer.position(tp);\nif (offset == null) {\noffset = 0L;\n}\nif (offset < endOffset) {\nlog.warn(\\\"[{}] Consumer group [{}] is lagging on partition [{}:{}] by [{}].\\\", groupId, topic, partition, offset - endOffset);\n}\n}\n}\n} catch (Exception e) {\nlog.warn(\\\"[{}] Exception occurred while logging consumer group statistics: {}\\\", groupId, e.getMessage(), e);\n}\n}, statsConfig.getTimeout().getSeconds(), statsConfig.getTimeout().getSeconds(), TimeUnit.SECONDS);\n}", "CodeBleu_score": 28.98954556148342}, {"code": "private void startLogScheduling(){\n\tthis.statsPrintScheduler.scheduleAtFixedRate(this::printStats, statsConfig.getStatsPrintingInterval(), statsConfig.getStatsPrintingInterval(), TimeUnit.SECONDS);\n}", "CodeBleu_score": 7.021765917592303}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeoutMs);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, 1000);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 79.9811130701978}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeoutMs);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, 1000);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MAX_MS_CONFIG, 1000);\nprops.put(AdminClientConfig.RETRY_BACKOFF_EXPONENTIAL_BASE_MS_CONFIG, 1000);\nreturn props;\n}", "CodeBleu_score": 71.69477620594697}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeoutMs);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retries * 1000);\nreturn props;\n}", "CodeBleu_score": 77.12895908828933}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t (metric instanceof Gauge) {\n\t\tgauges.put((Gauge<?>) metric, new MetricEvent(metricName, group.getName()));\n\t} else if (metric instanceof Counter) {\n\t\tcounters.put((Counter) metric, new MetricEvent(metricName, group.getName()));\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put((Histogram) metric, new MetricEvent(metricName, group.getName()));\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put((Meter) metric, new MetricEvent(metricName, group.getName()));\n\t} else {\n\t\tLOG.warn(\\\"Metric {} is not supported by the Kafka reporter\\\", metric.getClass().getSimpleName());\n\t}\n}", "CodeBleu_score": 55.675079082145395}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t (metric instanceof Gauge) {\n\t\tGauge<?> gauge = (Gauge<?>) metric;\n\t\tMetricEvent event = new MetricEvent(metricName, group.getName(), gauge.getTags());\n\t\tgauges.put(gauge, event);\n\t} else if (metric instanceof Counter) {\n\t\tCounter counter = (Counter) metric;\n\t\tMetricEvent event = new MetricEvent(metricName, group.getName(), counter.getTags());\n\t\tcounters.put(counter, event);\n\t} else if (metric instanceof Histogram) {\n\t\tHistogram histogram = (Histogram) metric;\n\t\tMetricEvent event = new MetricEvent(metricName, group.getName(), histogram.getTags());\n\t\thistograms.put(histogram, event);\n\t} else if (metric instanceof Meter) {\n\t\tMeter meter = (Meter) metric;\n\t\tMetricEvent event = new MetricEvent(metricName, group.getName(), meter.getTags());\n\t\tmeters.put(meter, event);\n\t} else {\n\t\tLOG.warn(\\\"Metric type {} is not supported\\\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 47.9082266654195}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\tring metricNameWithScope = metricName;\n\tString metricNameWithoutScope = metricName;\n\tString scope = group.getScope();\n\tif (scope!= null) {\n\t\tmetricNameWithScope = scope + SCOPE_SEPARATOR + metricName;\n\t\tmetricNameWithoutScope = metricNameWithScope.replaceAll(\\\"_\\\", \\\"\\\");\n\t}\n\tString tags = group.getTags();\n\tif (tags!= null) {\n\t\tmetricNameWithScope = metricNameWithScope + SCOPE_SEPARATOR + tags;\n\t\tmetricNameWithoutScope = metricNameWithoutScope + SCOPE_SEPARATOR + tags;\n\t}\n\tif (metric instanceof Counter) {\n\t\tCounter counter = (Counter) metric;\n\t\tcounters.put(counter, new MetricEvent(metricNameWithScope, metricNameWithoutScope, tags));\n\t} else if (metric instanceof Gauge) {\n\t\tGauge gauge = (Gauge) metric;\n\t\tgauges.put(gauge, new MetricEvent(metricNameWithScope, metricNameWithoutScope, tags));\n\t} else if (metric instanceof Histogram) {\n\t\tHistogram histogram = (Histogram) metric;\n\t\thistograms.put(histogram, new MetricEvent(metricNameWithScope, metricNameWithoutScope, tags));\n\t} else if (metric instanceof Meter) {\n\t\tMeter meter = (Meter) metric;\n\t\tmeters.put(meter, new MetricEvent(metricNameWithScope, metricNameWithoutScope, tags));\n\t} else {\n\t\tLOG.warn(\\\"Metric type \\\" + metric.getClass().getSimpleName() + \\\" is not supported\\\");\n\t}\n}", "CodeBleu_score": 31.93603877798444}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() == null) {\n\t\tmetricEvent.setFields(new HashMap<>());\n\t}\n\tNumber value = (Number) gauge.getValue();\n\tif (value instanceof Integer) {\n\t\tmetricEvent.getFields().put(field, value.intValue());\n\t} else if (value instanceof Long) {\n\t\tmetricEvent.getFields().put(field, value.longValue());\n\t} else if (value instanceof Double) {\n\t\tmetricEvent.getFields().put(field, value.doubleValue());\n\t} else if (value instanceof Float) {\n\t\tmetricEvent.getFields().put(field, value.floatValue());\n\t} else {\n\t\tmetricEvent.getFields().put(field, value.toString());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 39.208882212554364}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() == null) {\n\t\tmetricEvent.setFields(new HashMap<>());\n\t}\n\tif (gauge instanceof Gauge.LongGauge) {\n\t\tmetricEvent.getFields().put(field, String.valueOf(((Gauge.LongGauge) gauge).getValue()));\n\t} else if (gauge instanceof Gauge.DoubleGauge) {\n\t\tmetricEvent.getFields().put(field, String.valueOf(((Gauge.DoubleGauge) gauge).getValue()));\n\t} else if (gauge instanceof Gauge.BooleanGauge) {\n\t\tmetricEvent.getFields().put(field, String.valueOf(((Gauge.BooleanGauge) gauge).getValue()));\n\t} else if (gauge instanceof Gauge.StringGauge) {\n\t\tmetricEvent.getFields().put(field, ((Gauge.StringGauge) gauge).getValue());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 30.268017571391994}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (gauge.getValue() instanceof Number) {\n\t\tmetricEvent.addField(field, ((Number) gauge.getValue()).doubleValue());\n\t} else if (gauge.getValue() instanceof String) {\n\t\tmetricEvent.addField(field, (String) gauge.getValue());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 20.837096862367705}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tmetricEvent.addField(\"currentOffsets\", (Number) value);\n\t} else {\n\t\tmetricEvent.addField(\"currentOffsets\", String.valueOf(value));\n\t}\n\tString[] groups = metricEvent.getName().split(\\\"_\\\");\n\tString topic = groups[groups.length - 2];\n\tString partition = groups[groups.length - 1];\n\tString[] fields = metricEvent.getName().split(\\\"_currentDataTimestampOffsetsAndCommittedOffsets_\\\");\n\tif (fields.length == 2) {\n\t\tmetricEvent.addField(\"dataTimestamp\", fields[1]);\n\t}\n\tString[] offsets = metricEvent.getName().split(\\\"_currentOffsets_\\\");\n\tif (offsets.length == 2) {\n\t\tmetricEvent.addField(\"committedOffsets\", offsets[1]);\n\t}\n\tString[] lagTimes = metricEvent.getName().split(\\\"_lagTime_\\\");\n\tif (lagTimes.length == 2) {\n\t\tmetricEvent.addField(\"lagTime\", lagTimes[1]);\n\t}\n\tif (kafkaLagTimes.containsKey(topic + \\\"_\\\" + partition)) {\n\t\tif (kafkaLagTimes.get(topic + \\\"_\\\" + partition).get(\\\"currentOffsets\\\").equals(metricEvent.getFields().get(\\\"currentOffsets\\\")) && kafkaLagTimes.get(topic + \\\"_\\\" + partition).get(\\\"dataTimestamp\\\").equals(metricEvent.getFields().get(\\\"dataTimestamp\\\")) && kafkaLagTimes.get(topic + \\\"_\\\" + partition).get(\\\"committedOffsets\\\").equals(metricEvent.getFields().get(\\\"committedOffsets\\\"))) {\n\t\t\treturn null;\n\t\t}\n\t}\n\tkafkaLagTimes.put(topic + \\\"_\\\" + partition, metricEvent.getFields());\n\tmetricEvent.setTimestamp(timestamp);\n\treturn metricEvent;\n}", "CodeBleu_score": 30.862401617332623}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\nProperties props = buildKafkaProps(ParameterTool.fromSystemProperties());\n\nFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n\nif (time > 0L) {\nList<PartitionInfo> partitions = consumer.getPartitionInfos();\nMap<TopicPartition, Long> offsets = new HashMap<>();\nfor (PartitionInfo partition : partitions) {\noffsets.put(new TopicPartition(partition.topic(), partition.partition()), time);\n}\nconsumer.assign(offsets);\n}\n\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 55.18087534681377}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\nParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\nProperties kafkaProps = buildKafkaProps(parameter);\n\nKafkaConsumer<String, String> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), kafkaProps);\n\n// If a specific start time is provided, set the consumer to start from the specific offsets\nif (time > 0) {\nList<PartitionInfo> partitions = consumer.partitionsFor(topic);\nMap<TopicPartition, OffsetAndTimestamp> offsets = new HashMap<>();\nfor (PartitionInfo partition : partitions) {\noffsets.put(new TopicPartition(partition.topic(), partition.partition()), new OffsetAndTimestamp(time, 0));\n}\nconsumer.assign(offsets.keySet());\nconsumer.seek(offsets);\n}\n\nreturn env.addSource(consumer);\n}", "CodeBleu_score": 60.30769546722451}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\tProperties props = buildKafkaProps(parameter);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n\tif (time!= 0) {\n\t\tList<PartitionInfo> partitions = consumer.getPartitionsFor(topic);\n\t\tMap<TopicPartition, Long> offsets = new HashMap<>();\n\t\tfor (PartitionInfo partition : partitions) {\n\t\t\toffsets.put(new TopicPartition(partition.topic(), partition.partition()), time);\n\t\t}\n\t\tconsumer.assign(offsets);\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 66.5338432698626}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t", "CodeBleu_score": 5.654569915133498}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t/**\n * @param props\n * @param parameterTool\n * @param time\n * @return\n */\nMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\nKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\nList<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC));\nfor (PartitionInfo partitionInfo : partitionInfos) {\nTopicPartition topicPartition = new TopicPartition(partitionInfo.topic(), partitionInfo.partition());\nOffsetAndTimestamp offsetAndTimestamp = consumer.offsetAndTimestampFor(topicPartition, time);\npartitionOffset.put(new KafkaTopicPartition(partitionInfo.topic(), partitionInfo.partition()), offsetAndTimestamp.offset());\n}\nconsumer.close();\nreturn partitionOffset;\n}", "CodeBleu_score": 54.16217001383752}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t//    String topic = parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC);\n//    Long time = parameterTool.getLong(PropertiesConstants.CONSUMER_FROM_TIME, 0L);\n\n//    Properties props = buildKafkaProps(parameterTool);\n\n//    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n//            topic,\n//            new MetricSchema(),\n//            props);\n\n//    //\u91cd\u7f6eoffset\u5230time\u65f6\u523b\n//    if (time!= 0L) {\n//        Map<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n//        consumer.setStartFromSpecificOffsets(partitionOffset);\n//    }\n\n//    return env.addSource(consumer);\n\n//    }", "CodeBleu_score": 5.654569915133498}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\t// Kafka producer properties\n\tProperties props = new Properties();\n\tprops.put(\\\"bootstrap.servers\\\", broker_list);\n\tprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\tprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\t// Kafka producer\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\t// MetricEvent\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\\\"flink-metric\\\");\n\tevent.setTags(new HashMap<String, String>());\n\tevent.getTags().put(\\\"tag1\\\", \\\"value1\\\");\n\tevent.getTags().put(\\\"tag2\\\", \\\"value2\\\");\n\tevent.setFields(new HashMap<String, String>());\n\tevent.getFields().put(\\\"field1\\\", \\\"value1\\\");\n\tevent.getFields().put(\\\"field2\\\", \\\"value2\\\");\n\t// ProducerRecord\n\tProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, GsonUtil.toJson(event));\n\t// Send to Kafka\n\tproducer.send(record);\n\tSystem.out.println(\\\"Sent: \\\" + record.value());\n\t// Flush producer to ensure all data is sent\n\tproducer.flush();\n}", "CodeBleu_score": 27.406931524164392}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(\\\"bootstrap.servers\\\", broker_list);\nprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\\\"test\\\");\nevent.setTags(new HashMap<String, String>() {{\nput(\\\"tag1\\\", \\\"value1\\\");\nput(\\\"tag2\\\", \\\"value2\\\");\n}});\nevent.setFields(new HashMap<String, String>() {{\nput(\\\"field1\\\", \\\"value1\\\");\nput(\\\"field2\\\", \\\"value2\\\");\n}});\nProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, GsonUtil.toJson(event));\nproducer.send(record);\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 25.84912015711775}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\\\"bootstrap.servers\\\", broker_list);\n\tprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\tprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\tKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\tString name = \\\"flink-metric-event\\\";\n\tMap<String, String> tags = new HashMap<>();\n\ttags.put(\\\"job_id\\\", \\\"123\\\");\n\tMap<String, String> fields = new HashMap<>();\n\tfields.put(\\\"value\\\", \\\"123\\\");\n\tMetricEvent metricEvent = new MetricEvent(System.currentTimeMillis(), name, tags, fields);\n\tProducerRecord<String, String> record = new ProducerRecord<>(topic, GsonUtil.toJson(metricEvent));\n\tproducer.send(record);\n\tSystem.out.println(\\\"Sent: \\\" + GsonUtil.toJson(metricEvent));\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 27.228840528287645}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tis.level!= null &&!event.getLoggerName().contains(this.level)) {\nreturn;\n}\n\ntry {\nString logEvent = JacksonUtil.toJson(new LogEvent(event.getLevel().name(), event.getLoggerName(), event.getMessage().getFormattedMessage(), ExceptionUtil.getExceptionStackTrace(event.getThrown())));\nproducer.send(new ProducerRecord<>(this.topic, this.source, logEvent));\n} catch (Exception e) {\nlog.warn(\\\"Failed to send log event to Kafka topic\\\", e);\n}\n}", "CodeBleu_score": 41.61016575154526}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (event.getLoggerName().contains(\\\"xxx\\\") ||!level.contains(event.getLevel().toString())) {\nreturn;\n}\n\nString message = layout.toByteArray(event);\n\nLogEvent logEvent = new LogEvent();\nlogEvent.setSource(source);\nlogEvent.setTopic(topic);\nlogEvent.setLevel(event.getLevel().toString());\nlogEvent.setMessage(message);\nlogEvent.setAppId(appId);\nlogEvent.setContainerId(containerId);\nlogEvent.setContainerType(containerType);\nlogEvent.setTaskName(taskName);\nlogEvent.setTaskId(taskId);\nlogEvent.setNodeIp(nodeIp);\nlogEvent.setTimestamp(event.getMillis());\n\nString json = JacksonUtil.toJson(logEvent);\n\nProducerRecord<String, String> record = new ProducerRecord<>(topic, UUID.randomUUID().toString(), json);\nproducer.send(record);\n}", "CodeBleu_score": 40.93069215047154}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tis.filter == null || this.filter.isStarted() && this.filter.filter(event)) {\ntry {\nif (event.getLevel().toString().equals(this.level) &&!event.getLoggerName().contains(this.source)) {\nString message = this.layout.toSerializable(event).toString();\nLogEvent logEvent = new LogEvent(message, this.level, this.source, this.topic, this.appId, this.containerId, this.containerType, this.taskName, this.taskId, this.nodeIp);\nString json = JacksonUtil.toJson(logEvent);\nProducerRecord<String, String> record = new ProducerRecord<>(this.topic, json);\nproducer.send(record);\n}\n} catch (Exception e) {\nlog.warn(\\\"Exception occurred while sending log event to Kafka: \\\" + ExceptionUtil.getExceptionMessage(e));\n}\n}\n}", "CodeBleu_score": 44.86252469240711}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method: %s\\\", method)\n}", "CodeBleu_score": 77.73705903631904}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif validMethod == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method %q\\\", method)\n}", "CodeBleu_score": 73.35820545418179}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\\\"unknown topic suffix method: %s\\\", method)\n}", "CodeBleu_score": 77.73705903631904}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tkey, err := uuid.NewRandom()\n\t\tif err!= nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn key.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 75.65273244558499}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewRandom()\n\t\tif err!= nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 75.06070080581617}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\tutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewString(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 56.24173133733843}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\txps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tif k.regexps[i], err = regexp.Compile(topicRegexp); err!= nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic regexp %q: %w\\\", topicRegexp, err)\n\t\t}\n\t}\n\treturn nil\n}", "CodeBleu_score": 44.52656703135786}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\tcLock.Lock()\n\tdefer k.topicLock.Unlock()\n\n\tk.regexps = make([]regexp.Regexp, 0, len(k.TopicRegexps))\n\tfor _, topicRegexp := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"unable to compile topic regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.regexps = append(k.regexps, *r)\n\t}\n\treturn nil\n}", "CodeBleu_score": 72.13597144866743}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\txps = make([]regexp.Regexp, 0, len(k.TopicRegexps))\n\tfor _, topicRegexp := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.regexps = append(k.regexps, *regex)\n\t}\n\treturn nil\n}", "CodeBleu_score": 68.88452751636136}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.log.Debugf(\\\"onDelivery: message %d not found in undelivered map\\\", track.ID)\n\t\treturn\n\t}\n\n\t// Mark message as delivered\n\tmsg.session.MarkMessage(msg.message, \\\"\\\")\n\n\t// Remove message from undelivered map\n\tdelete(h.undelivered, track.ID)\n\n\t// Release semaphore slot\n\th.sem <- empty{}\n}", "CodeBleu_score": 59.33244137821361}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\treturn\n\t}\n\th.log.Debugf(\\\"delivered %s\\\", track.ID)\n\tmsg.session.MarkMessage(msg.message, \\\"\\\")\n\tdelete(h.undelivered, track.ID)\n\th.sem.Release()\n}", "CodeBleu_score": 57.10342749658057}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif!ok {\n\t\th.log.Debugf(\\\"onDelivery: no message found for delivery ID %d\\\", track.ID)\n\t\treturn\n\t}\n\n\t// Mark the message as delivered.\n\tmsg.session.MarkMessage(msg.message, \\\"\\\")\n\n\t// Remove the message from the undelivered map and release a semaphore slot.\n\tdelete(h.undelivered, track.ID)\n\th.sem <- empty{}\n}", "CodeBleu_score": 58.86841334777273}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx, cancel := context.WithCancel(context.Background())\n\th.cancel = cancel\n\n\th.wg.Add(1)\n\tgo func() {\n\t\tdefer h.wg.Done()\n\t\th.run(ctx)\n\t}()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase track := <-h.acc.Delivered():\n\t\t\th.onDelivery(track)\n\t\tcase msg, more := <-claim.Messages():\n\t\t\tif!more {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(session, msg); err!= nil {\n\t\t\t\th.log.Errorf(\\\"Error handling message: %s\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 45.17601203334368}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx, cancel := context.WithCancel(context.Background())\n\th.cancel = cancel\n\th.wg.Add(1)\n\tgo func() {\n\t\tdefer h.wg.Done()\n\t\th.run(ctx)\n\t}()\n\treturn nil\n}", "CodeBleu_score": 27.646566998269982}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx, cancel := context.WithCancel(context.Background())\n\th.cancel = cancel\n\n\th.wg.Add(1)\n\tgo func() {\n\t\tdefer h.wg.Done()\n\t\th.run(ctx)\n\t}()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(session, msg); err!= nil {\n\t\t\t\th.log.Errorf(\\\"Could not handle message: %s\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 47.986425198251936}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(!logkafka_id.equals(\\\".\\\"), LogkafkaIdDot)\ncheckCondition(!logkafka_id.equals(\\\"..\\\"), LogkafkaIdDotDot)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength)\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\n}", "CodeBleu_score": 80.96303667577772}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(logkafka_id!= \\\".\\\", LogkafkaIdDot)\ncheckCondition(logkafka_id!= \\\"..\\\", LogkafkaIdDotDot)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength(logkafka_id))\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\n}", "CodeBleu_score": 78.32199838484401}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(!logkafka_id.equals(\\\".\\\"), LogkafkaIdDot)\ncheckCondition(!logkafka_id.equals(\\\"..\\\"), LogkafkaIdDotDot)\ncheckCondition(logkafka_id.length <= maxNameLength, InvalidLogkafkaIdLength(logkafka_id))\nrgx.findFirstIn(logkafka_id) match {\ncase Some(t) =>\ncheckCondition(t.equals(logkafka_id), IllegalCharacterInLogkafkaId(logkafka_id))\ncase None =>\ncheckCondition(false, IllegalCharacterInLogkafkaId(logkafka_id))\n}\ncheckCondition(logkafka_id.matches(legalChars + \\\"+\\\"), InvalidLogkafkaId(logkafka_id))\n}", "CodeBleu_score": 74.01367141967417}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\nIt takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\nIf the actor responds with an error, it logs the failure and returns an ApiError.\nIf the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\nThe function also includes error handling for any thrown exceptions during the process.\n */\n    val response = kafkaManagerActor! msg\n    val transformedResponse = response.map {\n      case Right(output) =>\n        try {\n          fn(output)\n        } catch {\n          case e: Exception =>\n            error(s\\\"Error while transforming response: $e\\\")\n            ApiError(s\\\"Error while transforming response: $e\\\")\n        }\n      case Left(error) =>\n        error(s\\\"Error while processing request: $error\\\")\n        ApiError(s\\\"Error while processing request: $error\\\")\n    }\n    transformedResponse\n  }", "CodeBleu_score": 24.63624755564357}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\nIt takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\nIf the actor responds with an error, it logs the failure and returns an ApiError.\nIf the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\nThe function also includes error handling for any thrown exceptions during the process.\n */\n    val response = kafkaManagerActor? msg\n\n    response.map {\n      case Right(result) =>\n        try {\n          fn(result)\n        } catch {\n          case e: Exception =>\n            warn(s\\\"Error while processing the response from Kafka Manager: $e\\\")\n            ApiError(e.getMessage)\n        }\n      case Left(error) =>\n        warn(s\\\"Error while processing the response from Kafka Manager: $error\\\")\n        ApiError(error.getMessage)\n    }\n  }", "CodeBleu_score": 34.98889658536388}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The withKafkaManagerActor function sends a message to the Kafka Manager actor and processes the response.\nIt takes an input message and a function to handle the output.\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\nIf an ActorErrorResponse is received, it returns an ApiError.\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n */\n    implicit val ec = apiExecutionContext\n    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse =>\n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) =>\n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover { case t: Throwable =>\n      error(s\"Failed on input : $msg\", t)\n      -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 69.50556099887355}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n//    val cc = KMClusterCommandRequest(clusterName, topics, KMClusterCommandType.PreferredLeaderElection)\n//    tryWithKafkaManagerActor(cc) { result: KMCommandResult =>\n//      result.result\n//    }\n\n    val cc = KMClusterCommandRequest(clusterName, topics, KMClusterCommandType.PreferredLeaderElection)\n    withKafkaManagerActor(cc) { result: KMCommandResult =>\n      result.result\n    }\n  }", "CodeBleu_score": 24.669539979977873}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n//    val clusterContext = ClusterContext(clusterName, topics)\n//    val kmClusterCommandRequest = KMClusterCommandRequest(clusterContext)\n//    withKafkaManagerActor(kmClusterCommandRequest) { result =>\n//      toDisjunction(result)\n//    }\n    tryWithKafkaManagerActor(KMPreferredLeaderElection(clusterName, topics)) { result: KMCommandResult =>\n      toDisjunction(result)\n    }\n  }", "CodeBleu_score": 24.58440316853699}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t", "CodeBleu_score": 3.006318370370258}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t", "CodeBleu_score": 3.006318370370258}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMRunPreferredLeaderElection(Set()))) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 46.29481099369258}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMManualPartitionAssignments(assignments))) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 19.32505683647929}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMManualPartitionAssignments(assignments))) { result =>\nresult.map { cmr =>\ncmr.result.fold({ e =>\n-\\/(ApiError.from(e))\n}, { _ =>\n\\/-(Unit)\n})\n}\n}\n}", "CodeBleu_score": 29.126032040870403}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\n\ntryWithKafkaManagerActor(KMClusterCommandRequest(clusterName, KMManualPartitionAssignments(assignments))) { result: Future[KMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 19.490161928147273}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\tfinal DescribeClusterResult describeClusterResult = admin.describeCluster();\nfinal List<String> nodeIds = describeClusterResult.clusterId().nodes().stream().map(Node::id).collect(Collectors.toList());\nif (nodeIds.isEmpty()) {\nthrow new ConnectException(\\\"No Kafka broker available at \\\" + producerConfig.getString(BOOTSTRAP_SERVERS));\n}\nfinal String nodeId = nodeIds.get(0);\nfinal DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\nfinal Map<ConfigResource, Config> configs = describeConfigsResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\nif (configs.size()!= 1) {\nthrow new ConnectException(\\\"Expected one broker config to match the query but got \\\" + configs.values().size());\n}\nfinal Config brokerConfig = configs.values().iterator().next();\nif (brokerConfig == null) {\nthrow new ConnectException(\\\"Could not get config for broker \\\" + nodeId);\n}\nreturn brokerConfig;\n}", "CodeBleu_score": 38.977914308751124}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\t\tList<String> nodeIds = describeClusterResult.nodes().get().stream().map(Node::id).collect(Collectors.toList());\n\t\tif (nodeIds.isEmpty()) {\n\t\t\tthrow new ConnectException(\n\t\t\t\t\t\"No brokers available. Please check that Kafka is running and that the bootstrap servers are configured correctly.\");\n\t\t}\n\t\tString nodeId = nodeIds.get(0);\n\t\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\n\t\tMap<ConfigResource, Config> configs = describeConfigsResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\t\tif (configs.size()!= 1) {\n\t\t\tthrow new ConnectException(\"Expected one broker to match the query but got \" + configs.values().size());\n\t\t}\n\t\tConfig brokerConfig = configs.values().iterator().next();\n\t\tif (brokerConfig == null) {\n\t\t\tthrow new ConnectException(\"Could not get config for broker \" + nodeId);\n\t\t}\n\t\treturn brokerConfig;\n\t} catch (ExecutionException ex) {\n\t\tthrow new ConnectException(\"Error describing the cluster\", ex);\n\t}\n}", "CodeBleu_score": 52.97753070103075}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\ttry {\nDescribeClusterResult describeClusterResult = admin.describeCluster();\nClusterDescription clusterDescription = describeClusterResult.values().get(0);\nif (clusterDescription == null) {\nthrow new ConnectException(\\\"No cluster description received from Kafka brokers\\\");\n}\n\nList<Node> nodes = clusterDescription.nodes().values().stream().collect(Collectors.toList());\nif (nodes.isEmpty()) {\nthrow new ConnectException(\\\"No nodes in cluster description received from Kafka brokers\\\");\n}\n\n// Select the first node in the cluster\nNode node = nodes.get(0);\n\n// Request the configuration of the selected node\nDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, node.id())));\nMap<ConfigResource, Config> configs = describeConfigsResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\nif (configs.size()!= 1) {\nthrow new ConnectException(\\\"Expected one broker configuration to match the query but got \\\" + configs.values().size());\n}\n\nreturn configs.values().iterator().next();\n}\ncatch (ExecutionException e) {\nthrow new ConnectException(\\\"Failed to retrieve configuration from Kafka broker\\\", e);\n}\n}", "CodeBleu_score": 49.6738279792522}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n@Override\npublic ValidationResult validate(Config config) {\nif (config.getString(ConfigDef.SCHEMA_HISTORY_CONFIG_NAME).equals(KafkaSchemaHistory.SCHEMA_HISTORY_TYPE)) {\nreturn validator.validate(config);\n}\nreturn ValidationResult.success();\n}\n};\n}", "CodeBleu_score": 24.580532910740963}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n@Override\npublic int validate(Config config) {\nif (config.get(SCHEMA_HISTORY_CONFIG_NAME).value().equalsIgnoreCase(KafkaSchemaHistory.SCHEMA_HISTORY_NAME)) {\nreturn validator.validate(config);\n}\nreturn 0;\n}\n};\n}", "CodeBleu_score": 22.52429388191034}, {"code": "private static Validator forKafka(final Validator validator){\n\treturn new Validator() {\n@Override\npublic List<ValidationError> validate(ConfigDef config, ConfigValue value) {\nif (value.hasPath(SCHEMA_HISTORY_NAME)) {\nif (value.getString(SCHEMA_HISTORY_NAME).equals(KafkaSchemaHistory.SCHEMA_HISTORY_NAME)) {\nreturn validator.validate(config, value);\n}\n}\nreturn Collections.emptyList();\n}\n};\n}", "CodeBleu_score": 29.219615493200337}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t kafkaVersion = null;\nBoolean topicCreationEnabled = null;\ntry {\nkafkaVersion = parseVersion(AppInfoParser.getVersion());\n} catch (IllegalArgumentException e) {\n// Ignore\n}\nif (null!= kafkaVersion && kafkaVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0) {\ntry {\nField field = config.getClass().getDeclaredField(\\\"topic.creation.enable\\\");\nfield.setAccessible(true);\ntopicCreationEnabled = (Boolean) field.get(config);\n} catch (NoSuchFieldException | IllegalAccessException e) {\n// Ignore\n}\n}\nif (null == topicCreationEnabled) {\ntopicCreationEnabled = true;\n}\nreturn topicCreationEnabled;\n}", "CodeBleu_score": 43.69955464787086}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tersion kafkaConnectVersion = parseVersion(AppInfoParser.getVersion());\nif (kafkaConnectVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0) {\nField field = config.getClass().getDeclaredField(\\\"topic.creation.enable\\\");\nfield.setAccessible(true);\nreturn (Boolean) field.get(config);\n}\n}", "CodeBleu_score": 38.919634711167205}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tersion kafkaVersion = parseVersion(AppInfoParser.getVersion());\nfinal Boolean topicCreationEnabled = config.containsKey(\\\"topic.creation.enable\\\")? (Boolean) config.get(\\\"topic.creation.enable\\\") : true;\nreturn topicCreationEnabled && kafkaVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0;\n}", "CodeBleu_score": 33.21630031833573}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\nfinal String clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new DebeziumException(\"Missing \" + CLIENT_ID_CONFIG + \" configuration option\");\n}\n\nfinal Map<String, Object> adminProperties = new HashMap<>(config);\nadminProperties.put(CLIENT_ID_CONFIG, clientId);\n\nfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\n\nfinal Converter converter = converterForOffsetStore();\n\nreturn new KafkaOffsetBackingStore(admin, converter);\n}", "CodeBleu_score": 33.16939068043459}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tString clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new DebeziumException(String.format(\\\"The '%s' property is required but was not set.\\\", CLIENT_ID_CONFIG));\n}\n\nMap<String, Object> adminProps = new HashMap<>();\nadminProps.put(CLIENT_ID_CONFIG, clientId);\nadminProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG));\nadminProps.put(DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG, config.get(DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG));\n\nSharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\nConverter converter = converterForOffsetStore();\n\nreturn new KafkaOffsetBackingStore(admin, clientId, converter);\n}", "CodeBleu_score": 40.17893558769047}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new DebeziumException(String.format(\\\"Missing required configuration option '%s'\\\", CLIENT_ID_CONFIG));\n}\nfinal Map<String, Object> adminProperties = new HashMap<>();\nadminProperties.put(CLIENT_ID_CONFIG, clientId);\nadminProperties.put(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG));\nadminProperties.put(DistributedConfig.SECURITY_PROTOCOL_CONFIG, config.get(DistributedConfig.SECURITY_PROTOCOL_CONFIG));\nadminProperties.put(DistributedConfig.SASL_MECHANISM_CONFIG, config.get(DistributedConfig.SASL_MECHANISM_CONFIG));\nadminProperties.put(DistributedConfig.SASL_JAAS_CONFIG, config.get(DistributedConfig.SASL_JAAS_CONFIG));\nadminProperties.put(DistributedConfig.SASL_KERBEROS_SERVICE_NAME_CONFIG, config.get(DistributedConfig.SASL_KERBEROS_SERVICE_NAME_CONFIG));\nfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\nfinal Converter converter = converterForOffsetStore();\nreturn new KafkaOffsetBackingStore(admin, clientId, converter);\n}", "CodeBleu_score": 37.93869788497298}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t!node.isObject()) {\nthrow new RuntimeException(\\\"Expected an object but found \\\" + node.getNodeType());\n}\n\nJsonNode payload = node.get(PAYLOAD_FIELD);\nif (payload!= null) {\nnode = payload;\n}\n\nif (config.isCompositeKey()) {\nreturn reader.readValue(node);\n}\n\nIterator<String> fieldNames = node.fieldNames();\nif (!fieldNames.hasNext()) {\nthrow new RuntimeException(\\\"Expected a single field but found none\\\");\n}\n\nString fieldName = fieldNames.next();\nif (!fieldNames.hasNext()) {\nreturn reader.readValue(node.get(fieldName));\n}\n\nthrow new RuntimeException(\\\"Expected a single field but found \\\" + fieldNames.next());\n}", "CodeBleu_score": 21.536424438407025}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t!node.isObject()) {\nthrow new IOException(\\\"Key must be an object\\\");\n}\n\nJsonNode payload = node.get(PAYLOAD_FIELD);\nif (payload!= null) {\nnode = payload;\n}\n\nif (node.size() == 1) {\nIterator<Map.Entry<String, JsonNode>> fields = node.fields();\nif (fields.hasNext()) {\nMap.Entry<String, JsonNode> entry = fields.next();\nreturn reader.readValue(entry.getValue());\n}\n}\n\nreturn reader.readValue(node);\n}", "CodeBleu_score": 37.55707393659406}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tnode.isObject()) {\nJsonNode payload = node.get(PAYLOAD_FIELD);\nif (payload!= null) {\nnode = payload;\n}\n\nIterator<String> fieldNames = node.fieldNames();\nif (fieldNames.hasNext()) {\nString fieldName = fieldNames.next();\nif (fieldNames.hasNext()) {\nreturn reader.readValue(node);\n}\nelse {\nreturn reader.readValue(node.get(fieldName));\n}\n}\n}\n\nthrow new IOException(\\\"Not a valid key\\\");\n}", "CodeBleu_score": 43.77142343309266}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\nString sanitizedTopicName = topicName.replaceAll(\"[^a-zA-Z0-9\\\\-\\\\.]\", REPLACEMENT_CHAR);\nif (sanitizedTopicName!= topicName) {\nLOGGER.warn(\\\"Topic name {} was sanitized to {}\\\", topicName, sanitizedTopicName);\n}\nreturn sanitizedTopicName;\n}", "CodeBleu_score": 20.58883396879285}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\nif (topicName.contains(REPLACEMENT_CHAR)) {\nLOGGER.warn(\\\"Invalid topic name \\\" + topicName + \\\". Topic names must not contain any invalid characters. The name has been sanitized to \\\" + topicName.replaceAll(REPLACEMENT_CHAR, \\\"_\\\").toString());\n}\nreturn topicName;\n}", "CodeBleu_score": 19.926331638046506}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\n// Iterate through the characters of the topic name.\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\n\n// If the character is invalid, replace it with the replacement character.\nif (!Character.isJavaIdentifierPart(c)) {\ntopicName = topicName.substring(0, i) + REPLACEMENT_CHAR + topicName.substring(i + 1);\n}\n}\n\n// If any replacements were made, log a warning and return the sanitized name.\nif (!topicName.equals(delegate.topicNameFor(id, prefix, delimiter))) {\nLOGGER.warn(\\\"Invalid characters in topic name: {}\\\", topicName);\n}\n\nreturn topicName;\n}", "CodeBleu_score": 39.44513563554547}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\n\nthis.maxRetries = connectorConfig.getRetryMax();\nif (replacedErrorHandler!= null) {\nthis.retries = replacedErrorHandler.retries;\n} else {\nthis.retries = 0;\n}\n}", "CodeBleu_score": 63.52072368076668}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\nthis.maxRetries = connectorConfig.getConnectorConfig().getInt(connectorType.getSimpleName() + \".max.retries\", RETRIES_UNLIMITED);\nif (replacedErrorHandler!= null) {\nretries = replacedErrorHandler.retries;\n}\n}", "CodeBleu_score": 61.59816250684316}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tValidate the configuration.\nMap<String, ConfigValue> errors = configuration.validate(fields);\n\n// Iterate through the validation results.\nfor (Map.Entry<String, ConfigValue> error : errors.entrySet()) {\n// Throw a ConfigException with the first error message for that value.\nthrow new ConfigException(error.getKey(), error.getValue().errorMessages().iterator().next());\n}\n}", "CodeBleu_score": 45.82926279732607}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tr (Field field : fields) {\nConfigValue configValue = configuration.configValue(field.name());\n\nif (configValue.errorMessages().isEmpty()) {\ncontinue;\n}\n\nthrow new ConfigException(configValue.errorMessages().get(0));\n}\n}", "CodeBleu_score": 30.62787673641732}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t (Field field : fields) {\nConfigValue value = configuration.configValue(field.name());\nif (value.errorMessages().size() > 0) {\nthrow new ConfigException(value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 29.93907322772216}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.is(Schema.Type.STRING)) {\nreturn oldSchema;\n}\n\nSchemaBuilder schemaBuilder = SchemaBuilder.struct();\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (oldSchema.field(field.name()).schema().is(Schema.Type.STRING)) {\nschemaBuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\nelse {\nschemaBuilder.field(field.name(), buildNewSchema(field.name(), oldSchema.field(field.name()).schema(), headerToProcess, nestedFields, ++level));\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader!= null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> schemaBuilder.field(s, currentHeader.schema()));\n}\n}\n\nreturn schemaBuilder.build();\n}", "CodeBleu_score": 48.22077097046167}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.is(Schema.Type.STRING) || oldSchema.is(Schema.Type.INT32) || oldSchema.is(Schema.Type.INT64) || oldSchema.is(Schema.Type.FLOAT32) || oldSchema.is(Schema.Type.FLOAT64) || oldSchema.is(Schema.Type.BOOLEAN) || oldSchema.is(Schema.Type.BYTES) || oldSchema.is(Schema.Type.NULL) || oldSchema.is(Schema.Type.ARRAY) || oldSchema.is(Schema.Type.MAP) || oldSchema.is(Schema.Type.STRUCT)) {\n\nreturn oldSchema;\n\n}\n\nSchemaBuilder builder = SchemaBuilder.struct();\n\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n\nif (oldSchema.get(field)!= null) {\n\nif (isContainedIn(field.name(), nestedFields)) {\n\nStruct nestedField = requireStruct(oldSchema.get(field), \"Nested field\");\n\nbuilder.field(field.name(), buildNewSchema(field.name(), nestedField, headerToProcess, nestedFields, ++level));\n\n} else {\n\nbuilder.field(field.name(), oldSchema.get(field));\n\n}\n\n}\n\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader!= null) {\n\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\n\nfieldNameToAdd.ifPresent(s -> builder.field(s, currentHeader.schema()));\n\n}\n\n}\n\nreturn builder.build();\n\n}", "CodeBleu_score": 53.2013714982408}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.isPrimitive()) {\nreturn oldSchema;\n}\n\nfinal SchemaBuilder builder = SchemaBuilder.struct();\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (oldSchema.field(field.name())!= null) {\nif (isContainedIn(field.name(), nestedFields)) {\nSchema nestedField = requireStruct(oldSchema.field(field.name()).schema(), \"Nested field\");\nbuilder.field(field.name(), buildNewSchema(field.name(), nestedField, headerToProcess, nestedFields, ++level));\n} else {\nbuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader!= null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> builder.field(s, currentHeader.schema()));\n}\n}\n\nreturn builder.build();\n}", "CodeBleu_score": 50.352036020225874}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\tString snapshotString = source.getString(SnapshotRecord.SNAPSHOT_KEY);\nif (snapshotString == null) {\nreturn null;\n}\nString upperSnapshotString = snapshotString.toUpperCase();\nswitch (upperSnapshotString) {\ncase \"TRUE\":\nreturn TRUE;\ncase \"FIRST\":\nreturn FIRST;\ncase \"FIRST_IN_DATA_COLLECTION\":\nreturn FIRST_IN_DATA_COLLECTION;\ncase \"LAST_IN_DATA_COLLECTION\":\nreturn LAST_IN_DATA_COLLECTION;\ncase \"LAST\":\nreturn LAST;\ncase \"FALSE\":\nreturn FALSE;\ncase \"INCREMENTAL\":\nreturn INCREMENTAL;\ndefault:\nreturn null;\n}\n}", "CodeBleu_score": 36.52486988194361}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.schema().field(\"snapshot_key\")!= null) {\nString snapshotString = source.getString(\"snapshot_key\");\nif (snapshotString!= null) {\nreturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}\n}\nreturn null;\n}", "CodeBleu_score": 35.46392128423468}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\tif (source.schema().field(SnapshotRecord.SNAPSHOT_KEY)!= null) {\nString snapshotString = source.getString(SnapshotRecord.SNAPSHOT_KEY);\nif (snapshotString!= null) {\nsnapshotString = snapshotString.toUpperCase();\nif (snapshotString.equals(SnapshotRecord.TRUE.name())) {\nreturn SnapshotRecord.TRUE;\n} else if (snapshotString.equals(SnapshotRecord.FIRST.name())) {\nreturn SnapshotRecord.FIRST;\n} else if (snapshotString.equals(SnapshotRecord.FIRST_IN_DATA_COLLECTION.name())) {\nreturn SnapshotRecord.FIRST_IN_DATA_COLLECTION;\n} else if (snapshotString.equals(SnapshotRecord.LAST_IN_DATA_COLLECTION.name())) {\nreturn SnapshotRecord.LAST_IN_DATA_COLLECTION;\n} else if (snapshotString.equals(SnapshotRecord.LAST.name())) {\nreturn SnapshotRecord.LAST;\n} else if (snapshotString.equals(SnapshotRecord.FALSE.name())) {\nreturn SnapshotRecord.FALSE;\n} else if (snapshotString.equals(SnapshotRecord.INCREMENTAL.name())) {\nreturn SnapshotRecord.INCREMENTAL;\n}\n}\n}\nreturn null;\n}", "CodeBleu_score": 41.77497724965985}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\treturn Optional.of(Float.parseFloat(version.split(\"\\\\.\")[0]));\n\t} catch (ArrayIndexOutOfBoundsException | NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 28.540599645121596}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tif (parts.length > 2) {\n\t\t\tparts = new String[] {parts[0], parts[1]};\n\t\t}\n\t\tString[] versionParts = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(versionParts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 63.89235558602356}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tif (parts.length > 2) {\n\t\t\tparts = new String[] { parts[0], parts[1] };\n\t\t}\n\t\tString[] versionParts = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(versionParts[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 63.83924150534537}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(ConnectAction.CREATE)\n       .operationName(\"createConnector\")\n       .build();\n\nreturn validateAccess(context)\n       .thenReturn(kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector))\n       .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 65.59051228122168}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context)\n   .flatMap(ignored -> connector.map(c -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, c)))\n   .map(connectorDTO -> ResponseEntity.ok(connectorDTO))\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 66.2861712926657}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\ttext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context)\n   .thenReturn(kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector))\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 63.80567037294475}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n   .connector(connectorName)\n   .operationName(\"deleteConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 58.58479133936899}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tontext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n   .connector(connectorName)\n   .operationName(\"deleteConnector\")\n   .build();\nreturn validateAccess(context)\n   .thenReturn(kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName))\n   .map(ResponseEntity::ok)\n   .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 45.84409935520954}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n   .connector(connectorName)\n   .operationName(\"deleteConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .then(ResponseEntity.noContent().build())\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 52.34715859074057}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(getConnectorActions(action))\n       .operationName(\"updateConnectorState\")\n       .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n       .build();\n\nreturn validateAccess(context)\n       .thenReturn(kafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action))\n       .map(ResponseEntity::ok)\n       .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 49.004396299876554}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n       .operationName(\"updateConnectorState\")\n       .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n       .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 56.77677647196207}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tvar context = AccessContext.builder()\n       .cluster(clusterName)\n       .connect(connectName)\n       .connectActions(getConnectActions(action))\n       .operationName(\"updateConnectorState\")\n       .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n       .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n               .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 54.14491858802043}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\tConfigurableApplicationContext ctx = new SpringApplicationBuilder(KafkaUiApplication.class)\n.initializers(new DynamicConfigOperations())\n.run(args);\nreturn ctx;\n}", "CodeBleu_score": 44.47116606258333}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\tConfigurableApplicationContext context = new SpringApplicationBuilder(KafkaUiApplication.class)\n.initializers(new DynamicConfigOperations())\n.run(args);\nreturn context;\n}", "CodeBleu_score": 44.528254161565506}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\tConfigurableApplicationContext context = new SpringApplicationBuilder(KafkaUiApplication.class)\n.initializers(new DynamicConfigOperations())\n.run(args);\nreturn context;\n}", "CodeBleu_score": 44.528254161565506}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\ttils.isBlank(search)) {\nreturn (connector) -> true;\n} else {\nreturn (connector) -> Stream.of(connector.getName(), connector.getPlugin().getName(), connector.getPlugin().getClass().getName())\n.anyMatch(connectorName -> connectorName.toLowerCase().contains(search.toLowerCase()));\n}\n}", "CodeBleu_score": 35.124867380845814}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\ttils.isBlank(search)) {\nreturn fullConnectorInfo -> true;\n}\nreturn fullConnectorInfo -> Stream.of(fullConnectorInfo.getConnector().getName(), fullConnectorInfo.getConnector().getType())\n.anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 40.922063316973}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tch == null?\nPredicate.isEqual(true) :\nPredicate.isEqual(true);\n}", "CodeBleu_score": 26.23172029496901}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t   if (propertiesMap == null) {\n//      return new HashMap<>();\n//    }\n//\n//    Map<String, Object> flattenedMap = new HashMap<>();\n//    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n//      String key = entry.getKey();\n//      Object value = entry.getValue();\n//      if (value instanceof Map) {\n//        Map<String, Object> nestedFlattenedMap = flattenClusterProperties(prefix == null? key : prefix + \".\" + key, (Map<String, Object>) value);\n//        flattenedMap.putAll(nestedFlattenedMap);\n//      } else {\n//        flattenedMap.put(prefix == null? key : prefix + \".\" + key, value);\n//      }\n//    }\n//    return flattenedMap;\n//  }", "CodeBleu_score": 12.73357757500676}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t   if (propertiesMap == null) {\n//      return new HashMap<>();\n//    }\n//    Map<String, Object> flattenedProperties = new HashMap<>();\n//    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n//      String key = entry.getKey();\n//      Object value = entry.getValue();\n//      if (value instanceof Map) {\n//        flattenedProperties.putAll(flattenClusterProperties(prefix!= null? prefix + \".\" + key : key, (Map<String, Object>) value));\n//      } else {\n//        flattenedProperties.put(prefix!= null? prefix + \".\" + key : key, value);\n//      }\n//    }\n//    return flattenedProperties;\n//  }", "CodeBleu_score": 12.73357757500676}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t   if (propertiesMap == null) {\n//      return new HashMap<>();\n//    }\n//\n//    Map<String, Object> result = new HashMap<>();\n//    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n//      String key = prefix == null? entry.getKey() : prefix + \".\" + entry.getKey();\n//      if (entry.getValue() instanceof Map) {\n//        result.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n//      } else {\n//        result.put(key, entry.getValue());\n//      }\n//    }\n//    return result;\n//  }", "CodeBleu_score": 12.73357757500676}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tn adminClient.getAuthorizedOperations(clusterDescription.getClusterName())\n.filter(aclOperation -> aclOperation.equals(AclOperation.ALTER))\n.flatMap(aclOperation -> adminClient.isAclViewEnabled()\n.flatMap(aclViewEnabled -> {\nif (aclViewEnabled) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n} else {\nreturn Mono.empty();\n}\n})\n);\n}", "CodeBleu_score": 31.669448834320114}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tclOperation> authorizedOperations = clusterDescription.getAuthorizedOperations();\nreturn adminClient.isAclViewEnabled()\n&& authorizedOperations.contains(AclOperation.ALTER)\n? Mono.just(ClusterFeature.KAFKA_ACL_EDIT)\n: Mono.empty();\n}", "CodeBleu_score": 37.23031186169568}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tn adminClient.getAuthorizedOperations(clusterDescription.getClusterName())\n.flatMap(operations -> {\nif (operations.contains(AclOperation.VIEW_ACLS) && operations.contains(AclOperation.ALTER)) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}\nreturn Mono.empty();\n});\n}", "CodeBleu_score": 32.01423294151425}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\nTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>(Comparator.comparing(TopicPartition::topic));\n\nfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\nTopicPartition topicPartition = entry.getKey();\nFromToOffset fromToOffset = entry.getValue();\n\nif (fromToOffset.fromOffset == null) {\n// We're at the beginning of the topic\nfromToOffset = seekOperations.seekToBeginning(topicPartition);\n}\n\nint numMessagesToPoll = Math.min(messagesPerPage, fromToOffset.toOffset - fromToOffset.fromOffset + 1);\n\n// Adjust the start offset based on the number of messages to poll\nint newFromOffset = fromToOffset.fromOffset - numMessagesToPoll + 1;\n\n// If the new start offset is less than the beginning offset, we're at the beginning of the topic\nif (newFromOffset < fromToOffset.beginningOffset) {\nnewFromOffset = fromToOffset.beginningOffset;\n}\n\nnextRange.put(topicPartition, new FromToOffset(newFromOffset, fromToOffset.toOffset));\n}\n\nreturn nextRange;\n}", "CodeBleu_score": 36.83738240009864}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\nTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>(Comparator.comparing(TopicPartition::topic));\n\nif (prevRange.isEmpty()) {\nnextRange = seekOperations.getOffsets();\n} else {\nnextRange.putAll(prevRange);\n}\n\nMap<TopicPartition, Long> partitionsToPoll = nextRange.entrySet().stream()\n.collect(Collectors.toMap(Map.Entry::getKey, entry -> {\nFromToOffset offsetRange = entry.getValue();\nlong startOffset = offsetRange.from();\nlong endOffset = offsetRange.to();\n\nlong nextOffset = startOffset - messagesPerPage;\n\nif (nextOffset < 0) {\nnextOffset = 0;\n}\n\nreturn new FromToOffset(nextOffset, endOffset);\n}));\n\nreturn new TreeMap<>(partitionsToPoll);\n}", "CodeBleu_score": 41.17938275658661}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\n\n    TreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\n    if (prevRange.isEmpty()) {\n      for (Map.Entry<TopicPartition, FromToOffset> entry : seekOperations.seekOffsets().entrySet()) {\n        nextRange.put(entry.getKey(), entry.getValue());\n      }\n    } else {\n      for (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        FromToOffset prevOffset = entry.getValue();\n        FromToOffset nextOffset = seekOperations.seekOffsets().get(topicPartition);\n\n        if (nextOffset == null) {\n          nextRange.put(topicPartition, prevOffset);\n        } else {\n          int numberOfMessagesToPoll = Math.min(messagesPerPage, nextOffset.getTo() - prevOffset.getTo());\n          int adjustedStartOffset = prevOffset.getTo() - numberOfMessagesToPoll;\n\n          if (adjustedStartOffset < prevOffset.getFrom()) {\n            nextRange.put(topicPartition, new FromToOffset(prevOffset.getFrom(), prevOffset.getTo()));\n          } else {\n            nextRange.put(topicPartition, new FromToOffset(adjustedStartOffset, nextOffset.getTo()));\n          }\n        }\n      }\n    }\n\n    return nextRange;\n  }", "CodeBleu_score": 33.522372278991305}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\ttry {\nfinal Properties customProperties = new Properties();\ncustomProperties.load(new StringReader(configuration.getString(CK_CUSTOM_PROPERTIES)));\n\n// Merge the custom properties with the existing properties.\nprops.putAll(customProperties);\n} catch (IOException e) {\nLOG.error(\\\"Failed to load custom properties from configuration. Please check the configuration.\\\", e);\n}\n}", "CodeBleu_score": 46.86341454641282}, {"code": "private void insertCustomProperties(Properties props){\n\ttry {\nString customProperties = configuration.getString(CK_CUSTOM_PROPERTIES);\nif (customProperties!= null &&!customProperties.isEmpty()) {\nProperties customProps = new Properties();\ncustomProps.load(new StringReader(customProperties));\nprops.putAll(customProps);\n}\n} catch (IOException e) {\nLOG.error(\"Error loading custom properties. Error: {}\", e.getMessage());\n}\n}", "CodeBleu_score": 42.2865079810024}, {"code": "private void insertCustomProperties(Properties props){\n\ttry {\nfinal String customPropertiesString = configuration.getString(CK_CUSTOM_PROPERTIES);\nif (customPropertiesString!= null &&!customPropertiesString.isEmpty()) {\nfinal Properties customProperties = new Properties();\ncustomProperties.load(new StringReader(customPropertiesString));\nprops.putAll(customProperties);\n}\n} catch (IOException e) {\nLOG.error(\\\"Error inserting custom properties\\\", e);\n}\n}", "CodeBleu_score": 48.646508097771815}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\tentries == null || entries.isEmpty()) {\nreturn;\n}\n\nlong messageBytes = 0;\nfor (RawMessageEvent entry : entries) {\nif (entry == null) {\ncontinue;\n}\n\nmessageBytes += entry.getMessage().length();\n}\n\nmetrics.totalMessages().add(entries.size());\nmetrics.totalMessageBytes().add(messageBytes);\n\ntry {\nwriteRetryer.call(() -> kafkaJournal.write(entries));\nmetrics.successfulWriteAttempts().mark();\nmetrics.successfulWrites().mark();\n} catch (RetryException e) {\nmetrics.failedWriteAttempts().mark();\nthrow new MessageQueueException(\\\"Unable to write to journal - retrying with exponential back-off\\\", e);\n} catch (ExecutionException e) {\nmetrics.failedWriteAttempts().mark();\nthrow new MessageQueueException(\\\"Unable to write to journal\\\", e);\n}\n}", "CodeBleu_score": 29.936581652117827}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t  if (entries.isEmpty()) {\n        return;\n    }\n\n    long totalBytes = 0;\n    List<LocalKafkaJournal.JournalEntry> journalEntries = entries.stream()\n           .filter(Objects::nonNull)\n           .map(entry -> {\n                totalBytes += entry.getPayload().length;\n                return new LocalKafkaJournal.JournalEntry(entry.getPayload(), entry.getTimestamp());\n            })\n           .collect(Collectors.toList());\n\n    try {\n        writeRetryer.call(() -> {\n            kafkaJournal.write(journalEntries);\n            return null;\n        });\n    } catch (RetryException | ExecutionException e) {\n        throw new MessageQueueException(\\\"Unable to write to journal\\\", e);\n    }\n\n    metrics.writtenMessages().inc(entries.size());\n    metrics.writtenBytes().inc(totalBytes);\n}", "CodeBleu_score": 52.01363389900449}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t{\nlong totalBytes = 0;\nList<Journal.Entry> journalEntries = entries.stream()\n.filter(Objects::nonNull)\n.map(entry -> {\ntotalBytes += entry.getPayload().length;\nreturn new Journal.Entry(entry.getPayload(), entry.getTags(), entry.getStreamId());\n})\n.collect(Collectors.toList());\n\nif (journalEntries.isEmpty()) {\nreturn;\n}\n\nmetrics.writtenMessages().inc(journalEntries.size());\nmetrics.writtenBytes().inc(totalBytes);\n\ntry {\nwriteRetryer.call(() -> kafkaJournal.write(journalEntries));\n} catch (RetryException e) {\nmetrics.failedWriteAttempts().inc(journalEntries.size());\nthrow new MessageQueueException(\\\"Unable to write to journal\\\", e);\n}\n} catch (ExecutionException e) {\nthrow new MessageQueueException(\\\"Unable to write to journal\\\", e);\n}\n}", "CodeBleu_score": 47.39605906058707}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\tlong maxValidMessageQueueId = messages.stream()\n.map(Message::getMessageQueueId)\n.max(Long::compareTo)\n.orElse(0);\n\nif (maxValidMessageQueueId > 0) {\nkafkaJournal.acknowledge(maxValidMessageQueueId);\nmetrics.acknowledgedMessages.inc(messages.size());\n}\n}", "CodeBleu_score": 38.05387319826523}, {"code": "public void acknowledge(List<Message> messages){\n\tlong maxValidQueueId = messages.stream()\n.map(Message::getQueueId)\n.max(Long::compareTo)\n.orElse(-1L);\n\nif (maxValidQueueId > 0) {\nkafkaJournal.acknowledge(maxValidQueueId);\nmetrics.acknowledged(messages.size());\n}\n}", "CodeBleu_score": 35.2455713878811}, {"code": "public void acknowledge(List<Message> messages){\n\tOptional<Long> maxMessageQueueId = messages.stream().map(Message::getMessageQueueId).max(Long::compareTo);\nif (maxMessageQueueId.isPresent()) {\nLong messageQueueId = maxMessageQueueId.get();\nkafkaJournal.acknowledge(messageQueueId);\nmetrics.acknowledgedMessages.mark(messages.size());\n}\n}", "CodeBleu_score": 38.39174390501113}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\tfinal MetricFilter filter = new MetricFilter() {\n        @Override\n        public boolean matches(String name, String match) {\n            return name.startsWith(LocalKafkaJournal.class.getName());\n        }\n    };\n\n    final MetricFilter legacyFilter = new MetricFilter() {\n        @Override\n        public boolean matches(String name, String match) {\n            return name.startsWith(metricPrefix);\n        }\n    };\n\n    for (final Metric metric : metricRegistry.filteredMetrics(filter)) {\n        final String legacyMetricName = metricPrefix + metric.name().substring(LocalKafkaJournal.class.getName().length());\n        try {\n            metricRegistry.register(legacyMetricName, metric);\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\\\"Unable to register legacy metric {} under name {}. Original metric name: {}\\\", metric.name(), legacyMetricName, metric.name());\n        }\n    }\n\n    for (final Metric metric : metricRegistry.filteredMetrics(legacyFilter)) {\n        final String originalMetricName = metric.name().substring(metricPrefix.length());\n        try {\n            metricRegistry.register(originalMetricName, metric);\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\\\"Unable to register legacy metric {} under name {}. Original metric name: {}\\\", metric.name(), originalMetricName, metric.name());\n        }\n    }\n}", "CodeBleu_score": 36.69536424291975}, {"code": "private void registerLegacyMetrics(){\n\tfinal String metricPrefix = LocalKafkaJournal.class.getName();\nfinal MetricRegistry metricRegistry = this.metricRegistry;\nfinal MetricFilter filter = new MetricFilter() {\n@Override\npublic boolean matches(String name, String nameSpace, Metric metric) {\nreturn name.startsWith(metricPrefix);\n}\n};\n\nfor (final Metric metric : metricRegistry.getMetrics(filter)) {\nfinal String legacyMetricName = name(metricPrefix, metric.name());\ntry {\nmetricRegistry.register(legacyMetricName, metric);\n} catch (final Exception e) {\nLOG.warn(\\\"Unable to register legacy metric {} under name {}\\\", metric.name(), legacyMetricName);\n}\n}\n}", "CodeBleu_score": 37.073214443304}, {"code": "private void registerLegacyMetrics(){\n\t\tfor (final MetricName metricName : metricRegistry.getNames()) {\n\t\tif (metricName.name().startsWith(LocalKafkaJournal.class.getName())) {\n\t\t\ttry {\n\t\t\t\tfinal String legacyMetricName = metricName.name().replace(LocalKafkaJournal.class.getName(), \\\"graylog2-journal\\\");\n\t\t\t\tmetricRegistry.register(legacyMetricName, metricRegistry.getMetrics().get(metricName));\n\t\t\t\tLOG.warn(\\\"Registering legacy metric {} under name {}\\\", metricName, legacyMetricName);\n            } catch (final IllegalArgumentException e) {\n                LOG.warn(\\\"Failed to register legacy metric {} under name {}\\\", metricName, e);\n            }\n        }\n    }\n}", "CodeBleu_score": 27.178884405383137}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.timer(metricName);\n\t}\n}", "CodeBleu_score": 17.822503543523865}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.timer(metricName + \"-existing\");\n\t}\n}", "CodeBleu_score": 18.139164037429754}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.timer(metricName);\n\t}\n}", "CodeBleu_score": 17.822503543523865}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nfinal Gauge<Long> gauge = (Gauge<Long>) new Gauge<Long>() {\n@Override\npublic Long getValue() {\nif (kafkaLog.size() == 0) {\nreturn 0L;\n}\nif (committedOffset.get() == -1) {\nreturn kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n}\nreturn kafkaLog.logEndOffset() - committedOffset.get();\n}\n};\nmetricRegistry.register(name, gauge);\n} catch (IllegalArgumentException e) {\n// ignore\n}\n}", "CodeBleu_score": 44.41118959427828}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, (Gauge<Long>) () -> {\nfinal long uncommittedMessages = kafkaLog.size() - kafkaLog.recoveryPoint();\nreturn uncommittedMessages > 0? uncommittedMessages : 0;\n});\n} catch (IllegalArgumentException e) {\nfinal SortedMap<String, Gauge<Long>> gauges = metricRegistry.getGauges((name, metric) -> name.equals(name));\nfinal Gauge<Long> gauge = Iterables.getOnlyElement(gauges.values());\n}\n}", "CodeBleu_score": 43.09837070980983}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\nmetricRegistry.register(name, new Gauge<Long>() {\n@Override\npublic Long getValue() {\nlong uncommitted = 0;\nif (kafkaLog.size() > 0) {\nif (committedOffset.get() == -1) {\nuncommitted = kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n} else {\nuncommitted = kafkaLog.logEndOffset() - committedOffset.get();\n}\n}\nreturn uncommitted;\n}\n});\n} catch (IllegalArgumentException e) {\n// ignore\n}\n}", "CodeBleu_score": 39.170900459816906}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tlong lastWriteOffset = 0;\n\tif (messages.size() == 0) {\n\t\tLOG.debug(\\\"No messages to write to the log.\\\");\n\t\treturn lastWriteOffset;\n\t}\n\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n\tLOG.debug(\\\"Writing {} messages with {} bytes to the log.\\\", messages.size(), messageSet.sizeInBytes());\n\ttry {\n\t\tlastWriteOffset = log.append(messageSet);\n\t} catch (LogException e) {\n\t\tLOG.error(\\\"Failed to append message set to the log: \\\" + e.getMessage());\n\t}\n\n\twriteMessages.mark(messages.size());\n\twriteBytes.mark(payloadSize);\n\treturn lastWriteOffset;\n}", "CodeBleu_score": 35.10714912721704}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\ttry (Timer.Context ignored = writeTime.time()) {\nfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nfinal long lastWriteOffset = append(messageSet.buffer());\n\nif (LOG.isTraceEnabled()) {\nLOG.trace(\\\"Wrote {} bytes of messages to the log at offset {}.\\\", payloadSize, lastWriteOffset);\n}\n\nwriteMessages.mark();\nreturn lastWriteOffset;\n}\n}", "CodeBleu_score": 26.471614760925753}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\ttry (Timer.Context ignored = writeTime.time()) {\nfinal MessageSet messageSet = new MessageSet(messages);\n\nif (LOG.isDebugEnabled()) {\nLOG.debug(\\\"Appending {} bytes message set with {} messages to log at offset {}\\\",\n        messageSet.sizeInBytes(), messages.size(), messageSet.lastOffset());\n}\n\nfinal long lastWriteOffset = appendMessageSet(messageSet);\n\nif (LOG.isDebugEnabled()) {\nLOG.debug(\\\"Appended message set with {} messages to log at offset {}. Payload size: {} bytes.\\\",\n        messages.size(), lastWriteOffset, payloadSize);\n}\n\nwriteMessages.mark(messages.size());\n\nreturn lastWriteOffset;\n}\n}", "CodeBleu_score": 39.38323357762101}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t", "CodeBleu_score": 2.774556204846159}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tsynchronized (KAFKA_ADMIN_CLIENT_MAP) {\n\t\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\n\t\tif (adminClientList == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tLOGGER.info(\\\"[KafkaAdminClient] start to close kafka admin client for cluster phy id = {}\\\", clusterPhyId);\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close();\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\\\"[KafkaAdminClient] close kafka admin client failed for cluster phy id = {}\\\", clusterPhyId, e);\n\t\t\t}\n\t\t}\n\t\tLOGGER.info(\\\"[KafkaAdminClient] close kafka admin client for cluster phy id = {} success\\\", clusterPhyId);\n\t}\n}", "CodeBleu_score": 43.57259038919587}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\n\tif (adminClientList == null) {\n\t\treturn;\n\t}\n\tLOGGER.info(\\\"[KafkaAdminClient] close kafka admin client, clusterPhyId = \\\" + clusterPhyId);\n\ttry {\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close();\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\\\"[KafkaAdminClient] close kafka admin client failed, clusterPhyId = \\\" + clusterPhyId + \\\", error = \\\" + e.getMessage());\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tLOGGER.error(\\\"[KafkaAdminClient] close kafka admin client failed, clusterPhyId = \\\" + clusterPhyId + \\\", error = \\\" + e.getMessage());\n\t}\n\tLOGGER.info(\\\"[KafkaAdminClient] close kafka admin client success, clusterPhyId = \\\" + clusterPhyId);\n}", "CodeBleu_score": 31.8525990423276}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t (adminClientList == null) {\nreturn true;\n}\n\nboolean success = true;\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nLOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}\", clusterPhyId, e);\nsuccess = false;\n}\n}\nreturn success;\n}", "CodeBleu_score": 75.98014085369005}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tolean allSuccess = true;\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nLOGGER.error(\\\"close kafka AdminClient failed, clusterPhyId:{}\\\", clusterPhyId, e);\nallSuccess = false;\n}\n}\nreturn allSuccess;\n}", "CodeBleu_score": 57.38274919569075}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t (adminClientList == null) {\nreturn true;\n}\n\nboolean allSuccess = true;\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nLOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{} adminClient:{}\", clusterPhyId, adminClient, e);\nallSuccess = false;\n}\n}\n\nreturn allSuccess;\n}", "CodeBleu_score": 71.50991110339973}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.close();\n\t\tint attempts = 0;\n\t\twhile (app.isRunning() && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(\"Interrupted while waiting for app to stop\", e);\n\t\t\t}\n\t\t\tattempts++;\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 48.64442504294101}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop();\n\t\tfor (int i = 0; i < 5; i++) {\n\t\t\ttry {\n\t\t\t\tif (!app.isRunning()) {\n\t\t\t\t\tapp = null;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tthrow new IllegalStateException(\"Application did not stop in 5 seconds\");\n\t}\n}", "CodeBleu_score": 46.65098116598776}, {"code": "public void stop() {\n\t\tif (app!= null) {\n\t\tapp.stop();\n\t\tint maxAttempts = 5;\n\t\tfor (int i = 0; i < maxAttempts; i++) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t\tif (!app.isRunning()) {\n\t\t\t\t\tapp.close();\n\t\t\t\t\tapp = null;\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.84616615035705}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTLS();\n\trunner.setKeystore(serverCert, KEY_STORE_PASSWORD);\n\trunner.setTruststore(caCert, KEY_STORE_PASSWORD);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 48.979724260688094}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\teurekaServerRunner.enableTLS();\n\teurekaServerRunner.setKeystore(KEY_STORE_PASSWORD, KEY_PASSWORD, caCert, serverCert, clientCert);\n\teurekaServerRunner.setTruststore(KEY_STORE_PASSWORD, KEY_PASSWORD, caCert);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 46.05691115256524}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\teurekaServerRunner.enableTLS();\n\teurekaServerRunner.setKeystore(KEY_STORE_PASSWORD, KEY_PASSWORD, caCert, clientCert);\n\teurekaServerRunner.setTruststore(KEY_STORE_PASSWORD, caCert);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 49.67228887167118}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config);\n\tclient.setEurekaServer(server);\n\tclient.setServiceName(\"testservice\");\n\tclient.enableTls();\n\tclient.setKeyStore(clientCert, KEY_STORE_PASSWORD, \"client\", KEY_PASSWORD);\n\tclient.setTrustStore(caCert, KEY_STORE_PASSWORD);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 36.47140002473839}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\tEurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\");\nclient.enableTls();\nclient.setKeyStore(clientCert, KEY_STORE_PASSWORD, \"client\", KEY_PASSWORD);\nclient.setTrustStore(caCert, KEY_STORE_PASSWORD);\nclient.start();\nreturn client;\n}", "CodeBleu_score": 55.041656877327746}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config);\n\tclient.enableTls();\n\tclient.setKeyStore(clientCert, KEY_STORE_PASSWORD, \"client\", KEY_PASSWORD);\n\tclient.setTrustStore(caCert, KEY_STORE_PASSWORD);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 36.810891231221824}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t", "CodeBleu_score": 1.403125619965593}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate and key\n\tKeyTool keyTool = new KeyTool(KEY_STORE_PASSWORD);\n\tkeyTool.createSelfSignedCert(\"CN=CA\", \"CN=CA\", \"CN=CA\", \"CN=CA\", \"CN=CA\", \"CN=CA\", \"CA\");\n\tkeyTool.saveCert(caCert);\n\tkeyTool.saveKey(caCert, KEY_PASSWORD);\n\n\t// Create a server certificate and key\n\tkeyTool.createSelfSignedCert(\"CN=server\", \"CN=server\", \"CN=server\", \"CN=server\", \"CN=server\", \"CN=server\", \"server\");\n\tkeyTool.saveCert(serverCert);\n\tkeyTool.saveKey(serverCert, KEY_PASSWORD);\n\n\t// Create a client certificate and key\n\tkeyTool.createSelfSignedCert(\"CN=client\", \"CN=client\", \"CN=client\", \"CN=client\", \"CN=client\", \"CN=client\", \"client\");\n\tkeyTool.saveCert(clientCert);\n\tkeyTool.saveKey(clientCert, KEY_PASSWORD);\n\n\t// Create a second CA certificate and key\n\tkeyTool.createSelfSignedCert(\"CN=CA2\", \"CN=CA2\", \"CN=CA2\", \"CN=CA2\", \"CN=CA2\", \"CN=CA2\", \"CA2\");\n\tkeyTool.saveCert(wrongCaCert);\n\tkeyTool.saveKey(wrongCaCert, KEY_PASSWORD);\n\n\t// Create a second client certificate and key\n\tkeyTool.createSelfSignedCert(\"CN=client2\", \"CN=client2\", \"CN=client2\", \"CN=client2\", \"CN=client2\", \"CN=client2\", \"client2\");\n\tkeyTool.saveCert(wrongClientCert);\n\tkeyTool.saveKey(wrongClientCert, KEY_PASSWORD);\n}", "CodeBleu_score": 16.1336785568082}, {"code": "static void createCertificates() throws Exception{\n\t\tcreateCertificates(null);\n}", "CodeBleu_score": 1.4913144033016956}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + (seconds * 1000);\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(String.format(\\\"Assertion failed after %d seconds\\\", seconds));\n}", "CodeBleu_score": 49.13205735666707}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = startTime + seconds * 1000;\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(String.format(\\\"Assertion failed after %s seconds\\\", seconds));\n}", "CodeBleu_score": 50.2196466698132}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong start = System.currentTimeMillis();\n\tlong limit = start + (seconds * 1000);\n\twhile (System.currentTimeMillis() < limit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Condition not met within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 52.218915847725675}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(new X500Name(ca), BigInteger.valueOf(System.currentTimeMillis()), new Date(System.currentTimeMillis()), new Date(System.currentTimeMillis() + TEN_YEARS), new X500Name(subject), keyPair.getPublic());\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign));\n\tContentSigner signer = new JcaContentSignerBuilder(\\\"SHA256withRSA\\\").build(signer.privateKey());\n\treturn new JcaX509CertificateConverter().getCertificate(new X509CertificateHolder(builder.build(signer)));\n}", "CodeBleu_score": 43.87524496329217}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(\n\t\t\tnew X500Name(ca),\n\t\t\tnew BigInteger(1, new SecureRandom().generateSeed(8)),\n\t\t\tnew Date(System.currentTimeMillis()),\n\t\t\tnew Date(System.currentTimeMillis() + TEN_YEARS),\n\t\t\tnew X500Name(ca),\n\t\t\tkeyPair.getPublic());\n\n\tContentSigner signer = new JcaContentSignerBuilder(\\\"SHA256WithRSA\\\").build(keyPair.getPrivate());\n\treturn new JcaX509CertificateConverter().getCertificate(new X509CertificateHolder(builder.build(signer)));\n}", "CodeBleu_score": 36.77288512884901}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n\t\t\tnew X500Name(ca),\n\t\t\tnew BigInteger(1, new SecureRandom().generateSeed(16)),\n\t\t\tnew Date(System.currentTimeMillis()),\n\t\t\tnew Date(System.currentTimeMillis() + TEN_YEARS),\n\t\t\tnew X500Name(ca),\n\t\t\tkeyPair.getPublic());\n\tcertBuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.digitalSignature));\n\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\tContentSigner signer = new JcaContentSignerBuilder(\\\"SHA256withRSA\\\").build(keyPair.getPrivate());\n\treturn new JcaX509CertificateConverter().getCertificate(certBuilder.build(signer));\n}", "CodeBleu_score": 39.45735562851127}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) ReflectionUtils.getField(this.eurekaTransportField, this);\n\t\t\tthis.eurekaHttpClient.set(eurekaHttpClient);\n\t\t}\n\t\tcatch (IllegalAccessException e) {\n\t\t\tlog.error(\"Could not access the eurekaTransport field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 47.11059589483057}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tif (eurekaHttpClient.get() == null) {\n\t\ttry {\n\t\t\tObject eurekaTransport = ReflectionUtils.getField(eurekaTransportField, this);\n\t\t\tReflectionUtils.makeAccessible(eurekaTransportField);\n\t\t\teurekaHttpClient.set((EurekaHttpClient) ReflectionUtils.getField(ReflectionUtils.findField(eurekaTransport.getClass(), \\\"registrationClient\\\"), eurekaTransport));\n\t\t}\n\t\tcatch (IllegalAccessException ex) {\n\t\t\tlog.error(\\\"Failed to access EurekaHttpClient\\\", ex);\n\t\t}\n\t}\n\treturn eurekaHttpClient.get();\n}", "CodeBleu_score": 36.067990463952}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) ReflectionUtils.getField(this.eurekaTransportField, this);\n\t\t\tthis.eurekaHttpClient.set(eurekaHttpClient);\n\t\t}\n\t\tcatch (IllegalAccessException ex) {\n\t\t\tlog.error(\"Unable to retrieve EurekaHttpClient instance\", ex);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 43.86420467746594}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<Application> applications = this.eurekaClient.getApplications(false).getRegisteredApplications();\n\tif (applications.isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> serviceIds = new ArrayList<>();\n\tfor (Application application : applications) {\n\t\tfor (InstanceInfo info : application.getInstances()) {\n\t\t\tserviceIds.add(info.getAppName().toLowerCase());\n\t\t}\n\t}\n\treturn serviceIds;\n}", "CodeBleu_score": 58.11941149853068}, {"code": "public List<String> getServices(){\n\t\tApplications apps = this.eurekaClient.getApplications();\n\tif (apps == null || apps.getRegisteredApplications() == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application app : apps.getRegisteredApplications()) {\n\t\tfor (InstanceInfo info : app.getInstances()) {\n\t\t\tString name = info.getAppName().toLowerCase();\n\t\t\tif (!services.contains(name)) {\n\t\t\t\tservices.add(name);\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 57.58642863998398}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications(false);\n\tif (applications == null || applications.getRegisteredApplications() == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 58.6692319807115}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthIndicator indicator : composite.getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 47.93619424959286}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthIndicator indicator : composite.getHealthIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 48.02459668634897}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tString name = entry.getKey();\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tfor (HealthIndicator indicator : ((DiscoveryCompositeHealthContributor) value).getHealthIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(name, indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(name, value);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.79805440336914}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances.isEmpty()) {\nthrow new RuntimeException(\"No instances available for provider-application\");\n}\nServiceInstance serviceInstance = instances.get(0);\nURI uri = serviceInstance.getUri();\nreturn restTemplate.postForObject(uri + \"/echo\", \"Hello World!\", String.class);\n}", "CodeBleu_score": 49.82738739043825}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances.isEmpty()) {\nthrow new RuntimeException(\"No instances available for provider-application\");\n}\nServiceInstance instance = instances.get(0);\nURI uri = instance.getUri();\nreturn restTemplate.postForObject(uri.toString() + \"/echo\", \"Hello World!\", String.class);\n}", "CodeBleu_score": 48.00196055021368}, {"code": "public String hello(){\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\nif (instances.isEmpty()) {\nthrow new RuntimeException(\"No instances of provider-application were found\");\n}\nServiceInstance instance = instances.get(0);\nURI uri = instance.getUri();\nreturn restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n}", "CodeBleu_score": 46.58521116100249}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.getInstances(\"provider-application\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \"/echo\", null, String.class);\nreturn response;\n}\nthrow new RuntimeException(\"No service instance for provider-application found\");\n}", "CodeBleu_score": 75.32420640391015}, {"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.getInstances(\"provider-application\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \"/echo\", null, String.class);\nreturn response;\n}\nthrow new RuntimeException(\"No service instance for provider-application found\");\n}", "CodeBleu_score": 75.32420640391015}, {"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.getInstances(\"provider-application\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \"/echo\", null, String.class);\nreturn response;\n}\nthrow new RuntimeException(\"No service instance for provider-application found\");\n}", "CodeBleu_score": 75.32420640391015}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\\\"Registering service \\\" + serviceName + \\\" at \\\" + ip + \\\":\\\" + port);\nif (!serverMap.containsKey(serviceName)) {\nsynchronized (serverMap) {\nif (!serverMap.containsKey(serviceName)) {\nserverMap.put(serviceName, new HashSet<>());\n}\n}\n}\nserverMap.get(serviceName).add(new Server(ip, port));\nreturn true;\n}", "CodeBleu_score": 34.03606294312616}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\\\"Registering service \\\" + serviceName + \\\" at \\\" + ip + \\\":\\\" + port);\nif (!serverMap.containsKey(serviceName)) {\nserverMap.put(serviceName, new HashSet<>());\n}\nserverMap.get(serviceName).add(new Server(ip, port));\nreturn true;\n}", "CodeBleu_score": 32.71436957100686}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tif (!serverMap.containsKey(serviceName)) {\nserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n}\nserverMap.get(serviceName).add(new Server(ip, port));\nlogger.info(\\\"Service \\\" + serviceName + \\\" registered at \\\" + ip + \\\":\\\" + port);\nreturn true;\n}", "CodeBleu_score": 49.613604381260444}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\n\tserverMap.get(serviceName).removeIf(server -> server.getIp().equals(ip) && server.getPort() == port);\n\treturn true;\n}", "CodeBleu_score": 49.04026978016524}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\n\tserverMap.get(serviceName.toLowerCase()).removeIf(server -> server.equals(new Server(ip, port)));\n\treturn true;\n}", "CodeBleu_score": 51.39089827763305}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\n\tserverMap.get(serviceName).removeIf(s -> s.getIp().equals(ip) && s.getPort().equals(port));\n\treturn true;\n}", "CodeBleu_score": 47.366178355747316}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\nMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\nif (attributes.containsKey(\"defaultConfiguration\")) {\n\n// 1. \u5f97\u5230\u914d\u7f6e\u7c7b\nClass<?> configClass = (Class<?>) attributes.get(\"defaultConfiguration\");\n\n// 2. \u5f97\u5230\u914d\u7f6e\u7c7b\u540d\u79f0\nString name = configClass.getName();\n\n// 3. \u6ce8\u518c\u914d\u7f6e\u7c7b\nBeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(configClass);\n\n// 4. \u6ce8\u518cbean\nregistry.registerBeanDefinition(name, beanDefinitionBuilder.getBeanDefinition());\n\n}\n\n}", "CodeBleu_score": 45.77743308502602}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\nMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\nif (attributes == null) {\nreturn;\n}\n\nString defaultConfiguration = (String) attributes.get(\"defaultConfiguration\");\nif (defaultConfiguration!= null) {\nString name = \"RibbonClientConfiguration.\" + defaultConfiguration;\nBeanDefinitionBuilder beanDefinitionBuilder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbeanDefinitionBuilder.addPropertyValue(\"defaultConfiguration\", defaultConfiguration);\nregistry.registerBeanDefinition(name, beanDefinitionBuilder.getBeanDefinition());\n}\n}", "CodeBleu_score": 47.151671310842644}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nif (attributes!= null) {\nString defaultConfiguration = (String) attributes.get(\"defaultConfiguration\");\nif (defaultConfiguration!= null) {\nString name = RibbonClientConfiguration.class.getName() + \"$\" + defaultConfiguration;\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.rootBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"defaultConfiguration\", defaultConfiguration);\nregistry.registerBeanDefinition(name, builder.getBeanDefinition());\n}\n}\n}", "CodeBleu_score": 47.82576106586563}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\tILoadBalancer loadBalancer = clientFactory.getLoadBalancer(serviceId);\nif (loadBalancer == null) {\nreturn null;\n}\nServer server = loadBalancer.chooseServer(new LoadBalancerRequest(serviceId, request));\nif (server == null) {\nreturn null;\n}\nreturn new TutuServiceInstance(server);\n}", "CodeBleu_score": 50.35187974399486}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\tILoadBalancer lb = clientFactory.getLoadBalancer(serviceId);\nif (lb == null) {\nreturn null;\n}\nServer server = null;\ntry {\nserver = lb.chooseServer(new LoadBalancerRequest(serviceId, request));\n} catch (IOException e) {\nthrow new RuntimeException(\"Unable to choose server for load balancer \" + lb.getName(), e);\n}\nif (server == null) {\nreturn null;\n}\nreturn new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 56.49103283063867}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\nILoadBalancer loadBalancer = clientFactory.getLoadBalancer(serviceId);\nif (loadBalancer == null) {\nreturn null;\n}\n\nServer server = loadBalancer.chooseServer(new LoadBalancerRequest(serviceId, request));\nif (server == null) {\nreturn null;\n}\n\nreturn new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 62.3556703152215}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\ttring host = server.getHost();\nint port = server.getPort();\nString path = original.getPath();\nString query = original.getQuery();\ntry {\nreturn new URI(original.getScheme(), original.getUserInfo(), host, port, path, query, original.getFragment());\n} catch (URISyntaxException e) {\nthrow new RuntimeException(\"Unable to reconstruct URI\", e);\n}\n}", "CodeBleu_score": 33.38615818108373}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t", "CodeBleu_score": 3.8941988765375157}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString reconstructedURI;\n\tif (original.getQuery() == null) {\n\t\treconstructedURI = StrUtil.format(\\\"{}://{}:{}{}\\\", original.getScheme(), host, port, original.getPath());\n\t}\n\telse {\n\t\treconstructedURI = StrUtil.format(\\\"{}://{}:{}{}?{}\\\", original.getScheme(), host, port, original.getPath(), original.getQuery());\n\t}\n\ttry {\n\t\treturn new URI(reconstructedURI);\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 37.31477875662289}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\tString url = discoveryProperties.getDiscoveryUrl() + \"/list\";\nMap<String, Object> params = new HashMap<>();\nparams.put(\"serviceName\", discoveryProperties.getServiceName());\nString response = HttpUtil.get(url, params);\nJSONObject jsonObject = JSON.parseObject(response);\nList<TutuServer> tutuServerList = jsonObject.getJSONArray(\"data\").stream().map(o -> {\nJSONObject json = (JSONObject) o;\nreturn new TutuServer(json.getString(\"ip\"), json.getInteger(\"port\"));\n}).collect(Collectors.toList());\nreturn tutuServerList;\n}", "CodeBleu_score": 45.28754582597797}, {"code": "private List<TutuServer> getServer(){\n\t// 1. Construct parameters\nMap<String, String> params = new HashMap<>();\nparams.put(\"serviceName\", discoveryProperties.getServiceName());\n\n// 2. Send a request to the discovery service\nString response = HttpUtil.get(discoveryProperties.getServerAddress() + \"/list\", params);\n\n// 3. Parse the JSON array into a list of TutuServer objects\nList<TutuServer> tutuServers = JSON.parseArray(response, TutuServer.class);\n\n// 4. Return the list of TutuServer objects\nreturn tutuServers;\n}", "CodeBleu_score": 37.19214016615913}, {"code": "private List<TutuServer> getServer(){\n\tString url = discoveryProperties.getUrl();\nMap<String, String> params = new HashMap<>();\nparams.put(\"serviceName\", discoveryProperties.getServiceName());\nString json = HttpUtil.get(url, params);\nList<Map<String, Object>> list = JSON.parseArray(json, Map.class);\nreturn list.stream().map(item -> {\nString ip = (String) item.get(\"ip\");\nInteger port = (Integer) item.get(\"port\");\nreturn new TutuServer(ip, port);\n}).collect(Collectors.toList());\n}", "CodeBleu_score": 49.074272190030314}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (ZuulRoute zuulRoute : zuulProperties.getRoutes()) {\n\t\tif (pathMatcher.match(zuulRoute.getPattern(), path)) {\n\t\t\treturn new Route(zuulRoute.getPattern(), zuulRoute.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 25.000254343557238}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null || path.isEmpty()) {\n\t\treturn null;\n\t}\n\n\tfor (ZuulRoute zuulRoute : zuulProperties.getRoutes()) {\n\t\tif (pathMatcher.match(zuulRoute.getPath(), path)) {\n\t\t\tString targetPath = path.substring(zuulRoute.getPath().length());\n\t\t\treturn new Route(zuulRoute.getServiceId(), targetPath);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 37.89919538433002}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (ZuulRoute zuulRoute : zuulProperties.getRoutes()) {\n\t\tif (pathMatcher.match(zuulRoute.getPattern(), path)) {\n\t\t\tString targetPath = path.replaceFirst(zuulRoute.getPattern(), zuulRoute.getTarget());\n\t\t\treturn new Route(zuulRoute.getServiceId(), targetPath);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.096538155146696}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tSet<String> basePackages = ClassUtils.getAllSuperclasses(importingClassMetadata.getClassName());\nfor (String basePackage : basePackages) {\nif (basePackage.startsWith(\"com.github.cloud.openfeign\")) {\n// \u626b\u63cf\u5305\u4e0b\u6240\u6709\u7c7b\nSet<Class<?>> classes = ClassUtil.scanPackageByAnnotation(basePackage, FeignClient.class);\nfor (Class<?> clazz : classes) {\n// \u6ce8\u518cFeign\u5ba2\u6237\u7aef\nregisterFeignClient(registry, clazz);\n}\n}\n}\n}", "CodeBleu_score": 31.128329358840755}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\tSet<String> classNames = ClassUtil.scanPackageByAnnotation(FeignClient.class, importingClassMetadata.getClassName());\nfor (String className : classNames) {\nGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\nbeanDefinition.setBeanClass(FeignClientFactoryBean.class);\nbeanDefinition.setLazyInit(false);\nbeanDefinition.setScope(BeanDefinition.SCOPE_SINGLETON);\nbeanDefinition.setAutowireCandidate(true);\nbeanDefinition.setInitMethodName(\"setProperties\");\nbeanDefinition.setDestroyMethodName(\"destroy\");\nbeanDefinition.setSynthetic(true);\nbeanDefinition.getPropertyValues().add(\"contextId\", ClassUtil.getShortName(className));\nbeanDefinition.getPropertyValues().add(\"type\", ClassUtil.forName(className));\nregistry.registerBeanDefinition(ClassUtil.getShortName(className), beanDefinition);\n}\n}", "CodeBleu_score": 37.63449521352117}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}]}
