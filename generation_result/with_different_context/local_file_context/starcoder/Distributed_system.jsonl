{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time: float = self.loop_wait - 2\n    if wait_time < 2:\n        wait_time = 2\n    return wait_time, self._orig_kazoo_connect(*args)\n", "CodeBleu_score": 49.44521978379047}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self._loop_wait - 2) * 1000\n    return wait_time, self._orig_kazoo_connect(*args)\n", "CodeBleu_score": 49.64611726741393}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return self._orig_kazoo_connect(*args), wait_time\n", "CodeBleu_score": 50.194747430191015}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_ttl(config.get('ttl'))\n    self.set_retry_timeout(config.get('retry_timeout'))\n    self.set_loop_wait(config.get('loop_wait'))\n    self.set_socket_timeout(config.get('socket_timeout'))\n    self.set_maximum_lag(config.get('maximum_lag_on_failover'))\n    self.set_synchronous_mode(config.get('synchronous_mode'))\n    self.set_synchronous_mode_strict(config.get('synchronous_mode_strict'))\n    self.set_tags(config.get('tags', {}))\n    if self.loop_wait != config.get('loop_wait'):\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self.loop_wait)\n        self._client.stop()\n        self._client.start()\n    self.set_use_slots(config.get('use_slots', False))\n    self.set_use_cache(config.get('use_cache', True))\n    self.set_ttl(config.get('ttl'))\n    self.set_retry_timeout(config.get('retry_timeout'))\n    self.set_loop_wait(config.get('loop_wait'))\n    self.set_socket_timeout(config.get('socket_timeout'))\n    self.set_maximum_lag(config.get('maximum_lag_on_failover'))\n    self.set_synchronous_mode(config.get('synchronous_mode'))\n    self.set_synchronous_mode_strict(config.get('synchronous_mode_strict'))\n    self.set_tags(config.get('tags', {}))\n    if self.loop_wait != config.get('loop_wait'):\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.set_connect_timeout(self.loop_wait)\n        self._client.stop()\n        self._client.start()\n\n", "CodeBleu_score": 35.885178073171694}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not isinstance(config, dict):\n        config = config.config\n    self.set_ttl(config['ttl'])\n    self.set_loop_wait(config['loop_wait'])\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_maximum_lag(config['maximum_lag_on_failover'])\n    self._client.handler.set_connect_timeout(config['retry_timeout'])\n    if self.loop_wait != config['loop_wait'] and isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n        self._client.stop()\n        self._client.handler.set_connect_timeout(config['retry_timeout'])\n        self._client.start()\n    try:\n        self.set_ttl(config['ttl'])\n    except Exception:\n        self.set_ttl(config['loop_wait'] * 3)\n        logger.error('reload_config: %s', traceback.format_exc())\n\n", "CodeBleu_score": 41.36000039143993}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.config\n    if not isinstance(config, dict):\n        raise PatroniException('Invalid config type, must be a dictionary')\n\n    self.set_ttl(config.get('ttl'))\n    self.set_retry_timeout(config.get('retry_timeout'))\n    loop_wait = config.get('loop_wait')\n    if loop_wait and loop_wait != self.loop_wait:\n        self.set_loop_wait(loop_wait)\n\n    if self.loop_wait and isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n        self._client.handler.set_connect_timeout(self.loop_wait)\n\n    self.set_watch(config.get('watch', {}))\n    self.set_tags(config.get('tags', {}))\n\n", "CodeBleu_score": 42.18554798896671}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self)\n    cluster.initialize(path)\n    cluster.load_leader()\n    cluster.load_sync_state()\n    cluster.load_members()\n    cluster.load_config()\n    cluster.load_history()\n    cluster.load_status()\n    cluster.load_failover()\n    cluster.load_failsafe()\n    cluster.set_role_from_tags()\n    return cluster\n", "CodeBleu_score": 1.617489847141854}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    data = self.get_node(path)\n    if not data:\n        raise ClusterError(f'Could not get cluster from {path}')\n    data, _ = data\n    data = json.loads(data.decode('utf-8'))\n    cluster = Cluster(data['initialize'], data['config'], data['leader'], data['members'], data['failover'],\n                      data['sync'], data['history'], data['status'], data['paused'], data['version'])\n    cluster.set_synchronous_mode(data['synchronous_mode'])\n    cluster.set_synchronous_node_count(data['synchronous_node_count'])\n    cluster.set_synchronous_standby_names(data['synchronous_standby_names'])\n    cluster.set_synchronous_commit_enabled(data['synchronous_commit_enabled'])\n    cluster.set_synchronous_standby_names(data['synchronous_standby_names'])\n    cluster.set_synchronous_commit_enabled(data['synchronous_commit_enabled'])\n    cluster.set_synchronous_standby_names(data['synchronous_standby_names'])\n    cluster.set_synchronous_commit_enabled(data['synchronous_commit_enabled'])\n    return cluster\n", "CodeBleu_score": 13.239301541561089}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self)\n    cluster.initialize(self.get_node(path + self._INITIALIZE))\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.history = self.get_node(path + self._HISTORY)\n    cluster.sync = self.get_node(path + self._SYNC)\n    cluster.members = self.load_members(path + self._MEMBERS)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.fail_over = self.get_node(path + self._FAIL_OVER)\n    cluster.pause = self.get_node(path + self._PAUSE)\n    cluster.config_history = self.get_children(path + self._CONFIG_HISTORY)\n    cluster.failover_history = self.get_children(path + self._FAILOVER_HISTORY)\n    cluster.sync_history = self.get_children(path + self._SYNC_HISTORY)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.set_history_value = self.set_history_value\n    cluster.set_history_values = self.set_history_values\n    cluster.set_sync_state_value = self.set_sync_state_value\n    cluster.set_sync_state_values = self.set_sync_state_values\n    cluster.touch_member = self.touch_member\n    cluster.touch_members = self.touch_members\n    cluster.write_leader_optime = self.write_leader_optime\n    cluster.set_failover_value = self.set_failover_value\n    cluster.set_config_value = self.set_config_value\n    cluster.set_config_values = self.set_config_values\n    cluster.delete_leader = self.delete_leader\n    cluster.delete_cluster = self.delete_cluster\n    cluster.delete_history = self.delete_history\n    cluster.delete_sync_state = self.delete_sync_state\n    cluster.delete_sync_state_entries = self.delete_sync_state_entries\n    cluster.delete_config = self.delete_config\n    cluster.delete_failover = self", "CodeBleu_score": 23.161809647420018}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self._client.client_state == KazooState.LOST:\n        raise ZooKeeperError('ZooKeeper in not responding properly')\n    try:\n        self._client.retry(self._client.create, self._leader_path, self._name, ephemeral=True, makepath=True)\n        return True\n    except NodeExistsError:\n        logger.info('Could not take out TTL lock')\n        return False\n    except Exception:\n        logger.exception('Could not take out TTL lock')\n        raise ZooKeeperError('ZooKeeper in not responding properly')\n\n", "CodeBleu_score": 51.379078126969716}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._client.retry(self._client.create, self._leader_path, self._name.encode('utf-8'), ephemeral=True, makepath=True)\n        return True\n    except NodeExistsError:\n        logger.info('Could not take out TTL lock')\n        return False\n    except Exception:\n        logger.exception('Could not take out TTL lock')\n        raise ZooKeeperError('ZooKeeper in not responding properly')\n\n", "CodeBleu_score": 47.62281169727123}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._client.retry(self._client.create, self._leader_path, self._name.encode('utf-8'), ephemeral=True)\n        return True\n    except NodeExistsError:\n        logger.info('Could not take out TTL lock')\n        return False\n    except Exception:\n        logger.exception('Could not take out TTL lock')\n        raise ZooKeeperError('ZooKeeper in not responding properly')\n\n", "CodeBleu_score": 45.65378345282955}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session != self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n\n    if leader is None:\n        try:\n            self._client.create_async(self.leader_path, self._name.encode('utf-8'), makepath=True, ephemeral=True).get(timeout=1)\n            return True\n        except Exception as e:\n            if not isinstance(e, NodeExistsError):\n                logger.error('Failed to create %s: %r', self.leader_path, e)\n            return False\n\n    try:\n        self._client.set_async(self.leader_path, self._name.encode('utf-8')).get(timeout=1)\n        return True\n    except Exception:\n        logger.exception('Failed to update %s', self.leader_path)\n        return False\n\n", "CodeBleu_score": 61.077501922585164}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client.client_id is not None and leader.session != self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = None\n\n    encoded_leader = leader and leader.encode()\n    try:\n        if leader:\n            self._client.set_async(self.leader_path, encoded_leader).get(timeout=1)\n        else:\n            self._client.create_async(self.leader_path, encoded_leader, makepath=True, ephemeral=True).get(timeout=1)\n        return True\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.exception('update_leader')\n            return False\n    return True\n", "CodeBleu_score": 50.12392854968125}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session and self._client.client_id is not None and leader.session != self._client.client_id[0]:\n        logger.warning('Recreating the leader ZNode due to ownership mismatch')\n        try:\n            self._client.delete_async(self.leader_path).get(timeout=1)\n        except NoNodeError:\n            pass\n        except Exception:\n            return False\n        leader = Leader(-1, None, None)\n\n    try:\n        self._client.retry(self._client.create, self.leader_path, self._name.encode('utf-8'),\n                           makepath=True, ephemeral=True)\n        return True\n    except (ConnectionClosedError, RetryFailedError) as e:\n        raise ZooKeeperError(e)\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error('Failed to create %s: %r', self.leader_path, e)\n    logger.info('Could not take out TTL lock')\n    return False\n", "CodeBleu_score": 65.83022389286188}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self._next_poll is None or time.time() > self._next_poll:\n        self._next_poll = time.time() + self._poll_interval\n        try:\n            for exhibitor in self._exhibitors:\n                response = requests_get(exhibitor, self._exhibitor_port, self._uri_path, timeout=self.TIMEOUT)\n                if response.status_code == 200:\n                    data = response.json()\n                    if 'servers' in data and 'port' in data:\n                        servers = data['servers']\n                        port = data['port']\n                        if servers != self._boot_exhibitors or port != self._exhibitor_port:\n                            logger.info('exhibitor changed from %s:%s to %s:%s',\n                                        self._boot_exhibitors, self._exhibitor_port, servers, port)\n                            self._boot_exhibitors = servers\n                            self._exhibitor_port = port\n                            self._zookeeper_hosts = ','.join([f'{server}:{port}' for server in servers])\n                            return True\n        except Exception:\n            logger.exception('exhibitor poll failed')\n    return False\n\n", "CodeBleu_score": 34.197006725954196}, {"code": "def poll(self) -> bool\n\t\n    if self._next_poll is not None and self._next_poll > time.time():\n        return False\n    try:\n        response = requests_get(self._exhibitors, self._exhibitor_port, self._uri_path, timeout=self.TIMEOUT)\n        if response.status_code != 200:\n            logger.error('exhibitor returned %s', response.status_code)\n            return False\n        data = response.json()\n        if not isinstance(data, list):\n            logger.error('exhibitor returned invalid data: %s', data)\n            return False\n        servers = []\n        for server in data:\n            if not isinstance(server, dict) or 'hostname' not in server or 'port' not in server:\n                logger.error('exhibitor returned invalid data: %s', data)\n                return False\n            servers.append(f'{server[\"hostname\"]}:{server[\"port\"]}')\n        servers = ','.join(servers)\n        if servers != self._zookeeper_hosts:\n            logger.info('exhibitor changed from %s to %s', self._zookeeper_hosts, servers)\n            self._zookeeper_hosts = servers\n            return True\n    except Exception as e:\n        logger.error('exception while polling exhibitor: %s', e)\n        return False\n    self._next_poll = time.time() + self._poll_interval\n    return False\n\n", "CodeBleu_score": 41.868856349404616}, {"code": "def poll(self) -> bool\n\t\n    if self._next_poll is None or time.time() >= self._next_poll:\n        self._next_poll = time.time() + self._poll_interval\n        for exhibitor in self._exhibitors:\n            try:\n                resp = requests_get(exhibitor, self._exhibitor_port, self._uri_path, timeout=self.TIMEOUT)\n                if resp.status_code == 200:\n                    exhibitors = resp.json()\n                    if not exhibitors:\n                        continue\n                    zk_hosts = []\n                    for exhibitor in exhibitors:\n                        zk_hosts.append(exhibitor['hostname'] + ':' + str(exhibitor['port']))\n                    zk_hosts = ','.join(zk_hosts)\n                    if zk_hosts != self._zookeeper_hosts:\n                        logger.info('zookeeper hosts changed from %s to %s', self._zookeeper_hosts, zk_hosts)\n                        self._zookeeper_hosts = zk_hosts\n                        return True\n            except Exception:\n                logger.exception('failed to poll exhibitor')\n    return False\n\n", "CodeBleu_score": 37.98266635699409}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider:\n        self._ensemble_provider.poll()\n        if self._ensemble_provider.zookeeper_hosts != self.hosts:\n            self.hosts = self._ensemble_provider.zookeeper_hosts\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 73.47663304349167}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider and self._ensemble_provider.poll():\n        self._hosts = self._ensemble_provider.zookeeper_hosts\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 78.4499306198522}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider:\n        self._ensemble_provider.poll()\n        hosts = self._ensemble_provider.zookeeper_hosts\n        if hosts != self._hosts:\n            logger.info('Updating ZooKeeper hosts to %s', hosts)\n            self._hosts = hosts\n\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 70.20362124584979}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n\n}", "CodeBleu_score": 78.49526490509582}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n\nnodeCache.getListenable().addListener(nodeCacheListener);\n}", "CodeBleu_score": 61.396956143557176}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\tthis.nodeCache = nodeCache;\nthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.49526490509582}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener != null) {\n\t\tString group = getGroup();\n\t\tString dataId = getDataId();\n\n\t\tlogUnsubscribeStarted();\n\n\t\ttry {\n\t\t\tzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n\t\t} catch (Exception e) {\n\t\t\tlogUnsubscribeFailed(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 83.71625242541131}, {"code": "public void destroy(){\n\tif (zookeeperListener != null) {\ntry {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\nzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 79.10434601502514}, {"code": "public void destroy(){\n\tif (zookeeperListener != null) {\ntry {\nString group = getGroup();\nString dataId = getDataId();\n\nlogUnsubscribeStarted();\n\nzookeeperOperation.unsubscribeConfig(group, dataId, zookeeperListener);\n} catch (Exception e) {\nlogUnsubscribeFailed(e);\n}\n}\n}", "CodeBleu_score": 79.10434601502514}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\nreturn zookeeperServer.getInstance().getPayload();\n}\n\nreturn null;\n}", "CodeBleu_score": 61.864973048155}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\n\t\treturn zookeeperServer.getMetadata();\n\t}\n\n\treturn null;\n}", "CodeBleu_score": 59.25916165524006}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\tif (server instanceof ZookeeperServer) {\nZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\nreturn zookeeperServer.getMetadata();\n}\n\nreturn null;\n}", "CodeBleu_score": 59.01527596061338}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\n\tboolean hasPath = hasPath(path);\n\tif (!hasPath) {\n\t\treturn null;\n\t}\n\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tChildData childData = nodeCache.getCurrentData();\n\t\t\tif (childData != null) {\n\t\t\t\tString config = convertConfig(childData.getPath());\n\t\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t\t}\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\n\tZookeeperListener zookeeperListener = new ZookeeperListener();\n\tzookeeperListener.setNodeCache(nodeCache);\n\tzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\n\treturn zookeeperListener;\n}", "CodeBleu_score": 67.07976814503526}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\n\tboolean hasPath = hasPath(path);\n\tif (!hasPath) {\n\t\treturn null;\n\t}\n\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged(CuratorFramework client, ChildData data) throws Exception {\n\t\t\tif (data == null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tString config = convertConfig(data.getPath());\n\t\t\tif (config == null) {\n\t\t\t\treturn;\n\t\t\t}\n\n\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tzookeeperListenerMap.put(group + \"-\" + serviceId, zookeeperListener);\n\n\treturn zookeeperListener;\n}", "CodeBleu_score": 64.7225320091871}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\n\tboolean hasPath = hasPath(path);\n\tif (!hasPath) {\n\t\treturn null;\n\t}\n\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged(CuratorFramework client, ChildData data) throws Exception {\n\t\t\tString config = convertConfig(data);\n\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t}\n\t};\n\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\n\tZookeeperListener zookeeperListener = new ZookeeperListener();\n\tzookeeperListener.setNodeCache(nodeCache);\n\tzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\n\treturn zookeeperListener;\n}", "CodeBleu_score": 67.47570240971056}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.initWithNiwsConfig(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\n\nreturn serverList;\n}", "CodeBleu_score": 86.84155991881704}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.initWithNiwsConfig(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\n\nreturn serverList;\n}", "CodeBleu_score": 86.84155991881704}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\tZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\nserverList.init(config);\nserverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\nserverList.setServiceId(config.getClientName());\n\nreturn serverList;\n}", "CodeBleu_score": 78.96272210878446}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t//        LOG.debug(\"Registering instance with Zookeeper: \" + registration);\n\nRegisterListenerExecutor registerListenerExecutor = null;\ntry {\nregisterListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n} catch (BeansException e) {\n//            LOG.warn(\"No RegisterListenerExecutor found in the application context, skipping the execution of its onRegister method\");\n}\n\nif (registerListenerExecutor != null) {\nregisterListenerExecutor.onRegister(registration);\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 71.55912377250691}, {"code": "public void register(ZookeeperRegistration registration){\n\t//        LOG.info(\"Registering instance with Zookeeper Server\");\n\nRegisterListenerExecutor registerListenerExecutor = null;\ntry {\nregisterListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n} catch (BeansException e) {\n//            LOG.warn(\"No RegisterListenerExecutor found in the Spring application context\");\n}\n\nif (registerListenerExecutor != null) {\nregisterListenerExecutor.onRegister(registration);\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 71.55912377250691}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t    RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t    registerListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t    // LOG.warn(\"Failed to execute the onRegister method of the RegisterListenerExecutor\", e);\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 88.56354067854555}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\ttry {\n    if (globalConfig) {\n        log.info(\"Subscribe to global config...\");\n    } else {\n        log.info(\"Subscribe to partial config...\");\n    }\n\n    String group = getConfigGroup(globalConfig);\n    String dataId = getConfigDataId(globalConfig);\n\n    log.info(\"Subscribe group={}, dataId={}\", group, dataId);\n\n    ZookeeperSubscribeCallback callback = new ZookeeperSubscribeCallback() {\n        @Override\n        public void handleDataChange(String config) throws Exception {\n            log.info(\"Receive config change event, config={}\", config);\n            notifyChanged(config);\n        }\n\n        @Override\n        public void handleDataDeleted() throws Exception {\n            log.info(\"Receive config deleted event\");\n            notifyDeleted();\n        }\n    };\n\n    return zookeeperOperation.subscribeConfig(group, dataId, callback);\n} catch (Exception e) {\n    log.error(\"Subscribe config failed\", e);\n    return null;\n}\n}", "CodeBleu_score": 45.29712262481063}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\ttry {\n    String group = globalConfig ? getConfigGroup() : getGroup();\n    String dataId = globalConfig ? getConfigDataId() : getDataId();\n\n    logger.info(\"Subscribe config, group={}, dataId={}, globalConfig={}\", group, dataId, globalConfig);\n\n    ZookeeperSubscribeCallback callback = new ZookeeperSubscribeCallback() {\n        @Override\n        public void handleDataChange(String config) throws Exception {\n            notifyConfigChanged(config, ConfigType.ZOOKEEPER);\n        }\n\n        @Override\n        public void handleDataDeleted() throws Exception {\n            notifyConfigDeleted(ConfigType.ZOOKEEPER);\n        }\n    };\n\n    zookeeperOperation.subscribeConfig(group, dataId, callback, globalConfig);\n\n    return callback;\n} catch (Exception e) {\n    logger.error(\"Subscribe config failed\", e);\n\n    return null;\n}\n}", "CodeBleu_score": 45.17128970247053}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\tif (globalConfig) {\nlogger.info(\"Subscribe to global config\");\n} else {\nlogger.info(\"Subscribe to partial config\");\n}\n\nString group = getConfigGroup(globalConfig);\nString dataId = getConfigDataId(globalConfig);\n\ntry {\nZookeeperSubscribeCallback callback = new ZookeeperSubscribeCallback() {\n@Override\npublic void handleDataChange(String config) throws Exception {\nlogger.info(\"Handle config change, config=\" + config);\npublishConfig(config);\n}\n\n@Override\npublic void handleDataDeleted() throws Exception {\nlogger.info(\"Handle config deleted\");\npublishConfig(null);\n}\n};\n\nreturn zookeeperOperation.subscribeConfig(group, dataId, callback);\n} catch (Exception e) {\nlogger.error(\"Subscribe config failed\", e);\nreturn null;\n}\n}", "CodeBleu_score": 44.26044742612621}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t", "CodeBleu_score": 0.9803101440509456}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING, String.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_CONNECT_STRING);\nif (StringUtils.isEmpty(connectString)) {\nthrow new DiscoveryException(DiscoveryException.Type.ZOOKEEPER, \"Zookeeper connect string is empty\");\n}\n\nint sessionTimeout = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SESSION_TIMEOUT, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_SESSION_TIMEOUT);\nint connectionTimeout = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECTION_TIMEOUT, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_CONNECTION_TIMEOUT);\nint retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_RETRY_COUNT);\nint sleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_TIME, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_SLEEP_TIME);\n\nCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(new ExponentialBackoffRetry(sleepTime, retryCount));\nbuilder.sessionTimeoutMs(sessionTimeout).connectionTimeoutMs(connectionTimeout);\nCuratorFramework curatorFramework = builder.build();\ncuratorFramework.start();\n\nreturn curatorFramework;\n}", "CodeBleu_score": 60.507904355521745}, {"code": "public CuratorFramework curatorFramework(){\n\tString connectString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING);\nif (StringUtils.isEmpty(connectString)) {\nthrow new DiscoveryException(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING + \" can't be null or empty\");\n}\n\nint baseSleepTime = Integer.parseInt(environment.getProperty(ZookeeperConstant.ZOOKEEPER_BASE_SLEEP_TIME, ZookeeperConstant.ZOOKEEPER_BASE_SLEEP_TIME_DEFAULT));\nint maxRetries = Integer.parseInt(environment.getProperty(ZookeeperConstant.ZOOKEEPER_MAX_RETRIES, ZookeeperConstant.ZOOKEEPER_MAX_RETRIES_DEFAULT));\nCuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(new ExponentialBackoffRetry(baseSleepTime, maxRetries)).build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 76.65655080265056}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\nreturn new GatewayStrategyRouteZookeeperProcessor();\n}\n}", "CodeBleu_score": 72.07180280101966}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\nreturn new GatewayStrategyRouteZookeeperProcessor();\n}\n}", "CodeBleu_score": 72.07180280101966}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t@Bean\n@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\npublic ZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\nreturn new GatewayStrategyRouteZookeeperProcessor();\n}\n}", "CodeBleu_score": 72.07180280101966}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t\n//        RetryPolicy retryPolicy = new ExponentialBackoffRetry(zooKeeperClientProperties.getBaseSleepTimeMs(),\n//                zooKeeperClientProperties.getMaxRetries());\n//        curatorFramework = CuratorFrameworkFactory.builder().connectString(zooKeeperClientProperties.getConnectString())\n//                .namespace(zooKeeperClientProperties.getNamespace()).retryPolicy(retryPolicy).build();\n//        curatorFramework.start();\n//        return curatorFramework;\n}", "CodeBleu_score": 1.8554470505646803}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\nCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\nbuilder.connectString(zooKeeperClientProperties.getHosts());\nbuilder.sessionTimeoutMs(zooKeeperClientProperties.getSessionTimeout());\nif (StringUtils.isNotEmpty(zooKeeperClientProperties.getNamespace())) {\nbuilder.namespace(zooKeeperClientProperties.getNamespace());\n}\n\nRetryPolicy retryPolicy = new ExponentialBackoffRetry(\nzooKeeperClientProperties.getBaseSleepTimeMs(),\nzooKeeperClientProperties.getMaxRetries(),\nzooKeeperClientProperties.getMaxSleepMs());\n\nbuilder.retryPolicy(retryPolicy);\n\ncuratorFramework = builder.build();\ncuratorFramework.start();\nreturn curatorFramework;\n}", "CodeBleu_score": 47.46701688446293}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t//        RetryPolicy retryPolicy = new ExponentialBackoffRetry(zooKeeperClientProperties.getBaseSleepTimeMs(),\n//                zooKeeperClientProperties.getMaxRetries(), zooKeeperClientProperties.getMaxSleepMs());\n//        CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n//                .connectString(zooKeeperClientProperties.getConnectString())\n//                .sessionTimeoutMs(zooKeeperClientProperties.getSessionTimeoutMs())\n//                .namespace(zooKeeperClientProperties.getNamespace())\n//                .retryPolicy(retryPolicy)\n//                .build();\n//        curatorFramework.start();\n//        return curatorFramework;\n//    }", "CodeBleu_score": 1.6531227316461272}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = null;\nif (locksMap.containsKey(Thread.currentThread())) {\nlock = locksMap.get(Thread.currentThread());\n} else {\nlock = new InterProcessMutex(curatorFrameworkClient.getClient(), path);\ntry {\nif (lock.acquire(curatorFrameworkClient.getSessionTimeout(), TimeUnit.MILLISECONDS)) {\nlocksMap.put(Thread.currentThread(), lock);\n} else {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path);\n}\n} catch (Exception e) {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path, e);\n}\n}\n}", "CodeBleu_score": 42.271230712653896}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = null;\ntry {\nlock = new InterProcessMutex(curatorFrameworkClient.getClient(), path);\nlock.acquire();\nlocksMap.put(Thread.currentThread(), lock);\n} catch (Exception e) {\nthrow new DistributedLockException(e.getMessage(), e);\n}\n}", "CodeBleu_score": 25.075478119713967}, {"code": "public void lock(String path) throws DistributedLockException{\n\tInterProcessMutex lock = null;\ntry {\nif (locksMap.containsKey(Thread.currentThread())) {\nlock = locksMap.get(Thread.currentThread());\nif (lock.isAcquiredInThisProcess()) {\nlock.acquire();\nreturn;\n}\n}\nlock = new InterProcessMutex(curatorFrameworkClient.getClient(), path);\nif (lock.acquire(curatorFrameworkClient.getSessionTimeout(), TimeUnit.MILLISECONDS)) {\nlocksMap.put(Thread.currentThread(), lock);\n} else {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path);\n}\n} catch (Exception e) {\nthrow new DistributedLockException(\"Failed to acquire lock for path: \" + path, e);\n}\n}", "CodeBleu_score": 43.22382293313605}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tgetCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tif (JSON.equals(zookeeper.getConfigType())) {\n\t\tString configKey = zookeeper.getConfigKey();\n\t\tString configValue = new String(getCuratorFramework(dtpProperties).getData().forPath(ZKPaths.makePath(nodePath, configKey)), StandardCharsets.UTF_8);\n\t\treturn ConfigHandler.getConfig(JSON, configValue);\n\t} else {\n\t\treturn genPropertiesTypeMap(dtpProperties);\n\t}\n}", "CodeBleu_score": 43.17174285186572}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tcuratorFramework = CuratorFrameworkFactory.newClient(zookeeper.getZkConnectStr(), new ExponentialBackoffRetry(1000, 3));\n\tfinal ConnectionStateListener connectionStateListener = (client, newState) -> {\n\t\tif (newState == ConnectionState.CONNECTED) {\n\t\t\tCOUNT_DOWN_LATCH.countDown();\n\t\t}\n\t};\n\tcuratorFramework.getConnectionStateListenable().addListener(connectionStateListener);\n\tcuratorFramework.start();\n\ttry {\n\t\tCOUNT_DOWN_LATCH.await();\n\t} catch (InterruptedException e) {\n\t\tlog.error(\"get zk client error\", e);\n\t\tThread.currentThread().interrupt();\n\t}\n\tString nodePath = nodePath(dtpProperties);\n\tif (JSON == zookeeper.getConfigFileType()) {\n\t\tString configKey = zookeeper.getConfigKey();\n\t\tif (StringUtils.isEmpty(configKey)) {\n\t\t\tthrow new IllegalArgumentException(\"configKey must not be null\");\n\t\t}\n\t\tbyte[] data = curatorFramework.getData().forPath(ZKPaths.makePath(nodePath, configKey));\n\t\tif (data == null) {\n\t\t\treturn Collections.emptyMap();\n\t\t}\n\t\treturn ConfigHandler.getConfigMap(new String(data, StandardCharsets.UTF_8), JSON);\n\t} else {\n\t\treturn genPropertiesTypeMap(nodePath, zookeeper.getConfigFileType());\n\t}\n}", "CodeBleu_score": 41.190481887488914}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\nString nodePath = nodePath(dtpProperties);\nif (JSON.equals(zookeeper.getConfigType())) {\n    String configKey = zookeeper.getConfigKey();\n    byte[] data = getCuratorFramework(dtpProperties).getData().forPath(ZKPaths.makePath(nodePath, configKey));\n    return ConfigHandler.getConfigMap(new String(data, StandardCharsets.UTF_8), JSON);\n}\nreturn genPropertiesTypeMap(dtpProperties);\n}", "CodeBleu_score": 39.201833276600006}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\n//        if (BinderHelper.shouldBind(environment, DtpProperties.class)) {\n//            DtpProperties dtpProperties = BinderHelper.bind(environment, DtpProperties.class);\n//            if (dtpProperties.getZkServers() != null && dtpProperties.getZkServers().length > 0) {\n//                Map<String, Object> properties = BinderHelper.getBindProperties(dtpProperties);\n//                if (environment.getProperty(dtpProperties.getZkPath()) == null) {\n//                    CuratorUtil.createPropertySource(ZK_PROPERTY_SOURCE_NAME, properties);\n//                    MutablePropertySources propertySources = environment.getPropertySources();\n//                    if (propertySources.contains(ZK_PROPERTY_SOURCE_NAME)) {\n//                        propertySources.addLast(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));\n//                    } else {\n//                        propertySources.addFirst(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));\n//                    }\n//                }\n//            }\n//        }\n//    }", "CodeBleu_score": 5.918508044413007}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\n\tDtpProperties dtpProperties = DtpProperties.getDtpProperties();\n\tBinderHelper.bind(environment, dtpProperties);\n\tMap<String, Object> properties = dtpProperties.toProperties();\n\tMutablePropertySources propertySources = environment.getPropertySources();\n\tOriginTrackedMapPropertySource propertySource = new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties);\n\tif (!propertySources.contains(ZK_PROPERTY_SOURCE_NAME)) {\n\t    propertySources.addLast(propertySource);\n\t}\n\tCuratorUtil.initCurator(dtpProperties.getZk().getAddress());\n\tif (!CuratorUtil.checkExists(dtpProperties.getZk().getRoot())) {\n\t    CuratorUtil.createPersistent(dtpProperties.getZk().getRoot());\n\t}\n}", "CodeBleu_score": 45.89012237426121}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t  //1\n    DtpProperties dtpProperties = BinderHelper.getDtpProperties(environment);  //2\n    Map<String, Object> properties = BinderHelper.convertProperties(dtpProperties);  //3\n    if (properties.isEmpty()) {  //4\n        return;\n    }\n    MutablePropertySources propertySources = environment.getPropertySources();  //5\n    if (propertySources.contains(ZK_PROPERTY_SOURCE_NAME)) {  //6\n        return;\n    }\n    if (CuratorUtil.checkExists(dtpProperties.getZk().getServer())) {  //7\n        propertySources.addLast(new OriginTrackedMapPropertySource(ZK_PROPERTY_SOURCE_NAME, properties));  //8\n    } else {\n        log.warn(\\\"zookeeper server: {} is not exist, please check it\\\", dtpProperties.getZk().getServer());\n    }\n}", "CodeBleu_score": 45.84469327324708}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\treturn UseRouteManager(builder, (serviceProvider) => {\n\t\tvar serializer = serviceProvider.GetRequiredService<ISerializer<byte[]>>();\n\t\tvar loggerFactory = serviceProvider.GetRequiredService<ILoggerFactory>();\n\t\tvar routeFactory = serviceProvider.GetRequiredService<IServiceRouteFactory>();\n\t\tvar routeProvider = new ZookeeperServiceRouteProvider(configInfo, serializer, routeFactory, loggerFactory);\n\t\tvar clientProvider = serviceProvider.GetRequiredService<IZookeeperClientProvider>();\n\t\treturn new ZookeeperServiceRouteManager(routeProvider, clientProvider, loggerFactory);\n\t});\n}", "CodeBleu_score": 32.859975512551586}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\treturn UseZooKeeperRouteManager(builder, configInfo, null);\n}", "CodeBleu_score": 10.970863408289329}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\treturn UseRouteManager(builder, (serviceProvider) => new ZookeeperServiceRouteManager(serviceProvider, configInfo));\n}", "CodeBleu_score": 11.603080484866721}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t UseCommandManager(builder, provider =>\n new ZooKeeperServiceCommandManager(\n GetConfigInfo(configInfo),\n provider.GetRequiredService<ISerializer<byte[]>>(),\n provider.GetRequiredService<ISerializer<string>>(),\n provider.GetRequiredService<IServiceCommandProvider>(),\n provider.GetRequiredService<ILogger<ZooKeeperServiceCommandManager>>(),\n provider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n }", "CodeBleu_score": 64.57049205308478}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t UseCommandManager(builder, provider =>\nnew ZookeeperServiceCommandManager(\nGetConfigInfo(configInfo),\nprovider.GetRequiredService<ISerializer<byte[]>>(),\nprovider.GetRequiredService<ISerializer<string>>(),\nprovider.GetRequiredService<IServiceCommandProvider>(),\nprovider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\nprovider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n}", "CodeBleu_score": 67.0428729440692}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t UseCommandManager(builder, provider => new ZookeeperServiceCommandManager(GetConfigInfo(configInfo), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<ISerializer<string>>(), provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IZookeeperClientProvider>()));\n return this;\n}", "CodeBleu_score": 60.748507838390765}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) {\nthrow new ArgumentNullException(nameof(builder));\n}\nif (string.IsNullOrEmpty(path)) {\nthrow new ArgumentException(Resources.Error_PathCannotBeNullOrEmpty, nameof(path));\n}\nif (path[0] == Path.DirectorySeparatorChar || path[0] == Path.AltDirectorySeparatorChar) {\nprovider ??= new PhysicalFileProvider(Path.GetDirectoryName(path));\npath = Path.GetFileName(path);\n}\nreturn builder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n}", "CodeBleu_score": 45.093404545696046}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\tif (builder == null) throw new ArgumentNullException(nameof(builder));\nif (string.IsNullOrEmpty(path)) throw new ArgumentException(Resources.Error_Invalid_FileProvider_Path, nameof(path));\nif (path[0] == Path.DirectorySeparatorChar || path[0] == Path.AltDirectorySeparatorChar) {\nif (provider == null) {\nprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\npath = Path.GetFileName(path);\n}\n}\nif (provider == null) throw new ArgumentException(Resources.Error_Invalid_FileProvider_No_Prefix, nameof(provider));\nreturn builder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n}", "CodeBleu_score": 48.634851768672476}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t", "CodeBleu_score": 8.063975559205591}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u79fb\u9664\u670d\u52a1\u5730\u5740\u3002\");\n\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tawait CreateSubdirectory(zooKeeper, _configInfo.RoutePath);\n\n\t\tvar path = _configInfo.RoutePath;\n\t\tif (!path.EndsWith(\"/\"))\n\t\t\tpath += \"/\";\n\n\t\tvar routes = await GetRoutesAsync();\n\t\tforeach (var route in routes) {\n\t\t\tvar newRoute = route.DeepCopy();\n\t\t\tvar newAddresses = new List<AddressModel>();\n\t\t\tforeach (var address in newRoute.Address) {\n\t\t\t\tif (!Address.Any(p => p.ToString() == address.ToString()))\n\t\t\t\t\tnewAddresses.Add(address);\n\t\t\t}\n\t\t\tnewRoute.Address = newAddresses;\n\t\t\tvar nodePath = path + newRoute.ServiceDescriptor.Id;\n\t\t\tvar nodeData = _serializer.Serialize(newRoute);\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\n\t\t\t\tawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\n\t\t\t\tvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\n\t\t\t\tif (!DataEquals(nodeData, onlineData))\n\t\t\t\t\tawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 52.78509720680614}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u79fb\u9664\u670d\u52a1\u5730\u5740\u3002\");\n\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers)\n\t{\n\t\tvar path = _configInfo.RoutePath;\n\t\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\t\tvar index = 0;\n\t\twhile (childrens.Count() > 1)\n\t\t{\n\t\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) != null)\n\t\t\t{\n\t\t\t\tvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\n\t\t\t\tif (result?.Children != null)\n\t\t\t\t{\n\t\t\t\t\tforeach (var child in result.Children)\n\t\t\t\t\t{\n\t\t\t\t\t\tvar childPath = $\"{nodePath}/{child}\";\n\t\t\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\n\t\t\t\t\t\tawait zooKeeper.Item2.deleteAsync(childPath);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(nodePath);\n\t\t\t}\n\t\t\tindex++;\n\t\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u670d\u52a1\u5730\u5740\u79fb\u9664\u6210\u529f\u3002\");\n\t}\n}", "CodeBleu_score": 30.772256322772762}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tvar routes = await GetRoutesAsync();\n\tvar newRoutes = new List<ServiceRoute>();\n\tforeach (var route in routes) {\n\t\tvar newRoute = route.RemoveAddress(Address);\n\t\tif (newRoute != null) {\n\t\t\tnewRoutes.Add(newRoute);\n\t\t}\n\t}\n\tawait SetRoutesAsync(newRoutes);\n}", "CodeBleu_score": 44.4056991548361}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\\\"\u51c6\u5907\u5220\u9664\u9664{string.Join(\\\",\\\", hostAddr.ToString())}\u4ee5\u5916\u7684\u670d\u52a1\u8def\u7531\u3002\\\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = $\\\"/{string.Join(\\\"/\\\", childrens)}\\\";\n\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children != null) {\nforeach (var child in result.Children) {\nvar childPath = $\\\"{nodePath}/{child}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\\\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\\\"\u8def\u7531\u914d\u7f6e\u5220\u9664\u5b8c\u6210\u3002\\\");\n}\n}", "CodeBleu_score": 45.20822950910216}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\"\u51c6\u5907\u5220\u9664\u670d\u52a1\u8def\u7531\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nvar serviceRoutes = await GetRoutes(routes.Select(p => p.ServiceDescriptor.Id));\nforeach (var serviceRoute in serviceRoutes) {\nvar nodePath = path + serviceRoute.ServiceDescriptor.Id;\nvar nodeData = _serializer.Serialize(serviceRoute);\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData)) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u5220\u9664\u6210\u529f\u3002\");\n}", "CodeBleu_score": 57.90135424846745}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u5220\u9664\u670d\u52a1\u8def\u7531\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.RoutePath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\nvar routes = routes.ToArray();\nforeach (var serviceRoute in routes) {\nvar nodePath = path + serviceRoute.ServiceDescriptor.Id;\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nvar serviceRouteDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(onlineData);\nvar addresses = serviceRouteDescriptor.Address.Where(p => p.ToString() != hostAddr.ToString()).ToList();\nserviceRouteDescriptor.Address = addresses;\nvar nodeData = _serializer.Serialize(serviceRouteDescriptor);\nif (addresses.Count > 0) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u5220\u9664\u6210\u529f\u3002\");\n}", "CodeBleu_score": 57.07433406089564}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u53cd\u5e8f\u5217\u5316\u6570\u636e\uff1a{data.ToStr()}\u3002\\\");\nif (data == null)\nreturn null;\nvar serviceRouteDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u53cd\u5e8f\u5217\u5316\u5b8c\u6210\uff1a{serviceRouteDescriptor.ToJsonString()}\u3002\\\");\nvar serviceRoute = _serviceRouteFactory.CreateRoute(serviceRouteDescriptor);\nreturn serviceRoute;\n}", "CodeBleu_score": 45.3330893495904}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (data == null)\nreturn null;\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"Route data: {Encoding.UTF8.GetString(data)}\\\", data);\nvar routeDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nvar route = _serviceRouteFactory.CreateRoute(routeDescriptor);\nreturn route;\n}", "CodeBleu_score": 47.22588186772933}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"GetRouteAsync: {Encoding.UTF8.GetString(data)}\\\n\\\");\nif (data == null)\nreturn null;\nvar serviceRouteDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\nvar serviceRoute = _serviceRouteFactory.CreateRoute(serviceRouteDescriptor);\nreturn serviceRoute;\n}", "CodeBleu_score": 42.45349843484428}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (DataEquals(oldData, newData)) {\n\t\treturn;\n\t}\n\n\tif (_logger.IsEnabled(LogLevel.Debug)) {\n\t\t_logger.LogDebug($\\\"\u8282\u70b9\u6570\u636e\u53d1\u751f\u53d8\u5316\uff0c\u51c6\u5907\u66f4\u65b0\u8def\u7531\u4fe1\u606f\u3002\\\");\n\t}\n\n\tvar route = await GetRoute(newData);\n\tvar oldRoute = _routes.Where(p => p.ServiceDescriptor.Id == route.ServiceDescriptor.Id).FirstOrDefault();\n\tif (oldRoute != null) {\n\t\tvar newAddresses = route.Address.Concat(oldRoute.Address.Except(route.Address)).ToList();\n\t\tforeach (var address in route.Address) {\n\t\t\tnewAddresses.Remove(newAddresses.Where(p => p.ToString() == address.ToString()).FirstOrDefault());\n\t\t\tnewAddresses.Add(address);\n\t\t}\n\t\troute.Address = newAddresses;\n\t}\n\n\tawait SetRoutesAsync(new[] { route });\n}", "CodeBleu_score": 40.67559930370073}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (DataEquals(oldData, newData))\n\t\treturn;\n\n\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d1\u751f\u53d8\u66f4\uff0c\u5c06\u66f4\u65b0\u8def\u7531\u4fe1\u606f\u3002\");\n\n\tvar route = await GetRoute(newData);\n\tif (route == null)\n\t\treturn;\n\n\tvar oldRoute = _routes.Where(p => p.ServiceDescriptor.Id == route.ServiceDescriptor.Id).FirstOrDefault();\n\tif (oldRoute == null)\n\t{\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t_logger.LogDebug($\"\u8282\u70b9{route.ServiceDescriptor.Id}\u4e0d\u5b58\u5728\uff0c\u5c06\u8fdb\u884c\u6dfb\u52a0\u3002\");\n\t\tawait AddRouteAsync(route);\n\t}\n\telse\n\t{\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{route.ServiceDescriptor.Id}\u7684\u6570\u636e\u3002\");\n\n\t\tvar onlineData = (await GetZooKeeper()).Item2.getDataAsync(route.ServiceDescriptor.Id).Result.Data;\n\t\tif (!DataEquals(route.ServiceDescriptor.Bytes, onlineData))\n\t\t\tawait GetZooKeeper().Item2.setDataAsync(route.ServiceDescriptor.Id, route.ServiceDescriptor.Bytes);\n\t}\n\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u670d\u52a1\u8def\u7531\u6dfb\u52a0\u6210\u529f\u3002\");\n}", "CodeBleu_score": 38.477260501238554}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u8def\u7531\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\\\");\n\n\tif (DataEquals(oldData, newData))\n\t\treturn;\n\n\tvar route = await GetRoute(newData);\n\tvar oldRoute = _routes.Where(p => p.ServiceDescriptor.Id == route.ServiceDescriptor.Id).FirstOrDefault();\n\tif (oldRoute != null)\n\t{\n\t\tvar addresses = oldRoute.Address.Except(route.Address).ToList();\n\t\taddresses.AddRange(route.Address.Except(oldRoute.Address));\n\t\troute.Address = addresses;\n\t}\n\n\tawait SetRoutesAsync(new[] { route });\n}", "CodeBleu_score": 41.60679784622815}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (_logger.IsEnabled(LogLevel.Information)) _logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers != null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug)) _logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug)) _logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information)) _logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.569483385467194}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers != null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u66f4\u65b0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.558428325574994}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u6dfb\u52a0\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nawait CreateSubdirectory(zooKeeper, _configInfo.SubscriberPath);\n\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\"/\"))\npath += \"/\";\n\nsubscribers = subscribers.ToArray();\n\nif (_subscribers != null) {\nvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\nvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\nforeach (var deletedSubscriberId in deletedSubscriberIds) {\nvar nodePath = $\"{path}{deletedSubscriberId}\";\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\n}\n\nforeach (var serviceSubscriber in subscribers) {\nvar nodePath = $\"{path}{serviceSubscriber.ServiceDescriptor.Id}\";\nvar nodeData = _serializer.Serialize(serviceSubscriber);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\nawait zooKeeper.Item2.createAsync(nodePath, nodeData, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u5c06\u66f4\u65b0\u8282\u70b9\uff1a{nodePath}\u7684\u6570\u636e\u3002\");\n\nvar onlineData = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nif (!DataEquals(nodeData, onlineData))\nawait zooKeeper.Item2.setDataAsync(nodePath, nodeData);\n}\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u6dfb\u52a0\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 39.558428325574994}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar result = new List<ServiceSubscriber>();\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar path = _configInfo.SubscriberPath;\n\t\tforeach (var children in childrens) {\n\t\t\tvar nodePath = $\\\"{path}/{children}\\\";\n\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u4fe1\u606f\uff1a{nodePath}\u3002\\\");\n\t\t\tvar data = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\n\t\t\tvar subscriber = await GetSubscriber(data);\n\t\t\tif (subscriber != null)\n\t\t\t\tresult.Add(subscriber);\n\t\t}\n\t}\n\treturn result.ToArray();\n}", "CodeBleu_score": 44.88057258816898}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nvar subscribers = new List<ServiceSubscriber>();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.SubscriberPath;\nforeach (var children in childrens) {\nvar nodePath = $\\\"{path}/{children}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u4fe1\u606f\uff0c\u8282\u70b9\u8def\u5f84\uff1a{nodePath}\u3002\\\");\nvar data = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nvar subscriber = await GetSubscriber(data);\nif (subscriber != null)\nsubscribers.Add(subscriber);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 49.24814380039679}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u8def\u5f84\uff1a{_configInfo.SubscriberPath}\u3002\\\");\n\nvar result = new List<ServiceSubscriber>();\nvar zooKeeper = await GetZooKeeper();\nvar path = _configInfo.SubscriberPath;\nif (!path.EndsWith(\\\"/\\\"))\npath += \\\"/\\\";\n\nforeach (var children in childrens) {\nvar nodePath = $\\\"{path}{children}\\\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\uff0c\u8282\u70b9\u8def\u5f84\uff1a{nodePath}\u3002\\\");\nvar data = (await zooKeeper.Item2.getDataAsync(nodePath)).Data;\nvar subscriber = await GetSubscriber(data);\nif (subscriber != null)\nresult.Add(subscriber);\n}\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u5171\u83b7\u53d6\u5230{result.Count}\u4e2a\u670d\u52a1\u8ba2\u9605\u8005\u3002\\\");\nreturn result.ToArray();\n}", "CodeBleu_score": 55.63012814258388}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u4eceZookeeper\u4e2d\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\n\n\tvar zooKeeper = await GetZooKeeper();\n\tif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath) != null) {\n\t\tvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\n\t\tif (childrens != null) {\n\t\t\tvar subscribers = await GetSubscribers(childrens);\n\t\t\tif (_subscribers != null) {\n\t\t\t\tvar oldSubscriberIds = _subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\t\t\tvar newSubscriberIds = subscribers.Select(i => i.ServiceDescriptor.Id).ToArray();\n\t\t\t\tvar deletedSubscriberIds = oldSubscriberIds.Except(newSubscriberIds).ToArray();\n\t\t\t\tforeach (var deletedSubscriberId in deletedSubscriberIds) {\n\t\t\t\t\tvar nodePath = $\"/{_configInfo.SubscriberPath}/{deletedSubscriberId}\";\n\t\t\t\t\tawait zooKeeper.Item2.deleteAsync(nodePath);\n\t\t\t\t}\n\t\t\t}\n\t\t\t_subscribers = subscribers;\n\t\t}\n\t}\n\telse {\n\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t_logger.LogWarning($\"\u670d\u52a1\u8ba2\u9605\u8005\u8def\u5f84\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\uff0c\u5c06\u4f7f\u7528\u7a7a\u6570\u7ec4\u521d\u59cb\u5316\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\n\t\t_subscribers = new ServiceSubscriber[0];\n\t}\n}", "CodeBleu_score": 58.91975073271437}, {"code": "private async Task EnterSubscribers(){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u83b7\u53d6\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nvar zooKeeper = await GetZooKeeper();\nif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath) == null)\n{\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"\u670d\u52a1\u8ba2\u9605\u8005\u8def\u5f84\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\uff0c\u5c06\u8fd4\u56de\u4e00\u4e2a\u7a7a\u6570\u7ec4\u3002\");\n_subscribers = new ServiceSubscriber[0];\n}\nelse\n{\nvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\nif (childrens != null)\n{\n_subscribers = await GetSubscribers(childrens);\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\"\u670d\u52a1\u8ba2\u9605\u8005\u83b7\u53d6\u6210\u529f\uff0c\u603b\u8ba1\uff1a{_subscribers.Length}\u4e2a\u3002\");\n}\nelse\n{\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"\u670d\u52a1\u8ba2\u9605\u8005\u8def\u5f84\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\uff0c\u5c06\u8fd4\u56de\u4e00\u4e2a\u7a7a\u6570\u7ec4\u3002\");\n_subscribers = new ServiceSubscriber[0];\n}\n}\n}", "CodeBleu_score": 56.50284719217061}, {"code": "private async Task EnterSubscribers(){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u521d\u59cb\u5316\u670d\u52a1\u8ba2\u9605\u8005\u3002\");\nif (_subscribers != null)\nreturn;\n\nvar zooKeeper = await GetZooKeeper();\n\nif (await zooKeeper.Item2.existsAsync(_configInfo.SubscriberPath) != null) {\nvar childrens = (await zooKeeper.Item2.getChildrenAsync(_configInfo.SubscriberPath)).Children;\nif (childrens != null) {\n_subscribers = await GetSubscribers(childrens);\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u8ba2\u9605\u8005\u521d\u59cb\u5316\u5b8c\u6210\u3002\");\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning(\"\u670d\u52a1\u8ba2\u9605\u8005\u8282\u70b9\u4e0b\u6ca1\u6709\u4efb\u4f55\u5b50\u8282\u70b9\u3002\");\n_subscribers = new ServiceSubscriber[0];\n}\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning(\"\u670d\u52a1\u8ba2\u9605\u8005\u8282\u70b9\u4e0d\u5b58\u5728\u3002\");\n_subscribers = new ServiceSubscriber[0];\n}\n}", "CodeBleu_score": 61.63302119507815}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\n\tif (newData == null)\n\t\treturn;\n\n\tvar descriptor = _serializer.Deserialize<byte[], ServiceCommandDescriptor>(newData);\n\tNodeChange(descriptor);\n}", "CodeBleu_score": 16.14413131882212}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\\\");\n\nif (newData == null) {\nreturn;\n}\n\nvar descriptor = _serializer.Deserialize<byte[], ServiceCommandDescriptor>(newData);\nNodeChange(descriptor);\n}", "CodeBleu_score": 16.086240701382987}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t//\u5f97\u5230\u65e7\u7684\u670d\u52a1\u547d\u4ee4\u3002\nvar oldCommand = _serviceCommands.FirstOrDefault(i => i.ServiceId == newCommand.ServiceId);\n\nlock (_serviceCommands) {\n//\u5220\u9664\u65e7\u670d\u52a1\u547d\u4ee4\uff0c\u5e76\u6dfb\u52a0\u4e0a\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u3002\n_serviceCommands =\n_serviceCommands\n.Where(i => i.ServiceId != newCommand.ServiceId)\n.Concat(new[] { newCommand }).ToArray();\n}\n\n//\u89e6\u53d1\u670d\u52a1\u547d\u4ee4\u53d8\u66f4\u4e8b\u4ef6\u3002\nOnChanged(new ServiceCommandChangedEventArgs(newCommand, oldCommand));\n}", "CodeBleu_score": 72.76186558601268}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\nvar (manualResetEvent, zooKeeper) = await _zooKeeperCall();\nvar data = await zooKeeper.GetDataAsync(Path, Watcher);\n_action(_currentData, data);\n_currentData = data;\nmanualResetEvent.Set();\n}\n}", "CodeBleu_score": 48.87872383051721}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar (manualResetEvent, zooKeeper) = await _zooKeeperCall();\n\n\t\tvar newData = await zooKeeper.GetDataAsync(watchedEvent.Path);\n\n\t\t_action(_currentData, newData);\n\n\t\t_currentData = newData;\n\n\t\tmanualResetEvent.Set();\n\t}\n}", "CodeBleu_score": 49.155681119456865}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\tif (watchedEvent.Type == EventType.NodeDataChanged) {\nvar (resetEvent, zooKeeper) = await _zooKeeperCall();\nvar newData = await zooKeeper.GetDataAsync(watchedEvent.Path);\n_action(_currentData, newData);\n_currentData = newData;\nresetEvent.Set();\n}\n}", "CodeBleu_score": 48.49533110987215}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\tbuilder.Services.AddSingleton(provider => new DefaultZookeeperClientProvider(GetConfigInfo(configInfo), provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<IHealthCheckService>(), provider.GetRequiredService<IZookeeperAddressSelector>(), provider.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>()));\n\treturn builder;\n}", "CodeBleu_score": 53.28296024761568}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\tbuilder.Services.AddSingleton(provider => {\n\tvar result = new DefaultZookeeperClientProvider(configInfo, provider.GetRequiredService<ISerializer<byte[]>>(), provider.GetRequiredService<IHealthCheckService>(), provider.GetRequiredService<IZookeeperAddressSelector>(), provider.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>());\n\treturn result;\n});\nreturn builder;\n}", "CodeBleu_score": 46.85537339009708}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tbuilder.Services.AddSingleton<IZookeeperClientProvider>(provider =>\nnew DefaultZookeeperClientProvider(\nGetConfigInfo(configInfo),\nprovider.GetRequiredService<IHealthCheckService>(),\nprovider.GetRequiredService<IZookeeperAddressSelector>(),\nprovider.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>()));\nreturn builder;\n}", "CodeBleu_score": 68.07476365172094}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u8bbe\u7f6emqtt\u8def\u7531\u914d\u7f6e\u3002\");\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar path = _configInfo.MqttRoutePath;\n\t\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\t\tvar index = 0;\n\t\twhile (childrens.Count() > 1) {\n\t\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\uff1a{nodePath}\u3002\");\n\t\t\t\tawait zooKeeper.Item2.createAsync(nodePath, new byte[0]);\n\t\t\t}\n\t\t\tindex++;\n\t\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u8bbe\u7f6e\u5b8c\u6210\u3002\");\n\t}\n}", "CodeBleu_score": 48.468249430534506}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u8bbe\u7f6emqtt\u8def\u7531\u914d\u7f6e\u3002\");\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar path = _configInfo.MqttRoutePath;\n\t\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\t\tvar index = 0;\n\t\twhile (childrens.Count() > 1) {\n\t\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\uff1a{nodePath}\u3002\");\n\t\t\t\tawait zooKeeper.Item2.createAsync(nodePath, new byte[0], Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t\tindex++;\n\t\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u8bbe\u7f6e\u5b8c\u6210\u3002\");\n\t}\n}", "CodeBleu_score": 49.51115870729572}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u8bbe\u7f6emqtt\u8def\u7531\u914d\u7f6e\u3002\");\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar path = _configInfo.MqttRoutePath;\n\t\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\t\tvar index = 0;\n\t\twhile (childrens.Count() > 1) {\n\t\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\uff1a{nodePath}\u3002\");\n\t\t\t\tawait zooKeeper.Item2.createAsync(nodePath, Encoding.UTF8.GetBytes(string.Empty), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t\tindex++;\n\t\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"\u8def\u7531\u914d\u7f6e\u8bbe\u7f6e\u5b8c\u6210\u3002\");\n\t}\n}", "CodeBleu_score": 50.287052712623456}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u5220\u9664Zookeeper\u4e2d\u9664\u6307\u5b9a\u670d\u52a1\u8def\u7531\u5916\u7684\u5176\u4ed6\u670d\u52a1\u8def\u7531\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children != null) {\nforeach (var child in result.Children) {\nvar childPath = string.Format(\"{0}/{1}\", nodePath, child);\nvar route = routes.Where(p => p.MqttDescriptor.Topic == child).SingleOrDefault();\nif (route != null) {\nvar address = route.MqttEndpoint.Where(p => p.ToString() == hostAddr.ToString()).SingleOrDefault();\nif (address != null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(string.Format(\"\u51c6\u5907\u5220\u9664\uff1a{0}\u3002\", childPath));\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(string.Format(\"\u51c6\u5907\u5220\u9664\uff1a{0}\u3002\", nodePath));\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"Zookeeper\u4e2d\u9664\u6307\u5b9a\u670d\u52a1\u8def\u7531\u5916\u7684\u5176\u4ed6\u670d\u52a1\u8def\u7531\u5220\u9664\u6210\u529f\u3002\");\n}\n}", "CodeBleu_score": 51.156010745350414}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u5220\u9664Zookeeper\u4e2d\u9664\u6307\u5b9a\u8def\u7531\u4e4b\u5916\u7684\u5176\u4ed6\u8def\u7531\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.MqttRoutePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children != null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"Zookeeper\u4e2d\u9664\u6307\u5b9a\u8def\u7531\u4e4b\u5916\u7684\u5176\u4ed6\u8def\u7531\u914d\u7f6e\u5220\u9664\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 49.09091882323031}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t_logger.LogInformation(\"\u51c6\u5907\u5220\u9664Zookeeper\u4e2d\u9664\u6307\u5b9a\u8def\u7531\u4ee5\u5916\u7684\u5176\u4ed6\u8def\u7531\u3002\");\n\n\tvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\n\tforeach (var zooKeeper in zooKeepers) {\n\t\tvar path = _configInfo.MqttRoutePath;\n\t\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\t\tvar index = 0;\n\t\twhile (childrens.Count() > 1) {\n\t\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\n\t\t\tif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\n\t\t\t\tvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\n\t\t\t\tif (result?.Children != null) {\n\t\t\t\t\tforeach (var child in result.Children) {\n\t\t\t\t\t\tvar childPath = $\"{nodePath}/{child}\";\n\t\t\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\");\n\t\t\t\t\t\tawait zooKeeper.Item2.deleteAsync(childPath);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\");\n\t\t\t\tawait zooKeeper.Item2.deleteAsync(nodePath);\n\t\t\t}\n\t\t\tindex++;\n\t\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t\t}\n\t\tif (_logger.IsEnabled(LogLevel.Information))\n\t\t\t_logger.LogInformation(\"Zookeeper\u4e2d\u9664\u6307\u5b9a\u8def\u7531\u4ee5\u5916\u7684\u5176\u4ed6\u8def\u7531\u5220\u9664\u5b8c\u6210\u3002\");\n\t}\n}", "CodeBleu_score": 48.45780861851389}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u8bbe\u7f6e\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children != null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u8bbe\u7f6e\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 51.82135687447163}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\tif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u3002\");\nvar zooKeepers = await _zookeeperClientProvider.GetZooKeepers();\nforeach (var zooKeeper in zooKeepers) {\nvar path = _configInfo.CachePath;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nvar result = await zooKeeper.Item2.getChildrenAsync(nodePath);\nif (result?.Children != null) {\nforeach (var child in result.Children) {\nvar childPath = $\"{nodePath}/{child}\";\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{childPath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(childPath);\n}\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5220\u9664\uff1a{nodePath}\u3002\");\nawait zooKeeper.Item2.deleteAsync(nodePath);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u670d\u52a1\u7f13\u5b58\u914d\u7f6e\u66f4\u65b0\u5b8c\u6210\u3002\");\n}\n}", "CodeBleu_score": 51.83108612343413}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tif (zooKeeper.Item2.existsAsync(path) != null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{path} \u5df2\u7ecf\u5b58\u5728\u3002\\\");\nreturn;\n}\n\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", childrens);\n\nif (await zooKeeper.Item2.existsAsync(nodePath) != null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{nodePath} \u5df2\u7ecf\u5b58\u5728\u3002\\\");\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{nodePath} \u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\\\");\n\nawait zooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nindex++;\nchildrens = childrens.Take(childrens.Length - index).ToArray();\n}\n}", "CodeBleu_score": 59.908925810287464}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\u8282\u70b9\uff1a{path}\u3002\");\n\tvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\tvar index = 0;\n\twhile (childrens.Count() > 1) {\n\t\tvar nodePath = \"/\" + string.Join(\"/\", childrens);\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t_logger.LogDebug($\"\u51c6\u5907\u521b\u5efa\u8282\u70b9\uff1a{nodePath}\u3002\");\n\t\tif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t_logger.LogDebug($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\");\n\t\t\tvar mode = index == 0 ? CreateMode.PERSISTENT : CreateMode.PERSISTENT_SEQUENTIAL;\n\t\t\tawait zooKeeper.Item2.createAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, mode);\n\t\t}\n\t\tindex++;\n\t\tchildrens = childrens.Take(childrens.Length - index).ToArray();\n\t}\n}", "CodeBleu_score": 61.06218042465083}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u51c6\u5907\u521b\u5efa\u8def\u5f84\uff1a{path}\u3002\\\");\nvar nodePath = path;\nvar childrens = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\nvar index = 0;\nwhile (childrens.Count() > 1) {\nvar child = childrens.Last();\nchildrens = childrens.Take(childrens.Length - index).ToArray();\nvar nodePath = \\\"/\\\" + string.Join(\\\"/\\\", childrens);\nif (await zooKeeper.Item2.existsAsync(nodePath) == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\u5c06\u8fdb\u884c\u521b\u5efa\u3002\\\");\nawait zooKeeper.Item2.createAsync(nodePath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n}\nindex++;\n}\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\\\"\u8def\u5f84\uff1a{path}\u521b\u5efa\u6210\u529f\u3002\\\");\n}", "CodeBleu_score": 58.247578623000976}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t", "CodeBleu_score": 7.549424158321882}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tforeach (var address in _config.Addresses) {\nif (!await _healthCheckService.IsHealth(address)) {\nthrow new RegisterConnectionException(string.Format(\"\u6ce8\u518c\u4e2d\u5fc3{0}\u8fde\u63a5\u5f02\u5e38\uff0c\u8bf7\u8054\u7cfb\u7ba1\u7406\u56ed\", address.ToString()));\n}\n}\nList<AddressModel> address = new List<AddressModel>();\nforeach (var addressModel in _config.Addresses) {\n_healthCheckService.Monitor(addressModel);\nvar task = _healthCheckService.IsHealth(addressModel);\nif (!(task.IsCompletedSuccessfully ? task.Result : await task)) {\ncontinue;\n}\naddress.Add(addressModel);\n}\nif (address.Count == 0) {\nif (_logger.IsEnabled(Level.Warning))\n_logger.LogWarning(\"\u627e\u4e0d\u5230\u53ef\u7528\u7684\u6ce8\u518c\u4e2d\u5fc3\u5730\u5740\u3002\");\nreturn default(IEnumerable<(ManualResetEvent, ZooKeeper)>);\n}\n\nvar vt = _zookeeperAddressSelector.SelectAsync(new AddressSelectContext\n{\nDescriptor = new ServiceDescriptor { Id = nameof(DefaultZookeeperClientProvider) },\nAddress = address\n});\nvar addr = vt.IsCompletedSuccessfully ? vt.Result : await vt;\nif (addr != null) {\nvar ipAddress = addr as IpAddressModel;\nresult.Add(CreateZooKeeper(ipAddress));\n}\nreturn result;\n}", "CodeBleu_score": 60.6364025190735}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t", "CodeBleu_score": 7.549424158321882}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (data) {\n\t\tif (zooKeeper == null) {\n\t\t\tif (data.connectionString == null) {\n\t\t\t\tdata.connectionString = ensembleProvider.getConnectionString();\n\t\t\t}\n\t\t\tzooKeeper = zookeeperFactory.getZooKeeper(data.connectionString, sessionTimeout, watcher, canBeReadOnly);\n            }\n            return zooKeeper;\n        }\n    }", "CodeBleu_score": 45.978070914989964}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized (data) {\n\t\tif (zooKeeper == null) {\n\t\t\tzooKeeper = zookeeperFactory.newZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, watcher, canBeReadOnly);\n            }\n            return zooKeeper;\n        }\n    }", "CodeBleu_score": 35.42235822177127}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tZooKeeper zooKeeper = data.zooKeeper;\n\tif (zooKeeper != null) {\n\t\treturn zooKeeper;\n\t}\n\n\tsynchronized (this) {\n\t\tzooKeeper = data.zooKeeper;\n\t\tif (zooKeeper != null) {\n\t\t\treturn zooKeeper;\n\t\t}\n\n\t\tdata.zooKeeper = zooKeeper = zookeeperFactory.getZooKeeper(ensembleProvider, watcher, sessionTimeout, canBeReadOnly);\n\t\treturn zooKeeper;\n\t}\n}", "CodeBleu_score": 35.393170095071135}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (helper != null) {\n\t\tZooKeeper zooKeeper = helper.getZooKeeper();\n\t\tif (zooKeeper != null) {\n\t\t\tzooKeeper.register(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\ttry {\n\t\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\t\tzooKeeper.close(waitForShutdownTimeoutMs);\n\t\t\t\t} else {\n\t\t\t\t\tzooKeeper.close();\n\t\t\t\t}\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 44.486318930894306}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (helper != null) {\n\t\ttry {\n\t\t\tZooKeeper zooKeeper = helper.getZooKeeper();\n\t\t\tif (zooKeeper != null) {\n\t\t\t\tzooKeeper.register(new Watcher() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void process(WatchedEvent watchedEvent) {\n\t\t\t\t\t}\n\t\t\t\t});\n\t\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\t\tzooKeeper.close(waitForShutdownTimeoutMs);\n\t\t\t\t} else {\n\t\t\t\t\tzooKeeper.close();\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 44.74417130089997}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (helper != null) {\n\t\tZooKeeper zooKeeper = helper.getZooKeeper();\n\t\tif (zooKeeper != null) {\n\t\t\ttry {\n\t\t\t\tzooKeeper.register(new Watcher() {\n\t\t\t\t\t@Override\n\t\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\t}\n\t\t\t\t});\n\n\t\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\t\tzooKeeper.close(waitForShutdownTimeoutMs);\n\t\t\t\t} else {\n\t\t\t\t\tzooKeeper.close();\n\t\t\t\t}\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 44.189414375990985}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \\\"Client is not started\\\");\n\tlog.debug(\\\"blockUntilConnectedOrTimedOut\\\");\n\ttracer.get().reset();\n\tfinal CountDownLatch latch = new CountDownLatch(1);\n        final AtomicReference<OperationTrace> trace = new AtomicReference<OperationTrace>();\n        final AtomicReference<Exception> exception = new AtomicReference<Exception>();\n\n        state.addListener(\n                new ConnectionStateListener() {\n                    @Override\n                    public void stateChanged(CuratorFramework client, ConnectionState newState) {\n                        if (newState == ConnectionState.CONNECTED) {\n                            latch.countDown();\n                        }\n                    }\n                },\n                MoreExecutors.directExecutor());\n\n        try {\n            state.checkConnected();\n            return true;\n        } catch ( Exception e ) {\n            exception.set(e);\n        }\n\n        if ( !ThreadUtils.await(latch, connectionTimeoutMs, TimeUnit.MILLISECONDS) ) {\n            log.error(\\\"Connection timed out after {}ms\\\", connectionTimeoutMs);\n            trace.set(tracer.get().getTrace());\n            return false;\n        }\n\n        if ( exception.get() != null ) {\n            log.error(\\\"Connection timed out after {}ms\\\", connectionTimeoutMs);\n            trace.set(tracer.get().getTrace());\n            throw exception.get();\n        }\n\n        return true;\n    }", "CodeBleu_score": 12.64136753642759}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \\\"Client is not started\\\");\n\tlog.debug(\\\"blockUntilConnectedOrTimedOut\\\");\n\tfinal CountDownLatch connectedLatch = new CountDownLatch(1);\n\tfinal AtomicBoolean connected = new AtomicBoolean(false);\n\tstate.addListener(\n        new ConnectionStateListener() {\n            @Override\n            public void stateChanged(CuratorFramework client, ConnectionState newState) {\n                if ( newState == ConnectionState.CONNECTED ) {\n                    connected.set(true);\n                    connectedLatch.countDown();\n                }\n            }\n        },\n        MoreExecutors.sameThreadExecutor()\n    );\n    if ( state.isConnected() ) {\n        connected.set(true);\n    }\n    boolean success = connectedLatch.await(connectionTimeoutMs, TimeUnit.MILLISECONDS);\n    if ( success ) {\n        log.debug(\\\"blockUntilConnectedOrTimedOut - Connected\\\");\n    } else {\n        log.debug(\\\"blockUntilConnectedOrTimedOut - Not connected\\\");\n    }\n    return success;\n}", "CodeBleu_score": 15.719942676577187}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\tlog.debug(\\\"blockUntilConnectedOrTimedOut\\\");\n\tlong startMs = System.currentTimeMillis();\n\tstate.waitForConnection(connectionTimeoutMs, TimeUnit.MILLISECONDS);\n\tlong endMs = System.currentTimeMillis();\n\tlog.debug(\\\"blockUntilConnectedOrTimedOut - end - time [{}]\\\", endMs - startMs);\n\treturn state.isConnected();\n}", "CodeBleu_score": 43.2224405050084}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\tif (started.compareAndSet(true, false)) {\nlog.debug(\\\"Closing\\\");\ntry {\nstate.close(waitForShutdownTimeoutMs);\n} catch (IOException e) {\nif (Thread.currentThread().isInterrupted()) {\nlog.debug(\\\"Interrupted during close\\\", e);\n} else {\nlog.error(\\\"Unexpected exception during close\\\", e);\n}\n}\n}\n}", "CodeBleu_score": 59.514771676832524}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif ( started.compareAndSet(true, false) ) {\n\t\tlog.debug(\\\"Closing\\\");\n\t\tOperationTrace trace = startAdvancedTracer(\\\"close\\\");\n\n\t\ttry {\n\t\t\tstate.close(waitForShutdownTimeoutMs);\n\t\t}\n\t\tcatch ( InterruptedException e ) {\n\t\t\tlog.debug(\\\"Interrupted during close\\\", e);\n\t\t}\n\t\tcatch ( IOException e ) {\n\t\t\tlog.error(\\\"Error closing\\\", e);\n\t\t}\n\n\t\ttrace.commit();\n\t}\n\telse {\n\t\tlog.debug(\\\"Already closed\\\");\n\t}\n}", "CodeBleu_score": 44.87323817271211}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.debug(\\\"Closing\\\");\n\n\tif (!started.compareAndSet(true, false)) {\n\t\tlog.debug(\\\"Already closed\\\");\n\t\treturn;\n\t}\n\n\ttry {\n\t\tstate.close(waitForShutdownTimeoutMs);\n\t}\n\tcatch (IOException e) {\n\t\tlog.error(\\\"Error closing\\\", e);\n\n\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\tlog.error(\\\"Interrupted while closing\\\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 58.22229206190277}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\tPreconditions.checkState(state.isConnected(), \"Client is not connected\");\n\n\tlong startTime = System.currentTimeMillis();\n\tlong timeoutMs = connectionTimeoutMs;\n\tlong remainingTimeoutMs = timeoutMs;\n\tCountDownLatch connectedLatch = new CountDownLatch(1);\n\tWatcher connectionWatcher = new Watcher() {\n\t\t@Override\n\t\tpublic void process(WatchedEvent event) {\n\t\t\tif (event.getType() == Event.EventType.None && event.getState() == Event.KeeperState.SyncConnected) {\n\t\t\t\tconnectedLatch.countDown();\n\t\t\t}\n\t\t}\n\t};\n\tstate.addParentWatcher(connectionWatcher);\n\n\ttry {\n\t\twhile (!connectedLatch.await(remainingTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\tlong elapsedTime = System.currentTimeMillis() - startTime;\n\t\t\tremainingTimeoutMs = timeoutMs - elapsedTime;\n\t\t\tif (remainingTimeoutMs <= 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tstate.removeParentWatcher(connectionWatcher);\n\t}\n\n\tif (!connectedLatch.getCount() == 0) {\n\t\tthrow new TimeoutException(\"Timed out waiting for connection to ZooKeeper\");\n\t}\n}", "CodeBleu_score": 44.49787641026883}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tPreconditions.checkState(started.get(), \"Client is not started\");\n\n\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() start\");\n\tOperationTrace trace = startAdvancedTracer(\"internalBlockUntilConnectedOrTimedOut\");\n\n\tlong startMs = System.currentTimeMillis();\n\tlong timeoutMs = connectionTimeoutMs;\n\tCountDownLatch latch = new CountDownLatch(1);\n\tConnectionState.Listener listener = new ConnectionState.Listener() {\n\t\t@Override\n\t\tpublic void stateChanged(ConnectionState state) {\n\t\t\tif (state.isConnected()) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t}\n\t};\n\tstate.addListener(listener);\n\ttry {\n\t\twhile (true) {\n\t\t\tif (state.isConnected()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tlong remainingMs = timeoutMs - (System.currentTimeMillis() - startMs);\n\t\t\tif (remainingMs <= 0) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tlatch.await(remainingMs, TimeUnit.MILLISECONDS);\n\t\t}\n\t} finally {\n\t\tstate.removeListener(listener);\n\t}\n\n\ttrace.commit();\n\n\tboolean localIsConnected = state.isConnected();\n\tlog.debug(\"internalBlockUntilConnectedOrTimedOut() end. isConnected: \" + localIsConnected);\n}", "CodeBleu_score": 39.556264336428974}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong startMs = System.currentTimeMillis();\n\tlong remainingMs = connectionTimeoutMs;\n\tCountDownLatch latch = new CountDownLatch(1);\n\tWatcher watcher = new Watcher() {\n\t\t@Override\n\t\tpublic void process(WatchedEvent event) {\n\t\t\tlatch.countDown();\n\t\t}\n\t};\n\n\tstate.addParentWatcher(watcher);\n\ttry {\n\t\twhile (!state.isConnected() && remainingMs > 0) {\n\t\t\tlong waitMs = Math.min(remainingMs, 100);\n\t\t\tlatch.await(waitMs, TimeUnit.MILLISECONDS);\n\t\t\tremainingMs -= waitMs;\n\t\t}\n\t} finally {\n\t\tstate.removeParentWatcher(watcher);\n\t}\n\n\tlong elapsedMs = System.currentTimeMillis() - startMs;\n\tif (elapsedMs > connectionTimeoutMs) {\n\t\tthrow new TimeoutException(\\\"Connection timeout of \\\" + connectionTimeoutMs + \\\"ms exceeded while waiting to connect to ZooKeeper\\\");\n\t}\n}", "CodeBleu_score": 53.77214493547615}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (doProtected() && (sessionId != client.getZooKeeper().getSessionId())) {\nString oldSessionId = Long.toHexString(sessionId);\n            sessionId = client.getZooKeeper().getSessionId();\n            String newSessionId = Long.toHexString(sessionId);\n            log.warn(\\\"The ZooKeeper session has changed from {} to {}. The protected node \\\" +\n                    \\\"{} will be deleted and re-created.\\\",\n                    oldSessionId, newSessionId, foundNode);\n            client.getZooKeeper().delete(foundNode, -1);\n        }\n        return foundNode;\n    }", "CodeBleu_score": 39.24248297270554}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (doProtected() && (sessionId != client.getZooKeeper().getSessionId())) {\n\t\tString oldSessionId = Long.toHexString(sessionId);\n        sessionId = client.getZooKeeper().getSessionId();\n        String newSessionId = Long.toHexString(sessionId);\n        log.warn(\\\"Session changed from {} to {}.  Removing old node: {}\\\", oldSessionId, newSessionId, foundNode);\n        client.getZooKeeper().delete(foundNode, -1);\n        return null;\n    }\n    return foundNode;\n}", "CodeBleu_score": 38.31617099414008}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (doProtected() && (sessionId != 0) && createMode.isEphemeral()) {\nlong newSessionId = client.getZooKeeper().getSessionId();\nif (sessionId != newSessionId) {\nlog.warn(\"Session changed during protected create - clearing old node: old-session-id={}, new-session-id={}, node={}\", sessionId, newSessionId, foundNode);\ntry {\nclient.getZooKeeper().delete(foundNode);\n} catch (Exception e) {\nlog.error(\"Error deleting old node: old-session-id={}, new-session-id={}, node={}\", sessionId, newSessionId, foundNode, e);\n}\nsessionId = newSessionId;\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 46.658684129181275}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tOperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\n\tRetryLoop.callWithRetry(\n        client.getZookeeperClient(),\n        new Callable<Stat>() {\n            @Override\n            public Stat call() throws Exception {\n                Stat stat = client.getZooKeeper().setACL(path, aclList, version);\n                trace.setReturnCode(client.getZookeeperClient().blockUntilConnectedOrTimedOut())\n                        .setPath(path)\n                        .setStat(stat)\n                        .commit();\n                return stat;\n            }\n        }\n    );\n    return trace.getStat();\n}", "CodeBleu_score": 57.142244400715605}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tOperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\\\"SetACLBuilderImpl-Foreground\\\");\ntry {\nclient.getZooKeeper().setACL(path, aclList, version);\ntrace.setReturnCode(0).setPath(path).commit();\n} catch (KeeperException.NoNodeException e) {\ntrace.setReturnCode(e.code()).setPath(path).commit();\nclient.create().creatingParentsIfNeeded().withACL(aclList).forPath(path);\n} catch (KeeperException.BadVersionException e) {\ntrace.setReturnCode(e.code()).setPath(path).setStat(e.getStat()).commit();\nthrow e;\n} catch (KeeperException e) {\ntrace.setReturnCode(e.code()).setPath(path).commit();\nthrow e;\n}\nreturn trace.getStat();\n}", "CodeBleu_score": 36.92392600688429}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\tOperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\\\"SetACLBuilderImpl-Foreground\\\");\nStat stat = RetryLoop.callWithRetry(\n        client.getZookeeperClient(),\n        new Callable<Stat>() {\n            @Override\n            public Stat call() throws Exception {\n                return client.getZooKeeper().setACL(path, aclList, version);\n            }\n        });\ntrace.setReturnCode(stat.getErrorCode())\n        .setPath(path)\n        .setStat(stat)\n        .commit();\nreturn stat;\n}", "CodeBleu_score": 73.01793771678928}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tPreconditions.checkArgument(ZKPaths.getPathAndNode(membershipPath)[1] == null, \"Path must be a parent: %s\", membershipPath);\n\tPreconditions.checkArgument(thisId != null, \"Member ID cannot be null\");\n\tPreconditions.checkArgument(payload != null, \"Payload cannot be null\");\n\tthis.membershipPath = membershipPath;\n        this.thisId = thisId;\n        this.cache = CuratorCacheBridge.build(client, membershipPath, parentPathFilter(membershipPath));\n        this.pen = PersistentNode.create(client, CreateMode.EPHEMERAL, true, ZKPaths.makePath(membershipPath, thisId), payload);\n    }", "CodeBleu_score": 49.05675160257079}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tPreconditions.checkArgument(ZKPaths.PATH_SEPARATOR.equals(membershipPath.substring(0, 1)), \"Path must start with %s\", ZKPaths.PATH_SEPARATOR);\n\tPreconditions.checkArgument(ZKPaths.PATH_SEPARATOR.equals(membershipPath.substring(membershipPath.length() - 1, membershipPath.length())), \"Path must end with %s\", ZKPaths.PATH_SEPARATOR);\n\tPreconditions.checkArgument(thisId != null, \"thisId cannot be null\");\n\tPreconditions.checkArgument(payload != null, \"payload cannot be null\");\n\tthis.membershipPath = membershipPath;\n        this.thisId = thisId;\n        this.cache = CuratorCacheBridge.build(client, membershipPath, false, false, parentPathFilter(membershipPath));\n        this.pen = PersistentNode.builder(client, new GroupMember.PersistentNode.DataSerializer(payload)).withMode(CreateMode.EPHEMERAL).build();\n    }", "CodeBleu_score": 44.594856700114626}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tPreconditions.checkArgument(client != null, \"client cannot be null\");\n\tPreconditions.checkArgument(membershipPath != null, \"membershipPath cannot be null\");\n\tPreconditions.checkArgument(thisId != null, \"thisId cannot be null\");\n\tPreconditions.checkArgument(payload != null, \"payload cannot be null\");\n\n\tthis.membershipPath = ZKPaths.makePath(membershipPath, thisId);\n\tthis.thisId = thisId;\n\tthis.cache = CuratorCacheBridge.build(client, parentPathFilter(membershipPath));\n\tthis.pen = PersistentNode.make(client, CreateMode.EPHEMERAL, true, this.membershipPath, payload);\n}", "CodeBleu_score": 44.99295164918193}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\nasync.create().withProtection().withMode(CreateMode.PERSISTENT).forPath(path, \\\"data\\\".getBytes()).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\\\"Created node name is: \\\" + name);\n\n        // now set up a watch on the node\n        async.watched().getData().watched().forPath(name).whenComplete((data, event) -> {\n            if (event != null) {\n                System.out.println(\\\"Got event \\\" + event.getType() + \\\" on path \\\" + event.getPath());\n            } else {\n                System.out.println(\\\"Got data \\\" + new String(data));\n            }\n        });\n    }\n});\n}", "CodeBleu_score": 56.06548743224484}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t\tAsyncCuratorFramework async =\n\t\t\tAsyncCuratorFramework.wrap(client); // normally you'd wrap early in your app and reuse the instance\n\n\t// create a node at the given path with the given payload asynchronously\n\tasync.create().forPath(path, \\\"\\\".getBytes()).whenComplete((name, exception) -> {\n\t\tif (exception != null) {\n\t\t\t// there was a problem\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\\\"Created node name is: \\\" + name);\n\n\t\t\t// set up a watch on the node so that we get notified of changes to the node\n\t\t\tasync.watched().forPath(path).whenComplete((data, event, exception1) -> {\n\t\t\t\tif (exception1 != null) {\n\t\t\t\t\t// there was a problem\n\t\t\t\t\texception1.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\\\"Node \\\" + path + \\\" changed. Data is now \\\" + new String(data));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 54.16891786983058}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\nasync.create().creatingParentsIfNeeded().forPath(path, \\\"some data\\\");\n\nasync.watched().forPath(path).whenComplete((data, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        if (exception instanceof AsyncEventException) {\n            AsyncEventException aee = (AsyncEventException) exception;\n            System.out.println(\\\"Type: \\\" + aee.getType());\n            System.out.println(\\\"State: \\\" + aee.getState());\n            System.out.println(\\\"Path: \\\" + aee.getPath());\n            System.out.println(\\\"Message: \\\" + aee.getMessage());\n        }\n        exception.printStackTrace();\n    } else {\n        System.out.println(\\\"Node data is: \\\" + new String(data));\n    }\n});\n}", "CodeBleu_score": 55.53393057271842}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> resultList = client.getZookeeperClient().multi(transaction.getOperations(), transaction.getTransactionId(), transaction.getTxnOptions());\n\tif (resultList.size() > 0) {\n\t\tOpResult result = resultList.get(0);\n\t\tif (result.getType() == OpCode.error) {\n\t\t\tOpResult.ErrorResult errorResult = (OpResult.ErrorResult) result;\n\t\t\tint errorCode = errorResult.getErr();\n\t\t\tthrow KeeperException.create(errorCode);\n\t\t}\n\t}\n\n\treturn resultList;\n}", "CodeBleu_score": 46.99456127586699}, {"code": "private List<OpResult> doOperation() throws Exception{\n\tList<OpResult> resultList = client.getZookeeperClient().multi(transaction.getOperations());\n\n// check for errors\nOpResult opResult = resultList.get(0);\nif (opResult.getType() == OpCode.error) {\nOpResult.ErrorResult errorResult = (OpResult.ErrorResult) opResult;\nthrow KeeperException.create(Code.get(errorResult.getErr()));\n}\n\nreturn resultList;\n}", "CodeBleu_score": 35.334454937332474}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> resultList = client.getZookeeperClient().multi(transaction.getOperations());\n\tif (resultList.isEmpty()) {\n\t\tthrow new KeeperException.ConnectionLossException();\n\t}\n\n\tOpResult firstResult = resultList.get(0);\n\tif (firstResult.getType() == OpResult.Type.ERROR) {\n\t\tOpResult.ErrorResult errorResult = (OpResult.ErrorResult) firstResult;\n\t\tthrow KeeperException.create(KeeperException.Code.get(errorResult.getErr()), errorResult.getPath());\n\t}\n\n\treturn resultList;\n}", "CodeBleu_score": 43.73663631941476}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tCollection<String> services = serviceDiscovery.queryForNames();\nif (services.size() == 0) {\nSystem.err.println(\\\"No services registered\\\");\n} else {\nfor (String service : services) {\nCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\nSystem.out.println(\\\"Service: \\\" + service);\nfor (ServiceInstance<InstanceDetails> instance : instances) {\noutputInstance(instance);\n}\n}\n}\n}", "CodeBleu_score": 44.21519334907662}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tCollection<String> services = serviceDiscovery.queryForNames();\n\tfor (String service : services) {\n\t\tSystem.out.println(\\\"Service: \\\" + service);\n\n\t\tCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 30.749414505843003}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tCollection<String> services = serviceDiscovery.queryForNames();\n\tif (services.size() == 0) {\n\t\tSystem.err.println(\\\"No services registered\\\");\n\t} else {\n\t\tfor (String service : services) {\n\t\t\tCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\n\t\t\tSystem.out.println(\\\"Service: \\\" + service);\n\t\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\t\toutputInstance(instance);\n            }\n        }\n    }\n    CloseableUtils.closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 47.90358792933874}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> childList = Lists.newArrayList(children);\n\tchildList.removeIf(new Predicate<String>() {\n\t\t@Override\n\t\tpublic boolean apply(String input) {\n\t\t\treturn input.equals(READY_NODE);\n\t\t}\n\t});\n\tCollections.sort(childList);\n\treturn childList;\n}", "CodeBleu_score": 40.427737515221544}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> result = Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n\t\t@Override\n\t\tpublic boolean apply(String input) {\n\t\t\treturn !input.equals(READY_NODE);\n        }\n    }));\n    Collections.sort(result);\n    return result;\n}", "CodeBleu_score": 60.00760905244071}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filtered = Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n\t\t@Override\n\t\tpublic boolean apply(String child) {\n\t\t\treturn !child.equals(READY_NODE);\n\n\t\t}\n\t}));\n\tCollections.sort(filtered);\n\n\treturn filtered;\n\n}", "CodeBleu_score": 59.708928433601}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk != null) {\n\t\tzk.close();\n\t}\n\thost = newHost;\n\tzk = new ZooKeeper(host, sessionTimeout, this);\n\tif (readOnly) {\n\t\tzk.addAuthInfo(scheme, auth.getBytes());\n\t}\n}", "CodeBleu_score": 34.754794059393014}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk != null) {\n\t\tzk.close();\n\t}\n\thost = newHost;\n\tzk = new ZooKeeper(host, sessionTimeout, this);\n\tif (readOnly) {\n\t\tzk.addAuthInfo(\\\"digest\\\", (\\\"super:\\\" + new String(Base64.encodeBase64(new byte[0]))).getBytes());\n\t}\n\tif (printWatches) {\n\t\tzk.addWatches(WatchedEvent.EventType.None, \\\"\\\", this);\n}\n}", "CodeBleu_score": 37.06418108952433}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk != null) {\n\t\tzk.close();\n\t}\n\tif (newHost == null) {\n\t\thost = \\\"localhost\\\";\n\t\tzk = new ZooKeeper(host, 30000, this);\n        } else {\n            host = newHost;\n            zk = new ZooKeeper(host, 30000, this);\n        }\n        if (readOnly) {\n            zk.setACL(ZooDefs.Ids.ANYONE_ID_UNSAFE,\n                    new ArrayList<ACL>(Arrays.asList(new ACL(ZooDefs.Perms.ALL,\n                            ZooDefs.Ids.AUTH_IDS))));\n        }\n        if (printWatches) {\n            zk.addWatches(PathUtils.getWatchChildren(path), true);\n        }\n    }", "CodeBleu_score": 24.180736462331904}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acl = new ArrayList<ACL>();\n        String[] acls = aclString.split(\\\",\\\");\n        for (String aclStr : acls) {\n            String[] parts = aclStr.split(\\\"=\\\", 2);\n            if (parts.length != 2) {\n                outputStream.write((\\\"Invalid ACL syntax: \\\" + aclStr).getBytes());\n                continue;\n            }\n            String scheme = parts[0];\n            String id = parts[1];\n            int i = id.lastIndexOf(\\\"/\\\");\n            if (i == -1) {\n                outputStream.write((\\\"Invalid ACL id: \\\" + id).getBytes());\n                continue;\n            }\n            String perms = id.substring(i + 1);\n            id = id.substring(0, i);\n            try {\n                acl.add(new ACL(getPermFromString(perms), new Id(scheme, id.getBytes())));\n            } catch (IllegalArgumentException e) {\n                outputStream.write((\\\"Invalid ACL id: \\\" + id).getBytes());\n            }\n        }\n        return acl;\n    }", "CodeBleu_score": 26.15956938911188}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acl = new ArrayList<ACL>();\nString[] acls = aclString.split(\",\");\nfor (String s : acls) {\nString scheme = null;\nString id = null;\nint perms = -1;\ntry {\nscheme = s.substring(0, s.indexOf(\":\")).trim();\nid = s.substring(s.indexOf(\":\") + 1, s.lastIndexOf(\":\")).trim();\nperms = Integer.parseInt(s.substring(s.lastIndexOf(\":\") + 1).trim());\n} catch (NumberFormatException e) {\nSystem.err.println(\\\"Invalid ACL: \\\" + s);\n} catch (IndexOutOfBoundsException e) {\nSystem.err.println(\\\"Invalid ACL: \\\" + s);\n}\nif (scheme != null && id != null && perms != -1) {\nacl.add(new ACL(perms, new Id(scheme, id.getBytes())));\n}\n}\nreturn acl;\n}", "CodeBleu_score": 30.24362555685031}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acl = new ArrayList<ACL>();\n\tString[] acls = aclString.split(\",\");\n\tfor (String a : acls) {\n\t\tString[] parts = a.split(\":\");\n\t\tif (parts.length != 3) {\n\t\t\tSystem.err.println(\\\"Invalid ACL syntax: \\\" + a);\n            continue;\n        }\n        int perms;\n        try {\n            perms = parsePerm(parts[2]);\n        } catch (NumberFormatException e) {\n            System.err.println(\\\"Invalid ACL permissions: \\\" + parts[2]);\n            continue;\n        }\n        acl.add(new ACL(perms, new Id(parts[0], parts[1])));\n    }\n    return acl;\n}", "CodeBleu_score": 27.726179479566838}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null || pathList.isEmpty()) {\nreturn;\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).delete(pathList);\n}\n}", "CodeBleu_score": 81.52226609448464}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tassertZookeeperExists(serverId);\nif (pathList == null || pathList.isEmpty()) {\nreturn;\n}\nif (pathList.size() < 20) {\nfor (String path : pathList) {\ntry {\nzookeeperMap.get(serverId).delete(path);\n} catch (Exception e) {\nlog.error(\\\"delete data error \\\" + serverId + \\\" -> \\\" + path, e);\n}\n}\n} else {\nfinal List<String> pathListCopy = new ArrayList<>(pathList);\nnew Thread(() -> {\nfor (String path : pathListCopy) {\ntry {\nzookeeperMap.get(serverId).delete(path);\n} catch (Exception e) {\nlog.error(\\\"delete data error \\\" + serverId + \\\" -> \\\" + path, e);\n}\n}\n}).start();\n}\n}", "CodeBleu_score": 61.013771701417596}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tassertZookeeperExists(serverId);\n\tif (pathList == null || pathList.size() == 0) {\n\t\treturn;\n\t}\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tdelete(serverId, path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 74.58419545942849}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tfinal CuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n\tfinal ZookeeperParams params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(null)\n\t\t\t.maxRetries(5)\n\t\t\t.connectionTimeout(10000)\n\t\t\t.retryIntervalTime(1000)\n\t\t\t.sessionTimeout(10000)\n\t\t\t.build();\n\twriter.write(\"Connecting to Zookeeper instance: \" + url + \"\n\");\n\tfinal ZooKeeperMain client = factory.create(params);\n\twriter.write(\"Connected to Zookeeper instance: \" + url + \"\n\");\n\treturn new Terminal(id, url, client);\n}", "CodeBleu_score": 51.323579998630855}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\n}", "CodeBleu_score": 4.717936828636274}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(null)\n\t\t\t.maxRetries(3)\n\t\t\t.connectionTimeout(3000)\n\t\t\t.retryIntervalTime(500)\n\t\t\t.sessionTimeout(30000)\n\t\t\t.build();\n\tvar connection = factory.create(params);\n\tvar client = connection.getZookeeperClient();\n\twriter.write(\"Connecting to Zookeeper instance at \" + url + \"...\");\n\tif (client.isConnected()) {\n\t\twriter.write(\"Connected to Zookeeper instance at \" + url + \"!\");\n\t\treturn new Terminal(id, url, connection, new ZooKeeperMain(client));\n\t} else {\n\t\twriter.write(\"Failed to connect to Zookeeper instance at \" + url + \".\");\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 57.14575932013069}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t\tint retry = 0;\n\twhile (retry < 6) {\n\t\ttry {\n\t\t\tif (proxySocket.isClosed()) {\n\t\t\t\tlog.info(\\\"tunnel is closed, retry to create\\\");\n\t\t\t\tcreateAsync();\n\t\t\t}\n\t\t\tif (proxySocket.isClosed()) {\n\t\t\t\tlog.info(\\\"tunnel is still closed, wait 1s and retry\\\");\n\t\t\t\tretry++;\n\t\t\t\tThread.sleep(1000);\n\t\t\t} else {\n\t\t\t\tlog.info(\\\"tunnel is connected\\\");\n\t\t\t\treturn;\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\\\"block until connected failed\\\", e);\n\t\t\tthis.close();\n\t\t\tthrow new IllegalStateException(\\\"block until connected failed\\\", e);\n\t\t}\n\t}\n\tthis.close();\n\tthrow new IllegalStateException(\\\"SSH connect error by timeout: \\\" + sshHost);\n}", "CodeBleu_score": 42.68394073430321}, {"code": "public void blockUntilConnected(){\n\t\tint retry = 0;\n\twhile (retry < 6) {\n\t\ttry {\n\t\t\tif (proxySocket != null && proxySocket.isBound() && proxySocket.isClosed()) {\n\t\t\t\tthrow new IllegalStateException(\\\"SSH tunnel not connected\\\");\n\t\t\t}\n\t\t\treturn;\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\\\"SSH tunnel not connected, retrying in 1s\\\");\n\t\t\tretry++;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tlog.error(\\\"Interrupted\\\", e1);\n                }\n            }\n        }\n        this.close();\n        throw new IllegalStateException(\\\"SSH tunnel not connected\\\");\n    }", "CodeBleu_score": 39.40820274255141}, {"code": "public void blockUntilConnected(){\n\t\tint retryCount = 0;\n\twhile (retryCount < 6) {\n\t\ttry {\n\t\t\tif (proxySocket.isClosed()) {\n\t\t\t\tthrow new IllegalStateException(\\\"proxy socket is closed\\\");\n\t\t\t}\n\t\t\tif (proxySocket.isBound()) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tlog.warn(\\\"failed to check socket state, retrying\\\");\n\t\t}\n\t\tretryCount++;\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\tlog.warn(\\\"failed to sleep, retrying\\\");\n\t\t}\n\t}\n\tclose();\n\tthrow new IllegalStateException(\\\"Failed to connect to SSH server\\\");\n}", "CodeBleu_score": 35.476932161519194}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"delete node failed\", e);\n\t\tthrow new IllegalStateException(\"delete node failed\");\n\t}\n}", "CodeBleu_score": 78.8302686002636}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t    zookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t    log.error(\"failed to delete node\", e);\n\t    throw new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 85.84950778846229}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.delete(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error while deleting nodes\", e);\n\t\tthrow new IllegalStateException(\"Error while deleting nodes\");\n\t}\n}", "CodeBleu_score": 70.27625379896716}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tzookeeperDomainService.disconnect(id);\ntreeItemCache.removeServer(id);\n}", "CodeBleu_score": 13.870199916055725}, {"code": "public void disconnect(String id){\n\t\tvar serverConfig = configurationDomainService.getById(id).orElseThrow();\n\tzookeeperDomainService.disconnect(serverConfig);\n\tconfigurationDomainService.decrementConnectTimes(id);\n}", "CodeBleu_score": 44.61235230888315}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tvar serverConfig = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfig);\n\t\ttreeItemCache.removeServer(id);\n\t\tconfigurationDomainService.decrementConnectTimes(id);\n\t});\n}", "CodeBleu_score": 56.85286669547265}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tfinal Configuration configuration = configurationDomainService.get().orElseThrow();\n\tfinal ServerConfiguration serverConfiguration = configuration.getById(serverId).orElseThrow();\n\tfinal String connectionUrl = serverConfiguration.getConnectionUrl();\n\tzookeeperDomainService.startTerminal(connectionUrl, stream);\n}", "CodeBleu_score": 36.78569482477839}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServerConfiguration serverConfiguration = configurationDomainService.get()\n\t\t\t.orElseThrow()\n\t\t\t.getById(serverId)\n\t\t\t.orElseThrow();\n\tString connectionUrl = serverConfiguration.getConnectionUrl();\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 36.52484471891804}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tfinal Configuration configuration = configurationDomainService.get().orElseThrow();\n\tfinal ServerConfiguration serverConfiguration = configuration.getById(serverId).orElseThrow();\n\tString connectionUrl;\n\tif (serverConfiguration.isSshTunnelEnabled()) {\n\t\tconnectionUrl = serverConfiguration.getSshTunnel().getConnectionUrl();\n\t} else {\n\t\tconnectionUrl = ZookeeperDomainService.getConnectionUrl(serverConfiguration.getHost(), serverConfiguration.getPort());\n\t}\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 45.62231343134631}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\tServerConfiguration server = configurationDomainService.getById(id).orElseThrow();\n\tString urlToConnect;\n\tif (server.getSshTunnelEnabled()) {\n\t\turlToConnect = \"localhost:\" + server.getPort();\n\t} else {\n\t\turlToConnect = server.getHost() + \":\" + server.getPort();\n\t}\n\tzookeeperDomainService.executeCommand(id, urlToConnect, command);\n}", "CodeBleu_score": 29.360800656575453}, {"code": "public void executeCommand(String id, String command){\n\t\tzookeeperDomainService.executeCommand(id, command);\n}", "CodeBleu_score": 18.608362051549086}, {"code": "public void executeCommand(String id, String command){\n\t\tServerConfiguration server = configurationDomainService.getById(id).orElseThrow();\n\tString urlToConnect;\n\tif (server.getSshTunnelEnabled()) {\n\t\turlToConnect = \"localhost:\" + server.getPort();\n\t} else {\n\t\turlToConnect = server.getHost() + \":\" + server.getPort();\n\t}\n\tzookeeperDomainService.executeCommand(id, urlToConnect, command);\n}", "CodeBleu_score": 29.360800656575453}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tvar userHome = System.getProperty(\\\"user.home\\\");\n\tvar path = Paths.get(userHome + \\\"/.prettyZoo/config/zookeeper.properties\\\");\n\ttry {\n\t\tif (Files.exists(path)) {\n\t\t\tproperties.load(Files.newInputStream(path));\n\t\t\tlog.info(\\\"loaded zookeeper system properties from \\\" + path);\n}\n\t} catch (Exception e) {\n\t\tlog.error(\\\"file read error, msg:{}\\\", e.getMessage(), e);\n}\n\treturn properties;\n}", "CodeBleu_score": 24.013756817902866}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tString userHome = System.getProperty(\"user.home\");\n\t\tString filePath = userHome + \"/.prettyZoo/zookeeper.properties\";\n\t\tif (Files.exists(Paths.get(filePath))) {\n\t\t\tproperties.load(new FileInputStream(filePath));\n\t\t\tlog.info(\\\"load zookeeper system properties success\\\");\n\t\t} else {\n\t\t\tlog.info(\\\"can't find zookeeper.properties in \\\" + filePath);\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\\\"load zookeeper system properties failed, msg:{}\\\", e.getMessage(), e);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 40.9217992896032}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\ttry {\n\t\tvar properties = new Properties();\n\t\tvar file = new File(\\\"/etc/zookeeper/conf/zoo.cfg\\\");\n\t\tif (file.exists()) {\n\t\t\ttry (var inputStream = new FileInputStream(file)) {\n\t\t\t\tproperties.load(inputStream);\n            }\n        }\n        log.info(\\\"loaded zookeeper system properties: \\\" + properties);\n        return properties;\n    } catch (Exception e) {\n        log.error(\\\"error loading zookeeper system properties, msg:{}\\\", e.getMessage(), e);\n        return new Properties();\n    }\n}", "CodeBleu_score": 32.06336509926027}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\tString sysPropPath = PrettyZooConfigRepository.SYS_PROP_PATH;\nif (Files.exists(Paths.get(sysPropPath))) {\ntry (var reader = new StringReader(content)) {\nProperties properties = new Properties();\nproperties.load(reader);\nlog.info(\\\"save system properties success ->\n {}\\\", properties);\n} catch (IOException e) {\n// ignore error and log it\nlog.error(\\\"save system properties failed\\\", e);\nVToast.error(\\\"save system properties failed\\\");\n}\n} else {\nlog.info(\\\"ignore save system properties, file not exists -> {}\\\", sysPropPath);\n}\n}", "CodeBleu_score": 37.949487031791605}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tString sysPropPath = PrettyZooConfigRepository.SYS_PROP_PATH;\n\tif (Files.exists(Paths.get(sysPropPath))) {\n\t\ttry {\n\t\t\tProperties properties = new Properties();\n\t\t\tproperties.load(new StringReader(content));\n\t\t\tlog.info(\\\"save system properties success ->\n {}\\\", properties);\n\t\t\tproperties.store(new FileOutputStream(sysPropPath), \\\"pretty zoo system properties\\\");\n\t\t} catch (IOException e) {\n\t\t\t// ignore error and log it\n\t\t\tlog.error(\\\"save system properties failed\\\", e);\n\t\t\tVToast.error(\\\"save system properties failed\\\");\n\t\t}\n\t} else {\n\t\tlog.info(\\\"ignore save system properties, file not exists -> {}\\\", sysPropPath);\n\t}\n}", "CodeBleu_score": 30.90710978367931}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tStringReader reader = new StringReader(content);\n    Properties properties;\n    try {\n        properties = new Properties();\n        properties.load(reader);\n    } catch (IOException e) {\n        log.error(\\\"load system properties failed\\\", e);\n        VToast.error(\\\"load system properties failed\\\");\n        return;\n    }\n    try (FileOutputStream out = new FileOutputStream(PrettyZooConfigRepository.SYS_PROP_PATH)) {\n        properties.store(out, \\\"prettyZoo system properties\\\");\n    } catch (IOException e) {\n        log.error(\\\"save system properties failed\\\", e);\n        VToast.error(\\\"save system properties failed\\\");\n    }\n}", "CodeBleu_score": 41.24542902499447}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tStringBuilder responseBuilder = new StringBuilder();\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine()) != null) {\n\t\t\tresponseBuilder.append(line);\n\t\t}\n\t\tclient.close();\n\t\treturn responseBuilder.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 52.16221328552515}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tInputStream inputStream = client.getInputStream();\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));\n\t\tStringBuilder response = new StringBuilder();\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine()) != null) {\n\t\t\tresponse.append(line);\n\t\t}\n\t\tclient.close();\n\t\treturn response.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 52.58084747096792}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tfinal StringBuilder sb = new StringBuilder();\n\t\tfinal BufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = br.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tbr.close();\n\t\tclient.close();\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 51.174768326432904}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t", "CodeBleu_score": 3.373706656875291}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\nlog.debug(\"Creating CuratorZookeeperConnection with params: {}\", params);\n\nfinal CuratorFramework client = CuratorFrameworkFactory.builder()\n\n.connectString(params.getConnectString())\n\n.retryPolicy(new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries()))\n\n.namespace(params.getNamespace())\n\n.aclProvider(new ACLProvider() {\n\n@Override\n\npublic List<ACL> getDefaultAcl() {\n\nreturn ZooDefs.Ids.CREATOR_ALL_ACL;\n\n}\n\n@Override\n\npublic List<ACL> getAclForPath(final String path) {\n\nreturn ZooDefs.Ids.CREATOR_ALL_ACL;\n\n}\n\n})\n\n.authorization(params.getAuthInfo())\n\n.build();\n\nclient.start();\n\nfinal CuratorZookeeperConnection connection = new CuratorZookeeperConnection(client, params);\n\ntry {\n\nif (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n\nlog.error(\"Could not connect to zookeeper cluster in 5 seconds. Shutting down.\");\n\nclient.close();\n\nthrow new ZookeeperException(\"Could not connect to zookeeper cluster in 5 seconds\");\n\n}\n\n} catch (InterruptedException e) {\n\nlog.error(\"Interrupted while waiting for connection to zookeeper cluster\", e);\n\nclient.close();\n\nthrow new ZookeeperException(\"Interrupted while waiting for connection to zookeeper cluster\", e);\n\n}\n\nreturn connection;\n\n}", "CodeBleu_score": 46.357886153105255}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t", "CodeBleu_score": 3.373706656875291}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (!isSync.get()) {\n\t\tlog.info(\\\"Starting synchronization of Zookeeper nodes\\\");\n\t\ttry {\n\t\t\tfinal String connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\t\t\ttreeCache.getListenable().addListener((client, event) -> {\n\t\t\t\tif (event.getType() == TreeCacheEvent.Type.INITIALIZED) {\n\t\t\t\t\tlog.info(\\\"Zookeeper nodes synchronized\\\");\n\t\t\t\t} else if (event.getType() == TreeCacheEvent.Type.NODE_ADDED) {\n\t\t\t\t\tlog.info(\\\"Node {} added\\\", event.getData().getPath());\n\t\t\t\t\tfor (ZookeeperNodeListener listener : listeners) {\n\t\t\t\t\t\tlistener.nodeAdded(event.getData().getPath(), event.getData().getData());\n\t\t\t\t\t}\n\t\t\t\t} else if (event.getType() == TreeCacheEvent.Type.NODE_UPDATED) {\n\t\t\t\t\tlog.info(\\\"Node {} updated\\\", event.getData().getPath());\n\t\t\t\t\tfor (ZookeeperNodeListener listener : listeners) {\n\t\t\t\t\t\tlistener.nodeUpdated(event.getData().getPath(), event.getData().getData());\n\t\t\t\t\t}\n\t\t\t\t} else if (event.getType() == TreeCacheEvent.Type.NODE_REMOVED) {\n\t\t\t\t\tlog.info(\\\"Node {} removed\\\", event.getData().getPath());\n\t\t\t\t\tfor (ZookeeperNodeListener listener : listeners) {\n\t\t\t\t\t\tlistener.nodeRemoved(event.getData().getPath());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t});\n\t\t\ttreeCache.start();\n\t\t\tisSync.set(true);\n\t\t\tlog.info(\\\"Synchronization of Zookeeper nodes started\\\");\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\\\"Failed to synchronize Zookeeper nodes\\\", e);\n\t\t\ttreeCache.close();\n\t\t\tisSync.set(false);\n\t\t}\n\t} else {\n\t\tlog.info(\\\"Synchronization of Zookeeper nodes already in progress\\\");\n\t}\n}", "CodeBleu_score": 40.39423436198189}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (isSync.compareAndSet(false, true)) {\n\t\ttry {\n\t\t\tlog.info(\\\"Starting sync for {}\\\", id);\n        final String connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners, connectionString));\n        treeCache.start();\n        log.info(\\\"Sync for {} started\\\", id);\n        isSync.set(true);\n    } catch (Exception e) {\n        log.error(\\\"Error starting sync for {}\\\", id, e);\n        close();\n    }\n}\n\n}", "CodeBleu_score": 52.15060149987922}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tif (isSync.compareAndSet(false, true)) {\n\t\tlog.info(\\\"Start syncing Zookeeper nodes\\\");\n\t\ttry {\n\t\t\tfinal String connectionString = getClient().getZookeeperClient().getCurrentConnectionString();\n\t\t\tlog.info(\\\"Connection string: {}\\\", connectionString);\n\t\t\ttreeCache.getListenable().addListener((client, event) -> {\n\t\t\t\tlog.info(\\\"Event: {}\\\", event.getType());\n\t\t\t\tlog.info(\\\"Path: {}\\\", event.getData().getPath());\n\t\t\t\tfor (ZookeeperNodeListener listener : listeners) {\n\t\t\t\t\tlistener.onNodeChanged(event.getType(), event.getData().getPath(), new String(event.getData().getData()));\n\t\t\t\t}\n\t\t\t});\n\t\t\ttreeCache.start();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\\\"Error\\\", e);\n\t\t\ttreeCache.close();\n\t\t}\n\t} else {\n\t\tlog.info(\\\"Already syncing Zookeeper nodes\\\");\n\t}\n}", "CodeBleu_score": 42.25424760100694}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n\tpathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tpathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 91.23760518143125}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache childrenCache = new PathChildrenCache(client, path, true);\n\tchildrenCache.getListenable().addListener(listener);\n\tchildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 71.87330366783459}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\ncache.getListenable().addListener(listener);\ncache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 69.06949503425042}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tlogger.info(\\\"Un-register service\\\");\n\tfor (String path : pathList) {\n\t\ttry {\n\t\t\tcuratorClient.deletePath(path);\n\t\t\tlogger.info(\\\"Un-register service: {}\\\", path);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\\\"Un-register service fail, exception: {}\\\", e.getMessage());\n\t\t}\n\t}\n\tcuratorClient.close();\n}", "CodeBleu_score": 47.069155981642695}, {"code": "public void unregisterService(){\n\t// Unregister service info\nfor (String path : pathList) {\n    try {\n        curatorClient.deletePath(path);\n        logger.info(\\\"Unregister service: {} \\\", path);\n    } catch (Exception e) {\n        logger.error(\\\"Unregister service fail, exception: {}\\\", e.getMessage());\n    }\n}\ncuratorClient.close();\n}", "CodeBleu_score": 35.39371032855297}, {"code": "public void unregisterService(){\n\t// Unregister service info\nfor (String path : pathList) {\ntry {\ncuratorClient.deletePath(path);\nlogger.info(\\\"Unregister service: {}\\\", path);\n} catch (Exception e) {\nlogger.error(\\\"Unregister service fail, exception: {}\\\", e.getMessage());\n}\n}\ncuratorClient.close();\n}", "CodeBleu_score": 44.91116559970994}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t\tif (client == null) {\n\t\tcompletableFuture.whenComplete(this::makeClientReady);\n\t} else {\n\t\tclient.subscribeStateChanges(listener);\n\t}\n}", "CodeBleu_score": 24.183877478324728}, {"code": "public void addListener(IZkStateListener listener){\n\tif (client == null) {\nmakeClientReady(null, listener);\n} else {\nclient.subscribeStateChanges(listener);\n}\n}", "CodeBleu_score": 27.20802822888543}, {"code": "public void addListener(IZkStateListener listener){\n\t\tif (!started) {\n\t\ttry {\n\t\t\tclient = completableFuture.get(timeout, TimeUnit.MILLISECONDS);\n//\t\t\tthis.client.subscribeStateChanges(stateListener);\n\t\t} catch (Throwable t) {\n\t\t\tlogger.error(\"Timeout! zookeeper server can not be connected in : \" + timeout + \"ms!\", t);\n\t\t\tcompletableFuture.whenComplete(this::makeClientReady);\n\t\t}\n\t\tstarted = true;\n\t} else {\n\t\tlogger.warn(\"Zkclient has already been started!\");\n\t}\n}", "CodeBleu_score": 24.092922928455618}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\n\n\nthis.client = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(new RetryNTimes(Integer.MAX_VALUE, 1000)).connectionTimeoutMs(30000).authorization(\"digest\", authority.getBytes()).build();\n\nclient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n\npublic void stateChanged(CuratorFramework client, ConnectionState state) {\n\nif (state == ConnectionState.LOST) {\n\nCuratorZookeeperClient.this.state = StateListener.DISCONNECTED;\n\n}\n\nelse if (state == ConnectionState.CONNECTED) {\n\nCuratorZookeeperClient.this.state = StateListener.CONNECTED;\n\n}\n\nelse if (state == ConnectionState.RECONNECTED) {\n\nCuratorZookeeperClient.this.state = StateListener.RECONNECTED;\n\n}\n\n}\n\n});\n\ntry {\n\nclient.start();\n\n}\n\ncatch (Exception e) {\n\nthrow new IllegalStateException(e);\n\n}\n\n}", "CodeBleu_score": 56.669838707987964}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\n\n\nclient = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(new RetryNTimes(Integer.MAX_VALUE, 1000)).connectionTimeoutMs(15000).authorization(\"digest\", authority.getBytes()).build();\n\nclient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n\n\n/**\n * Invoked when the connection state changes.\n */\npublic void stateChanged(CuratorFramework client, ConnectionState state) {\n\nif (state == ConnectionState.LOST) {\n\nstateChanged(StateListener.DISCONNECTED);\n\n}\n\nelse if (state == ConnectionState.CONNECTED) {\n\nstateChanged(StateListener.CONNECTED);\n\n}\n\nelse if (state == ConnectionState.RECONNECTED) {\n\nstateChanged(StateListener.RECONNECTED);\n\n}\n\n}\n\n});\n\ntry {\n\nclient.start();\n\n}\n\ncatch (Exception e) {\n\nthrow new IllegalStateException(e);\n\n}\n\n}", "CodeBleu_score": 56.7044174343381}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\n\n\nclient = CuratorFrameworkFactory.newClient(serverAddr, authority, getRetryPolicy(), getSessionTimeoutMs());\n\nclient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n\n    public void stateChanged(CuratorFramework client, ConnectionState state) {\n\n        if (state == ConnectionState.LOST) {\n\n            lost();\n\n        }\n\n        else if (state == ConnectionState.CONNECTED) {\n\n            connected();\n\n        }\n\n        else if (state == ConnectionState.RECONNECTED) {\n\n            reconnected();\n\n        }\n\n    }\n\n});\n\ntry {\n\n    client.start();\n\n} catch (Exception e) {\n\n    throw new IllegalStateException(\\\"Unable to connect to server\\\", e);\n\n}\n\n}", "CodeBleu_score": 40.04345356422234}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners != null) {\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener != null) {\nremoveTargetChildListener(path, targetListener);\nif (listeners.isEmpty()) {\nchildListeners.remove(path);\n}\n}\n}\n}", "CodeBleu_score": 82.81181815073111}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners == null) {\nreturn;\n}\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener != null) {\nremoveTargetChildListener(path, targetListener);\n}\nif (listeners.isEmpty()) {\nchildListeners.remove(path);\n}\n}", "CodeBleu_score": 79.95143890248788}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\tConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\nif (listeners != null) {\nTargetChildListener targetListener = listeners.remove(listener);\nif (targetListener != null) {\nremoveTargetChildListener(path, targetListener);\n}\n}\n}", "CodeBleu_score": 88.39787336515684}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"Invalid zhandle_t pointer\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tif (QCONF_OK != lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != lock_ht_remove(_ht_handle_idchost, _ht_hi_mutex, htkey)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != lock_ht_remove(_ht_idchost_handle, _ht_ih_mutex, idc)) return QCONF_ERR_OTHER;\n\tif (NULL != zh) zookeeper_close(zh);\n\n\tdeserialize_from_idc_host(idc, host);\n\tzh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tinit_env_for_zk(zh, idc, host);\n\treturn QCONF_OK;\n}", "CodeBleu_score": 60.79174548415952}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) {\n\t\tLOG_ERR(\"Invalid zookeeper handle!\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tstring idc_host, idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tif (QCONF_OK != lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc_host)) return QCONF_ERR_OTHER;\n\tdeserialize_from_idc_host(idc_host, idc, host);\n\tif (QCONF_OK != lock_ht_delete(_ht_handle_idchost, _ht_hi_mutex, htkey)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != lock_ht_delete(_ht_idchost_handle, _ht_ih_mutex, idc_host)) return QCONF_ERR_OTHER;\n\tif (0 != zookeeper_close(zh)) {\n\t\tLOG_ERR(\"Failed to close zookeeper handle!\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tzh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tinit_env_for_zk(zh, idc_host, idc);\n\t// reset the table watcher\n\t_finish_process_tbl_sleep_setting = true;\n\treturn QCONF_OK;\n}", "CodeBleu_score": 68.85424309450252}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (NULL == zh) return QCONF_ERR_OTHER;\n\tstring idc, host;\n\tunsigned long htkey = reinterpret_cast<unsigned long>(zh);\n\tif (QCONF_OK != lock_ht_find(_ht_handle_idchost, _ht_hi_mutex, htkey, idc)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != lock_ht_delete(_ht_handle_idchost, _ht_hi_mutex, htkey)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != lock_ht_delete(_ht_idchost_handle, _ht_ih_mutex, idc)) return QCONF_ERR_OTHER;\n\tif (QCONF_OK != zookeeper_close(zh)) return QCONF_ERR_OTHER;\n\tdeserialize_from_idc_host(idc, host);\n\tzh = zookeeper_init(host.c_str(), global_watcher, _recv_timeout, NULL, NULL, 0);\n\tif (NULL == zh) {\n\t\tLOG_ERR(\"Failed to initial zookeeper. host:%s timeout:%d\", host.c_str(), _recv_timeout);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tinit_env_for_zk(zh, idc, host);\n\t// reset the table watcher\n\t_finish_process_tbl_sleep_setting = true;\n\treturn QCONF_OK;\n}", "CodeBleu_score": 60.635881110509104}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t#ifdef QCONF_CURL_ENABLE\n    string notify_node = get_notify_node_path(idc);\n    int ret = zookeeper_exists(zh, notify_node.c_str(), 0, NULL);\n    if (ZOK == ret)\n    {\n        LOG_INFO(\\\"Notify node:%s exists. Start to watch it.\\\",\n                 notify_node.c_str());\n        ret = zookeeper_aexists(zh, notify_node.c_str(), global_watcher, NULL, &g_notify_node_stat);\n        if (ZOK != ret)\n        {\n            LOG_ERR(\\\"Failed to aexists notify node:%s. ret:%d\\\",\n                    notify_node.c_str(), ret);\n        }\n    }\n    else\n    {\n        LOG_ERR(\\\"Notify node:%s does not exist. ret:%d\\\",\n                notify_node.c_str(), ret);\n    }\n#endif\n    lock_ht_insert(_ht_handle_idchost, _ht_hi_mutex, reinterpret_cast<unsigned long>(zh), idc_host);\n    lock_ht_insert(_ht_idchost_handle, _ht_ih_mutex, idc_host, zh);\n}", "CodeBleu_score": 48.895703330894705}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t#ifdef QCONF_DEBUG_ON\n    string host;\n    if (QCONF_OK != get_idc_conf(idc, host))\n    {\n        LOG_ERR(\\\"Failed to get host by idc:%s\\\", idc.c_str());\n        return;\n    }\n    if (idc_host != host)\n    {\n        LOG_ERR(\\\"idc_host:%s is not equal to host:%s\\\", idc_host.c_str(), host.c_str());\n        return;\n    }\n#endif\n    string notify_path = _notify_path + \\\"/\\\" + idc;\n    int ret = zoo_exists(zh, notify_path.c_str(), NULL, NULL);\n    switch (ret)\n    {\n    case ZOK:\n        LOG_INFO(\\\"Already registered. idc:%s host:%s\\\", idc.c_str(), idc_host.c_str());\n        break;\n    case ZNONODE:\n        LOG_INFO(\\\"Registering. idc:%s host:%s\\\", idc.c_str(), idc_host.c_str());\n        ret = zoo_create(zh, notify_path.c_str(), \\\"\\\", 0, ZOO_OPEN_ACL_UNSAFE, ZOO_EPHEMERAL);\n        if (ZOK != ret)\n        {\n            LOG_ERR(\\\"Failed to register. idc:%s host:%s ret:%d\\\", idc.c_str(), idc_host.c_str(), ret);\n        }\n        break;\n    case ZOK:\n        LOG_ERR(\\\"Already registered. idc:%s host:%s\\\", idc.c_str(), idc_host.c_str());\n        break;\n    default:\n        LOG_ERR(\\\"Failed to register. idc:%s host:%s ret:%d\\\", idc.c_str(), idc_host.c_str(), ret);\n        break;\n    }\n}", "CodeBleu_score": 32.34457667726974}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t", "CodeBleu_score": 4.2583564394715525}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    return \"%s:%s\" % (username, b64encode(hashlib.sha1(\"%s:%s\" % (username, password)).digest()).decode(\"utf-8\"))\n", "CodeBleu_score": 20.44870387595118}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \":\" + b64encode(hashlib.sha1(password).digest()).decode(\"utf-8\")\n\n", "CodeBleu_score": 27.627971179876265}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \\\":\\\" + b64encode(hashlib.sha1(password).digest()).decode()\n\n", "CodeBleu_score": 17.598660106574037}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.path + self.lock\n    try:\n        lock_data, _ = self.client.retry(self.client.get, lock_path)\n        return lock_data == self.id\n    except NoNodeError:\n        return False\n", "CodeBleu_score": 49.204992651308}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.processing_element[0]\n        lock_value = self.client.retry(self.client.get, lock_path)[0]\n        return lock_value == self.id\n\n", "CodeBleu_score": 44.93844459887159}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        self.client.sync(self._lock_path)\n        lock_value, _ = self.client.get(self._lock_path)\n        return lock_value == self.id\n\n", "CodeBleu_score": 37.8548609214761}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        with self.client.transaction() as transaction:\n            transaction.delete(lock_path)\n            transaction.delete(self.processing_element[0])\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 59.66608516789109}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        value, stat = self.client.retry(self.client.get, lock_path)\n        if value == self.id:\n            with self.client.transaction() as transaction:\n                transaction.delete(lock_path)\n                transaction.delete(self.processing_element[0])\n            self.processing_element = None\n            return True\n    return False\n\n", "CodeBleu_score": 59.02720159029814}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        with self.client.transaction() as transaction:\n            transaction.delete(lock_path)\n            transaction.delete(self.processing_element[0])\n        self.processing_element = None\n        return True\n    else:\n        return False\n", "CodeBleu_score": 59.66608516789109}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    self.logger.log(BLATHER, \\\"Reading from %s\\\", self._socket)\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except Exception as e:\n        self.logger.exception(\\\"Exception during read header: %s\\\", e)\n        return\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \\\"Received ping response\\\")\n        self._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        self.logger.debug(\\\"Received auth response\\\")\n        if header.err:\n            self.logger.error(\\\"Authentication failed: %s\\\", header.err)\n            self._state = KeeperState.AUTH_FAILED\n            self.handler.dispatch_callback(Callback(\\\"authentication\\\", None, (e,)))\n        else:\n            self.logger.debug(\\\"Authentication successful\\\")\n            self._state = KeeperState.CONNECTED\n            self.handler.dispatch_callback(Callback(\\\"authentication\\\", None, ()))\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 53.13526698028329}, {"code": "def _read_socket(self, read_timeout)\n\t\n    # Read the header\n    header, buffer, offset = self._read_header(read_timeout)\n    xid = header.xid\n\n    # Process the header's xid\n    if xid == PING_XID:\n        self.logger.log(\n            BLATHER,\n            \\\"Received ping response from server %s\\\",\n            self._server_id,\n        )\n        self._outstanding_ping = False\n    elif xid == AUTH_XID:\n        self.logger.log(\n            BLATHER,\n            \\\"Received authentication response from server %s\\\",\n            self._server_id,\n        )\n        if header.err:\n            self._auth_in_progress = False\n            self._auth_failed = True\n            self.handler.dispatch_callback(\n                Callback(\\\"auth\\\", self._auth_future, (None,))\n            )\n        else:\n            self._auth_in_progress = False\n            self._auth_failed = False\n            self.handler.dispatch_callback(\n                Callback(\\\"auth\\\", self._auth_future, (True,))\n            )\n    elif xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self.logger.log(\n            BLATHER,\n            \\\"Received response(xid=%s) from server %s: %r\\\",\n            xid,\n            self._server_id,\n            header,\n        )\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 39.010973403679586}, {"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    self.logger.debug(\\\"_read_socket: entering\\\")\n    while True:\n        try:\n            header, buffer, offset = self._read_header(read_timeout)\n        except ConnectionDropped as e:\n            self.logger.debug(\\\"_read_socket: Connection dropped: %s\\\", e)\n            return\n        except self.handler.timeout_exception:\n            self.logger.debug(\\\"_read_socket: Read timed out\\\")\n            return\n\n        if header.xid == PING_XID:\n            self.logger.debug(\\\"_read_socket: Received PING\\\")\n            client._outstanding_pings = False\n            continue\n\n        if header.xid == AUTH_XID:\n            self.logger.debug(\\\"_read_socket: Received AUTH response\\\")\n            if header.err:\n                exc = EXCEPTIONS[header.err]()\n                self.logger.debug(\\\"_read_socket: Error received: %s\\\", exc)\n                client._auth_in_progress = False\n                client._session_id = None\n                client._pending.clear()\n                client._reset_state()\n                client.handler.dispatch_callback(Callback(\\\"disconnected\\\", exc))\n                return\n            client._auth_in_progress = False\n            client._session_id = header.session\n            self.logger.debug(\\\"_read_socket: Received session id: %s\\\", client._session_id)\n            client.handler.dispatch_callback(Callback(\\\"connected\\\", client))\n            continue\n\n        if header.xid == WATCH_XID:\n            self.logger.debug(\\\"_read_socket: Received WATCH event\\\")\n            self._read_watch_event(buffer, offset)\n            continue\n\n        if header.xid not in client._pending:\n            self.logger.debug(\\\"_read_socket: Received unknown xid: %s\\\", header.xid)\n            continue\n\n        request, async_object, xid = client._pending.popleft()\n        if header.zxid and header.zxid > 0:\n            client.last_zxid = header.zxid\n        if header.xid != xid:\n            exc = RuntimeError(\n                \\\"xids do not match, expected %r \\\" \\\"received %r\\\", xid, header.xid\n            )\n            async_object.set_exception(exc)\n            raise exc\n\n        # Determine if its an exists request and a no node", "CodeBleu_score": 46.07432682207387}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.debug(\\\"Starting zk_loop\\\")\n    self.connection_stopped.clear()\n    try:\n        self._connect(self.retry_sleeper)\n    except Exception:\n        self.logger.exception(\\\"Unable to connect to Zookeeper, retrying in %r seconds\\\", self.retry_sleeper.seconds())\n        self.retry_sleeper.sleep()\n        self._connect(self.retry_sleeper)\n    self.connection_stopped.set()\n    self.handler.dispatch_callback(Callback(\\\"state\\\", self, (KeeperState.CLOSED,)))\n    self.logger.debug(\\\"Stopping zk_loop\\\")\n\n", "CodeBleu_score": 38.86964769343034}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\\\"Starting ZK connection\\\")\n    self.connection_stopped.clear()\n    self.handler.connection_created(self)\n    while not self._stopped.is_set():\n        try:\n            self._connect()\n        except Exception as e:\n            self.logger.exception(\\\"Unable to connect to Zookeeper: %s\\\", e)\n            self.handler.connection_dropped(self)\n            if self._stopped.wait(self._session_timeout / 2.0):\n                break\n        else:\n            self.logger.info(\\\"Connected to Zookeeper\\\")\n            self.handler.connection_made(self)\n            self.handler.connection_lost(self)\n    self.connection_stopped.set()\n    self.handler.connection_closed(self)\n    self.logger.info(\\\"ZK connection stopped\\\")\n\n\n\n\n", "CodeBleu_score": 39.83566229194938}, {"code": "def zk_loop(self)\n\t\n    self.logger.debug(\\\"Starting ZK loop\\\")\n    self.connection_stopped.clear()\n    self.handler.before_loop()\n    self.last_zxid = -1\n    self.session_id = 0\n    self.xid = 0\n    self.session_passwd = <PASSWORD>\n    self.session_timeout = 30000\n    self.pinger = None\n    self.stopped = False\n    self.connected = False\n    self.connecting = False\n    self.last_read = 0\n    self.last_write = 0\n    self.last_cxid = 0\n    self.last_zxid = 0\n    self.session_passwd = <PASSWORD>\n    self.session_timeout = 30000\n    self.session_id = 0\n    self.ping_interval = 10000\n    self.ping_timeout = 60000\n    self.last_ping = 0\n    self.last_pong = 0\n    self.last_ping_txid = 0\n    self.last_ping_zxid = 0\n    self.last_pong_zxid = 0\n    self.last_pong_txid = 0\n    self.last_ping_sent = 0\n    self.last_pong_received = 0\n    self.last_ping_interval = 10000\n    self.last_ping_timeout = 60000\n    self.last_ping_outstanding = False\n    self.last_ping_xid = 0\n    self.last_ping_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = 0\n    self.last_pong_sent = 0\n    self.last_pong_received = ", "CodeBleu_score": 19.395665750919743}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = bisect.bisect_left(members, identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 33.38376432132335}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = bisect.bisect(members, identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 33.26886843201298}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    # make sure our barrier parent node exists\n    if not self.assured_path:\n        self.client.ensure_path(self.path)\n        self.assured_path = True\n\n    try:\n        self.client.retry(self._inner_leave)\n        self.participating = False\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n        self.participating = False\n\n", "CodeBleu_score": 63.064637359110556}, {"code": "def leave(self)\n\t\n    # make sure our barrier parent node exists\n    if not self.assured_path:\n        self.client.ensure_path(self.path)\n        self.assured_path = True\n\n    ready = self.client.handler.event_object()\n\n    try:\n        self.client.create(\n            self.create_path,\n            self._identifier.encode(\"utf-8\"),\n            ephemeral=True,\n        )\n    except NodeExistsError:\n        pass\n\n    def created(event):\n        if event.type == EventType.CREATED:\n            ready.set()\n\n    self.client.exists(self.path + \"/ready\", watch=created)\n\n    children = self.client.get_children(self.path)\n\n    if len(children) < self.num_clients:\n        ready.wait()\n    else:\n        self.client.ensure_path(self.path + \"/ready\")\n    return True\n\n", "CodeBleu_score": 35.94576378561223}, {"code": "def leave(self)\n\t\n    # make sure our barrier parent node exists\n    if not self.assured_path:\n        self.client.ensure_path(self.path)\n        self.assured_path = True\n\n    try:\n        self.client.retry(self._inner_leave)\n    except KazooException:\n        # We failed to leave, best effort cleanup\n        self._best_effort_cleanup()\n    self.participating = False\n\n", "CodeBleu_score": 74.90468306397258}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\tMap<String, Object> map = new HashMap<>();\n\ttry {\n\t\tboolean status = hdfsOverFtpServer.statusServer();\n\t\tif (!status) {\n\t\t\thdfsOverFtpServer.startServer();\n\t\t\treturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\");\n\t\t} else {\n\t\t\treturn new Result(true, map, \"FTP \u670d\u52a1\u5df2\u7ecf\u542f\u52a8\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, map, \"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 56.145975059950516}, {"code": "public Result start(){\n\tMap map = new HashMap();\ntry {\nboolean status = hdfsOverFtpServer.statusServer();\nif (!status) {\nhdfsOverFtpServer.startServer();\n}\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u72b6\u6001\u83b7\u53d6\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nmap.put(\"is_running\", false);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u72b6\u6001\u83b7\u53d6\u6210\u529f\");\n}\n}", "CodeBleu_score": 51.17050885682235}, {"code": "public Result start(){\n\tMap map = new HashMap<>();\ntry {\nboolean status = hdfsOverFtpServer.statusServer();\nif (status) {\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u5df2\u7ecf\u5904\u4e8e\u8fd0\u884c\u72b6\u6001\uff0c\u65e0\u9700\u91cd\u590d\u542f\u52a8\");\n}\nhdfsOverFtpServer.startServer();\nstatus = hdfsOverFtpServer.statusServer();\nmap.put(\"is_running\", status);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nmap.put(\"is_running\", false);\nreturn new Result(true, map, \"FTP \u670d\u52a1\u542f\u52a8\u5931\u8d25\");\n}\n}", "CodeBleu_score": 48.419599564796165}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif(status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 89.60593044836757}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif (status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 84.54686376978196}, {"code": "public Result stop(){\n\ttry {\nboolean status = hdfsOverFtpServer.statusServer();\nif (status) {\nhdfsOverFtpServer.stopServer();\n}\nreturn new Result(true, \"FTP \u670d\u52a1\u505c\u6b62\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"FTP \u670d\u52a1\u505c\u6b62\u5931\u8d25\");\n}\n}", "CodeBleu_score": 84.54686376978196}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities == null) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\trequest = authority.authorize(request);\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t}\n\treturn request;\n}", "CodeBleu_score": 41.93340299236391}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities == null) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tAuthorizationRequest newRequest = authority.authorize(request);\n\t\tif (newRequest != null) {\n\t\t\treturn newRequest;\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.367469860954998}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tfor (Authority authority : authorities) {\n\t\tAuthorizationRequest newRequest = authority.authorize(request);\n\t\tif (newRequest != null) {\n\t\t\trequest = newRequest;\n\t\t}\n\t}\n\treturn request;\n}", "CodeBleu_score": 20.493594194644153}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 88.87274151549165}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tlog.debug(\\\"mkdir: \\\" + fullPath + \\\" failed\\\", e);\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 71.2065178267787}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.mkdirs(fullPath);\n\n\t\treturn true;\n\n\t} catch (IOException e) {\n\t\tlog.debug(\\\"mkdir failed: \\\" + fullPath, e);\n\n\t\treturn false;\n\n\t}\n\n}", "CodeBleu_score": 71.7273237257707}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 89.40143081256369}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 89.40143081256369}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 89.40143081256369}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.rename(fullPath, new Path(ftpFile.getAbsolutePath()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 63.81911890023978}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.rename(fullPath, new Path(ftpFile.getParent().getAbsolutePath() + ftpFile.getName()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 68.47999606392693}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = HdfsOverFtpSystem.getDfs();\n\t\tfs.rename(fullPath, new Path(ftpFile.getParent().getAbsolutePath(), getName()));\n//\t\tfs.setOwner(path, user.getName(), user.getMainGroup());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 61.10715990301632}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] files = dfs.listStatus(fullPath);\n\n\t\tlog.debug(\\\"listFiles(): \\\" + fullPath);\n\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\n\t\tfor (FileStatus file : files) {\n\n\t\t\tString fileName = file.getPath().getName();\n\n\t\t\tif (fileName.startsWith(\\\".\\\")) {\n\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tString fullFileName = fullPath + File.separator + fileName;\n\n\t\t\tlog.debug(\\\"listFiles(): \\\" + fullFileName);\n\n\t\t\tlist.add(new HdfsFileObject(homePath.toString(), fullFileName, user));\n\n\t\t}\n\n\t\treturn Collections.unmodifiableList(list);\n\n\t} catch (IOException e) {\n\n\t\tlog.debug(\\\"listFiles(): \\\" + fullPath + \\\" is not dir\\\", e);\n\n\t\treturn null;\n\n\t}\n\n}", "CodeBleu_score": 32.10323424788945}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] files = dfs.listStatus(fullPath);\n\n\t\tList<FtpFile> fileList = new ArrayList<FtpFile>();\n\n\t\tfor (FileStatus file : files) {\n\n\t\t\tString fileName = file.getPath().toString();\n\n\t\t\tString name = fileName.substring(fileName.lastIndexOf(\\\"/\\\") + 1);\n\n\t\t\tif (name.length() == 0) {\n\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tif (name.charAt(0) == \\'.\\') {\n\n\t\t\t\tcontinue;\n\n\t\t\t}\n\n\t\t\tHdfsFileObject fileObject = new HdfsFileObject(homePath.toString(), fileName, user);\n\n\t\t\tfileList.add(fileObject);\n\n\t\t}\n\n\t\treturn Collections.unmodifiableList(fileList);\n\n\t} catch (IOException e) {\n\n\t\te.printStackTrace();\n\n\t\treturn null;\n\n\t}\n\n}", "CodeBleu_score": 41.56047470631001}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tlog.debug(\\\"listFiles(): \\\" + fullPath);\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tFileStatus[] files = dfs.listStatus(fullPath);\n\t\tList<FtpFile> fileList = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tString name = file.getPath().getName();\n\t\t\tif (!name.startsWith(\\\".\\\")) {\n\t\t\t\tString fullName = homePath.toString() + file.getPath().toString();\n\t\t\t\tif (file.isDir()) {\n\t\t\t\t\tfullName += \\\"/\\\";\n\t\t\t\t}\n\t\t\t\tfileList.add(new HdfsFileObject(fullName, user));\n\t\t\t}\n\t\t}\n\t\treturn Collections.unmodifiableList(fileList);\n\t} catch (IOException e) {\n\t\tlog.error(\\\"listFiles(): \\\" + fullPath + \\\" failed\\\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 22.343684569136006}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\n\t// check if the file exists\n\tif (!userDataFile.exists()) {\n\t\tthrow new FtpServerConfigurationException(\\\"User data file does not exist: \\\" + userDataFile.getAbsolutePath());\n\t}\n\n\t// load the properties\n\ttry {\n\t\tuserDataProp = new BaseProperties();\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Failed to load user data file: \\\" + userDataFile.getAbsolutePath(), e);\n\t}\n\n\t// check if there are any deprecated properties\n\tProperties deprecatedProps = new Properties();\n\tfor (Object key : userDataProp.keySet()) {\n\t\tString name = (String) key;\n\t\tif (name.startsWith(DEPRECATED_PREFIX)) {\n\t\t\tdeprecatedProps.setProperty(name.substring(DEPRECATED_PREFIX.length()), (String) userDataProp.get(name));\n\t\t}\n\t}\n\n\t// convert deprecated properties\n\tconvertDeprecatedProperties(deprecatedProps);\n\n\t// check if there are any properties that are not prefixed with PREFIX\n\tProperties unknownProps = new Properties();\n\tfor (Object key : userDataProp.keySet()) {\n\t\tString name = (String) key;\n\t\tif (!name.startsWith(PREFIX)) {\n\t\t\tunknownProps.setProperty(name, (String) userDataProp.get(name));\n\t\t}\n\t}\n\n\t// if there are any unknown properties, throw an exception\n\tif (unknownProps.size() > 0) {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tsb.append(\\\"Unknown properties in user data file: \\\" + userDataFile.getAbsolutePath());\n\t\tsb.append(\\\"\\\n\\\");\n\t\tfor (Object key : unknownProps.keySet()) {\n\t\t\tsb.append(\\\"\\\\t\\\" + key + \\\" = \\\" + unknownProps.get(key) + \\\"\\\n\\\");\n\t\t}\n\t\tthrow new FtpServerConfigurationException(sb.toString());\n\t}\n\n\t// set configured to true\n\tisConfigured = true;\n}", "CodeBleu_score": 18.488374639754767}, {"code": "public void configure(){\n\t\tLOG.debug(\\\"Configuring user manager\\\");\n\n\t// check if user data file exists\n\tif (!userDataFile.exists()) {\n\t\tthrow new FtpServerConfigurationException(\\\"User data file does not exist: \\\" + userDataFile);\n\t}\n\n\t// load the user data file\n\ttry {\n\t\tuserDataProp = new BaseProperties();\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Failed to load user data file: \\\" + userDataFile, e);\n\t}\n\n\t// convert any deprecated properties\n\tconvertDeprecatedProperties();\n\n\t// set the configured state\n\tisConfigured = true;\n}", "CodeBleu_score": 26.135255374046018}, {"code": "public void configure(){\n\t\tif (isConfigured) {\n\t\treturn;\n\t}\n\n\tif (!userDataFile.exists()) {\n\t\tthrow new FtpServerConfigurationException(\\\"User data file does not exist: \\\" + userDataFile);\n\t}\n\n\ttry {\n\t\tuserDataProp = new BaseProperties();\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\\\"Failed to load user data file: \\\" + userDataFile, e);\n\t}\n\n\tconvertDeprecatedNames();\n\n\tisConfigured = true;\n}", "CodeBleu_score": 27.55405850688607}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\t// create parent directory if necessary\n\tFile parentDir = userDataFile.getParentFile();\n\tif (!parentDir.exists()) {\n\t\t\tif (!parentDir.mkdirs()) {\n\t\t\t\tLOG.warn(\\\"Failed to create parent directory for user data file \\\"\n\t\t\t\t\t\t+ userDataFile.getAbsolutePath());\n\t\t\t\tthrow new FtpException(\\\"Failed to create parent directory for user data file \\\"\n\t\t\t\t\t\t+ userDataFile.getAbsolutePath());\n\t\t\t}\n\t\t}\n\n\t// write to file\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, \\\"User data\\\");\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Failed to write user data to \\\"\n\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\\\"Failed to write user data to \\\"\n\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 33.132573811476426}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile parent = userDataFile.getParentFile();\n\tif (!parent.exists()) {\n\t\t\tif (!parent.mkdirs()) {\n\t\t\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\t\t\\\"Failed to create directory : \\\"\n\t\t\t\t\t\t\t\t+ parent.getAbsolutePath());\n\t\t\t}\n\t\t}\n\t\tFileOutputStream fos = null;\n\t\ttry {\n\t\t\tfos = new FileOutputStream(userDataFile);\n\t\t\tuserDataProp.store(fos, \\\"FtpServer User Data\\\");\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\\\"Error storing user data file : \\\"\n\t\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t\t\tthrow new FtpException(\\\"Failed to save user data\\\");\n\t\t} finally {\n\t\t\tIoUtils.close(fos);\n\t\t}\n\t}", "CodeBleu_score": 37.610004752735556}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile parentFile = userDataFile.getParentFile();\n\n\tif (!parentFile.exists()) {\n\t\t\tLOG.debug(\\\"Creating parent directory for user data file : \\\"\n\t\t\t\t\t+ parentFile.getAbsolutePath());\n\t\t\tif (!parentFile.mkdirs()) {\n\t\t\t\tLOG.error(\\\"Failed to create parent directory for user data file : \\\"\n\t\t\t\t\t\t+ parentFile.getAbsolutePath());\n\t\t\t\tthrow new FtpException(\\\"Failed to create parent directory for user data file : \\\"\n\t\t\t\t\t\t+ parentFile.getAbsolutePath());\n\t\t\t}\n\t\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserDataProp.store(fos, \\\"FtpServer User Data\\\");\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Error saving user data file : \\\"\n\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\\\"Error saving user data file : \\\"\n\t\t\t\t+ userDataFile.getAbsolutePath(), e);\n\t} finally {\n\t\tIoUtils.close(fos);\n\t}\n}", "CodeBleu_score": 32.187577917803736}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 80.10398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.setPasswordEncryptor(new Md5PasswordEncryptor());\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 75.78726691170789}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManagerFactory = new HdfsUserManager();\n\t\tuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n\t\tuserManagerFactory.setPasswordEncryptor(new Md5PasswordEncryptor());\n\t\tuserManagerFactory.delete(user);\n\t\treturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 74.96918470165754}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\\\"open: path={}, bufferSize={}\\\", path, bufferSize);\n\n\t// get qualified path\n\n\tPath qualifiedPath = makeQualified(path);\n\n\t// open file\n\n\tFSDataInputStream inputStream = seaweedFileSystemStore.openFileForRead(qualifiedPath);\n\n\t// wrap input stream with buffered input stream\n\n\treturn new FSDataInputStream(new BufferedInputStream(inputStream, bufferSize));\n\n}", "CodeBleu_score": 23.625136366677875}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\\\"open: {}, bufferSize: {}\\\", path, bufferSize);\n\n\t// qualify the path\n\tpath = makeQualified(path);\n\n\t// open the file\n\tFSDataInputStream fsDataInputStream = null;\n\ttry {\n\t\tfsDataInputStream = seaweedFileSystemStore.open(path, bufferSize);\n\t} catch (FileNotFoundException e) {\n\t\tLOG.warn(\\\"File not found: {}\\\", path);\n\t} catch (IOException e) {\n\t\tLOG.warn(\\\"Error opening file: {}\\\", path, e);\n\t}\n\treturn fsDataInputStream;\n}", "CodeBleu_score": 37.0727248218056}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\\\"open: \\\" + path + \\\" bufferSize: \\\" + bufferSize);\n\n\t// check if path is qualified\n\tif (path == null) {\n\t\tthrow new NullPointerException(\\\"Path is null\\\");\n\t}\n\tif (!path.isAbsolute()) {\n\t\tthrow new IllegalArgumentException(\\\"Path is not absolute: \\\" + path);\n\t}\n\n\t// get qualified path\n\tpath = makeQualified(path);\n\n\t// open file\n\tFSDataInputStream in = null;\n\ttry {\n\t\tin = seaweedFileSystemStore.open(path, bufferSize);\n\t} catch (FileNotFoundException fnfe) {\n\t\tLOG.warn(\\\"open: \\\" + path + \\\" not found\\\");\n\t}\n\n\treturn in;\n}", "CodeBleu_score": 16.836922876713157}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\n//        LOG.debug(\\\"rename src: {} dst: {}\\\", src, dst);\n\n//\n//        src = qualify(src);\n\n//        dst = qualify(dst);\n\n//\n//        if (src.equals(dst)) {\n\n//            return true;\n\n//        }\n\n//\n//        if (src.getParent() == null) {\n\n//            return false;\n\n//        }\n\n//\n//        // Check if the destination exists and is a directory. If so, adjust the destination path.\n\n//        Path qualifiedDst = dst;\n\n//        if (getFileStatus(dst).isDirectory()) {\n\n//            qualifiedDst = new Path(qualifiedDst, src.getName());\n\n//        }\n\n//\n//        // Rename the source to the destination.\n\n//        boolean success = seaweedFileSystemStore.rename(src, qualifiedDst);\n\n//\n//        LOG.debug(\\\"rename src: {} dst: {} success: {}\\\", src, dst, success);\n\n//\n//        return success;\n\n//    }", "CodeBleu_score": 3.957500776646815}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\\\"rename src: {} dst: {}\\\", src, dst);\n\n\nif (src.equals(dst)) {\n\nreturn true;\n\n}\n\n\nif (src.getParent() == null) {\n\nLOG.warn(\\\"rename cannot rename root path: {} to: {}\\\", src, dst);\n\nreturn false;\n\n}\n\n\n// check if the source exists\n\nFileStatus srcStatus = getFileStatus(src);\n\nif (srcStatus == null) {\n\nLOG.warn(\\\"rename cannot rename missing path: {} to: {}\\\", src, dst);\n\nreturn false;\n\n}\n\n\n// check if the destination exists\n\nFileStatus dstStatus = getFileStatus(dst);\n\nif (dstStatus != null) {\n\nif (dstStatus.isDirectory()) {\n\ndst = new Path(dst, src.getName());\n\n}\n\n}\n\n\nsrc = qualify(src);\n\ndst = qualify(dst);\n\n\nLOG.debug(\\\"rename src: {} dst: {}\\\", src, dst);\n\n\ntry {\n\nseaweedFileSystemStore.rename(src, dst);\n\nreturn true;\n\n} catch (Exception ex) {\n\nLOG.warn(\\\"rename src: {} dst: {}\\\", src, dst, ex);\n\nreturn false;\n\n}\n\n}", "CodeBleu_score": 51.02656897514433}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\\\"rename src: {} dst: {}\\\", src, dst);\n\n\nif (src.equals(dst)) {\n\nreturn true;\n\n}\n\n\nPath qualifiedDst = qualify(dst);\n\n\n// check if the source is the root\n\nif (src.depth() == 0) {\n\nLOG.error(\\\"Cannot rename the root path\\\");\n\nreturn false;\n\n}\n\n\n// check if the source and destination are the same\n\nif (src.equals(qualifiedDst)) {\n\nLOG.error(\\\"Cannot rename a file to itself: src: {} dst: {}\\\", src, dst);\n\nreturn false;\n\n}\n\n\n// check if the destination exists and is a directory\n\nif (qualifiedDst.depth() > 0 && qualifiedDst.depth() == qualifiedDst.getNameCount()) {\n\nif (exists(qualifiedDst)) {\n\nif (!getFileStatus(qualifiedDst).isDirectory()) {\n\nLOG.error(\\\"Destination is not a directory: {}\\\", qualifiedDst);\n\nreturn false;\n\n}\n\n}\n\n}\n\n\n// qualify the source and destination paths\n\nPath qualifiedSrc = qualify(src);\n\n\n// perform the rename operation\n\ntry {\n\nseaweedFileSystemStore.rename(qualifiedSrc, qualifiedDst);\n\nreturn true;\n\n} catch (Exception ex) {\n\nLOG.warn(\\\"rename src: {} dst: {}\\\", src, dst, ex);\n\nreturn false;\n\n}\n\n}", "CodeBleu_score": 46.376636573266}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\tif (capability == null) {\nreturn false;\n}\ncapability = capability.toLowerCase(Locale.ENGLISH);\nreturn (capability.equals(\"hsync\") || capability.equals(\"hflush\"));\n}", "CodeBleu_score": 42.45257553942832}, {"code": "public boolean hasCapability(String capability){\n\t\treturn capability.toLowerCase(Locale.ENGLISH).equals(\"hsync\") || capability.toLowerCase(Locale.ENGLISH).equals(\"hflush\");\n}", "CodeBleu_score": 40.644764266481616}, {"code": "public boolean hasCapability(String capability){\n\treturn capability.toLowerCase(Locale.US).equals(\"hsync\") || capability.toLowerCase(Locale.US).equals(\"hflush\");\n}", "CodeBleu_score": 39.49206048180111}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < this.lastFlushOffset) {\n\t\treturn;\n\t}\n\tif (this.lastError != null) {\n\t\tthrow new IOException(this.lastError.getMessage(), this.lastError);\n\t}\n\tif (offset < this.lastTotalAppendOffset) {\n\t\treturn;\n\t}\n\tlong appendOffset = this.lastTotalAppendOffset;\n\tif (offset > appendOffset) {\n\t\t// write out the data\n\t\tfinal long writeSize = offset - appendOffset;\n\t\tLOG.debug(\\\"Flushing {} bytes to service, starting from offset {}\\\", writeSize, appendOffset);\n        // TODO: use a buffer pool\n\t\tfinal ByteBuffer writeBuffer = ByteBuffer.allocate((int) writeSize);\n        this.filerClient.append(this.path, writeBuffer, appendOffset, this.replication, this.collection);\n        appendOffset += writeSize;\n        this.lastTotalAppendOffset = appendOffset;\n    }\n    // write out the metadata\n    if (this.shouldSaveMetadata) {\n        if (this.entry.getAttributes().getFileSize() != this.lastTotalAppendOffset) {\n            this.entry.getAttributes().setFileSize(this.lastTotalAppendOffset);\n        }\n        this.filerClient.updateEntry(this.path, this.entry);\n    }\n    this.lastFlushOffset = offset;\n}", "CodeBleu_score": 35.580911229336294}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < lastFlushOffset) {\n\t\treturn;\n\t}\n\n\tif (offset == lastFlushOffset) {\n\t\treturn;\n\t}\n\n\tif (offset > lastFlushOffset) {\n\t\tLOG.debug(\\\"Flushing bytes from offset \\\" + offset + \\\" to \\\" + lastFlushOffset);\n        }\n        try {\n            flushBuffer();\n        }\n        catch (IOException e) {\n            throw e;\n        }\n        catch (Exception e) {\n            throw new IOException(\\\"Failed to flush bytes to service\\\", e);\n        }\n        finally {\n            lastFlushOffset = offset;\n        }\n    }", "CodeBleu_score": 32.13956595116595}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\n//        System.out.println(\\\"submitWriteBufferToService: \\\" + path + \\\" \\\" + writePosition);\n\n        final int bufferLength = bufferToWrite.position();\n        if (bufferLength == 0) {\n\n            return 0;\n\n        }\n\n\n        final ByteBuffer bufferToRelease = bufferToWrite;\n        final long writeOffset = writePosition;\n\n\n        final WriteOperation writeOperation = new WriteOperation(bufferToWrite, writeOffset);\n\n        writeOperations.add(writeOperation);\n\n\n        completionService.submit(new Callable<Void>() {\n\n            @Override\n\n            public Void call() throws Exception {\n\n                try {\n\n                    if (bufferToWrite.hasArray()) {\n\n                        filerClient.append(path, bufferToWrite.array(), writeOffset, bufferLength);\n\n                    } else {\n\n                        byte[] buffer = new byte[bufferLength];\n\n                        bufferToWrite.get(buffer, 0, bufferLength);\n\n                        filerClient.append(path, buffer, writeOffset, bufferLength);\n\n                    }\n\n                    bufferToRelease.position(0);\n\n                    ByteBufferPool.release(bufferToRelease);\n\n                    writeOperations.remove(writeOperation);\n\n                    return null;\n\n                }\n\n                catch (Exception ex) {\n\n                    LOG.error(\\\"submitWriteBufferToService error: \\\" + path + \\\" \\\" + writeOffset, ex);\n\n                    lastError = new IOException(\\\"Failed to write to stream: \\\" + path + \\\" \\\" + writeOffset, ex);\n\n                    writeOperations.remove(writeOperation);\n\n                    throw ex;\n\n                }\n\n            }\n\n        });\n\n\n        return bufferLength;\n\n    }", "CodeBleu_score": 29.514980363114198}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\n//        if (bufferToWrite.position() == 0) {\n            return;\n        }\n\n\n        final byte[] data = new byte[bufferToWrite.position()];\n        bufferToWrite.flip();\n        bufferToWrite.get(data);\n        bufferToWrite.clear();\n\n        final WriteOperation writeOperation = new WriteOperation(data, writePosition, this.outputIndex);\n\n        writeOperations.add(writeOperation);\n\n        completionService.submit(new Callable<Void>() {\n\n            @Override\n\n            public Void call() throws Exception {\n\n                writeOperation.writeBuffer(filerClient, path, entry, replication, collection);\n\n                return null;\n\n            }\n\n        });\n\n        this.outputIndex += data.length;\n\n\n        return data.length;\n\n    }", "CodeBleu_score": 36.32321174264332}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tfinal int bufferLength = bufferToWrite.position();\n\tfinal byte[] buffer = new byte[bufferLength];\n\tbufferToWrite.flip();\n\tbufferToWrite.get(buffer, 0, bufferLength);\n\tbufferToWrite.clear();\n\n\tfinal Future<Void> writeTask = completionService.submit(new SeaweedWrite(path, buffer, writePosition, replication, collection));\n\n\twriteOperations.add(new WriteOperation(writePosition, bufferLength, writeTask));\n\n\treturn bufferLength;\n}", "CodeBleu_score": 33.15866531729779}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\ttry {\n    final Future<Void> job = completionService.take();\n    job.get();\n} catch (InterruptedException ex) {\n    throw new IOException(\\\"Interrupted while waiting for job to complete\\\", ex);\n} catch (ExecutionException ex) {\n    throw new IOException(\\\"Failed to complete job\\\", ex);\n}\n}", "CodeBleu_score": 26.6013350307185}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\twhile (true) {\n\t\t\tFuture<Void> future = completionService.poll();\n\t\t\tif (future == null) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tfuture.get();\n\t\t\t} catch (ExecutionException ex) {\n\t\t\t\tthrow new IOException(ex);\n\t\t\t}\n\t\t}\n\t} catch (InterruptedException ex) {\n\t\tthrow new IOException(ex);\n\t}\n}", "CodeBleu_score": 23.2330966258339}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\twhile (true) {\n\t\t\tFuture<Void> job = completionService.poll();\n\t\t\tif (job == null) {\n\t\t\t\tThread.sleep(100);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tjob.get();\n\t\t\t} catch (ExecutionException ex) {\n\t\t\t\tthrow new IOException(ex);\n\t\t\t}\n\t\t}\n\t} catch (InterruptedException ex) {\n\t\tthrow new IOException(ex);\n\t}\n}", "CodeBleu_score": 23.45425844689179}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\tmaybeThrowLastError();\n\nif (writeOperations.isEmpty()) {\nreturn;\n}\n\nWriteOperation writeOperation = writeOperations.peek();\nif (writeOperation.future.isDone()) {\ntry {\nwriteOperation.future.get();\n} catch (InterruptedException e) {\nlastError = (IOException) new InterruptedIOException(e.toString()).initCause(e);\nthrow lastError;\n} catch (ExecutionException e) {\nlastError = (IOException) new IOException(e.toString()).initCause(e);\nthrow lastError;\n}\n\n// Update the lastFlushOffset\nlastFlushOffset = writeOperation.lastFlushOffset + writeOperation.bytesLength;\n\n// Remove the completed write operation from the queue\nwriteOperations.remove();\n}\n}", "CodeBleu_score": 35.84246983181399}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\nwhile (!writeOperations.isEmpty()) {\nWriteOperation operation = writeOperations.peek();\nif (operation.getJob().isDone()) {\ntry {\noperation.getJob().get();\n} catch (ExecutionException e) {\nlastError = (IOException) new IOException(e.toString()).initCause(e);\nthrow lastError;\n} catch (InterruptedException e) {\nlastError = (IOException) new InterruptedIOException(e.toString()).initCause(e);\nthrow lastError;\n}\nwriteOperations.remove();\nposition += operation.getLength();\n} else {\nbreak;\n}\n}\n}", "CodeBleu_score": 37.556418436702856}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\twhile (!writeOperations.isEmpty()) {\nWriteOperation writeOperation = writeOperations.peek();\nif (writeOperation.getJob().isDone()) {\ntry {\nwriteOperation.getJob().get();\n} catch (ExecutionException e) {\nthrow new IOException(e.getCause());\n} catch (InterruptedException e) {\nthrow new IOException(e.getCause());\n}\nwriteOperations.remove();\nposition += writeOperation.getLength();\n} else {\nbreak;\n}\n}\n}", "CodeBleu_score": 31.02072938481486}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\\\"user can not be null\\\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\\\"user home directory can not be null\\\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 62.68288941416951}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\\\"User can't be null\\\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\\\"User home directory can't be null\\\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 52.136012643401564}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\\\"User may not be null\\\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\\\"User home directory may not be null\\\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 59.196762504479594}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be null\\\");\n\t}\n\tif (dir.equals(\\\"\\\")) {\n\t\treturn true;\n\t}\n\tif (dir.equals(\\\"..\\\")) {\n\t\tif (currPath.equals(File.separator)) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tcurrPath = new File(currPath).getParent();\n\t\t\treturn true;\n\t\t}\n\t}\n\tif (dir.startsWith(\\\"..\\\")) {\n\t\tthrow new IllegalArgumentException(\\\"Cannot change to parent of root\\\");\n\t}\n\tif (dir.startsWith(File.separator)) {\n\t\tcurrPath = dir;\n\t\treturn true;\n\t}\n\tcurrPath = currPath + File.separator + dir;\n\treturn true;\n}", "CodeBleu_score": 30.533084691613034}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be null\\\");\n\t}\n\tif (dir.equals(\\\"..\\\")) {\n\t\tString parentPath = File.separator;\n\t\tint lastSlash = currPath.lastIndexOf(File.separator);\n\t\tif (lastSlash > 0) {\n\t\t\tparentPath = currPath.substring(0, lastSlash);\n\t\t}\n\t\tcurrPath = parentPath;\n\t\treturn true;\n\t}\n\tif (dir.equals(\\\".\\\")) {\n\t\treturn true;\n\t}\n\tif (dir.startsWith(\\\"..\\\")) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be parent directory\\\");\n\t}\n\tif (dir.startsWith(\\\".\\\")) {\n\t\tdir = currPath + dir;\n\t}\n\tPath path = new Path(dir);\n\tif (hdfs.exists(path)) {\n\t\tif (hdfs.isDirectory(path)) {\n\t\t\tcurrPath = path.toString();\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\treturn false;\n}", "CodeBleu_score": 38.15251351466649}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir == null) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be null\\\");\n\t}\n\tif (dir.equals(\\\"..\\\")) {\n\t\tif (currPath.equals(File.separator)) {\n\t\t\treturn false;\n\t\t}\n\t\tint index = currPath.lastIndexOf(File.separator);\n\t\tif (index == 0) {\n\t\t\tcurrPath = File.separator;\n\t\t} else {\n\t\t\tcurrPath = currPath.substring(0, index);\n\t\t}\n\t\treturn true;\n\t} else if (dir.equals(\\\".\\\")) {\n\t\treturn true;\n\t} else if (dir.startsWith(\\\"..\\\")) {\n\t\tthrow new IllegalArgumentException(\\\"dir can not be parent directory\\\");\n\t} else if (dir.startsWith(\\\".\\\")) {\n\t\tdir = currPath + dir;\n\t} else {\n\t\tdir = currPath + File.separator + dir;\n\t}\n\tPath path = new Path(dir);\n\tif (hdfs.isDirectory(path)) {\n\t\tcurrPath = dir;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 36.554010242601734}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.conf = conf;\n\tString accessMode = conf.get(ACCESS_MODE, DEFAULT_ACCESS_MODE);\n\tif (accessMode.equals(DIRECT_ACCESS_MODE)) {\n\t\tLOG.info(\"Using direct access mode\");\n\t\tfilerClient = new FilerClient(host, port, grpcPort, conf);\n\t} else if (accessMode.equals(PUBLIC_URL_ACCESS_MODE)) {\n\t\tLOG.info(\"Using public URL access mode\");\n\t\tfilerClient = new FilerClient(host, port, grpcPort, conf);\n\t} else if (accessMode.equals(FILER_PROXY_ACCESS_MODE)) {\n\t\tLOG.info(\"Using filer proxy access mode\");\n\t\tfilerClient = new FilerClient(host, port, grpcPort, conf);\n\t} else {\n\t\tLOG.error(\"Unknown access mode: \" + accessMode);\n\t\tthrow new IllegalArgumentException(\"Unknown access mode: \" + accessMode);\n\t}\n}", "CodeBleu_score": 41.66367970116326}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\nthis.conf = conf;\n\n// create a new FilerClient\nthis.filerClient = new FilerClient(host, port, grpcPort);\n\n// set the access mode for the volume server\nString accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\nif (accessMode.equals(DIRECT_ACCESS_MODE)) {\nthis.filerClient.setFilerHost(host, port);\n} else if (accessMode.equals(PUBLIC_URL_ACCESS_MODE)) {\nthis.filerClient.setFilerHost(host, grpcPort);\n} else if (accessMode.equals(FILER_PROXY_ACCESS_MODE)) {\nthis.filerClient.setFilerHost(host, port);\n} else {\nLOG.error(\"Invalid access mode: \" + accessMode);\n}\n\n}", "CodeBleu_score": 45.20308856218425}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.conf = conf;\n\tString accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\n\tif (accessMode.equals(ACCESS_MODE_DIRECT)) {\n\t\tfilerClient.setDirectAccess(true);\n\t} else if (accessMode.equals(ACCESS_MODE_PUBLIC_URL)) {\n\t\tfilerClient.setDirectAccess(false);\n\t} else if (accessMode.equals(ACCESS_MODE_FILER_PROXY)) {\n\t\tfilerClient.setFilerGrpcAddress(conf.get(FILER_GRPC_ADDRESS_KEY));\n\t\tfilerClient.setFilerAddress(conf.get(FILER_ADDRESS_KEY));\n\t} else {\n\t\tthrow new IllegalArgumentException(\"Invalid access mode: \" + accessMode);\n\t}\n}", "CodeBleu_score": 43.00561259288983}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\\\"openFileForRead path: {}\\\", path);\n\n\tFilerProto.Entry entry = lookupEntry(path);\n\n\tif (entry == null) {\n\n\t\tthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n\n\t}\n\n\tLOG.debug(\\\"openFileForRead path:{} entry:{}\\\", path, entry);\n\n\treturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n\n}", "CodeBleu_score": 64.81373677319388}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\\\"openFileForRead path: {} statistics: {}\\\", path, statistics);\n\n    FilerProto.Entry entry = lookupEntry(path);\n    if (entry == null) {\n        throw new FileNotFoundException(\\\"File does not exist: \\\" + path);\n    }\n    LOG.debug(\\\"openFileForRead path:{} entry:{}\\\", path, entry);\n\n    return new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n}", "CodeBleu_score": 58.325608673079735}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\tLOG.debug(\\\"openFileForRead path: {}\\\", path);\n\n\tFilerProto.Entry entry = lookupEntry(path);\n\tif (entry == null) {\n\t\tthrow new FileNotFoundException(\\\"File does not exist: \\\" + path);\n\t}\n\tLOG.debug(\\\"openFileForRead path:{} entry:{}\\\", path, entry);\n\n\treturn new SeaweedHadoopInputStream(filerClient, path.toString(), entry, statistics);\n}", "CodeBleu_score": 64.81373677319388}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tsuper.setConf(conf);\n\thostName = \"localhost\";\n\ttry {\n\t\thostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tLOG.warn(\"Unable to determine local hostname, defaulting to 'localhost'\", e);\n\t}\n\tthreadsPerMap = conf.getInt(\"juicefs.bench.threadsPerMap\", 1);\n\tfilesPerThread = conf.getInt(\"juicefs.bench.filesPerThread\", 1);\n\tpool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 49.93291392292944}, {"code": "public void configure(JobConf conf){\n\t\ttry {\n\t\thostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tLOG.warn(\"Unable to retrieve local host name, defaulting to 'localhost'\", e);\n\t\thostName = \"localhost\";\n\t}\n\n\tthreadsPerMap = conf.getInt(\"juicefs.threadsPerMap\", 1);\n\tfilesPerThread = conf.getInt(\"juicefs.filesPerThread\", 1);\n\tpool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 50.67728374569472}, {"code": "public void configure(JobConf conf){\n\t\tsuper.setConf(conf);\n\ttry {\n\t\thostName = InetAddress.getLocalHost().getHostName();\n\t} catch (Exception e) {\n\t\tLOG.warn(\"Unable to get hostname, defaulting to 'localhost'\", e);\n\t\thostName = \"localhost\";\n\t}\n\tthreadsPerMap = conf.getInt(\"juicefs.bench.threads.per.map\", 1);\n\tfilesPerThread = conf.getInt(\"juicefs.bench.files.per.thread\", 1);\n\tpool = Executors.newFixedThreadPool(threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 53.372378898459374}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\tString host = uri.getHost();\n\tif (host == null) {\n\t\thost = \"\";\n\t}\n\tif (trashEmptier != null && trashEmptier.getHost().equals(host)) {\n\t\treturn;\n\t}\n\tsynchronized (trashEmptierLock) {\n\t\tif (trashEmptier != null && trashEmptier.getHost().equals(host)) {\n\t\t\treturn;\n\t\t}\n\t\tUserGroupInformation superuser = null;\n\t\ttry {\n\t\t\tsuperuser = UserGroupInformation.createProxyUser(\"hdfs\", UserGroupInformation.getLoginUser());\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Failed to create proxy user for trash emptier\", e);\n\t\t\tthrow new IOException(\"Failed to create proxy user for trash emptier\", e);\n\t\t}\n\t\ttry {\n\t\t\temptierFs = superuser.doAs(new PrivilegedExceptionAction<FileSystem>() {\n\t\t\t\t@Override\n\t\t\t\tpublic FileSystem run() throws Exception {\n\t\t\t\t\treturn new JuiceFileSystemImpl(conf);\n\t\t\t\t}\n\t\t\t});\n\t\t} catch (Exception e) {\n\t\t\tLOG.error(\"Failed to initialize trash emptier file system\", e);\n\t\t\tthrow new IOException(\"Failed to initialize trash emptier file system\", e);\n\t\t}\n\t\ttrashEmptier = new TrashEmptier(conf, emptierFs);\n\t\ttrashEmptier.scheduleWithFixedDelay(10, 10, TimeUnit.MINUTES);\n\t\tLOG.info(\"Trash emptier started for host {}\", host);\n\t}\n}", "CodeBleu_score": 41.87689639230786}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t", "CodeBleu_score": 3.9342063425737863}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (emptierFs != null) {\nreturn ;\n}\nfinal String host = uri.getHost();\nfinal String superuser = getConf(conf, \\\"superuser\\\", \\\"root\\\");\ntry {\nUserGroupInformation.createProxyUser(superuser, UserGroupInformation.getLoginUser()).doAs(new PrivilegedExceptionAction<Void>() {\n@Override\npublic Void run() throws Exception {\nemptierFs = new JuiceFileSystemImpl(uri, conf);\nreturn null;\n}\n});\n} catch (Exception e) {\nthrow new IOException(\\\"Failed to initialize trash emptier for host \\\" + host + \\\" with superuser \\\" + superuser, e);\n}\nfinal long trashInterval = Long.parseLong(getConf(conf, \\\"trash.interval\\\", \\\"600000\\\"));\nfinal long trashAge = Long.parseLong(getConf(conf, \\\"trash.age\\\", \\\"604800000\\\"));\nfinal long trashIntervalMultiplier = Long.parseLong(getConf(conf, \\\"trash.interval.multiplier\\\", \\\"1\\\"));\nBgTaskUtil.scheduleWithFixedDelay(new Runnable() {\n@Override\npublic void run() {\ntry {\nemptierFs.deleteTrash(trashAge, trashInterval * trashIntervalMultiplier, TimeUnit.MILLISECONDS);\n} catch (Exception e) {\nLOG.error(\\\"Failed to delete trash on host \\\" + host, e);\n}\n}\n}, trashInterval, trashInterval, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 22.4303126622283}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tCallerContext currentContext = CallerContext.getCurrent();\n\tif (currentContext == null || currentContext.getContext() == null) {\n\t\tCallerContext.setCurrent(CallerContext.create(context));\n\t} else {\n\t\tString current = currentContext.getContext();\n\t\tif (current.contains(context)) {\n\t\t\treturn;\n\t\t}\n\t\tif (current.contains(context + \" \")) {\n\t\t\treturn;\n\t\t}\n\t\tif (current.contains(\" \" + context)) {\n\t\t\treturn;\n\t\t}\n\t\tif (current.contains(\" \" + context + \" \")) {\n\t\t\treturn;\n\t\t}\n\t\tCallerContext.setCurrent(CallerContext.create(current + \" \" + context));\n\t}\n}", "CodeBleu_score": 37.68571360759684}, {"code": "public static void setContext(String context) throws Exception{\n\t\n}", "CodeBleu_score": 3.1494709380915578}, {"code": "public static void setContext(String context) throws Exception{\n\t\tCallerContext current = CallerContext.getCurrent();\n\tif (current == null || !current.isContextValid()) {\n\t\tCallerContext.setCurrent(CallerContext.newCallerContext(context));\n\t} else if (current.getContext() != null && !current.getContext().contains(context)) {\n\t\tCallerContext.setCurrent(CallerContext.newCallerContext(current.getContext() + \",\" + context));\n\t}\n}", "CodeBleu_score": 45.34034987187515}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\nif (rc < 0) {\nreturn LOG_STATUS(Status_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 75.81070653722517}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\nif (rc < 0) {\nreturn LOG_STATUS(Status_HDFSError(\n\"Cannot remove path: \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 75.79415735148652}, {"code": "Status HDFS::remove_file(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint rc = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\nif (rc < 0) {\nreturn LOG_STATUS(Status_HDFSError(\"Cannot remove path: \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 75.81070653722517}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn Status::Ok();\n}\nhdfsFile write_file = libhdfs_->hdfsOpenFile(\nfs, uri.to_path().c_str(), O_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\nif (!write_file) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File opening error\"));\n}\n// Flush data to HDFS\nif (libhdfs_->hdfsFlush(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File writing error\"));\n}\n// Close file\nif (libhdfs_->hdfsCloseFile(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File closing error\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 81.67231830786629}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn Status::Ok();\n}\nhdfsFile write_file = libhdfs_->hdfsOpenFile(\nfs, uri.to_path().c_str(), O_WRONLY | O_APPEND, constants::max_write_bytes, 0, 0);\nif (!write_file) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File opening error\"));\n}\n// Flush file\nif (libhdfs_->hdfsFlush(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File flushing error\"));\n}\n// Close file\nif (libhdfs_->hdfsCloseFile(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File closing error\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 81.69702174736163}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nint flags = file_exists ? O_WRONLY | O_APPEND : O_WRONLY;\nhdfsFile write_file = libhdfs_->hdfsOpenFile(\nfs, uri.to_path().c_str(), flags, constants::max_write_bytes, 0, 0);\nif (!write_file) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File opening error\"));\n}\n// Flush data to the file\nif (libhdfs_->hdfsFlush(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File writing error\"));\n}\n// Close file\nif (libhdfs_->hdfsCloseFile(fs, write_file)) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot write to file \") + uri.to_string() +\n\"; File closing error\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 77.69683949392319}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nhdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (!file_info) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot get file info for file \") + uri.to_string()));\n}\nif (file_info->mKind != kObjectKindFile) {\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn LOG_STATUS(Status_Invalid(\"Cannot get file size; Path is not a file\"));\n}\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn Status::Ok();\n}", "CodeBleu_score": 63.55373001505408}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nbool file_exists = false;\nRETURN_NOT_OK(is_file(uri, &file_exists));\nif (!file_exists) {\nreturn LOG_STATUS(Status_NotFound(\nstd::string(\"Cannot get size of file '\") + uri.to_string() + \"'\"));\n}\n*nbytes = 0;\nhdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (file_info == NULL) {\nreturn LOG_STATUS(Status_HDFSError(\nstd::string(\"Cannot get file info for file '\") + uri.to_string() + \"'\"));\n}\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn Status::Ok();\n}", "CodeBleu_score": 59.488712716048056}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\n\nbool is_file = false;\nRETURN_NOT_OK(is_file(uri, &is_file));\nif (!is_file) {\nreturn LOG_STATUS(Status_NotFound(\\\"URI \\'\\\" + uri.to_string() + \\\"\\' is not a file\\\"));\n}\n\nhdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.to_path().c_str());\nif (file_info == NULL) {\nreturn LOG_STATUS(Status_HDFSError(\\\"Cannot get file info for \\'\\\" + uri.to_string() + \\\"\\'\\\"));\n}\n*nbytes = file_info->mSize;\nlibhdfs_->hdfsFreeFileInfo(file_info, 1);\nreturn Status::Ok();\n}", "CodeBleu_score": 53.62026974763926}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (StringUtils.isEmpty(hbaseCfgString)) {\n\t\tthrow new IllegalArgumentException(\"HBase config string is empty\");\n\t}\n\t// Parse the HBase configuration string into a JSON object\n\tJsonObject jsonObj = JsonParser.parseString(hbaseCfgString).getAsJsonObject();\n\t// Extract the Zookeeper quorum\n\tString zkQuorum = jsonObj.get(\"hbase.zookeeper.quorum\").getAsString();\n\t// Extract the Zookeeper znode parent\n\tString zkZnodeParent = jsonObj.get(\"zookeeper.znode.parent\").getAsString();\n\t// Ensure the quorum includes the port number, defaulting to 2181 if not specified\n\tif (!zkQuorum.contains(\":\")) {\n\t\tzkQuorum += \":2181\";\n\t}\n\t// Default the znode parent to a predefined value\n\tif (StringUtils.isEmpty(zkZnodeParent)) {\n\t\tzkZnodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(zkQuorum, zkZnodeParent);\n}", "CodeBleu_score": 33.7930329553542}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\n// The HBase configuration string is a JSON object with the following format:\n// {\n//   \"hbase.zookeeper.quorum\": \"localhost,host.domain.com\",\n//   \"zookeeper.znode.parent\": \"/hbase\"\n// }\n\n// The JSON object is parsed using the fastjson parser.\nMap<String, String> hbaseCfg = JSON.parseObject(hbaseCfgString, new TypeReference<HashMap<String, String>>() {});\n\n// The quorum is required and must include the port number.\nString hbaseZookeeperQuorum = hbaseCfg.get(HBaseKey.HBASE_ZOOKEEPER_QUORUM);\nif (hbaseZookeeperQuorum == null) {\nthrow new IllegalArgumentException(HBaseKey.HBASE_ZOOKEEPER_QUORUM + \" is a required parameter\");\n}\n\n// The znode parent is optional and defaults to /hbase if not provided.\nString hbaseZookeeperZnodeParent = hbaseCfg.getOrDefault(HBaseKey.HBASE_ZOOKEEPER_ZNODE_PARENT, HBaseConstant.DEFAULT_ZOOKEEPER_ZNODE_PARENT);\n\nreturn new Pair<>(hbaseZookeeperQuorum, hbaseZookeeperZnodeParent);\n}", "CodeBleu_score": 47.521558743686796}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (StringUtils.isEmpty(hbaseCfgString)) {\n\t\tthrow new IllegalArgumentException(\"HBase configuration cannot be null or empty\");\n\t}\n\tMap<String, String> hbaseCfg = JSON.parseObject(hbaseCfgString, new TypeReference<HashMap<String, String>>() {});\n\tString zkQuorum = hbaseCfg.get(HBaseKey.HBASE_ZOOKEEPER_QUORUM);\n\tif (StringUtils.isEmpty(zkQuorum)) {\n\t\tthrow new IllegalArgumentException(\"HBase configuration does not contain a value for \" + HBaseKey.HBASE_ZOOKEEPER_QUORUM);\n\t}\n\tif (!zkQuorum.contains(\":\")) {\n\t\tzkQuorum += \":2181\";\n\t}\n\tString zkNodeParent = hbaseCfg.get(HBaseKey.HBASE_ZOOKEEPER_ZNODE_PARENT);\n\tif (StringUtils.isEmpty(zkNodeParent)) {\n\t\tzkNodeParent = HBaseConstant.DEFAULT_ZNODE_PARENT;\n\t}\n\treturn new Pair<>(zkQuorum, zkNodeParent);\n}", "CodeBleu_score": 57.4502558285118}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos && StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\ntry {\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n}\ncatch (IOException e) {\nLOG.error(\\\"Kerberos login failure, please check the principal and keytab file path.\\\", e);\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR,\n\\\"Kerberos login failure, please check the principal and keytab file path.\\\", e);\n}\n}\n}", "CodeBleu_score": 52.49439265414808}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\tif (haveKerberos && StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\ntry {\nLOG.info(\\\"Kerberos authentication is enabled.\\\");\nUserGroupInformation.setConfiguration(hadoopConf);\nUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR,\n\\\"Kerberos login failure, please check the principal and keytab file path configured\\\", e);\n}\n}\n}", "CodeBleu_score": 49.94028760420996}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (haveKerberos && StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n\t\tLOG.info(\\\"Kerberos authentication for principal: {}\\\", kerberosPrincipal);\n\n\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\n\t\ttry {\n\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\n\t\t}\n\n\t\tcatch (IOException e) {\n\n\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR,\n\n\t\t\t\t\t\\\"Kerberos login failure, please check the configuration of principal and keytab file path\\\", e);\n\n\t\t}\n\n\t}\n\n}", "CodeBleu_score": 54.3723356814345}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint columnCount = rsmd.getColumnCount();\n\tfor (int i = 1; i <= columnCount; i++) {\n\t\tString columnName = rsmd.getColumnLabel(i);\n\t\tif (columnName == null) {\n\t\t\tthrow new SQLException(\\\"The column name is null.\\\");\n\t\t}\n\t\tint columnType = rsmd.getColumnType(i);\n\t\tif (columnType == Types.NULL) {\n\t\t\tthrow new SQLException(\\\"The column type is null.\\\");\n\t\t}\n\t\tThinClientPTable.ThinClientPColumn colType = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n\t\tcolTypeMap.put(columnName, colType);\n\t}\n\treturn colTypeMap;\n}", "CodeBleu_score": 43.56891638311829}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = Maps.newHashMap();\nResultSetMetaData rsmd = rs.getMetaData();\nint columnCount = rsmd.getColumnCount();\nfor (int i = 1; i <= columnCount; i++) {\n    String columnName = rsmd.getColumnName(i);\n    if (columnName == null) {\n        throw new SQLException(\\\"Column name is null\\\");\n    }\n    int columnType = rsmd.getColumnType(i);\n    if (columnType == Types.NULL) {\n        throw new SQLException(\\\"Column type is null\\\");\n    }\n    ThinClientPTable.ThinClientPColumn colType = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n    colTypeMap.put(columnName, colType);\n}\nreturn colTypeMap;\n}", "CodeBleu_score": 42.83188026065006}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint columnCount = rsmd.getColumnCount();\n\tfor (int i = 1; i <= columnCount; i++) {\n\t\tString columnName = rsmd.getColumnName(i);\n\t\tif (columnName == null) {\n\t\t\tthrow new SQLException(\\\"Column name is null\\\");\n\t\t}\n\t\tint columnType = rsmd.getColumnType(i);\n\t\tif (columnType == Types.NULL) {\n\t\t\tthrow new SQLException(\\\"Column type is null\\\");\n\t\t}\n\t\tThinClientPTable.ThinClientPColumn colType = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n\t\tcolTypeMap.put(columnName, colType);\n\t}\n\treturn colTypeMap;\n}", "CodeBleu_score": 42.63143095312982}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t\ttry {\n\t\tPhoenixConnection hconn = conn.unwrap(PhoenixConnection.class);\n\t\tHBaseAdmin admin = hconn.getQueryServices().getAdmin();\n\t\tif (!admin.tableExists(tableName)) {\n\t\t\tLOG.debug(\\\"The table {} does not exist. No need to truncate it.\\\", tableName);\n\t\t\treturn;\n\t\t}\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, true);\n\t\tLOG.debug(\\\"The table {} has been truncated.\\\", tableName);\n\t}\n\tcatch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_TABLE_ERROR,\n\t\t\t\t\\\"Failed to truncate table \\\" + tableName, e);\n\t}\n\tfinally {\n\t\ttry {\n\t\t\tif (conn != null) {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tLOG.error(\\\"Failed to close connection\\\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.58776434829786}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\tPhoenixConnection hconn = conn.unwrap(PhoenixConnection.class);\n\tHBaseAdmin admin = null;\n\ttry {\n\t\tadmin = (HBaseAdmin) hconn.getQueryServices().getAdmin();\n\t\tif (!admin.tableExists(tableName)) {\n\t\t\tLOG.warn(\\\"The table \\\" + tableName + \\\" does not exist. No need to truncate.\\\");\n\t\t\treturn;\n\t\t}\n\t\tadmin.disableTable(tableName);\n\t\tadmin.truncateTable(tableName, true);\n\t\tLOG.info(\\\"Truncated table \\\" + tableName);\n\t}\n\tcatch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_TABLE_ERROR, e);\n\t}\n\tfinally {\n\t\tif (admin != null) {\n\t\t\ttry {\n\t\t\t\tadmin.close();\n\t\t\t}\n\t\t\tcatch (IOException e) {\n\t\t\t\tLOG.error(\\\"Failed to close the HBase admin instance\\\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.36331709254968}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t\n}", "CodeBleu_score": 3.0156022420126165}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\tif (specifiedFileType == null) {\n// If the user has not specified a file type, add all files to the source files list\nsourceHDFSAllFilesList.add(filePath);\n}\nelse if (specifiedFileType.equals(\\\"text\\\")) {\n// If the user has specified text file type, check if the file type is text\nif (filePath.endsWith(\\\".\\\" + FileType.TEXT.toString().toLowerCase())) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nString message = String.format(\\\"The [%s] file type is not supported, please check the configuration file.\\\", filePath);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n}\n}\nelse if (specifiedFileType.equals(\\\"orc\\\")) {\n// If the user has specified orc file type, check if the file type is orc\nif (filePath.endsWith(\\\".\\\" + FileType.ORC.toString().toLowerCase())) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nString message = String.format(\\\"The [%s] file type is not supported, please check the configuration file.\\\", filePath);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n}\n}\nelse if (specifiedFileType.equals(\\\"parquet\\\")) {\n// If the user has specified parquet file type, check if the file type is parquet\nif (filePath.endsWith(\\\".\\\" + FileType.PARQUET.toString().toLowerCase())) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\nString message = String.format(\\\"The [%s] file type is not supported, please check the configuration file.\\\", filePath);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n}\n}\nelse {\nString message = String.format(\\\"The [%s] file type is not supported, please check the configuration file.\\\", filePath);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n}\n}", "CodeBleu_score": 39.36898482679656}, {"code": "private void addSourceFileByType(String filePath){\n\tif (specifiedFileType == null) {\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\n\nif (filePath.endsWith(specifiedFileType)) {\n\nsourceHDFSAllFilesList.add(filePath);\n}\nelse {\n\nString message = String.format(\\\"The file type of [%s] is not [%s], please check the configuration.\\\", filePath, specifiedFileType);\n\nLOG.error(message);\n\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT, message);\n}\n}\n}", "CodeBleu_score": 38.82275609152105}, {"code": "private void addSourceFileByType(String filePath){\n\t", "CodeBleu_score": 2.1136257717372766}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\tLOG.info(\"The start read sourceSequenceFilePath:[{}]\", sourceSequenceFilePath);\n\tFileSystem fs = null;\n\tFSDataInputStream inputStream = null;\n\ttry {\n\t\tfs = FileSystem.get(hadoopConf);\n\t\tinputStream = fs.open(new Path(sourceSequenceFilePath));\n\t\t// get reader\n\t\tSequenceFile.Reader reader = new SequenceFile.Reader(inputStream, readerSliceConfig);\n\t\t// get key and value class\n\t\tClass keyClass = reader.getKeyClass();\n\t\tClass valueClass = reader.getValueClass();\n\t\t// get key and value object\n\t\tObject key = ReflectionUtils.newInstance(keyClass, hadoopConf);\n\t\tObject value = ReflectionUtils.newInstance(valueClass, hadoopConf);\n\t\t// get reader context\n\t\tReader.Context readerContext = reader.getContext();\n\t\tLOG.info(\"Begin to read key class:[{}], value class:[{}]\", keyClass.getCanonicalName(), valueClass.getCanonicalName());\n\t\t// read key-value\n\t\twhile (reader.next(key, value)) {\n\t\t\tif (null == key) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t\tStorageReaderUtil.transportOneRecord(recordSender, readerContext, readerSliceConfig, key, value, taskPluginCollector);\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tString message = String.format(\"IO exception occurred while reading the file [%s].\", sourceSequenceFilePath);\n\t\tLOG.error(message);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_IO_ERROR, e);\n\t}\n\tfinally {\n\t\tIOUtils.closeStream(inputStream);\n\t\tIOUtils.closeStream(fs);\n\t}\n}", "CodeBleu_score": 50.316452734494824}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t", "CodeBleu_score": 4.1920025933337515}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tPath path = new Path(filepath);\n\tFileSystem fs = null;\n\ttry {\n\t\tfs = FileSystem.get(hadoopConf);\n\t\tif (fs.isFile(path)) {\n\t\t\tif (specifiedFileType.equals(FileType.ORC.name())) {\n\t\t\t\treturn checkOrcFile(fs, path);\n\t\t\t}\n\t\t\telse if (specifiedFileType.equals(FileType.RC.name())) {\n\t\t\t\treturn checkRcFile(fs, path);\n\t\t\t}\n\t\t\telse if (specifiedFileType.equals(FileType.SEQUENCE.name())) {\n\t\t\t\treturn checkSequenceFile(fs, path);\n\t\t\t}\n\t\t\telse if (specifiedFileType.equals(FileType.PARQUET.name())) {\n\t\t\t\treturn checkParquetFile(fs, path);\n\t\t\t}\n\t\t\telse if (specifiedFileType.equals(FileType.CSV.name())) {\n\t\t\t\treturn checkCsvFile(fs, path);\n\t\t\t}\n\t\t\telse if (specifiedFileType.equals(FileType.TEXT.name())) {\n\t\t\t\treturn checkTextFile(fs, path);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tLOG.warn(\"The specified file type [{}] is not supported.\", specifiedFileType);\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tLOG.warn(\"The specified file [{}] does not exist or is not a file.\", filepath);\n\t\t\treturn false;\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, \"IO exception occurred when checking file type.\");\n\t}\n\tfinally {\n\t\tif (null != fs) {\n\t\t\ttry {\n\t\t\t\tfs.close();\n\t\t\t}\n\t\t\tcatch (IOException e) {\n\t\t\t\tLOG.warn(\"IO exception occurred when closing file system.\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 35.09400269252884}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t//    LOG.info(\"Begin to check the file type of [{}].\", filepath);\n//    Path path = new Path(filepath);\n//    String fileType = \"\";\n//    try {\n//        fileType = getHdfsFileType(path);\n//    }\n//    catch (Exception e) {\n//        throw AddaxException.asAddaxException(HdfsReaderErrorCode.UNKNOWN_FILE_TYPE, e.getMessage());\n//    }\n//\n//    if (fileType.equals(specifiedFileType)) {\n//        return true;\n//    }\n//    else {\n//        return false;\n//    }\n//\n//}", "CodeBleu_score": 2.382402701443833}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tPath path = new Path(filepath);\n\t\tFileSystem fs = FileSystem.get(hadoopConf);\n\t\tFileStatus fileStatus = fs.getFileStatus(path);\n\t\tString fileType = fileStatus.isFile() ? getHdfsFileType(fileStatus) : null;\n\t\tif (fileType == null) {\n\t\t\tLOG.info(\"The file {} is not a file, it's a directory\", filepath);\n\t\t\treturn false;\n\t\t}\n\t\tif (fileType.equals(specifiedFileType)) {\n\t\t\tLOG.info(\"The file {} is a {} file\", filepath, specifiedFileType);\n\t\t\treturn true;\n\t\t}\n\t\tLOG.info(\"The file {} is not a {} file\", filepath, specifiedFileType);\n\t\treturn false;\n\t}\n\tcatch (Exception e) {\n\t\tLOG.error(\"Failed to verify the file type of {} against the specified file type {}\", filepath, specifiedFileType, e);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.ILLEGAL_VALUE, e.getMessage());\n\t}\n}", "CodeBleu_score": 34.91878024868241}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\tif (null != hConnection) {\ntry {\nhConnection.close();\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 78.02349515434763}, {"code": "public static void closeConnection(Connection hConnection){\n\tif (hConnection != null) {\ntry {\nhConnection.close();\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n}\n}\n}", "CodeBleu_score": 59.98841294880262}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n\t}\n}", "CodeBleu_score": 63.39944375653753}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null != admin) {\nadmin.close();\n}\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 84.7415126182708}, {"code": "public static void closeAdmin(Admin admin){\n\t\ttry {\n\t\tif (null != admin) {\n\t\t\tadmin.close();\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n\t}\n}", "CodeBleu_score": 85.0567951805611}, {"code": "public static void closeAdmin(Admin admin){\n\ttry {\nif (null != admin) {\nadmin.close();\n}\n}\ncatch (IOException e) {\nthrow AddaxException.asAddaxException(Hbase11xWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n}\n}", "CodeBleu_score": 84.7415126182708}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\tString rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n\tString family = Bytes.toString(CellUtil.cloneFamily(cell));\n\tString qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n\tString value = Bytes.toString(CellUtil.cloneValue(cell));\n\tlong timestamp = cell.getTimestamp();\n\t// add row key column\n\trecord.addColumn(new LongColumn(HBaseConstant.COLUMN_NAME_ROWKEY, rowKey));\n\t// add column family column\n\trecord.addColumn(new LongColumn(HBaseConstant.COLUMN_NAME_FAMILY, family));\n\t// add column qualifier column\n\trecord.addColumn(new LongColumn(HBaseConstant.COLUMN_NAME_QUALIFIER, qualifier));\n\t// add column timestamp column\n\trecord.addColumn(new LongColumn(HBaseConstant.COLUMN_NAME_TIMESTAMP, timestamp));\n\t// add column value column\n\trecord.addColumn(new LongColumn(HBaseConstant.COLUMN_NAME_VALUE, value));\n}", "CodeBleu_score": 25.528522595828406}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n\tif (StringUtils.isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tif (Bytes.isBinary(userStartRowkey.getBytes(Charset.forName(\\\"UTF-8\\\")))) {\n\t\treturn userStartRowkey.getBytes(Charset.forName(\\\"UTF-8\\\"));\n\t} else {\n\t\treturn Bytes.toBytesBinary(userStartRowkey);\n\t}\n}", "CodeBleu_score": 45.48167597277335}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY, \"\");\n\tif (StringUtils.isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tbyte[] startRowkeyBytes = Bytes.toBytesBinary(userStartRowkey);\n\treturn startRowkeyBytes;\n}", "CodeBleu_score": 38.897234215272945}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n\tif (StringUtils.isBlank(userStartRowkey)) {\n\t\treturn new byte[0];\n\t}\n\tif (Bytes.isBinary(userStartRowkey.getBytes(Charset.forName(\"UTF-8\")))) {\n\t\treturn userStartRowkey.getBytes(Charset.forName(\"UTF-8\"));\n\t}\n\tthrow AddaxException.asAddaxException(Hbase20xReaderErrorCode.ILLEGAL_VALUE, \"startRowkey\u914d\u7f6e\u9879\u7684\u503c\u4e0d\u662f\u5408\u6cd5\u7684\u4e8c\u8fdb\u5236\u5b57\u7b26\u4e32\");\n}", "CodeBleu_score": 40.323546329298196}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn HConstants.EMPTY_BYTE_ARRAY;\n\t}\n\telse {\n\t\tboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\n\t\treturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 71.03812635341905}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\nif (StringUtils.isBlank(startRowkey)) {\nreturn HConstants.EMPTY_BYTE_ARRAY;\n} else {\nboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\nreturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n}\n}", "CodeBleu_score": 71.61217180658655}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn HConstants.EMPTY_BYTE_ARRAY;\n\t} else {\n\t\tboolean isBinaryRowkey = configuration.getBool(HBaseKey.IS_BINARY_ROW_KEY);\n\t\treturn Hbase20xHelper.stringToBytes(startRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 71.10083502186306}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 42.571804455549525}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tsuper();\nthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 41.792832126278}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\tsuper();\nthis.key = UUID.fromString(record.key());\nthis.headers = new DefaultTbQueueMsgHeaders(record.headers());\nthis.data = record.value();\n}", "CodeBleu_score": 41.792832126278}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\treturn new TbKafkaProducerTemplate<>(kafkaSettings, transportNotificationSettings.getNotificationsTopic(), new TbKafkaAdmin(kafkaSettings, transportNotificationSettings.getNotificationsTopic()), ToTransportMsg.parser());\n}", "CodeBleu_score": 23.624495017991283}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\nreturn new TbKafkaProducerTemplate<>(kafkaSettings, transportNotificationSettings.getNotificationsTopic(),\n\nnew TbKafkaProducerTemplate.DefaultKeySerializer(),\n\nnew TbKafkaProducerTemplate.DefaultMsgSerializer<ToTransportMsg>() {\n\n@Override\npublic byte[] serialize(ToTransportMsg msg) {\n\nToTransportNotificationMsg toTransportNotificationMsg = ToTransportNotificationMsg.newBuilder()\n\n.setNotificationMsg(msg)\n\n.build();\n\nreturn toTransportNotificationMsg.toByteArray();\n\n}\n\n});\n\n}", "CodeBleu_score": 39.60777945867825}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\nconsumerBuilder.settings(kafkaSettings);\nconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\nconsumerBuilder.clientId(\\\"tb-core-consumer-\\\" + serviceInfoProvider.getServiceId() + \\\"-\\\" + consumerCount.incrementAndGet());\nconsumerBuilder.groupId(topicService.buildTopicName(\\\"tb-core-node\\\"));\nconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\nconsumerBuilder.admin(coreAdmin);\nconsumerBuilder.statsService(consumerStatsService);\nreturn consumerBuilder.build();\n}", "CodeBleu_score": 54.718382704842675}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\n\tconsumerBuilder.settings(kafkaSettings);\n\tconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\n\tconsumerBuilder.clientId(\\\"tb-core-consumer-\\\" + serviceInfoProvider.getServiceId() + \\\"-\\\" + consumerCount.incrementAndGet());\n\tconsumerBuilder.groupId(topicService.buildTopicName(\\\"tb-core-node\\\"));\n\tconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\n\tconsumerBuilder.admin(coreAdmin);\n\tconsumerBuilder.statsService(consumerStatsService);\n\treturn consumerBuilder.build();\n}", "CodeBleu_score": 54.75547809078994}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\tTbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate.builder();\nconsumerBuilder.settings(kafkaSettings);\nconsumerBuilder.topic(topicService.buildTopicName(coreSettings.getTopic()));\nconsumerBuilder.clientId(\\\"tb-core-consumer-\\\" + serviceInfoProvider.getServiceId() + \\\"-\\\" + consumerCount.incrementAndGet());\nconsumerBuilder.groupId(topicService.buildTopicName(\\\"tb-core-node\\\"));\nconsumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData()), msg.getHeaders()));\nconsumerBuilder.admin(coreAdmin);\nconsumerBuilder.statsService(consumerStatsService);\nreturn consumerBuilder.build();\n}", "CodeBleu_score": 54.718382704842675}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames != null && !topicNames.isEmpty()) {\nlog.info(\"[{}] Subscribing to topics: {}\", groupId, topicNames);\nadmin.createTopicIfNotExists(topicNames);\nconsumer.subscribe(topicNames);\n} else {\nlog.info(\"[{}] No topics to subscribe to. Unsubscribing from all topics\", groupId);\nconsumer.unsubscribe();\n}\n}", "CodeBleu_score": 56.593455135320006}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames.isEmpty()) {\nlog.info(\"Unsubscribing consumer from all topics\");\nconsumer.unsubscribe();\n} else {\nlog.info(\"Subscribing consumer to topics: [{}]\", topicNames);\nconsumer.subscribe(topicNames);\n}\n}", "CodeBleu_score": 56.876862664285746}, {"code": "protected void doSubscribe(List<String> topicNames){\n\tif (topicNames != null && !topicNames.isEmpty()) {\nfor (String topicName : topicNames) {\ntry {\nadmin.createTopicIfNotExists(topicName);\n} catch (IOException e) {\nlog.warn(\"[{}] Failed to subscribe to topic [{}]\", groupId, topicName, e);\n}\n}\nconsumer.subscribe(topicNames);\n} else {\nlog.info(\"[{}] No topics to subscribe to\", groupId);\nconsumer.unsubscribe();\n}\n}", "CodeBleu_score": 55.12078413506658}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\nStopWatch stopWatch = new StopWatch();\nstopWatch.start();\n\nList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\ntry {\nConsumerRecords<String, byte[]> consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\nif (consumerRecords != null && !consumerRecords.isEmpty()) {\nrecords.addAll(consumerRecords);\n}\n} catch (Exception e) {\nlog.warn(\\\"Failed to poll messages from topic: [{}], partition: [{}], duration: [{}], due to: [{}]\\\", topic, partition, durationInMillis, e.getMessage());\n} finally {\nstopWatch.stop();\nlog.debug(\\\"Topic: [{}], partition: [{}], duration: [{}], records found: [{}], time taken: [{}]\\\", topic, partition, durationInMillis, records.size(), stopWatch.getTotalTimeMillis());\nif (statsService != null) {\nstatsService.registerMessagesConsumed(groupId, records.size());\n}\n}\nreturn records;\n}", "CodeBleu_score": 49.941785744363955}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tStopWatch stopWatch = new StopWatch();\nstopWatch.start();\nlog.debug(\\\"[{}] Poll request with duration {} ms.\\\", getTopic(), durationInMillis);\nList<ConsumerRecord<String, byte[]>> records = consumer.poll(Duration.ofMillis(durationInMillis));\nstopWatch.stop();\nlog.debug(\\\"[{}] Poll request with duration {} ms took {} ms.\\\", getTopic(), durationInMillis, stopWatch.getTotalTimeMillis());\nreturn records;\n}", "CodeBleu_score": 54.659734848953036}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\tStopWatch stopWatch = new StopWatch();\nstopWatch.start();\nlog.debug(\\\"[{}] Going to poll messages from topic: {}. Duration: {} ms.\\\", groupId, topic, durationInMillis);\nList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\ntry {\n    records = consumer.poll(Duration.ofMillis(durationInMillis)).records(topic);\n} catch (Exception e) {\n    log.warn(\\\"[{}] Failed to poll messages from topic: {}. Duration: {} ms. Error: {}\\\", groupId, topic, durationInMillis, e.getMessage());\n}\nstopWatch.stop();\nlog.debug(\\\"[{}] Successfully polled messages from topic: {}. Duration: {} ms. Took: {} ms.\\\", groupId, topic, durationInMillis, stopWatch.getTotalTimeMillis());\nreturn records;\n}", "CodeBleu_score": 52.89714102180986}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\nString topic = config.getTopicPattern().replaceAll(\\\"\\\\\\\\{\\\\$\\\\{ruleNode\\\\..+?\\\\}\\\\}\\\", msg.getRuleChainId().toString());\nString key = config.getKeyPattern().replaceAll(\\\"\\\\\\\\{\\\\$\\\\{ruleNode\\\\..+?\\\\}\\\\}\\\", msg.getRuleChainId().toString());\n\nif (initError != null) {\n\nctx.tellFailure(msg, new TbKafkaNodeException(\\\"Failed to initialize Kafka producer\\\", initError));\nreturn;\n}\n\nctx.logJsEvalRequest();\nctx.createChainableFuture(processMsg(msg, topic, key)).thenAccept(v -> ctx.resume(msg, true));\n}", "CodeBleu_score": 31.513774272263927}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\n        if (initError != null) {\n            ctx.tellFailure(msg, new TbKafkaNodeException(\\\"Failed to initialize Kafka producer\\\", initError));\n            return;\n        }\n        String keyPattern = config.getKeyPattern();\n        String topicPattern = config.getTopicPattern();\n        String key = null;\n        String topic = null;\n        try {\n            if (keyPattern != null) {\n                key = TbNodeUtils.processPattern(keyPattern, msg.getData());\n            }\n            if (topicPattern != null) {\n                topic = TbNodeUtils.processPattern(topicPattern, msg.getData());\n            }\n            if (topic == null) {\n                topic = config.getDefaultTopic();\n            }\n            if (key == null) {\n                key = UUID.randomUUID().toString();\n            }\n            if (topic == null) {\n                log.warn(\\\"No topic is configured for the message. Using default topic: {}\\\", config.getDefaultTopic());\n                topic = config.getDefaultTopic();\n            }\n            if (key == null) {\n                log.warn(\\\"No key is configured for the message. Using random key: {}\\\", key);\n                key = UUID.randomUUID().toString();\n            }\n            if (log.isDebugEnabled()) {\n                log.debug(\\\"Going to publish message to Kafka topic: {}\\\", topic);\n            }\n            ctx.getSelf().tell(new TbKafkaNodePublishMsg(topic, key, msg), ctx.getSelf());\n        } catch (Exception e) {\n            ctx.tellFailure(msg, new TbKafkaNodeException(\\\"Failed to process message\\\", e));\n        }\n    }", "CodeBleu_score": 40.710846728088555}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t", "CodeBleu_score": 2.454125543921295}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t", "CodeBleu_score": 5.441118430176013}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\nif (addMetadataKeyValuesAsKafkaHeaders) {\n\nMap<String, String> headers = new HashMap<>();\n\nfor (Map.Entry<String, String> entry : msg.getMetaData().entrySet()) {\n\nheaders.put(TB_MSG_MD_PREFIX + entry.getKey(), entry.getValue());\n\n}\n\nproducer.send(new ProducerRecord<>(topic, key, msg.getData(), headers), (metadata, exception) -> {\n\nif (exception != null) {\n\nlog.debug(\\\"Failed to publish message to Kafka due to {}\\\", exception.getMessage(), exception);\nctx.tellFailure(msg, new TbKafkaClientError(\\\"Failed to publish message to Kafka due to \\\" + exception.getMessage(), exception));\n} else {\nctx.tellSuccess(msg);\n}\n});\n} else {\nproducer.send(new ProducerRecord<>(topic, key, msg.getData()), (metadata, exception) -> {\nif (exception != null) {\nlog.debug(\\\"Failed to publish message to Kafka due to {}\\\", exception.getMessage(), exception);\nctx.tellFailure(msg, new TbKafkaClientError(\\\"Failed to publish message to Kafka due to \\\" + exception.getMessage(), exception));\n} else {\nctx.tellSuccess(msg);\n}\n});\n}\n}", "CodeBleu_score": 31.741208477956768}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tif (addMetadataKeyValuesAsKafkaHeaders) {\nMap<String, String> headers = new HashMap<>();\nmsg.getMetaData().forEach((k, v) -> headers.put(TB_MSG_MD_PREFIX + k, v.toString()));\nproducer.send(new ProducerRecord<>(topic, key, msg.getPayload(), headers), (recordMetadata, e) -> {\nif (e != null) {\nlog.debug(\\\"Failed to publish message with metadata to Kafka due to: {}\\\", e.getMessage(), e);\nctx.tellFailure(msg, e);\n} else {\nctx.tellSuccess(msg);\n}\n});\n} else {\nproducer.send(new ProducerRecord<>(topic, key, msg.getPayload()), (recordMetadata, e) -> {\nif (e != null) {\nlog.debug(\\\"Failed to publish message to Kafka due to: {}\\\", e.getMessage(), e);\nctx.tellFailure(msg, e);\n} else {\nctx.tellSuccess(msg);\n}\n});\n}\n}", "CodeBleu_score": 38.22306673689848}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\ttry {\nif (producer != null) {\nproducer.close();\nproducer = null;\n}\n} catch (Exception e) {\nlog.error(\\\"Failed to close Kafka producer\\\", e);\n}\n}", "CodeBleu_score": 34.300522693468}, {"code": "public void destroy(){\n\t\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\\\"Failed to close producer\\\", e);\n\t\t} finally {\n\t\t\tproducer = null;\n        }\n    }\n}", "CodeBleu_score": 55.68462197323147}, {"code": "public void destroy(){\n\ttry {\nproducer.close();\n} catch (Exception e) {\nlog.error(\\\"Failed to close producer\\\", e);\n}\n}", "CodeBleu_score": 44.03609770204129}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\n\trequestBuilder.settings(kafkaSettings);\n\trequestBuilder.clientId(\"monolith-rule-engine-\"+serviceInfoProvider.getServiceId());\n\trequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getTopic()));\n\trequestBuilder.admin(ruleEngineAdmin);\n\treturn requestBuilder.build();\n}", "CodeBleu_score": 88.51477267392316}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\n\trequestBuilder.settings(kafkaSettings);\n\trequestBuilder.clientId(\"monolith-rule-engine-\\\" + serviceInfoProvider.getServiceId());\n\trequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getRuleEngineTopic()));\n\trequestBuilder.admin(ruleEngineAdmin);\n\treturn requestBuilder.build();\n}", "CodeBleu_score": 72.07047362577697}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\tTbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> requestBuilder = TbKafkaProducerTemplate.builder();\nrequestBuilder.settings(kafkaSettings);\nrequestBuilder.clientId(\"monolith-rule-engine-\\\" + serviceInfoProvider.getServiceId());\nrequestBuilder.defaultTopic(topicService.buildTopicName(ruleEngineSettings.getTopic()));\nrequestBuilder.admin(ruleEngineAdmin);\nreturn requestBuilder.build();\n}", "CodeBleu_score": 77.31635715297578}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t\tlong timeoutMs = kafkaSettings.getResponseTimeoutMs();\n\tlong schedulePeriodMs = statsConfig.getPrintPeriodMs();\n\tstatsPrintScheduler.scheduleAtFixedRate(this::logStats, timeoutMs, schedulePeriodMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 9.161376812508996}, {"code": "private void startLogScheduling(){\n\tlong timeoutMs = kafkaSettings.getResponseTimeoutMs();\nlong schedulePeriodMs = statsConfig.getPrintPeriodMs();\nlong timeoutDurationMs = timeoutMs + schedulePeriodMs;\nlong initialDelayMs = statsConfig.getInitialDelayMs();\n\nstatsPrintScheduler.scheduleWithFixedDelay(() -> {\nif (monitoredGroups.isEmpty()) {\nreturn;\n}\n\ntry {\nMap<String, List<PartitionInfo>> topicPartitionsMap = partitionService.getTopicPartitionsMap();\n\nfor (String groupId : monitoredGroups) {\nList<PartitionInfo> partitions = topicPartitionsMap.get(groupId);\nif (partitions == null) {\ncontinue;\n}\n\nList<TopicPartition> topicPartitions = new ArrayList<>();\nfor (PartitionInfo partitionInfo : partitions) {\ntopicPartitions.add(new TopicPartition(partitionInfo.getTopic(), partitionInfo.getPartition()));\n}\n\nMap<TopicPartition, OffsetAndMetadata> offsets = consumer.committed(topicPartitions);\nMap<TopicPartition, Long> endOffsets = consumer.endOffsets(topicPartitions);\n\nfor (TopicPartition topicPartition : topicPartitions) {\nlong endOffset = endOffsets.get(topicPartition);\nOffsetAndMetadata offset = offsets.get(topicPartition);\nlong currentOffset = offset != null ? offset.offset() : -1;\nlong lag = endOffset - currentOffset;\nif (lag > 0) {\nlogLaggingTopic(groupId, topicPartition.topic(), topicPartition.partition(), currentOffset, endOffset, lag);\n}\n}\n}\n} catch (Exception e) {\nlog.warn(\\\"Failed to print consumer group statistics due to {}\\\", e.getMessage(), e);\n}\n}, initialDelayMs, schedulePeriodMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 33.294584019840336}, {"code": "private void startLogScheduling(){\n\t", "CodeBleu_score": 0.6449045691040067}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, servers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 96.75968336616603}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(group, metricName);\n\tMap<String, String> tags = getTagsFromMetricGroup(group);\n\n\tif (metric instanceof Counter) {\n\t\tcounters.put(metric, new MetricEvent(scopedName, tags, ((Counter) metric).getCount()));\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(metric, new MetricEvent(scopedName, tags, ((Gauge<?>) metric).getValue()));\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(metric, new MetricEvent(scopedName, tags, ((Histogram) metric).getStatistics().toJson()));\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(metric, new MetricEvent(scopedName, tags, ((Meter) metric).getStatistics().toJson()));\n\t} else {\n\t\tLOG.warn(\\\"Unknown metric type: {}. Ignoring metric {}.\\\", metric.getClass().getName(), metricName);\n\t}\n}", "CodeBleu_score": 50.47581044889367}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(group, metricName);\n\tMetricEvent event = new MetricEvent(scopedName, group.getAllVariables());\n\tif (metric instanceof Counter) {\n\t\tcounters.put((Counter) metric, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put((Gauge<?>) metric, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put((Histogram) metric, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put((Meter) metric, event);\n\t} else {\n\t\tLOG.warn(\\\"Unknown metric type: \\\" + metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 63.22042914103464}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t// get the metric group name\n\tString groupPrefix = group.getScopeComponents();\n\tif (groupPrefix == null) {\n\t\tgroupPrefix = \"\";\n\t}\n\n\t// get the metric scope\n\tString scope = groupPrefix + SCOPE_SEPARATOR + metricName;\n\n\t// create the metric event\n\tMetricEvent metricEvent = new MetricEvent(scope, metric.getMetricName(), metric.getMetricTags(), System.currentTimeMillis());\n\n\t// add the metric to the corresponding collection\n\tif (metric instanceof Counter) {\n\t\tcounters.put((Counter) metric, metricEvent);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put((Gauge<?>) metric, metricEvent);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put((Histogram) metric, metricEvent);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put((Meter) metric, metricEvent);\n\t} else {\n\t\tLOG.warn(\\\"Metric type \\\" + metric.getClass().getName() + \\\" is not supported by the KafkaReporter\\\");\n\t}\n}", "CodeBleu_score": 66.14632433484915}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tmetricEvent.addField(field, (Number) value);\n\t} else if (value instanceof Boolean) {\n\t\tmetricEvent.addField(field, (Boolean) value);\n\t} else {\n\t\tmetricEvent.addField(field, value.toString());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 38.26619975100096}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\tif (metricEvent.getFields() == null) {\n\t\t\tmetricEvent.setFields(new HashMap<>());\n\t\t}\n\t\tmetricEvent.getFields().put(field, ((Number) value).doubleValue());\n\t} else if (value instanceof String) {\n\t\tif (metricEvent.getFields() == null) {\n\t\t\tmetricEvent.setFields(new HashMap<>());\n\t\t}\n\t\tmetricEvent.getFields().put(field, value);\n\t} else {\n\t\tthrow new IllegalArgumentException(\\\"Gauge value is of type \\\" + value.getClass().getName() + \\\", which is not supported.\\\");\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 45.89414303952933}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\treturn metricEvent.addField(field, (Number) value);\n\t} else if (value instanceof String) {\n\t\treturn metricEvent.addField(field, (String) value);\n\t} else {\n\t\treturn metricEvent.addField(field, value.toString());\n\t}\n}", "CodeBleu_score": 34.223204679833245}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields != null) {\n\t\tif (value instanceof Number) {\n\t\t\tmetricEvent.addField(\"currentOffset\", (Number) value);\n\t\t} else {\n\t\t\tmetricEvent.addField(\"currentOffset\", String.valueOf(value));\n\t\t}\n\t} else {\n\t\tMap<String, Object> eventFields = new HashMap<>();\n\t\tif (value instanceof Number) {\n\t\t\teventFields.put(\"currentOffset\", (Number) value);\n\t\t} else {\n\t\t\teventFields.put(\"currentOffset\", String.valueOf(value));\n\t\t}\n\t\tmetricEvent.setFields(eventFields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 26.489920954816697}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields != null) {\n\t\tif (value instanceof Number) {\n\t\t\tmetricEvent.addField(KAFKA_CURRENT_OFFSET_FIELD, (Number) value);\n\t\t} else {\n\t\t\tmetricEvent.addField(KAFKA_CURRENT_OFFSET_FIELD, String.valueOf(value));\n\t\t}\n\t} else {\n\t\tMap<String, Object> eventFields = new HashMap<>();\n\t\tif (value instanceof Number) {\n\t\t\teventFields.put(KAFKA_CURRENT_OFFSET_FIELD, (Number) value);\n\t\t} else {\n\t\t\teventFields.put(KAFKA_CURRENT_OFFSET_FIELD, String.valueOf(value));\n\t\t}\n\t\tmetricEvent.setFields(eventFields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 23.759451482630904}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tMap<String, Object> fields = metricEvent.getFields();\n\tif (fields != null) {\n\t\tif (value instanceof Number) {\n\t\t\tmetricEvent.addField(\"currentOffset\", (Number) value);\n\t\t\tmetricEvent.addField(\"dataTimestamp\", timestamp);\n\t\t\tmetricEvent.addField(\"committedOffset\", (Number) value);\n\t\t\treturn metricEvent;\n\t\t} else {\n\t\t\tmetricEvent.addField(\"currentOffset\", String.valueOf(value));\n\t\t\tmetricEvent.addField(\"dataTimestamp\", timestamp);\n\t\t\tmetricEvent.addField(\"committedOffset\", String.valueOf(value));\n\t\t\treturn metricEvent;\n\t\t}\n\t} else {\n\t\tMap<String, Object> eventFields = new HashMap<>();\n\t\tif (value instanceof Number) {\n\t\t\teventFields.put(\"currentOffset\", (Number) value);\n\t\t\teventFields.put(\"dataTimestamp\", timestamp);\n\t\t\teventFields.put(\"committedOffset\", (Number) value);\n\t\t} else {\n\t\t\teventFields.put(\"currentOffset\", String.valueOf(value));\n\t\t\teventFields.put(\"dataTimestamp\", timestamp);\n\t\t\teventFields.put(\"committedOffset\", String.valueOf(value));\n\t\t}\n\t\tmetricEvent.setFields(eventFields);\n\t\treturn metricEvent;\n\t}\n}", "CodeBleu_score": 28.231620823800064}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\t// get global job parameters\n\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\t// build kafka properties\n\tProperties props = buildKafkaProps(parameter);\n\t// build kafka consumer\n\tFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n\t// if a specific start time is provided, set the consumer to start from the specific offsets based on the given time\n\tif (time > 0) {\n\t\tkafkaConsumer.setStartFromTimestamp(time);\n\t}\n\t// add the consumer as a source to the StreamExecutionEnvironment\n\tDataStreamSource<MetricEvent> dataStreamSource = env.addSource(kafkaConsumer);\n\treturn dataStreamSource;\n}", "CodeBleu_score": 60.786379986758334}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tProperties props = buildKafkaProps(env.getConfig().getGlobalJobParameters());\n\tDataStreamSource<MetricEvent> source = null;\n\tif (time != 0) {\n\t\tsource = buildSourceFromTime(env, topic, props, time);\n\t} else {\n\t\tsource = buildSourceFromBeginning(env, topic, props);\n\t}\n\treturn source;\n}", "CodeBleu_score": 34.465945537386965}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameter = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\tProperties props = buildKafkaProps(parameter);\n\tDataStreamSource<MetricEvent> source = null;\n\tif (time > 0) {\n\t\tsource = buildSourceFromTime(env, topic, time, props);\n\t} else {\n\t\tsource = buildSourceFromLatest(env, topic, props);\n\t}\n\treturn source;\n}", "CodeBleu_score": 46.61384566083322}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\tMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\nString topic = parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC);\n        List<PartitionInfo> partitionInfos = getPartitionInfos(props, topic);\n        KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            TopicPartition topicPartition = new TopicPartition(partitionInfo.topic(), partitionInfo.partition());\n            OffsetAndTimestamp offsetAndTimestamp = consumer.offsetsForTimes(ImmutableMap.of(topicPartition, time));\n            if (offsetAndTimestamp.offset() != null) {\n                partitionOffset.put(new KafkaTopicPartition(topicPartition), offsetAndTimestamp.offset());\n            }\n        }\n        consumer.close();\n        return partitionOffset;\n    }", "CodeBleu_score": 54.16147065369445}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\t// Set the consumer group ID using the provided time\n\tprops.put(\"group.id\", \"flink-consumer-\" + time);\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\t// Retrieve partition information for the specified topic\n\tList<PartitionInfo> partitions = consumer.partitionsFor(parameterTool.getRequired(PropertiesConstants.METRICS_TOPIC));\n\t// Create a map associating each partition with the timestamp\n\tMap<TopicPartition, Long> partitionTimestamp = new HashMap<>();\n\tfor (PartitionInfo partitionInfo : partitions) {\n\t\tpartitionTimestamp.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n\t}\n\t// Fetch offsets for the given times\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionTimestamp);\n\t// Build a map of KafkaTopicPartition to offsets\n\tMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\n\tfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n\t\tpartitionOffset.put(new KafkaTopicPartition(entry.getKey()), entry.getValue().offset());\n\t}\n\tconsumer.close();\n\treturn partitionOffset;\n}", "CodeBleu_score": 66.54179146332613}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\n\tString groupId = parameterTool.getRequired(PropertiesConstants.KAFKA_GROUP_ID);\n\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n\tconsumer.assign(getPartitionsForTopic(props, parameterTool, topic));\n\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(getPartitionTimestamps(props, parameterTool, topic, time));\n\n\tfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n\n\t\tpartitionOffset.put(new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry.getValue().offset());\n\n\t}\n\n\tconsumer.close();\n\n\treturn partitionOffset;\n\n}", "CodeBleu_score": 43.775873227266466}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties properties = new Properties();\nproperties.setProperty(\\\"bootstrap.servers\\\", broker_list);\nproperties.setProperty(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nproperties.setProperty(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);\n\nMetricEvent metricEvent = new MetricEvent();\nmetricEvent.setTimestamp(System.currentTimeMillis());\nmetricEvent.setName(\\\"test\\\");\nmetricEvent.setFields(new HashMap<String, Object>() {{\nput(\\\"field1\\\", 1);\nput(\\\"field2\\\", 2);\n}});\nmetricEvent.setTags(new HashMap<String, String>() {{\nput(\\\"tag1\\\", \\\"tag1\\\");\nput(\\\"tag2\\\", \\\"tag2\\\");\n}});\n\nProducerRecord<String, String> record = new ProducerRecord<String, String>(topic, metricEvent.getName(),\nGsonUtil.toJson(metricEvent));\n\nproducer.send(record);\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 24.590563269395666}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(\\\"bootstrap.servers\\\", broker_list);\nprops.put(\\\"acks\\\", \\\"all\\\");\nprops.put(\\\"retries\\\", 0);\nprops.put(\\\"batch.size\\\", 16384);\nprops.put(\\\"linger.ms\\\", 1);\nprops.put(\\\"buffer.memory\\\", 33554432);\nprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\nMap<String, String> tags = new HashMap<String, String>();\ntags.put(\\\"host\\\", \\\"localhost\\\");\ntags.put(\\\"region\\\", \\\"us-west-2\\\");\ntags.put(\\\"datacenter\\\", \\\"aws\\\");\n\nMap<String, Object> fields = new HashMap<String, Object>();\nfields.put(\\\"temperature\\\", 70);\nfields.put(\\\"humidity\\\", 80);\nfields.put(\\\"pressure\\\", 90);\n\nMetricEvent metric = new MetricEvent(\\\"metric\\\", tags, fields, System.currentTimeMillis());\nString metricJson = GsonUtil.toJson(metric);\n\nProducerRecord<String, String> data = new ProducerRecord<String, String>(topic, metricJson);\nproducer.send(data);\n\nSystem.out.println(\\\"Write data: \\\" + metricJson);\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 29.863367097976184}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\nProperties props = new Properties();\nprops.put(\\\"bootstrap.servers\\\", broker_list);\nprops.put(\\\"acks\\\", \\\"all\\\");\nprops.put(\\\"retries\\\", 0);\nprops.put(\\\"batch.size\\\", 16384);\nprops.put(\\\"linger.ms\\\", 1);\nprops.put(\\\"buffer.memory\\\", 33554432);\nprops.put(\\\"key.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\nprops.put(\\\"value.serializer\\\", \\\"org.apache.kafka.common.serialization.StringSerializer\\\");\n\nKafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\nString[] names = new String[] {\\\"sensor_1\\\", \\\"sensor_2\\\", \\\"sensor_3\\\"};\nString[] tags = new String[] {\\\"location_lon=11.555,location_lat=48.1234567\\\", \\\"location_lon=11.555,location_lat=48.1234567\\\", \\\"location_lon=11.555,location_lat=48.1234567\\\"};\nString[] fields = new String[] {\\\"temp=12.3,humidity=45.6\\\", \\\"temp=12.3,humidity=45.6\\\", \\\"temp=12.3,humidity=45.6\\\"};\n\nfor (int i = 0; i < 1000; i++) {\nMetricEvent metricEvent = new MetricEvent(\\\"metric\\\", System.currentTimeMillis(), names[i % 3], tags[i % 3], fields[i % 3]);\nString data = GsonUtil.toJson(metricEvent);\nproducer.send(new ProducerRecord<>(topic, data));\nThread.sleep(1000);\n}\n\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 23.40374018164401}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (this.filter != null && !this.filter.isLoggable(event)) {\nreturn;\n}\n\nString level = event.getLevel().name();\nString loggerName = event.getLoggerName();\n\nif (level.equals(this.level) && !loggerName.contains(\\\"xxx\\\")) {\ntry {\nString message = new String(this.getLayout().toByteArray(event));\nLogEvent logEvent = LogEvent.builder().timestamp(System.currentTimeMillis()).containerId(containerId).containerType(containerType).source(source).level(level).loggerName(loggerName).message(message).taskId(taskId).taskName(taskName).appId(appId).nodeIp(nodeIp).build();\nString json = JacksonUtil.toJson(logEvent);\nproducer.send(new ProducerRecord<>(topic, json));\n} catch (JsonProcessingException e) {\nlog.warn(\\\"Error serializing log event to JSON\\\", e);\n} catch (Exception e) {\nlog.warn(\\\"Error sending log event to Kafka\\\", e);\n}\n}\n}", "CodeBleu_score": 40.540255423150704}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().toString().equals(level) && !event.getLoggerName().contains(\\\"xxx\\\")) {\n\t\tString message = layout.toSerializable(event).toString();\n\t\ttry {\n\t\t\tLogEvent logEvent = new LogEvent();\n\t\t\tlogEvent.setAppId(appId);\n\t\t\tlogEvent.setContainerId(containerId);\n\t\t\tlogEvent.setContainerType(containerType);\n\t\t\tlogEvent.setHost(InetAddress.getLocalHost().getHostName());\n\t\t\tlogEvent.setNodeIp(nodeIp);\n\t\t\tlogEvent.setLoggerName(event.getLoggerName());\n\t\t\tlogEvent.setLevel(event.getLevel().toString());\n\t\t\tlogEvent.setSource(source);\n\t\t\tlogEvent.setTimestamp(event.getTimeMillis());\n\t\t\tlogEvent.setThread(event.getThreadName());\n\t\t\tlogEvent.setMessage(message);\n\t\t\tlogEvent.setStacktrace(ExceptionUtil.getStackTrace(event.getThrown()));\n\t\t\tlogEvent.setTaskName(taskName);\n\t\t\tlogEvent.setTaskId(taskId);\n\t\t\tString json = JacksonUtil.toJson(logEvent);\n\t\t\tproducer.send(new ProducerRecord<>(topic, json));\n\t\t} catch (JsonProcessingException e) {\n\t\t\tlog.warn(\\\"Failed to serialize log event to JSON\\\", e);\n\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\\\"Failed to send log event to Kafka\\\", e);\n\n\t\t}\n\n\t}\n\n}", "CodeBleu_score": 45.14696704171952}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nif (event.getLevel().isMoreSpecificThan(org.apache.logging.log4j.Level.getLevel(level))) {\n            return;\n        }\n        if (event.getLoggerName().contains(\\\"xxx\\\")) {\n            return;\n        }\n        String json = null;\n        try {\n            json = JacksonUtil.toJson(event);\n        } catch (JsonProcessingException e) {\n            log.warn(\\\"Unable to serialize log event to JSON: {}\\\", e.getMessage());\n        }\n        if (json != null) {\n            try {\n                producer.send(new ProducerRecord<>(topic, json));\n            } catch (Exception e) {\n                log.warn(\\\"Unable to send log event to Kafka: {}\\\", e.getMessage());\n            }\n        }\n    }", "CodeBleu_score": 42.17750684544777}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 92.41207029386057}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn errors.New(fmt.Sprintf(\\\"unknown topic suffix method: %s\\\", method))\n}", "CodeBleu_score": 77.26836703920704}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 92.41207029386057}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar key string\n\tif k.RoutingTag != \\\"\\\" {\n\t\tif t, ok := metric.GetTag(k.RoutingTag);\n\t\tok {\n\t\t\tkey = t\n\t\t}\n\t}\n\tif k.RoutingKey == \\\"random\\\" {\n\t\tkey = uuid.NewV4().String()\n\t} else {\n\t\tkey = k.RoutingKey\n\t}\n\treturn key, nil\n}", "CodeBleu_score": 48.8231841460051}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \\\"\\\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag);\n\t\tok {\n\t\t\treturn tag,\n\t\t}\n\t}\n\tif k.RoutingKey == \\\"random\\\" {\n\t\tid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \\\"\\\", err\n\t\t}\n\t\treturn id.String(), nil\n\t}\n\treturn k.RoutingKey,\n}", "CodeBleu_score": 66.74380760763779}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \\\"\\\" {\n\t\tif key, ok := metric.GetTag(k.RoutingTag);\n\t\tok {\n\t\t\treturn key, nil\n\t\t}\n\t\treturn \\\"\\\", fmt.Errorf(\\\"routing tag not found: %s\\\", k.RoutingTag)\n\t}\n\tif k.RoutingKey == \\\"random\\\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 58.02002373924336}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, r := range k.TopicRegexps {\n\t\tif k.regexps[i], err = regexp.Compile(r);\n\t\terr != nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic regexp %q: %w\\\", r, err)\n\t\t}\n\t}\n\treturn nil\n}", "CodeBleu_score": 50.75200341407356}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, pattern := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(pattern)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic_regexp %q: %w\\\", pattern, err)\n\t\t}\n\t\tk.regexps[i] = *regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.431734872221135}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]regexp.Regexp, len(k.TopicRegexps))\n\tfor i, s := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(s)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\\\"invalid topic_regexp %q: %w\\\", s, err)\n\t\t}\n\t\tk.regexps[i] = *regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.292644023471425}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\treturn\n\t}\n\tmsg.session.MarkMessage(msg.message, \"\")\n\tdelete(h.undelivered, track.ID)\n\th.sem <- empty{}\n}", "CodeBleu_score": 52.25907021259128}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID()]\n\tif ok {\n\t\tif track.Delivered() {\n\t\t\tmsg.session.MarkMessage(msg.message, \"\")\n\t\t}\n\t\tdelete(h.undelivered, track.ID())\n\t\th.sem <- empty{}\n\t}\n}", "CodeBleu_score": 69.8602620124335}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID()]\n\tif !ok {\n\t\th.log.Warnf(\\\"message with tracking id %d not found\\\", track.ID())\n\t\treturn\n\t}\n\n\tif track.Delivered() {\n\t\tmsg.session.MarkMessage(msg.message, \\\"\\\")\n\t\tdelete(h.undelivered, track.ID())\n\t}\n\th.sem <- empty{}\n}", "CodeBleu_score": 75.61119405387815}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\th.wg.Add(1)\n\tdefer h.wg.Done()\n\n\tctx := session.Context()\n\tfor {\n\t\t// Wait for a message or the context to be done.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\tif msg == nil {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(session, msg); err != nil {\n\t\t\t\th.log.Errorf(\\\"Failed to handle message: %v\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 63.61338435273139}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\t// Wait for a message to be delivered.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg := <-claim.Messages():\n\t\t\tif err := h.Handle(session, msg); err != nil {\n\t\t\t\th.log.Errorf(\\\"Error handling message: %v\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 47.778707230221684}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tfor {\n\t\tif err := session.Context().Err(); err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// Wait for a message to be delivered.\n\t\tselect {\n\t\tcase <-session.Context().Done():\n\t\t\treturn nil\n\t\tcase msg := <-claim.Messages():\n\t\t\tif err := h.Handle(session, msg); err != nil {\n\t\t\t\th.log.Errorf(\\\"Error handling message: %v\\\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 62.05667385216621}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\n\tcheckCondition(logkafka_id.length <= maxNameLength, LogkafkaIdInvalidLength)\n\tcheckCondition(logkafka_id != \".\", LogkafkaIdIsDot)\n\tcheckCondition(logkafka_id != \"..\", LogkafkaIdIsDotDot)\n\trgx.findFirstIn(logkafka_id) match {\n\t\tcase Some(t) =>\n\t\t\tcheckCondition(t.equals(logkafka_id), LogkafkaIdIllegalCharacter(logkafka_id))\n\t\tcase None =>\n\t\t\tcheckCondition(false, LogkafkaIdIllegalCharacter(logkafka_id))\n\t}\n}", "CodeBleu_score": 71.65637549227053}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\ncheckCondition(logkafka_id != \".\", LogkafkaIdInvalid)\ncheckCondition(logkafka_id != \"..\", LogkafkaIdInvalid)\ncheckCondition(logkafka_id.length <= maxNameLength, LogkafkaIdLengthExceeded)\ncheckCondition(rgx.findFirstIn(logkafka_id).isDefined, LogkafkaIdIllegalCharacter(logkafka_id))\n}", "CodeBleu_score": 50.06878511613883}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id.length > 0, LogkafkaIdEmpty)\n\tcheckCondition(logkafka_id != \".\", LogkafkaIdDot)\n\tcheckCondition(logkafka_id != \"..\", LogkafkaIdDotDot)\n\tcheckCondition(logkafka_id.length <= maxNameLength, LogkafkaIdTooLong)\n\tcheckCondition(rgx.findFirstIn(logkafka_id).isDefined, IllegalCharacterInLogkafkaId(logkafka_id))\n}", "CodeBleu_score": 51.587386685734494}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * Send the message to the actor and get a response.\n */\n    val response = ask(kafkaManagerActor, msg)(Timeout(kafkaManagerConfig.clusterActorsAskTimeoutMillis, MILLISECONDS))\n\n/**\n * Process the response.\n */\n    response.map {\n      case Success(result) =>\n        try {\n          Success(fn(result))\n        } catch {\n          case NonFatal(e) =>\n            error(s\"Error processing response from kafka manager actor: $e\")\n            error(s\"Response was: $result\")\n            Failure(ApiError(ApiError.error500, s\"Error processing response from kafka manager actor: $e\"))\n        }\n      case Failure(e) =>\n        error(s\"Error communicating with kafka manager actor: $e\")\n        Failure(ApiError(ApiError.error500, s\"Error communicating with kafka manager actor: $e\"))\n    }\n  }", "CodeBleu_score": 25.170409940011996}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\nIt takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\nIf the actor responds with an error, it logs the failure and returns an ApiError.\nIf the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\nThe function also includes error handling for any thrown exceptions during the process.\n */\n    val response = ask(kafkaManagerActor, msg).mapTo[Try[Output]].map {\n      case Success(output) => \\/-(fn(output))\n      case Failure(e) => {\n        error(s\\\"Failed to process response from kafka-manager actor : ${e.getMessage}\\\")\n        ApiError(\\\"Internal server error\\\", 500)\n      }\n    }\n\n/**\n * The tryWithKafkaManagerActor function sends a message to the Kafka manager actor and processes the response.\nIt takes an input message and a function to transform the output, returning a Future containing either an ApiError or the transformed output.\nIf the actor responds with an error, it logs the failure and returns an ApiError.\nIf the response is successful, it applies the transformation function and handles any exceptions, returning either the transformed output or an ApiError.\nThe function also includes error handling for any thrown exceptions during the process.\n */\n    response.recover {\n      case e: AskTimeoutException => {\n        error(s\\\"Failed to process response from kafka-manager actor : ${e.getMessage}\\\")\n        ApiError(\\\"Internal server error\\\", 500)\n      }\n    }\n  }", "CodeBleu_score": 24.47526343684742}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The future is created by sending the message to the Kafka manager actor.\n */\n    val future = ask(kafkaManagerActor, msg)(timeout = apiTimeout).mapTo[Output]\n\n/**\n * If the future is successful, it applies the transformation function and returns the result.\n */\n    future.map { output =>\n      try {\n        \\/-(fn(output))\n      } catch {\n        case NonFatal(e) =>\n          error(s\\\"Failed to transform response from Kafka manager actor: $output\\\", e)\n          -\\/(ApiError(ApiError.managerActorFailure, \\\"Failed to transform response from Kafka manager actor\\\", e))\n      }\n    }\n\n/**\n * If the future fails, it logs the failure and returns an ApiError.\n */\n    future.recover {\n      case NonFatal(e) =>\n        error(s\\\"Failed to get response from Kafka manager actor: $msg\\\", e)\n        -\\/(ApiError(ApiError.managerActorFailure, \\\"Failed to get response from Kafka manager actor\\\", e))\n    }\n  }", "CodeBleu_score": 23.819527015478688}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n}", "CodeBleu_score": 8.530240643372098}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\nimplicit val ec = apiExecutionContext\nsystem.actorSelection(kafkaManagerActor).ask(msg).map {\n  case err: ActorErrorResponse =>\n    error(s\\\"Failed on input : $msg\\\")\n    -\\/(ApiError.from(err))\n  case o: Output =>\n    Try {\n      fn(o)\n    } match {\n      case Failure(t) =>\n        error(s\\\"Failed on input : $msg\\\")\n        -\\/(ApiError.fromThrowable(t))\n      case Success(foutput) => \\/-(foutput)\n    }\n}.recover { case t: Throwable =>\n  error(s\\\"Failed on input : $msg\\\", t)\n  -\\/(ApiError.fromThrowable(t))\n}\n}", "CodeBleu_score": 70.90241731318969}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n}", "CodeBleu_score": 8.140979095809902}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMRunPreferredLeaderElection(Set.empty[String])\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 49.69900100899948}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMRunPreferredLeaderElectionWithAllTopics\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 47.49419153520394}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\nKMClusterCommandRequest(\nclusterName,\nCMRunPreferredLeaderElection(Set())\n)\n) { result: Future[CMCommandResult] =>\nresult.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 46.17715750966927}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMMakePreferredReplicaElection(\n      assignments\n    )\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 21.947132361424128}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMMakePreferredReplicaElectionManualAssignments(assignments)\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 22.419838227289528}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nwithKafkaManagerActor(\n  KMClusterCommandRequest(\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 23.080880879504946}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tSet<Node> nodes = admin.describeCluster().nodes().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No brokers available to retrieve configuration\");\n\t}\n\n\tNode node = nodes.iterator().next();\n\tDescribeConfigsResult result = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString())));\n\tMap<ConfigResource, Config> configs = result.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration for broker \" + node.idString());\n\t}\n\n\treturn configs.get(new ConfigResource(ConfigResource.Type.BROKER, node.idString()));\n}", "CodeBleu_score": 69.74724804319852}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tfinal DescribeClusterResult clusterResult = admin.describeCluster(DescribeClusterOptions.builder().timeoutMs(kafkaQueryTimeout.toMillis()).build());\n\tfinal Collection<Node> nodes = clusterResult.nodes().get();\n\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No broker nodes available to retrieve configuration\");\n\t}\n\n\tfinal Node node = nodes.iterator().next();\n\tfinal DescribeConfigsResult configResult = admin.describeConfigs(Collections.singleton(ConfigResource.forNode(node.idString(), ConfigResource.Type.BROKER)), DescribeConfigsOptions.builder().includeSynonyms(false).build());\n\tfinal Map<ConfigResource, Config> configs = configResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration available for broker node \" + node.idString());\n\t}\n\n\treturn configs.values().iterator().next();\n}", "CodeBleu_score": 63.09462359151106}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tfinal DescribeClusterResult clusterResult = admin.describeCluster(DescribeClusterOptions.builder().timeoutMs(kafkaQueryTimeout.toMillis()).build());\n\tfinal Collection<Node> nodes = clusterResult.nodes().get();\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(String.format(\"No nodes found in cluster %s\", clusterResult.clusterId().get()));\n\t}\n\tfinal Node node = nodes.iterator().next();\n\tfinal DescribeConfigsResult configsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString())), DescribeConfigsOptions.builder().includeSynonyms(false).build());\n\tfinal Map<ConfigResource, Config> configs = configsResult.all().get(kafkaQueryTimeout.toMillis(), TimeUnit.MILLISECONDS);\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(String.format(\"No broker configs found in cluster %s\", clusterResult.clusterId().get()));\n\t}\n\treturn configs.values().iterator().next();\n}", "CodeBleu_score": 57.77368722334245}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void ensureValid(Config config) {\n\t\t\tfinal String schemaHistory = config.getString(DatabaseConnectorConfig.SCHEMA_HISTORY_CLASS_CONFIG);\n\t\t\tif (schemaHistory != null && schemaHistory.equals(KafkaDatabaseHistory.class.getName())) {\n\t\t\t\tvalidator.ensureValid(config);\n\t\t\t}\n\t\t}\n\t};\n}", "CodeBleu_score": 39.8923942952455}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void ensureValid(final Configuration configuration) {\n\t\t\tif (KafkaSchemaHistory.isEnabled(configuration)) {\n\t\t\t\tvalidator.ensureValid(configuration);\n\t\t\t}\n\t\t}\n\t};\n}", "CodeBleu_score": 19.861372083477626}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\tif (KafkaSchemaHistory.isConfigured(configs)) {\n\t\t\t\tvalidator.configure(configs);\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic ValidationResult validate(String name, Map<String, ?> configs) {\n\t\t\tif (KafkaSchemaHistory.isConfigured(configs)) {\n\t\t\t\treturn validator.validate(name, configs);\n\t\t\t}\n\t\t\treturn ValidationResult.success();\n\t\t}\n\t};\n}", "CodeBleu_score": 28.07209792182519}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tVersion kafkaVersion = parseVersion(AppInfoParser.getVersion());\n\tBoolean isTopicCreationEnabled = Boolean.TRUE;\n\tif (kafkaVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0) {\n\t\tObject topicCreationEnabled = config.get(\\\"topic.creation.enable\\\");\n\t\tif (null != topicCreationEnabled) {\n\t\t\tisTopicCreationEnabled = Boolean.parseBoolean(topicCreationEnabled.toString());\n\t\t}\n\n\t}\n\n\treturn isTopicCreationEnabled;\n\n}", "CodeBleu_score": 46.15677685085004}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tVersion kafkaVersion = parseVersion(AppInfoParser.getVersion());\n\tif (kafkaVersion.compareTo(TOPIC_CREATION_KAFKA_VERSION) >= 0) {\n\t\tObject topicCreationEnabled = config.get(\\\"topic.creation.enable\\\");\n\t\tif (null != topicCreationEnabled) {\n\t\t\treturn Boolean.parseBoolean(topicCreationEnabled.toString());\n\t\t}\n\t}\n\treturn true;\n}", "CodeBleu_score": 38.8811839146374}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (null == this.isTopicCreationEnabled) {\n\t\tthis.isTopicCreationEnabled = TOPIC_CREATION_KAFKA_VERSION.compareTo(parseVersion(AppInfoParser.getVersion())) >= 0\n\t\t\t\t&& Boolean.parseBoolean(config.getOrDefault(\\\"topic.creation.enable\\\", \\\"true\\\").toString());\n\t}\n\treturn this.isTopicCreationEnabled;\n}", "CodeBleu_score": 19.96026011177989}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tMap<String, String> adminConfig = new HashMap<>();\n\tadminConfig.put(DistributedConfig.GROUP_ID_CONFIG, config.get(DistributedConfig.GROUP_ID_CONFIG));\n\tadminConfig.put(DistributedConfig.ZOOKEEPER_CONNECT_CONFIG, config.get(DistributedConfig.ZOOKEEPER_CONNECT_CONFIG));\n\tadminConfig.put(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG));\n\tadminConfig.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG));\n\tadminConfig.put(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG));\n\tadminConfig.put(CLIENT_ID_CONFIG, config.get(CLIENT_ID_CONFIG));\n\tSharedTopicAdmin admin = new SharedTopicAdmin(adminConfig);\n\tif (admin.partitionsRemaining(config.get(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG)) < 1) {\n\t\tthrow new DebeziumException(config.get(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG) + \" topic does not exist or is not configured properly.\");\n\t}\n\tif (admin.partitionsRemaining(config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG)) < 1) {\n\t\tthrow new DebeziumException(config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG) + \" topic does not exist or is not configured properly.\");\n\t}\n\tif (admin.partitionsRemaining(config.get(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG)) < 1) {\n\t\tthrow new DebeziumException(config.get(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG) + \" topic does not exist or is not configured properly.\");\n\t}\n\treturn new KafkaOffsetBackingStore(admin, config.get(CLIENT_ID_CONFIG), converterForOffsetStore());\n}", "CodeBleu_score": 36.0583728158671}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tif (config.get(DistributedConfig.GROUP_ID_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect group.id configuration property is required\\\");\n\t}\n\tif (config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect offset.storage.topic configuration property is required\\\");\n\t}\n\tif (config.get(DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect offset.storage.replication.factor configuration property is required\\\");\n\t}\n\tif (config.get(DistributedConfig.OFFSET_STORAGE_PARTITIONS_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect offset.storage.partitions configuration property is required\\\");\n\t}\n\tif (config.get(CLIENT_ID_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect client.id configuration property is required\\\");\n\t}\n\tif (config.get(DistributedConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect offset.storage.file.filename configuration property is required\\\");\n\t}\n\tif (config.get(DistributedConfig.OFFSET_STORAGE_FILE_SYNC_INTERVAL_MS_CONFIG) == null) {\n\t\tthrow new DebeziumException(\\\"Kafka Connect offset.storage.file.sync.interval.ms configuration property is required\\\");\n\t}\n\tMap<String, Object> adminProps = new HashMap<>();\n\tadminProps.put(DistributedConfig.GROUP_ID_CONFIG, config.get(DistributedConfig.GROUP_ID_CONFIG));\n\tadminProps.put(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG));\n\tSharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\treturn new KafkaOffsetBackingStore(admin, config.get(CLIENT_ID_CONFIG), converterForOffsetStore());\n}", "CodeBleu_score": 39.08911960374431}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t\nif (node.isObject()) {\nIterator<String> fieldNames = node.fieldNames();\nif (fieldNames.hasNext()) {\nString fieldName = fieldNames.next();\nif (fieldNames.hasNext()) {\nreturn reader.readValue(node);\n}\nelse {\nreturn reader.readValue(node.get(fieldName));\n}\n}\n}\n}", "CodeBleu_score": 36.857020727731125}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t\n\tif (!node.isObject()) {\n\t\tthrow new IOException(\"Invalid key format: expected JSON object, but got \" + node.getNodeType());\n\t}\n\n\tIterator<String> fieldNames = node.fieldNames();\n\tif (fieldNames.hasNext()) {\n\t\tString fieldName = fieldNames.next();\n\t\tif (fieldNames.hasNext()) {\n\t\t\treturn reader.readValue(node);\n\t\t}\n\t\telse {\n\t\t\treturn reader.readValue(node.get(fieldName));\n\t\t}\n\t}\n\telse {\n\t\tthrow new IOException(\"Invalid key format: expected JSON object with at least one field, but got \" + node.getNodeType());\n\t}\n}", "CodeBleu_score": 43.80356160489385}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t\nif (!node.isObject()) {\nthrow new IllegalArgumentException(\\\"Key must be an object\\\");\n}\n\nIterator<String> fieldNames = node.fieldNames();\n\nif (!fieldNames.hasNext()) {\nthrow new IllegalArgumentException(\\\"Key must not be empty\\\");\n}\n\nString fieldName = fieldNames.next();\n\n// Schema + payload format\nif (fieldNames.hasNext()) {\nnode = node.get(fieldName);\n}\n// Debezium envelope\nif (config.asEnvelope()) {\nreturn reader.readValue(node);\n}\nelse if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\nreturn reader.readValue(node.get(config.sourceField()));\n}\n// Extracted format\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 45.91810566373091}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tString sanitized = sanitize(topicName);\n\tif (!topicName.equals(sanitized)) {\n\t\tLOGGER.warn(\\\"Topic name {} is invalid, sanitized to {}\\\", topicName, sanitized);\n\t}\n\treturn sanitized;\n}", "CodeBleu_score": 21.65439236478321}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tString sanitizedName = topicName;\n\tboolean replaced = false;\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (c == '.' || c == '_' || c == '\\\\' || c == '-' || c == '/' || (c >= '0' && c <= '9') || (c >= 'A' && c <= 'Z') || (c >= 'a' && c <= 'z')) {\n\t\t\tcontinue;\n\t\t}\n\t\treplaced = true;\n\t\tsanitizedName = sanitizedName.substring(0, i) + REPLACEMENT_CHAR + sanitizedName.substring(i + 1);\n\n\t}\n\tif (replaced) {\n\t\tLOGGER.warn(\\\"Topic name '{}' contains invalid characters, replacing with '{}'. This may be a sign of a misconfigured topic naming strategy. The topic name will be used as-is, but this may result in data loss. To avoid this, change the topic naming strategy configuration to use a valid topic name.\\\", topicName, sanitizedName);\n\t}\n\treturn sanitizedName;\n}", "CodeBleu_score": 52.33030291971764}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t\tString topicName = delegate.topicNameFor(id, prefix, delimiter);\n\tif (topicName.equals(prefix)) {\n\t\treturn topicName;\n\t}\n\t\n\tStringBuilder sb = new StringBuilder(topicName.length());\n\tboolean replaced = false;\n\tfor (int i = 0; i < topicName.length(); i++) {\n\t\tchar c = topicName.charAt(i);\n\t\tif (c == delimiter.charAt(0) || c == REPLACEMENT_CHAR.charAt(0)) {\n\t\t\treplaced = true;\n\t\t\tsb.append(REPLACEMENT_CHAR);\n\t\t} else {\n\t\t\tsb.append(c);\n\t\t}\n\t}\n\tif (replaced) {\n\t\tLOGGER.warn(\\\"Topic name '{}' contains invalid characters and will be replaced with '{}'.\\\",\n\t\t\t\ttopicName, sb);\n\t\treturn sb.toString();\n\t}\n\treturn topicName;\n}", "CodeBleu_score": 55.36064793642076}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.producerThrowable = new AtomicReference<>();\n\tthis.maxRetries = connectorConfig.maxRetries();\n\tthis.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : RETRIES_UNLIMITED;\n}", "CodeBleu_score": 59.93501048371272}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\nthis.connectorConfig = connectorConfig;\n\n// Determine the maximum number of retries; default to unlimited\nmaxRetries = connectorConfig.getMaxRetries();\nif (maxRetries <= 0) {\nmaxRetries = RETRIES_UNLIMITED;\n}\n\nif (replacedErrorHandler != null) {\nretries = replacedErrorHandler.retries;\n}\nelse {\nretries = 0;\n}\n}", "CodeBleu_score": 60.254615406960134}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.producerThrowable = new AtomicReference<>();\nthis.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : RETRIES_UNLIMITED;\nthis.maxRetries = connectorConfig.getMaxRetries();\nif (maxRetries < 0) {\nLOGGER.warn(\"Invalid max.retries value {} for connector {}; using unlimited retries instead\", maxRetries, connectorType.getName());\nthis.maxRetries = RETRIES_UNLIMITED;\n}\n}", "CodeBleu_score": 63.932313595299895}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\t// Check if the configuration is null\n\tif (configuration == null) {\n\t\tthrow new ConfigException(\"Configuration cannot be null\");\n\t}\n\n\t// Check if the fields is null\n\tif (fields == null) {\n\t\tthrow new ConfigException(\"Fields cannot be null\");\n\t}\n\n\t// Iterate through the fields\n\tfor (Field field : fields) {\n\t\t// Get the configuration value for the field\n\t\tConfigValue configValue = configuration.get(field);\n\n\t\t// Check if the config value is null\n\t\tif (configValue == null) {\n\t\t\t// Check if the field is required\n\t\t\tif (field.isRequired()) {\n\t\t\t\t// The field is required but was not found\n\t\t\t\tthrow new ConfigException(String.format(\"Field '%s' is required but was not found\", field.name()));\n\t\t\t}\n\t\t} else {\n\t\t\t// Check if the config value has error messages\n\t\t\tif (!configValue.errorMessages().isEmpty()) {\n\t\t\t\t// The config value has error messages\n\t\t\t\tthrow new ConfigException(configValue.errorMessages().get(0));\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 33.937291576768104}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tfor (ConfigValue configValue : configuration.validate(fields)) {\n\t\tif (configValue.errorMessages().size() > 0) {\n\t\t\tthrow new ConfigException(configValue.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 26.041681988746873}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tfor (ConfigValue configValue : configuration.validate(fields)) {\n\t\tif (configValue.errorMessages() != null && !configValue.errorMessages().isEmpty()) {\n\t\t\tthrow new ConfigException(configValue.errorMessages().iterator().next());\n\t\t}\n\t}\n}", "CodeBleu_score": 28.03845308551133}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nSchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n\nif (isContainedIn(field.name(), nestedFields)) {\n\nSchema nestedSchema = oldSchema.field(field.name()).schema();\n\nif (nestedSchema.type() == Schema.Type.STRUCT) {\n\nSchemaBuilder nestedSchemaBuilder = SchemaBuilder.struct();\n\nfor (org.apache.kafka.connect.data.Field nestedField : nestedSchema.fields()) {\n\nSchema newNestedSchema = buildNewSchema(field.name(), nestedSchema, headerToProcess, nestedFields, ++level);\n\nnestedSchemaBuilder.field(nestedField.name(), newNestedSchema);\n}\n\nSchema newNestedSchema = nestedSchemaBuilder.build();\n\nnewSchemaBuilder.field(field.name(), newNestedSchema);\n}\nelse {\nnewSchemaBuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\n}\nelse {\nnewSchemaBuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader != null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\n\nif (fieldNameToAdd.isPresent()) {\nnewSchemaBuilder.field(fieldNameToAdd.get(), Schema.OPTIONAL_STRING_SCHEMA);\n}\n}\n}\n\nreturn newSchemaBuilder.build();\n}", "CodeBleu_score": 51.02308060835371}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\nSchemaBuilder newSchemaBuilder = SchemaBuilder.struct().name(oldSchema.name());\n\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n\nif (isContainedIn(field.name(), nestedFields)) {\n\nStructSchema nestedSchema = (StructSchema) oldSchema.field(field.name()).schema();\nnewSchemaBuilder.field(field.name(), buildNewSchema(field.name(), nestedSchema, headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemaBuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\n}\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader != null) {\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\nfieldNameToAdd.ifPresent(s -> newSchemaBuilder.field(s, currentHeader.schema()));\n}\n}\n\nreturn newSchemaBuilder.build();\n}", "CodeBleu_score": 54.34570305474976}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\nLOGGER.debug(\\\"Schema {} is primitive. Returning as is\\\", oldSchema);\nreturn oldSchema;\n}\n\nLOGGER.debug(\\\"Building new schema for field {}\\\", fieldName);\nSchemaBuilder schemaBuilder = SchemaBuilder.struct().name(oldSchema.name());\n\n\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n\nif (isContainedIn(field.name(), nestedFields)) {\n\nStruct nestedField = requireStruct(oldSchema.field(field.name()).schema(), \\\"Nested field\\\");\nschemaBuilder.field(field.name(), buildNewSchema(field.name(), nestedField, headerToProcess, nestedFields, ++level));\n}\nelse {\nschemaBuilder.field(field.name(), oldSchema.field(field.name()).schema());\n}\n}\n\n\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\n\nif (currentHeader != null) {\n\nOptional<String> fieldNameToAdd = getFieldName(fields.get(i), fieldName, level);\n\nfieldNameToAdd.ifPresent(s -> schemaBuilder.field(s, Schema.OPTIONAL_STRING_SCHEMA));\n}\n}\n\n\nreturn schemaBuilder.build();\n}", "CodeBleu_score": 43.11981021390976}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source == null) {\n\t\treturn null;\n\t}\n\tObject snapshotString = source.get(SNAPSHOT_KEY);\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\tString snapshot = snapshotString.toString().toUpperCase();\n\ttry {\n\t\treturn SnapshotRecord.valueOf(snapshot);\n\t}\n\tcatch (IllegalArgumentException e) {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 32.82240739073621}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source == null) {\n\t\treturn null;\n\t}\n\tObject snapshotString = source.get(SNAPSHOT_KEY);\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\ttry {\n\t\treturn SnapshotRecord.valueOf(snapshotString.toString().toUpperCase());\n\t}\n\tcatch (Exception e) {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 27.054162485130067}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source != null) {\n\t\tfinal String snapshotString = (String) source.get(SNAPSHOT_KEY);\n\t\tif (snapshotString != null) {\n\t\t\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 43.97904287373842}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0].split(\"-\")[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 61.44056952461673}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\tString[] parts = version.split(\"\\\\.\");\nif (parts.length > 2) {\nparts = Arrays.copyOfRange(parts, 0, 2);\n}\nString[] subParts = parts[0].split(\"-\");\nif (subParts.length > 0) {\nreturn Optional.of(Float.parseFloat(subParts[0]));\n} else {\nreturn Optional.of(Float.parseFloat(parts[0]));\n}\n}", "CodeBleu_score": 53.38322053628842}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\nString[] parts = version.split(\"\\\\.\");\n\nif (parts.length > 2) {\nparts = new String[]{parts[0], parts[1]};\n}\n\nfloat major = Float.parseFloat(parts[0]);\n\nif (parts.length > 1) {\nString[] minorParts = parts[1].split(\"-\");\n\nif (minorParts.length > 0) {\nreturn Optional.of(major + Float.parseFloat(minorParts[0]) / 100);\n}\n}\n\nreturn Optional.of(major);\n}", "CodeBleu_score": 51.46587051974054}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context)\n.then(connector.map(c -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, c)))\n.map(ResponseEntity::ok)\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 69.02713431041924}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context)\n.then(connector)\n.map(kafkaConnectService::createConnector)\n.map(ResponseEntity::ok)\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 63.55080828421001}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context)\n.then(connector.map(c -> kafkaConnectService.createConnector(getCluster(clusterName), connectName, c)))\n.map(ResponseEntity::ok)\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 69.01911578759506}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n    .cluster(clusterName)\n    .connect(connectName)\n    .connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n    .connector(connectorName)\n    .operationName(\"deleteConnector\")\n    .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n        .then(Mono.just(ResponseEntity.ok().build()))\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 73.31673506601082}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n.connector(connectorName)\n.operationName(\"deleteConnector\")\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 77.19586843301744}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.DELETE)\n.connector(connectorName)\n.operationName(\"deleteConnector\")\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n.then(Mono.just(ResponseEntity.ok().build()))\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 70.77888018247289}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n.operationName(\"updateConnectorState\")\n.operationParams(Map.of(\"connectorName\", connectorName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n.map(ResponseEntity::ok))\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 49.753426403519505}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok))\n    .doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 55.344542528226306}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n.operationName(\"updateConnectorState\")\n.operationParams(Map.of(CONNECTOR_NAME, connectorName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n.map(ResponseEntity::ok))\n.doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 51.78610963028125}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n}", "CodeBleu_score": 8.648212644078399}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n    .initializers(new DynamicConfigInitializer())\n    .run(args);\n}", "CodeBleu_score": 40.29984642933106}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\n    return new SpringApplicationBuilder(KafkaUiApplication.class)\n      .initializers((ApplicationContextInitializer<ConfigurableApplicationContext>) applicationContext -> {\n        DynamicConfigOperations.init(applicationContext.getEnvironment());\n      })\n      .run(args);\n  }", "CodeBleu_score": 40.547317998930886}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\nreturn new SpringApplicationBuilder(KafkaUiApplication.class)\n    .initializers(new DynamicConfigInitializer())\n    .run(args);\n\n}", "CodeBleu_score": 40.25405484054776}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn search == null ? t -> true : t -> Stream.of(t.getName(), t.getType(), t.getState().getStatus())\n.anyMatch(s -> s != null && s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 36.68421644905108}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\nreturn connector -> true;\n}\nreturn connector -> Stream.of(connector.getName(), connector.getType(), connector.getState())\n.anyMatch(s -> StringUtils.containsIgnoreCase(s, search));\n}", "CodeBleu_score": 63.744237001973225}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\nreturn connector -> true;\n}\nreturn connector -> Stream.of(\nconnector.getName(),\nconnector.getType(),\nconnector.getState().getStatus(),\nconnector.getConnector().getConnectorClass(),\nconnector.getConnector().getTasks().stream()\n.map(TaskDTO::getId)\n.toList(),\nconnector.getTopics().stream()\n.map(ConnectorTopics::getName)\n.toList()\n).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 50.301816047656445}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\nIf the value is another map, it recursively flattens it with the new key as the prefix.\nOtherwise, it adds the key-value pair to the flattened map.\nFinally, it returns the flattened map.\n */\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String newKey = (prefix != null ? prefix + \".\" + entry.getKey() : entry.getKey());\n      if (entry.getValue() instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattened.put(newKey, entry.getValue());\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 50.14797530742487}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\nIf the value is another map, it recursively flattens it with the new key as the prefix.\nOtherwise, it adds the key-value pair to the flattened map.\nFinally, it returns the flattened map.\n */\n    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newPrefix = prefix != null ? prefix + \".\" + key : key;\n        if (value instanceof Map) {\n          flattenedProperties.putAll(flattenClusterProperties(newPrefix, (Map<String, Object>) value));\n        } else {\n          flattenedProperties.put(newPrefix, value);\n        }\n      }\n    }\n    return flattenedProperties;\n\n  }", "CodeBleu_score": 53.52195248814191}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t", "CodeBleu_score": 11.217587828108096}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SslConfigs.SSL_KEYSTORE_PASSWORD_DOC);\n configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SslConfigs.SSL_KEY_PASSWORD_DOC);\n configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SslConfigs.SSL_TRUSTSTORE_PASSWORD_DOC);\n configDef.define(SslConfigs.SSL_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SslConfigs.SSL_PASSWORD_DOC);\n configDef.define(SaslConfigs.SASL_JAAS_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SaslConfigs.SASL_JAAS_PASSWORD_DOC);\n configDef.define(SaslConfigs.SASL_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, null, ConfigDef.Importance.HIGH, SaslConfigs.SASL_PASSWORD_DOC);\n return configDef.configKeys().stream()\n .filter(c -> c.type == ConfigDef.Type.PASSWORD)\n .map(c -> c.name)\n .collect(Collectors.toSet());\n }", "CodeBleu_score": 50.06063878826622}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn adminClient.describeAcls(AclOperation.ALL)\n.flatMap(acl -> {\nSet<AclOperation> operations = acl.values().stream()\n.flatMap(List::stream)\n.map(aclEntry -> AclOperation.fromCode(aclEntry.operation()))\n.collect(Collectors.toSet());\n\nif (operations.containsAll(AclOperation.WRITE_OPERATIONS)) {\nreturn Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n} else {\nreturn Mono.empty();\n}\n});\n}", "CodeBleu_score": 46.66674706617279}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn adminClient.describeAcls()\n    .map(aclBinding -> aclBinding.entries().stream()\n        .map(aclEntry -> aclEntry.operation())\n        .filter(operation -> operation != AclOperation.DESCRIBE)\n        .collect(Collectors.toSet()))\n    .filter(operations -> operations.containsAll(ACL_VIEW_OPERATIONS))\n    .map(operations -> operations.containsAll(ACL_EDIT_OPERATIONS))\n    .filter(Boolean::booleanValue)\n    .map(isAllowed -> isAllowed ? ClusterFeature.KAFKA_ACL_EDIT : null)\n    .switchIfEmpty(Mono.empty());\n}", "CodeBleu_score": 24.380123339077528}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn clusterDescription.authorizedOperations()\n\t\t.map(this::getAclOperations)\n\t\t.filter(ops -> ops.containsAll(Set.of(AclOperation.ALTER, AclOperation.DESCRIBE)))\n\t\t.switchIfEmpty(adminClient.describeAcls(AclBindingFilter.ANY)\n\t\t\t.map(aclBinding -> getAclOperations(aclBinding.entry().operation()))\n\t\t\t.filter(ops -> ops.containsAll(Set.of(AclOperation.ALTER, AclOperation.DESCRIBE))))\n\t\t.map(ops -> ops.containsAll(Set.of(AclOperation.ALTER, AclOperation.DESCRIBE)) ? ClusterFeature.KAFKA_ACL_EDIT : null)\n\t\t.switchIfEmpty(Mono.empty());\n}", "CodeBleu_score": 31.4992649019705}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\nTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>(Comparator.comparing(TopicPartition::topic));\n\n// Initialize the map of offsets to read from based on the previous range or the offsets from seek operations\nif (!prevRange.isEmpty()) {\nnextRange.putAll(prevRange);\n} else {\nnextRange.putAll(seekOperations.getSeekToOffsets());\n}\n\n// Calculate the number of messages to poll per partition\nint messagesToPoll = calculateMessagesToPoll(nextRange);\n\n// For each topic partition, determine the start offset and adjust it based on the number of messages to poll\n// ensuring it does not go below the beginning offset\nfor (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\nTopicPartition tp = entry.getKey();\nFromToOffset offset = entry.getValue();\n\nlong startOffset = offset.getFrom();\nlong endOffset = offset.getTo();\n\nif (startOffset - messagesToPoll < 0) {\nstartOffset = 0;\n} else {\nstartOffset -= messagesToPoll;\n}\n\nnextRange.put(tp, new FromToOffset(startOffset, endOffset));\n}\n\nreturn nextRange;\n}", "CodeBleu_score": 37.76153773796088}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, Long> offsetsToReadFrom = new TreeMap<>();\n\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n\t\tif (entry.getValue().getFrom() != null) {\n\t\t\toffsetsToReadFrom.put(entry.getKey(), entry.getValue().getFrom());\n\t\t} else {\n\t\t\toffsetsToReadFrom.put(entry.getKey(), seekOperations.get(entry.getKey()));\n\t\t}\n\t}\n\tlong numberOfMessagesToPoll = Math.min(messagesPerPage, getNumberOfMessagesToPoll(offsetsToReadFrom));\n\tTreeMap<TopicPartition, FromToOffset> result = new TreeMap<>();\n\tfor (Map.Entry<TopicPartition, Long> entry : offsetsToReadFrom.entrySet()) {\n\t\tlong startOffset = Math.max(entry.getValue() - numberOfMessagesToPoll, 0);\n\t\tresult.put(entry.getKey(), new FromToOffset(startOffset, entry.getValue()));\n\t}\n\treturn result;\n}", "CodeBleu_score": 38.315810837857136}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t", "CodeBleu_score": 3.709413387662834}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}, {"code": "public void doLaunch(final MessageInput input){\n\t", "CodeBleu_score": 2.3542208163979508}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tfinal Properties customProps = new Properties();\n\t\tcustomProps.load(new StringReader(configuration.getString(CK_CUSTOM_PROPERTIES)));\n\t\tprops.putAll(customProps);\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Failed to load custom properties\\\", e);\n}\n}", "CodeBleu_score": 38.91575985656834}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tfinal String customProperties = configuration.getString(CK_CUSTOM_PROPERTIES);\n\t\tif (customProperties != null) {\n\t\t\tfinal Properties customProps = new Properties();\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t}\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Failed to load custom properties\\\", e);\n\t}\n}", "CodeBleu_score": 46.426680207110635}, {"code": "private void insertCustomProperties(Properties props){\n\t\tfinal String customPropertiesString = configuration.getString(CK_CUSTOM_PROPERTIES);\n\ttry {\n\t\tfinal Properties customProperties = new Properties();\n\t\tcustomProperties.load(new StringReader(customPropertiesString));\n\t\tprops.putAll(customProperties);\n\t} catch (IOException e) {\n\t\tLOG.error(\\\"Failed to load custom properties: \\\" + customPropertiesString, e);\n\t}\n}", "CodeBleu_score": 50.83475696253992}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tObjects.requireNonNull(entries, \"entries\");\n\n\tfinal List<RawMessageEvent> filteredEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n\tfinal long totalMessageBytes = filteredEntries.stream().mapToLong(RawMessageEvent::getSize).sum();\n\n\tmetrics.totalMessages().mark(filteredEntries.size());\n\tmetrics.totalMessageBytes().mark(totalMessageBytes);\n\n\ttry {\n\t\twriteRetryer.call(() -> {\n\t\t\tkafkaJournal.write(filteredEntries);\n\t\t\treturn null;\n\t\t});\n\t} catch (ExecutionException | RetryException e) {\n\t\tLOG.error(\"Failed to write to journal\", e);\n\t\tmetrics.failedWriteAttempts().mark();\n\t\tthrow new MessageQueueException(\"Failed to write to journal\", e);\n\t}\n}", "CodeBleu_score": 41.92933281031827}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tObjects.requireNonNull(entries, \\\"entries must not be null\\\");\n\tmetrics.writeAttempts().mark();\n\ttry {\n\t\twriteRetryer.call(() -> {\n\t\t\tmetrics.writeAttemptsSucceeded().mark();\n\t\t\tlong bytesWritten = entries.stream().filter(Objects::nonNull).mapToLong(RawMessageEvent::serializedMessageSize).sum();\n\t\t\tmetrics.writeBytes().mark(bytesWritten);\n\t\t\tkafkaJournal.write(entries.stream().filter(Objects::nonNull).map(entry -> new LocalKafkaJournal.JournalEntry(entry.message(), entry.messageSize(), entry.timestamp(), entry.id())).collect(Collectors.toList()));\n\t\t\tmetrics.messagesWritten().mark(entries.size());\n\t\t\tmetrics.bytesWritten().mark(bytesWritten);\n\t\t\treturn null;\n\t\t});\n\t} catch (ExecutionException | RetryException e) {\n\t\tmetrics.writeAttemptsFailed().mark();\n\t\tthrow new MessageQueueException(\\\"Failed to write to journal\\\", e);\n\t}\n}", "CodeBleu_score": 20.545599411438754}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n        if (entries == null || entries.isEmpty()) {\n            return;\n        }\n\n        try {\n            writeRetryer.call(() -> {\n                long start = System.nanoTime();\n                List<Journal.WriteContext> contexts = kafkaJournal.write(entries);\n                long duration = TimeUnit.NANOSECONDS.toMillis(System.nanoTime() - start);\n                metrics.writeAttempts().mark();\n                metrics.writeDuration(duration).mark();\n                metrics.writtenBytes(entries.stream().mapToLong(RawMessageEvent::getSize).sum()).mark();\n                metrics.writtenMessages(entries.size()).mark();\n                return null;\n            });\n        } catch (ExecutionException | RetryException e) {\n            throw new MessageQueueException(\\\"Failed to write to journal\\\", e);\n        }\n    }", "CodeBleu_score": 40.953457004181146}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages == null || messages.isEmpty()) {\n\t\treturn;\n\t}\n\n\tOptional<Long> maxValidMessageQueueId = messages.stream()\n\t\t.map(Message::getMessageQueueId)\n\t\t.filter(id -> id != null && id >= 0)\n\t\t.max(Long::compare);\n\n\tmaxValidMessageQueueId.ifPresent(this::acknowledge);\n\tmetrics.markAcknowledged(messages.size());\n}", "CodeBleu_score": 46.902819895037275}, {"code": "public void acknowledge(List<Message> messages){\n\tfinal Optional<Long> maxValidId = messages.stream().map(Message::getMessageQueueId).filter(Objects::nonNull).max(Comparator.naturalOrder());\nif (maxValidId.isPresent()) {\nkafkaJournal.ack(maxValidId.get());\n}\nmetrics.markMessagesAcknowledged(messages.size());\n}", "CodeBleu_score": 40.62215208963966}, {"code": "public void acknowledge(List<Message> messages){\n\tlong maxValidId = messages.stream().mapToLong(m -> m.getMessageQueueId()).max().orElse(0L);\nOptional<Long> lastCommittedId = kafkaJournal.lastCommittedMessageQueueId();\nif (lastCommittedId.isPresent() && lastCommittedId.get() >= maxValidId) {\nreturn;\n}\nkafkaJournal.commitOffset(maxValidId);\nmetrics.markMessagesAcknowledged(messages.size());\n}", "CodeBleu_score": 37.793156174701224}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tfinal Set<String> metricNames = metricRegistry.getNames();\n\tfor (final String metricName : metricNames) {\n\t\tif (metricName.startsWith(LocalKafkaJournal.class.getName())) {\n\t\t\tfinal String legacyMetricName = metricName.replace(LocalKafkaJournal.class.getName(), LocalJournal.class.getName());\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyMetricName, metricRegistry.getMetrics().get(metricName));\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOG.warn(\\\"Failed to register legacy metric {}. This may be due to a change in the metric name.\\\", legacyMetricName, e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 38.65569007997456}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal Map<String, Gauge> gauges = metricRegistry.getGauges((name, metric) -> name.toString().startsWith(LocalKafkaJournal.class.getName()));\n\tfor (final Map.Entry<String, Gauge> entry : gauges.entrySet()) {\n\t\tfinal String legacyMetricName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \\\"org.graylog2.shared.journal.KafkaJournal\\\");\n\t\ttry {\n\t\t\tmetricRegistry.register(legacyMetricName, entry.getValue());\n\t\t} catch (IllegalArgumentException e) {\n\t\t\tLOG.warn(\\\"Could not register legacy metric name {}\\\", legacyMetricName);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.147824699351986}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal Map<String, Gauge> gauges = metricRegistry.getGauges((name, metric) -> name.toString().startsWith(LocalKafkaJournal.class.getName()));\n\tfor (final Map.Entry<String, Gauge> gaugeEntry : gauges.entrySet()) {\n\t\tfinal String legacyMetricName = gaugeEntry.getKey().replace(LocalKafkaJournal.class.getName(), LEGACY_METRIC_PREFIX);\n\t\ttry {\n\t\t\tmetricRegistry.register(legacyMetricName, gaugeEntry.getValue());\n\t\t} catch (IllegalArgumentException e) {\n\t\t\tLOG.warn(\\\"Failed to register legacy metric {}. Original metric name was {}\\\", legacyMetricName, gaugeEntry.getKey());\n\t\t}\n\t}\n}", "CodeBleu_score": 42.53694280798106}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\tLOG.warn(\\\"Unable to register timer with name <{}>. This may be due to the metric name already being registered. Attempting to retrieve the existing timer.\\\", metricName);\n\t\treturn metricRegistry.timer(metricRegistry.getMetrics().keySet().stream().filter(key -> key.toString().equals(metricName)).findFirst().get());\n\t}\n}", "CodeBleu_score": 27.66240166856707}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tfinal Timer hdrTimer;\n\ttry {\n\t\thdrTimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\tLOG.warn(\\\"Timer with name [{}] is already registered. Retrieving existing timer.\\\", metricName);\n\t\thdrTimer = metricRegistry.timer(metricRegistry.getMetrics().get(metricName).getKey());\n\t}\n\treturn hdrTimer;\n}", "CodeBleu_score": 39.927202664211606}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\tTimer timer = metricRegistry.timer(metricName);\ntry {\nmetricRegistry.register(metricName, timer);\n} catch (IllegalArgumentException e) {\n// if the timer was already registered, we want to use the existing timer\ntimer = metricRegistry.timer(metricName);\n}\nreturn timer;\n}", "CodeBleu_score": 28.10745744376656}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\tfinal Gauge<Integer> gauge = new Gauge<Integer>() {\n@Override\npublic Integer getValue() {\nfinal long committedOffset = LocalKafkaJournal.this.getCommittedOffset();\nif (committedOffset == DEFAULT_COMMITTED_OFFSET) {\n// committed offset is not set, calculate the uncommitted messages\nfinal long logEndOffset = LocalKafkaJournal.this.getLogEndOffset();\nfinal long logStartOffset = LocalKafkaJournal.this.getLogStartOffset();\nif (logEndOffset < logStartOffset) {\nreturn 0;\n}\nreturn intRange((int) (logEndOffset - logStartOffset), 0, Integer.MAX_VALUE);\n} else {\n// committed offset is set, calculate the uncommitted messages\nfinal long logEndOffset = LocalKafkaJournal.this.getLogEndOffset();\nif (logEndOffset < committedOffset) {\nreturn 0;\n}\nreturn intRange((int) (logEndOffset - committedOffset), 0, Integer.MAX_VALUE);\n}\n}\n};\ntry {\nmetricRegistry.register(name, gauge);\n} catch (IllegalArgumentException e) {\nfinal SortedMap<String, Gauge> gauges = metricRegistry.getGauges((n, m) -> name.equals(n));\nfinal Gauge<Integer> existingGauge = Iterables.getOnlyElement(gauges.values());\nif (existingGauge.getClass().equals(gauge.getClass())) {\n// ignore exception if the gauge is already registered\n} else {\nthrow e;\n}\n}\n}", "CodeBleu_score": 30.791560736023126}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tGauge<Long> gauge = new Gauge<Long>() {\n\t\t@Override\n\t\tpublic Long getValue() {\n\t\t\tlong size = kafkaLog.size();\n\t\t\tif (size == 0) {\n\t\t\t\treturn 0L;\n\t\t\t}\n\n\t\t\tlong committedOffset = LocalKafkaJournal.this.getCommittedOffset();\n\t\t\tif (committedOffset == KafkaJournal.DEFAULT_COMMITTED_OFFSET) {\n\t\t\t\treturn kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n\t\t\t} else {\n\t\t\t\treturn kafkaLog.logEndOffset() - committedOffset;\n\t\t\t}\n\t\t}\n\t};\n\ttry {\n\t\tmetricRegistry.register(name, gauge);\n\t} catch (IllegalArgumentException e) {\n\t\tfinal SortedMap<String, Gauge> gauges = metricRegistry.getGauges((n, metric) -> name.equals(n));\n\t\tIterables.getOnlyElement(gauges.values());\n\t}\n}", "CodeBleu_score": 35.739538899246845}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tGauge<Integer> gauge = new Gauge<Integer>() {\n\t\t@Override\n\t\tpublic Integer getValue() {\n\t\t\tfinal long committedOffset = LocalKafkaJournal.this.getCommittedOffset();\n\t\t\tif (committedOffset == DEFAULT_COMMITTED_OFFSET) {\n\t\t\t\treturn intRange(intRange((int) kafkaLog.logEndOffset(), 0, Integer.MAX_VALUE), 0, Integer.MAX_VALUE);\n\t\t\t} else {\n\t\t\t\treturn intRange(intRange((int) kafkaLog.logEndOffset() - (int) committedOffset, 0, Integer.MAX_VALUE), 0, Integer.MAX_VALUE);\n\t\t\t}\n\t\t}\n\t};\n\ttry {\n\t\tmetricRegistry.register(name, gauge);\n\t} catch (IllegalArgumentException e) {\n\t\tfinal SortedMap<String, Gauge> gauges = metricRegistry.getGauges((n, m) -> name.equals(n));\n\t\tIterables.getOnlyElement(gauges.values());\n\t}\n}", "CodeBleu_score": 28.485625688306264}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tif (LOG.isDebugEnabled()) {\n\t\t\tLOG.debug(\\\"Flushing empty message set\\\");\n\t\t}\n\n\n\t} else {\n\n\t\tfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n\n\t\tfinal long messageSetSize = messageSet.sizeInBytes();\n\n\t\tif (LOG.isTraceEnabled()) {\n\n\t\t\tLOG.trace(\\\"Flushing {} bytes message set with {} messages\\\",\n\n\t\t\t\t\tmessageSetSize, messages.size());\n\n\t\t}\n\n\n\t}\n\tfinal long lastWriteOffset = log.append(messageSet);\n\n\tif (LOG.isTraceEnabled()) {\n\n\t\tLOG.trace(\\\"Journal {} wrote {} bytes to offset {} ({} bytes written, {} bytes in buffer)\\\",\n\n\t\t\t\tname, messageSetSize, lastWriteOffset, payloadSize, log.getAppendBuffer().size());\n\n\t}\n\n\twrittenMessages.mark(messages.size());\n\n\treturn lastWriteOffset;\n\n}", "CodeBleu_score": 47.00820539239481}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tLOG.debug(\\\"Flushing empty message set\\\");\n\t\treturn lastWriteOffset.get();\n\t}\n\n\n\tfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n\n\n\tif (LOG.isTraceEnabled()) {\n\n\t\tLOG.trace(\\\"Flushing message set with {} messages and {} bytes\\\", messages.size(), payloadSize);\n\n\t}\n\n\n\tfinal long startOffset = lastWriteOffset.get();\n\n\ttry {\n\n\t\tlastWriteOffset.set(append(messageSet).get());\n\n\t} catch (Exception e) {\n\n\t\tLOG.error(\\\"Error writing messages to log\\\", e);\n\n\t\tthrow new JournalException(\\\"Error writing messages to log\\\", e);\n\n\t}\n\n\n\tfinal long endOffset = lastWriteOffset.get();\n\n\tfinal long messageSetSize = endOffset - startOffset;\n\n\twrittenMessages.mark(messages.size());\n\n\tLOG.debug(\\\"Wrote {} messages with {} bytes to log, starting at offset {} and ending at offset {}. Total log size is now {} bytes\\\",\n\n\t\t\tmessages.size(), payloadSize, startOffset, endOffset, messageSetSize);\n\n\treturn endOffset;\n\n}", "CodeBleu_score": 48.135259290327916}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nLOG.debug(\\\"Flushing empty message set\\\");\n} else {\nLOG.debug(\\\"Flushing {} bytes message set with {} messages\\\", messageSetSize, messages.size());\n}\nfinal ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages.toArray(new Message[messages.size()]));\nfinal long startOffset = log.append(messageSet);\nlong lastWriteOffset = startOffset + messageSet.size() - 1;\n\nif (LOG.isTraceEnabled()) {\n\nLOG.trace(\\\"Flushing messages with payload size {} bytes, starting offset {} and last offset {}. Message set size {} bytes\\\",\n\npayloadSize, startOffset, lastWriteOffset, messageSet.sizeInBytes());\n\n}\n\nif (LOG.isDebugEnabled()) {\n\nLOG.debug(\\\"Wrote {} messages to log, starting at offset {} and ending at offset {}. Message set size {} bytes\\\",\n\nmessages.size(), startOffset, lastWriteOffset, messageSet.sizeInBytes());\n\n}\n\nwrittenMessages.mark(messages.size());\n\nreturn lastWriteOffset;\n\n}", "CodeBleu_score": 52.315227244376125}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\nif (adminClientList == null) {\nreturn;\n}\n\nLOGGER.info(\\\"Start closing kafka-admin-client for cluster-phy-id: {}\\\", clusterPhyId);\n\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close();\nLOGGER.info(\\\"Kafka-admin-client closed for cluster-phy-id: {}\\\", clusterPhyId);\n} catch (Exception e) {\nLOGGER.error(\\\"Kafka-admin-client close failed for cluster-phy-id: {}\\\", clusterPhyId, e);\n}\n}\n\nKAFKA_ADMIN_CLIENT_MAP.remove(clusterPhyId);\nLOGGER.info(\\\"Kafka-admin-client closed for cluster-phy-id: {}\\\", clusterPhyId);\n}", "CodeBleu_score": 43.360071413287606}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tLOGGER.info(\\\"close kafka admin client for cluster id: {}\\\", clusterPhyId);\n\tsynchronized (KAFKA_ADMIN_CLIENT_MAP) {\n\t\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\n\t\tif (adminClientList == null) {\n\t\t\treturn;\n\t\t}\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close();\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(e.getMessage(), e);\n\t\t\t}\n\t\t}\n\t\tKAFKA_ADMIN_CLIENT_MAP.remove(clusterPhyId);\n\t}\n}", "CodeBleu_score": 32.17330831514754}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\tList<AdminClient> adminClientList = KAFKA_ADMIN_CLIENT_MAP.get(clusterPhyId);\nif (adminClientList == null) {\n    return;\n}\n\nLOGGER.info(\\\"Start to close kafka admin-client for cluster-phy-id: {}\\\", clusterPhyId);\n\ntry {\n    for (AdminClient adminClient : adminClientList) {\n        adminClient.close();\n    }\n} catch (Exception e) {\n    LOGGER.error(\\\"Close kafka admin-client for cluster-phy-id: {} failed\\\", clusterPhyId, e);\n}\n\nKAFKA_ADMIN_CLIENT_MAP.remove(clusterPhyId);\nLOGGER.info(\\\"Close kafka admin-client for cluster-phy-id: {} successfully\\\", clusterPhyId);\n}", "CodeBleu_score": 45.15353541619923}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\n\tboolean success = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(Duration.ofSeconds(30));\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\n\treturn success;\n}", "CodeBleu_score": 80.71805809132513}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\n\tboolean success = true;\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(Duration.ofSeconds(30));\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\\\"close kafka AdminClient failed, clusterPhyId:{}\\\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\n\treturn success;\n}", "CodeBleu_score": 66.56933286020721}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\tboolean success = true;\nif (adminClientList == null) {\nreturn true;\n}\n\nfor (AdminClient adminClient : adminClientList) {\ntry {\nadminClient.close(Duration.ofSeconds(30));\n} catch (Exception e) {\nLOGGER.error(\\\"close kafka AdminClient failed, clusterPhyId:{}\\\", clusterPhyId, e);\nsuccess = false;\n}\n}\n\nreturn success;\n}", "CodeBleu_score": 64.28477902188419}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app != null)  {\n\t\tapp.stop();\n\t\tint count = 0;\n\t\twhile (app.isRunning() && count++ < 5)  {\n\t\t\ttry  {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e)  {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tif (app.isRunning())  {\n\t\t\tthrow new IllegalStateException(\\\"Application failed to stop\\\");\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 58.23318271146175}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\ttry {\n\t\t\tapp.stop();\n\t\t\tfor (int i = 0; i < 5; i++) {\n\t\t\t\tif (app.isRunning()) {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (app.isRunning()) {\n\t\t\t\tthrow new IllegalStateException(\\\"The application did not stop\\\");\n\t\t\t}\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tthrow new IllegalStateException(\\\"The application did not stop\\\", e);\n\t\t}\n\t\tfinally {\n\t\t\tapp = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 48.888412051878724}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\ttry {\n\t\t\tapp.stop();\n\t\t\tapp.close();\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tthrow new IllegalStateException(\\\"Failed to stop\\\", e);\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 29.723828892879595}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTls(caCert, serverCert, clientCert, KEY_STORE_PASSWORD, KEY_PASSWORD);\n\trunner.run();\n\treturn runner;\n}", "CodeBleu_score": 46.52621561083606}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\treturn startEurekaServer(config, null, null, null, null, null, null);\n}", "CodeBleu_score": 8.06009040843174}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\teurekaServerRunner.enableTls(caCert, serverCert, clientCert);\n\teurekaServerRunner.setKeystorePassword(KEY_STORE_PASSWORD);\n\teurekaServerRunner.setKeyPassword(KEY_PASSWORD);\n\teurekaServerRunner.setTruststorePassword(KEY_STORE_PASSWORD);\n\teurekaServerRunner.setTruststore(caCert);\n\teurekaServerRunner.setKeystore(serverCert, KEY_STORE_PASSWORD, KEY_PASSWORD);\n\teurekaServerRunner.setClientKeystore(clientCert, KEY_STORE_PASSWORD, KEY_PASSWORD);\n\teurekaServerRunner.setClientTruststore(caCert, KEY_STORE_PASSWORD);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 44.80226738526353}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner service = new EurekaClientRunner(config, server, \\\"testservice\\\");\n\tservice.enableTls();\n\tservice.setKeyStore(clientCert, KEY_STORE_PASSWORD, \\\"client\\\", KEY_PASSWORD);\n\tservice.setTrustStore(caCert, KEY_STORE_PASSWORD);\n\tservice.start();\n\treturn service;\n}", "CodeBleu_score": 40.651438805607185}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config);\n\tclient.enableTls();\n\tclient.setTrustStore(caCert, KEY_STORE_PASSWORD);\n\tclient.setClientCert(clientCert, KEY_STORE_PASSWORD);\n\tclient.setEurekaServer(server.getEurekaServer());\n\tclient.setService(\"testservice\");\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 35.09695152504663}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(config, server, \\\"testservice\\\");\n\tclient.enableTls();\n\tclient.setTrustStore(caCert, KEY_STORE_PASSWORD);\n\tclient.setKeyStore(clientCert, KEY_STORE_PASSWORD, \\\"client\\\", KEY_PASSWORD);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 28.14355220212613}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\tlog.info(\\\"Creating certificates\\\");\n\tString caCertName = \\\"ca-cert\\\";\n\tString wrongCaCertName = \\\"wrong-ca-cert\\\";\n\tString serverCertName = \\\"server-cert\\\";\n\tString clientCertName = \\\"client-cert\\\";\n\tString wrongClientCertName = \\\"wrong-client-cert\\\";\n\tString caKeyPassword = \\\"<PASSWORD>\\\";\n\tString caPassword = \\\"<PASSWORD>\\\";\n\tString serverPassword = \\\"<PASSWORD>\\\";\n\tString clientPassword = \\\"<PASSWORD>\\\";\n\tString wrongClientPassword = \\\"<PASSWORD>\\\";\n\n\t// Create CA certificate\n\tKeyTool keyTool = new KeyTool();\n\tkeyTool.createCA(caCertName, caKeyPassword, caPassword);\n\n\t// Create server certificate\n\tkeyTool.createSignedCert(caCertName, caKeyPassword, serverCertName, serverPassword);\n\n\t// Create client certificate\n\tkeyTool.createSignedCert(caCertName, caKeyPassword, clientCertName, clientPassword);\n\n\t// Create wrong client certificate\n\tkeyTool.createSignedCert(caCertName, caKeyPassword, wrongClientCertName, wrongClientPassword);\n\n\t// Create wrong CA certificate\n\tkeyTool.createCA(wrongCaCertName, caKeyPassword, caPassword);\n\n\t// Save CA certificate\n\tsaveCert(caCertName, caPassword);\n\n\t// Save wrong CA certificate\n\tsaveCert(wrongCaCertName, caPassword);\n\n\t// Save server certificate\n\tsaveCert(serverCertName, serverPassword);\n\n\t// Save client certificate\n\tsaveCert(clientCertName, clientPassword);\n\n\t// Save wrong client certificate\n\tsaveCert(wrongClientCertName, wrongClientPassword);\n}", "CodeBleu_score": 7.391847137910412}, {"code": "static void createCertificates() throws Exception{\n\t\t// create CA cert\n\tKeyTool ca = new KeyTool();\n\tca.generateKeyPair();\n\tca.generateRootCertificate();\n\tca.generateCertificate(\"CN=ca\", ca.getCert());\n\tcaCert = saveCert(\"ca\", ca.getCert());\n\n\t// create server cert\n\tKeyTool server = new KeyTool();\n\tserver.generateKeyPair();\n\tserver.generateCertificate(\"CN=server\", ca.getCert());\n\tserverCert = saveCert(\"server\", server.getCert());\n\n\t// create client cert\n\tKeyTool client = new KeyTool();\n\tclient.generateKeyPair();\n\tclient.generateCertificate(\"CN=client\", ca.getCert());\n\tclientCert = saveCert(\"client\", client.getCert());\n\n\t// create wrong client cert\n\tKeyTool wrongClient = new KeyTool();\n\twrongClient.generateKeyPair();\n\twrongClient.generateCertificate(\"CN=wrong-client\", ca.getCert());\n\twrongClientCert = saveCert(\"wrong-client\", wrongClient.getCert());\n\n\t// create wrong CA cert\n\tKeyTool wrongCa = new KeyTool();\n\twrongCa.generateKeyPair();\n\twrongCa.generateRootCertificate();\n\twrongCa.generateCertificate(\"CN=wrong-ca\", wrongCa.getCert());\n\twrongCaCert = saveCert(\"wrong-ca\", wrongCa.getCert());\n}", "CodeBleu_score": 26.128666021044072}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create CA certificate and key\n\tKeyTool ca = createCa();\n\n\t// Create server certificate and key\n\tKeyTool server = createServer(ca);\n\n\t// Create client certificate and key\n\tKeyTool client = createClient(ca);\n\n\t// Save certificates and keys\n\tsaveCert(ca, \\\"ca\\\", \\\"cacert.pem\\\");\n\tsaveCert(ca, \\\"ca\\\", \\\"cacert.der\\\");\n\tsaveCert(server, \\\"server\\\", \\\"servercert.pem\\\");\n\tsaveCert(server, \\\"server\\\", \\\"servercert.der\\\");\n\tsaveCert(client, \\\"client\\\", \\\"clientcert.pem\\\");\n\tsaveCert(client, \\\"client\\\", \\\"clientcert.der\\\");\n\n\tsaveKeyAndCert(server, \\\"server\\\", \\\"serverkey.pem\\\", \\\"servercert.pem\\\");\n\tsaveKeyAndCert(server, \\\"server\\\", \\\"serverkey.der\\\", \\\"servercert.der\\\");\n\tsaveKeyAndCert(client, \\\"client\\\", \\\"clientkey.pem\\\", \\\"clientcert.pem\\\");\n\tsaveKeyAndCert(client, \\\"client\\\", \\\"clientkey.der\\\", \\\"clientcert.der\\\");\n\n\t// Create another CA and client certificate pair\n\tKeyTool wrongCa = createCa();\n\tKeyTool wrongClient = createClient(wrongCa);\n\n\tsaveCert(wrongCa, \\\"wrongca\\\", \\\"wrongcacert.pem\\\");\n\tsaveCert(wrongCa, \\\"wrongca\\\", \\\"wrongcacert.der\\\");\n\tsaveCert(wrongClient, \\\"wrongclient\\\", \\\"wrongclientcert.pem\\\");\n\tsaveCert(wrongClient, \\\"wrongclient\\\", \\\"wrongclientcert.der\\\");\n\n\tsaveKeyAndCert(wrongClient, \\\"wrongclient\\\", \\\"wrongclientkey.pem\\\", \\\"wrongclientcert.pem\\\");\n\tsaveKeyAndCert(wrongClient, \\\"wrongclient\\\", \\\"wrongclientkey.der\\\", \\\"wrongclientcert.der\\\");\n\n\tcaCert = new File(\\\"cacert.pem\\\");\n\twrongCaCert = new File(\\\"wrongcacert.pem\\\");\n\tserverCert = new File(\\\"servercert.pem\\\");\n\tclientCert = new File(\\\"clientcert.pem\\\");\n\twrongClientCert = new File(\\\"wrongclientcert.pem\\\");\n}", "CodeBleu_score": 15.37058950357759}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong endTime = System.currentTimeMillis() + seconds * 1000;\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\tthrow new RuntimeException(\\\"Timed out waiting for assertion to be true\\\");\n}", "CodeBleu_score": 41.24345515740577}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong limit = System.currentTimeMillis() + (seconds * 1000);\n\twhile (System.currentTimeMillis() < limit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\tthrow new RuntimeException(\\\"Timed out waiting for condition\\\");\n}", "CodeBleu_score": 45.03358282552158}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong limit = System.currentTimeMillis() + seconds * 1000L;\n\twhile (System.currentTimeMillis() < limit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t}\n\t\tcatch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n\tthrow new RuntimeException(\\\"Timed out waiting for condition\\\");\n}", "CodeBleu_score": 43.97877378998169}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\tX500Name subject = new X500Name(\\\"CN=\\\", ca);\n\tX500Name issuer = subject;\n\tDate notBefore = new Date();\n\tDate notAfter = new Date(System.currentTimeMillis() + TEN_YEARS);\n\tContentSigner signer = new JcaContentSignerBuilder(\\\"SHA256WithRSAEncryption\\\").build(privateKey);\n\tJcaX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(subject, BigInteger.ONE, notBefore, notAfter, issuer, publicKey);\n\tbuilder.addExtension(Extension.subjectKeyIdentifier, false, createSubjectKeyId(publicKey));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\tbuilder.addExtension(Extension.authorityKeyIdentifier, false, createAuthorityKeyId(publicKey));\n\tbuilder.addExtension(Extension.subjectAlternativeName, false, new GeneralNames(new GeneralName(GeneralName.dNSName, ca)));\n\treturn new JcaX509CertificateConverter().setProvider(\\\"BC\\\").getCertificate(builder.build(signer));\n}", "CodeBleu_score": 36.96730468791769}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509CertificateHolder holder = createCertHolder(keyPair, ca);\n\treturn new JcaX509CertificateConverter().setProvider(\\\"BC\\\").getCertificate(holder);\n}", "CodeBleu_score": 20.478928659204538}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\tX500Name issuer = new X500Name(ca);\n\tX500Name subject = new X500Name(ca);\n\tDate notBefore = new Date();\n\tDate notAfter = new Date(System.currentTimeMillis() + TEN_YEARS);\n\tBigInteger serial = new BigInteger(64, new SecureRandom());\n\tContentSigner signer = new JcaContentSignerBuilder(\\\"SHA256withRSA\\\").setProvider(\\\"BC\\\").build(privateKey);\n\tJcaX509v3CertificateBuilder builder = new JcaX509v3CertificateBuilder(issuer, serial, notBefore, notAfter, subject, publicKey);\n\tbuilder.addExtension(Extension.subjectAlternativeName, false, new GeneralNames(new GeneralName(GeneralName.dNSName, ca)));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\tX509CertificateHolder holder = builder.build(signer);\n\treturn new JcaX509CertificateConverter().setProvider(\\\"BC\\\").getCertificate(holder);\n}", "CodeBleu_score": 40.33138451063996}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient != null) {\n\t\treturn eurekaHttpClient;\n\t}\n\tEurekaHttpClient newEurekaHttpClient = null;\n\ttry {\n\t\tObject eurekaTransport = this.eurekaTransportField.get(this);\n\t\tField registrationClientField = ReflectionUtils.findField(eurekaTransport.getClass(), \"registrationClient\");\n\t\tReflectionUtils.makeAccessible(registrationClientField);\n\t\tObject registrationClient = registrationClientField.get(eurekaTransport);\n\t\tField eurekaHttpClientField = ReflectionUtils.findField(registrationClient.getClass(), \"eurekaHttpClient\");\n\t\tReflectionUtils.makeAccessible(eurekaHttpClientField);\n\t\tnewEurekaHttpClient = (EurekaHttpClient) eurekaHttpClientField.get(registrationClient);\n\t}\n\tcatch (IllegalAccessException e) {\n\t\tlog.error(\\\"Error accessing eurekaHttpClient\\\", e);\n\t}\n\tthis.eurekaHttpClient.compareAndSet(null, newEurekaHttpClient);\n\treturn newEurekaHttpClient;\n}", "CodeBleu_score": 55.27258279108733}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\tEurekaHttpClient registrationClient = null;\n\t\ttry {\n\t\t\tregistrationClient = (EurekaHttpClient) ReflectionUtils.getField(this.eurekaTransportField, this)\n\t\t\t\t\t.getRegistrationClient();\n\t\t}\n\t\tcatch (IllegalAccessException e) {\n\t\t\tlog.error(\\\"Cannot access eurekaTransport field\\\", e);\n\t\t}\n\t\tthis.eurekaHttpClient.compareAndSet(null, registrationClient);\n\t}\n\treturn this.eurekaHttpClient.get();\n}", "CodeBleu_score": 46.69334208895566}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tEurekaHttpClient eurekaHttpClient = this.eurekaHttpClient.get();\n\tif (eurekaHttpClient == null) {\n\t\tDiscoveryClient eurekaTransport = (DiscoveryClient) ReflectionUtils.getField(this.eurekaTransportField, this);\n\t\tif (eurekaTransport != null) {\n\t\t\ttry {\n\t\t\t\tObject registrationClient = ReflectionUtils.getField(ReflectionUtils.findField(eurekaTransport.getClass(), \"registrationClient\"), eurekaTransport);\n\t\t\t\tif (registrationClient != null) {\n\t\t\t\t\teurekaHttpClient = ((TransportClientFactories.JerseyClientFactory) registrationClient).getEurekaHttpClient();\n\t\t\t\t\tthis.eurekaHttpClient.compareAndSet(null, eurekaHttpClient);\n\t\t\t\t}\n\t\t\t}\n\t\t\tcatch (IllegalAccessException e) {\n\t\t\t\tlog.error(\\\"Cannot access eurekaTransport field\\\");\n\t\t\t}\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 47.16927839556443}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 68.59796273715652}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 56.45543966816273}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tfor (String instanceId : application.getInstances().keySet()) {\n\t\t\tString serviceId = application.getName().toLowerCase();\n\t\t\tif (!services.contains(serviceId)) {\n\t\t\t\tservices.add(serviceId);\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 60.195149221567334}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (NamedContributor<HealthContributor> namedContributor : compositeContributor.getContributors()) {\n\t\t\t\tif (!(namedContributor.getContributor() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(namedContributor.getName(), namedContributor.getContributor());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 41.87805793632888}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (NamedContributor<HealthContributor> namedContributor : compositeHealthContributor.getContributors()) {\n\t\t\t\tif (!(namedContributor.getContributor() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(namedContributor.getName(), namedContributor.getContributor());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 41.8762062011542}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (NamedContributor<HealthContributor> namedContributor : compositeContributor.getContributors()) {\n\t\t\t\tif (!(namedContributor.getContributor() instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(namedContributor.getName(), namedContributor.getContributor());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 41.87805793632888}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> serviceInstances = discoveryClient.getInstances(\\\"provider-application\\\");\n\tif (serviceInstances == null || serviceInstances.isEmpty()) {\n\t\tthrow new RuntimeException(\\\"No instances found for \\\" + \\\"provider-application\\\");\n\t}\n\tServiceInstance serviceInstance = serviceInstances.get(0);\n\tURI uri = serviceInstance.getUri();\n\tString result = restTemplate.postForObject(uri + \\\"/echo?name=Spring+Cloud+Open+Feign+Consumer\\\", \\\"\\\", String.class);\n\treturn result;\n}", "CodeBleu_score": 38.938786256836316}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\\\"provider-application\\\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\\\"No instances found for provider-application\\\");\n\t}\n\tURI uri = loadBalancerClient.choose(\\\"provider-application\\\");\n\tif (uri == null) {\n\t\tthrow new RuntimeException(\\\"No instances found for provider-application\\\");\n\t}\n\tString response = restTemplate.postForObject(uri + \\\"/echo\\\", \\\"Hello from Consumer\\\", String.class);\n\treturn response;\n}", "CodeBleu_score": 34.13331043861434}, {"code": "public String hello(){\n\t\tServiceInstance instance = discoveryClient.getInstance(\\\"provider-application\\\");\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\\\"No service instance found for 'provider-application'\\\");\n\t}\n\tURI uri = instance.getUri();\n\tString response = restTemplate.postForObject(uri + \\\"/echo\\\", \\\"hello\\\", String.class);\n\treturn response;\n}", "CodeBleu_score": 32.15421314142728}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.choose(\\\"provider-application\\\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \\\"/echo\\\", null, String.class);\nreturn response;\n}\n\nthrow new RuntimeException(\\\"No service instance for provider-application found\\\");\n}", "CodeBleu_score": 51.52538656433375}, {"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.choose(\\\"provider-application\\\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \\\"/echo\\\", null, String.class);\nreturn response;\n}\n\nthrow new RuntimeException(\\\"No service instance for provider-application found\\\");\n}", "CodeBleu_score": 51.52538656433375}, {"code": "public String world(){\n\tList<ServiceInstance> serviceInstances = loadBalancerClient.choose(\\\"provider-application\\\");\nif (serviceInstances.size() > 0) {\nServiceInstance serviceInstance = serviceInstances.get(0);\nURI uri = serviceInstance.getUri();\nString response = loadBalancedRestTemplate.postForObject(uri.toString() + \\\"/echo\\\", null, String.class);\nreturn response;\n}\n\nthrow new RuntimeException(\\\"No service instance for provider-application found\\\");\n}", "CodeBleu_score": 51.52538656433375}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Registering service: \" + serviceName + \" with ip: \" + ip + \" and port: \" + port);\n\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlogger.info(\"Successfully registered service: \" + serviceName);\n\t\treturn true;\n\t} else {\n\t\tSet<Server> servers = Collections.synchronizedSet(new HashSet<Server>());\n\t\tservers.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, servers);\n\t\tlogger.info(\"Successfully registered service: \" + serviceName);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 48.326702776477305}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tSet<Server> serverSet = serverMap.get(serviceName);\nif (serverSet == null) {\nserverSet = Collections.synchronizedSet(new HashSet<>());\nserverMap.put(serviceName, serverSet);\n}\nServer server = new Server(ip, port);\nserverSet.add(server);\nlogger.info(\"Registered server: \" + JSON.toJSONString(server));\nreturn true;\n}", "CodeBleu_score": 58.09656552239203}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tif (serverMap.containsKey(serviceName)) {\nSet<Server> serverSet = serverMap.get(serviceName);\nsynchronized (serverSet) {\nserverSet.add(new Server(ip, port));\n}\n} else {\nSet<Server> serverSet = Collections.synchronizedSet(new HashSet<>());\nserverSet.add(new Server(ip, port));\nserverMap.put(serviceName, serverSet);\n}\nlogger.info(\"Registered service {} with ip {} and port {}\", serviceName, ip, port);\nreturn true;\n}", "CodeBleu_score": 60.48723704858992}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nSet<Server> serverSet = serverMap.get(serviceName.toLowerCase());\nif (serverSet != null) {\nserverSet.remove(new Server(ip, port));\nif (serverSet.isEmpty()) {\nserverMap.remove(serviceName.toLowerCase());\n}\n}\nreturn true;\n}", "CodeBleu_score": 78.45532881020544}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\nif (serverMap.containsKey(serviceName.toLowerCase())) {\nserverMap.get(serviceName.toLowerCase()).remove(new Server(ip, port));\n}\nreturn true;\n}", "CodeBleu_score": 55.37827362511082}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"deregister service, serviceName: {}, ip: {}, port: {}\", serviceName, ip, port);\n\tserverMap.get(serviceName).remove(new Server(ip, port));\n\treturn true;\n}", "CodeBleu_score": 46.64177704713991}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nif (attributes == null) {\nreturn;\n}\nMap<String, Object> defaultConfiguration = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\nif (defaultConfiguration != null) {\nString name = metadata.getClassName() + \".\" + defaultConfiguration.get(\"name\");\nBeanDefinitionBuilder definition = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\ndefinition.addPropertyValue(\"name\", name);\ndefinition.addPropertyValue(\"configuration\", defaultConfiguration);\nregistry.registerBeanDefinition(name, definition.getBeanDefinition());\n}\n}", "CodeBleu_score": 47.21120055284393}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t// 1. \u83b7\u53d6RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027\nMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n// 2. \u83b7\u53d6RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027defaultConfiguration\nString defaultConfig = (String) attributes.get(\"defaultConfiguration\");\n// 3. \u5982\u679cdefaultConfiguration\u4e0d\u4e3a\u7a7a\uff0c\u5219\u751f\u6210beanName\uff0c\u5e76\u6ce8\u518cbean\nif (StringUtils.hasText(defaultConfig)) {\nString generatedBeanName = defaultConfig.trim();\nif (registry.containsBeanDefinition(generatedBeanName)) {\nlogger.warn(\"Could not generate bean name for default Ribbon configuration, '\" + generatedBeanName + \"' already exists\");\n}\nelse {\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"name\", generatedBeanName);\nregistry.registerBeanDefinition(generatedBeanName, builder.getBeanDefinition());\n}\n}\n// 4. \u83b7\u53d6RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027value\nMap<String, Object> clients = (Map<String, Object>) attributes.get(\"value\");\n// 5. \u904d\u5386RibbonClients\u6ce8\u89e3\u7684\u5c5e\u6027value\nfor (Map.Entry<String, Object> entry : clients.entrySet()) {\nString beanName = entry.getKey();\nif (registry.containsBeanDefinition(beanName)) {\nlogger.warn(\"Could not generate bean name for Ribbon client, '\" + beanName + \"' already exists\");\n}\nelse {\nBeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\nbuilder.addPropertyValue(\"name\", beanName);\nbuilder.addPropertyValue(\"configuration\", entry.getValue());\nregistry.registerBeanDefinition(beanName, builder.getBeanDefinition());\n}\n}\n}", "CodeBleu_score": 37.60322121571868}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nString[] value = (String[]) attributes.get(\"value\");\nif (value.length > 0) {\nString basePackage = value[0];\nregisterDefaultConfiguration(basePackage, registry);\n}\n}", "CodeBleu_score": 45.416041048876636}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tILoadBalancer loadBalancer = this.clientFactory.getLoadBalancer(serviceId);\n\tif (loadBalancer == null) {\n\t\treturn null;\n\t}\n\tServer server = loadBalancer.chooseServer(this.chooseRequest(request));\n\tif (server == null) {\n\t\treturn null;\n\t}\n\tTutuServiceInstance serviceInstance = new TutuServiceInstance(serviceId, server.getHost(), server.getPort(), server.isSecure());\n\tserviceInstance.setUri(this.buildUri(serviceInstance));\n\treturn serviceInstance;\n}", "CodeBleu_score": 50.09690932074881}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tILoadBalancer loadBalancer = clientFactory.getLoadBalancer(serviceId);\n\tif (loadBalancer == null) {\n\t\treturn null;\n\t}\n\tServer server = loadBalancer.chooseServer(getPredicate(request));\n\tif (server == null) {\n\t\treturn null;\n\t}\n\treturn getServiceInstance(serviceId, server);\n}", "CodeBleu_score": 49.484599492125604}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\tILoadBalancer loadBalancer = clientFactory.getLoadBalancer(serviceId);\n\tif (loadBalancer == null) {\n\t\treturn null;\n\t}\n\tServer server = loadBalancer.chooseServer(request);\n\tif (server == null) {\n\t\treturn null;\n\t}\n\treturn new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 60.58336389817258}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString scheme = original.getScheme();\n\tString userInfo = original.getUserInfo();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString path = original.getPath();\n\tString query = original.getQuery();\n\tString fragment = original.getFragment();\n\n\tStringBuilder uri = new StringBuilder();\n\turi.append(scheme).append(\"://\").append(host).append(\":\").append(port);\n\turi.append(path);\n\tif (StrUtil.isNotEmpty(query)) {\n\t\turi.append(\"?\").append(query);\n\t}\n\tif (StrUtil.isNotEmpty(fragment)) {\n\t\turi.append(\"#\").append(fragment);\n\t}\n\n\ttry {\n\t\treturn new URI(uri.toString());\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Failed to reconstruct URI\", e);\n\t}\n}", "CodeBleu_score": 45.570647697195405}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\tString scheme = original.getScheme();\n\t\tString userInfo = original.getUserInfo();\n\t\tString host = server.getHost();\n\t\tint port = server.getPort();\n\t\tString path = original.getPath();\n\t\tString query = original.getQuery();\n\t\tString fragment = original.getFragment();\n\t\tURI reconstructed = new URI(scheme, userInfo, host, port, path, query, fragment);\n\t\treturn reconstructed;\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 37.69942491358346}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\tString scheme = original.getScheme();\n\t\tString userInfo = original.getUserInfo();\n\t\tString host = server.getHost();\n\t\tint port = server.getPort();\n\t\tString path = original.getPath();\n\t\tString query = original.getQuery();\n\t\tString fragment = original.getFragment();\n\n\t\tStringBuilder uriBuilder = new StringBuilder();\n\t\turiBuilder.append(scheme).append(\"://\").append(host).append(\":\").append(port);\n\t\turiBuilder.append(path);\n\t\tif (StrUtil.isNotEmpty(query)) {\n\t\t\turiBuilder.append(\"?\").append(query);\n\t\t}\n\t\tif (StrUtil.isNotEmpty(fragment)) {\n\t\t\turiBuilder.append(\"#\").append(fragment);\n\t\t}\n\t\treturn new URI(uriBuilder.toString());\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Failed to reconstruct URI\", e);\n\t}\n}", "CodeBleu_score": 45.061721682336156}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tString serverAddress = discoveryProperties.getServerAddress();\n\tString serviceName = discoveryProperties.getServiceName();\n\tString port = discoveryProperties.getPort();\n\tString path = discoveryProperties.getPath();\n\tString scheme = discoveryProperties.getScheme();\n\tString url = scheme + \"://\" + serverAddress + \":\" + port + path + \"?serviceName=\" + serviceName;\n\tString result = HttpUtil.get(url);\n\tJSONObject jsonObject = JSON.parseObject(result);\n\tList<Map<String, String>> data = jsonObject.getJSONArray(\"data\").toJavaList(Map.class);\n\treturn data.stream().map(item -> new TutuServer(item.get(\"ip\"), item.get(\"port\"), item.get(\"serviceName\"), item.get(\"instanceId\"))).collect(Collectors.toList());\n}", "CodeBleu_score": 36.15072282790152}, {"code": "private List<TutuServer> getServer(){\n\t\n// Construct the request URL\nString url = discoveryProperties.getServerAddress() + \"/list\";\nMap<String, Object> params = new HashMap<>();\nparams.put(\"serviceName\", serviceId);\n\n// Send the request and get the response\nString result = HttpUtil.get(url, params);\n\n// Parse the JSON array into a list of TutuServer objects\nList<TutuServer> servers = JSON.parseArray(result, TutuServer.class);\n\n// Log the list of servers\nlogger.info(\"Servers: \" + servers.toString());\n\n// Return the list of servers\nreturn servers;\n}", "CodeBleu_score": 36.17550176543616}, {"code": "private List<TutuServer> getServer(){\n\t\ttry {\n\t\tString serviceName = discoveryProperties.getServiceName();\n\t\tString serverAddress = discoveryProperties.getServerAddress();\n\t\tString serverPort = discoveryProperties.getServerPort();\n\t\tString serverProtocol = discoveryProperties.getServerProtocol();\n\t\tString serverContext = discoveryProperties.getServerContext();\n\t\tString serverPath = discoveryProperties.getServerPath();\n\t\tString serverUrl = serverProtocol + \"://\" + serverAddress + \":\" + serverPort + serverContext + serverPath;\n\n\t\tMap<String, Object> params = new HashMap<>();\n\t\tparams.put(\"serviceName\", serviceName);\n\n\t\tString result = HttpUtil.get(serverUrl, params);\n\t\tlogger.info(\"TutuServerList: result: {}\", result);\n\n\t\tList<TutuServer> servers = JSONObject.parseArray(result, TutuServer.class);\n\t\treturn servers;\n\t} catch (Exception e) {\n\t\tlogger.error(\"TutuServerList: error: {}\", e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 34.35607564866932}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tString serviceId = null;\n\tfor (Route route : this.zuulProperties.getRoutes().values()) {\n\t\tif (this.pathMatcher.match(route.getPath(), path)) {\n\t\t\tserviceId = route.getServiceId();\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (serviceId != null) {\n\t\tMap<String, String> routeMetadata = this.zuulProperties.getRoutes().get(serviceId).getRouteMetadata();\n\t\treturn new Route(routeMetadata.get(\"path\"), serviceId, routeMetadata);\n\t}\n\treturn null;\n}", "CodeBleu_score": 33.69931481933576}, {"code": "public Route getMatchingRoute(String path){\n\t\tRoute route = null;\n\tfor (Map.Entry<String, ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n\t\tString pattern = entry.getValue().getPath();\n\t\tif (pathMatcher.match(pattern, path)) {\n\t\t\tString serviceId = entry.getValue().getServiceId();\n\t\t\troute = new Route(serviceId, pattern, null, null, null, null, null);\n\t\t\tbreak;\n\t\t}\n\t}\n\treturn route;\n}", "CodeBleu_score": 45.20700399835674}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (zuulProperties.getRoutes() == null) {\n\t\treturn null;\n\t}\n\tfor (Map.Entry<String, ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n\t\tString routePath = entry.getValue().getPath();\n\t\tif (pathMatcher.match(routePath, path)) {\n\t\t\tString serviceId = entry.getValue().getServiceId();\n\t\t\treturn new Route(routePath, serviceId);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 40.67263161828077}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tSet<String> packagesToScan = getPackagesToScan(importingClassMetadata);\n\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Searching for @FeignClient annotations in the following packages: \" + packagesToScan);\n\t}\n\tClassPathScanningCandidateComponentProvider provider = new ClassPathScanningCandidateComponentProvider(false, registry);\n\tprovider.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n\tSet<BeanDefinition> candidateComponents = provider.findCandidateComponents(StringUtils.toStringArray(packagesToScan));\n\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Identified the following candidates for registration as Feign Client: \" + candidateComponents);\n\t}\n\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\tif (candidateComponent instanceof AnnotatedBeanDefinition) {\n\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n\t\t\tAnnotationMetadata metadata = beanDefinition.getMetadata();\n\t\t\tif (!metadata.isInterface()) {\n\t\t\t\tthrow new IllegalArgumentException(\"Feign Client annotations must be specified on an interface\");\n\t\t\t}\n\t\t\tif (logger.isInfoEnabled()) {\n\t\t\t\tlogger.info(\"Registering feign client \" + metadata.getClassName());\n\t\t\t}\n\t\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\t\tdefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\t\tdefinition.getConstructorArgumentValues().addGenericArgumentValue(metadata.getClassName());\n\t\t\tdefinition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n\t\t\tdefinition.setSynthetic(true);\n\t\t\tString beanName = StringUtils.uncapitalize(ClassUtils.getShortName(metadata.getClassName()));\n\t\t\tregistry.registerBeanDefinition(beanName, definition);\n\t\t}\n\t}\n}", "CodeBleu_score": 36.20565525248301}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tSet<String> packagesToScan = getPackagesToScan(importingClassMetadata);\n\tif (logger.isTraceEnabled()) {\n\t\tlogger.trace(\"Searching for @FeignClient annotations in \" + packagesToScan);\n\t}\n\tClassPathScanningCandidateComponentProvider provider = new ClassPathScanningCandidateComponentProvider(false, this.environment) {\n\t\t@Override\n\t\tprotected boolean isCandidateComponent(AnnotatedBeanDefinition beanDefinition) {\n\t\t\tboolean isCandidate = false;\n\t\t\tif (beanDefinition.getMetadata().isIndependent()) {\n\t\t\t\tif (!beanDefinition.getMetadata().isInterface()) {\n\t\t\t\t\tif (beanDefinition.getMetadata().getInterfaceNames().length == 1) {\n\t\t\t\t\t\tisCandidate = AnnotationUtils.isCandidateClass(beanDefinition.getMetadata().getInterfaceNames()[0], beanDefinition.getMetadata().getClassName());\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn isCandidate;\n\t\t}\n\t};\n\tfor (String basePackage : packagesToScan) {\n\t\tfor (BeanDefinition candidate : provider.findCandidateComponents(basePackage)) {\n\t\t\tif (candidate instanceof AnnotatedBeanDefinition) {\n\t\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition)candidate;\n\t\t\t\tAnnotationMetadata metadata = beanDefinition.getMetadata();\n\t\t\t\tString className = metadata.getClassName();\n\t\t\t\ttry {\n\t\t\t\t\tClass<?> clazz = ClassUtils.forName(className, this.classLoader);\n\t\t\t\t\tif (clazz.isAnnotationPresent(FeignClient.class)) {\n\t\t\t\t\t\tif (logger.isTraceEnabled()) {\n\t\t\t\t\t\t\tlogger.trace(\"Adding feign client from \" + className);\n\t\t\t\t\t\t}\n\t\t\t\t\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\t\t\t\t\tdefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\t\t\t\t\tdefinition.getConstructorArgumentValues().addIndexedArgumentValue(0, clazz);\n\t\t\t\t\t\tdefinition.setRole(2);\n\t\t\t\t\t\tregistry.registerBeanDefinition(clazz.getName(), definition);\n\t\t\t\t\t}\n\t\t\t\t} catch (ClassNotFoundException ex) {\n\t\t\t\t\tlogger.error(\"Failed to load feign client class [\" + className + \"]\", ex);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 34.318837633126584}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tSet<String> packagesToScan = getPackagesToScan(importingClassMetadata);\n\tif (logger.isTraceEnabled()) {\n\t\tlogger.trace(\"Searching for @FeignClient annotations in package(s): \" + packagesToScan);\n\t}\n\tSet<BeanDefinition> candidates = new LinkedHashSet<>();\n\tfor (String basePackage : packagesToScan) {\n\t\tcandidates.addAll(scanForCandidateComponents(basePackage));\n\t}\n\tif (logger.isDebugEnabled()) {\n\t\tlogger.debug(\"Identified the following candidates for registration against the BeanDefinitionRegistry: \" + candidates);\n\t}\n\tfor (BeanDefinition candidate : candidates) {\n\t\tif (candidate instanceof AnnotatedBeanDefinition) {\n\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidate;\n\t\t\tAnnotationMetadata metadata = beanDefinition.getMetadata();\n\t\t\tif (metadata.isInterface() && metadata.getInterfaceNames().length == 1) {\n\t\t\t\tregisterFeignClient(importingClassMetadata, registry, beanDefinition);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tlogger.warn(\"Skipping BeanDefinition [\" + beanDefinition + \"] because it does not declare exactly 1 interface\");\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tlogger.warn(\"Skipping BeanDefinition [\" + candidate + \"] because it does not represent an @Bean method\");\n\t\t}\n\t}\n}", "CodeBleu_score": 23.251790211538143}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.51924881462398}]}
