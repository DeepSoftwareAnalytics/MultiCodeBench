{"instance_id": "58936b2a621b", "generation_result": [{"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n", "CodeBleu_score": 83.87646776544821}]}
{"instance_id": "83b142d9d251", "generation_result": [{"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        train_size=support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n\n\n\n", "CodeBleu_score": 67.31491587948683}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        train_size=support_ratio,\n        stratify=label,\n        random_state=42,\n    )\n    return x_train, x_test, y_train, y_test\n\n\n", "CodeBleu_score": 70.74912473326597}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        stratify=label,\n        random_state=42,\n    )\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}]}
{"instance_id": "5fd02b540f61", "generation_result": [{"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, X_test, y_train, y_test\n\n\n\n", "CodeBleu_score": 38.79514250108158}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, X_test, y_train, y_test\n\n\n\n", "CodeBleu_score": 38.79514250108158}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.92483101817302}]}
{"instance_id": "ad958cb31a57", "generation_result": [{"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n\n\n", "CodeBleu_score": 79.03672928896962}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(label=ndarrays[0], means=ndarrays[1], weights=ndarrays[2], covariances=ndarrays[3], num_samples=ndarrays[4])\n\n\n", "CodeBleu_score": 47.658975813227}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    label = ndarrays[0]\n    means = ndarrays[1]\n    weights = ndarrays[2]\n    covariances = ndarrays[3]\n    num_samples = ndarrays[4]\n    return GMMParameters(label, means, weights, covariances, num_samples)\n\n\n", "CodeBleu_score": 40.08951228295815}]}
{"instance_id": "061d5a5b9d56", "generation_result": [{"code": "def datafiles_fusion(data_paths):\n\t\n    X, y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for path in data_paths[1:]:\n        X_new, y_new = load_svmlight_file(path)\n        X_new = X_new.toarray()\n        assert X_new.shape[1] == X.shape[1], \"Number of features in new file does not match first file\"\n        X = np.concatenate((X, X_new), axis=0)\n        y = np.concatenate((y, y_new), axis=0)\n    return X, y\n\n", "CodeBleu_score": 34.60936464135864}, {"code": "def datafiles_fusion(data_paths):\n\t\n    \n    # Load the first data file and convert features to a dense array\n    X, y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    \n    # Iterate over the remaining data files\n    for path in data_paths[1:]:\n        # Load the data and convert features to a dense array\n        X_new, y_new = load_svmlight_file(path)\n        X_new = X_new.toarray()\n        \n        # Check that the number of features matches the first file\n        assert X_new.shape[1] == X.shape[1], \"Number of features in {} does not match the first file\".format(path)\n        \n        # Concatenate the new features and labels to the existing arrays\n        X = np.concatenate((X, X_new), axis=0)\n        y = np.concatenate((y, y_new), axis=0)\n    \n    return X, y\n\n\n", "CodeBleu_score": 33.75036664117554}, {"code": "def datafiles_fusion(data_paths):\n\t\n    X, y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for data_path in data_paths[1:]:\n        X_new, y_new = load_svmlight_file(data_path)\n        X_new = X_new.toarray()\n        assert X_new.shape[1] == X.shape[1], f\"Number of features in {data_path} does not match number of features in {data_paths[0]}\"\n        X = np.concatenate((X, X_new), axis=0)\n        y = np.concatenate((y, y_new), axis=0)\n    return X, y\n\n\n", "CodeBleu_score": 33.465558627445816}]}
{"instance_id": "977d3bd5d5a3", "generation_result": [{"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n\n", "CodeBleu_score": 54.6058043693212}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n\n\n", "CodeBleu_score": 54.6058043693212}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    acc = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return acc, recall, precision, f1\n\n\n\n", "CodeBleu_score": 56.9726563343633}]}
{"instance_id": "f4c838f1f092", "generation_result": [{"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}]}
{"instance_id": "35068c779c02", "generation_result": [{"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\", f\"Dataset type is not LIBSVM, but {cfg.dataset.type}\"\n    dataset_path = cfg.dataset.path\n    dataset_name = cfg.dataset.name\n    data, labels = load_svmlight_file(dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int32)\n    if dataset_name == \"MUSHROOMS\":\n        labels = np.where(labels == 1, 0, 1)\n    else:\n        raise RuntimeError(f\"Unknown dataset name: {dataset_name}\")\n    print(f\"Unique labels: {np.unique(labels, return_counts=True)}\")\n    print(f\"Shape of features: {data.shape}\")\n    return TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.41110943899391}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    if cfg.dataset.type != \"LIBSVM\":\n        raise RuntimeError(f\"Dataset type {cfg.dataset.type} not supported\")\n    path = cfg.dataset.path\n    name = cfg.dataset.name\n    if name == \"MUSHROOMS\":\n        data, labels = load_svmlight_file(path, n_features=128)\n        labels = labels.astype(np.float32)\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(f\"Dataset name {name} not supported\")\n    print(f\"Unique labels: {np.unique(labels, return_counts=True)}\")\n    print(f\"Shape of features: {data.shape}\")\n    return TensorDataset(torch.from_numpy(data.toarray()).float(), torch.from_numpy(labels).long())\n\n\n\n", "CodeBleu_score": 38.58668301571546}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    if cfg.data.type != 'LIBSVM':\n        raise RuntimeError(f'Invalid dataset type: {cfg.data.type}')\n    dataset_path = cfg.data.path\n    dataset_name = cfg.data.name\n    data, labels = load_svmlight_file(dataset_path)\n    data = data.toarray().astype(np.float32)\n    labels = labels.astype(np.int64)\n    if dataset_name == 'MUSHROOMS':\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    print(f'Unique labels: {np.unique(labels, return_counts=True)}')\n    print(f'Features shape: {data.shape}')\n    return TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n\n\n", "CodeBleu_score": 39.22844137146759}]}
{"instance_id": "d602a96e571e", "generation_result": [{"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, 'fit_transform'):\n        result = transformer.fit_transform(X, y, **fit_params)\n    else:\n        transformer.fit(X, y, **fit_params)\n        result = transformer.transform(X)\n    if weight is not None:\n        result *= weight\n    return result, transformer\n", "CodeBleu_score": 58.08517415338316}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, 'fit_transform'):\n        Xt = transformer.fit_transform(X, y, **fit_params)\n    else:\n        transformer.fit(X, y, **fit_params)\n        Xt = transformer.transform(X)\n    if weight is not None:\n        Xt *= weight\n    return Xt, transformer\n\n", "CodeBleu_score": 58.246129616441934}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, 'fit_transform'):\n        if y is None:\n            res = transformer.fit_transform(X, **fit_params)\n        else:\n            res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is not None:\n        res *= weight\n    return res, transformer\n\n", "CodeBleu_score": 68.00709364332019}]}
{"instance_id": "fcf88a773fd8", "generation_result": [{"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    if not isinstance(X, np.ndarray):\n        if sparse.issparse(X):\n            if X.format != \"csc\":\n                X = X.tocsc()\n        else:\n            X = np.array(X, dtype=np.float64)\n    if selected == \"all\":\n        return transform(X, copy=copy)\n    elif selected == \"none\":\n        return X\n    else:\n        selected = np.array(selected, dtype=np.int64)\n        if not np.all(selected >= 0):\n            raise ValueError(\"Selected features must be non-negative\")\n        if not np.all(selected < X.shape[1]):\n            raise ValueError(\"Selected features must be less than the number \"\n                             \"of features\")\n        if not np.all(np.sort(selected) == selected):\n            raise ValueError(\"Selected features must be sorted\")\n        if not np.all(np.unique(selected) == selected):\n            raise ValueError(\"Selected features must be unique\")\n        if sparse.issparse(X):\n            X_selected = X[:, selected]\n            X_selected = transform(X_selected, copy=copy)\n            X_rest = X[:, np.setdiff1d(np.arange(X.shape[1]), selected)]\n            return sparse.hstack((X_selected, X_rest), format=\"csc\")\n        else:\n            X_selected = X[:, selected]\n            X_selected = transform(X_selected, copy=copy)\n            X_rest = X[:, np.setdiff1d(np.arange(X.shape[1]), selected)]\n            return np.hstack((X_selected, X_rest))\n\n", "CodeBleu_score": 38.15257101891346}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    if not isinstance(X, np.ndarray):\n        raise TypeError(\"X must be a numpy array\")\n\n    if not isinstance(X, (np.ndarray, sp.spmatrix)):\n        raise TypeError(\"X must be a numpy array or sparse matrix\")\n\n    if not isinstance(X, sp.spmatrix):\n        X = np.asarray(X)\n\n    if not isinstance(X, sp.spmatrix):\n        X = sp.csc_matrix(X)\n\n    if selected == \"all\":\n        return transform(X)\n\n    if not isinstance(selected, list):\n        selected = [selected]\n\n    if len(selected) == 0:\n        return X\n\n    n_features = X.shape[1]\n    selected = np.array(selected)\n    if selected.max() >= n_features:\n        raise ValueError(\"Selected features must be in [0, n_features)\")\n\n    selected_mask = np.zeros(n_features, dtype=bool)\n    selected_mask[selected] = True\n    selected_mask_not = np.logical_not(selected_mask)\n\n    X_selected = transform(X[:, selected_mask])\n    X_not_selected = X[:, selected_mask_not]\n\n    if sp.issparse(X):\n        X_selected = sp.hstack((X_selected, X_not_selected))\n    else:\n        X_selected = np.hstack((X_selected, X_not_selected))\n\n    return X_selected", "CodeBleu_score": 52.087391859536034}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', copy=copy,\n                    force_all_finite=False)\n    n_features = X.shape[1]\n    if selected == \"all\":\n        selected = np.arange(n_features)\n    elif selected == \"default\":\n        selected = _get_default_categorical_features(n_features)\n    else:\n        selected = np.asarray(selected, dtype=np.int32)\n        if selected.min() < 0 or selected.max() >= n_features:\n            raise ValueError(\"Selected features are not valid for the data.\")\n\n    if len(selected) == 0:\n        return X\n\n    if sp.issparse(X):\n        # Sparse input: apply transform to selected features\n        X_selected = X[:, selected]\n        X_selected = transform(X_selected)\n        X_selected = sp.csr_matrix(X_selected)\n        # Combine transformed and non-transformed features\n        X_out = sp.hstack((X.tocsr()[:, np.delete(np.arange(n_features),\n                                                  selected)], X_selected))\n    else:\n        # Dense input: apply transform to selected features\n        X_selected = X[:, selected]\n        X_selected = transform(X_selected)\n        # Combine transformed and non-transformed features\n        X_out = np.hstack((X[:, np.delete(np.arange(n_features), selected)],\n                           X_selected))\n\n    return X_out", "CodeBleu_score": 43.03284280391233}]}
{"instance_id": "c9dfb00047d1", "generation_result": [{"code": "def _transform_new(self, X)\n\t\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    _, n_features = X.shape\n    X_int = np.zeros_like(X, dtype=np.int)\n    X_mask = np.ones_like(X, dtype=np.bool)\n\n    for i in range(n_features):\n        Xi = X[:, i]\n        valid_mask = np.in1d(Xi, self.categories_[i])\n\n        if not np.all(valid_mask):\n            if handle_unknown == 'error':\n                diff = np.unique(X[~valid_mask, i])\n                msg = (\"Found unknown categories {0} in column {1}\"\n                       \" during transform\".format(diff, i))\n                raise ValueError(msg)\n            else:\n                # Set the problematic rows to an acceptable value and\n                # continue `The rows are marked `X_mask` and will be\n                # removed later.\n                X_mask[:, i] = valid_mask\n                Xi = Xi.copy()\n                Xi[~valid_mask] = self.categories_[i][0]\n        X_int[:, i] = self._label_encoders_[i].transform(Xi)\n\n    return X_int, X_mask\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.509759762671614}, {"code": "def _transform_new(self, X)\n\t\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    _, n_features = X.shape\n    X_int = np.zeros_like(X, dtype=np.int)\n    X_mask = np.ones_like(X, dtype=np.bool)\n\n    for i in range(n_features):\n        Xi = X[:, i]\n        valid_mask = np.in1d(Xi, self.categories_[i])\n\n        if not np.all(valid_mask):\n            if self.handle_unknown == 'error':\n                diff = np.unique(X[~valid_mask, i])\n                msg = (\"Found unknown categories {0} in column {1}\"\n                       \" during transform\".format(diff, i))\n                raise ValueError(msg)\n            else:\n                # Set the problematic rows to an acceptable value and\n                # continue `The rows are marked `X_mask` and will be\n                # removed later.\n                X_mask[:, i] = valid_mask\n                Xi = Xi.copy()\n                Xi[~valid_mask] = self.categories_[i][0]\n        X_int[:, i] = self._label_encoders_[i].transform(Xi)\n\n    return X_int, X_mask\n\n", "CodeBleu_score": 41.53639661376162}, {"code": "def _transform_new(self, X)\n\t\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    n_samples, n_features = X.shape\n    X_int = np.zeros((n_samples, n_features), dtype=np.int)\n    X_mask = np.ones((n_samples, n_features), dtype=np.bool)\n\n    for i in range(n_features):\n        Xi = X[:, i]\n        valid_mask = np.in1d(Xi, self.categories_[i])\n\n        if not np.all(valid_mask):\n            if self.handle_unknown == 'error':\n                diff = np.unique(X[~valid_mask, i])\n                msg = (\"Found unknown categories {0} in column {1}\"\n                       \" during transform\".format(diff, i))\n                raise ValueError(msg)\n            else:\n                # Set the problematic rows to an acceptable value and\n                # continue `The rows are marked `X_mask` and will be\n                # removed later.\n                X_mask[:, i] = valid_mask\n                Xi = Xi.copy()\n                Xi[~valid_mask] = self.categories_[i][0]\n        X_int[:, i] = self._label_encoders_[i].transform(Xi)\n\n    return X_int, X_mask\n\n", "CodeBleu_score": 44.30138412832684}]}
{"instance_id": "fcde391a8972", "generation_result": [{"code": "def convert_to_sklearn(self)\n\t\n    import scipy.stats as st\n    if self.log:\n        return st.uniform(loc=self.lower, scale=self.upper - self.lower)\n    else:\n        return st.uniform(loc=self.lower, scale=self.upper - self.lower)", "CodeBleu_score": 30.871969438537718}, {"code": "def convert_to_sklearn(self)\n\t\n    from scipy.stats import uniform, loguniform\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    else:\n        return uniform(self.lower, self.upper)", "CodeBleu_score": 34.62120361072451}, {"code": "def convert_to_sklearn(self)\n\t\n    import scipy.stats as st\n    if self.log:\n        return st.uniform(loc=self.lower_bound, scale=self.upper_bound - self.lower_bound)\n    else:\n        return st.uniform(loc=self.lower_bound, scale=self.upper_bound - self.lower_bound)", "CodeBleu_score": 28.026261378308725}]}
{"instance_id": "5d5413adcca6", "generation_result": [{"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n\n    if self.headers:\n        self._render_header(state)\n\n    fig, axs = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.kwargs}\n    if self.two_way:\n        data = state.data.dropna(subset=features)\n    else:\n        data = state.data\n\n    for i, feature in enumerate(features):\n        if self.two_way:\n            if i == len(features) - 1:\n                break\n            feature_1, feature_2 = feature\n            display = PartialDependenceDisplay.from_estimator(\n                state.model, data, [feature_1, feature_2], ax=axs[i], **kwargs\n            )\n        else:\n            display = PartialDependenceDisplay.from_estimator(\n                state.model, data, [feature], ax=axs[i], **kwargs\n            )\n\n    fig.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 51.18733687994366}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers:\n        self._render_header(state)\n    fig, axes = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.pd_kwargs}\n    if self.two_way:\n        if self.two_way_filter_non_null:\n            data = state.data[state.data[features[0]] != None]\n        else:\n            data = state.data\n        display = PartialDependenceDisplay.from_estimator(\n            state.model, data, features, ax=axes, **kwargs\n        )\n    else:\n        display = PartialDependenceDisplay.from_estimator(\n            state.model, state.data, features, ax=axes, **kwargs\n        )\n    fig.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 52.90725042542688}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers is not None:\n        self._render_header(state)\n    fig, axes = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.pd_line_kw, **self.ice_lines_kw}\n    if self.two_way:\n        data = state.data.loc[~state.data[features[0]].isnull() & ~state.data[features[1]].isnull()]\n    else:\n        data = state.data\n    PartialDependenceDisplay.from_estimator(\n        state.model, data, features, ax=axes, **kwargs\n    )\n    fig.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 48.69613415961075}]}
{"instance_id": "db8aac29180b", "generation_result": [{"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}]}
{"instance_id": "d4eb45e6d013", "generation_result": [{"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # Get model parameters\n    num_trees = self.get_params()['num_trees']\n    num_classes = self.get_params()['num_classes']\n    num_features = self.get_params()['num_features']\n    num_leaves = self.get_params()['num_leaves']\n    num_trees_per_estimator = self.get_params()['num_trees_per_estimator']\n    # Determine final number of estimators\n    if num_trees is None and self.search_space is not None:\n        final_num_estimators = self.search_space['num_estimators']['max']\n    elif num_trees is None:\n        final_num_estimators = 40\n    else:\n        final_num_estimators = num_trees\n    # Calculate number of trees per estimator\n    if num_trees_per_estimator is None:\n        num_trees_per_estimator = self._get_num_trees_per_estimator()\n    # Estimate bytes per estimator\n    if self.problem_type in [MULTICLASS, SOFTCLASS]:\n        bytes_per_estimator = (\n            num_classes * num_features * num_leaves * num_trees_per_estimator * 4\n        )\n    else:\n        bytes_per_estimator = num_features * num_leaves * num_trees_per_estimator * 4\n    # Adjustment factor for memory usage\n    adjustment_factor = 1.2\n    # Calculate expected minimum memory usage\n    expected_min_memory_usage = (\n        bytes_per_estimator * final_num_estimators * adjustment_factor\n    )\n    return expected_min_memory_usage\n\n", "CodeBleu_score": 36.07553449754937}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # Get model parameters\n    num_estimators = self.get_params()[\"num_estimators\"]\n    final_num_estimators = self.get_params()[\"final_num_estimators\"]\n    search_space = self.get_params()[\"search_space\"]\n    # Set minimum number of estimators to 40 if final_num_estimators is less than 40 or if a search space is defined\n    if final_num_estimators is None or final_num_estimators < 40 or search_space is not None:\n        final_num_estimators = max(40, final_num_estimators)\n    # Get number of trees per estimator\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    # Estimate bytes used per estimator based on the size of X, with an adjustment factor\n    bytes_per_estimator = estimate_bytes_per_estimator(X, num_trees_per_estimator, **kwargs)\n    # Calculate the expected minimum memory usage\n    min_mem_usage = final_num_estimators * bytes_per_estimator\n    return min_mem_usage\n\n", "CodeBleu_score": 43.747552777574604}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # Get model parameters\n    num_trees = self.get_params().get(\"n_estimators\", 100)\n    # Get final number of estimators\n    if self.estimators_ is None:\n        final_num_estimators = num_trees\n    else:\n        final_num_estimators = len(self.estimators_)\n    # Set minimum number of estimators\n    if final_num_estimators < 40 or self.search_space is not None:\n        final_num_estimators = max(40, final_num_estimators)\n    # Get number of trees per estimator\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    # Estimate bytes per estimator\n    bytes_per_estimator = X.nbytes * 1.1\n    # Calculate expected minimum memory usage\n    expected_min_memory_usage = bytes_per_estimator * final_num_estimators\n    return expected_min_memory_usage\n\n", "CodeBleu_score": 47.366926352166686}]}
{"instance_id": "6923cb007f4c", "generation_result": [{"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    ngram_counter = Counter(ngram_freq)\n    top_ngrams = ngram_counter.most_common(vocab_size)\n    top_ngrams = [ngram[0] for ngram in top_ngrams]\n    top_ngrams.sort()\n    new_vocab = {ngram: index for index, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = new_vocab\n\n\n", "CodeBleu_score": 31.869926725684927}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    ngram_counts = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, count in ngram_counts.most_common(vocab_size)]\n    top_ngrams.sort()\n    new_vocab = {ngram: i for i, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary_ = new_vocab\n    return vectorizer\n\n\n", "CodeBleu_score": 32.52687462565045}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    ngram_counter = Counter(ngram_freq)\n    top_ngrams = [ngram for ngram, count in ngram_counter.most_common(vocab_size)]\n    top_ngrams.sort()\n    new_vocab = {ngram: idx for idx, ngram in enumerate(top_ngrams)}\n    vectorizer.vocabulary = new_vocab\n    return vectorizer\n\n\n", "CodeBleu_score": 30.99011505159356}]}
{"instance_id": "0e837b2d8088", "generation_result": [{"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = {}\n    skewness_threshold = self.params.get('skewness_threshold', 0.75)\n\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            feature_types[feature] = 'skewed'\n        else:\n            feature_types[feature] = 'continuous'\n\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.46663267506551}, {"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = {}\n    skewness_threshold = self.params['skewness_threshold']\n    for feature in features:\n        skewness = df[feature].skew()\n        if skewness > skewness_threshold:\n            feature_types[feature] = 'skewed'\n        else:\n            feature_types[feature] = 'continuous'\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.573334829043674}, {"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = {}\n    skew_threshold = self.params.get(\"skew_threshold\", 0.5)\n    for feature in features:\n        skew = df[feature].skew()\n        if skew > skew_threshold:\n            feature_types[feature] = \"skewed\"\n        else:\n            feature_types[feature] = \"continuous\"\n    return feature_types\n\n\n\n\n def _select_categorical(self, df, features):\n    \"\"\"# This function categorizes features in a DataFrame as either continuous or skewed based on their skewness.", "CodeBleu_score": 35.41494960567714}]}
{"instance_id": "bb569c10f975", "generation_result": [{"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    if weights == \"distance\":\n        weights = 1.0 / dist\n        inf_mask = np.isinf(weights)\n        weights[inf_mask] = 0\n        weights = weights / np.sum(weights)\n        return weights\n    if callable(weights):\n        return weights(dist)\n    raise ValueError(\"weights should be 'uniform', 'distance', or a callable function\")\n\n\n\n", "CodeBleu_score": 49.12457972725291}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        weights = 1.0 / dist\n        weights[weights == np.inf] = 0.0\n        weights /= weights.sum()\n        return weights\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"Unknown weights parameter: {}\".format(weights))\n\n\n", "CodeBleu_score": 39.772727560280416}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        dist = dist.copy()\n        dist[np.isinf(dist)] = np.nan\n        dist[np.isnan(dist)] = 0\n        dist = np.reciprocal(dist)\n        dist[np.isnan(dist)] = 0\n        dist[np.isinf(dist)] = 0\n        return dist\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"weights should be 'uniform', 'distance', or a callable function\")\n\n", "CodeBleu_score": 50.86822392721921}]}
{"instance_id": "12aaa9c78402", "generation_result": [{"code": "def predict_loo(self)\n\t\n    # Compute the distances and indices of the k-nearest neighbors\n    distances, indices = self.kneighbors(self.X)\n\n    # Compute the weights for the neighbors\n    weights = self._get_weights(distances)\n\n    # Reshape the target variable if it is one-dimensional\n    if self.y.ndim == 1:\n        self.y = self.y.reshape(-1, 1)\n\n    # Compute the predictions\n    if self.weights == \"uniform\":\n        # Unweighted prediction\n        predictions = np.mean(self.y[indices], axis=1)\n    else:\n        # Weighted prediction\n        predictions = np.sum(self.y[indices] * weights, axis=1) / np.sum(weights, axis=1)\n\n    # Flatten the predictions if the original target variable was one-dimensional\n    if self.y.ndim == 1:\n        predictions = predictions.flatten()\n\n    return predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.165114277267012}, {"code": "def predict_loo(self)\n\t\n    self.distances, self.indices = self.knn.kneighbors(self.X)\n    self.weights = self._get_weights()\n    if len(self.y.shape) == 1:\n        self.y = self.y.reshape(-1, 1)\n    if self.weights is None:\n        self.predictions = np.mean(self.y[self.indices], axis=1)\n    else:\n        self.predictions = np.sum(self.y[self.indices] * self.weights, axis=1) / np.sum(self.weights, axis=1)\n    if len(self.y.shape) == 1:\n        self.predictions = self.predictions.flatten()\n    return self.predictions\n\n\n\n", "CodeBleu_score": 27.74137508164089}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors(self.X)\n    weights = self._get_weights(distances)\n    if self.y.ndim == 1:\n        self.y = self.y.reshape(-1, 1)\n    predictions = np.average(self.y[indices], axis=1, weights=weights)\n    if self.y.ndim == 1:\n        predictions = predictions.flatten()\n    return predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 22.596475124855296}]}
{"instance_id": "b316687d9e9b", "generation_result": [{"code": "def isotonic(input_data, quantile_list)\n\t\n    import numpy as np\n    from sklearn.isotonic import IsotonicRegression\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        data_row = input_data[i]\n        ir = IsotonicRegression(y_min=np.min(quantile_list), y_max=np.max(quantile_list), increasing=True)\n        ir.fit(quantile_list, data_row)\n        transformed_data.append(ir.transform(data_row))\n    return np.stack(transformed_data)\n\n\n", "CodeBleu_score": 56.03945742650962}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_array = np.reshape(quantile_list, (-1))\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        row = input_data[i]\n        isotonic_regressor = IsotonicRegression(quantile_array)\n        transformed_row = isotonic_regressor.fit_transform(row)\n        transformed_data.append(transformed_row)\n    transformed_data = np.stack(transformed_data)\n    return transformed_data\n\n\n", "CodeBleu_score": 31.57698500958046}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = quantile_list.reshape(-1)\n    batch_size = input_data.shape[0]\n    output_data = []\n    for i in range(batch_size):\n        row = input_data[i]\n        isotonic_regression = IsotonicRegression(quantile_list)\n        transformed_row = isotonic_regression.fit_transform(row)\n        output_data.append(transformed_row)\n    output_data = np.stack(output_data)\n    return output_data\n\n\n", "CodeBleu_score": 43.91510897650242}]}
{"instance_id": "17566e088b4e", "generation_result": [{"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_text = vectorizer.transform(text_data)\n    return vectorizer, vectorized_text\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.22807051565422}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.stop_words_ = None\n    vectorizer.fit(text_data)\n    vectorized_data = vectorizer.transform(text_data)\n    return vectorizer, vectorized_data\n\n", "CodeBleu_score": 45.25213029105295}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    return vectorizer, vectorizer.transform(text_data)\n\n", "CodeBleu_score": 40.6826747095547}]}
{"instance_id": "be23c0afc2d6", "generation_result": [{"code": "def preprocess(df, test_size, shuffle)\n\t\n    df = df.dropna(subset=[\"days_to_death\", \"year_of_death\"])\n    df = df.drop(df.columns[df.nunique() <= 1], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"id\")], axis=1)\n    df = df.drop([\"days_to_death\", \"year_of_death\"], axis=1)\n    df = df.drop([\"age_at_diagnosis\", \"age_at_death\"], axis=1)\n    df = df.drop([\"days_to_last_followup\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis\"], axis=1)\n    df = df.drop([\"days_to_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis_and_last_followup_diagnosis_and_", "CodeBleu_score": 16.544623798646143}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    df = df.dropna(subset=['days_to_death', 'year_of_death'])\n    df = df.drop(df.columns[df.nunique() <= 1], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"id\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"shortcut\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"age\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"year\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"month\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"day\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"day_of_week\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"hour\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"minute\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"second\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"microsecond\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"time\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply(lambda x: \"date\" in x.name.lower())], axis=1)\n    df = df.drop(df.columns[df.apply", "CodeBleu_score": 18.511416634257095}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    df = df.dropna(subset=df.columns[df.isna().any()])\n    df = df.drop(df.columns[df.nunique() <= 1], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"id\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"shortcut\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"date\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"time\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"year\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"month\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"day\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"hour\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"minute\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"second\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"day_of_week\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"day_of_year\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"week_of_year\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"month_of_year\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"year_of_century\")], axis=1)\n    df = df.drop(df.columns[df.columns.str.contains(\"year_of_decade\")], axis=1)\n    df = df.drop", "CodeBleu_score": 19.656337161522018}]}
{"instance_id": "6a82997a8c59", "generation_result": [{"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n    search_space = classifier.get_hyperparameter_search_space()\n    config = search_space.get_default_configuration()\n    cl = classifier(config=config, random_state=42)\n    cl.fit(X_train, Y_train)\n    for i in range(2):\n        cl.fit(X_train, Y_train, refit=True)\n    for i in range(2):\n        cl.fit(X_train, Y_train, refit=True, iterative_fit=True)\n    cl.fit(X_train, Y_train, refit=True, iterative_fit=True)\n    preds = cl.predict(X_test)\n    return preds, Y_test, cl\n\n", "CodeBleu_score": 31.96117797483798}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, make_sparse=sparse)\n    hyperparameters = classifier.get_hyperparameter_search_space().get_default_configuration()\n    classifier = classifier(hyperparameters=hyperparameters, random_state=42)\n    classifier.fit(X_train, Y_train)\n    for i in range(2):\n        classifier.fit(X_train, Y_train, refit=True)\n    while classifier.get_current_iteration() < classifier.get_max_iter():\n        classifier.fit(X_train, Y_train, refit=True)\n    Y_pred = classifier.predict(X_test)\n    return Y_pred, Y_test, classifier\n\n", "CodeBleu_score": 33.06324619805231}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(\n        dataset=dataset, make_sparse=sparse\n    )\n    search_space = classifier.get_hyperparameter_search_space()\n    default_config = search_space.get_default_configuration()\n    classifier = classifier(\n        **default_config, random_state=1, refit_full=True\n    )\n    classifier.fit(X_train, Y_train)\n    for _ in range(2):\n        classifier.fit_iterative(X_train, Y_train, refit=True)\n    for _ in range(10):\n        classifier.fit_iterative(X_train, Y_train, refit=False)\n    Y_pred = classifier.predict(X_test)\n    return Y_pred, Y_test, classifier\n\n", "CodeBleu_score": 35.3310515106063}]}
{"instance_id": "d0d8450c4c17", "generation_result": [{"code": "def _load_models(self)\n\t\n    # Load ensemble\n    if self._ensemble_class:\n        self._logger.info(\"Loading ensemble from backend\")\n        ensemble = self._ensemble_class(\n            metrics=self._metrics,\n            task_type=self._task,\n            seed=self._seed,\n            backend=self._backend,\n            random_state=self._seed,\n        )\n        ensemble.load_ensemble(self._ensemble_name)\n        self._models = ensemble.get_models()\n        self._cv_models = ensemble.get_cv_models()\n        self._logger.info(\n            \"Loaded ensemble with {} models\".format(len(self._models))\n        )\n    else:\n        # Load best individual model\n        if self._best_individual_model_from_runhistory:\n            self._logger.info(\n                \"Loading best individual model from runhistory\"\n            )\n            self._models = [\n                self._load_best_individual_model(),\n            ]\n            self._cv_models = None\n        else:\n            self._logger.info(\"Loading best individual model\")\n            self._models = [\n                self._load_best_individual_model(),\n            ]\n            self._cv_models = None\n\n    # Load cross-validated models\n    if self._cv_models_from_runhistory:\n        self._logger.info(\"Loading cross-validated models from runhistory\")\n        self._cv_models = self._load_cv_models()\n    else:\n        self._logger.info(\"Loading cross-validated models\")\n        self._cv_models = self._load_cv_models()\n\n    # Initialize empty lists for models and cross-validated models\n    if not self._models and not self._cv_models:\n        self._models = []\n        self._cv_models = []\n\n    # Retrieve model identifiers\n    self._model_identifiers = [\n        model.get_model_id() for model in self._models\n    ]\n    self._cv_model_identifiers = [\n        model.get_model_id() for model in self._cv_models\n    ]\n\n", "CodeBleu_score": 38.41613019707141}, {"code": "def _load_models(self)\n\t\n    # Load the ensemble model\n    if self._ensemble_class:\n        self._logger.info(\"Loading ensemble model from backend.\")\n        self._ensemble = self._ensemble_class(\n            task_type=self._task,\n            seed=self._seed,\n            backend=self._backend,\n            random_state=self._seed,\n        )\n        self._ensemble.load(self._ensemble_class.get_ensemble_name(self._seed))\n\n    # Load the best individual model if no ensemble was loaded\n    if not self._ensemble:\n        self._ensemble = self._load_best_individual_model()\n\n    # If the ensemble was loaded, load the models\n    if self._ensemble:\n        self._logger.info(\"Loading models from backend.\")\n        self._identifiers = self._ensemble.get_identifiers_with_weights()\n        self._models = self._ensemble.get_models()\n        self._cross_validated_models = self._ensemble.get_cross_validated_models()\n\n        # If the ensemble was loaded but no models were found, load the best individual model\n        if not self._identifiers:\n            self._ensemble = self._load_best_individual_model()\n\n        # If the ensemble was loaded and models were found, load the cross-validated models\n        if self._identifiers and self._cross_validated_models is None:\n            self._cross_validated_models = self._ensemble.get_cross_validated_models()\n\n        # If the ensemble was loaded and no models were found, load the best individual model\n        if not self._identifiers and not self._cross_validated_models:\n            self._ensemble = self._load_best_individual_model()\n\n    # If no ensemble was loaded, initialize empty lists for models and cross-validated models\n    else:\n        self._identifiers = []\n        self._models = []\n        self._cross_validated_models = []\n\n", "CodeBleu_score": 40.001652899080796}, {"code": "def _load_models(self)\n\t\n    # If ensemble class is specified, load the ensemble using the backend and a seed\n    if self._ensemble_class:\n        ensemble = self._ensemble_class(\n            metrics=self._metrics,\n            task_type=self._task,\n            seed=self._seed,\n            run_history=self.runhistory_,\n            backend=self._backend,\n            random_state=self._seed,\n        )\n        ensemble.load(self._seed)\n        self._logger.info(\n            \"Loaded ensemble with the following model identifiers: %s\",\n            ensemble.get_identifiers_with_weights(),\n        )\n        self._models = ensemble.get_models()\n        self._cross_validated_models = ensemble.get_cross_validated_models()\n    else:\n        # If ensemble is not loaded, check if certain evaluator output conditions and resampling strategies are met\n        if (\n            self._ensemble_size > 1\n            and self._resampling_strategy == \"cv\"\n            and self._resampling_strategy_arguments is None\n        ):\n            ensemble = self._load_best_individual_model()\n            self._logger.info(\n                \"Loaded best individual model with the following model identifier: %s\",\n                ensemble.get_identifiers_with_weights(),\n            )\n            self._models = ensemble.get_models()\n            self._cross_validated_models = ensemble.get_cross_validated_models()\n        else:\n            # If no ensemble is loaded, initialize empty lists for models and cross-validated models\n            self._models = []\n            self._cross_validated_models = []\n\n    # If ensemble is successfully loaded, retrieve model identifiers and load the corresponding models using the backend\n    if self._models:\n        self._logger.info(\n            \"Loaded %s models with the following model identifiers: %s\",\n            len(self._models),\n            self._get_model_identifiers(),\n        )\n\n    # If cross-validated models are loaded, retrieve model identifiers and load the corresponding models using the backend\n    if self._cross_validated_models:\n       ", "CodeBleu_score": 37.17573136070848}]}
{"instance_id": "ef71b1cddb50", "generation_result": [{"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y, categorical_indicator, attribute_names = task.get_X_and_y(\n        target=task.default_target_attribute, return_categorical_indicator=True, return_attribute_names=True)\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    y_train_encoded = np.unique(y_train, return_inverse=True)[1]\n    y_test_encoded = np.unique(y_test, return_inverse=True)[1]\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.620088098051554}, {"code": "def load_task(task_id)\n\t\n    import openml\n    task = openml.tasks.get_task(task_id)\n    X, y, categorical_indicator, attribute_names = task.get_X_and_y(\n        return_categorical_indicator=True, return_attribute_names=True)\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train, X_test = X[train_indices], X[test_indices]\n    y_train, y_test = y[train_indices], y[test_indices]\n    unique_labels = np.unique(y_train)\n    y_train = np.searchsorted(unique_labels, y_train)\n    y_test = np.searchsorted(unique_labels, y_test)\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n\n\n\n", "CodeBleu_score": 21.767948528459026}, {"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y, _, _ = task.get_X_and_y(target=task.default_target_attribute, dataset_format='dataframe')\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n    feature_types = task.get_dataset().get_features_as_dataframe().type.values\n    is_categorical = [feature_type == 'categorical' for feature_type in feature_types]\n    y_train = y_train.astype('category').cat.codes.values\n    y_test = y_test.astype('category').cat.codes.values\n    return X_train, y_train, X_test, y_test, is_categorical\n\n\n", "CodeBleu_score": 26.982913120684422}]}
{"instance_id": "90bd6edbcc9e", "generation_result": [{"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, sp.spmatrix):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y", "CodeBleu_score": 55.56702222115098}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, (pd.DataFrame, pd.Series)):\n        return y\n    if sparse.issparse(y):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 52.9351866477359}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, (sparse.csr_matrix, sparse.csc_matrix, sparse.coo_matrix)):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.ravel()\n    return y\n\n\n\n\n", "CodeBleu_score": 52.007584945831255}]}
{"instance_id": "5728e3d4f914", "generation_result": [{"code": "def _calculate_weights(self) -> None\n\t\n    ensemble_size = len(self.ensemble)\n    weights = np.zeros(ensemble_size)\n    for i in range(ensemble_size):\n        weights[i] = np.sum(self.ensemble == i) / ensemble_size\n    if np.sum(weights) < 1:\n        weights = weights / np.sum(weights)\n    self.weights_ = weights\n\n\n\n", "CodeBleu_score": 39.87415760304449}, {"code": "def _calculate_weights(self) -> None\n\t\n    self.weights_ = np.zeros(self.n_models)\n    for i in range(self.n_models):\n        self.weights_[i] = np.count_nonzero(self.ensemble_indices_ == i) / self.n_models\n    if np.sum(self.weights_) < 1:\n        self.weights_ = self.weights_ / np.sum(self.weights_)\n\n\n", "CodeBleu_score": 23.45853532142213}, {"code": "def _calculate_weights(self) -> None\n\t\n    if self.weights_ is not None:\n        return\n    if self.ensemble_size == 1:\n        self.weights_ = np.array([1.0])\n        return\n    if self.ensemble_size == 2:\n        self.weights_ = np.array([0.5, 0.5])\n        return\n    if self.ensemble_size == 3:\n        self.weights_ = np.array([0.3333333333333333, 0.3333333333333333, 0.3333333333333333])\n        return\n    if self.ensemble_size == 4:\n        self.weights_ = np.array([0.25, 0.25, 0.25, 0.25])\n        return\n    if self.ensemble_size == 5:\n        self.weights_ = np.array([0.2, 0.2, 0.2, 0.2, 0.2])\n        return\n    if self.ensemble_size == 6:\n        self.weights_ = np.array([0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666])\n        return\n    if self.ensemble_size == 7:\n        self.weights_ = np.array([0.14285714285714285, 0.14285714285714285, 0.1428571428571428", "CodeBleu_score": 23.412648441690354}]}
{"instance_id": "4f9c4799fd8f", "generation_result": [{"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    pred_proba = self.automl_.predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ == \"multilabel-indicator\":\n        return pred_proba\n    else:\n        assert np.allclose(np.sum(pred_proba, axis=1), 1)\n        assert np.all(pred_proba >= 0)\n        assert np.all(pred_proba <= 1)\n        return pred_proba\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.00292607472911}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    return self.automl_.predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n\n", "CodeBleu_score": 9.489018990699531}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    proba = self.automl_.predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ == \"multilabel-indicator\":\n        return proba\n    else:\n        assert np.allclose(np.sum(proba, axis=1), 1)\n        assert np.all((proba >= 0) & (proba <= 1))\n        return proba\n\n", "CodeBleu_score": 32.89328186868195}]}
{"instance_id": "a9a13150aebe", "generation_result": [{"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, np.arange(Ybin.shape[1]))\n\n\n\n", "CodeBleu_score": 30.43598530373655}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if len(Ybin.shape) == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, np.arange(Ybin.shape[1]))\n\n\n", "CodeBleu_score": 36.03567744702259}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if len(Ybin.shape) > 1:\n        Ynum = np.dot(Ybin, np.arange(1, Ybin.shape[1] + 1))\n    else:\n        Ynum = Ybin\n    return Ynum\n\n\n", "CodeBleu_score": 50.11735340866325}]}
{"instance_id": "e97d38e62f81", "generation_result": [{"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n\n\n", "CodeBleu_score": 98.02795049070139}]}
{"instance_id": "b1aaad80a9c4", "generation_result": [{"code": "def test_glm_identity_link_func()\n\t\n    # Create a small dataset with two features and a target variable\n    df = pd.DataFrame({'feature1': [1, 2, 3, 4, 5], 'feature2': [2, 3, 4, 5, 6], 'target': [3, 4, 5, 6, 7]})\n    # Fit the GLM with an identity link function\n    glm = GeneralizedLinearModel(family=TweedieFamily(link=Power(1)), link=IdentityLink())\n    glm.fit(df[['feature1', 'feature2']], df['target'])\n    # Convert the fitted model into an expression representation\n    assembler = VectorAssembler(inputCols=['feature1', 'feature2'], outputCol='features')\n    assembled_df = assembler.transform(df)\n    # Compare the assembled expression to an expected expression\n    assert glm.coef_[0] == assembled_df.select('features').collect()[0][0][0]\n    assert glm.coef_[1] == assembled_df.select('features').collect()[0][0][1]\n    assert glm.intercept_ == assembled_df.select('features').collect()[0][0][2]\n\n", "CodeBleu_score": 24.42666260102967}, {"code": "def test_glm_identity_link_func()\n\t\n    from pyspark.ml.regression import GeneralizedLinearRegression\n    from pyspark.ml.feature import VectorAssembler\n    from pyspark.sql.functions import col\n    from pyspark.sql.types import StructType, StructField, DoubleType\n    from pyspark.sql.session import SparkSession\n    spark = SparkSession.builder.appName(\"GLMIdentityLinkFunc\").getOrCreate()\n    schema = StructType([StructField(\"x\", DoubleType(), True)])\n    data = spark.createDataFrame([(1.0,), (2.0,), (3.0,)], schema)\n    glm = GeneralizedLinearRegression(family=\"tweedie\", link=\"power\", power=1.0)\n    glm_model = glm.fit(data)\n    assembler = VectorAssembler(inputCols=[\"coefficients\"], outputCol=\"features\")\n    assembled_model = assembler.transform(glm_model)\n    expected_expression = \"0.0 + (1.0 * x)\"\n    assert assembled_model.select(\"features\").collect()[0][0].toString() == expected_expression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.676591817131296}, {"code": "def test_glm_identity_link_func()\n\t\n    from pyspark.ml.feature import VectorAssembler\n    from pyspark.ml.regression import GeneralizedLinearRegression\n    from pyspark.sql.functions import col\n    from pyspark.sql.types import DoubleType, IntegerType, StructField, StructType\n    from pyspark.sql.window import Window\n    from pyspark.sql import SparkSession\n    spark = SparkSession.builder.appName(\"GLM_Identity_Link_Func\").getOrCreate()\n    data = spark.createDataFrame(\n        [(1, 0.0, 1.0, 1.0), (2, 2.0, 2.0, 4.0), (3, 4.0, 3.0, 9.0)],\n        StructType(\n            [\n                StructField(\"id\", IntegerType(), True),\n                StructField(\"x\", DoubleType(), True),\n                StructField(\"y\", DoubleType(), True),\n                StructField(\"z\", DoubleType(), True),\n            ]\n        ),\n    )\n    glm = GeneralizedLinearRegression(\n        family=\"tweedie\", link=\"power\", linkParam=1.0, maxIter=10, regParam=0.0\n    )\n    model = glm.fit(data)\n    assembler = VectorAssembler(inputCols=[\"x\", \"y\"], outputCol=\"features\")\n    assembled_data = assembler.transform(data)\n    assembled_data = assembled_data.withColumn(\n        \"prediction\", model.transform(assembled_data).select(\"prediction\").collect()[0][0]\n    )\n    expected_expression = (\n        \"(1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 + (1.0 * (1.0 +", "CodeBleu_score": 33.600611627531116}]}
{"instance_id": "bcab63e592d0", "generation_result": [{"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        if isinstance(agg, str):\n            agg_name = agg\n        else:\n            agg_name = agg.__name__\n        agg_func = agg\n\n    new_col_name = f\"{col.name}_{agg_name}\"\n\n    return self.groupby(col.name).agg({col.name: agg_func}).reset_index(drop=True).rename(\n        columns={col.name: new_col_name}\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.04055064707459}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n    new_col_name = f\"{col.name}_{agg_name}\"\n    return self.groupby(level=0)[col.name].apply(agg_func).rename(new_col_name)\n\n\n\n", "CodeBleu_score": 59.563480423563554}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg = agg\n    elif isinstance(agg, str):\n        agg_name = agg\n    else:\n        agg_name = agg.__name__\n    col_name = f\"{col.name}_{agg_name}\"\n    if agg_name == \"count\":\n        return getattr(col, agg_name)()\n    return getattr(col, agg_name)().rename(col_name)\n\n\n", "CodeBleu_score": 47.16295847500987}]}
{"instance_id": "114d623dae7b", "generation_result": [{"code": "def _corrfunc(self, x, y, **kws)\n\t\n    import numpy as np\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as ticker\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.colorbar as colorbar\n    import matplotlib.colors as colors\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.colorbar as colorbar\n    import matplotlib.colors as colors\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.colorbar as colorbar\n    import matplotlib.colors as colors\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.colorbar as colorbar\n    import matplotlib.colors as colors\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.colorbar as colorbar\n    import matplotlib.colors as colors\n    import matplotlib.patches as mpatches\n    import matplotlib.transforms as mtransforms\n    import matplotlib.font_manager as font_manager\n   ", "CodeBleu_score": 6.316240257589792}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    import numpy as np\n    import pandas as pd\n    from scipy.stats import pearsonr\n    import warnings\n    warnings.filterwarnings(\"ignore\")\n    if 'ax' in kws:\n        ax = kws.pop('ax')\n    else:\n        ax = plt.gca()\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        hue_order = None\n    if 'hue_order' in kws:\n        hue_order = kws.pop('hue_order')\n    else:\n        h", "CodeBleu_score": 18.78789275233088}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    import seaborn as sns\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as ticker\n    import matplotlib.font_manager as font_manager\n    import matplotlib.patheffects as path_effects\n    import matplotlib.transforms as mtransforms\n    import matplotlib.colors as mcolors\n    import matplotlib.cm as cm\n    import matplotlib.patches as mpatches\n    import matplotlib.lines as mlines\n    import matplotlib.collections as mcollections\n    import matplotlib.artist as martist\n    import matplotlib.text as mtext\n    import matplotlib.axes as maxes\n    import matplotlib.figure as mfigure\n    import matplotlib.image as mimage\n    import matplotlib.contour as mcontour\n    import matplotlib.path as mpath\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n    import matplotlib.contour as mcontour\n   ", "CodeBleu_score": 4.422112627274911}]}
{"instance_id": "4c1ade308953", "generation_result": [{"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        return src\n    if method == 'decimal':\n        return round(src, rounddigit)\n    if method == 'sig':\n        from decimal import Decimal\n        return Decimal(src).quantize(Decimal('1e-{}'.format(rounddigit)))\n    if method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n\n", "CodeBleu_score": 53.253259599519254}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        from decimal import Decimal\n        return Decimal(str(src)).quantize(Decimal('1e-' + str(rounddigit)))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}f}')\n    else:\n        raise ValueError('Invalid rounding method.')\n\n", "CodeBleu_score": 55.145115563582735}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        from decimal import Decimal, ROUND_HALF_UP\n        return float(Decimal(src).quantize(Decimal('1E-{}'.format(rounddigit)), rounding=ROUND_HALF_UP))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}f}')\n    else:\n        raise ValueError('Invalid method. Use \"decimal\", \"sig\", or \"format\".')\n\n\n", "CodeBleu_score": 57.27614030748682}]}
{"instance_id": "a9923e678320", "generation_result": [{"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict", "CodeBleu_score": 81.96305219908217}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict", "CodeBleu_score": 81.96305219908217}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 81.96305219908217}]}
{"instance_id": "b6106e079dc0", "generation_result": [{"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    if hue_data is not None:\n        data = pd.DataFrame({\n            x_name: x.flatten(),\n            y_name: y.flatten(),\n            hue_name: hue_data.flatten(),\n        })\n    else:\n        data = pd.DataFrame({\n            x_name: x.flatten(),\n            y_name: y.flatten(),\n        })\n    sns.scatterplot(data=data, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if legend_kws.get('title') is None:\n        legend_kws['title'] = hue_name\n    if legend_kws.get('title') is not None:\n        ax.legend(**legend_kws)\n    return ax\n\n", "CodeBleu_score": 48.52065195320885}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    import pandas as pd\n    import seaborn as sns\n    import matplotlib.pyplot as plt\n    data = pd.DataFrame({\n        x_name: x.flatten(),\n        y_name: y.flatten(),\n    })\n    if hue_data is not None:\n        data[hue_name] = hue_data.flatten()\n    sns.scatterplot(data=data, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if legend_kws.get('title') is None:\n        legend_kws['title'] = hue_name\n    ax.legend(**legend_kws)\n    plt.show()\n\n", "CodeBleu_score": 46.420393344272085}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    import pandas as pd\n    import seaborn as sns\n    data = pd.DataFrame({x_name: x.flatten(), y_name: y.flatten()})\n    if hue_data is not None:\n        data[hue_name] = hue_data.flatten()\n    sns.scatterplot(data=data, x=x_name, y=y_name, hue=hue_name, ax=ax, **scatter_kws)\n    if legend_kws.get('title') is None:\n        legend_kws['title'] = hue_name\n    ax.legend(**legend_kws)\n    return ax\n\n", "CodeBleu_score": 46.49106847938654}]}
{"instance_id": "257e0aa5dd4d", "generation_result": [{"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}]}
{"instance_id": "6446de2223e8", "generation_result": [{"code": "def create_model(self, **kwargs)\n\t\n    model_type = kwargs.get(\"model_type\", \"auto_arima\")\n    if model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data()\n        model = ExponentialSmoothing(\n            endog=transformed_data[self.node.key],\n            seasonal_periods=self.seasonal_periods,\n            seasonal=self.seasonal,\n            trend=self.trend,\n            damped=self.damped,\n        )\n    elif model_type == \"auto_arima\":\n        try:\n            from pmdarima.arima import AutoARIMA\n        except ImportError:\n            logger.error(\n                \"pmdarima is not installed. Please install it to use auto_arima model.\"\n            )\n            return\n        transformed_data = self._get_transformed_data()\n        model = AutoARIMA(\n            start_p=self.start_p,\n            max_p=self.max_p,\n            start_q=self.start_q,\n            max_q=self.max_q,\n            m=self.m,\n            start_P=self.start_P,\n            max_P=self.max_P,\n            start_Q=self.start_Q,\n            max_Q=self.max_Q,\n            D=self.D,\n            start_d=self.start_d,\n            max_d=self.max_d,\n            max_order=self.max_order,\n            max_iter=self.max_iter,\n            trace=self.trace,\n            error_action=self.error_action,\n            suppress_warnings=self.suppress_warnings,\n            stepwise=self.stepwise,\n            seasonal=self.seasonal,\n            stationary=self.stationary,\n            information_criterion=self.information_criterion,\n            alpha=self.alpha,\n            test=self.test,\n            scoring=self.scoring,\n            n_jobs=self.n_jobs,\n            random_state=self.random_state,\n", "CodeBleu_score": 37.27325946018066}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data()\n        model = ExponentialSmoothing(\n            transformed_data, seasonal_periods=self.seasonal_periods\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import auto_arima\n        except ImportError:\n            self.logger.error(\n                \"pmdarima is not installed. Please install pmdarima to use auto_arima model.\"\n            )\n            sys.exit(1)\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = auto_arima(\n            transformed_data,\n            start_p=kwargs.get(\"start_p\", 1),\n            start_q=kwargs.get(\"start_q\", 1),\n            max_p=kwargs.get(\"max_p\", 3),\n            max_q=kwargs.get(\"max_q\", 3),\n            m=kwargs.get(\"m\", 12),\n            seasonal=kwargs.get(\"seasonal\", True),\n            stationary=kwargs.get(\"stationary\", False),\n            information_criterion=kwargs.get(\"information_criterion\", \"aic\"),\n            alpha=kwargs.get(\"alpha\", 0.05),\n            test=kwargs.get(\"test\", \"kpss\"),\n            stepwise=kwargs.get(\"stepwise\", True),\n            suppress_warnings=kwargs.get(\"suppress_warnings\", True),\n            error_action=kwargs.get(\"error_action\", \"ignore\"),\n            trace=kwargs.get(\"trace\", False),\n            random_state=kwargs.get(\"random_state\", 42),\n            n_jobs=kwargs.get(\"n_jobs\", -1),\n        )\n    elif self.model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exogenous = kwargs.get(\"exogenous\", None)\n        if exogenous is not None:\n            exogenous", "CodeBleu_score": 40.09934032623437}, {"code": "def create_model(self, **kwargs)\n\t\n    model_type = kwargs.get(\"model_type\", \"auto_arima\")\n    if model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data()\n        model = ExponentialSmoothing(\n            transformed_data,\n            seasonal_periods=self.seasonal_periods,\n            seasonal=self.seasonal,\n            trend=self.trend,\n            damped_trend=self.damped_trend,\n            initialization_method=self.initialization_method,\n            initial_level=self.initial_level,\n            initial_trend=self.initial_trend,\n            initial_seasonal=self.initial_seasonal,\n            use_boxcox=self.use_boxcox,\n            lambda_=self.lambda_,\n            remove_bias=self.remove_bias,\n            use_trend=self.use_trend,\n            use_damped_trend=self.use_damped_trend,\n            use_basinhopping=self.use_basinhopping,\n            remove_seasonality=self.remove_seasonality,\n            use_arma_errors=self.use_arma_errors,\n            suppress_warnings=self.suppress_warnings,\n            error_action=self.error_action,\n            stepwise=self.stepwise,\n            approximation=self.approximation,\n            optimizer=self.optimizer,\n            mle_regression=self.mle_regression,\n            simple_differencing=self.simple_differencing,\n            damped=self.damped,\n            trend=self.trend,\n            start_p=self.start_p,\n            start_q=self.start_q,\n            max_p=self.max_p,\n            max_q=self.max_q,\n            m=self.m,\n            seasonal=self.seasonal,\n            start_P=self.start_P,\n            start_Q=self.start_Q,\n            max_P=self.max_P,\n            max_Q=self.max", "CodeBleu_score": 19.44852788004486}]}
{"instance_id": "b2f67820e27f", "generation_result": [{"code": "def _to_chx(array)\n\t\n    if isinstance(array, chainerx.ndarray):\n        return array\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy is not None and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 82.4707901447282}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, chainerx.ndarray):\n        return array\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy is not None and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 82.4707901447282}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, chainerx.ndarray):\n        return array\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if cupy is not None and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 82.4707901447282}]}
{"instance_id": "b96f7d9bcc95", "generation_result": [{"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 0:\n        return []\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys) == 2:\n        return ys\n    if len(ys) > 2:\n        return ys\n    if", "CodeBleu_score": 9.770943523781197}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) > 0 and len(ys[0].shape) != len(x.shape):\n        # Calculate the expected shape of the split segments\n        expected_shape = list(x.shape)\n        expected_shape[axis] = indices_or_sections\n        # Split an empty array with the same shape as x along the specified axis\n        empty_array = np.empty(x.shape, dtype=x.dtype)\n        empty_array_split = np.split(empty_array, indices_or_sections, axis=axis)\n        # Calculate the split sizes based on the empty array split\n        split_sizes = [empty_array_split[i].shape[axis] for i in range(len(empty_array_split))]\n        # Reshape each segment to the expected shape\n        for i in range(len(ys)):\n            if ys[i].shape[axis] != split_sizes[i]:\n                ys[i] = ys[i].reshape(split_sizes[i], *ys[i].shape[1:])\n    return ys\n", "CodeBleu_score": 39.1421505122473}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 1:\n        return ys\n    if len(ys) != indices_or_sections.size + 1:\n        raise ValueError(\"indices_or_sections must have one element less than the number of splits.\")\n    if indices_or_sections.size == 0:\n        return [y.copy() for y in ys]\n    if indices_or_sections.size == 1:\n        if indices_or_sections[0] == 0:\n            return [y.copy() for y in ys]\n        elif indices_or_sections[0] == x.shape[axis]:\n            return [y.copy() for y in ys]\n        else:\n            raise ValueError(\"indices_or_sections must be either 0 or the length of the array along the specified axis.\")\n    if indices_or_sections.size > 1:\n        if indices_or_sections[0] != 0:\n            raise ValueError(\"indices_or_sections must start with 0.\")\n        if indices_or_sections[-1] != x.shape[axis]:\n            raise ValueError(\"indices_or_sections must end with the length of the array along the specified axis.\")\n        if np.any(np.diff(indices_or_sections) < 0):\n            raise ValueError(\"indices_or_sections must be strictly increasing.\")\n    if len(ys) != indices_or_sections.size + 1:\n        raise ValueError(\"indices_or_sections must have one element less than the number of splits.\")\n    if indices_or_sections.size == 0:\n        return [y.copy() for y in ys]\n    if indices_or_sections.size == 1:\n        if indices_or_sections[0] == 0:\n            return [y.copy() for y in ys]\n        elif indices_or_sections[0] == x.shape[axis]:\n            return [y.copy() for y in ys]\n        else:\n            raise ValueError(\"indices_or_sections must be either 0 or the length of the array along the specified axis.\")\n    if indices_or_sections.size > 1:\n        if indices_or", "CodeBleu_score": 20.377766828032687}]}
{"instance_id": "cf39fb123842", "generation_result": [{"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [to_device(b, device) for b in batch]\n    else:\n        xp = get_array_module(batch[0])\n        x = xp.concatenate([b[None] for b in batch], axis=0)\n        x = to_device(x, device)\n        return x.split(batch)\n\n\n", "CodeBleu_score": 37.2046189332917}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [to_device(b, device) for b in batch]\n    else:\n        xp = get_array_module(batch[0])\n        x = xp.concatenate([b for b in batch], axis=0)\n        sections = [b.shape[0] for b in batch]\n        return xp.split(to_device(x, device), sections, axis=0)\n\n\n", "CodeBleu_score": 39.5136519456732}, {"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    if device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    xp = chainer.backends.cuda.get_array_module(batch[0])\n    x = xp.concatenate([x[None] for x in batch])\n    sections = [len(b) for b in batch]\n    return xp.split(chainer.dataset.to_device(device, x), sections)\n\n\n", "CodeBleu_score": 47.86314646292658}]}
{"instance_id": "845c744d897c", "generation_result": [{"code": "def make_image(trainer)\n\t\n    torch.manual_seed(0)\n    num_images = trainer.args.num_images\n    z = torch.randn(num_images, trainer.args.latent_dim, 1, 1, device=trainer.device)\n    with torch.no_grad():\n        trainer.generator.eval()\n        images = trainer.generator(z)\n        images = images.cpu().numpy()\n        images = (images + 1) / 2\n        images = (images * 255).astype(np.uint8)\n        images = np.reshape(images, (num_images, trainer.args.image_size, trainer.args.image_size))\n        images = np.transpose(images, (0, 2, 1))\n        images = np.reshape(images, (num_images, trainer.args.image_size, trainer.args.image_size))\n        if not os.path.exists(trainer.args.preview_dir):\n            os.makedirs(trainer.args.preview_dir)\n        imageio.imwrite(os.path.join(trainer.args.preview_dir, 'preview_{}.png'.format(trainer.iteration)), images[0])\n\n\n", "CodeBleu_score": 31.57256867193802}, {"code": "def make_image(trainer)\n\t\n    trainer.set_random_seed()\n    num_images = min(trainer.config.preview_num_images,\n                     len(trainer.dataset))\n    z = trainer.get_latent_variable(num_images)\n    with torch.no_grad():\n        trainer.generator.eval()\n        images = trainer.generator(z).detach().cpu()\n        images = ((images + 1) / 2 * 255).clamp(0, 255).to(torch.uint8)\n        images = images.reshape(num_images, trainer.config.channels,\n                                trainer.config.image_size,\n                                trainer.config.image_size).permute(0, 2, 3, 1)\n        images = images.numpy()\n    if not os.path.exists(trainer.config.preview_dir):\n        os.makedirs(trainer.config.preview_dir)\n    filename = os.path.join(trainer.config.preview_dir,\n                            f'{trainer.current_iteration}.png')\n    preview_image = Image.fromarray(images[0])\n    preview_image.save(filename)\n\n\n", "CodeBleu_score": 32.884198221059215}, {"code": "def make_image(trainer)\n\t\n    torch.manual_seed(0)\n    num_images = 20\n    z = torch.randn(num_images, trainer.generator.z_dim, 1, 1, device=trainer.device)\n    with torch.no_grad():\n        trainer.generator.eval()\n        images = trainer.generator(z).cpu().numpy()\n        images = ((images + 1) / 2 * 255).astype(np.uint8)\n        images = np.reshape(images, (num_images, 3, 32, 32))\n        images = np.transpose(images, (0, 2, 3, 1))\n        images = np.reshape(images, (4, 5, 3, 32, 32))\n        images = np.transpose(images, (0, 2, 1, 3, 4))\n        images = np.reshape(images, (4 * 32, 5 * 32, 3))\n        images = Image.fromarray(images)\n        if not os.path.exists(\"preview\"):\n            os.makedirs(\"preview\")\n        images.save(f\"preview/iter_{trainer.iteration}.png\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.51647726362035}]}
{"instance_id": "fc2162d43aee", "generation_result": [{"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    _typechars = \"?biufFcCDO0\"\n    if from_dtype.char in _typechars and to_dtype.char in _typechars:\n        return _typechars.index(from_dtype.char) <= _typechars.index(to_dtype.char)\n    else:\n        return False\n\n", "CodeBleu_score": 44.10646134551561}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    _typechars = \"biufFcCDO?\"\n    return _typechars.find(from_dtype.char) <= _typechars.find(to_dtype.char)\n\n", "CodeBleu_score": 56.01154177328043}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    _typechars = \"?biufFD\"\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    return _typechars.find(from_dtype.char) < _typechars.find(to_dtype.char)\n\n", "CodeBleu_score": 52.34142875201911}]}
{"instance_id": "5b8e2d5e6e12", "generation_result": [{"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    import matplotlib.pyplot as plt\n    import matplotlib.patches as patches\n    if g is None:\n        ax = plt.gca()\n    else:\n        ax = g.ax\n    if len(labels) != len(colors):\n        raise ValueError(\"Length of labels and colors must match\")\n    handles = [patches.Patch(color=c, label=l) for (c, l) in zip(colors, labels)]\n    return ax.legend(handles=handles, **legend_kwargs)", "CodeBleu_score": 54.93650258676644}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    import matplotlib.pyplot as plt\n    import matplotlib.patches as patches\n    import numpy as np\n    \n    # Get the matplotlib Axes object from the input\n    ax = g.ax if isinstance(g, plt.Axes) else None\n    if ax is None:\n        ax = g.gca()\n    if ax is None:\n        ax = plt.gca()\n    \n    # Check that the lengths of the labels and colors lists match\n    if len(labels) != len(colors):\n        raise ValueError(\"Length of labels and colors lists must match.\")\n    \n    # Create legend handles by pairing each label with its corresponding color\n    legend_handles = [patches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]\n    \n    # Create the legend and return it\n    return ax.legend(handles=legend_handles, **legend_kwargs)\n\n\n", "CodeBleu_score": 48.31150316062479}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    import matplotlib.pyplot as plt\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as lines\n    import matplotlib.colors as colors\n    import matplotlib.patches as patches\n    import matplotlib.lines as", "CodeBleu_score": 10.867419229546496}]}
{"instance_id": "494e7f719eb6", "generation_result": [{"code": "def pcoords_time(X, y, fast=True)\n\t\n    import time\n    import matplotlib.pyplot as plt\n    from yellowbrick.visualizer import ParallelCoordinates\n\n    plt.figure()\n    visualizer = ParallelCoordinates(labels=['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'], speed='fast')\n    start_time = time.time()\n    visualizer.fit(X, y)\n    visualizer.transform(X)\n    elapsed_time = time.time() - start_time\n    plt.clf()\n    plt.close()\n    return elapsed_time\n\n\n", "CodeBleu_score": 43.45901808401849}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    # Initialize the ParallelCoordinates visualizer with the specified speed setting\n    pc = ParallelCoordinates(speed='fast' if fast else 'normal')\n\n    # Record the start time\n    start_time = time.time()\n\n    # Fit and transform the input data X and y with the visualizer\n    pc.fit_transform(X, y)\n\n    # Calculate the elapsed time\n    elapsed_time = time.time() - start_time\n\n    # Clear and close the current plot to free up resources\n    plt.clf()\n    plt.close()\n\n    # Return the elapsed time for the fit and transform process\n    return elapsed_time\n\n\n", "CodeBleu_score": 22.46444463720135}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    import time\n    import matplotlib.pyplot as plt\n    from yellowbrick.visualizer import ParallelCoordinates\n    plt.axis('off')\n    visualizer = ParallelCoordinates(speed=fast)\n    start = time.time()\n    visualizer.fit(X, y)\n    visualizer.transform(X)\n    end = time.time()\n    plt.clf()\n    plt.close()\n    return end - start\n\n\n", "CodeBleu_score": 43.47256037644688}]}
{"instance_id": "db4143bc029f", "generation_result": [{"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the alpha value from the object's attributes or default to 0.25\n    alpha = self.alpha_\n\n    # Initialize an empty list to store the plotted instances\n    plotted_instances = []\n\n    # Iterate over each instance in X and its corresponding label in y\n    for i, (x, yi) in enumerate(zip(X, y)):\n        # Get the color for the instance based on its label\n        color = self.get_colors(yi)\n\n        # Plot the instance using the provided features and the specified color\n        # and alpha value\n        plotted_instances.append(self.ax.plot(x, self.inc_, color=color, alpha=alpha))\n\n    # Return the plotted instances\n    return plotted_instances\n\n", "CodeBleu_score": 31.845040989220873}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n\n    # Get the alpha value from the object's attributes or default to 0.25\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n\n    # Loop over each instance and plot the feature vector against a predefined\n    # increment sequence on the axis\n    for i, x in enumerate(X):\n        self.ax.plot(x, self.increment, alpha=alpha, color=self.get_colors([y[i]])[0])\n\n    # Return the axis object with the plotted instances\n    return self.ax\n\n", "CodeBleu_score": 31.117641496119436}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n    for i, instance in enumerate(X):\n        color = self.get_colors([y[i]])[0]\n        self.ax.plot(self.x, instance, color=color, alpha=alpha)\n\n    return self.ax\n\n", "CodeBleu_score": 37.99290962482138}]}
{"instance_id": "676433312ffe", "generation_result": [{"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Set the alpha transparency value from the object's attributes or defaults to 0.5\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n\n    # Add a column of ones to X to separate the instances visually and append None to the increments list to create breaks between instances\n    X_ = np.hstack((X, np.ones((X.shape[0], 1))))\n    self.increments.append(None)\n\n    # Identify unique class labels in y and iterate over them\n    for label in np.unique(y):\n        # Determine the color, select the instances of X belonging to that class, and plot them as a single line plot with the specified color and alpha transparency\n        color = self.get_colors(label)\n        X_class = X_[y == label]\n        self.ax.plot(X_class, color=color, alpha=alpha)\n\n    # Return the axis object with the plotted classes\n    return self.ax", "CodeBleu_score": 28.688559644390292}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n    X = np.c_[X, np.ones(len(X))]\n    increments = [None]\n    for label in np.unique(y):\n        color = self.get_colors(label)\n        mask = y == label\n        self.ax.plot(\n            X[mask, 0],\n            X[mask, 1],\n            color=color,\n            alpha=alpha,\n            linestyle=\"None\",\n            marker=\"o\",\n            markersize=10,\n            markeredgecolor=color,\n            markeredgewidth=2.5,\n            markerfacecolor=\"None\",\n            **kwargs\n        )\n        increments.append(None)\n    return self.ax", "CodeBleu_score": 38.66882135819119}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Set the alpha transparency value from the object's attributes or default to 0.5\n    alpha = self.alpha if hasattr(self, \"alpha\") else 0.5\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.hstack((X, np.ones((X.shape[0], 1))))\n\n    # Append None to the increments list to create breaks between instances\n    self.increments.append(None)\n\n    # Identify unique class labels in y\n    classes = np.unique(y)\n\n    # Iterate over the classes\n    for c in classes:\n        # Determine the color for the class\n        color = self.get_colors(c)\n\n        # Select the instances of X belonging to the class\n        X_class = X[y == c]\n\n        # Plot the instances as a single line plot with the specified color and alpha transparency\n        self.ax.plot(\n            X_class[:, 0],\n            X_class[:, 1],\n            color=color,\n            alpha=alpha,\n            label=c,\n            **kwargs,\n        )\n\n    return self.ax\n\n", "CodeBleu_score": 37.40002046543834}]}
{"instance_id": "9d297b12a673", "generation_result": [{"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Set up figure and axes\n    fig, axs = plt.subplots(1, 2, figsize=(12, 5))\n\n    # Perform RadViz analysis on occupancy data\n    occupancy = load_occupancy()\n    X, y = occupancy\n    radviz = RadViz(classes=[\"unoccupied\", \"occupied\"])\n    radviz.fit(X, y)\n    radviz.transform(X)\n    radviz.ax_ = axs[0]\n    radviz.finalize()\n\n    # Perform Rank2D analysis on concrete data\n    concrete = load_concrete()\n    X, y = concrete\n    rank2d = Rank2D(classes=[\"low\", \"medium\", \"high\"])\n    rank2d.fit(X, y)\n    rank2d.transform(X)\n    rank2d.ax_ = axs[1]\n    rank2d.finalize()\n\n    # Save the figure\n    plt.savefig(fname)\n\n", "CodeBleu_score": 36.153391639159004}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    occupancy = load_occupancy()\n    concrete = load_concrete()\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n\n    occupancy_radviz = RadViz(ax=ax1)\n    occupancy_radviz.fit(occupancy.X, occupancy.y)\n    occupancy_radviz.finalize()\n\n    concrete_rank2d = Rank2D(ax=ax2)\n    concrete_rank2d.fit(concrete.X, concrete.y)\n    concrete_rank2d.transform(concrete.X)\n    concrete_rank2d.finalize()\n\n    plt.savefig(fname)\n\n", "CodeBleu_score": 20.750393053044775}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n    occupancy = load_occupancy()\n    X, y = occupancy\n    occupancy_rv = RadViz(ax=ax1)\n    occupancy_rv.fit(X, y)\n    occupancy_rv.finalize()\n\n    concrete = load_concrete()\n    X, y = concrete\n    concrete_r2d = Rank2D(ax=ax2)\n    concrete_r2d.fit(X, y)\n    concrete_r2d.transform(X)\n    concrete_r2d.finalize()\n\n    fig.savefig(fname)\n\n", "CodeBleu_score": 21.541341420383198}]}
{"instance_id": "fd1b4b9cd7ef", "generation_result": [{"code": "def regression(fname=\"regression.png\")\n\t\n    X, y = load_concrete(split=True)\n    alphas = np.logspace(-3, 3, 50)\n\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n\n    axes[0].plot(alphas, np.array([LassoCV(alphas=alphas).fit(X, y).mse_path_]).T)\n    axes[0].set_xlabel(\"alpha\")\n    axes[0].set_ylabel(\"Mean Squared Error\")\n    axes[0].set_title(\"LassoCV\")\n\n    axes[1].plot(alphas, np.array([RidgeCV(alphas=alphas).fit(X, y).cv_values_]).T)\n    axes[1].set_xlabel(\"alpha\")\n    axes[1].set_ylabel(\"Mean Squared Error\")\n    axes[1].set_title(\"RidgeCV\")\n\n    fig.tight_layout()\n    plt.savefig(fname)\n    return fname\n\n", "CodeBleu_score": 31.676767689778636}, {"code": "def regression(fname=\"regression.png\")\n\t\n    X, y = load_concrete(split=True)\n\n    alphas = np.logspace(-4, 4, 50)\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n    ax1.plot(alphas, np.array([LassoCV(alphas=alphas).fit(X_train, y_train).score(X_test, y_test) for X_train, y_train, X_test, y_test in Xy_split]), label=\"LassoCV\")\n    ax1.plot(alphas, np.array([Lasso(alpha=alpha).fit(X_train, y_train).score(X_test, y_test) for X_train, y_train, X_test, y_test in Xy_split]), label=\"Lasso\")\n    ax1.set_title(\"Prediction error\")\n    ax1.set_xlabel(\"Alpha\")\n    ax1.set_ylabel(\"R2 score\")\n    ax1.set_xscale(\"log\")\n    ax1.legend()\n\n    ax2.plot(alphas, np.array([RidgeCV(alphas=alphas).fit(X_train, y_train).score(X_test, y_test) for X_train, y_train, X_test, y_test in Xy_split]), label=\"RidgeCV\")\n    ax2.plot(alphas, np.array([Ridge(alpha=alpha).fit(X_train, y_train).score(X_test, y_test) for X_train, y_train, X_test, y_test in Xy_split]), label=\"Ridge\")\n    ax2.set_title(\"Residuals\")\n    ax2.set_xlabel(\"Alpha\")\n    ax2.set_ylabel(\"R2 score\")\n    ax2.set_xscale(\"log\")\n    ax2.legend()\n\n    fig.tight_layout()\n    fig.savefig(fname)\n    return fname", "CodeBleu_score": 27.828709278185283}, {"code": "def regression(fname=\"regression.png\")\n\t\n    X, y = load_concrete(split=True)\n\n    alphas = np.logspace(-3, 2, 100)\n\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n\n    # LassoCV\n    ax1.plot(alphas, np.array([mean_squared_error(y_test, LassoCV(alphas=a).fit(X_train, y_train).predict(X_test)) for a in alphas]))\n    ax1.set_xscale(\"log\")\n    ax1.set_xlabel(\"alpha\")\n    ax1.set_ylabel(\"MSE\")\n    ax1.set_title(\"LassoCV\")\n\n    # RidgeCV\n    ax2.plot(alphas, np.array([mean_squared_error(y_test, RidgeCV(alphas=a).fit(X_train, y_train).predict(X_test)) for a in alphas]))\n    ax2.set_xscale(\"log\")\n    ax2.set_xlabel(\"alpha\")\n    ax2.set_ylabel(\"MSE\")\n    ax2.set_title(\"RidgeCV\")\n\n    fig.tight_layout()\n    fig.savefig(fname)\n    return fname\n\n", "CodeBleu_score": 31.077363713427363}]}
{"instance_id": "627126918f88", "generation_result": [{"code": "def classification(fname=\"classification.png\")\n\t\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n\n    X_train, X_test, y_train, y_test = load_spam(split=True)\n    clf = MultinomialNB()\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    report = ClassificationReport(clf, ax=ax1)\n    report.fit(X_train, y_train)\n    report.score(X_test, y_test)\n    report.finalize()\n\n    X, y = load_spam()\n    clf = LogisticRegression(C=0.1, max_iter=1000)\n    clf.fit(X, y)\n    DiscriminationThreshold(clf, ax=ax2).finalize()\n\n    fig.tight_layout()\n    fig.savefig(fname)\n\n", "CodeBleu_score": 23.70539068288073}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\n    data = load_spam(split=True)\n    X_train, X_test, y_train, y_test = data\n\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n\n    y_pred = model.predict(X_test)\n\n    report = classification_report(y_test, y_pred)\n    print(report)\n\n    axes[0].text(0.01, 1.25, str(report), ha=\"left\", va=\"top\", fontsize=12)\n    axes[0].set_ylabel(\"\")\n    axes[0].set_xlabel(\"\")\n    axes[0].xaxis.set_visible(False)\n    axes[0].yaxis.set_visible(False)\n\n    data = load_spam()\n    X, y = data\n\n    model = LogisticRegression()\n    model.fit(X, y)\n\n    visualizer = DiscriminationThreshold(model)\n    visualizer.fit(X, y)\n    visualizer.finalize()\n\n    axes[1].text(0.01, 1.25, str(visualizer), ha=\"left\", va=\"top\", fontsize=12)\n    axes[1].set_ylabel(\"\")\n    axes[1].set_xlabel(\"\")\n    axes[1].xaxis.set_visible(False)\n    axes[1].yaxis.set_visible(False)\n\n    fig.tight_layout()\n\n    plt.savefig(fname)\n    plt.close()\n\n", "CodeBleu_score": 37.19173061582189}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n\n    X_train, X_test, y_train, y_test = load_spam(split=True)\n\n    mnb = MultinomialNB()\n    mnb.fit(X_train, y_train)\n    y_pred = mnb.predict(X_test)\n\n    report = classification_report(y_test, y_pred, output_dict=True)\n    sns.heatmap(pd.DataFrame(report).iloc[:-1, :].T, annot=True)\n    ax1.set_title(\"Classification Report\")\n\n    logreg = LogisticRegression()\n    logreg.fit(X_train, y_train)\n    DiscriminationThreshold().fit(logreg, X_train, y_train).poof()\n    ax2.set_title(\"Discrimination Threshold\")\n\n    fig.tight_layout()\n    fig.savefig(fname)\n\n", "CodeBleu_score": 28.53920302644187}]}
{"instance_id": "318d3a674694", "generation_result": [{"code": "def get_color_cycle()\n\t\n    import matplotlib\n    if matplotlib.__version__ >= \"1.5.0\":\n        try:\n            return matplotlib.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n        except KeyError:\n            pass\n    return matplotlib.rcParams[\"axes.color_cycle\"]\n\n\n\n", "CodeBleu_score": 41.20945811600997}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib\n        if matplotlib.__version__ >= \"1.5.0\":\n            return matplotlib.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n        else:\n            return matplotlib.rcParams[\"axes.color_cycle\"]\n    except KeyError:\n        return None\n\n", "CodeBleu_score": 32.341151528144664}, {"code": "def get_color_cycle()\n\t\n    import matplotlib\n    if matplotlib.__version__ >= \"1.5.0\":\n        try:\n            return matplotlib.rcParams[\"axes.prop_cycle\"].by_key()[\"color\"]\n        except KeyError:\n            pass\n    return matplotlib.rcParams[\"axes.color_cycle\"]\n\n\n", "CodeBleu_score": 41.20945811600997}]}
{"instance_id": "f3fac557334c", "generation_result": [{"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    fig = plt.figure(figsize=(8, 8))\n    plt.plot(self.normalized_x, self.normalized_y, label='Normalized Curve')\n    plt.plot(self.distance_curve, 'r', label='Distance Curve')\n    plt.xlabel('Distance')\n    plt.ylabel('Normalized Value')\n    plt.title('Normalized Curve and Distance Curve')\n    plt.legend()\n    if self.knee_point is not None:\n        plt.axvline(x=self.knee_point, color='black', linestyle='--', label='Knee Point')\n        plt.legend()\n    plt.xticks(np.arange(min(self.distance_curve), max(self.distance_curve)+1, 0.1))\n    plt.yticks(np.arange(min(self.normalized_y), max(self.normalized_y)+1, 0.1))\n    plt.show()\n\n\n", "CodeBleu_score": 39.699187670616865}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized, label=\"Normalized Curve\")\n    plt.plot(self.x_distance, self.y_distance, color=\"red\", label=\"Distance Curve\")\n    if self.knee_point is not None:\n        plt.axvline(x=self.knee_point, color=\"black\", linestyle=\"--\", label=\"Knee Point\")\n    plt.xlabel(\"X\")\n    plt.ylabel(\"Y\")\n    plt.xticks(np.arange(min(self.x_normalized), max(self.x_normalized) + 0.1, 0.1))\n    plt.yticks(np.arange(min(self.y_normalized), max(self.y_normalized) + 0.1, 0.1))\n    plt.legend()\n    plt.show()\n\n\n", "CodeBleu_score": 47.10763971919967}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y_normalized)\n    plt.plot(self.x, self.y_distance, color='red')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.xticks(np.arange(min(self.x), max(self.x) + 1, 0.1))\n    plt.yticks(np.arange(min(self.y_normalized), max(self.y_normalized) + 1, 0.1))\n    plt.axvline(x=self.knee_point, color='black', linestyle='--')\n    plt.show()\n\n\n", "CodeBleu_score": 48.237994316632125}]}
{"instance_id": "b2d48aae4fce", "generation_result": [{"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    import matplotlib.ticker as ticker\n    import numpy as np\n\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.plot(self.x, self.y, color=\"black\")\n    ax.set_xlabel(\"X\")\n    ax.set_ylabel(\"Y\")\n    ax.set_title(\"Knee Point\")\n    ax.set_xlim(0, np.max(self.x) * 1.1)\n    ax.set_ylim(0, np.max(self.y) * 1.1)\n    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n    ax.grid(True)\n    if self.knee_point is not None:\n        ax.axvline(x=self.knee_point, color=\"red\", linestyle=\"--\")\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.374176671536354}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    plt.axvline(x=self.knee, color=\"red\")\n    plt.show()", "CodeBleu_score": 47.41732252642772}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.plot(self.x, self.y)\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.set_title('Curve')\n    ax.axvline(self.knee_point, color='red', linestyle='--')\n    plt.show()\n\n\n\n", "CodeBleu_score": 41.627769391883895}]}
{"instance_id": "4450ba2384c9", "generation_result": [{"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from IPython.html.widgets import interact\n\n    pca = PCA(n_components=n_components)\n    X_transformed = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        approx = X_transformed[i].dot(pca.components_) + pca.mean_\n        plot_image_components(data[i], pca.components_, pca.mean_,\n                              approx, imshape=(8, 8), n_components=6,\n                              fontsize=10)\n\n    return interact(show_decomp, i=(0, len(data) - 1))\n\n", "CodeBleu_score": 68.59378622979115}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    \n    pca = PCA(n_components=n_components)\n    X_pca = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        approx = X_pca[i].dot(pca.components_) + pca.mean_\n        plot_image_components(data[i], X_pca[i], pca.mean_, pca.components_,\n                              imshape=(8, 8), n_components=n_components)\n        plt.gca().text(0, 1.05, '$+$', ha='right', va='bottom',\n                       transform=plt.gca().transAxes, fontsize=12)\n        plt.show()\n\n    interact(show_decomp, i=(0, len(X_pca) - 1))\n\n", "CodeBleu_score": 41.82826927433141}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    pca = PCA(n_components)\n    X_pca = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plt.figure(figsize=(10, 5))\n        plt.subplot(1, 2, 1)\n        plt.imshow(data[i].reshape(8, 8), cmap='gray')\n        plt.title('Original')\n        plt.subplot(1, 2, 2)\n        plt.imshow(X_pca[i].reshape(1, n_components), cmap='gray',\n                   interpolation='none')\n        plt.title('PCA Components')\n        plt.colorbar()\n        plt.show()\n\n    interact(show_decomp, i=(0, data.shape[0] - 1))\n\n", "CodeBleu_score": 39.12686934273349}]}
{"instance_id": "b09a163f3ff1", "generation_result": [{"code": "def plot_iris_knn()\n\t\n    from sklearn import datasets\n    from sklearn.neighbors import KNeighborsClassifier\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    # Load the Iris dataset\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n    \n    # Create a kNN classifier with 5 neighbors\n    knn = KNeighborsClassifier(n_neighbors=5)\n    \n    # Train the kNN model on the Iris dataset\n    knn.fit(X, y)\n    \n    # Define the mesh grid over the feature space\n    h = 0.02  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n    \n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n    \n    # Reshape the predictions to match the shape of the mesh grid\n    Z = Z.reshape(xx.shape)\n    \n    # Plot the decision boundaries\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n    \n    # Plot the training points\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max", "CodeBleu_score": 71.19954522304968}, {"code": "def plot_iris_knn()\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from sklearn import datasets\n    from sklearn.neighbors import KNeighborsClassifier\n\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n\n    # Create a kNN classifier with 5 neighbors\n    knn = KNeighborsClassifier(n_neighbors=5)\n\n    # Train the kNN classifier on the Iris dataset\n    knn.fit(X, y)\n\n    # Create a meshgrid of feature values\n    h = .02  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # Predict the class for each point in the meshgrid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Reshape the predictions to match the shape of the meshgrid\n    Z = Z.reshape(xx.shape)\n\n    # Plot the decision boundaries\n    plt.contourf(xx, yy, Z, cmap=plt.cm.Paired, alpha=0.8)\n\n    # Plot the training points\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired)\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.xticks(", "CodeBleu_score": 70.8843507885074}, {"code": "def plot_iris_knn()\n\t\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n    X = iris.data[:, :2]  # we only take the first two features.\n    y = iris.target\n\n    # Create a kNN classifier with 5 neighbors\n    knn = KNeighborsClassifier(n_neighbors=5)\n\n    # Train the kNN classifier on the Iris dataset\n    knn.fit(X, y)\n\n    # Create a mesh grid over the feature space\n    h = .02  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                         np.arange(y_min, y_max, h))\n\n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Reshape the predictions to match the mesh grid shape\n    Z = Z.reshape(xx.shape)\n\n    # Plot the decision boundaries\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n\n    # Plot the training points\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=cmap_bold,\n                edgecolor='k', s=20)\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.title(\"3-Class classification (k = %i)\"\n              % (5))\n\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.36897489547362}]}
{"instance_id": "8eaee3207c09", "generation_result": [{"code": "def plot_sgd_separator()\n\t\n    X, y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, y)\n    xx, yy = np.meshgrid(np.linspace(-1, 5, 500), np.linspace(-1, 5, 500))\n    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    plt.contour(xx, yy, Z, levels=[-1, 0, 1], linestyles=['dashed', 'solid', 'dashed'])\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, edgecolors='k', cmap=plt.cm.Paired)\n    plt.xlim(-1, 4.5)\n    plt.ylim(-1, 4.5)\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 28.696386046811988}, {"code": "def plot_sgd_separator()\n\t\n    from sklearn.datasets import make_blobs\n    from sklearn.linear_model import SGDClassifier\n    import matplotlib.pyplot as plt\n    import numpy as np\n    # Generate 50 separable data points\n    X, y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n    # Create a SGD classifier with hinge loss and fit it to the data\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, y)\n    # Create a meshgrid of values for plotting the decision boundary\n    xx, yy = np.meshgrid(np.linspace(-1, 5, 500), np.linspace(-1, 5, 500))\n    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    # Plot the decision boundary with different line styles\n    plt.contour(xx, yy, Z, levels=[-1, 0, 1], alpha=0.5, linestyles=['--', '-', '--'])\n    # Scatter plot the original data points\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=50, edgecolors='k')\n    plt.xlim(-1, 5)\n    plt.ylim(-1, 5)\n    plt.tight_layout()\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.32527847444949}, {"code": "def plot_sgd_separator()\n\t\n    X, y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, y)\n    xx, yy = np.meshgrid(np.linspace(-1, 5, 50), np.linspace(-1, 5, 50))\n    Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n    plt.contour(xx, yy, Z, levels=[-1, 0, 1], linestyles=['dashed', 'solid', 'dashed'])\n    plt.scatter(X[:, 0], X[:, 1], c=y, s=30, cmap='viridis')\n    plt.xlim(-1, 4)\n    plt.ylim(-1, 4)\n    plt.show()\n\n\n", "CodeBleu_score": 27.214492196217567}]}
{"instance_id": "8b54f999b4c0", "generation_result": [{"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}]}
{"instance_id": "2419013adc6e", "generation_result": [{"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}]}
{"instance_id": "e887fd2a8513", "generation_result": [{"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import re\n    import importlib\n    import warnings\n    import traceback\n    import sys\n    import types\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.util\n    import importlib.machinery\n    import importlib.", "CodeBleu_score": 6.299516671321248}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import importlib\n    import sys\n    if sourcecode.startswith(\"tpot.\"):\n        module_name = sourcecode[5:]\n        object_name = module_name\n    else:\n        module_name = sourcecode\n        object_name = sourcecode\n    try:\n        module = importlib.import_module(module_name)\n    except ImportError as e:\n        if verbose > 2:\n            raise\n        else:\n            print(\"Warning: could not import module '{}'\".format(module_name), file=sys.stderr)\n            return None\n    try:\n        obj = getattr(module, object_name)\n    except AttributeError as e:\n        if verbose > 2:\n            raise\n        else:\n            print(\"Warning: could not import object '{}' from module '{}'\".format(object_name, module_name), file=sys.stderr)\n            return None\n    return module_name, object_name, obj", "CodeBleu_score": 42.757488670029275}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    if sourcecode.startswith('tpot.'):\n        module_name = 'tpot.' + sourcecode.split('.')[1]\n        object_name = sourcecode.split('.')[2]\n    else:\n        module_name = sourcecode.split('.')[0]\n        object_name = sourcecode.split('.')[1]\n    try:\n        module = __import__(module_name, fromlist=[object_name])\n        obj = getattr(module, object_name)\n    except ImportError as e:\n        if verbose > 2:\n            raise e\n        elif verbose > 1:\n            print('Warning: Failed to import object: {}'.format(e))\n        else:\n            return None, None, None\n    return module_name, object_name, obj\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.87521095040374}]}
{"instance_id": "5d6f629c3363", "generation_result": [{"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step in pipeline_steps:\n            if hasattr(step, 'fit'):\n                if hasattr(step.fit, '__call__'):\n                    if hasattr(step.fit, '__code__'):\n                        if hasattr(step.fit.__code__, 'co_varnames'):\n                            if 'sample_weight' in step.fit.__code__.co_varnames:\n                                sample_weight_dict[step.__class__.__name__ + '_sample_weight'] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.645681452956794}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if hasattr(step.fit, \"__call__\"):\n                    if hasattr(step.fit, \"sample_weight\"):\n                        sample_weight_dict[step.__class__.__name__ + \"_sample_weight\"] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None", "CodeBleu_score": 42.91478876076426}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if hasattr(step.fit, \"__call__\"):\n                    if hasattr(step.fit, \"__self__\"):\n                        if hasattr(step.fit.__self__, \"sample_weight\"):\n                            sample_weight_dict[step.__class__.__name__ + \"_sample_weight\"] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None", "CodeBleu_score": 42.288735298215464}]}
{"instance_id": "cae17d519818", "generation_result": [{"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._best_pipeline:\n        raise RuntimeError(\n            \"No optimized pipeline found. Please run fit() before calling predict().\"\n        )\n\n    # Compile and fit the best pipeline\n    best_pipeline = self._best_pipeline.compile(features)\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        best_pipeline.fit(features, target)\n\n    # Print the best pipeline\n    if self.verbosity >= 1:\n        if self.verbosity >= 2:\n            print(\"\n", "CodeBleu_score": 20.579079550752112}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._top_pipeline:\n        raise RuntimeError(\n            \"No optimized pipeline found. Please run TPOT.fit(X, y) before trying to access the best pipeline.\"\n        )\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._top_pipeline.fit(features, target)\n    if self.verbosity >= 1:\n        print(\n            \"Best pipeline:\",\n            self._top_pipeline.steps,\n            file=self.log_file_,\n            end=\"\n", "CodeBleu_score": 20.062474986625848}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    if not self._best_pipeline:\n        raise RuntimeError(\n            \"No optimized pipeline found. Please run fit() before calling predict().\"\n        )\n\n    if self.verbosity >= 1:\n        if self.verbosity >= 2:\n            print(\n                \"\n", "CodeBleu_score": 11.088304973741444}]}
{"instance_id": "638683d78167", "generation_result": [{"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.optimized:\n        raise ValueError(\n            \"Error: The pipeline has not been optimized. Please call the optimize() method first.\"\n        )\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n    if self.scoring_function_type == \"callable\":\n        score = self.scoring_function(\n            self.fitted_pipeline, testing_features, testing_target\n        )\n    else:\n        score = SCORERS[self.scoring_function](\n            self.fitted_pipeline, testing_features, testing_target\n        )\n    return score\n\n", "CodeBleu_score": 41.090203385046415}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if self.optimized is False:\n        raise ValueError(\n            \"The pipeline has not been optimized. Please call `optimize()` first.\"\n        )\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n    scorer = get_scorer(self.scoring)\n    score = scorer(self.pipeline, testing_features, testing_target)\n    return score\n\n", "CodeBleu_score": 34.82266569478452}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.optimized:\n        raise Exception(\"Pipeline has not been optimized yet.\")\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n    if self.scoring_func_type == \"callable\":\n        scorer = self.scoring_func\n    else:\n        scorer = SCORERS[self.scoring_func]\n    return scorer(self.fitted_pipeline, testing_features, testing_target)\n\n", "CodeBleu_score": 33.43949231209161}]}
{"instance_id": "a04382560333", "generation_result": [{"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\n            \"Imputing missing values using median imputation strategy\",\n            file=self.log_file_,\n        )\n    if not self._imputer:\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n", "CodeBleu_score": 56.053302800172055}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        self._pbar.write(\n            \"Imputing missing values using median strategy\", file=self.log_file_\n        )\n    if not self._imputer:\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n", "CodeBleu_score": 64.4249893314673}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values...\")\n    if not self._imputer:\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n\n def _check_dataset(self, features, target, sample_weight):\n    \"\"\"Check the dataset for missing values and impute them if necessary.\n\n    Parameters\n    ----------\n    features: array-like {n_samples, n_features}\n        Feature matrix\n\n        TPOT and all scikit-learn algorithms assume that the features will be numerical\n        and there will be no missing values. As such, when a feature matrix is provided\n        to TPOT, all missing values will automatically be replaced (i.e., imputed) using\n        median value imputation.\n\n        If you wish to use a different imputation strategy than median imputation, please\n        make sure to apply imputation to your feature set prior to passing it to TPOT.\n    target: array-like {n_samples}\n        List of class labels for prediction\n    sample_weight: array-like {n_samples}, optional\n        Per-sample weights. Higher weights indicate more importance. If specified,\n        sample_weight will be passed to any pipeline element whose fit() function accepts\n        a sample_weight argument. By default, using sample_weight does not affect tpot's\n        scoring functions, which determine preferences between pipelines.\n\n    Returns\n    -------\n    features: array-like {n_samples, n_features}\n        Feature matrix with missing values imputed\n    target: array-like {n_samples}\n        List of class labels for prediction\n    sample_weight: array-like {n_samples}, optional\n        Per-sample weights. Higher weights indicate more importance. If specified,\n        sample_weight will be passed to any pipeline element whose fit() function accepts\n        a sample_weight argument. By default, using sample_weight does not affect tpot's\n        scoring functions, which determine preferences between pipelines.\n\n    \"\"\"\n    if sample_weight", "CodeBleu_score": 61.50105481229281}]}
{"instance_id": "0043d411c332", "generation_result": [{"code": "def _compile_to_sklearn(self, expr)\n\t\n    import sklearn.pipeline\n    from sklearn.base import BaseEstimator, TransformerMixin\n    from sklearn.utils.validation import check_is_fitted\n    from sklearn.utils import _safe_indexing\n    from sklearn.preprocessing import FunctionTransformer\n    from sklearn.utils.metaestimators import _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestimators import _BaseComposition as _BaseComposition\n    from sklearn.utils.metaestim", "CodeBleu_score": 10.653909673022222}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    from sklearn.pipeline import make_pipeline\n    from sklearn.utils import _safe_indexing\n    import numpy as np\n    import pandas as pd\n    import sklearn\n    import inspect\n    import sklearn.base\n    import sklearn.compose\n    import sklearn.impute\n    import sklearn.pipeline\n    import sklearn.preprocessing\n    import sklearn.utils\n    import sklearn.utils._param_validation\n    import sklearn.utils.validation\n    import sklearn.utils.validation\n    import sklearn.utils.validation._deprecation\n    import sklearn.utils.validation._deprecation._validation\n    import sklearn.utils.validation._deprecation._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base._validation._base._validation._base\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._validation._base._validation._base._validation._base._validation._base._validation\n    import sklearn.utils.validation._deprecation._validation._base._validation._base._", "CodeBleu_score": 12.072694888626986}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    from sklearn.pipeline import make_pipeline\n    from sklearn.base import clone\n    from sklearn.utils.validation import check_is_fitted\n    from sklearn.utils import _safe_indexing\n    from sklearn.utils.metaestimators import _BaseComposition\n    from sklearn.utils.metaestimators import _BaseEstimator\n    from sklearn.utils.metaestimators import _BaseMetaEstimator\n    from sklearn.utils.metaestimators import _ClassifierMixin\n    from sklearn.utils.metaestimators import _DecisionFunctionMixin\n    from sklearn.utils.metaestimators import _RegressorMixin\n    from sklearn.utils.metaestimators import _clone_estimator\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score_and_predict\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score_and_predict_and_transform\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score_and_predict_and_transform_and_inverse_transform\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score_and_predict_and_transform_and_inverse_transform_and_get_params\n    from sklearn.utils.metaestimators import _clone_estimator_with_checks_and_init_and_fit_and_score_and_predict_and_transform_and", "CodeBleu_score": 6.778230893670621}]}
{"instance_id": "ca0ce462aa76", "generation_result": [{"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n\n    # Create sets of primitive nodes for each individual\n    primitive_nodes_sets = [set(individual.primitives) for individual in population]\n\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            if (primitive_nodes_sets[i] & primitive_nodes_sets[j]) and individual_strings[i] != individual_strings[j]:\n                eligible_pairs.append((population[i], population[j]))\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Otherwise, randomly select one of the eligible pairs and return the corresponding individuals from the population\n    pair = random.choice(eligible_pairs)\n    return pair[0], pair[1]\n\n\n", "CodeBleu_score": 25.092586460984162}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    primitive_nodes_sets = [set(individual.primitive_nodes) for individual in population]\n\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n\n    # Find pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            if primitive_nodes_sets[i] & primitive_nodes_sets[j]:  # Check if there is at least one common primitive node\n                if individual_strings[i] != individual_strings[j]:  # Check if the individuals are not identical\n                    eligible_pairs.append((population[i], population[j]))\n                    eligible_pairs.append((population[j], population[i]))\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs and return the corresponding individuals from the population\n    pair = random.choice(eligible_pairs)\n    return pair[0], pair[1]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.427213899332905}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    primitive_nodes_sets = [set(individual.primitive_nodes) for individual in population]\n\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i in range(len(population)):\n        for j in range(i + 1, len(population)):\n            if primitive_nodes_sets[i] & primitive_nodes_sets[j] and individual_strings[i] != individual_strings[j]:\n                eligible_pairs.append((population[i], population[j]))\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs and return the corresponding individuals from the population\n    return random.choice(eligible_pairs)\n\n\n\n", "CodeBleu_score": 23.359420402902813}]}
{"instance_id": "4b03c843f506", "generation_result": [{"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n    if num_steps > 1:\n        steps_str = \",", "CodeBleu_score": 11.809302241097292}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n    if num_steps > 1:\n        steps_str = \"", "CodeBleu_score": 11.734245082859598}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(\"root\", operators)\n    if len(steps) > 1:\n        steps = \",", "CodeBleu_score": 7.217141583744574}]}
{"instance_id": "e9aec2ee39a4", "generation_result": [{"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}]}
{"instance_id": "0513bf969510", "generation_result": [{"code": "def transform(self, X)\n\t\n    # Select categorical features\n    categorical_features = self.select_features(X)\n    if len(categorical_features) == 0:\n        raise ValueError('No categorical features found in the input data.')\n    # Apply one-hot encoding to categorical features\n    X_transformed = self.one_hot_encode(X, categorical_features)\n    return X_transformed\n\n\n", "CodeBleu_score": 27.241891287533598}, {"code": "def transform(self, X)\n\t\n    # Check if there are any categorical features in the input data\n    if len(X.select_dtypes(include='object').columns) == 0:\n        raise ValueError(\"No categorical features found in the input data.\")\n    # Select categorical features based on the threshold\n    categorical_features = X.select_dtypes(include='object').columns\n    # Apply one-hot encoding to the selected categorical features\n    X_transformed = pd.get_dummies(X, columns=categorical_features)\n    return X_transformed", "CodeBleu_score": 29.085589314166505}, {"code": "def transform(self, X)\n\t\n    categorical_features = self.select_categorical_features(X)\n    if len(categorical_features) == 0:\n        raise ValueError(\"No categorical features found in the input data.\")\n    X_transformed = self.one_hot_encode(X, categorical_features)\n    return X_transformed\n", "CodeBleu_score": 24.781960646455754}]}
{"instance_id": "5b1bcf42ca9e", "generation_result": [{"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    classes = np.unique(y_true)\n    class_accuracies = []\n    for cls in classes:\n        y_true_cls = (y_true == cls).astype(int)\n        y_pred_cls = (y_pred == cls).astype(int)\n        tp = np.sum(y_true_cls * y_pred_cls)\n        fp = np.sum((1 - y_true_cls) * y_pred_cls)\n        fn = np.sum(y_true_cls * (1 - y_pred_cls))\n        tn = np.sum((1 - y_true_cls) * (1 - y_pred_cls))\n        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 1\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n    return np.mean(class_accuracies)\n\n\n", "CodeBleu_score": 22.23776150263125}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    # Get unique classes in true and predicted labels\n    classes = np.unique(np.concatenate([y_true, y_pred]))\n    \n    # Initialize variables to store sensitivity, specificity, and class accuracy\n    sensitivity = np.zeros(len(classes))\n    specificity = np.zeros(len(classes))\n    class_accuracy = np.zeros(len(classes))\n    \n    # Calculate sensitivity, specificity, and class accuracy for each class\n    for i, c in enumerate(classes):\n        tp = np.sum((y_true == c) & (y_pred == c))\n        fp = np.sum((y_true != c) & (y_pred == c))\n        fn = np.sum((y_true == c) & (y_pred != c))\n        tn = np.sum((y_true != c) & (y_pred != c))\n        \n        if tp + fn == 0:\n            sensitivity[i] = 0\n        else:\n            sensitivity[i] = tp / (tp + fn)\n        \n        if tn + fp == 0:\n            specificity[i] = 1\n        else:\n            specificity[i] = tn / (tn + fp)\n        \n        class_accuracy[i] = (sensitivity[i] + specificity[i]) / 2\n    \n    # Return the mean of the class accuracies as the balanced accuracy\n    return np.mean(class_accuracy)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.50950119090352}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    unique_classes = np.unique(np.concatenate((y_true, y_pred)))\n    class_accuracies = []\n    for c in unique_classes:\n        y_true_c = (y_true == c).astype(int)\n        y_pred_c = (y_pred == c).astype(int)\n        tp = np.sum((y_true_c == 1) & (y_pred_c == 1))\n        fp = np.sum((y_true_c == 0) & (y_pred_c == 1))\n        fn = np.sum((y_true_c == 1) & (y_pred_c == 0))\n        tn = np.sum((y_true_c == 0) & (y_pred_c == 0))\n        sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 1\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n    return np.mean(class_accuracies)\n\n\n", "CodeBleu_score": 23.022316531722932}]}
{"instance_id": "19a9ad39de0a", "generation_result": [{"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr', dtype=np.float64)\n    n_nonzero = X.indptr[1:] - X.indptr[:-1]\n    n_zero = X.shape[1] - n_nonzero\n    return np.hstack([n_nonzero[:, np.newaxis], n_zero[:, np.newaxis], X])\n\n\n", "CodeBleu_score": 15.088435717583861}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    n_samples, n_features = X.shape\n    n_nonzero = X.nnz / n_samples\n    n_zero = n_features - X.nnz / n_samples\n    X_new = np.hstack((n_nonzero.reshape((n_samples, 1)), n_zero.reshape((n_samples, 1)), X))\n    return X_new\n\n\n", "CodeBleu_score": 18.07133591380507}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    n_samples, n_features = X.shape\n    n_nonzero_per_row = X.sum(axis=1)\n    n_zero_per_row = n_features - n_nonzero_per_row\n    return np.hstack((n_nonzero_per_row.reshape(-1, 1), n_zero_per_row.reshape(-1, 1), X))\n\n\n", "CodeBleu_score": 18.61347835151542}]}
{"instance_id": "5e8db0b5d447", "generation_result": [{"code": "def _init_pretest(self, features, target)\n\t\n    self.n_classes = len(np.unique(target))\n    if self.n_classes > len(features):\n        raise ValueError(\"The number of unique target classes is greater than the number of examples.\")\n    self.pretest_X, self.pretest_y = train_test_split(features, target, random_state=self.random_state, stratify=target)\n    if len(np.unique(self.pretest_y)) < self.n_classes:\n        unique_targets = np.unique(target)\n        for target_value in unique_targets:\n            if target_value not in self.pretest_y:\n                self.pretest_y = np.append(self.pretest_y, target_value)\n                self.pretest_X = np.vstack((self.pretest_X, features[target == target_value][0]))\n\n", "CodeBleu_score": 32.89197280736135}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.classes_ = np.unique(target)\n    if len(self.classes_) < self.n_splits:\n        raise ValueError(\n            \"Number of classes must be greater than or equal to n_splits\")\n    if len(target) < len(self.classes_):\n        raise ValueError(\n            \"Number of examples must be greater than or equal to number of classes\"\n        )\n    self.pretest_X, self.pretest_y = train_test_split(\n        features, target, random_state=self.random_state, stratify=target)\n    if len(self.pretest_y) < len(self.classes_):\n        self.pretest_y = target[self.pretest_y.index]\n\n", "CodeBleu_score": 28.505251950462757}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.n_classes = len(np.unique(target))\n    self.train_size = max(self.n_classes, self.train_size)\n    pretest_X, pretest_y = train_test_split(features, target, train_size=self.train_size, random_state=self.random_state)\n    if len(np.unique(pretest_y)) < self.n_classes:\n        unique_target = np.unique(pretest_y)\n        for i in range(self.n_classes):\n            if i not in unique_target:\n                pretest_y = np.append(pretest_y, i)\n    return pretest_X, pretest_y", "CodeBleu_score": 26.921388765207944}]}
{"instance_id": "5e3d48667396", "generation_result": [{"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, type):\n        if dtype == np.bool_:\n            return np.bool_\n        elif dtype == np.int32:\n            return np.int32\n        elif dtype == np.int64:\n            return np.int64\n        elif dtype == np.float32:\n            return np.float32\n        elif dtype == np.float64:\n            return np.float64\n        else:\n            raise ValueError(\"Unknown data type: {}\".format(dtype))\n    elif isinstance(dtype, str):\n        if dtype == \"bool\":\n            return np.bool_\n        elif dtype == \"int32\":\n            return np.int32\n        elif dtype == \"int64\":\n            return np.int64\n        elif dtype == \"float32\":\n            return np.float32\n        elif dtype == \"float64\":\n            return np.float64\n        else:\n            raise ValueError(\"Unknown data type: {}\".format(dtype))\n    else:\n        raise ValueError(\"Unknown data type: {}\".format(dtype))\n\n\n\n", "CodeBleu_score": 40.58046088586743}, {"code": "def _to_numpy_type(dtype)\n\t\n    if dtype == 'float32':\n        return np.float32\n    elif dtype == 'float64':\n        return np.float64\n    elif dtype == 'int32':\n        return np.int32\n    elif dtype == 'int64':\n        return np.int64\n    elif dtype == 'bool':\n        return np.bool\n    elif dtype == 'uint8':\n        return np.uint8\n    elif dtype == 'int8':\n        return np.int8\n    elif dtype == 'uint16':\n        return np.uint16\n    elif dtype == 'int16':\n        return np.int16\n    elif dtype == 'uint32':\n        return np.uint32\n    elif dtype == 'int32':\n        return np.int32\n    elif dtype == 'uint64':\n        return np.uint64\n    elif dtype == 'int64':\n        return np.int64\n    elif dtype == 'string':\n        return np.str\n    elif dtype == 'complex64':\n        return np.complex64\n    elif dtype == 'complex128':\n        return np.complex128\n    elif dtype == 'resource':\n        return np.resource\n    elif dtype == 'variant':\n        return np.variant\n    elif dtype == 'bfloat16':\n        return np.bfloat16\n    elif dtype == 'float16':\n        return np.float16\n    elif dtype == 'float8':\n        return np.float8\n    elif dtype == 'float128':\n        return np.float128\n    elif dtype == 'float256':\n        return np.float256\n    elif dtype == 'float512':\n        return np.float512\n    elif dtype == 'float1024':\n        return np.float1024\n    elif dtype == 'float2048':\n        return np.float2048\n    elif dtype == 'float4096':\n        return np.float4", "CodeBleu_score": 35.315081242177314}, {"code": "def _to_numpy_type(dtype)\n\t\n    if dtype == 'float32':\n        return np.float32\n    elif dtype == 'float64':\n        return np.float64\n    elif dtype == 'int32':\n        return np.int32\n    elif dtype == 'int64':\n        return np.int64\n    elif dtype == 'bool':\n        return np.bool\n    elif dtype == 'string':\n        return np.string_\n    elif dtype == 'complex64':\n        return np.complex64\n    elif dtype == 'complex128':\n        return np.complex128\n    else:\n        raise ValueError('Unknown data type: {}'.format(dtype))\n\n", "CodeBleu_score": 38.78276881632629}]}
{"instance_id": "8f1120fdd463", "generation_result": [{"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size is None:\n            return np.concatenate(list(ds), axis=0)\n        else:\n            return np.concatenate([_to_numpy(x) for x in ds.batch(batch_size)], axis=0)\n    except AttributeError:\n        return np.concatenate(list(iter(ds)), axis=0)\n\n", "CodeBleu_score": 14.817704624146355}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    if batch_size is None:\n        return np.concatenate(list(ds), axis=0)\n    try:\n        return np.concatenate(list(ds.batch(batch_size)), axis=0)\n    except AttributeError:\n        return np.concatenate([_to_numpy(x) for x in ds], axis=0)\n\n", "CodeBleu_score": 13.970787381014931}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    if batch_size is None:\n        return _to_numpy(ds)\n    try:\n        return np.concatenate([_to_numpy(x) for x in ds.batch(batch_size)])\n    except AttributeError:\n        return _to_numpy(ds)\n\n", "CodeBleu_score": 13.265059521038799}]}
{"instance_id": "282271955871", "generation_result": [{"code": "def get_prng(seed)\n\t\n    seed = jnp.asarray(seed)\n    seed = jnp.asarray(seed, dtype=jnp.uint32)\n    seed = jnp.reshape(seed, ())\n    seed = jnp.uint32(seed)\n    key = jax.random.PRNGKey(seed)\n    return key\n\n\n", "CodeBleu_score": 17.951111504922363}, {"code": "def get_prng(seed)\n\t\n    seed = jnp.asarray(seed, jnp.int32)\n    if seed.ndim != 0:\n        raise ValueError(f\"seed must be a scalar, got {seed.shape}\")\n    return jax.random.PRNGKey(seed)\n\n\n", "CodeBleu_score": 15.289245795765938}, {"code": "def get_prng(seed)\n\t\n    seed = jnp.array(seed)\n    seed = jnp.atleast_1d(seed)\n    seed = jnp.atleast_1d(seed[0])\n    seed = jnp.atleast_1d(seed[0])\n    key = jax.random.PRNGKey(seed)\n    return key\n\n\n", "CodeBleu_score": 10.415307904922138}]}
{"instance_id": "42234dccce9a", "generation_result": [{"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s, pd.DatetimeTZDtype):\n        return s.tz_convert(dtype.tz)\n    elif s.dtype == \"datetime64[ns]\":\n        return s.tz_localize(dtype.tz)\n    elif s.dtype.kind == \"i\":\n        return s.astype(\"datetime64[ns]\").tz_localize(dtype.tz)\n    else:\n        return pd.to_datetime(s, utc=True).tz_localize(dtype.tz)\n", "CodeBleu_score": 52.99497876716948}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_convert(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.tz_localize(dtype.tz)\n    elif isinstance(s.d", "CodeBleu_score": 39.020199191245794}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.tz)\n    elif isinstance(s.dtype, pd.Datetime64Dtype):\n        return s.dt.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, (pd.Int64Dtype, pd.Float64Dtype, pd.UInt64Dtype)):\n        return pd.to_datetime(s, utc=True).dt.tz_localize(dtype.tz)\n    else:\n        return pd.to_datetime(s, utc=True).dt.tz_localize(None).dt.tz_localize(dtype.tz)\n\n", "CodeBleu_score": 65.0353102025889}]}
{"instance_id": "9cee7388879b", "generation_result": [{"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if not arg.tz:\n        arg = arg.tz_localize(tz=\"UTC\")\n    if not lower_bound.tz:\n        lower_bound = lower_bound.tz_localize(tz=\"UTC\")\n    if not upper_bound.tz:\n        upper_bound = upper_bound.tz_localize(tz=\"UTC\")\n    if lower_bound > upper_bound:\n        raise ValueError(\"Lower bound must be less than or equal to upper bound.\")\n    indexer = (arg >= lower_bound) & (arg <= upper_bound)\n    return indexer.to_dask_array().to_dask_dataframe()", "CodeBleu_score": 27.554750522190176}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if lower_bound is None:\n        lower_bound = arg.min()\n    if upper_bound is None:\n        upper_bound = arg.max()\n    if lower_bound is None:\n        raise ValueError(\"Lower bound is None\")\n    if upper_bound is None:\n        raise ValueError(\"Upper bound is None\")\n    if lower_bound > upper_bound:\n        raise ValueError(\"Lower bound is greater than upper bound\")\n    if lower_bound == upper_bound:\n        raise ValueError(\"Lower bound is equal to upper bound\")\n    if lower_bound > arg.max():\n        raise ValueError(\"Lower bound is greater than the maximum value\")\n    if upper_bound < arg.min():\n        raise ValueError(\"Upper bound is less than the minimum value\")\n    if lower_bound < arg.min():\n        raise ValueError(\"Lower bound is less than the minimum value\")\n    if upper_bound > arg.max():\n        raise ValueError(\"Upper bound is greater than the maximum value\")\n    if lower_bound == arg.min() and upper_bound == arg.max():\n        return cls(True)\n    if lower_bound == arg.min():\n        return cls(arg <= upper_bound)\n    if upper_bound == arg.max():\n        return cls(arg >= lower_bound)\n    return cls((arg >= lower_bound) & (arg <= upper_bound))\n\n\n", "CodeBleu_score": 19.833142226176175}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.tz is not None:\n        arg = arg.tz_convert(None)\n    if lower_bound.tz is not None:\n        lower_bound = lower_bound.tz_convert(None)\n    if upper_bound.tz is not None:\n        upper_bound = upper_bound.tz_convert(None)\n    return arg.between_time(lower_bound, upper_bound)\n\n\n", "CodeBleu_score": 21.454621199850433}]}
{"instance_id": "0ab1cc8ccf71", "generation_result": [{"code": "def asseries(cls, value, like=None)\n\t\n    import dask.array as da\n    import dask.dataframe as dd\n    import numpy as np\n    import pandas as pd\n    if isinstance(value, dd.Series):\n        return value\n    elif isinstance(value, da.Array):\n        return dd.from_array(value)\n    elif isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    elif isinstance(value, (tuple, list, dict)):\n        if like is None:\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, dd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, pd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, da.Array):\n            return dd.from_array(da.from_array(value, chunks=like.chunksize))\n        elif isinstance(like, dd.DataFrame):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, pd.DataFrame):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, da.Array):\n            return dd.from_array(da.from_array(value, chunks=like.chunksize))\n        elif isinstance(like, dd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, pd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, da.Array):\n            return dd.from_array(da.from_array(value, chunks=", "CodeBleu_score": 34.87875278823236}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    elif isinstance(value, dd.Scalar):\n        return dd.from_array(value.to_array())\n    elif isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    elif like is not None:\n        if isinstance(like, dd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, dd.DataFrame):\n            return dd.from_pandas(pd.Series(value), npartitions=like.npartitions)\n        elif isinstance(like, pd.Series):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, pd.DataFrame):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, tuple):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, list):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        elif isinstance(like, dict):\n            return dd.from_pandas(pd.Series(value), npartitions=1)\n        else:\n            raise ValueError(\"Unsupported type for 'like' argument: {}\".format(type(like)))\n    else:\n        return dd.from_pandas(pd.Series(value), npartitions=1)\n\n\n", "CodeBleu_score": 35.69082930400469}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, cls.dask_type):\n        return value\n    elif isinstance(value, cls.pandas_type):\n        return cls.from_pandas(value, npartitions=1)\n    elif isinstance(value, (tuple, list, dict)):\n        return cls.from_like(value, like=like)\n    else:\n        return cls.from_scalar(value, npartitions=1)\n\n", "CodeBleu_score": 21.444692728979096}]}
{"instance_id": "926220a06a0c", "generation_result": [{"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k} got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 88.02424710383727}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k} got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 88.02424710383727}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k} got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 88.02424710383727}]}
{"instance_id": "95afc38c9125", "generation_result": [{"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} could not be found in module {library_name}\")\n    if len(classes[estimator_name]) > 1:\n        logging.debug(f\"Found multiple estimators matching {estimator_name}: {list(classes[estimator_name].keys())}\")\n        logging.warning(f\"Multiple estimators matching {estimator_name} found, using first one: {list(classes[estimator_name].keys())[0]}\")\n    selected_estimator = list(classes[estimator_name].values())[0]\n    if not issubclass(selected_estimator, BaseEstimator):\n        logging.info(f\"{selected_estimator} is not a subclass of sklearn.BaseEstimator, using as is\")\n    return selected_estimator", "CodeBleu_score": 43.43477391881616}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f'Estimator {estimator_name} not found in module {library_name}')\n    if len(classes[estimator_name]) > 1:\n        logging.debug(f'Multiple classes found for estimator {estimator_name}: {classes[estimator_name]}')\n        logging.warning(f'Multiple classes found for estimator {estimator_name}. Using the first one.')\n    estimator_class = classes[estimator_name][0]\n    if not issubclass(estimator_class, BaseEstimator):\n        logging.info(f'Estimator {estimator_name} is not a subclass of BaseEstimator')\n    return estimator_class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.72905112892914}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    from sklearn.base import BaseEstimator\n    from sklearn.utils import get_module_members\n    from logging import getLogger, DEBUG, WARNING\n    from typing import Any\n    logger = getLogger(__name__)\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} could not be found in {library_name}\")\n    if len(classes[estimator_name]) > 1:\n        logger.debug(f\"Multiple classes found for {estimator_name}: {classes[estimator_name]}\")\n        logger.warning(f\"Multiple classes found for {estimator_name}. Using the first one.\")\n    estimator_class = classes[estimator_name][0]\n    if not issubclass(estimator_class, BaseEstimator):\n        logger.info(f\"{estimator_class} is not a subclass of sklearn.base.BaseEstimator\")\n    return estimator_class\n\n\n", "CodeBleu_score": 50.27125454734974}]}
{"instance_id": "9562a9cc043b", "generation_result": [{"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    # Define the mapping of estimator names to tasks\n    task_mapping = {\n        \"LinearRegression\": \"regression\",\n        \"RandomForestRegressor\": \"regression\",\n        \"GradientBoostingRegressor\": \"regression\",\n        \"KNeighborsRegressor\": \"regression\",\n        \"XGBRegressor\": \"regression\",\n        \"LGBMRegressor\": \"regression\",\n        \"CatBoostRegressor\": \"regression\",\n        \"LinearSVR\": \"regression\",\n        \"SVR\": \"regression\",\n        \"RandomForestClassifier\": \"classification\",\n        \"GradientBoostingClassifier\": \"classification\",\n        \"KNeighborsClassifier\": \"classification\",\n        \"XGBClassifier\": \"classification\",\n        \"LGBMClassifier\": \"classification\",\n        \"CatBoostClassifier\": \"classification\",\n        \"LogisticRegression\": \"classification\",\n        \"SGDClassifier\": \"classification\",\n        \"DecisionTreeClassifier\": \"classification\",\n        \"ExtraTreesClassifier\": \"classification\",\n        \"RandomForestRegressor\": \"regression\",\n        \"GradientBoostingRegressor\": \"regression\",\n        \"KNeighborsRegressor\": \"regression\",\n        \"XGBRegressor\": \"regression\",\n        \"LGBMRegressor\": \"regression\",\n        \"CatBoostRegressor\": \"regression\",\n        \"LinearSVR\": \"regression\",\n        \"SVR\": \"regression\",\n        \"RandomForestClassifier\": \"classification\",\n        \"GradientBoostingClassifier\": \"classification\",\n        \"KNeighborsClassifier\": \"classification\",\n        \"XGBClassifier\": \"classification\",\n        \"LGBMClassifier\": \"classification\",\n        \"CatBoostClassifier\": \"classification\",\n        \"LogisticRegression\": \"classification\",\n        \"SGDClassifier\": \"classification\",\n        \"DecisionTreeClassifier\": \"classification\",\n        \"ExtraTreesClassifier\": \"classification\",\n    }\n\n", "CodeBleu_score": 6.203937897779713}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    import json\n    with open('estimator_to_task.json', 'r') as f:\n        mapping = json.load(f)\n    for task, estimators in mapping.items():\n        if estimator_name in estimators:\n            return task\n    return \"unknown\"\n\n\n\n\n\n", "CodeBleu_score": 34.100026326011374}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    import json\n    import os\n    import pathlib\n    import sys\n\n    def get_json_data(file_path):\n        \"\"\"Reads a JSON file and returns its data as a dictionary.\"\"\"\n        with open(file_path, 'r') as file:\n            data = json.load(file)\n        return data\n\n    def get_mapping_file_path(file_name):\n        \"\"\"Returns the path to the mapping file with the given file name.\"\"\"\n        current_dir = pathlib.Path(__file__).parent.resolve()\n        mapping_file_path = os.path.join(current_dir, file_name)\n        return mapping_file_path\n\n    def get_task_from_mapping(mapping, estimator_name):\n        \"\"\"Returns the task corresponding to the estimator name from the mapping.\"\"\"\n        for task, estimators in mapping.items():\n            if estimator_name in estimators:\n                return task\n        return \"unknown\"\n\n    mapping_file_name = 'estimator_to_task_mapping.json'\n    mapping_file_path = get_mapping_file_path(mapping_file_name)\n    mapping = get_json_data(mapping_file_path)\n    task = get_task_from_mapping(mapping, estimator_name)\n    return task\n\n\n\n\n\n", "CodeBleu_score": 38.11401222442778}]}
{"instance_id": "2f50195d043a", "generation_result": [{"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_files = get_filenames_by_prefix(data_cache, data_name)\n    data = {}\n    for file in data_files:\n        if file.endswith(\".json\"):\n            continue\n        component, extension = file.split(\".\")\n        data[component] = load_data_file(\n            os.path.join(data_cache, file), extension\n        )\n    return data\n\n", "CodeBleu_score": 45.90983426808101}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_files = get_filenames_by_prefix(data_cache, data_name)\n    data = {}\n    for file in data_files:\n        if file.endswith(\".json\"):\n            continue\n        component, extension = file.split(\".\")\n        data[component] = load_data_file(os.path.join(data_cache, file), extension)\n    return data\n\n", "CodeBleu_score": 42.56566021694967}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data = {}\n    for filename in get_filenames_by_prefix(data_cache, data_name):\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.split(\".\")\n        data[component] = load_data_file(\n            os.path.join(data_cache, filename), extension\n        )\n    return data\n\n", "CodeBleu_score": 41.41525440316013}]}
{"instance_id": "e0281206029e", "generation_result": [{"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n    import time\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        assert response.status_code == 200\n        total_size = int(response.headers.get('content-length', 0))\n        block_size = 1024\n        written = 0\n        with open(filename, 'wb') as file:\n            for data in response.iter_content(block_size):\n                written += len(data)\n                file.write(data)\n                print(f\"\\r{written / total_size * 100:.1f}%\", end=\"\")\n                time.sleep(0.1)\n        print()\n    else:\n        raise NotImplementedError(f\"Cannot handle {url}\")\n    assert total_size == written\n\n\n", "CodeBleu_score": 55.15759127438501}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        assert response.status_code == 200, f\"Download failed with status code {response.status_code}\"\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written_size = 0\n        with open(filename, \"wb\") as file:\n            for data in response.iter_content(block_size):\n                written_size += len(data)\n                file.write(data)\n        assert written_size == total_size, f\"Downloaded {written_size} bytes, expected {total_size} bytes\"\n    else:\n        raise NotImplementedError(f\"URL scheme {url.split(':')[0]} not supported\")\n\n\n", "CodeBleu_score": 57.50021540183913}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n    if os.path.isfile(filename):\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        assert response.status_code == 200\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written_size = 0\n        with open(filename, \"wb\") as f:\n            for data in response.iter_content(block_size):\n                f.write(data)\n                written_size += len(data)\n                print(\"\\rDownloading {}: {:.2f}%\".format(filename, written_size / total_size * 100), end=\"\")\n        print()\n        assert total_size == written_size\n    else:\n        raise AssertionError(\"Invalid URL: {}\".format(url))\n\n", "CodeBleu_score": 59.643179756084564}]}
{"instance_id": "a69a71cc2fe8", "generation_result": [{"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    # Load the dataset\n    (x_train, y_train), (x_test, y_test) = tf.keras.datasets.covtype.load_data()\n\n    # Adjust the labels to be zero-indexed\n    y_train = y_train - 1\n    y_test = y_test - 1\n\n    # Convert the labels to binary based on a parameter\n    if dataset_params[\"binary\"]:\n        y_train = (y_train > 0).astype(int)\n        y_test = (y_test > 0).astype(int)\n\n    # Create a description dictionary\n    description = {\n        \"num_classes\": int(np.max(y_train) + 1),\n        \"default_split\": {\"train\": 0.8, \"valid\": 0.1, \"test\": 0.1},\n    }\n\n    # Return the dataset and its description\n    return {\n        \"x_train\": x_train,\n        \"y_train\": y_train,\n        \"x_test\": x_test,\n        \"y_test\": y_test,\n    }, description\n\n\n\n\n", "CodeBleu_score": 40.74704647764371}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    dataset = load_dataset(data_name, data_cache, raw_data_cache)\n    dataset[\"train\"] = dataset[\"train\"].rename_column(\"label\", \"labels\")\n    dataset[\"test\"] = dataset[\"test\"].rename_column(\"label\", \"labels\")\n    dataset[\"validation\"] = dataset[\"validation\"].rename_column(\"label\", \"labels\")\n    dataset[\"train\"][\"labels\"] = dataset[\"train\"][\"labels\"] - 1\n    dataset[\"test\"][\"labels\"] = dataset[\"test\"][\"labels\"] - 1\n    dataset[\"validation\"][\"labels\"] = dataset[\"validation\"][\"labels\"] - 1\n\n    if dataset_params[\"binary_labels\"]:\n        dataset[\"train\"][\"labels\"] = dataset[\"train\"][\"labels\"] % 2\n        dataset[\"test\"][\"labels\"] = dataset[\"test\"][\"labels\"] % 2\n        dataset[\"validation\"][\"labels\"] = dataset[\"validation\"][\"labels\"] % 2\n\n    description = {\n        \"name\": \"Covertype\",\n        \"num_classes\": 7,\n        \"default_split\": \"train\",\n        \"multilabel\": False,\n    }\n\n    return dataset, description\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.29441899785783}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n\n    data_path = os.path.join(raw_data_cache, \"covtype.data\")\n    data = pd.read_csv(data_path, header=None)\n    data.columns = [\n        \"Elevation\",\n        \"Aspect\",\n        \"Slope\",\n        \"Horizontal_Distance_To_Hydrology\",\n        \"Vertical_Distance_To_Hydrology\",\n        \"Horizontal_Distance_To_Roadways\",\n        \"Hillshade_9am\",\n        \"Hillshade_Noon\",\n        \"Hillshade_3pm\",\n        \"Horizontal_Distance_To_Fire_Points\",\n        \"Wilderness_Area1\",\n        \"Wilderness_Area2\",\n        \"Wilderness_Area3\",\n        \"Wilderness_Area4\",\n        \"Soil_Type1\",\n        \"Soil_Type2\",\n        \"Soil_Type3\",\n        \"Soil_Type4\",\n        \"Soil_Type5\",\n        \"Soil_Type6\",\n        \"Soil_Type7\",\n        \"Soil_Type8\",\n        \"Soil_Type9\",\n        \"Soil_Type10\",\n        \"Soil_Type11\",\n        \"Soil_Type12\",\n        \"Soil_Type13\",\n        \"Soil_Type14\",\n        \"Soil_Type15\",\n        \"Soil_Type16\",\n        \"Soil_Type17\",\n        \"Soil_Type18\",\n        \"Soil_Type19\",\n        \"Soil_Type20\",\n        \"Soil_Type21\",\n        \"Soil_Type22\",\n        \"Soil_Type23\",\n        \"Soil_Type24\",\n        \"Soil_Type25\",\n        \"Soil_Type26\",\n        \"Soil_Type27\",\n        \"Soil_Type28\",\n        \"Soil_Type29\",\n        \"Soil_Type30\",\n        \"Soil_Type31\",\n        \"Soil_Type32\",\n        \"So", "CodeBleu_score": 16.90346231486934}]}
{"instance_id": "129cbd2529ef", "generation_result": [{"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}]}
{"instance_id": "2d38c2c60b59", "generation_result": [{"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    return ivy.logit(x, eps=eps, complex_mode=complex_mode, out=out)", "CodeBleu_score": 17.014450717675988}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    return current_backend(x).logit(x, eps=eps, complex_mode=complex_mode, out=out)\n\n", "CodeBleu_score": 17.472183660571833}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    return current_backend(x).logit(x, eps=eps, complex_mode=complex_mode, out=out)\n\n", "CodeBleu_score": 17.472183660571833}]}
{"instance_id": "205e296f8621", "generation_result": [{"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) < lambd, 0, x)\n\n\n", "CodeBleu_score": 22.980222295228085}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) <= lambd, 0, x)\n\n", "CodeBleu_score": 23.021761690299734}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    ret = np.copy(x)\n    if lambd > 0:\n        ret[x > lambd] -= lambd\n        ret[x < -lambd] += lambd\n    else:\n        ret[x > lambd] -= lambd\n        ret[x < lambd] += lambd\n    if out is None:\n        return ret\n    out[:] = ret\n    return out\n\n", "CodeBleu_score": 32.13083987930945}]}
{"instance_id": "5b133f6ebe2d", "generation_result": [{"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if window_length < 1:\n        raise ValueError(\"window_length must be at least 1.\")\n    if not isinstance(window_length, int):\n        raise TypeError(\"window_length must be an integer.\")\n    if not isinstance(dtype, np.dtype):\n        raise TypeError(\"dtype must be a numpy dtype.\")\n    if out is not None and not isinstance(out, np.ndarray):\n        raise TypeError(\"out must be a numpy array.\")\n    if out is not None and out.shape != (window_length,):\n        raise ValueError(\"out must have the same shape as window_length.\")\n    if out is not None and out.dtype != dtype:\n        raise ValueError(\"out must have the same dtype as dtype.\")\n    if out is not None:\n        return np.array(\n            [\n                np.sin(\n                    (\n                        np.pi\n                        / 2\n                        * (\n                            (i + 1)\n                            - (window_length / 2)\n                            + (window_length / 2) * np.sin(2 * np.pi * i / (window_length - 1))\n                        )\n                    )\n                )\n                for i in range(window_length)\n            ],\n            dtype=dtype,\n            out=out,\n        )\n    else:\n        return np.array(\n            [\n                np.sin(\n                    (\n                        np.pi\n                        / 2\n                        * (\n                            (i + 1)\n                            - (window_length / 2)\n                            + (window_length / 2) * np.sin(2 * np.pi * i / (window_length - 1))\n                        )\n                    )\n                )\n                for i in range(window_length)\n            ],\n            dtype=dtype,\n        )", "CodeBleu_score": 30.569544315375826}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if window_length < 1:\n        raise ValueError(\"Window length must be at least 1.\")\n    if out is not None and out.shape != (window_length,):\n        raise ValueError(\"Output array has incorrect shape.\")\n    if dtype not in (np.float32, np.float64):\n        raise ValueError(\"Only float32 and float64 dtypes are supported.\")\n\n    if out is None:\n        out = np.empty(window_length, dtype=dtype)\n\n    n = np.arange(window_length)\n    out[:] = (1 - np.cos(2 * np.pi * n / (window_length - 1))) / 2\n    return out\n\n\n\n", "CodeBleu_score": 31.984624878946548}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is not None:\n        if out.shape[0] != window_length:\n            raise ValueError(\"out must have the same shape as window_length\")\n        if out.dtype != dtype:\n            raise ValueError(\"out must have the same dtype as dtype\")\n        out = out.ravel()\n    else:\n        out = np.empty(window_length, dtype=dtype)\n    out[0] = 0.0\n    if window_length == 1:\n        return out\n    out[1] = 1.0\n    if window_length == 2:\n        return out\n    out[2] = 1.0\n    if window_length == 3:\n        return out\n    out[3] = 1.0\n    if window_length == 4:\n        return out\n    out[4] = 1.0\n    if window_length == 5:\n        return out\n    out[5] = 1.0\n    if window_length == 6:\n        return out\n    out[6] = 1.0\n    if window_length == 7:\n        return out\n    out[7] = 1.0\n    if window_length == 8:\n        return out\n    out[8] = 1.0\n    if window_length == 9:\n        return out\n    out[9] = 1.0\n    if window_length == 10:\n        return out\n    out[10] = 1.0\n    if window_length == 11:\n        return out\n    out[11] = 1.0\n    if window_length == 12:\n        return out\n    out[12] = 1.0\n    if window_length == 13:\n        return out\n    out[13] = 1.0\n    if window_length == 14:\n        return out\n    out[14] = 1.0\n    if window_length == 15:\n        return out\n    out[15] = 1.0\n    if window_length == 16:\n        return out\n    out[16] = 1.0\n    if window_length == 17:\n        return out\n    out[17", "CodeBleu_score": 25.183786534433693}]}
{"instance_id": "473296f771a9", "generation_result": [{"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.polyval(coeffs, x)\n\n", "CodeBleu_score": 13.70552496491311}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.polyval(coeffs, x)", "CodeBleu_score": 13.70552496491311}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    return np.polyval(coeffs, x)", "CodeBleu_score": 13.70552496491311}]}
{"instance_id": "b8455221cb2a", "generation_result": [{"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.amax(x, axis=axis, keepdims=keepdims, out=out)", "CodeBleu_score": 26.902649231113717}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret", "CodeBleu_score": 78.35765070891931}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret\n\n", "CodeBleu_score": 78.35765070891931}]}
{"instance_id": "f72489f434a3", "generation_result": [{"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = _promote_args_dispatcher(x1, x2)\n    return np.copysign(x1, x2, out=out)\n\n\n", "CodeBleu_score": 29.014887254911702}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2, out = promote_types_of_inputs(x1, x2, out)\n    return np.copysign(x1, x2, out=out)\n\n\n", "CodeBleu_score": 29.074290037643046}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2, out = promote_types_of_inputs(x1, x2, out)\n    return np.copysign(x1, x2, out=out)\n\n\n", "CodeBleu_score": 29.074290037643046}]}
{"instance_id": "55c0d77e4dc2", "generation_result": [{"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    a = np.asarray(a)\n    if axis is None:\n        axis = tuple(range(a.ndim))\n    if isinstance(axis, int):\n        axis = (axis,)\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    if not isinstance(axis, tuple):\n        raise TypeError(f\"axis must be a tuple, got {type(axis)}\")\n    if not all(isinstance(ax, int) for ax in axis):\n        raise TypeError(f\"axis must be a tuple of integers, got {type(axis)}\")\n    if not all(ax < a.ndim for ax in axis):\n        raise ValueError(f\"axis must be less than the number of dimensions\")\n    if not all(ax >= -a.ndim for ax in axis):\n        raise ValueError(f\"axis must be greater than or equal to -{a.ndim}\")\n    if not all(ax >= 0 for ax in axis):\n        raise ValueError(f\"axis must be greater than or equal to 0\")\n    if not all(ax < a.ndim for ax in axis):\n        raise ValueError(f\"axis must be less than the number of dimensions\")\n    if not all(ax >= 0 for ax in axis):\n        raise ValueError(f\"axis must be greater than or equal to 0\")\n    if not all(ax < a.ndim for ax in axis):\n        raise ValueError(f\"axis must be less than the number of dimensions\")\n    if not all(ax >= 0 for ax in axis):\n        raise ValueError(f\"axis must be greater than or equal to 0\")\n    if not all(ax < a.ndim for ax in axis):\n        raise ValueError(f\"axis must be less than the number of dimensions\")\n    if not all(ax >= 0 for ax in axis):\n        raise ValueError(f\"axis must be greater than or equal to 0\")\n    if not all(ax < a.ndim for ax in axis):\n        raise ValueError(f\"axis must be less than the number of dimensions\")\n    if not all(ax >= 0 for ax in axis):\n        raise ValueError(f\"axis must", "CodeBleu_score": 49.65997636614663}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)", "CodeBleu_score": 33.64802727171017}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if isinstance(axis, list):\n        axis = tuple(axis)\n    if dtype is None:\n        dtype = np.int64\n    res = np.count_nonzero(a, axis=axis, keepdims=keepdims)\n    if np.isscalar(res):\n        res = np.array(res, dtype=dtype)\n    return res", "CodeBleu_score": 77.39694747227666}]}
{"instance_id": "784bf7d24fc2", "generation_result": [{"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}]}
{"instance_id": "efa0a51af6bc", "generation_result": [{"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x = np.asarray(x)\n    y = np.asarray(y)\n    dtype = promote_types_of_inputs(x.dtype, y.dtype)\n    x = x.astype(dtype, copy=False)\n    y = y.astype(dtype, copy=False)\n    if out is None:\n        return np.where(x == 0.0, 0.0, x * np.log(y))\n    else:\n        np.copyto(out, np.where(x == 0.0, 0.0, x * np.log(y)))\n        return out\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.836396553063786}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return _cur_framework(xlogy, locals()).xlogy(x=x, y=y, out=out)\n\n", "CodeBleu_score": 29.905398765325874}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.xlogy(x, y, out=out)\n\n", "CodeBleu_score": 29.11541612017427}]}
{"instance_id": "ac1645284260", "generation_result": [{"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    x_shape = x.shape\n    if len(x_shape) != dims + 2:\n        raise ValueError(\n            f\"Expected input tensor of rank {dims + 2}, but received input tensor with rank {len(x_shape)}\"\n        )\n    kernel, strides, depth_pooling = _determine_depth_max_pooling_helper(\n        x_shape, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = tf.transpose(x, [0, 3, 1, 2])\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 45.89547424743961}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(\n        x.shape, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = tf.transpose(x, [0, 1, 3, 2, 4])\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 51.86966460676109}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _determine_depth_max_pooling_helper(\n        x.shape, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = tf.transpose(x, [0, 1, 3, 2])\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 41.53365869729523}]}
{"instance_id": "18ff0a4f7550", "generation_result": [{"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if data_format == \"NWC\":\n        if training:\n            if x.ndim == 2:\n                x = x[:, :, None]\n            elif x.ndim == 3:\n                pass\n            else:\n                raise ValueError(\n                    f\"Expected input with 2 or 3 dimensions, but got {x.ndim} dimensions.\"\n                )\n            mask = np.random.binomial(1, prob, x.shape).astype(x.dtype)\n            out = x * mask * (1 / (1 - prob))\n            if x.ndim == 2:\n                out = out[:, :, 0]\n        else:\n            out = x\n    elif data_format == \"NCW\":\n        if training:\n            if x.ndim == 2:\n                x = x[None, :, :]\n            elif x.ndim == 3:\n                pass\n            else:\n                raise ValueError(\n                    f\"Expected input with 2 or 3 dimensions, but got {x.ndim} dimensions.\"\n                )\n            mask = np.random.binomial(1, prob, x.shape).astype(x.dtype)\n            out = x * mask * (1 / (1 - prob))\n            if x.ndim == 2:\n                out = out[0, :, :]\n        else:\n            out = x\n    else:\n        raise ValueError(f\"Unsupported data format: {data_format}\")\n    return out\n\n", "CodeBleu_score": 36.64882561723991}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    ...\n\n", "CodeBleu_score": 13.144132653061224}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not training:\n        return x\n    if data_format == \"NWC\":\n        x = x.transpose(0, 2, 1)\n    mask = np.random.binomial(1, prob, x.shape).astype(x.dtype)\n    if prob > 0.0:\n        x = x * mask * (1.0 / (1.0 - prob))\n    if data_format == \"NWC\":\n        x = x.transpose(0, 2, 1)\n    return x\n\n", "CodeBleu_score": 35.359509162731506}]}
{"instance_id": "0ce45eb7cbd9", "generation_result": [{"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n\n\n", "CodeBleu_score": 14.79044834307992}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return current_backend(x).top_k(\n        x, k=k, axis=axis, largest=largest, sorted=sorted, out=out\n    )\n\n", "CodeBleu_score": 17.32595419961292}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return current_backend(x).top_k(x, k=k, axis=axis, largest=largest, sorted=sorted, out=out)", "CodeBleu_score": 16.96209434462725}]}
{"instance_id": "1424f9541998", "generation_result": [{"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.linalg.norm(x, ord=1, axis=axis, keepdims=True)\n\n", "CodeBleu_score": 16.264011900405766}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.linalg.norm(x, ord=1, axis=axis, keepdims=True)\n\n", "CodeBleu_score": 16.264011900405766}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.linalg.norm(x, ord=1, axis=axis, keepdims=True)\n\n\n", "CodeBleu_score": 16.264011900405766}]}
{"instance_id": "4c3a386a1f05", "generation_result": [{"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}]}
{"instance_id": "271200a8b261", "generation_result": [{"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.asarray(x)\n    y = np.argsort(x)\n    inverse = np.zeros_like(y)\n    inverse[y] = np.arange(len(x))\n    return np.sort(inverse)", "CodeBleu_score": 42.120680169047574}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.asarray(x)\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 56.64729339934459}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.asarray(x)\n    inverse = np.zeros(len(x), dtype=int)\n    inverse[np.argsort(x)] = np.arange(len(x))\n    return np.sort(inverse)\n\n", "CodeBleu_score": 36.811917485309344}]}
{"instance_id": "040d73b37229", "generation_result": [{"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    plt.style.use(\"ggplot\")\n\n    # Create figure with subplots\n    fig, ax = plt.subplots(2, 2, figsize=(15, 10))\n    fig.suptitle(\"Medical Charts\")\n\n    # Plot vomit\n    plot_monthly_vomit(ax[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(ax[0, 1], data)\n\n    # Plot daycare days\n    plot_daycare_days(ax[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(ax[1, 1], data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Save figure\n    fig.savefig(\"output/medical_charts.png\")\n\n", "CodeBleu_score": 27.182765446026846}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    plt.style.use(\"seaborn-whitegrid\")\n\n    # Create figure with subplots\n    fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(ax[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(ax[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(ax[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(ax[1, 1], data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export figure\n    fig.savefig(\n        \"./output/medical_charts.png\",\n        dpi=150,\n        bbox_inches=\"tight\",\n    )\n\n", "CodeBleu_score": 27.93627041281433}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    plt.style.use(\"seaborn\")\n\n    # Create figure with subplots\n    fig, ax = plt.subplots(2, 2)\n\n    # Plot total vomit per month\n    plot_monthly_vomit(ax[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(ax[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(ax[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(ax[1, 1], data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export to file\n    plt.savefig(\"./output/medical_charts.png\")\n\n", "CodeBleu_score": 24.940913976875663}]}
{"instance_id": "7061f4d0c3fc", "generation_result": [{"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    data = parse_raw_data(data=pd.read_csv(filepath_or_buffer=\"data/feeding_data.csv\"), key=[\"Date\", \"Bottle\", \"Solid\"])\n\n    # Set up plot with dark grid style\n    plt.style.use(\"dark_background\")\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = (data[\"Date\"].iloc[0] - data[\"Date\"].iloc[-1]).days\n\n    # Create a scatter plot of feeding times, using red for bottle feedings and blue for solid feedings, adding a legend to distinguish between the two\n    plt.scatter(\n        x=data[\"timestamp_hour\"],\n        y=data[\"day_number\"] + offset,\n        c=[\"red\" if feeding_type == \"Bottle\" else \"blue\" for feeding_type in data[\"Feeding Type\"]],\n        s=100,\n        label=[\"Bottle\", \"Solid\"],\n    )\n\n    # Calculate the end date for the plot\n    end_date = get_end_date(data=data, first_year_only=True)\n\n    # Format the plot to display feeding data over a week in a 24-hour format\n    plt.xlim(0, 24)\n    plt.ylim(0, end_date)\n    plt.xticks(np.arange(0, 25, 2))\n    plt.yticks(np.arange(0, end_date + 1, 7))\n    plt.xlabel(\"Time of Day (24-hour)\")\n    plt.ylabel(\"Day Number\")\n    plt.title(\"24-Hour Feeding Data\")\n    plt.legend()\n\n    # Export the figure\n    export_figure(figure=plt, filename=\"feeding_24h_viz\", file_format=\"png\", transparent=True)\n\n    # Display the plot\n    plt.show()\n\n", "CodeBleu_score": 25.856406748638115}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import data\n    data = pd.read_csv(\"feeding_data.csv\")\n\n    # Extract data\n    data = parse_raw_data(data, [\"Bottle\", \"Solid\"])\n\n    # Set up plot\n    plt.style.use(\"dark_background\")\n\n    # Calculate offset from birthday\n    offset = (data[\"Date\"].iloc[-1] - data[\"Date\"].iloc[-2]).days\n\n    # Create scatter plot\n    plt.scatter(\n        data[\"day_number\"] + offset,\n        data[\"timestamp_hour\"],\n        c=data[\"Bottle\"].map({\"Yes\": \"r\", \"No\": \"b\"}),\n    )\n\n    # Add legend\n    plt.legend([\"Bottle\", \"Solid\"])\n\n    # Calculate end date\n    end_date = get_end_date(data, first_year_only=True)\n\n    # Format plot\n    plt.xlim(0, end_date)\n    plt.ylim(0, 24)\n    plt.xticks(range(0, end_date + 1, 7))\n    plt.yticks(range(0, 25, 2))\n    plt.xlabel(\"Day Number\")\n    plt.ylabel(\"Time of Day\")\n\n    # Export figure\n    export_figure(\"feeding_24h_viz.png\")\n\n", "CodeBleu_score": 17.266335772649125}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import data\n    data = parse_raw_data(pd.read_csv(\"feeding_data.csv\"), [\"timestamp_hour\"])\n\n    # Set up plot\n    plt.style.use(\"dark_background\")\n\n    # Compute offset from birthday\n    offset = get_end_date(data[data[\"solid_feeding\"] == 1], first_year_only=True)\n\n    # Create scatter plot\n    plt.scatter(\n        data[\"day_number\"] + offset,\n        data[\"timestamp_hour\"],\n        c=data[\"solid_feeding\"].map({0: \"red\", 1: \"blue\"}),\n        label=[\"bottle\", \"solid\"],\n    )\n\n    # Add legend\n    plt.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date(data, first_year_only=False)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    plt.xlim(end_date - 7, end_date)\n    plt.ylim(0, 24)\n    plt.xticks(np.arange(0, 365, 7), np.arange(0, 365, 7))\n    plt.yticks(np.arange(0, 24, 2))\n    plt.xlabel(\"Day\")\n    plt.ylabel(\"Hour\")\n\n    # Export figure\n    export_figure(plt, \"feeding_24h_viz\")\n\n", "CodeBleu_score": 20.10589837610671}]}
{"instance_id": "6c1ffa63d122", "generation_result": [{"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'{task.name} counts')\n    ax.set_xlabel('')\n    ax.set_ylabel('Counts')\n    return ax\n\n", "CodeBleu_score": 41.24393286364602}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    counts, labels = self._get_target_counts(task)\n    sns.barplot(x=labels, y=counts, ax=ax, **kwargs)\n    ax.set_title(f'Target counts for {task.name}')\n    ax.set_ylabel('Count')\n\n", "CodeBleu_score": 42.406078830392026}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_ylabel('Count')\n    ax.set_xlabel(task.name)\n\n", "CodeBleu_score": 44.19176348407892}]}
{"instance_id": "2f81a906bad5", "generation_result": [{"code": "def render_to_rgb(figure)\n\t\n    from matplotlib import pyplot as plt\n    from matplotlib.backends import backend_agg as plt_backend_agg\n    import numpy as np\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = plt_backend_agg.FigureCanvasAgg(fig)\n            canvas.draw()\n            image = np.array(canvas.buffer_rgba())\n            image = image.reshape(image.shape[1], image.shape[0], -1)\n            images.append(image)\n        images = np.stack(images, axis=0)\n        plt.close(fig)\n        return images\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        image = np.array(canvas.buffer_rgba())\n        image = image.reshape(image.shape[1], image.shape[0], -1)\n        plt.close(figure)\n        return image\n\n\n", "CodeBleu_score": 37.511833963649835}, {"code": "def render_to_rgb(figure)\n\t\n    from matplotlib.backends import backend_agg as plt_backend_agg\n    import numpy as np\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = plt_backend_agg.FigureCanvasAgg(fig)\n            canvas.draw()\n            data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n            image = data.reshape(fig.canvas.get_width_height()[::-1] + (4,))\n            image = image[..., :3]\n            images.append(image)\n        images = np.stack(images)\n        return images\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        data = np.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)\n        image = data.reshape(figure.canvas.get_width_height()[::-1] + (4,))\n        image = image[..., :3]\n        return image", "CodeBleu_score": 45.86930521337445}, {"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from matplotlib.backends import backend_agg as plt_backend_agg\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = plt_backend_agg.FigureCanvasAgg(fig)\n            canvas.draw()\n            rgba_buf = canvas.buffer_rgba()\n            image = np.reshape(np.asarray(rgba_buf, dtype=np.uint8), (rgba_buf.height, rgba_buf.width, 4))\n            image = image[:, :, :3]\n            images.append(image)\n        images = np.stack(images, axis=0)\n        return images\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        rgba_buf = canvas.buffer_rgba()\n        image = np.reshape(np.asarray(rgba_buf, dtype=np.uint8), (rgba_buf.height, rgba_buf.width, 4))\n        image = image[:, :, :3]\n        plt.close(figure)\n        return image\n\n\n", "CodeBleu_score": 41.8359478589186}]}
{"instance_id": "c3037b01569c", "generation_result": [{"code": "def beholder_pytorch()\n\t\n    import torch\n    import time\n    import beholder\n    from beholder.visualization.beholder import Beholder\n    beholder.set_logdir(\"logs/beholder_pytorch\")\n    beholder.clear_logdir()\n    beholder.set_visualization(\"beholder\")\n    beholder.set_visualization_params({\"logdir\": \"logs/beholder_pytorch\"})\n    beholder.start_visualization()\n    for i in range(1000):\n        x = torch.randn(10, 10)\n        y = torch.randn(10, 10)\n        beholder.update(x, \"x\")\n        beholder.update(y, \"y\")\n        beholder.update(torch.randn(10, 10), \"random\")\n        time.sleep(0.01)\n        print(i)\n\n", "CodeBleu_score": 23.18481589540668}, {"code": "def beholder_pytorch()\n\t\n    import time\n    import torch\n    import random\n    from beholder.beholder import Beholder\n    log_dir = \"./logs/pytorch\"\n    beholder = Beholder(log_dir)\n    for i in range(1000):\n        t1 = torch.randn(10, 10)\n        t2 = torch.randn(10, 10)\n        beholder.update({\"t1\": t1, \"t2\": t2}, frame=random.randint(0, 1000))\n        time.sleep(0.01)\n        print(i)\n\n", "CodeBleu_score": 23.55632538297885}, {"code": "def beholder_pytorch()\n\t\n    import torch\n    import time\n    import numpy as np\n    from beholder import Beholder\n\n    beholder = Beholder(log_dir=\"logs/pytorch/\")\n\n    for i in range(1000):\n        x1 = torch.randn(100, 100)\n        x2 = torch.randn(100, 100)\n        beholder.update(x1, \"x1\", frame=i)\n        beholder.update(x2, \"x2\", frame=i)\n        time.sleep(0.01)\n        print(i)\n\n", "CodeBleu_score": 24.664455961641355}]}
{"instance_id": "cd57b5de8a88", "generation_result": [{"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.tensor_content\n    tensor_data = np.frombuffer(tensor_data, dtype=np.float32)\n    tensor_data = tensor_data.reshape(summary.tensor.shape.dim)\n    thresholds = np.linspace(0, 1, num_thresholds)\n    tp = tensor_data[0]\n    fp = tensor_data[1]\n    tn = tensor_data[2]\n    fn = tensor_data[3]\n    precision = tensor_data[4]\n    recall = tensor_data[5]\n    pr_data = {\n        \"thresholds\": thresholds,\n        \"tp\": tp,\n        \"fp\": fp,\n        \"tn\": tn,\n        \"fn\": fn,\n        \"precision\": precision,\n        \"recall\": recall,\n    }\n    self.log_asset_data(tag, pr_data, step)", "CodeBleu_score": 28.924524539573966}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.tensor_content\n    tensor_data = np.frombuffer(tensor_data, dtype=np.float32)\n    if len(summary.tensor.tensor_shape.dim) == 2:\n        tensor_data = tensor_data.reshape((-1, summary.tensor.tensor_shape.dim[1].size))\n    elif len(summary.tensor.tensor_shape.dim) == 3:\n        tensor_data = tensor_data.reshape((-1, summary.tensor.tensor_shape.dim[1].size, summary.tensor.tensor_shape.dim[2].size))\n    elif len(summary.tensor.tensor_shape.dim) == 4:\n        tensor_data = tensor_data.reshape((-1, summary.tensor.tensor_shape.dim[1].size, summary.tensor.tensor_shape.dim[2].size, summary.tensor.tensor_shape.dim[3].size))\n    thresholds = np.linspace(0, 1, num_thresholds)\n    tp = np.sum(tensor_data > thresholds, axis=0)\n    fp = np.sum(tensor_data <= thresholds, axis=0)\n    tn = np.sum(tensor_data <= thresholds, axis=0)\n    fn = np.sum(tensor_data > thresholds, axis=0)\n    precision = tp / (tp + fp)\n    recall = tp / (tp + fn)\n    pr_data = {\n        'thresholds': thresholds.tolist(),\n        'tp': tp.tolist(),\n        'fp': fp.tolist(),\n        'tn': tn.tolist(),\n        'fn': fn.tolist(),\n        'precision': precision.tolist(),\n        'recall': recall.tolist()\n    }\n    self.log_asset_data(tag, pr_data, step)", "CodeBleu_score": 30.91539291566672}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.tensor_content\n    tensor_data = np.frombuffer(tensor_data, dtype=np.float32)\n    if len(summary.tensor.shape.dim) == 1:\n        tensor_data = tensor_data.reshape((-1, 1))\n    elif len(summary.tensor.shape.dim) == 2:\n        tensor_data = tensor_data.reshape((-1, summary.tensor.shape.dim[1].size))\n    elif len(summary.tensor.shape.dim) == 3:\n        tensor_data = tensor_data.reshape((-1, summary.tensor.shape.dim[1].size, summary.tensor.shape.dim[2].size))\n    thresholds = np.linspace(0, 1, num_thresholds + 1)[1:]\n    tp, fp, tn, fn, precision, recall = [], [], [], [], [], []\n    for threshold in thresholds:\n        tp.append(np.sum(tensor_data > threshold))\n        fp.append(np.sum(tensor_data <= threshold))\n        tn.append(np.sum(tensor_data <= threshold))\n        fn.append(np.sum(tensor_data > threshold))\n        precision.append(tp[-1] / (tp[-1] + fp[-1]))\n        recall.append(tp[-1] / (tp[-1] + fn[-1]))\n    pr_data = {\n        'tag': tag,\n        'thresholds': thresholds,\n        'tp': tp,\n        'fp': fp,\n        'tn': tn,\n        'fn': fn,\n        'precision': precision,\n        'recall': recall,\n    }\n    self.log_asset_data(tag, pr_data, step)", "CodeBleu_score": 36.35352345791991}]}
{"instance_id": "7c4ea9beecc9", "generation_result": [{"code": "def load_mnist(images, labels, num)\n\t\n    data = np.zeros((num, 28, 28), dtype=np.uint8)\n    target = np.zeros(num, dtype=np.uint8)\n    with gzip.open(images, 'rb') as img_file:\n        img_file.read(16)\n        for i in range(num):\n            for j in range(28):\n                for k in range(28):\n                    data[i, j, k] = ord(img_file.read(1))\n    with gzip.open(labels, 'rb') as lbl_file:\n        lbl_file.read(8)\n        for i in range(num):\n            target[i] = ord(lbl_file.read(1))\n    return data, target\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.43605225485829}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = np.empty((num, 1, 28, 28), dtype=np.uint8)\n    target = np.empty((num,), dtype=np.uint8)\n    with gzip.open(labels, 'rb') as lbpath:\n        lbpath.read(8)\n        for i in range(num):\n            target[i] = ord(lbpath.read(1))\n    with gzip.open(images, 'rb') as imgpath:\n        imgpath.read(16)\n        for i in range(num):\n            for j in range(28 * 28):\n                data[i, 0, j // 28, j % 28] = ord(imgpath.read(1))\n    return data, target\n\n\n", "CodeBleu_score": 45.32653749802304}, {"code": "def load_mnist(images, labels, num)\n\t\n    data = []\n    target = []\n    with gzip.open(images, 'rb') as f:\n        f.read(16)\n        for i in range(num):\n            image = []\n            for j in range(28 * 28):\n                image.append(ord(f.read(1)))\n            data.append(image)\n    with gzip.open(labels, 'rb') as f:\n        f.read(8)\n        for i in range(num):\n            target.append(ord(f.read(1)))\n    return np.array(data), np.array(target)\n\n\n", "CodeBleu_score": 39.16827814308693}]}
{"instance_id": "bf4f1c828b25", "generation_result": [{"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_values = {}\n    self.max_values = {}\n    self.cardinality = {}\n    self.length = ldf.shape[0]\n    for col in ldf.columns:\n        if ldf[col].dtype == \"datetime64[ns]\":\n            self.unique_values[col] = ldf[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\").unique()\n            self.cardinality[col] = len(self.unique_values[col])\n        elif ldf[col].dtype == \"timedelta64[ns]\":\n            self.unique_values[col] = ldf[col].dt.strftime(\"%H:%M:%S\").unique()\n            self.cardinality[col] = len(self.unique_values[col])\n        elif ldf[col].dtype == \"int64\" or ldf[col].dtype == \"float64\":\n            self.unique_values[col] = ldf[col].unique()\n            self.cardinality[col] = len(self.unique_values[col])\n            self.min_values[col] = ldf[col].min()\n            self.max_values[col] = ldf[col].max()\n        else:\n            self.unique_values[col] = ldf[col].unique()\n            self.cardinality[col] = len(self.unique_values[col])\n\n    if ldf.index.dtype != \"int64\":\n        self.unique_values[ldf.index.name] = ldf.index.unique()\n        self.cardinality[ldf.index.name] = len(self.unique_values[ldf.index.name])\n\n\n\n\n", "CodeBleu_score": 32.32307879936755}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_vals = {}\n    self.min_max_vals = {}\n    self.cardinality = {}\n    self.data_length = len(ldf)\n    for col in ldf.columns:\n        if ldf[col].dtype == \"datetime64[ns]\":\n            self.unique_vals[col] = ldf[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\").unique()\n        else:\n            self.unique_vals[col] = ldf[col].unique()\n        self.cardinality[col] = len(self.unique_vals[col])\n        if ldf[col].dtype in [\"int64\", \"float64\"]:\n            self.min_max_vals[col] = [ldf[col].min(), ldf[col].max()]\n    if ldf.index.dtype != \"int64\":\n        self.unique_vals[\"index\"] = ldf.index.unique()\n        self.cardinality[\"index\"] = len(self.unique_vals[\"index\"])\n\n\n", "CodeBleu_score": 30.25679724524137}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max_values = {}\n    self.cardinality = {}\n    self.length = len(ldf)\n    for col in ldf.columns:\n        self.unique_values[col] = ldf[col].unique()\n        self.cardinality[col] = len(self.unique_values[col])\n        if ldf.dtypes[col] == \"datetime64[ns]\":\n            self.unique_values[col] = [\n                str(datetime.datetime.strftime(x, \"%Y-%m-%d %H:%M:%S\"))\n                for x in self.unique_values[col]\n            ]\n        if ldf.dtypes[col] in [\"int64\", \"float64\"]:\n            self.min_max_values[col] = [\n                ldf[col].min(),\n                ldf[col].max(),\n            ]\n    if ldf.index.dtype != \"int64\":\n        self.unique_values[ldf.index.name] = ldf.index.unique()\n        self.cardinality[ldf.index.name] = len(self.unique_values[ldf.index.name])\n\n", "CodeBleu_score": 34.85291101821778}]}
{"instance_id": "3e6fc3d2f47c", "generation_result": [{"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    query = tbl.preview_query(preview_size)\n    df = tbl.execute(query)\n    return df\n\n\n", "CodeBleu_score": 12.90849331700036}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    preview_query = f\"SELECT * FROM {tbl.name} LIMIT {preview_size}\"\n    print(preview_query)\n    return tbl.sql_connection.execute(preview_query)\n\n\n", "CodeBleu_score": 23.464224070311218}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    query = f\"SELECT * FROM {tbl.name} LIMIT {preview_size}\"\n    return tbl.sql_connection.execute(query)\n\n", "CodeBleu_score": 16.970236427708603}]}
{"instance_id": "b3dee87be4b8", "generation_result": [{"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    from lux.config import Config\n    from lux.utils.utils import get_limit_str\n    from lux.utils.utils import get_sampling_query\n    from lux.utils.utils import get_table_length\n\n    sampling_flag = Config.get_global_config()[\"SAMPLE_FLAG\"]\n    sampling_start = Config.get_global_config()[\"SAMPLE_START\"]\n    sampling_cap = Config.get_global_config()[\"SAMPLE_CAP\"]\n    sampling_frac = Config.get_global_config()[\"SAMPLE_FRAC\"]\n\n    if sampling_flag:\n        length = get_table_length(tbl)\n        limit = get_limit_str(length, sampling_start, sampling_cap, sampling_frac)\n        query = get_sampling_query(tbl.table_name, limit)\n        tbl._sampled = tbl.engine.execute(query).fetchall()\n\n", "CodeBleu_score": 30.693222166753685}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    sample_flag = lux.config[\"SAMPLE_FLAG\"]\n    sample_start = lux.config[\"SAMPLE_START\"]\n    sample_cap = lux.config[\"SAMPLE_CAP\"]\n    sample_frac = lux.config[\"SAMPLE_FRAC\"]\n\n    if sample_flag:\n        query = f\"SELECT COUNT(*) FROM {tbl.table_name}\"\n        df = tbl.sql_engine.execute(query)\n        table_length = df.iloc[0][\"count\"]\n        limit = int(sample_frac * table_length)\n        if limit > sample_cap:\n            limit = sample_cap\n        query = f\"SELECT * FROM {tbl.table_name} LIMIT {limit}\"\n        tbl._sampled = tbl.sql_engine.execute(query)\n        tbl._sampled.index = tbl._sampled[tbl.index_col]\n        tbl._sampled.drop(columns=[tbl.index_col], inplace=True)\n        if sample_start:\n            tbl._sampled = tbl._sampled.iloc[sample_start:]\n\n", "CodeBleu_score": 26.675603701800032}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    if not tbl.is_sampled:\n        sample_flag = lux.config.SAMPLE_FLAG\n        sample_start = lux.config.SAMPLE_START\n        sample_cap = lux.config.SAMPLE_CAP\n        sample_frac = lux.config.SAMPLE_FRAC\n        if sample_flag:\n            if sample_flag == \"head\":\n                sample_limit = sample_start\n            elif sample_flag == \"tail\":\n                sample_limit = sample_start\n            elif sample_flag == \"frac\":\n                sample_limit = sample_start * sample_frac\n            else:\n                sample_limit = sample_start\n            if sample_cap and sample_limit > sample_cap:\n                sample_limit = sample_cap\n            tbl._sampled = tbl.sql(\"SELECT * FROM ({}) LIMIT {}\".format(tbl.sql(), sample_limit))\n            tbl.is_sampled = True\n    return tbl\n\n\n", "CodeBleu_score": 26.81144325609924}]}
{"instance_id": "485253b1088a", "generation_result": [{"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    default_params = {\n        'text': 'Text',\n        'x': 0.5,\n        'y': 0.5,\n        'fontsize': 12,\n        'horizontalalignment': 'center',\n        'verticalalignment': 'center',\n        'transform': None,\n        'color': 'k',\n        'bbox': {\n            'facecolor': 'white',\n            'edgecolor': 'none',\n            'boxstyle': 'round',\n            'alpha': 0.6,\n        },\n        'zorder': 2,\n    }\n\n    params = override_params(default_params, params)\n\n    text = params['text']\n    x = params['x']\n    y = params['y']\n\n    x0, x1, y0, y1 = background.bounds\n    x = np.interp(x, [0, 1], [x0, x1])\n    y = np.interp(y, [0, 1], [y0, y1])\n\n    plt.text(\n        x,\n        y,\n        text,\n        fontsize=params['fontsize'],\n        horizontalalignment=params['horizontalalignment'],\n        verticalalignment=params['verticalalignment'],\n        transform=params['transform'],\n        color=params['color'],\n        bbox=params['bbox'],\n        zorder=params['zorder'],\n    )\n\n", "CodeBleu_score": 23.84065798165057}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n    # Override default text settings with provided parameters\n    text_params = override_params(params['text'], params['text_params'])\n    text = text_params['text']\n    x = text_params['x']\n    y = text_params['y']\n\n    # Retrieve the background's bounds\n    bounds = background.bounds\n\n    # Interpolate the x and y values to fit within the background's bounds\n    x = np.interp(x, [0, 1], [bounds[0], bounds[2]])\n    y = np.interp(y, [0, 1], [bounds[1], bounds[3]])\n\n    # Draw the text at the calculated position with the remaining parameters\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 16.46243952602636}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    # Override default text settings with provided parameters\n    text_params = override_params(params[\"text_params\"], params[\"text\"])\n    text = text_params[\"text\"]\n    x = text_params[\"x\"]\n    y = text_params[\"y\"]\n\n    # Get background bounds\n    xmin, ymin, xmax, ymax = background.bounds\n\n    # Interpolate x and y values to fit within background bounds\n    x = np.interp(x, [xmin, xmax], [0, 1])\n    y = np.interp(y, [ymin, ymax], [0, 1])\n\n    # Draw text\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 20.12150067322519}]}
{"instance_id": "5f70a88b6b72", "generation_result": [{"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format:\n        return datetime_format\n    else:\n        days = [(dates[i + 1] - dates[i]).days for i in range(len(dates) - 1)]\n        average_days = sum(days) / len(days)\n        if average_days < 0.33:\n            if (dates[-1] - dates[0]).days > 1:\n                return '%b %d, %H:%M'\n            else:\n                return '%H:%M'\n        else:\n            if (dates[-1].year - dates[0].year) > 0:\n                return '%Y-%b-%d'\n            else:\n                return '%b %d'\n\n", "CodeBleu_score": 37.82322432725434}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    # Calculate the average number of days between consecutive dates\n    if len(dates) > 1:\n        days_between_points = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]\n        average_days = sum(days_between_points) / len(days_between_points)\n    else:\n        average_days = 0\n\n    # If datetime_format is provided, return it\n    if datetime_format:\n        return datetime_format\n\n    # If the average days between points is less than 0.33, indicating intraday data, check if the data spans more than one day\n    if average_days < 0.33:\n        # If the data spans more than one day, set the format string to '%b %d, %H:%M'\n        if (dates[-1] - dates[0]).days > 1:\n            return '%b %d, %H:%M'\n        # Otherwise, set the format string to '%H:%M'\n        else:\n            return '%H:%M'\n    # If the data spans multiple years, set the format string to '%Y-%b-%d'\n    elif (dates[-1] - dates[0]).days > 365:\n        return '%Y-%b-%d'\n    # Otherwise, set the format string to '%b %d'\n    else:\n        return '%b %d'", "CodeBleu_score": 37.88754752110434}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    if len(dates) < 2:\n        return '%Y-%m-%d'\n    days_between_dates = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]\n    average_days_between_dates = sum(days_between_dates) / len(days_between_dates)\n    if average_days_between_dates < 0.33:\n        if max(days_between_dates) > 1:\n            return '%H:%M'\n        else:\n            return '%H:%M:%S'\n    else:\n        if max(days_between_dates) > 365:\n            return '%Y-%b-%d'\n        elif max(days_between_dates) > 31:\n            return '%b %d'\n        else:\n            return '%b %d, %H:%M'\n\n\n\n", "CodeBleu_score": 39.69927513073993}]}
{"instance_id": "f9589bf4666d", "generation_result": [{"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        c = [v/255 for v in c]\n    else:\n        c = list(c)\n        if len(c) == 3:\n            c.append(1)\n        c = [v/255 for v in c]\n    if alpha is not None:\n        c[-1] = alpha\n    return c\n\n", "CodeBleu_score": 27.01693050151541}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        c = np.array(c, dtype=float) / 255.0\n    else:\n        c = np.array(c, dtype=float)\n        if any(c > 1.0):\n            c /= 255.0\n    if alpha is not None:\n        c = np.append(c, alpha)\n    return c\n\n", "CodeBleu_score": 23.65547821219173}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if isinstance(c,str):\n        c = mpl.colors.to_rgba(c)\n    elif _is_uint8_rgb_or_rgba(c):\n        c = tuple(v/255 for v in c)\n    if alpha is not None:\n        c = c[:3] + (alpha,)\n    return c\n\n", "CodeBleu_score": 36.66068784256}]}
{"instance_id": "4202e378ab0b", "generation_result": [{"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n", "CodeBleu_score": 91.92960540361257}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    \n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n    \n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist", "CodeBleu_score": 91.92960540361257}, {"code": "def subplots(self,*args,**kwargs)\n\t\n    \n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n    \n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n", "CodeBleu_score": 91.92960540361257}]}
{"instance_id": "3e2b6dfe4753", "generation_result": [{"code": "def _adjust_figsize(fig,config)\n\t\n    if not fig:\n        return\n    if not config.get('figure'):\n        return\n    if config.get('figure').get('size'):\n        fig.set_size_inches(config.get('figure').get('size'))\n        return\n    fig_ratio = config.get('figure').get('ratio')\n    if not fig_ratio:\n        return\n    if not (0.0 < fig_ratio < 1.0):\n        return\n    fig_size = fig.get_size_inches()\n    if fig_size[0] > fig_size[1]:\n        fig_size = (fig_size[0],fig_size[0] * fig_ratio)\n    else:\n        fig_size = (fig_size[1] / fig_ratio,fig_size[1])\n    fig.set_size_inches(fig_size)\n\n", "CodeBleu_score": 29.33296587972709}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if 'figsize' not in config:\n        fig.set_size_inches(10, 10 / fig.get_figwidth() * fig.get_figheight())\n    else:\n        fig.set_size_inches(config['figsize'])\n\n\n", "CodeBleu_score": 11.75607462367014}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if config.get('figsize') is not None:\n        fig.set_size_inches(config['figsize'])\n        return\n    fig_ratio = config.get('fig_ratio',(16,9))\n    if fig_ratio is None:\n        return\n    fig_ratio = np.array(fig_ratio)\n    if np.any(fig_ratio <= 0):\n        raise ValueError('Invalid figure ratio: {}'.format(fig_ratio))\n    fig_ratio = fig_ratio / np.sum(fig_ratio)\n    if fig_ratio[0] > 1 or fig_ratio[1] > 1:\n        raise ValueError('Invalid figure ratio: {}'.format(fig_ratio))\n    if fig_ratio[0] > 0.5 or fig_ratio[1] > 0.5:\n        fig_ratio = fig_ratio / 2\n    if fig_ratio[0] > 0.25 or fig_ratio[1] > 0.25:\n        fig_ratio = fig_ratio / 4\n    if fig_ratio[0] > 0.125 or fig_ratio[1] > 0.125:\n        fig_ratio = fig_ratio / 8\n    fig_ratio = fig_ratio / np.max(fig_ratio)\n    fig_ratio = fig_ratio * 16\n    fig.set_size_inches(fig_ratio)\n", "CodeBleu_score": 31.72097679839817}]}
{"instance_id": "986e5804b941", "generation_result": [{"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}]}
{"instance_id": "5308e20f3c90", "generation_result": [{"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kernel_height, kernel_width = inputs[0].shape[2:]\n    input_channels = inputs[0].shape[1]\n    output_channels = outputs[0].shape[1]\n    output_height, output_width = outputs[0].shape[2:]\n    output_elements = output_height * output_width\n    flops = output_elements * input_channels * kernel_height * kernel_width\n    if opnode.bias is not None:\n        flops += output_elements * output_channels\n    return flops\n\n", "CodeBleu_score": 18.557534150045214}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kernel_height = inputs[0].shape[2]\n    kernel_width = inputs[0].shape[3]\n    input_channels = inputs[0].shape[1]\n    output_height = outputs[0].shape[2]\n    output_width = outputs[0].shape[3]\n    output_channels = outputs[0].shape[1]\n    output_elements = output_height * output_width * output_channels\n    flops = output_elements * input_channels * kernel_height * kernel_width\n    if opnode.bias is not None:\n        flops += output_elements * output_channels\n    return flops\n\n", "CodeBleu_score": 18.68752526720861}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    kernel_height, kernel_width = inputs[0].shape[2:]\n    input_channels = inputs[0].shape[1]\n    output_elements = outputs[0].shape[0] * outputs[0].shape[1] * outputs[0].shape[2] * outputs[0].shape[3]\n    flops = output_elements * input_channels * kernel_height * kernel_width\n    if opnode.bias is not None:\n        flops += output_elements * 1\n    return flops\n\n", "CodeBleu_score": 21.579164249360772}]}
{"instance_id": "70811d3cf578", "generation_result": [{"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert mge_dtype.kind == 'b' or mge_dtype.kind == 'i' or mge_dtype.kind == 'u' or mge_dtype.kind == 'f' or mge_dtype.kind == 'c'\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)\n\n\n", "CodeBleu_score": 30.04685998244777}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert mge_dtype.type is not None\n    return _dtype_to_ir_type[mge_dtype.type](mge_dtype)\n\n", "CodeBleu_score": 21.540560496694283}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert mge_dtype.kind in _dtype_to_ir_type\n    return _dtype_to_ir_type[mge_dtype.kind](mge_dtype)\n\n\n", "CodeBleu_score": 22.193647278234014}]}
{"instance_id": "a108c9ba2c22", "generation_result": [{"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(np.float32)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if ir_type == ir.FloatType(32):\n        x = x.astype(np.float32)\n    elif ir_type == ir.FloatType(16):\n        x = x.astype(np.bfloat16)\n    elif ir_type == ir.FloatType(64):\n        x = x.astype(np.float64)\n    elif ir_type == ir.FloatType(128):\n        x = x.astype(np.float128)\n    elif ir_type == ir.IntegerType(1):\n        x = x.astype(np.bool_)\n    elif ir_type == ir.IntegerType(8):\n        x = x.astype(np.int8)\n    elif ir_type == ir.IntegerType(16):\n        x = x.astype(np.int16)\n    elif ir_type == ir.IntegerType(32):\n        x = x.astype(np.int32)\n    elif ir_type == ir.IntegerType(64):\n        x = x.astype(np.int64)\n    else:\n        raise NotImplementedError(f\"dtype {ir_type} is not supported\")\n    x = np.ascontiguousarray(x)\n    attr = ir.DenseElementsAttr.get(x)\n    return [ir.ConstantOp(attr, ir_type)]\n\n", "CodeBleu_score": 39.874796550875104}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(np.float32)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool:\n        x = x.astype(np.int8)\n    if x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    attr = ir.DenseElementsAttr.get(x, ir_type)\n    return [ir.ConstantOp(attr)]\n\n", "CodeBleu_score": 39.65471423778782}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(np.float32)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.int32)\n        ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n        ir_type = mge_dtype_to_ir_type(x.dtype)\n    x = np.ascontiguousarray(x)\n    attr = ir.DenseElementsAttr.get(x, ir_type)\n    return [ir.ConstantOp(attr)]\n\n", "CodeBleu_score": 43.627906130369595}]}
{"instance_id": "3345fe4d008b", "generation_result": [{"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.strides.any() == 0 and val.size != 0:\n        nonzero_stride_axes = np.where(val.strides != 0)[0]\n        nonzero_stride_axes_set = set(nonzero_stride_axes)\n        zero_stride_axes = np.where(val.strides == 0)[0]\n        zero_stride_axes_set = set(zero_stride_axes)\n        val = np.reshape(val, val.shape[nonzero_stride_axes])\n        if canonicalize_types:\n            val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n        val = np.ascontiguousarray(val)\n        attr = ir.DenseElementsAttr.get(val, type=mge_dtype_to_ir_type(val.dtype))\n        return (\n            hlo.BroadcastInDimOp(\n                hlo.ConstantOp(attr).result,\n                hlo.ConstantOp(dense_int_elements(nonzero_stride_axes)).result,\n            ).result,\n        )\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 42.31420012275999}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.strides[0] == 0 and val.size > 0:\n        zero_stride_axes = [i for i, s in enumerate(val.strides) if s == 0]\n        non_zero_stride_axes = [\n            i for i, s in enumerate(val.strides) if s != 0\n        ]\n        if len(zero_stride_axes) > 0:\n            collapsed_shape = np.array(\n                [val.shape[i] for i in non_zero_stride_axes]\n            )\n            collapsed_val = val.reshape(collapsed_shape)\n            collapsed_val = np.asarray(\n                collapsed_val, dtype.canonicalize_dtype(collapsed_val.dtype)\n            )\n            collapsed_val = collapsed_val[()]\n        else:\n            collapsed_val = val\n        return _numpy_array_constant(collapsed_val, canonicalize_types)\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 42.35378403727027}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.strides == (0,) * val.ndim:\n        if val.size == 0:\n            return _numpy_array_constant(val, canonicalize_types)\n        else:\n            zero_stride_axes = [i for i, s in enumerate(val.strides) if s == 0]\n            if len(zero_stride_axes) > 0:\n                collapsed_val = val.reshape(\n                    val.shape[:1] + (val.shape[1:],)\n                )\n                collapsed_val = collapsed_val.reshape(val.shape[0], -1)\n                non_zero_stride_axes = [\n                    i for i in range(val.ndim) if i not in zero_stride_axes\n                ]\n                if canonicalize_types:\n                    collapsed_val = np.asarray(\n                        collapsed_val,\n                        dtype.canonicalize_dtype(collapsed_val.dtype),\n                    )\n                collapsed_val = np.ascontiguousarray(collapsed_val)\n                collapsed_val = collapsed_val.view(\n                    np.ndarray,\n                    dtype=collapsed_val.dtype,\n                    shape=collapsed_val.shape,\n                )\n                return (\n                    hlo.BroadcastOp(\n                        collapsed_val,\n                        broadcast_dimensions=non_zero_stride_axes,\n                    ).result,\n                )\n            else:\n                return _numpy_array_constant(val, canonicalize_types)\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 46.136494688890096}]}
{"instance_id": "91b298678351", "generation_result": [{"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    if len(xs) == 1:\n        if xs[0]:\n            packed_bits = ir.DenseIntElementsAttr.get_scalar_value(1)\n        else:\n            packed_bits = ir.DenseIntElementsAttr.get_scalar_value(0)\n    else:\n        packed_bits = ir.DenseIntElementsAttr.get(ir.IntType.get_signless(1), xs)\n    return ir.DenseElementsAttr.get(ir.IntType.get_signless(1), packed_bits)\n\n\n\n", "CodeBleu_score": 38.524399143619334}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    if not xs:\n        raise ValueError(\"dense_bool_elements: empty sequence\")\n    if len(xs) == 1:\n        return ir.DenseElementsAttr.get_scalar_int(ir.IntegerType.get_signless(1), int(xs[0]))\n    bits = \"\".join(\"1\" if x else \"0\" for x in xs)\n    return ir.DenseElementsAttr.get_from_raw_data(ir.IntegerType.get_signless(1), bits, len(xs))\n\n\n", "CodeBleu_score": 37.40554906063643}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed_array = np.packbits(np.array(xs, dtype=np.bool8))\n    if len(packed_array) == 1:\n        packed_array = packed_array.repeat(len(xs))\n    return ir.DenseElementsAttr.get(ir.IntegerType.get_signless(1), packed_array)\n\n\n", "CodeBleu_score": 33.60704148144192}]}
{"instance_id": "06ebabf1e0ff", "generation_result": [{"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    assert len(args) == len(ctx.vars_in)", "CodeBleu_score": 14.675821103824497}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == len(ctx.vars_in) == len(ctx.vars_out) == 1\n    in_var, out_var = ctx.vars_in[0], ctx.vars_out[0]\n    assert in_var.data is not None or out_var.data is not None\n    if in_var.data is not None:\n        assert in_var.shape == out_var.shape\n        data = np.array(in_var.data, dtype=out_var.dtype)\n        in_var.data = data\n        out_var.data = data\n    elif out_var.data is not None:\n        assert in_var.shape == out_var.shape\n        data = np.array(out_var.data, dtype=in_var.dtype)\n        in_var.data = data\n        out_var.data = data\n    else:\n        assert False, 'Only tensor creation from constants is supported'\n    return HLOTensor(data, out_var.dtype)\n\n\n", "CodeBleu_score": 55.06877499950833}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == len(ctx.vars_in) == len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n    if input_var.bound_data is not None:\n        input_var.set_values(input_var.bound_data)\n    if output_var.bound_data is not None:\n        output_var.set_values(output_var.bound_data)\n    assert input_var.shape == output_var.shape\n    if output_var.bound_data is not None:\n        output_var.set_values(output_var.bound_data)\n    if input_var.bound_data is not None:\n        input_var.set_values(input_var.bound_data)\n    if input_var.bound_data is None and output_var.bound_data is None:\n        assert False, \"Only tensor creation from constants is supported\"\n    if input_var.bound_data is not None:\n        output_var.set_values(np.array(input_var.bound_data, dtype=output_var.data_type))\n    return output_var\n\n\n", "CodeBleu_score": 45.6173888179785}]}
{"instance_id": "6cd750fa0c8d", "generation_result": [{"code": "def _device_put_scalar(x, device)\n\t\n    if isinstance(x, (int, float, complex)):\n        if isinstance(x, complex):\n            x = np.array(x, dtype=np.complex128)\n        else:\n            x = np.array(x, dtype=np.float64)\n    else:\n        x = np.array(x, dtype=_get_dtype(x))\n    return _device_put(x, device)\n\n", "CodeBleu_score": 39.82455327757959}, {"code": "def _device_put_scalar(x, device)\n\t\n    if isinstance(x, (int, float)):\n        x = np.array(x, dtype=_get_dtype(x))\n    return _device_put(x, device)\n\n", "CodeBleu_score": 29.339886485730126}, {"code": "def _device_put_scalar(x, device)\n\t\n    if isinstance(x, torch._C.ScalarType):\n        x = _numpy_scalar_to_array(x)\n    return _device_put(x, device)\n\n", "CodeBleu_score": 21.229051511231273}]}
{"instance_id": "140de7c2b6a8", "generation_result": [{"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if not lhs_shape and not rhs_shape:\n        return True\n    assert isinstance(lhs_shape[0], int)\n    assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 45.371678253364294}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if not lhs_shape and not rhs_shape:\n        return True\n    if lhs_shape and rhs_shape:\n        assert isinstance(lhs_shape[0], int)\n        assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for (lhs, rhs) in zip(lhs_shape, rhs_shape):\n        if lhs != rhs:\n            return False\n    return True\n\n", "CodeBleu_score": 46.2516541362967}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = lhs_shape.tolist()\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = rhs_shape.tolist()\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    assert isinstance(lhs_shape[0], int)\n    assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for i in range(len(lhs_shape)):\n        if lhs_shape[i] != rhs_shape[i]:\n            return False\n    return True\n\n", "CodeBleu_score": 48.51314144896357}]}
{"instance_id": "55d0c71a259b", "generation_result": [{"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(\n        training_set_filename,\n        dtype=dtypes,\n        parse_dates=[\"date\"],\n        infer_datetime_format=True,\n    )\n    test_set = pd.read_csv(\n        test_set_filename,\n        dtype=dtypes,\n        parse_dates=[\"date\"],\n        infer_datetime_format=True,\n    )\n    training_set_metadata = pd.read_csv(\n        training_set_metadata_filename, dtype=meta_dtypes\n    )\n    test_set_metadata = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    test_set_metadata.drop([\"target\"], axis=1, inplace=True)\n    test_set_metadata[\"target\"] = training_set_metadata[\"target\"]\n    return training_set, test_set, training_set_metadata, test_set_metadata\n\n\n", "CodeBleu_score": 27.16644885171106}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(\n        training_set_filename,\n        dtype=dtypes,\n        na_values=[\"n/a\", \"?\"],\n        keep_default_na=False,\n    )\n    test_set = pd.read_csv(\n        test_set_filename,\n        dtype=dtypes,\n        na_values=[\"n/a\", \"?\"],\n        keep_default_na=False,\n    )\n    training_set_metadata = pd.read_csv(\n        training_set_metadata_filename, dtype=meta_dtypes\n    )\n    test_set_metadata = pd.read_csv(\n        test_set_metadata_filename, dtype=meta_dtypes\n    )\n    del meta_dtypes[\"target\"]\n    test_set_metadata = pd.read_csv(\n        test_set_metadata_filename, dtype=meta_dtypes\n    )\n    return (training_set, test_set, training_set_metadata, test_set_metadata)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.13570905507844}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n    training_set_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_set_metadata = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes)\n    test_set_metadata = test_set_metadata.drop(\"target\", axis=1)\n    test_set_metadata[\"target\"] = training_set_metadata[\"target\"]\n    return training_set, test_set, training_set_metadata, test_set_metadata", "CodeBleu_score": 29.292781210815377}]}
{"instance_id": "9e5e02cd73e0", "generation_result": [{"code": "def _show_cmap(cmap)\n\t\n    import matplotlib.pyplot as plt\n    from matplotlib.colors import LinearSegmentedColormap\n    from matplotlib.colors import ListedColormap\n    from matplotlib.colors import BoundaryNorm\n    from matplotlib.colors import Normalize\n    from matplotlib.colors import LogNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import SymLogNorm\n    from matplotlib.colors import CenteredNorm\n    from matplotlib.colors import DivergingNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import Normalize\n    from matplotlib.colors import LogNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import SymLogNorm\n    from matplotlib.colors import CenteredNorm\n    from matplotlib.colors import DivergingNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import Normalize\n    from matplotlib.colors import LogNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import SymLogNorm\n    from matplotlib.colors import CenteredNorm\n    from matplotlib.colors import DivergingNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import Normalize\n    from matplotlib.colors import LogNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import SymLogNorm\n    from matplotlib.colors import CenteredNorm\n    from matplotlib.colors import DivergingNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import Normalize\n    from matplotlib.colors import LogNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import SymLogNorm\n    from matplotlib.colors import CenteredNorm\n    from matplotlib.colors import DivergingNorm\n    from matplotlib.colors import PowerNorm\n    from matplotlib.colors import Normalize\n   ", "CodeBleu_score": 8.401060411430626}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    with axes_style('white'):\n        fig, ax = plt.subplots(figsize=(10, 1))\n        ax.set_axis_off()\n        ax.imshow(np.array([[0, 1]]), cmap=cmap)\n    return fig, ax\n\n\n", "CodeBleu_score": 35.98827338705396}, {"code": "def _show_cmap(cmap)\n\t\n    from rcmod import axes_style\n    import matplotlib.pyplot as plt\n    import numpy as np\n    with axes_style('white'):\n        fig, ax = plt.subplots(figsize=(10, 1))\n        ax.set_axis_off()\n        ax.imshow([[0, 1]], cmap=cmap, aspect='auto')\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n        ax.imshow(np.arange(100).reshape(1, -1), cmap=cmap)\n        plt.show()\n\n", "CodeBleu_score": 33.48498190507821}]}
{"instance_id": "ad0781b5cc38", "generation_result": [{"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None or obj.axes.get_transform() == obj.get_transform():\n        return xdata, ydata\n    xdata, ydata = obj.axes.transData.inverted().transform(xdata, ydata)\n    xdata, ydata = obj.get_transform().transform(xdata, ydata)\n    return xdata, ydata\n\n\n", "CodeBleu_score": 43.34529100842466}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    ax = obj.axes\n    if ax is None:\n        return xdata, ydata\n    xdata_orig = xdata\n    ydata_orig = ydata\n    if ax.transData.is_affine:\n        if ax.transData != obj.get_transform():\n            xdata, ydata = obj.transData.inverted().transform(xdata, ydata)\n    else:\n        xdata, ydata = obj.get_transform().transform_non_affine(xdata, ydata)\n    if xdata_orig is not None and ydata_orig is not None:\n        xdata = np.array(xdata)\n        ydata = np.array(ydata)\n        if xdata.shape != ydata.shape:\n            raise ValueError('xdata and ydata must have the same shape')\n        if xdata.ndim == 1:\n            xdata = xdata.reshape((-1, 1))\n            ydata = ydata.reshape((-1, 1))\n        if xdata.shape[1] != 2:\n            raise ValueError('xdata and ydata must have shape (N, 2)')\n    return xdata, ydata\n\n\n", "CodeBleu_score": 46.11259326870992}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        raise ValueError(\"Object has no axes\")\n    if obj.axes.get_xaxis_transform() == obj.axes.get_data_transform():\n        return xdata, ydata\n    else:\n        xdata, ydata = obj.axes.transData.inverted().transform((xdata, ydata))\n        xdata, ydata = obj.axes.transData.transform((xdata, ydata))\n        return xdata, ydata\n\n\n", "CodeBleu_score": 43.57002848312537}]}
{"instance_id": "bf776cadef8d", "generation_result": [{"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n\n    if data2 is not None:\n        if not pd.api.types.is_list_like(data2):\n            data2 = self._df[data2]\n    return self._module.kdeplot(data, data2=data2, *args, **kwargs)\n\n", "CodeBleu_score": 78.95861998202267}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n\n    if data2 is not None:\n        if not pd.api.types.is_list_like(data2):\n            data2 = self._df[data2]\n    return self._module.kdeplot(data, data2=data2, *args, **kwargs)\n\n", "CodeBleu_score": 78.95861998202267}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n    data = self._maybe_target_series(data, key='data')\n\n    if data2 is not None:\n        if not pd.api.types.is_list_like(data2):\n            data2 = self._df[data2]\n    return self._module.kdeplot(data, data2=data2, *args, **kwargs)\n\n", "CodeBleu_score": 78.95861998202267}]}
{"instance_id": "fb44964174d9", "generation_result": [{"code": "def plot_most_used_words(df)\n\t\n    df.loc[df['token'] == 'programa', 'token'] = 'programar'\n    df = df[df['token'].str.isalpha()]\n    df = df[df['token'].str.len() > 1]\n    df = df[~df['token'].isin(stopwords.words('spanish'))]\n    df = df[~df['token'].isin(stopwords.words('english'))]\n    df = df[~df['token'].isin(['programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', 'programar', '", "CodeBleu_score": 14.265595186763546}, {"code": "def plot_most_used_words(df)\n\t\n    df = df.replace('programa', 'programar')\n    df = df.loc[df['token'].str.isalpha()]\n    df = df.loc[df['token'].str.len() > 1]\n    df = df.loc[~df['token'].isin(stopwords.words('spanish'))]\n    df = df.groupby('token').size().reset_index(name='counts')\n    df = df.sort_values(by='counts', ascending=False)\n    df = df.head(20)\n    plt.figure(figsize=(10, 6))\n    sns.barplot(x='counts', y='token', data=df)\n    plt.xlabel('Frequency')\n    plt.ylabel('Word')\n    plt.title('Most Frequent Words')\n    plt.savefig('most_frequent_words.png')\n    plt.show()\n\n\n", "CodeBleu_score": 36.01165970645273}, {"code": "def plot_most_used_words(df)\n\t\n    df = df.replace(\"programa\", \"programar\")\n    df = df[df[\"token\"].str.isalpha()]\n    df = df[df[\"token\"].str.len() > 1]\n    df = df[~df[\"token\"].isin(stopwords)]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar\"]\n    df = df[df[\"token\"] != \"programar", "CodeBleu_score": 18.882956719512023}]}
{"instance_id": "13414a7eb4e3", "generation_result": [{"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n    from dask.array.overlap import overlap, trim_internal\n    from dask.array.utils import promote_types\n    from dask.base import tokenize\n    from dask.highlevelgraph import HighLevelGraph\n    from dask.utils import apply, funcname\n    from dask.utils import meta_from_array\n    from dask.utils import normalize_token\n    from dask.utils import tokenize_kwargs\n    from numba import types\n    from numba.typed import Dict\n    from numba.typed import List\n    from numba.typed import make_list\n    from numba.typed import make_tuple\n    from numba.typed import typed\n    from numba.types import Array\n    from numba.types import DictType\n    from numba.types import ListType\n    from numba.types import TupleType\n    from numba.types import UniTuple\n    from numba.types import void\n    from numba.typed import Dict\n    from numba.typed import List\n    from numba.typed import make_list\n    from numba.typed import make_tuple\n    from numba.typed import typed\n    from numba.types import Array\n    from numba.types import DictType\n    from numba.types import ListType\n    from numba.types import TupleType\n    from numba.types import UniTuple\n    from numba.types import void\n    from numba.typed import Dict\n    from numba.typed import List\n    from numba.typed import make_list\n    from numba.typed import make_tuple\n    from numba.typed import typed\n    from numba.types import Array\n    from numba.types import DictType\n    from numba.types import ListType\n    from numba.types import TupleType\n    from numba.types import UniTuple\n    from numba.types import void\n    from numba.typed import Dict\n    from numba.typed import List\n    from numba.typed import make_list\n    from numba.typed import make_tuple\n    from numba.typed", "CodeBleu_score": 11.66120098276986}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n    from dask.array.overlap import overlap\n    from dask.array.overlap import trim_internal\n    from dask.array.utils import promote_types\n    if min_count is None:\n        min_count = window\n    if not isinstance(a, da.Array):\n        a = da.from_array(a, chunks=(-1,))\n    a = promote_types(a, np.float64)\n    if a.ndim == 0:\n        a = a.reshape((1,))\n    if a.ndim == 1:\n        a = a.reshape((-1, 1))\n    depth = window // 2\n    if min_count < window:\n        depth = min_count // 2\n    if axis == -1:\n        axis = a.ndim - 1\n    if axis >= a.ndim:\n        raise ValueError('axis is out of bounds')\n    if axis == 0:\n        a = a.rechunk(a.chunks[1:])\n        axis = 1\n    if axis == a.ndim - 1:\n        a = a.rechunk(a.chunks[:-1])\n        axis = a.ndim - 2\n    if a.ndim == 2:\n        a = a.rechunk((a.chunks[0], a.chunks[1]))\n    if a.ndim == 3:\n        a = a.rechunk((a.chunks[0], a.chunks[1], a.chunks[2]))\n    if a.ndim == 4:\n        a = a.rechunk((a.chunks[0], a.chunks[1], a.chunks[2], a.chunks[3]))\n    if a.ndim == 5:\n        a = a.rechunk((a.chunks[0], a.chunks[1], a.chunks[2], a.chunks[3], a.chunks[4]))\n    if a.ndim == 6:\n        a = a.rechunk((a.chunks[0], a", "CodeBleu_score": 29.198123028735257}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n    import bottleneck as bn\n    if a.dtype == np.float32:\n        fill_value = np.finfo(np.float32).min\n    elif a.dtype == np.float64:\n        fill_value = np.finfo(np.float64).min\n    else:\n        fill_value = np.iinfo(a.dtype).min\n    depth = da.overlap.overlap_depth(a, window, axis=axis)\n    ag = da.overlap.overlap(a, depth, boundary='reflect', trim=False, axis=axis)\n    if min_count is not None:\n        ag = ag.map_blocks(bn.move_min, window, min_count=min_count, axis=axis, fill_value=fill_value)\n    else:\n        ag = ag.map_blocks(bn.move_min, window, axis=axis, fill_value=fill_value)\n    return da.overlap.trim_internal(ag, depth, axis=axis)\n\n", "CodeBleu_score": 35.92936843685882}]}
{"instance_id": "68ce25d325d4", "generation_result": [{"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    return _curry(least_squares, lhs, rhs, rcond=rcond, skipna=skipna)\n\n\n", "CodeBleu_score": 1.8141485000980027}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    pass\n\n", "CodeBleu_score": 1.37987012987013}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    pass\n\n", "CodeBleu_score": 1.37987012987013}]}
{"instance_id": "c0c2c53b76e0", "generation_result": [{"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]\n\n", "CodeBleu_score": 92.04127144323292}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]", "CodeBleu_score": 92.04127144323292}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]\n\n", "CodeBleu_score": 92.04127144323292}]}
{"instance_id": "6559019d09a0", "generation_result": [{"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n\n", "CodeBleu_score": 93.9150977472243}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n  \n\n", "CodeBleu_score": 93.9150977472243}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n", "CodeBleu_score": 93.9150977472243}]}
{"instance_id": "4a2801bb3851", "generation_result": [{"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(x) for x in args + tuple(kwargs.values())):\n            dask_module = import_optional_dependency(dask_module)\n            dask_func = getattr(dask_module, name)\n        else:\n            eager_func = getattr(eager_module, name)\n            dask_func = eager_func\n        return dask_func(*args, **kwargs)\n    return f\n\n", "CodeBleu_score": 54.645165451463484}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n    @wraps(getattr(eager_module, name))\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            dask_module = import_optional_dependency(dask_module)\n            return getattr(dask_module, name)(*args, **kwargs)\n        else:\n            return getattr(eager_module, name)(*args, **kwargs)\n    return f\n\n", "CodeBleu_score": 43.80288616816066}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            dask_module = import_optional_dependency(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n    return f\n\n", "CodeBleu_score": 53.582832663007906}]}
{"instance_id": "eef8d746d01e", "generation_result": [{"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n\n    if arr1.shape != arr2.shape:\n        return False\n\n    if is_dask_array(arr1) and is_dask_array(arr2):\n        return tokenize(arr1) == tokenize(arr2)\n\n    return None\n\n", "CodeBleu_score": 69.26374204401154}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask_available and is_dask_array(arr1) and is_dask_array(arr2):\n        return dask.base.tokenize(arr1) == dask.base.tokenize(arr2)\n    else:\n        return None\n\n", "CodeBleu_score": 76.00928568626706}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n\n    if arr1.shape != arr2.shape:\n        return False\n\n    if is_dask_array(arr1) and is_dask_array(arr2):\n        return tokenize(arr1) == tokenize(arr2)\n\n    return None\n\n", "CodeBleu_score": 69.26374204401154}]}
{"instance_id": "15e830ff5fcb", "generation_result": [{"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is None:\n        if frac_nan is not None:\n            r = np.random.RandomState(seed)\n            arr = r.randn(*shape)\n            arr[r.rand(*shape) < frac_nan] = np.nan\n            return arr\n        else:\n            return np.random.randn(*shape)\n    else:\n        if frac_nan is not None:\n            r = np.random.RandomState(seed)\n            arr = da.random.randn(*shape, chunks=chunks)\n            arr[r.rand(*shape) < frac_nan] = np.nan\n            return arr\n        else:\n            return da.random.randn(*shape, chunks=chunks)\n\n\n", "CodeBleu_score": 38.59190496098003}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        import dask.array as da\n        import numpy as np\n        np.random.seed(seed)\n        if frac_nan is not None:\n            arr = da.random.randn(shape, chunks=chunks)\n            nan_indices = np.random.choice(arr.size, int(arr.size * frac_nan), replace=False)\n            arr = arr.rechunk(chunks)\n            arr = arr.rechunk({i: 1 for i in range(arr.ndim)})\n            arr = arr.map_blocks(lambda x: x, dtype=arr.dtype, chunks=chunks)\n            arr[tuple(nan_indices)] = np.nan\n            return arr\n        else:\n            return da.random.randn(shape, chunks=chunks)\n    else:\n        import numpy as np\n        np.random.seed(seed)\n        if frac_nan is not None:\n            arr = np.random.randn(shape)\n            nan_indices = np.random.choice(arr.size, int(arr.size * frac_nan), replace=False)\n            arr[tuple(nan_indices)] = np.nan\n            return arr\n        else:\n            return np.random.randn(shape)\n\n\n", "CodeBleu_score": 48.63456885300736}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    if chunks is not None:\n        import dask.array as da\n        import numpy as np\n        if frac_nan is not None:\n            r = np.random.RandomState(seed)\n            a = r.rand(*shape)\n            nan_idx = np.where(a < frac_nan)\n            a[nan_idx] = np.nan\n            return da.from_array(a, chunks=chunks)\n        else:\n            return da.random.normal(size=shape, chunks=chunks)\n    else:\n        if frac_nan is not None:\n            r = np.random.RandomState(seed)\n            a = r.rand(*shape)\n            nan_idx = np.where(a < frac_nan)\n            a[nan_idx] = np.nan\n            return a\n        else:\n            return np.random.randn(*shape)\n\n\n", "CodeBleu_score": 39.89732467499496}]}
{"instance_id": "5b57abbbe38b", "generation_result": [{"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n\n", "CodeBleu_score": 90.57611571255117}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n\n", "CodeBleu_score": 90.57611571255117}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError('analyst_price_target')\n    return self._analyst_price_target\n\n\n", "CodeBleu_score": 90.57611571255117}]}
{"instance_id": "592e414671e9", "generation_result": [{"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.financial_statements:\n        raise ValueError(f\"{name} is not a valid financial statement\")\n\n    if timescale not in const.financial_periods:\n        raise ValueError(f\"{timescale} is not a valid period\")\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        logger.error(f\"Error fetching {name} time series: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 29.849896776151486}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n\n    if name not in const.financials_statements:\n        raise ValueError(f\"{name} is not a valid financial statement\")\n\n    if timescale not in const.financials_periods:\n        raise ValueError(f\"{timescale} is not a valid financial period\")\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        self.logger.error(f\"Error creating {name} table: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 30.938566137384367}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n\n    if name not in const.fundamentals_keys:\n        raise ValueError(f\"Invalid financial statement: {name}\")\n\n    if timescale not in const.fundamentals_timescales:\n        raise ValueError(f\"Invalid timescale: {timescale}\")\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        self.logger.error(f\"Error fetching time series: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 34.465351776721484}]}
{"instance_id": "af01d9bae091", "generation_result": [{"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership_data = data.get('ownership', [])\n    ownership_df = pd.DataFrame(ownership_data)\n    if not ownership_df.empty:\n        ownership_df['reportDate'] = pd.to_datetime(ownership_df['reportDate'])\n        ownership_df.rename(columns={'reportDate': 'report_date', 'ownership': 'ownership_data'}, inplace=True)\n        self._mutualfund['ownership'] = ownership_df\n\n", "CodeBleu_score": 22.049814166440388}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data['fundOwnership']\n    if ownership:\n        ownership = ownership['owner']\n        if ownership:\n            ownership = [{\n                'ownerName': owner['ownerName'],\n                'ownerType': owner['ownerType'],\n                'ownerPercentage': owner['ownerPercentage'],\n                'ownerShares': owner['ownerShares'],\n                'ownerSharesValue': owner['ownerSharesValue'],\n                'ownerSharesPercentage': owner['ownerSharesPercentage']\n            } for owner in ownership]\n            self._mutualfund = pd.DataFrame(ownership)\n            if not self._mutualfund.empty:\n                self._mutualfund['reportDate'] = pd.to_datetime(self._mutualfund['reportDate'])\n                self._mutualfund.rename(columns={\n                    'ownerName': 'Name',\n                    'ownerType': 'Type',\n                    'ownerPercentage': 'Percentage',\n                    'ownerShares': 'Shares',\n                    'ownerSharesValue': 'Shares Value',\n                    'ownerSharesPercentage': 'Shares Percentage'\n                }, inplace=True)\n    else:\n        self._mutualfund = pd.DataFrame()\n\n", "CodeBleu_score": 24.792392242382515}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data.get('fundOwnership')\n    if ownership is not None:\n        ownership = ownership.get('ownership')\n        if ownership is not None:\n            ownership = ownership.get('ownershipDetails')\n            if ownership is not None:\n                ownership = ownership.get('ownershipDetail')\n                if ownership is not None:\n                    ownership = [ownership] if isinstance(ownership, dict) else ownership\n                    self._mutualfund = pd.DataFrame(ownership)\n                    self._mutualfund = self._mutualfund.drop('maxAge', axis=1)\n                    if self._mutualfund.empty:\n                        self._mutualfund = None\n                    else:\n                        self._mutualfund['reportDate'] = pd.to_datetime(self._mutualfund['reportDate'], format='%Y-%m-%d')\n                        self._mutualfund.rename(columns={'reportDate': 'Report Date', 'ownershipPercentage': 'Ownership Percentage', 'ownershipType': 'Ownership Type', 'ownershipTypeName': 'Ownership Type Name', 'ownershipTypeId': 'Ownership Type ID'}, inplace=True)\n    else:\n        self._mutualfund = None\n\n\n\n", "CodeBleu_score": 30.24223618464917}]}
{"instance_id": "2b5c6f1253db", "generation_result": [{"code": "def currency(self)\n\t\n    if hasattr(self, '_currency'):\n        return self._currency\n    else:\n        self.history(start='2000-01-01', end='2000-01-02', auto_adjust=False)\n        return self._currency", "CodeBleu_score": 29.407671238877125}, {"code": "def currency(self)\n\t\n    if hasattr(self, '_currency'):\n        return self._currency\n    else:\n        if self.proxy is None:\n            metadata = self.get_metadata()\n        else:\n            metadata = self.get_metadata(self.proxy)\n        self._currency = metadata['currency']\n        return self._currency", "CodeBleu_score": 43.239283498972306}, {"code": "def currency(self)\n\t\n    if self.currency:\n        return self.currency\n    else:\n        self.metadata = self.get_metadata()\n        self.currency = self.metadata['currency']\n        return self.currency\n\n\n", "CodeBleu_score": 40.366496695401445}]}
{"instance_id": "16b80be60e3b", "generation_result": [{"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(self._proxy, quote_summary_valid_modules)\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n            return self._recommendations\n        try:\n            self._recommendations = self._recommendations[\"finance\"][\"result\"][0][\"recommendationTrend\"][\"trend\"]\n            self._recommendations = pd.DataFrame(self._recommendations)\n            self._recommendations.columns = self._recommendations.iloc[0]\n            self._recommendations = self._recommendations.drop(0)\n        except (KeyError, IndexError) as e:\n            raise YFDataException(f\"Error parsing data: {e}\")\n    return self._recommendations\n\n", "CodeBleu_score": 48.6005265665081}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(proxy=self._data.proxy, modules=['recommendationTrend'])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n            return self._recommendations\n        try:\n            self._recommendations = self._recommendations['finance']['result'][0]['recommendationTrend']\n        except KeyError:\n            raise YFDataException(f'Error parsing recommendations for {self._symbol}')\n    return self._recommendations\n\n", "CodeBleu_score": 49.714068405689666}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(proxy=self._proxy, modules=quote_summary_valid_modules)\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = pd.DataFrame(self._recommendations[\"finance\"][\"result\"][0][\"recommendationTrend\"][\"trend\"])\n            except KeyError:\n                raise YFDataException(\"Error parsing recommendations data\")\n    return self._recommendations\n\n", "CodeBleu_score": 54.84017695490101}]}
{"instance_id": "abaf8c2a3ecc", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise AttributeError(\"Classifier %s has no attribute n_clusters\" %\n                             clf.__class__.__name__)\n    if cluster_ranges is None:\n        cluster_ranges = range(1, clf.n_clusters + 1)\n    scores = []\n    times = []\n    for n_clusters in cluster_ranges:\n        clf.set_params(n_clusters=n_clusters)\n        t0 = time()\n        clf.fit(X)\n        duration = time() - t0\n        scores.append(clf.inertia_)\n        times.append(duration)\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n    ax.plot(cluster_ranges, scores, 'b*-', markersize=10)\n    ax.set_xlabel('n_clusters', fontsize=text_fontsize)\n    ax.set_ylabel('score', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, times, 'r*-', markersize=10)\n        ax2.set_ylabel('time (s)', fontsize=text_fontsize)\n        ax2.set_title(title + \" with computation time (lower is better)\",\n                      fontsize=title_fontsize)\n        ax2.grid(False)\n    return ax", "CodeBleu_score": 52.76299494925338}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise AttributeError(\"Classifier object has no attribute 'n_clusters'\")\n    if cluster_ranges is None:\n        cluster_ranges = [2, 10]\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n    else:\n        fig = ax.figure\n    if show_cluster_time:\n        ax2 = ax.twinx()\n    else:\n        ax2 = None\n    cluster_range = range(cluster_ranges[0], cluster_ranges[1] + 1)\n    sse = []\n    cluster_times = []\n    for n_clusters in cluster_range:\n        clf.set_params(n_clusters=n_clusters)\n        start_time = time.time()\n        clf.fit(X)\n        end_time = time.time()\n        sse.append(clf.inertia_)\n        cluster_times.append(end_time - start_time)\n    ax.plot(cluster_range, sse, 'b*-')\n    ax.set_xlabel('n_clusters')\n    ax.set_ylabel('SSE')\n    ax.set_title(title, fontsize=title_fontsize)\n    if show_cluster_time:\n        ax2.plot(cluster_range, cluster_times, 'r*-')\n        ax2.set_ylabel('Cluster time (s)')\n    ax.grid()\n    ax.tick_params(axis='both', which='major', labelsize=text_fontsize)\n    ax.tick_params(axis='both', which='minor', labelsize=text_fontsize)\n    if show_cluster_time:\n        ax2.tick_params(axis='both', which='major', labelsize=text_fontsize)\n        ax2.tick_params(axis='both', which='minor', labelsize=text_fontsize)\n    return ax\n\n\n\n\n", "CodeBleu_score": 49.55175505002504}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise AttributeError(\"Classifier %s must have n_clusters attribute\" %\n                             clf.__class__.__name__)\n    if cluster_ranges is None:\n        cluster_ranges = [2, clf.n_clusters + 1]\n    elif not isinstance(cluster_ranges, list):\n        cluster_ranges = [cluster_ranges]\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    else:\n        fig = ax.get_figure()\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Number of clusters\", fontsize=text_fontsize)\n    ax.set_ylabel(\"SSE\", fontsize=text_fontsize)\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.set_ylabel(\"Clustering duration (s)\", fontsize=text_fontsize)\n        ax2.tick_params(axis='y', labelcolor='tab:red')\n    for i, cluster_range in enumerate(cluster_ranges):\n        cluster_range = range(cluster_range[0], cluster_range[1])\n        sse = []\n        cluster_times = []\n        for n_clusters in cluster_range:\n            clf.set_params(n_clusters=n_clusters)\n            t0 = time()\n            clf.fit(X)\n            t1 = time()\n            sse.append(clf.inertia_)\n            cluster_times.append(t1 - t0)\n        ax.plot(cluster_range, sse, label=\"n_clusters = %d\" % cluster_range[-1])\n        if show_cluster_time:\n            ax2.plot(cluster_range, cluster_times, color='tab:red')\n    ax.legend()\n    return ax", "CodeBleu_score": 49.49185667510242}]}
{"instance_id": "8a90815c4ee1", "generation_result": [{"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time.time()\n    clf_ = clone(clf)\n    clf_.set_params(n_clusters=n_clusters)\n    clf_.fit(X)\n    return clf_.score(X), time.time() - start_time\n\n", "CodeBleu_score": 34.5948264176589}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    from time import time\n    start_time = time()\n    clf_ = clone(clf)\n    clf_.set_params(n_clusters=n_clusters)\n    clf_.fit(X)\n    return clf_.score(X), time() - start_time\n\n\n", "CodeBleu_score": 43.339172483497656}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    import time\n    start_time = time.time()\n    clf_ = clf.clone()\n    clf_.set_params(n_clusters=n_clusters)\n    clf_.fit(X)\n    return clf_.score(X), time.time() - start_time\n\n\n", "CodeBleu_score": 32.35617658682554}]}
{"instance_id": "da40bd5dd81a", "generation_result": [{"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('Clusterer object must have fit and fit_predict methods')\n    if not hasattr(clf, 'plot_silhouette'):\n        clf.plot_silhouette = plot_silhouette\n    if not hasattr(clf, 'plot_elbow_curve'):\n        clf.plot_elbow_curve = plot_elbow_curve\n    return clf\n\n", "CodeBleu_score": 14.922349422444478}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, 'fit') or not hasattr(clf, 'fit_predict'):\n        raise TypeError('Invalid clusterer instance')\n    if not hasattr(clf, 'plot_silhouette'):\n        clf.plot_silhouette = plot_silhouette\n    if not hasattr(clf, 'plot_elbow_curve'):\n        clf.plot_elbow_curve = plot_elbow_curve\n    return clf\n\n", "CodeBleu_score": 14.244342519895145}, {"code": "def clustering_factory(clf)\n\t\n    required_methods = ['fit', 'fit_predict']\n    for method in required_methods:\n        if not hasattr(clf, method):\n            raise TypeError(f\"{clf} is not a valid clusterer instance\")\n\n    def plot_silhouette(X, labels, metric='euclidean', ax=None, **kwargs):\n        \"\"\"The function plot_silhouette takes a dataset X, cluster labels labels, a metric metric, and an optional axes object ax.", "CodeBleu_score": 18.5493023595164}]}
{"instance_id": "b8d8ba3c0b1b", "generation_result": [{"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    from sklearn.model_selection import learning_curve\n    from matplotlib import pyplot as plt\n    import numpy as np\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n    if scoring is None:\n        scoring = 'accuracy'\n    train_sizes, train_scores, test_scores = learning_curve(clf, X, y, cv=cv,\n                                                            train_sizes=train_sizes,\n                                                            n_jobs=n_jobs,\n                                                            scoring=scoring)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score\")\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n    return ax\n\n\n", "CodeBleu_score": 69.11465342602351}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    from sklearn.model_selection import learning_curve\n    from matplotlib import pyplot as plt\n    import numpy as np\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score\")\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    # Plot learning curve\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n\n    # Add legend\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 74.50786772762063}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    import matplotlib.pyplot as plt\n    from sklearn.model_selection import learning_curve\n    import numpy as np\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    if train_sizes is None:\n        train_sizes = np.linspace(0.1, 1.0, 5)\n\n    train_sizes, train_scores, test_scores = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel(\"Training examples\")\n    ax.set_ylabel(\"Score\")\n\n    ax.grid()\n\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    return ax\n", "CodeBleu_score": 83.11878267724069}]}
{"instance_id": "e6e76eb35945", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"Classifier must have n_clusters attribute\")\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n    classifiers = [type(clf)(n_clusters=n) for n in cluster_ranges]\n    scores = [abs(clf.fit(X).score(X)) for clf in classifiers]\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.plot(cluster_ranges, scores, 'bx-')\n    ax.grid(True)\n    ax.set_xlabel('Number of clusters')\n    ax.set_ylabel('Score')\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n    return ax\n\n\n\n\n", "CodeBleu_score": 50.451390098506636}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('clf must have an n_clusters attribute')\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n    classifiers = [type(clf)(n_clusters=n) for n in cluster_ranges]\n    scores = [abs(clf.fit(X).score(X)) for clf in classifiers]\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.plot(cluster_ranges, scores, 'bo-')\n    ax.grid(True)\n    ax.set_xlabel('Number of clusters')\n    ax.set_ylabel('Score')\n    ax.set_title(title, fontsize=title_fontsize)\n    return ax\n\n\n", "CodeBleu_score": 48.31313291663696}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError('Classifier must have n_clusters attribute')\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    clfs = [type(clf)(n_clusters=n) for n in cluster_ranges]\n\n    scores = [abs(clf.fit(X).score(X)) for clf in clfs]\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.grid(True)\n    ax.plot(cluster_ranges, scores, '.-')\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Score', fontsize=text_fontsize)\n\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.980447697503195}]}
{"instance_id": "6f4530c8a20f", "generation_result": [{"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    import matplotlib.pyplot as plt\n    from sklearn.decomposition import PCA\n    from sklearn.preprocessing import StandardScaler\n\n    # Standardize the data\n    X_std = StandardScaler().fit_transform(X)\n\n    # Apply PCA to the data\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X_std)\n\n    # Set up the plot\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('PC 1', fontsize=text_fontsize)\n    ax.set_ylabel('PC 2', fontsize=text_fontsize)\n\n    # Plot the data points\n    colors = ['b', 'r']\n    for color, label in zip(colors, [0, 1]):\n        ax.scatter(X_pca[y == label, 0], X_pca[y == label, 1], c=color, label=label)\n\n    # Add a legend\n    ax.legend(loc='best', fontsize=text_fontsize)\n\n    return ax\n\n\n", "CodeBleu_score": 49.89181511552644}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from sklearn.decomposition import PCA\n    from matplotlib import pyplot as plt\n    import numpy as np\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y, cmap=cmap, edgecolor='none', alpha=0.5,\n               linewidth=0.5)\n    ax.set_xlabel('PC1', fontsize=text_fontsize)\n    ax.set_ylabel('PC2', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n    return ax\n\n\n", "CodeBleu_score": 44.24008799265569}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from sklearn.decomposition import PCA\n    import matplotlib.pyplot as plt\n    pca = PCA(n_components=2)\n    X_r = pca.fit(X).transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.scatter(X_r[:, 0], X_r[:, 1], c=y, cmap=cmap, edgecolor='k', s=50)\n    ax.set_xlabel('First principal component', fontsize=text_fontsize)\n    ax.set_ylabel('Second principal component', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.legend(loc='best', shadow=False, scatterpoints=1)\n    return ax\n\n\n", "CodeBleu_score": 41.485811346123214}]}
{"instance_id": "e7c2775d024c", "generation_result": [{"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n    ax.add_patch(clip1)\n    ax.add_patch(clip2)\n\n    Y1 = np.random.uniform(0, 1, 16)\n    Y2 = np.random.uniform(0, 1, 16)\n\n    ax.bar(np.arange(16), Y1, color='gray', edgecolor='black', clip_on=True)\n    ax.bar(np.arange(16), Y2, color='red', edgecolor='black', clip_on=True)\n\n    ax.bar(np.arange(16), Y1, color='gray', edgecolor='black', clip_path=clip1,\n           clip_on=True)\n    ax.bar(np.arange(16), Y2, color='red', edgecolor='black', clip_path=clip2,\n           clip_on=True)\n\n    ax.set_xlim(-1, 16)\n    ax.text(0.5, 1.05, 'Bar plot',\n            horizontalalignment='center',\n            verticalalignment='bottom',\n            transform=ax.transAxes,\n            fontsize=16)\n    ax.text(0.5, -0.05, 'ax.bar()',\n            horizontalalignment='center',\n            verticalalignment='top',\n            transform=ax.transAxes,\n            fontsize=16,\n            fontfamily='monospace')\n\n", "CodeBleu_score": 40.11123054208454}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n    Y1 = np.random.uniform(0.1, 1, 16)\n    Y2 = np.random.uniform(0.1, 1, 16)\n\n    ax.bar(np.arange(16), Y1, color='gray', edgecolor='None',\n           clip_path=clip1)\n    ax.bar(np.arange(16), Y2, color='gray', edgecolor='None',\n           alpha=0.5, clip_path=clip2)\n\n    ax.bar(np.arange(16), Y1, color='red', edgecolor='None',\n           clip_path=clip2)\n    ax.bar(np.arange(16), Y2, color='red', edgecolor='None',\n           alpha=0.5, clip_path=clip1)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0, 1.05, \"Bar plot\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", fontsize=18,\n            bbox=dict(boxstyle=\"square\", fc=\"w\"))\n\n    ax.text(0, 1.05, \"ax.bar()\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", fontsize=18,\n            bbox=dict(boxstyle=\"square\", fc=\"w\"),\n            color=\"b\", fontdict={\"fontfamily\": \"monospace\"})\n\n", "CodeBleu_score": 39.130983141217044}, {"code": "def barplot(ax)\n\t\n\n    clip1, clip2 = clip_path(ax)\n    ax.add_artist(clip1)\n    ax.add_artist(clip2)\n\n    Y1 = np.random.uniform(0, 1, 16)\n    Y2 = np.random.uniform(0, 1, 16)\n\n    ax.bar(np.arange(16), Y1, color='gray', zorder=10,\n           clip_on=True, clip_path=clip1)\n    ax.bar(np.arange(16), Y2, color='gray', zorder=10,\n           alpha=0.5, clip_on=True, clip_path=clip2)\n\n    ax.bar(np.arange(16), Y1, color='red', zorder=10,\n           clip_on=True, clip_path=clip1)\n    ax.bar(np.arange(16), Y2, color='red', zorder=10,\n           alpha=0.5, clip_on=True, clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0, 1.05, \"Bar plot\",\n            ha='center', va='bottom', transform=ax.transAxes)\n    ax.text(0, 0.9, \"ax.bar()\",\n            ha='center', va='bottom', transform=ax.transAxes,\n            color='blue', fontweight='bold', fontfamily='monospace')\n\n", "CodeBleu_score": 34.36277123699032}]}
{"instance_id": "0ec1d146a32b", "generation_result": [{"code": "def split(n_segment)\n\t\n\n    # Calculate the width of each segment\n    width = (n_segment - 1) / n_segment\n\n    # Calculate the padding between segments\n    padding = width / 2\n\n    # Calculate the starting (X0) and ending (X1) positions of each segment\n    x0 = np.arange(0, n_segment) * width + padding\n    x1 = x0 + width\n\n    return x0, x1\n\n\n\n", "CodeBleu_score": 23.54339937387485}, {"code": "def split(n_segment)\n\t\n    width = 1 / n_segment\n    padding = width / 2\n    X0 = np.arange(0, 1, width)\n    X1 = np.arange(padding, 1, width)\n    return X0, X1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.15366189092536}, {"code": "def split(n_segment)\n\t\n    # Compute the width of each segment\n    width = (n_segment - 1) / n_segment\n    # Compute the padding between segments\n    padding = width / 2\n    # Compute the starting and ending positions of each segment\n    X0 = np.arange(n_segment) * width + padding\n    X1 = X0 + width\n    return X0, X1\n\n\n", "CodeBleu_score": 30.067398984436217}]}
{"instance_id": "604a3e93ac0d", "generation_result": [{"code": "def pixelated_text(dpi=100)\n\t\n    fig = plt.figure(figsize=(1, 1))\n    canvas = fig.canvas\n    ax = fig.add_subplot(111)\n    ax.text(0.5, 0.5, 'a', fontsize=75, horizontalalignment='center', verticalalignment='center')\n    ax.axis('off')\n    canvas.draw()\n    data = np.frombuffer(canvas.tostring_rgb(), dtype='uint8').reshape(canvas.get_width_height()[::-1] + (3,))\n    data = data.reshape((dpi, dpi, 3))\n    data = np.roll(data, 1, axis=-1)\n    return data\n\n\n", "CodeBleu_score": 47.24567596852417}, {"code": "def pixelated_text(dpi=100)\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n    \n    fig, ax = plt.subplots(figsize=(1, 1))\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.axis('off')\n    fig.canvas.draw()\n    \n    data = np.frombuffer(fig.canvas.tostring_rgb(), dtype=np.uint8).reshape(fig.canvas.get_width_height()[::-1] + (3,))\n    \n    data = data.reshape((-1, dpi, 4))\n    data = np.roll(data, 1, axis=2)\n    \n    return data\n\n\n", "CodeBleu_score": 48.83347618937325}, {"code": "def pixelated_text(dpi=100)\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n    fig = plt.figure(figsize=(1, 1), dpi=dpi)\n    canvas = fig.canvas\n    ax = fig.add_subplot(111)\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n    ax.set_axis_off()\n    canvas.draw()\n    data = np.frombuffer(canvas.tostring_rgb(), dtype='uint8').reshape(canvas.get_width_height()[::-1] + (3,))\n    data = np.roll(data, 3, axis=2)\n    return data\n\n\n", "CodeBleu_score": 51.8061536705851}]}
{"instance_id": "2a7fc7d560ea", "generation_result": [{"code": "def curve()\n\t\n    n = random.randint(2, 6)\n    centers = np.random.uniform(0, 1, n)\n    widths = np.random.uniform(0.1, 0.5, n)\n    scales = np.random.uniform(0.1, 0.5, n)\n    widths /= np.sum(widths)\n    scales /= np.sum(scales)\n    curve = np.zeros(100)\n    for i in range(n):\n        curve += np.exp(-((np.arange(100) - centers[i]) ** 2) / (2 * widths[i] ** 2)) * scales[i]\n    return curve\n\n", "CodeBleu_score": 37.434071214091034}, {"code": "def curve()\n\t\n    import numpy as np\n    import random\n    import math\n\n    # Generate a random number of components\n    num_components = random.randint(2, 5)\n\n    # Initialize an array of zeros to store the composite curve\n    composite_curve = np.zeros(100)\n\n    # Generate random centers, widths, and scales for each component\n    centers = np.random.uniform(size=num_components)\n    widths = np.random.uniform(size=num_components)\n    scales = np.random.uniform(size=num_components)\n\n    # Normalize the widths and scales to ensure they sum to specific values\n    widths /= np.sum(widths)\n    scales /= np.sum(scales)\n\n    # Iteratively add scaled Gaussian components to the composite curve\n    for i in range(num_components):\n        component = np.exp(-((np.arange(100) - centers[i]) ** 2) / (2 * widths[i] ** 2)) * scales[i]\n        composite_curve += component\n\n    # Return the resulting composite curve\n    return composite_curve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.907722135198632}, {"code": "def curve()\n\t\n    import numpy as np\n    import random\n    import math\n    def gaussian(x, mu, sigma):\n        \"\"\"The function gaussian calculates the Gaussian probability density function (PDF) for a given x value, mean (mu), and standard deviation (sigma). It returns the PDF value for the given x, mu, and sigma.", "CodeBleu_score": 7.273600348722295}]}
{"instance_id": "be694335ebfc", "generation_result": [{"code": "def difference(derivative, accuracy=1)\n\t\n    order = derivative + 1\n    radius = accuracy / order\n    points = np.linspace(-radius, radius, order)\n    vandermonde = np.vander(points, increasing=True)\n    inverse = np.linalg.inv(vandermonde)\n    coefficients = inverse[0, :] * np.math.factorial(order - 1)\n    return coefficients, points\n\n\n", "CodeBleu_score": 42.51215569588142}, {"code": "def difference(derivative, accuracy=1)\n\t\n    order = derivative + 1\n    radius = 1 / accuracy\n    points = np.linspace(-radius, radius, order)\n    vandermonde = np.vander(points, increasing=True)\n    coefficients = np.linalg.inv(vandermonde)[0]\n    return coefficients * np.math.factorial(derivative), points\n\n\n", "CodeBleu_score": 40.34794230501968}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative += 1\n    radius = accuracy / derivative\n    points = np.arange(-derivative + 1, derivative) * radius\n    vandermonde = np.vander(points, increasing=True)\n    inverse = np.linalg.inv(vandermonde)\n    coefficients = inverse[0] / np.math.factorial(derivative - 1)\n    return coefficients, points\n\n\n\n", "CodeBleu_score": 46.1894979461683}]}
{"instance_id": "fa3fb47f33fa", "generation_result": [{"code": "def interpolate(X, Y, T)\n\t\n    # Calculate the distances between consecutive points\n    distances = np.sqrt((X[1:] - X[:-1]) ** 2 + (Y[1:] - Y[:-1]) ** 2)\n\n    # Calculate the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    interpolated_X = np.interp(T, cumulative_distances, X)\n    interpolated_Y = np.interp(T, cumulative_distances, Y)\n\n    # Return the interpolated X and Y coordinates along with the total distance covered by the original coordinates\n    return interpolated_X, interpolated_Y, cumulative_distances[-1]\n\n\n", "CodeBleu_score": 22.598578747973924}, {"code": "def interpolate(X, Y, T)\n\t\n    # Calculate the distances between consecutive points\n    distances = np.sqrt((X[1:] - X[:-1])**2 + (Y[1:] - Y[:-1])**2)\n    # Calculate the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interpolated = np.interp(T, cumulative_distances, X)\n    Y_interpolated = np.interp(T, cumulative_distances, Y)\n    # Return the interpolated X and Y coordinates along with the total distance covered by the original coordinates\n    return X_interpolated, Y_interpolated, cumulative_distances[-1]\n\n\n\n\n", "CodeBleu_score": 20.928349522918165}, {"code": "def interpolate(X, Y, T)\n\t\n    # Calculate the distances between consecutive points\n    distances = np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2)\n    # Calculate the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n    # Normalize the cumulative distances\n    cumulative_distances /= cumulative_distances[-1]\n    # Interpolate the X and Y coordinates at the positions specified by T\n    interpolated_X = np.interp(T, cumulative_distances, X[:-1])\n    interpolated_Y = np.interp(T, cumulative_distances, Y[:-1])\n    # Calculate the total distance covered by the original coordinates\n    total_distance = cumulative_distances[-1]\n    return interpolated_X, interpolated_Y, total_distance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.20871135265383}]}
{"instance_id": "870a2dad3c66", "generation_result": [{"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None]*1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n", "CodeBleu_score": 71.3527625890938}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None]*1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 71.3527625890938}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None]*1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n", "CodeBleu_score": 71.3527625890938}]}
{"instance_id": "e1a908945acf", "generation_result": [{"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = np.abs(np.ceil(sigma * 3))\n    window_len = window_len if window_len % 2 else window_len + 1\n    return smooth1d(smooth1d(A, window_len).T, window_len).T\n\n", "CodeBleu_score": 14.565953009666668}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = np.abs(np.ceil(sigma * 3))\n    window_len = window_len if window_len % 2 == 1 else window_len + 1\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    A = A.T\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    A = A.T\n    return A\n\n", "CodeBleu_score": 17.496742795726206}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = np.abs(np.round(sigma * 3)) * 2 + 1\n    window_len = window_len if window_len % 2 == 1 else window_len + 1\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    A = A.T\n    A = np.apply_along_axis(smooth1d, 1, A, window_len)\n    A = A.T\n    return A\n\n", "CodeBleu_score": 26.344638370492973}]}
{"instance_id": "94563c54b483", "generation_result": [{"code": "def process_image(self, padded_src, dpi)\n\t\n    ox = self.ox\n    oy = self.oy\n    ox = int(ox * dpi / 25.4)\n    oy = int(oy * dpi / 25.4)\n    padded_src = np.roll(padded_src, ox, axis=1)\n    padded_src = np.roll(padded_src, oy, axis=0)\n    return padded_src", "CodeBleu_score": 25.43072132814962}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox = self.ox\n    oy = self.oy\n    return np.roll(np.roll(padded_src, ox, axis=1), oy, axis=0)", "CodeBleu_score": 21.37803480276374}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox = self.ox * dpi / 25.4\n    oy = self.oy * dpi / 25.4\n    return np.roll(np.roll(padded_src, int(ox), axis=1), int(oy), axis=0)\n\n\n", "CodeBleu_score": 28.25975238234846}]}
{"instance_id": "d71d232872fe", "generation_result": [{"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    mgrid = np.ogrid[tuple(map(slice, shape))]\n    distance = np.sum((mgrid - center) ** 2, axis=0) / width ** 2\n    return np.exp(-0.5 * distance)\n\n\n", "CodeBleu_score": 7.216293446461325}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = tuple(shape)\n    center = tuple(center)\n    width = tuple(width)\n    ndim = len(shape)\n    s = np.zeros(shape)\n    for i in range(ndim):\n        s += np.square((np.arange(shape[i]) - center[i]) / width[i])\n    return np.exp(-0.5 * s)\n\n\n", "CodeBleu_score": 20.675156906886862}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    x = np.arange(shape[0])\n    y = np.arange(shape[1])\n    x, y = np.meshgrid(x, y)\n    center = np.array(center)\n    o = np.atleast_3d(center)\n    r = np.sqrt((x - o[0]) ** 2 + (y - o[1]) ** 2)\n    d = np.exp(-(r ** 2) / (2.0 * width ** 2))\n    return d\n\n", "CodeBleu_score": 12.20135483603938}]}
{"instance_id": "7bbd08c987bc", "generation_result": [{"code": "def stimulus(position, size, intensity)\n\t\n    \n    # Convert polar coordinates to Cartesian coordinates\n    x = np.cos(position[0]) * np.cos(position[1])\n    y = np.sin(position[0]) * np.cos(position[1])\n    z = np.sin(position[1])\n    \n    # Normalize the coordinates\n    x_norm = x / np.sqrt(x**2 + y**2 + z**2)\n    y_norm = y / np.sqrt(x**2 + y**2 + z**2)\n    z_norm = z / np.sqrt(x**2 + y**2 + z**2)\n    \n    # Create a mesh grid representing the spatial domain\n    x_grid, y_grid, z_grid = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n    \n    # Compute the squared Euclidean distance (R) from each point in the grid to the stimulus center\n    R = (x_grid - x_norm)**2 + (y_grid - y_norm)**2 + (z_grid - z_norm)**2\n    \n    # Return the exponential decay function of these distances, scaled by the size parameter\n    return np.exp(-R / size**2) * intensity\n\n\n", "CodeBleu_score": 30.442287861832916}, {"code": "def stimulus(position, size, intensity)\n\t\n    x = np.linspace(-1, 1, 500)\n    y = np.linspace(-1, 1, 500)\n    x, y = np.meshgrid(x, y)\n    x = x - position[0]\n    y = y - position[1]\n    R = np.sqrt(x**2 + y**2)\n    return np.exp(-R**2 / (2 * size**2)) * intensity\n\n\n", "CodeBleu_score": 26.604962593964114}, {"code": "def stimulus(position, size, intensity)\n\t\n    x, y = position\n    x_norm = (x - 0.5) * 2\n    y_norm = (y - 0.5) * 2\n    x_mesh, y_mesh = np.meshgrid(np.linspace(-1, 1, 100), np.linspace(-1, 1, 100))\n    x_mesh_norm = (x_mesh - 0.5) * 2\n    y_mesh_norm = (y_mesh - 0.5) * 2\n    R = np.sqrt((x_mesh_norm - x_norm)**2 + (y_mesh_norm - y_norm)**2)\n    return np.exp(-R**2 / (2 * size**2)) * intensity\n\n\n", "CodeBleu_score": 27.637177691748597}]}
{"instance_id": "2b5806238d5d", "generation_result": [{"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=20, fontweight='bold')\n    ax.set_title('Plot with Text', fontfamily='serif', fontweight='bold')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.71384744665672}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks(np.arange(0, 1, 0.1))\n    ax.set_yticks(np.arange(0, 1, 0.1))\n    ax.set_xlabel('X')\n    ax.set_ylabel('Y')\n    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=12, fontfamily='serif', fontweight='bold')\n    ax.set_title('Plot', fontfamily='serif', fontweight='bold')\n\n\n\n", "CodeBleu_score": 46.773351621391825}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_yticks([0, 0.25, 0.5, 0.75, 1])\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.text(0.5, 0.5, text, ha='center', va='center', fontsize=12, fontfamily='serif', fontweight='bold')\n    ax.set_title('My Plot', fontfamily='serif', fontweight='bold')\n\n\n", "CodeBleu_score": 45.6536325475243}]}
{"instance_id": "0b42aac61e21", "generation_result": [{"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    X = self.check_X(X)\n    Xt = self.transform(X, **kwargs)\n    return self.final_estimator_.predict_cumulative_hazard_function(Xt)\n\n\n", "CodeBleu_score": 20.136834298545853}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    X = self._check_input(X)\n    Xt = X\n    for name, transform in self.named_transformers_.items():\n        Xt = transform.transform(Xt)\n    return self.final_estimator_.predict_cumulative_hazard_function(Xt, **kwargs)\n\n\n", "CodeBleu_score": 44.86139779287551}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    return self.predict_cumulative_hazard_function_\n\n", "CodeBleu_score": 5.853846005293182}]}
{"instance_id": "c8439e4918ad", "generation_result": [{"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    # Transform the input data using the pipeline\n    X_transformed = self.pipeline.transform(X)\n    # Predict the survival function using the transformed data and any additional keyword arguments\n    survival_function = self.pipeline.steps[-1][1].predict_survival_function(X_transformed, **kwargs)\n    return survival_function\n\n\n", "CodeBleu_score": 24.98186011737396}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    X = self.transform(X, **kwargs)\n    return self.pipeline[-1].predict_survival_function(X)", "CodeBleu_score": 17.386430897716586}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    X_transformed = self.transform(X, **kwargs)\n    return self.final_step.predict_survival_function(X_transformed, **kwargs)", "CodeBleu_score": 19.721561829024886}]}
{"instance_id": "216662ca7db4", "generation_result": [{"code": "def _check_success(self, results)\n\t\n    if results['status'] == 'optimal':\n        return\n    elif results['status'] == 'maximum iterations reached':\n        self.logger.warning('Maximum iterations reached.')\n        return\n    elif results['status'] in ('primal infeasible', 'dual infeasible'):\n        raise RuntimeError(f'Solver reported {results[\"status\"]}.')\n    else:\n        raise RuntimeError(f'Solver reported unknown status {results[\"status\"]}.')\n\n\n", "CodeBleu_score": 19.18421316685317}, {"code": "def _check_success(self, results)\n\t\n    if results.success:\n        return\n    if results.status == self.OPTIMAL:\n        return\n    if results.status == self.OPTIMAL_INACCURATE:\n        return\n    if results.status == self.MAXITER_EXCEEDED:\n        self._convergence_warning(results)\n        return\n    if results.status == self.PRIMAL_INFEASIBLE:\n        raise RuntimeError('Optimization failed. The problem is infeasible.')\n    if results.status == self.DUAL_INFEASIBLE:\n        raise RuntimeError('Optimization failed. The problem is unbounded.')\n    raise RuntimeError('Optimization failed. Unknown status: %s' % results.status)\n\n\n", "CodeBleu_score": 27.48205361734341}, {"code": "def _check_success(self, results)\n\t\n    if results.status == self.status.OPTIMAL:\n        return\n    if results.status == self.status.MAX_ITER_REACHED:\n        self._logger.warning('Maximum iterations reached.')\n        return\n    if results.status == self.status.PRIMAL_INFEASIBLE:\n        raise RuntimeError('Primal infeasibility detected.')\n    if results.status == self.status.DUAL_INFEASIBLE:\n        raise RuntimeError('Dual infeasibility detected.')\n    raise RuntimeError('Unknown exit flag: {}'.format(results.status))\n\n\n", "CodeBleu_score": 27.90426036485385}]}
{"instance_id": "1fe2e379fca0", "generation_result": [{"code": "def _decompose(self, P)\n\t\n    # Compute the eigenvalues and eigenvectors of the matrix P\n    eigvals, eigvecs = linalg.eigh(P)\n    # Identify the largest eigenvalue and calculate a condition number\n    largest_eigval = eigvals[-1]\n    cond_num = np.linalg.cond(P)\n    # Check if all eigenvalues are above the negative cutoff\n    if np.all(eigvals > -self.cutoff):\n        # Filter out eigenvalues below the positive cutoff\n        eigvals = eigvals[eigvals > self.cutoff]\n        eigvecs = eigvecs[:, eigvals > self.cutoff]\n        # Normalize the eigenvalues so that the maximum eigenvalue is set to 1\n        eigvals /= largest_eigval\n        # Return the transposed decomposed matrix and the largest eigenvalue\n        return eigvecs.T, largest_eigval\n    else:\n        # If all eigenvalues are below the negative cutoff, return None\n        return None, None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 19.470537758686007}, {"code": "def _decompose(self, P)\n\t\n    # Compute eigenvalues and eigenvectors\n    eigvals, eigvecs = linalg.eigh(P)\n    # Identify the largest eigenvalue\n    largest_eigval = np.max(eigvals)\n    # Compute the condition number\n    condition_number = largest_eigval * P.shape[0] * np.finfo(np.float64).eps\n    # Filter out eigenvalues below the cutoff\n    eigvals = eigvals[eigvals > -condition_number]\n    # Normalize the eigenvalues so that the maximum eigenvalue is set to 1\n    eigvals /= np.max(eigvals)\n    # Compute the transposed decomposed matrix\n    P_decomposed = np.dot(eigvecs, np.diag(eigvals))\n    # Return the transposed decomposed matrix and the largest eigenvalue\n    return P_decomposed.T, largest_eigval\n\n", "CodeBleu_score": 23.961838203434212}, {"code": "def _decompose(self, P)\n\t\n    # Compute the eigenvalues and eigenvectors of the matrix\n    eigvals, eigvecs = linalg.eigh(P)\n    # Identify the largest eigenvalue and calculate a condition number based on this eigenvalue, the shape of P, and machine epsilon\n    max_eigval = max(eigvals)\n    condition_number = max_eigval * P.shape[0] * np.finfo(float).eps\n    # Filter out eigenvalues below the positive cutoff\n    eigvals = eigvals[eigvals > -condition_number]\n    # Normalize the eigenvalues so that the maximum eigenvalue is set to 1\n    eigvals = eigvals / max_eigval\n    # Return the transposed decomposed matrix and the largest eigenvalue\n    return eigvecs.T, max_eigval\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 16.021365495324062}]}
{"instance_id": "20c3f5d05d79", "generation_result": [{"code": "def _update_coef(self, coef, D)\n\t\n    coef = coef.copy()\n    coef[np.abs(coef) < self.threshold] = 0.0\n    coef *= D\n    self.coef_ = coef\n\n\n", "CodeBleu_score": 18.121715796255423}, {"code": "def _update_coef(self, coef, D)\n\t\n    self.coef = coef[np.abs(coef) > self.threshold] * D\n\n", "CodeBleu_score": 18.38357500000819}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef = np.asarray(coef)\n    if coef.ndim != 1:\n        raise ValueError('coef must be a 1D array or column vector')\n    if coef.shape[0] != D.shape[1]:\n        raise ValueError('coef must have the same number of elements as the number of features')\n    coef = np.where(np.abs(coef) > self.tol, coef, 0)\n    self.coef_ = coef * D\n\n\n", "CodeBleu_score": 25.576609643015697}]}
{"instance_id": "37c347d00d35", "generation_result": [{"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    if sample_weight is not None:\n        sample_weight = tf.cast(sample_weight, tf.float32)\n        sample_weight = tf.reshape(sample_weight, (-1, 1))\n    event_type = y_true[:, 0]\n    event_time = y_true[:, 1]\n    event_type = tf.cast(event_type, tf.int32)\n    event_time = tf.cast(event_time, tf.float32)\n    event_type = tf.one_hot(event_type, self.num_classes)\n    event_type = tf.cast(event_type, tf.float32)\n    raw_prediction = tf.cast(raw_prediction, tf.float32)\n    time_diff = tf.math.exp(raw_prediction)\n    time_diff = tf.reduce_sum(event_type * time_diff, axis=1)\n    time_diff = tf.reshape(time_diff, (-1, 1))\n    time_diff = tf.math.log(time_diff)\n    time_diff = tf.cast(time_diff, tf.float32)\n    time_diff = tf.subtract(event_time, time_diff)\n    time_diff = tf.reshape(time_diff, (-1, 1))\n    if sample_weight is not None:\n        time_diff = tf.multiply(time_diff, sample_weight)\n    return -time_diff\n\n", "CodeBleu_score": 37.0706535128065}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    return self._cox_gradient(y_true, raw_prediction, sample_weight)\n\n", "CodeBleu_score": 10.26791552249787}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    (event_type, event_time) = self._get_event_data(y_true, sample_weight)\n    (event_type, event_time) = self._check_event_data(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_shape(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_type(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_range(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_value(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_nan(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_time(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type_time(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type_time_nan(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type_time_nan_unique(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type_time_nan_unique_unique(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_type_time_nan_unique_unique_unique(event_type, event_time)\n    (event_type, event_time) = self._check_event_data_unique_", "CodeBleu_score": 11.48269485578747}]}
{"instance_id": "6be432d27e52", "generation_result": [{"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if np.all(np.isfinite(X)):\n            return None\n        else:\n            raise ValueError(\n                \"Input contains NaN, infinity or a value too large for \"\n                \"dtype('float64').\"\n            )\n    if estimator_name is None:\n        estimator_name = self.__class__.__name__\n    if hasattr(self, \"_missing_values_mask\"):\n        missing_values_mask = self._missing_values_mask\n    else:\n        missing_values_mask = np.zeros(X.shape[1], dtype=bool)\n    if hasattr(self, \"_n_samples_seen\"):\n        n_samples_seen = self._n_samples_seen\n    else:\n        n_samples_seen = 0\n    if n_samples_seen == 0:\n        with np.errstate(over=\"ignore\"):\n            finite_sum = np.sum(X, axis=0)\n        if np.any(~np.isfinite(finite_sum)):\n            raise ValueError(\n                f\"{estimator_name} does not support missing values in \"\n                \"datasets with n_samples == 1. Consider using a different \"\n                \"estimator.\"\n            )\n        else:\n            return None\n    with np.errstate(over=\"ignore\"):\n        finite_sum = np.sum(X, axis=0)\n    if np.any(~np.isfinite(finite_sum)):\n        missing_values_mask |= np.logical_not(np.isfinite(finite_sum))\n    if np.any(np.isnan(finite_sum)):\n        missing_values_mask |= np.isnan(finite_sum)\n    if np.any(missing_values_mask):\n        return missing_values_mask\n    else:\n        return None\n\n", "CodeBleu_score": 39.240200857289395}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self.support_missing_values(X):\n        if np.all(np.isfinite(X)):\n            return None\n        else:\n            raise ValueError(\n                f\"{estimator_name} does not support missing values in the input matrix\"\n            )\n\n    # If the sum is not finite, there are infinite elements in X\n    with np.errstate(over=\"ignore\"):\n        finite_sum = np.sum(X, axis=0)\n\n    if not np.all(np.isfinite(finite_sum)):\n        # Raise an error for any infinite elements in X\n        raise ValueError(\n            f\"{estimator_name} does not support infinite values in the input matrix\"\n        )\n\n    # If the sum is finite and not NaN, there are no missing values\n    if not np.any(np.isnan(finite_sum)):\n        return None\n\n    # Otherwise, there are missing values in some features\n    return np.isnan(finite_sum)\n\n", "CodeBleu_score": 37.70854866277353}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if not np.all(np.isfinite(X)):\n            raise ValueError(\n                \"The estimator %s does not support missing values. \"\n                \"Please provide a dataset without missing values.\" % estimator_name\n            )\n        return None\n    if np.isnan(np.sum(X)):\n        raise ValueError(\n            \"The estimator %s does not support missing values. \"\n            \"Please provide a dataset without missing values.\" % estimator_name\n        )\n    if np.isfinite(np.sum(X)):\n        return None\n    raise ValueError(\n        \"The estimator %s does not support missing values. \"\n        \"Please provide a dataset without missing values.\" % estimator_name\n    )\n\n\n", "CodeBleu_score": 26.953516496229906}]}
{"instance_id": "dc5bda895a07", "generation_result": [{"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._check_low_memory(\"predict_survival_function\")\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n    pred = self.tree_.predict(X)[..., 1]\n    if return_array:\n        return pred\n    else:\n        return _array_to_step_function(self.unique_times_, pred)\n\n", "CodeBleu_score": 74.78058994001788}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    self._check_low_memory(\"predict_survival_function\")\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n    pred = self.tree_.predict(X)\n    if return_array:\n        return pred[..., 1]\n    else:\n        unique_times = np.unique(self.event_times_)\n        return _array_to_step_function(unique_times, pred[..., 1])\n\n", "CodeBleu_score": 72.08645506322772}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    if self.low_memory:\n        check_is_fitted(self, \"tree_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        pred = self.tree_.predict(X)\n        return pred[..., 1]\n\n    if return_array:\n        return self.predict_cumulative_hazard_function(X, check_input, return_array=True)\n\n    chf = self.predict_cumulative_hazard_function(X, check_input, return_array=True)\n    return _array_to_step_function(self.event_times_, chf[:, self.is_event_time_])\n\n    ", "CodeBleu_score": 66.66498152554063}]}
{"instance_id": "84ae915b5933", "generation_result": [{"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y)\n    X, y = check_estimator_X_y(self, X, y)\n\n    X = np.asarray(X, dtype=np.float64)\n    y = np.asarray(y, dtype=np.float64)\n\n    if X.shape[0] < self.min_samples:\n        raise ValueError(\"Number of samples must be at least %d, but got %d\" % (self.min_samples, X.shape[0]))\n\n    if self.center:\n        self.feature_means_ = X.mean(axis=0)\n        X = X - self.feature_means_\n\n    if self.scale:\n        self.feature_scales_ = X.std(axis=0)\n        X = X / self.feature_scales_\n\n    # sort by descending survival time\n    idx = np.argsort(y[:, 1])[::-1]\n    X = np.asfortranarray(X[idx])\n    y = np.asfortranarray(y[idx])\n    return X, y\n\n\n", "CodeBleu_score": 28.8134173108879}, {"code": "def _pre_fit(self, X, y)\n\t\n    X = np.asarray(X, dtype=np.float64)\n    y = np.asarray(y, dtype=np.float64)\n    if len(y) < self.min_samples:\n        raise ValueError(\"Minimum number of samples is {0}\".format(self.min_samples))\n    if len(y) != len(X):\n        raise ValueError(\"Number of samples in X and y must be the same.\")\n    if (y < 0).any():\n        raise ValueError(\"Survival time must be non-negative.\")\n    if (y == 0).any():\n        raise ValueError(\"Survival time must be non-zero.\")\n    if (y == np.inf).any():\n        raise ValueError(\"Survival time must be finite.\")\n    if (y != y).any():\n        raise ValueError(\"Survival time must be finite.\")\n    if (X < 0).any():\n        raise ValueError(\"Feature matrix must be non-negative.\")\n    if (X == np.inf).any():\n        raise ValueError(\"Feature matrix must be finite.\")\n    if (X != X).any():\n        raise ValueError(\"Feature matrix must be finite.\")\n    if self.scale:\n        self.feature_means_ = X.mean(axis=0)\n        X -= self.feature_means_\n    if self.normalize:\n        self.feature_scales_ = X.std(axis=0)\n        X /= self.feature_scales_\n    event_numbers = np.ones(len(y), dtype=np.int64)\n    event_numbers[y == np.inf] = 0\n    y = y.astype(np.float64)\n    y[y == np.inf] = 0\n    y = y.astype(np.float64)\n    y = y.ravel()\n    X = np.asfortranarray(X)\n    y = np.asfortranarray(y)\n    event_numbers = np.asfortranarray(event_numbers)\n    return X, event_numbers, y, self.feature_means_, self", "CodeBleu_score": 25.66290608039854}, {"code": "def _pre_fit(self, X, y)\n\t\n    # Validate input data\n    if X.shape[0] < self.min_samples:\n        raise ValueError('Number of samples must be at least %d' % self.min_samples)\n    if y.shape[0] < self.min_samples:\n        raise ValueError('Number of samples must be at least %d' % self.min_samples)\n    # Convert input data to float64\n    X = X.astype(np.float64)\n    y = y.astype(np.float64)\n    # Separate survival events and times\n    events = y[:, 0].astype(np.int32)\n    times = y[:, 1].astype(np.float64)\n    # Center the feature matrix\n    if self.center:\n        X -= X.mean(axis=0)\n    # Normalize the feature matrix\n    if self.scale:\n        X /= X.std(axis=0)\n    # Sort the data in descending order based on survival time\n    indices = np.argsort(-times)\n    X = X[indices, :]\n    events = events[indices]\n    times = times[indices]\n    # Convert the sorted data to Fortran-contiguous arrays\n    X = np.asfortranarray(X)\n    events = np.asfortranarray(events)\n    times = np.asfortranarray(times)\n    # Return the processed feature matrix, event numbers, survival times, feature means, and scales\n    return X, events, times, X.mean(axis=0), X.std(axis=0)\n\n\n", "CodeBleu_score": 31.700568009297843}]}
{"instance_id": "c70bb013f85f", "generation_result": [{"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if not isinstance(self.n_alphas, int) or self.n_alphas <= 0:\n            raise ValueError(\"n_alphas must be a positive integer\")\n        self.alphas = np.linspace(self.alpha_min, self.alpha_max, self.n_alphas)\n        self.alphas_created = True\n    else:\n        self.alphas = np.array(self.alphas)\n        if self.alphas.ndim != 1:\n            raise ValueError(\"alphas must be a 1D array\")\n        if not np.all(np.isfinite(self.alphas)):\n            raise ValueError(\"alphas must be finite\")\n        if not np.all(self.alphas >= 0):\n            raise ValueError(\"alphas must be non-negative\")\n        self.alphas_created = False\n    return self.alphas, self.alphas_created\n\n\n", "CodeBleu_score": 41.73662367843303}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        self.alphas = np.linspace(0, 1, self.n_alphas)\n        new_path = True\n    else:\n        if not isinstance(self.alphas, np.ndarray):\n            self.alphas = np.array(self.alphas)\n        if self.alphas.ndim != 1:\n            raise ValueError(\"alphas must be a 1D array\")\n        if np.any(~np.isfinite(self.alphas)):\n            raise ValueError(\"alphas must be finite\")\n        if np.any(self.alphas < 0):\n            raise ValueError(\"alphas must be non-negative\")\n        new_path = False\n    return self.alphas, new_path", "CodeBleu_score": 33.443106610851274}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if self.num_alphas <= 0:\n            raise ValueError(\"The number of alphas must be a positive integer\")\n        self.alphas = np.linspace(0, 1, self.num_alphas)\n        self.alphas_created = True\n    else:\n        self.alphas = np.asarray(self.alphas).ravel()\n        if len(self.alphas) != self.num_alphas:\n            raise ValueError(\"The number of alphas must be equal to the length of the alphas array\")\n        if not np.all(np.isfinite(self.alphas)):\n            raise ValueError(\"The alphas array must be finite\")\n        if not np.all(self.alphas >= 0):\n            raise ValueError(\"The alphas array must be non-negative\")\n        self.alphas_created = False\n    return self.alphas, self.alphas_created\n\n\n", "CodeBleu_score": 38.47708430401592}]}
{"instance_id": "7b54a0554ba4", "generation_result": [{"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_arrays(event, time)\n    validate_times(time, event)\n\n    times, n_events, n_at_risk, _ = _compute_counts(event, time)\n\n    cum_hazard = np.cumsum(n_events / n_at_risk)\n\n    return times, cum_hazard\n\n", "CodeBleu_score": 41.386067654457136}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    # check_consistent_length(event, time)\n    event = np.asarray(event, dtype=bool)\n    time = np.asarray(time, dtype=float)\n    n_samples = event.shape[0]\n\n    if time.ndim != 1:\n        raise ValueError(\"time must be a 1-dimensional array\")\n\n    if n_samples != time.shape[0]:\n        raise ValueError(\n            \"event and time must have the same length; \"\n            \"got %d and %d\" % (n_samples, time.shape[0])\n        )\n\n    order = np.argsort(time, kind=\"mergesort\")\n    times, n_events, n_at_risk, n_censored = _compute_counts(event, time, order)\n\n    cum_hazard = np.cumsum(n_events / n_at_risk)\n\n    return times, cum_hazard\n\n", "CodeBleu_score": 34.67060798420054}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event = np.asarray(event)\n    time = np.asarray(time)\n\n    if event.ndim != 1:\n        raise ValueError(\"event array must be 1-dimensional\")\n\n    if time.ndim != 1:\n        raise ValueError(\"time array must be 1-dimensional\")\n\n    if event.shape[0] != time.shape[0]:\n        raise ValueError(\"event and time arrays must have the same length\")\n\n    times, n_events, n_at_risk, _ = _compute_counts(event, time)\n    cum_haz = np.cumsum(n_events / n_at_risk)\n\n    return times, cum_haz\n\n", "CodeBleu_score": 47.343680866982794}]}
{"instance_id": "35af806300cc", "generation_result": [{"code": "def ipc_weights(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    check_consistent_length(event, time)\n\n    if np.all(event == 1):\n        return np.ones(len(event))\n\n    _, prob_survival = kaplan_meier_estimator(event, time, reverse=True)\n\n    idx = np.searchsorted(prob_survival, time)\n    weights = prob_survival[idx - 1]\n    weights[weights == 0] = 1\n    return 1 / weights\n\n", "CodeBleu_score": 38.87706452951388}, {"code": "def ipc_weights(event, time)\n\t\n    event, time_enter, time_exit = check_y_survival(event, None, time, allow_all_censored=True)\n    check_consistent_length(event, time_exit)\n\n    if np.all(event == 1):\n        return np.ones(event.shape[0])\n\n    _, prob_survival, _ = kaplan_meier_estimator(event, time_exit, reverse=True)\n\n    event_times = np.unique(time_exit[event == 1])\n    event_times_idx = np.searchsorted(prob_survival, event_times)\n    event_times_idx = np.clip(event_times_idx, 0, len(prob_survival) - 1)\n    event_times_survival = prob_survival[event_times_idx]\n    event_times_survival = np.clip(event_times_survival, 0, 1)\n    weights = 1 / event_times_survival\n\n    return weights\n\n", "CodeBleu_score": 39.40824585350649}, {"code": "def ipc_weights(event, time)\n\t\n\n    # Check if all events have occurred\n    if np.all(event == 1):\n        return np.ones(len(event))\n\n    # Compute the Kaplan-Meier estimator for the event and time data in reverse\n    km_estimator = kaplan_meier_estimator(event, time, reverse=True)\n\n    # Find the index positions of event times within the unique time values\n    event_times = np.unique(time[event == 1])\n    index_positions = np.searchsorted(km_estimator[0], event_times)\n\n    # Retrieve the corresponding survival probabilities\n    survival_probs = km_estimator[1][index_positions]\n\n    # Ensure all retrieved probabilities are positive\n    survival_probs = np.maximum(survival_probs, 1e-10)\n\n    # Create a weights array and assign inverse probabilities to events\n    weights = np.zeros(len(event))\n    weights[event == 1] = 1 / survival_probs\n\n    return weights\n\n", "CodeBleu_score": 39.22055895754261}]}
{"instance_id": "72b19985ea11", "generation_result": [{"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    elif isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n    elif isinstance(dfs, list):\n        pass\n    else:\n        raise ValueError(f\"Invalid input type: {type(dfs)}\")\n    dfs = [df if isinstance(df, BaseConnector) else self.from_pandas(df) for df in dfs]\n    return dfs\n\n\n", "CodeBleu_score": 16.805460255041037}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    if not isinstance(dfs, list):\n        raise ValueError(\n            \"dfs must be a pandas DataFrame, modin DataFrame, polars DataFrame, or a list of such objects.\"\n        )\n    if len(dfs) == 0:\n        raise ValueError(\"dfs must not be empty.\")\n    for i, df in enumerate(dfs):\n        if isinstance(df, pd.DataFrame):\n            dfs[i] = PandasConnector(df)\n        elif isinstance(df, md.DataFrame):\n            dfs[i] = ModinConnector(df)\n        elif isinstance(df, pl.DataFrame):\n            dfs[i] = PolarsConnector(df)\n        elif isinstance(df, BaseConnector):\n            pass\n        else:\n            raise ValueError(\n                \"dfs must be a pandas DataFrame, modin DataFrame, polars DataFrame, or a list of such objects.\"\n            )\n    return dfs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.026779247215885}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    elif isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n    elif isinstance(dfs, list):\n        if all(isinstance(df, pd.DataFrame) for df in dfs):\n            dfs = [pd.DataFrameConnector(df) for df in dfs]\n        elif all(isinstance(df, BaseConnector) for df in dfs):\n            pass\n        else:\n            raise ValueError(\n                \"All items in the list must be pandas dataframes or connector objects.\"\n            )\n    else:\n        raise ValueError(\"Invalid input type. Please provide a list of dataframes.\")\n    return dfs", "CodeBleu_score": 26.02113715746454}]}
{"instance_id": "cf22fb696e90", "generation_result": [{"code": "def execute(self) -> pd.DataFrame\n\t\n    if self.data is not None:\n        return self.data\n\n    cached = self._cached()\n    if cached is not None:\n        self.data = pd.read_csv(cached)\n        return self.data\n\n    self.data = self._fetch_data()\n    return self.data\n\n", "CodeBleu_score": 47.28557839369287}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    if isinstance(self.data, pd.DataFrame):\n        return self.data\n\n    cached_data = self._cached()\n    if cached_data is not None:\n        self.data = pd.read_csv(cached_data)\n        return self.data\n\n    cached_data = self._cached(include_additional_filters=True)\n    if cached_data is not None:\n        self.data = pd.read_csv(cached_data)\n        return self.data\n\n    self.data = self._fetch_data()\n    return self.data\n\n", "CodeBleu_score": 51.82571279606128}, {"code": "def execute(self) -> pd.DataFrame\n\t\n\n    if self._data is not None:\n        return self._data\n\n    cached_data = self._cached()\n    if cached_data is not None:\n        self._data = pd.read_csv(cached_data)\n        return self._data\n\n    self._data = self._fetch_data()\n    return self._data\n\n", "CodeBleu_score": 47.562978383930044}]}
{"instance_id": "21df5ecea95f", "generation_result": [{"code": "def column_hash(self)\n\t\n    if isinstance(self._instance, pd.DataFrame):\n        df = self._instance\n    else:\n        df = self.execute()\n\n    formula = self._build_formula()\n    column_string = \"|\".join(df.columns)\n    hash_string = f\"{column_string}|{formula}\"\n    return hashlib.sha256(hash_string.encode()).hexdigest()\n\n", "CodeBleu_score": 43.11412651096731}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self._fetch_data()\n    column_names = self._instance.columns.tolist()\n    column_names.sort()\n    column_names_string = \"|\".join(column_names)\n    formula = self._build_formula()\n    return hashlib.sha256(\n        f\"{column_names_string}{formula}\".encode(\"utf-8\")\n    ).hexdigest()\n\n", "CodeBleu_score": 54.39513891210632}, {"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self._fetch_data()\n    return hashlib.sha256(\n        (\n            \"|\".join(self._instance.columns)\n            + self._build_formula()\n            + self.config.view\n        ).encode(\"utf-8\")\n    ).hexdigest()\n\n", "CodeBleu_score": 53.79463033647996}]}
{"instance_id": "27ee5f415000", "generation_result": [{"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = pd.DataFrame(df)\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        df = pd.read_csv(df)\n    elif isinstance(df, pd.DataFrame):\n        pass\n    else:\n        raise ValueError(f\"Unsupported type {type(df)}\")\n    return df\n\n", "CodeBleu_score": 33.628317130418125}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.DataFrame):\n        self.df = df\n    elif isinstance(df, pd.Series):\n        self.df = pd.DataFrame(df)\n    elif isinstance(df, str):\n        if df.endswith('.csv'):\n            self.df = pd.read_csv(df)\n        elif df.endswith('.xlsx'):\n            self.df = pd.read_excel(df)\n        else:\n            raise ValueError(f'Unsupported file type: {df}')\n    elif isinstance(df, (list, dict)):\n        self.df = pd.DataFrame(df)\n    else:\n        raise ValueError(f'Unsupported data type: {type(df)}')\n\n\n", "CodeBleu_score": 50.03311952608096}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.DataFrame):\n        return df\n    elif isinstance(df, pd.Series):\n        return pd.DataFrame(df)\n    elif isinstance(df, str):\n        return pd.read_csv(df)\n    elif isinstance(df, (list, dict)):\n        return pd.DataFrame(df)\n    else:\n        raise ValueError(f\"Unsupported data type: {type(df)}\")\n\n", "CodeBleu_score": 32.25014709339043}]}
{"instance_id": "38f48a358606", "generation_result": [{"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n    return sampled_df\n\n", "CodeBleu_score": 76.95090533983699}]}
{"instance_id": "8bddad2e31ca", "generation_result": [{"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get('name', '')\n    description = extras.get('description', '')\n    csv = df.to_csv(index=False)\n    return f'<{name} description=\"{description}\">", "CodeBleu_score": 21.29406966684434}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    csv_string = f\"<{name} description=\\\"{description}\\\">", "CodeBleu_score": 21.154934677412594}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    if df.empty:\n        return \"\"\n    csv_str = \"\"\n    if \"name\" in extras:\n        csv_str += f'<data name=\"{extras[\"name\"]}\"'\n    else:\n        csv_str += \"<data\"\n    if \"description\" in extras:\n        csv_str += f' description=\"{extras[\"description\"]}\"'\n    csv_str += f' rows=\"{df.shape[0]}\" cols=\"{df.shape[1]}\">", "CodeBleu_score": 30.59855047721759}]}
{"instance_id": "5380bb60fd39", "generation_result": [{"code": "def convert_df_sql_connector_to_str\n\t\n    table_name = df.metadata.name\n    description = df.metadata.description\n    html_str = f'<table border=\"1\" class=\"dataframe\">\n  <caption>{table_name}</caption>", "CodeBleu_score": 10.662276851124942}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Convert the DataFrame to an HTML table string\n    html_table = df.to_html(index=False)\n\n    # Add the description to the table if it exists in the DataFrame metadata\n    if \"description\" in df.metadata:\n        html_table = f\"<p>{df.metadata['description']}</p>\" + html_table\n\n    # Construct the opening table tag with the table name and optional description\n    html_table = f\"<table class='table'><caption>{df.name}</caption>\" + html_table\n\n    # Add the CSV representation of the DataFrame's head\n    html_table += f\"<p>{df.head().to_csv(index=False)}</p>\"\n\n    # Close the table tag and return the complete HTML string\n    html_table += \"</table>\"\n    return html_table\n\n", "CodeBleu_score": 28.36039023255328}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Create an HTML table string from a DataFrame\n    # Add a description if it exists in the DataFrame metadata\n    html_str = f\"<h2>{df.name}</h2>", "CodeBleu_score": 4.742927453570506}]}
{"instance_id": "0afd995716c5", "generation_result": [{"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    # Convert DataFrame to JSON\n    json_data = self.convert_df_to_json(df, extras)\n\n    # Convert JSON to YAML\n    yaml_data = yaml.dump(json_data)\n\n    # Wrap YAML in HTML table tags if is_direct_sql is True\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        return f\"<table>{yaml_data}</table>\"\n\n    return yaml_data", "CodeBleu_score": 65.49661404469978}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    # Convert DataFrame to JSON\n    df_json = self.convert_df_to_json(df, extras)\n\n    # Convert JSON to YAML\n    yaml_str = yaml.dump(df_json, allow_unicode=True)\n\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        # Wrap YAML string in HTML table tags\n        yaml_str = f\"<table><tr><td>{yaml_str}</td></tr></table>\"\n\n    return yaml_str", "CodeBleu_score": 67.26243515660865}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    # Convert DataFrame to JSON format\n    json_data = self.convert_df_to_json(df, extras)\n\n    # Convert JSON to YAML string\n    yaml_string = yaml.dump(json_data, sort_keys=False)\n\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        # Wrap YAML string in HTML table tags\n        return f\"<table><tr><td><pre>{yaml_string}</pre></td></tr></table>\"\n\n    return yaml_string", "CodeBleu_score": 75.43949158749199}]}
{"instance_id": "e2b90ebd4e5d", "generation_result": [{"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self.value, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self.value, (str, dict))\n    else:\n        raise ValueError(f\"Invalid expected_type: {expected_type}\")", "CodeBleu_score": 53.81706687602234}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        if isinstance(self.value, (int, float)):\n            return True\n        else:\n            return False\n    elif expected_type == \"string\":\n        if isinstance(self.value, str):\n            return True\n        else:\n            return False\n    elif expected_type == \"dataframe\":\n        if isinstance(self.value, (pd.DataFrame, pd.Series)):\n            return True\n        else:\n            return False\n    elif expected_type == \"plot\":\n        if isinstance(self.value, str):\n            if self.value.endswith(\".png\") or self.value.endswith(\".jpg\") or self.value.endswith(\".jpeg\") or self.value.endswith(\".pdf\"):\n                return True\n            else:\n                return False\n        elif isinstance(self.value, dict):\n            return True\n        else:\n            return False\n    else:\n        return False\n\n\n\n", "CodeBleu_score": 50.31079146990404}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        if isinstance(self.value, int) or isinstance(self.value, float):\n            return True\n        else:\n            return False\n    elif expected_type == \"string\":\n        if isinstance(self.value, str):\n            return True\n        else:\n            return False\n    elif expected_type == \"dataframe\":\n        if isinstance(self.value, pd.DataFrame) or isinstance(self.value, pd.Series):\n            return True\n        else:\n            return False\n    elif expected_type == \"plot\":\n        if isinstance(self.value, str):\n            if os.path.isfile(self.value):\n                return True\n            else:\n                return False\n        elif isinstance(self.value, dict):\n            return True\n        else:\n            return False\n    else:\n        return False\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.40646361784092}]}
{"instance_id": "d95828fdcbcb", "generation_result": [{"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if inspect.signature(self.distance).parameters.get(\"X2\", None) is None:\n            return self.distance(X)\n        else:\n            return self.distance(X, X2)\n    else:\n        return self.distance(X, X2)\n\n\n\n\n def _fit_distance(self, X):\n    \"\"\"The function _fit_distance calculates the distance between all pairs of rows in the input dataset X using the specified distance metric and its parameters. If no additional parameters are provided, it initializes an empty dictionary. If the distance metric is a string, it uses the pairwise_distance function from sktime.distances. Otherwise, it directly calls the distance function with the given datasets and parameters. The function returns the computed distances.", "CodeBleu_score": 24.460657241131113}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if hasattr(self.distance_func, \"__call__\"):\n            if len(inspect.signature(self.distance_func).parameters) == 1:\n                return self.distance_func(X)\n            else:\n                return self.distance_func(X, **self.distance_params)\n        else:\n            return self.distance_func(X, **self.distance_params)\n    else:\n        return self.distance_func(X, X2, **self.distance_params)", "CodeBleu_score": 18.497214741263708}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if inspect.signature(self.distance).parameters:\n            return self.distance(X)\n        else:\n            return self.distance()\n    else:\n        return self.distance(X, X2)\n\n\n\n\n def _distance_matrix(self, X, X2=None):\n    \"\"\"The function _distance_matrix calculates the distance matrix between two datasets, X and X2, using a specified distance metric and its parameters. If no additional parameters are provided, it initializes an empty dictionary. If the distance metric is a string, it uses the pairwise_distance function from sktime.distances. Otherwise, it directly calls the distance function with the given datasets and parameters. If X2 is None, the function checks if the distance function can handle a single dataset by inspecting its signature and calls it accordingly. The function returns the computed distance matrix.", "CodeBleu_score": 26.31734226555467}]}
{"instance_id": "497d73b298ee", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if isinstance(X, pd.DataFrame):\n        X = X.values\n    if isinstance(X, pd.Series):\n        X = X.values\n    if isinstance(X, list):\n        X = np.array(X)\n    if isinstance(X, np.ndarray):\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n        if X.ndim == 3:\n            X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n        if X.ndim == 2:\n            if X.shape[1] == 1:\n                X = X.reshape(-1)\n            else:\n                X = X.reshape(X.shape[0], X.shape[1])\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n    if isinstance(X, np.ndarray):\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n        if X.ndim == 3:\n            X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n        if X.ndim == 2:\n            if X.shape[1] == 1:\n                X = X.reshape(-1)\n            else:\n                X = X.reshape(X.shape[0], X.shape[1])\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n    if isinstance(X, np.ndarray):\n        if X.ndim == 1:\n            X = X.reshape(-1, 1)\n        if X.ndim == 3:\n            X = X.reshape(X.shape[0], X.shape[1] * X.shape[2])\n        if X.ndim == 2:\n            if X.shape[1] == 1:\n                X = X.reshape(-1)\n            else:\n                X = X.reshape(X.shape[0], X.shape[1])\n        if X", "CodeBleu_score": 23.49999947532994}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if isinstance(X, pd.DataFrame):\n        X = X.values\n    elif isinstance(X, pd.Series):\n        X = X.values.reshape(-1, 1)\n    elif isinstance(X, np.ndarray):\n        if len(X.shape) == 1:\n            X = X.reshape(-1, 1)\n    else:\n        raise ValueError(\"Input data must be a pandas DataFrame, Series, or numpy array.\")\n    if self.equal_length:\n        if self.data_type == \"univariate\":\n            X = X.flatten()\n        elif self.data_type == \"multivariate\":\n            X = X.reshape(-1, self.n_features)\n        else:\n            raise ValueError(\"Invalid data type. Must be 'univariate' or 'multivariate'.\")\n    else:\n        if self.data_type == \"univariate\":\n            X = pd.DataFrame(X)\n        elif self.data_type == \"multivariate\":\n            X = pd.DataFrame(X)\n        else:\n            raise ValueError(\"Invalid data type. Must be 'univariate' or 'multivariate'.\")\n        X = X.reset_index(drop=True)\n        X = X.pivot(index=\"index\", columns=\"level_0\", values=0)\n        X = X.fillna(0)\n        X = X.values\n        lengths = np.array([len(X[i]) for i in range(X.shape[0])])\n        X = np.concatenate((lengths.reshape(-1, 1), X), axis=1)\n    return X\n\n\n", "CodeBleu_score": 36.744572545578436}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if isinstance(X, pd.DataFrame):\n        X = X.values\n    if isinstance(X, list):\n        X = np.array(X)\n    if isinstance(X, np.ndarray):\n        if (X.ndim == 1):\n            X = X.reshape(-1, 1)\n    if (X.shape[1] != self.n_features_in_):\n        raise ValueError((f\"X has {X.shape[1]} features, expected {self.n_features_in_}.\"))\n    if (not isinstance(X, np.ndarray)):\n        X = np.array(X)\n    if (X.ndim == 1):\n        X = X.reshape(-1, 1)\n    if (X.ndim == 2):\n        if (X.shape[0] != self.n_samples_):\n            raise ValueError((f\"X has {X.shape[0]} samples, expected {self.n_samples_}.\"))\n        if (X.shape[1] != self.n_features_in_):\n            raise ValueError((f\"X has {X.shape[1]} features, expected {self.n_features_in_}.\"))\n        if (self.n_features_in_ == 1):\n            X = X.flatten()\n        else:\n            X = X.reshape((-1, self.n_features_in_))\n    return X\n\n\n", "CodeBleu_score": 23.876116111692724}]}
{"instance_id": "8798260a6f12", "generation_result": [{"code": "def is_sklearn_estimator(obj)\n\t\n    from sktime.base import BaseObject\n    from sktime.utils.validation.base import SklearnBaseEstimator\n    if not isinstance(obj, type):\n        return False\n    if not issubclass(obj, SklearnBaseEstimator):\n        return False\n    if issubclass(obj, BaseObject):\n        return False\n    return True", "CodeBleu_score": 22.92410662884531}, {"code": "def is_sklearn_estimator(obj)\n\t\n    from sktime.utils.validation.base import SklearnBaseEstimator\n\n    return isinstance(obj, type) and issubclass(obj, SklearnBaseEstimator) and not issubclass(\n        obj, SklearnBaseEstimator\n    )\n\n", "CodeBleu_score": 25.020442729545977}, {"code": "def is_sklearn_estimator(obj)\n\t\n    return isinstance(obj, type) and issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n\n", "CodeBleu_score": 16.54750964754997}]}
{"instance_id": "2ab2596d8520", "generation_result": [{"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return TransformerPipeline(self.transformers + other.transformers)\n    return NotImplemented\n\n\n", "CodeBleu_score": 16.286605234397754}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        transformers = other.transformers\n        transformers.append(self.transformer)\n        regressor = self.regressor\n        return SklearnRegressorPipeline(regressor=regressor, transformers=transformers)\n    else:\n        return NotImplemented\n\n\n\n", "CodeBleu_score": 30.22959450033444}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        transformer_pipeline = TransformerPipeline(self.transformers + [other])\n        regressor_pipeline = SklearnRegressorPipeline(self.regressor, transformer_pipeline)\n        return regressor_pipeline\n    else:\n        return NotImplemented\n\n\n", "CodeBleu_score": 44.408240441690715}]}
{"instance_id": "5c1c6d14ca93", "generation_result": [{"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if not all(isinstance(col, str) for col in df.columns):\n        if copy_df:\n            df = df.copy()\n        df.columns = df.columns.astype(str)\n    return df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.57364644381207}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = df.columns.astype(str)\n    if not all(isinstance(col, str) for col in df.columns):\n        raise ValueError(\"All columns must be strings\")\n    return df\n\n\n", "CodeBleu_score": 50.20459040300561}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if not all(isinstance(col, str) for col in df.columns):\n        if copy_df:\n            df = df.copy()\n        df.columns = [str(col) for col in df.columns]\n    return df\n\n\n", "CodeBleu_score": 53.85232432381512}]}
{"instance_id": "d5e567c20361", "generation_result": [{"code": "def predict(self, X)\n\t\n    rng = np.random.RandomState(self.random_state)\n    y_proba = self.predict_proba(X)\n    y_pred = np.argmax(y_proba, axis=1)\n    return y_pred\n\n\n", "CodeBleu_score": 19.16675404793394}, {"code": "def predict(self, X)\n\t\n    rng = np.random.default_rng(self.random_state)\n    y_probas = self.predict_proba(X)\n    y_pred = np.argmax(y_probas, axis=1)\n    return y_pred\n\n\n", "CodeBleu_score": 19.069091244577095}, {"code": "def predict(self, X)\n\t\n    rng = np.random.default_rng(self.random_state)\n    y_pred = np.zeros(X.shape[0], dtype=int)\n    for i in range(X.shape[0]):\n        probas = self.predict_proba(X[i, :].reshape(1, -1))\n        max_indices = np.argwhere(probas == np.max(probas)).flatten()\n        y_pred[i] = rng.choice(max_indices)\n    return y_pred\n\n\n", "CodeBleu_score": 22.781034129866306}]}
{"instance_id": "210b60dffd55", "generation_result": [{"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    # Apply PCA transformations to each group of features\n    X_transformed = np.concatenate(\n        [\n            pcas[i].transform(X[:, groups[i]])\n            if len(groups[i]) > 0\n            else np.zeros((X.shape[0], 0))\n            for i in range(len(groups))\n        ],\n        axis=1,\n    )\n\n    # Replace missing values with zeros\n    X_transformed[np.isnan(X_transformed)] = 0\n\n    # Compute class probabilities using the classifier\n    y_probas = clf.predict_proba(X_transformed)\n\n    # Adjust class probabilities to match the expected class structure\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas = self._adjust_class_probas(y_probas)\n\n    return y_probas\n\n\n", "CodeBleu_score": 27.589975634505993}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n\n    # Apply PCA transformations to each group of features\n    X_transformed = []\n    for i in range(len(groups)):\n        X_group = X[:, groups[i]]\n        X_group = pcas[i].transform(X_group)\n        X_transformed.append(X_group)\n\n    # Concatenate transformed features\n    X_transformed = np.concatenate(X_transformed, axis=1)\n\n    # Replace missing values with 0\n    X_transformed[np.isnan(X_transformed)] = 0\n\n    # Compute class probabilities\n    y_probas = clf.predict_proba(X_transformed)\n\n    # Adjust class probabilities if necessary\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas = self._adjust_class_proba(y_probas)\n\n    return y_probas\n\n\n", "CodeBleu_score": 34.13706086824432}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    # transform the data\n    X_transformed = np.concatenate(\n        [\n            pcas[i].transform(X[:, groups[i]])\n            if len(groups[i]) > 0\n            else np.zeros((X.shape[0], 1))\n            for i in range(len(groups))\n        ],\n        axis=1,\n    )\n\n    # replace missing values with 0\n    X_transformed[np.isnan(X_transformed)] = 0\n\n    # compute class probabilities\n    y_probas = clf.predict_proba(X_transformed)\n\n    # adjust probabilities if necessary\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas = _adjust_proba(y_probas, self.n_classes_)\n\n    return y_probas\n\n", "CodeBleu_score": 27.731050082464854}]}
{"instance_id": "9436ee0860bb", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists\n\n", "CodeBleu_score": 89.31183340968327}, {"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 89.31183340968327}, {"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists\n\n", "CodeBleu_score": 89.31183340968327}]}
{"instance_id": "d7cb1cb66840", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    if self.transformers_[0].scitype_ == \"Primitives\":\n        return X.to_numpy().reshape(-1, 1)\n    if self.transformers_[0].scitype_ == \"Series\":\n        return X.to_numpy().reshape(-1, 1)\n    raise TypeError(\"Unexpected output type\")\n\n\n", "CodeBleu_score": 18.357782189590328}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    from sklearn.utils import check_array\n    from sklearn.utils.validation import check_is_fitted\n    check_is_fitted(self, 'transformers_')\n    if self.transformers_[0].scitype_ == 'Primitives':\n        X = check_array(X, accept_sparse=True, force_all_finite=False, ensure_2d=True, dtype=None, order='C', copy=True, force_all_finite='allow-nan')\n    elif self.transformers_[0].scitype_ == 'Series':\n        X = check_array(X, accept_sparse=True, force_all_finite=False, ensure_2d=True, dtype=None, order='C', copy=True, force_all_finite='allow-nan').reshape(-1, X.shape[1])\n    else:\n        raise TypeError('Unexpected output type')\n    return X", "CodeBleu_score": 38.33157690725992}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n        raise ValueError(\"The pipeline has not been fitted yet.\")\n    if self.transformers_ is None:\n", "CodeBleu_score": 11.108160297135925}]}
{"instance_id": "497cb75f2b4d", "generation_result": [{"code": "def set_random_state(estimator, random_state=0)\n\t\n    import numpy as np\n    import random\n    import inspect\n    import warnings\n    from sklearn.exceptions import ConvergenceWarning\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.validation import check_random_state\n    from sklearn.utils.estimator_checks import parametrize\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_estimator\n    from sklearn.utils.estimator_checks import check_", "CodeBleu_score": 5.954649894346957}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    import numpy as np\n    import random\n    import inspect\n    import re\n    import warnings\n    from sklearn.utils import check_random_state\n    from sklearn.utils.fixes import _sklearn_version\n    from sklearn.utils.validation import check_is_fitted\n    from sklearn.exceptions import NotFittedError\n    from sklearn.ensemble import RandomForestClassifier\n    from sklearn.ensemble import RandomForestRegressor\n    from sklearn.linear_model import LogisticRegression\n    from sklearn.linear_model import LinearRegression\n    from sklearn.linear_model import SGDClassifier\n    from sklearn.linear_model import SGDRegressor\n    from sklearn.neural_network import MLPClassifier\n    from sklearn.neural_network import MLPRegressor\n    from sklearn.svm import SVC\n    from sklearn.svm import SVR\n    from sklearn.tree import DecisionTreeClassifier\n    from sklearn.tree import DecisionTreeRegressor\n    from sklearn.ensemble import GradientBoostingClassifier\n    from sklearn.ensemble import GradientBoostingRegressor\n    from sklearn.ensemble import AdaBoostClassifier\n    from sklearn.ensemble import AdaBoostRegressor\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.ensemble import BaggingRegressor\n    from sklearn.ensemble import ExtraTreesClassifier\n    from sklearn.ensemble import ExtraTreesRegressor\n    from sklearn.ensemble import RandomTreesEmbedding\n    from sklearn.ensemble import RandomForestEmbedding\n    from sklearn.ensemble import GradientBoostingRegressor\n    from sklearn.ensemble import GradientBoostingClassifier\n    from sklearn.ensemble import AdaBoostRegressor\n    from sklearn.ensemble import AdaBoostClassifier\n    from sklearn.ensemble import BaggingRegressor\n    from sklearn.ensemble import BaggingClassifier\n    from sklearn.", "CodeBleu_score": 9.853185855847466}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    # Ensure random_state is a valid random state object\n    if isinstance(random_state, int):\n        random_state = np.random.RandomState(random_state)\n    elif not isinstance(random_state, np.random.RandomState):\n        raise ValueError(\"random_state must be an integer or np.random.RandomState\")\n\n    # Initialize an empty dictionary to hold parameters that need updating\n    params = {}\n\n    # Iterate over the estimator's parameters\n    for name, value in estimator.get_params().items():\n        # Check if the parameter is related to random state\n        if name.endswith(\"random_state\"):\n            # Assign a random integer value to the parameter\n            params[name] = random_state.randint(0, 2**32 - 1)\n\n    # Update the estimator with the new random state values if any were found\n    if params:\n        estimator.set_params(**params)\n\n    return estimator\n\n\n\n", "CodeBleu_score": 35.98907439305343}]}
{"instance_id": "59ffd1d596a1", "generation_result": [{"code": "def _transform(X, intervals)\n\t\n    # Calculate the number of instances and intervals\n    n_instances, n_intervals = intervals.shape\n\n    # Initialize an empty array to store the transformed features\n    transformed = np.zeros((n_instances, n_intervals * 3))\n\n    # Loop over each interval\n    for i in range(n_intervals):\n        # Slice the input matrix using the current interval\n        X_slice = X[:, intervals[0, i] : intervals[1, i]]\n\n        # Compute the mean, standard deviation, and slope of the slice\n        mean = np.mean(X_slice, axis=1)\n        std = np.std(X_slice, axis=1)\n        slope = _slope(X_slice)\n\n        # Store the computed values in the transformed array\n        transformed[:, i * 3] = mean\n        transformed[:, i * 3 + 1] = std\n        transformed[:, i * 3 + 2] = slope\n\n    # Return the transposed transformed array\n    return transformed.T\n\n", "CodeBleu_score": 40.67070953756122}, {"code": "def _transform(X, intervals)\n\t\n    # Get the number of instances and intervals\n    n_instances, n_intervals = intervals.shape\n\n    # Initialize an empty array to store the transformed features\n    transformed = np.zeros((n_instances, n_intervals * 3))\n\n    # Loop over each interval\n    for i in range(n_intervals):\n        # Get the start and end indices for the current interval\n        start, end = intervals[:, i]\n\n        # Slice the input matrix along the time axis\n        X_slice = X[:, start:end]\n\n        # Compute the mean, standard deviation, and slope of the slice\n        mean = np.mean(X_slice, axis=1)\n        std = np.std(X_slice, axis=1)\n        slope = _slope(X_slice)\n\n        # Store the mean, standard deviation, and slope in the transformed array\n        transformed[:, i * 3] = mean\n        transformed[:, i * 3 + 1] = std\n        transformed[:, i * 3 + 2] = slope\n\n    # Return the transposed transformed array\n    return transformed.T\n\n", "CodeBleu_score": 39.42151835817829}, {"code": "def _transform(X, intervals)\n\t\n    n_instances, n_intervals = intervals.shape\n    X_transformed = np.zeros((n_intervals, n_instances))\n    for i in range(n_intervals):\n        start, end = intervals[i]\n        X_slice = X[:, start:end]\n        X_transformed[i, :] = np.hstack(\n            (\n                np.mean(X_slice, axis=1),\n                np.std(X_slice, axis=1),\n                _slope(X_slice, axis=1),\n            )\n        )\n    return X_transformed.T\n\n", "CodeBleu_score": 30.69518413500274}]}
{"instance_id": "5a01594eebfb", "generation_result": [{"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n    annotation_params = self._get_annotation_params(annotation_params)\n    annotate_params = self._get_annotate_params(annotate_params)\n    self.configure(**configuration)\n    self.new_plot(plot, **plot_params)\n    self._apply_ax_operations(self.ax, ax_op_before)\n    self.configure(**annotate_params)\n    getattr(self, annotation_func)(*args, **annotation_params)\n    self._apply_ax_operations(self.ax, ax_op_after)\n    return self._get_output()\n\n", "CodeBleu_score": 53.07355723112002}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n    if annotate_params is None:\n        annotate_params = {}\n\n    self.new_plot(plot=plot, **plot_params)\n    self.configure(**configuration)\n    self.annotate_by(annotation_func, *args, **annotation_params)\n    _apply_ax_operations(self.ax, ax_op_before)\n    self.annotate(**annotate_params)\n    _apply_ax_operations(self.ax, ax_op_after)\n    return self._get_output()\n\n", "CodeBleu_score": 50.4401711780804}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n\n    # Initialize annotation and operation parameters\n    if \"annotations\" not in configuration:\n        configuration[\"annotations\"] = []\n    if \"operations\" not in configuration:\n        configuration[\"operations\"] = []\n\n    # Create the plot with given parameters\n    plotter = self._get_plotter(plot, plot_params, **kwargs)\n    plotter.plot()\n\n    # Apply pre-plot axis operations\n    _apply_ax_operations(plotter.ax, ax_op_before)\n\n    # Configure and annotate the plot\n    plotter.configure(**configuration)\n    plotter.annotate(**annotation_params)\n\n    # Apply post-plot axis operations\n    _apply_ax_operations(plotter.ax, ax_op_after)\n\n    # Return the output of the plotting process\n    return plotter.get_output()\n\n", "CodeBleu_score": 47.15983977648356}]}
{"instance_id": "b5b17d312c74", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('Model has not been fitted yet.')\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError('Input data must be a pandas DataFrame.')\n    if len(X.columns) != self._expected_feature_count:\n        raise ValueError(f'Expected {self._expected_feature_count} features, got {len(X.columns)}.')\n    scores = self._program.predict(X)\n    probabilities = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n    return probabilities\n\n\n", "CodeBleu_score": 42.38504507645282}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('Model has not been fitted.')\n    X = self._validate_data(X, dtype='numeric', accept_sparse='csr', reset=False)\n    if X.shape[1] != self._feature_count:\n        raise ValueError(f'Expected {self._feature_count} features, got {X.shape[1]}')\n    scores = self._program.execute(X.toarray())\n    probs = np.array([[1 - score, score] for score in scores])\n    return probs", "CodeBleu_score": 40.424127506579154}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('The model has not been fitted yet.')\n    if not isinstance(X, (list, tuple)):\n        raise ValueError('The input data must be a list or tuple.')\n    if not isinstance(X[0], (list, tuple)):\n        raise ValueError('The input data must be a list of lists or tuples.')\n    if len(X[0]) != self._feature_count:\n        raise ValueError(f'The input data must have {self._feature_count} features.')\n    scores = self._program(X)\n    probs = [(1 / (1 + np.exp(-score))) for score in scores]\n    return np.array([[1 - prob, prob] for prob in probs])\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.9483756902592}]}
{"instance_id": "83f71c959df7", "generation_result": [{"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    mutated_program = copy.deepcopy(self)\n\n    # Get the number of nodes in the program\n    num_nodes = len(mutated_program)\n\n    # Define the probability threshold for mutation\n    mutation_probability = 0.1\n\n    # Define the probability of replacing a node with a constant\n    constant_probability = 0.5\n\n    # Define the probability of replacing a node with a variable\n    variable_probability = 0.5\n\n    # Define the range of constants to use for replacement\n    constant_range = (-10, 10)\n\n    # Define the number of features to use for replacement\n    num_features = 1\n\n    # Define a list to store the indices of modified nodes\n    modified_node_indices = []\n\n    # Iterate over the nodes in the program\n    for i in range(num_nodes):\n        # Check if the node should be mutated\n        if random_state.uniform(0, 1) < mutation_probability:\n            # Get the node\n            node = mutated_program[i]\n\n            # If the node is a function, find a valid replacement function\n            if node.is_function:\n                # Get the arity of the function\n                arity = node.arity\n\n                # Find a valid replacement function with the same arity\n                replacement_function = None\n                while replacement_function is None:\n                    # Choose a random function from the function set\n                    random_function = random_state.choice(self.function_set)\n\n                    # Check if the function has the same arity as the original function\n                    if random_function.arity == arity:\n                        # Check if the function is valid for replacement\n                        if self.is_valid_replacement(random_function):\n                            replacement_function = random_function\n\n                # Update the node with the replacement function\n                mutated_program[i] = replacement_function\n\n            # If the node is a terminal, replace it with either a constant or a variable\n            else:\n                # Check if the node is a constant\n                if node.is_constant:\n                    # Replace the node with a constant\n                    mutated_program[", "CodeBleu_score": 29.249174158922553}, {"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    mutated_program = copy.deepcopy(self)\n    # Get the list of nodes in the program\n    nodes = mutated_program.get_nodes()\n    # Get the number of nodes in the program\n    num_nodes = len(nodes)\n    # Create a list to store the indices of modified nodes\n    modified_indices = []\n    # Iterate over the nodes in the program\n    for i in range(num_nodes):\n        # Check if the node should be mutated\n        if random_state.uniform() < self.mutation_rate:\n            # Get the node at the current index\n            node = nodes[i]\n            # Check if the node is a function\n            if node.is_function():\n                # Find a replacement function with the same arity\n                replacement_node = self.get_function_node_with_arity(node.arity, random_state)\n                # Replace the node with the replacement function\n                nodes[i] = replacement_node\n                # Add the index of the modified node to the list\n                modified_indices.append(i)\n            # Check if the node is a terminal\n            elif node.is_terminal():\n                # Replace the terminal with a constant or variable\n                if random_state.uniform() < 0.5:\n                    # Replace with a constant\n                    nodes[i] = self.get_constant_node(random_state)\n                else:\n                    # Replace with a variable\n                    nodes[i] = self.get_variable_node(random_state)\n                # Add the index of the modified node to the list\n                modified_indices.append(i)\n    # Set the list of nodes in the mutated program\n    mutated_program.set_nodes(nodes)\n    # Return the mutated program and the list of modified node indices\n    return mutated_program, modified_indices\n\n\n", "CodeBleu_score": 22.672363810695646}, {"code": "def point_mutation(self, random_state)\n\t\n    mutated_program = self.copy()\n    modified_node_indices = []\n    for node in mutated_program.pre_order():\n        if random_state.uniform() < self.mutation_probability:\n            if node.is_function():\n                replacement_function = self.get_valid_replacement_function(node.function, random_state)\n                if replacement_function is not None:\n                    node.function = replacement_function\n                    modified_node_indices.append(node.index)\n            elif node.is_terminal():\n                if random_state.uniform() < self.mutation_probability:\n                    replacement_value = self.get_valid_replacement_value(node.value, random_state)\n                    node.value = replacement_value\n                    modified_node_indices.append(node.index)\n    return mutated_program, modified_node_indices\n\n\n\n", "CodeBleu_score": 22.052322126081595}]}
{"instance_id": "f1853251e671", "generation_result": [{"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate arguments\n    length = validate_int(length, 20)\n    mamode = validate_ma_mode(mamode)\n    offset = validate_offset(offset, length)\n\n    # Calculate Result\n    ma = ma(close, length=length, mamode=mamode)\n    result = (close - ma) / ma * 100\n\n    # Offset\n    if offset != 0:\n        result = result.shift(offset)\n\n    # Name and Categorize it\n    result.name = f\"BIAS_{length}_{mamode}\"\n    result.category = \"momentum\"\n\n    return result\n\n\n", "CodeBleu_score": 16.772748597739}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    name = \"bias\"\n    mode = mamode\n    length = length or 6\n    offset = offset or length - 1\n    fill = kwargs.pop(\"fill\", None)\n    fill_method = kwargs.pop(\"fill_method\", None)\n    if len(close) == 0:\n        return close\n    if close.empty:\n        return close\n    if isinstance(close, pd.Series):\n        if close.name is None:\n            close = close.rename(\"CLOSE\")\n    else:\n        close = pd.Series(close)\n        close.name = \"CLOSE\"\n    if isinstance(length, int):\n        length = int(length)\n    else:\n        length = int(length[1:])\n    if isinstance(offset, int):\n        offset = int(offset)\n    else:\n        offset = int(offset[1:])\n    if close.index.name:\n        close = close.reset_index(drop=True)\n    if close.index.name == None:\n        close.index.name = \"date\"\n    if len(close) <= length:\n        return close\n    min_periods = 0 if mode == \"sma\" else length\n    ma = close.ewm(alpha=1 / length, min_periods=min_periods, adjust=False).mean()\n    bias = (close - ma) / ma * 100\n    bias.name = f\"BIAS_{length}\"\n    if isinstance(offset, int) and offset != 0:\n        bias = bias.shift(offset)\n    if isinstance(fill, str):\n        bias = _fill_for_co(bias, fill, fill_method)\n    if isinstance(name, str) and name in _CATEGORIES:\n        bias.name = f\"{_CATEGORIES[name]}_{bias.name}\"\n    return bias", "CodeBleu_score": 41.11358434035955}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    # Validate arguments\n    length = validate_int(length, 20)\n    mamode = validate_ma_mode(mamode)\n    offset = validate_offset(offset, length)\n    # Calculate Result\n    ma = ma(close=close, length=length, mamode=mamode)\n    result = ((close - ma) / ma) * 100\n    # Offset\n    if offset != 0:\n        result = offset_result(result, offset)\n    # Name and Categorize it\n    result = result.rename('BIAS')\n    result.metadata['_TechnicalAnalysis', 'function'] = 'bias'\n    result.metadata['_TechnicalAnalysis', 'series_type'] = 'momentum'\n    return result", "CodeBleu_score": 20.07551262080397}]}
{"instance_id": "77825be37c24", "generation_result": [{"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    if broker == 'hb':\n        url = f'https://api.huobi.pro/market/history/kline?symbol={code.lower()}&period={ktype}&size={size}'\n    elif broker == 'bh':\n        url = f'https://api.binance.com/api/v3/klines?symbol={code.upper()}{ktype}&limit={size}'\n    elif broker == 'ok':\n        url = f'https://www.okcoin.com/api/v5/market/history-kline?instId={code.lower()}-{ktype}&bar={ktype}&limit={size}'\n    else:\n        print('broker not found')\n        return\n    try:\n        js = get_data(url)\n        if broker == 'hb':\n            data = js['data']\n            df = pd.DataFrame(data)\n            df.columns = ['date', 'open', 'close', 'high', 'low', 'amount', 'vol', 'count']\n            df['date'] = df['date'].apply(lambda x: int2time(x))\n        elif broker == 'bh':\n            data = js\n            df = pd.DataFrame(data)\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'amount', 'vol', 'count', 'buy', 'sell', 'buy_amount',\n                          'sell_amount', 'buy_vol', 'sell_vol', 'buy_count', 'sell_count']\n            df['date'] = df['date'].apply(lambda x: int2time(x))\n        elif broker == 'ok':\n            data = js['data']\n            df = pd.DataFrame(data)\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'amount', 'vol', 'count']\n            df['date'] = df['date'].apply(lambda x: int2time(x))\n        else:\n            print('broker not found')\n            return\n        df['date'] = pd.to_datetime(df['date'], format='%Y-", "CodeBleu_score": 32.16312938658885}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    url = f\"https://api.{broker}.com/market/history/kline?symbol={code}&period={ktype}&size={size}\"\n    try:\n        js = _get_data(url)\n        if broker == 'hb':\n            data = js['data']\n            df = pd.DataFrame(data)\n            df.columns = ['date', 'open', 'close', 'low', 'high', 'amount', 'vol', 'count']\n            df['date'] = df['date'].apply(int2time)\n            df['date'] = pd.to_datetime(df['date'])\n            df.set_index('date', inplace=True)\n            return df\n        else:\n            return js\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 33.93903253850343}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    if broker == 'hb':\n        url = f'https://api.huobi.pro/market/history/kline?symbol={code.upper()}&period={ktype.upper()}&size={size}'\n        data = _get_data(url)\n        df = pd.DataFrame(data['data'])\n        df.columns = ['date', 'open', 'close', 'high', 'low', 'amount', 'vol', 'count']\n        df['date'] = df['date'].apply(lambda x: int2time(x / 1000))\n        df['date'] = pd.to_datetime(df['date'])\n    elif broker == 'bj':\n        url = f'https://api.big.one/public/v1/kline?symbol={code.upper()}_USDT&period={ktype.upper()}&size={size}'\n        data = _get_data(url)\n        df = pd.DataFrame(data['data'])\n        df.columns = ['date', 'open', 'close', 'high', 'low', 'amount', 'vol', 'count']\n        df['date'] = df['date'].apply(lambda x: int2time(x / 1000))\n        df['date'] = pd.to_datetime(df['date'])\n    elif broker == 'hk':\n        url = f'https://api.huobi.pro/market/history/kline?symbol={code.upper()}_USDT&period={ktype.upper()}&size={size}'\n        data = _get_data(url)\n        df = pd.DataFrame(data['data'])\n        df.columns = ['date', 'open', 'close', 'high', 'low', 'amount', 'vol', 'count']\n        df['date'] = df['date'].apply(lambda x: int2time(x / 1000))\n        df['date'] = pd.to_datetime(df['date'])\n    else:\n        raise ValueError(f'Broker {broker} not supported')\n    return df\n\n", "CodeBleu_score": 33.57305768982501}]}
{"instance_id": "c6552851da8a", "generation_result": [{"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        if broker == 'hb':\n            df_ask = pd.DataFrame(_get_data(f'https://api.huobi.pro/market/depth?symbol={code.upper()}&type=step0&size={size}'))\n            df_bid = pd.DataFrame(_get_data(f'https://api.huobi.pro/market/depth?symbol={code.upper()}&type=step0&size={size}'))\n            df_ask.columns = ['price', 'amount']\n            df_bid.columns = ['price', 'amount']\n            df_ask['timestamp'] = int2time(int(df_ask['timestamp'][0]))\n            df_bid['timestamp'] = int2time(int(df_bid['timestamp'][0]))\n            df_ask = df_ask.set_index('timestamp')\n            df_bid = df_bid.set_index('timestamp')\n            df_ask = df_ask.sort_index(ascending=False)\n            df_bid = df_bid.sort_index(ascending=False)\n            df_ask = df_ask.astype(float)\n            df_bid = df_bid.astype(float)\n            df_ask = df_ask.astype(int)\n            df_bid = df_bid.astype(int)\n            df_ask = df_ask.drop(df_ask.index[0])\n            df_bid = df_bid.drop(df_bid.index[0])\n            df_ask = df_ask.drop(df_ask.index[0])\n            df_bid = df_bid.drop(df_bid.index[0])\n            df_ask = df_ask.drop(df_ask.index[0])\n            df_bid = df_bid.drop(df_bid.index[0])\n            df_ask = df_ask.drop(df_ask.index[0])\n            df_bid = df_bid.drop(df_bid.index[0])\n            df_ask = df_ask.drop(df_ask.index[0])\n            df_bid = df_bid.drop(df", "CodeBleu_score": 35.235759459361034}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        data = _get_data(broker, code, size)\n        ask = pd.DataFrame(data['ask'], columns=['price', 'amount'])\n        bid = pd.DataFrame(data['bid'], columns=['price', 'amount'])\n        ask['timestamp'] = ask['timestamp'].apply(int2time)\n        bid['timestamp'] = bid['timestamp'].apply(int2time)\n        df = {'ask': ask, 'bid': bid}\n        p = pd.Panel(df)\n        return p\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 34.72812103798491}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        data = _get_data(broker, code, size)\n        if broker == 'hb':\n            data = data['tick']['data']\n            data = pd.DataFrame(data)\n            data['timestamp'] = data['ts'].apply(int2time)\n            data['ask'] = data['ask'].apply(lambda x: pd.Series(x))\n            data['bid'] = data['bid'].apply(lambda x: pd.Series(x))\n            ask = data[['timestamp', 'ask']]\n            bid = data[['timestamp', 'bid']]\n            df = pd.Panel({'ask': ask, 'bid': bid})\n            return df\n        elif broker == 'huobi':\n            data = data['tick']['data']\n            data = pd.DataFrame(data)\n            data['timestamp'] = data['ts'].apply(int2time)\n            data['ask'] = data['ask'].apply(lambda x: pd.Series(x))\n            data['bid'] = data['bid'].apply(lambda x: pd.Series(x))\n            ask = data[['timestamp', 'ask']]\n            bid = data[['timestamp', 'bid']]\n            df = pd.Panel({'ask': ask, 'bid': bid})\n            return df\n        else:\n            print('broker is not supported')\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 39.428981261904724}]}
{"instance_id": "8b5fee723398", "generation_result": [{"code": "def coins_trade(broker='hb', code='btc')\n\t\n    if broker == 'hb':\n        url = f'https://api.huobi.pro/market/history/trade?symbol={code}'\n        data = _get_data(url)\n        if data is not None:\n            df = pd.DataFrame(data['data'])\n            df = df[['id', 'ts', 'price', 'amount', 'direction']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n            return df\n    elif broker == 'ok':\n        url = f'https://www.okcoin.com/api/v5/market/history-trades.do?symbol={code}-USDT'\n        data = _get_data(url)\n        if data is not None:\n            df = pd.DataFrame(data['data'])\n            df = df[['tid', 'ts', 'price', 'size', 'side']]\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n            return df\n    elif broker == 'chbtc':\n        url = f'https://api.chbtc.com/api/v1/trades?symbol={code}'\n        data = _get_data(url)\n        if data is not None:\n            df = pd.DataFrame(data['data'])\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n            df['datetime'] = df['datetime'].apply(int2time)\n            return df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.89141150940089}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = 'https://api.huobi.pro/market/history/trade?symbol=' + code.upper()\n    data = get_data(url)\n    if data is not None:\n        if broker == 'hb':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(lambda x: int2time(x / 1000))\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        elif broker == 'ok':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(lambda x: int2time(x / 1000))\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        elif broker == 'chbtc':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(lambda x: int2time(x / 1000))\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        else:\n            print('Broker not supported')\n            return None\n        return df\n    else:\n        print('No data')\n        return None\n\n", "CodeBleu_score": 51.58658494090274}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    url = 'https://api.huobi.pro/market/history/trade?symbol={}usdt'.format(code)\n    data = _get_data(url)\n    if data is not None:\n        if broker == 'hb':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        elif broker == 'ok':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        elif broker == 'chbtc':\n            df = pd.DataFrame(data['data'])\n            df.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            df['datetime'] = df['datetime'].apply(int2time)\n            df = df[['tid', 'datetime', 'price', 'amount', 'type']]\n        else:\n            raise ValueError('broker must be in [\"hb\", \"ok\", \"chbtc\"]')\n        return df\n    else:\n        return None\n\n\n\n", "CodeBleu_score": 44.40553036835435}]}
{"instance_id": "25e0a134c45b", "generation_result": [{"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    import requests\n    import pandas as pd\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import numpy as np\n    import pandas as pd\n    import requests\n    import json\n    import sys\n    import re\n    import os\n    import time\n    import datetime\n    import", "CodeBleu_score": 9.315359750102015}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n\n    try:\n        response = requests.get(url)\n        response.raise_for_status()\n        text = response.text\n        soup = BeautifulSoup(text, 'html.parser')\n\n        # Find the table containing the fund data\n        table = soup.find('table', {'class': 'table-data'})\n\n        # Extract the rows from the table\n        rows = table.find_all('tr')\n\n        # Extract the headers from the first row\n        headers = [th.text.strip() for th in rows[0].find_all('th')]\n\n        # Extract the data from the remaining rows\n        data = []\n        for row in rows[1:]:\n            cols = row.find_all('td')\n            row_data = [col.text.strip() for col in cols]\n            data.append(row_data)\n\n        # Create a pandas DataFrame from the data\n        df = pd.DataFrame(data, columns=headers)\n\n        # Format the DataFrame\n        df = df.dropna()\n        df['fund_name'] = df['fund_name'].str.strip()\n        df['fund_name'] = df['fund_name'].str.replace(r'\\s+', ' ', regex=True)\n        df['fund_name'] = df['fund_name'].str.replace(r'[^\\w\\s]', '', regex=True)\n        df['fund_name'] = df['fund_name'].str.replace(r'^\\s+|\\s+$', '', regex=True)\n        df['fund_name'] = df['fund_name'].str.lower()\n        df['fund_name'] = df['fund_name'].str.replace(r'\\s+', '_', regex=True)\n        df['fund_name'] = df['fund_name'].str.replace(r'[^\\w\\s]', '', regex=True)\n        df['fund_name'] = df['fund_name'].str.replace(r'^\\s+|\\s+$', '', regex=True)\n        df['fund_name'] = df['fund_name'].str.replace(r'\\s+', '_", "CodeBleu_score": 35.45635077597474}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    try:\n        print(f\"Retrieving {fund_type} fund data from {url}\")\n        response = requests.get(url)\n        response.raise_for_status()\n        text = response.text\n        if 'charset=utf-8' in response.headers.get('Content-Type', ''):\n            text = text.encode('utf-8').decode('utf-8-sig')\n        text = text.replace('\\r", "CodeBleu_score": 17.39013111290053}]}
{"instance_id": "401d18e122d8", "generation_result": [{"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    from datetime import datetime, timedelta\n    import pandas as pd\n    import tushare as ts\n    import ccxt\n    import numpy as np\n    import os\n    import json\n    import time\n    import sys\n    import requests\n    import re\n    import warnings\n    warnings.filterwarnings('ignore')\n\n    if market == 'CFFEX':\n        def get_daily_data(date):\n            df = ts.pro_bar(ts_code='CFFEX.IF1903.P{}'.format(date), adj='qfq', freq='D', start_date=date, end_date=date)\n            return df\n    elif market == 'SHFE':\n        def get_daily_data(date):\n            df = ts.pro_bar(ts_code='SHFE.AG1903.P{}'.format(date), adj='qfq', freq='D', start_date=date, end_date=date)\n            return df\n    elif market == 'DCE':\n        def get_daily_data(date):\n            df = ts.pro_bar(ts_code='DCE.AL1903.P{}'.format(date), adj='qfq', freq='D', start_date=date, end_date=date)\n            return df\n    elif market == 'CZCE':\n        def get_daily_data(date):\n            df = ts.pro_bar(ts_code='CZCE.TA1903.P{}'.format(date), adj='qfq', freq='D', start_date=date, end_date=date)\n            return df\n    elif market == 'INE':\n        def get_daily_data(date):\n            df = ts.pro_bar(ts_code='INE.I1903.P{}'.format(date), adj='qfq', freq='D', start_date=date, end_date=date)\n            return df\n    elif market == 'SSE':\n        def get_daily_data(date):\n            df = ts.pro", "CodeBleu_score": 29.089699592785536}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        from quant.data.futures.cffex import get_daily as get_daily_cffex\n        get_daily = get_daily_cffex\n    elif market == 'SHFE':\n        from quant.data.futures.shfe import get_daily as get_daily_shfe\n        get_daily = get_daily_shfe\n    elif market == 'DCE':\n        from quant.data.futures.dce import get_daily as get_daily_dce\n        get_daily = get_daily_dce\n    elif market == 'CZCE':\n        from quant.data.futures.czce import get_daily as get_daily_czce\n        get_daily = get_daily_czce\n    elif market == 'INE':\n        from quant.data.futures.ine import get_daily as get_daily_ine\n        get_daily = get_daily_ine\n    elif market == 'SGE':\n        from quant.data.futures.sge import get_daily as get_daily_sge\n        get_daily = get_daily_sge\n    elif market == 'SSE':\n        from quant.data.futures.sse import get_daily as get_daily_sse\n        get_daily = get_daily_sse\n    elif market == 'SZSE':\n        from quant.data.futures.szse import get_daily as get_daily_szse\n        get_daily = get_daily_szse\n    elif market == 'SGE':\n        from quant.data.futures.sge import get_daily as get_daily_sge\n        get_daily = get_daily_sge\n    else:\n        raise ValueError('Invalid market')\n    if start is None:\n        start = datetime.date.today()\n    if end is None:\n        end = datetime.date.today()\n    start = start.strftime('%Y-%m-%", "CodeBleu_score": 29.840488920917196}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    import datetime\n    import pandas as pd\n    import tushare as ts\n    import tqsdk\n    import tqsdk.ta as ta\n    import tqsdk.tafunc as tafunc\n    import tqsdk.tafunc.ta as tafunc_ta\n    import tqsdk.tafunc.tafunc as tafunc_tafunc\n    import tqsdk.tafunc.tafunc_ta as tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc as tafunc_tafunc_tafunc\n    import tqsdk.tafunc.tafunc_tafunc_ta as tafunc_tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc_tafunc as tafunc_tafunc_tafunc_tafunc\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_ta as tafunc_tafunc_tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc as tafunc_tafunc_tafunc_tafunc_tafunc\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_ta as tafunc_tafunc_tafunc_tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_tafunc as tafunc_tafunc_tafunc_tafunc_tafunc_tafunc\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_tafunc_ta as tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_tafunc_tafunc as tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_tafunc\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_ta as tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_ta\n    import tqsdk.tafunc.tafunc_tafunc_tafunc_tafunc_tafunc_tafunc_", "CodeBleu_score": 7.710934471537939}]}
{"instance_id": "697779825988", "generation_result": [{"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    import pandas as pd\n    import requests\n    import time\n    from bs4 import BeautifulSoup\n    import json\n    import datetime\n    import re\n    import random\n    import time\n    import requests\n    from retrying import retry\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import RetryCallState\n    from retrying import RetryError\n    from retrying import Ret", "CodeBleu_score": 5.396672857587081}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    import pandas as pd\n    import requests\n    import time\n    import json\n    import datetime\n    import random\n    import string\n    import os\n    import re\n    import sys\n    import logging\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime\n    import pandas as pd\n    import requests\n    import json\n    import time\n    import datetime", "CodeBleu_score": 6.0755555368329786}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    url = \"https://movie.daum.net/api/movieboxoffice/realtime\"\n    for i in range(retry_count):\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                data = response.json()\n                if 'data2' in data:\n                    df = pd.DataFrame(data['data2'])\n                    df = df.drop(['MovieImg', 'mId'], axis=1)\n                    df['timestamp'] = pd.Timestamp.now()\n                    return df\n                else:\n                    print(f\"No data found in response. Retrying (attempt {i+1}/{retry_count})...\")\n            else:\n                print(f\"Error {response.status_code}. Retrying (attempt {i+1}/{retry_count})...\")\n        except Exception as e:\n            print(f\"An error occurred: {e}. Retrying (attempt {i+1}/{retry_count})...\")\n        time.sleep(pause)\n    print(\"Failed to retrieve real-time box office data after retrying.\")\n    return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.46467174008065}]}
