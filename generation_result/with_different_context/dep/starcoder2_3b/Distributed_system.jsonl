{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    loop_wait = self.loop_wait - 2\n    if loop_wait < 2:\n        loop_wait = 2\n    return loop_wait, self.connect(*args)\n\n", "CodeBleu_score": 46.94104433353531}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = self.loop_wait - 2\n    if wait_time < 2:\n        wait_time = 2\n    return (wait_time * 1000, *args)\n\n", "CodeBleu_score": 41.83325392399969}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self.loop_wait -= 2\n    return super()._kazoo_connect(*args)\n\n", "CodeBleu_score": 39.26312005980002}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config.from_dict(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_loop_wait(config.loop_wait)\n    self.set_ttl(config.ttl)\n    if isinstance(self._client, PatroniSequentialThreadingHandler):\n        self._client.set_connect_timeout(config.connect_timeout)\n    else:\n        self._client.set_connect_timeout(self._connect_timeout)", "CodeBleu_score": 36.73118391268726}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.retry_timeout)\n    self.set_loop_wait(config.loop_wait)\n    self.set_ttl(config.ttl)\n    if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n        self._client.handler.set_connect_timeout(config.connect_timeout)", "CodeBleu_score": 40.18921818426713}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    self.set_retry_timeout(config.get('retry_timeout', self._client.retry.deadline))\n    self.set_loop_wait(config.get('loop_wait', self._client.retry.loop_wait))\n    self.set_ttl(config.get('ttl', self._client.session_timeout / 1000))\n    if self._client._handler is not None and isinstance(self._client._handler, PatroniSequentialThreadingHandler):\n        self._client._handler.set_connect_timeout(config.get('connect_timeout', self._connect_timeout))\n\n", "CodeBleu_score": 39.06043518003773}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.path = path\n    cluster.initialization_state = self.get_node(path + self._INITIALIZATION_STATE)\n    cluster.configuration = self.get_node(path + self._CONFIGURATION)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.synchronization_state = self.get_node(path + self._SYNCHRONIZATION_STATE)\n    cluster.members = self.load_members(path + self._MEMBERS)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover_state = self.get_node(path + self._FAILOVER_STATE)\n    cluster.failsafe_configuration = self.get_node(path + self._FAILSAFE_CONFIGURATION)\n    return cluster", "CodeBleu_score": 13.641158125889131}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.path = path\n    cluster.init_state = self.get_node(path + self._INIT_STATE)\n    cluster.config = self.get_node(path + self._CONFIG)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.sync_state = self.get_node(path + self._SYNC_STATE)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster", "CodeBleu_score": 13.16757886980173}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.initialize_state = self.get_node(path + self._INITIALIZE_STATE)\n    cluster.configuration = self.get_node(path + self._CONFIGURATION)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.sync_state = self.get_node(path + self._SYNC_STATE)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_node(path + self._LEADER)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover_state = self.get_node(path + self._FAILOVER_STATE)\n    cluster.failsafe_config = self.get_node(path + self._FAILSAFE_CONFIG)\n    return cluster", "CodeBleu_score": 13.092497751710702}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    self.log.debug(\"Attempting to acquire leader lock...\")\n    try:\n        self.zk.create(self.leader_lock_path, b\"\", ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL)\n        self.log.info(\"Leader lock acquired\")\n        return True\n    except ZooKeeperError as e:\n        if isinstance(e, NodeExistsError):\n            self.log.info(\"Another instance has the lock\")\n            return False\n        else:\n            self.log.error(\"Error acquiring leader lock: %s\", e)\n            raise e\n\n", "CodeBleu_score": 46.13636645161793}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    path = self._leader_path\n    while True:\n        try:\n            self._zk.create(path, b'', ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL)\n            return True\n        except ZooKeeperError as e:\n            if e.code!= ZooKeeperError.NODEEXISTS:\n                raise e\n            elif self._zk.exists(path):\n                return False\n            else:\n                # ZooKeeper closed or connection lost\n                return False\n        except Exception as e:\n            if not isinstance(e, ZooKeeperError):\n                _log.error('Unexpected error: %s', e)\n            if not isinstance(e, ZooKeeperError) or e.code!= ZooKeeperError.NODEEXISTS:\n                _log.error('Failed to acquire lock: %s', e)\n            return False\n\n", "CodeBleu_score": 48.99370710041101}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._zk.create(self._leader_path, b'', ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL)\n        return True\n    except ZooKeeperError as e:\n        if e.code == ZooKeeperError.NODEEXISTS:\n            logger.info('Another instance has the lock')\n            return False\n        else:\n            raise e\n\n", "CodeBleu_score": 28.86731625457064}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id == leader.session:\n        return False\n    else:\n        try:\n            self.zk.delete(self.leader_path, recursive=True)\n        except NoNodeError:\n            pass\n        except ZooKeeperError:\n            logger.error(\"Failed to delete existing leader node.\")\n            return False\n        try:\n            self.zk.create(self.leader_path, leader.session.encode(\"utf-8\"), acl=self.acl)\n        except ZooKeeperError:\n            logger.error(\"Failed to create new leader node.\")\n            return False\n        return True\n\n", "CodeBleu_score": 29.344083318233032}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    # Check if the current client ID matches the leader's session\n    if leader.session_id!= self.session_id:\n        logger.warning(f\"Leader's session ID does not match current client's session ID. Deleting existing leader ZNode.\")\n        try:\n            self._zk.delete(self.leader_path, recursive=True)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            logger.exception(\"Failed to delete existing leader ZNode.\")\n            return False\n\n    # Create a new leader ZNode with the current client's name encoded in UTF-8\n    try:\n        self._zk.create(self.leader_path, self.client_name.encode(\"utf-8\"), mode=CreateMode.EPHEMERAL)\n    except (NoNodeError, ConnectionClosedError, RetryFailedError):\n        logger.exception(\"Failed to create new leader ZNode.\")\n        return False\n\n    return True\n\n", "CodeBleu_score": 35.37518500346582}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id!= leader.session:\n        log.warning(\"Leader session ID mismatch. Deleting existing leader.\")\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        try:\n            self.zk.create(self.leader_path, leader.name.encode(\"utf-8\"), self.acl)\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        except ZooKeeperError:\n            log.exception(\"Error creating leader ZNode.\")\n            return False\n    return True\n\n", "CodeBleu_score": 36.50391225836248}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self._last_poll + self.POLL_INTERVAL < time.time():\n        self._last_poll = time.time()\n        exhibitors = self._query_exhibitors(self._exhibitors)\n        if exhibitors:\n            new_exhibitors = exhibitors['exhibitors']\n            if new_exhibitors!= self._exhibitors:\n                self._exhibitors = new_exhibitors\n                logging.info('Exhibitors changed from %s to %s', self._exhibitors, new_exhibitors)\n                self._update_connection_string()\n            return True\n        else:\n            return False\n    else:\n        return False", "CodeBleu_score": 32.482157080060894}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None or time.time() - self._last_poll_time >= self._poll_interval:\n        self._last_poll_time = time.time()\n        logging.debug('Polling for new exhibitor data')\n        data = self._query_exhibitors(self._exhibitors)\n        if data is not None:\n            self._exhibitors = data['exhibitors']\n            if self._zk_connection_string!= data['zk_connection_string']:\n                self._zk_connection_string = data['zk_connection_string']\n                logging.info('Exhibitor connection string updated to %s', self._zk_connection_string)\n            return True\n        return False\n    return False", "CodeBleu_score": 34.492530656807304}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll + self.POLL_INTERVAL < time.time():\n        self._last_poll = time.time()\n        try:\n            exhibitors = self._query_exhibitors(self._exhibitors)\n            if exhibitors is None:\n                return False\n            if self._zk_servers!= exhibitors.get('servers', ''):\n                logging.info('Exhibitor servers changed from %s to %s', self._zk_servers, exhibitors.get('servers', ''))\n                self._zk_servers = exhibitors.get('servers', '')\n                self._zk_port = exhibitors.get('port', 2181)\n                return True\n            return False\n        except Exception:\n            return False", "CodeBleu_score": 33.831249630786466}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (this.zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = this.zookeeperListener.getGroup();\n\tString dataId = this.zookeeperListener.getDataId();\n\tthis.logger.info(\"Unsubscribe from Zookeeper configuration, group: \" + group + \", dataId: \" + dataId);\n\ttry {\n\t\tthis.zookeeperListener.unsubscribe();\n\t}\n\tcatch (Exception e) {\n\t\tthis.logger.error(\"Failed to unsubscribe from Zookeeper configuration, group: \" + group + \", dataId: \" + dataId, e);\n\t}\n}", "CodeBleu_score": 46.17320432496843}, {"code": "public void destroy(){\n\t\tif (this.zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = this.zookeeperListener.getGroup();\n\tString dataId = this.zookeeperListener.getDataId();\n\tthis.log.info(\"start to unsubscribe from zookeeper configuration, group: {}, dataId: {}\", group, dataId);\n\ttry {\n\t\tthis.zookeeperListener.unsubscribe();\n\t} catch (Exception e) {\n\t\tthis.log.error(\"failed to unsubscribe from zookeeper configuration, group: {}, dataId: {}\", group, dataId, e);\n\t}\n}", "CodeBleu_score": 44.37724214680819}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = zookeeperListener.getGroup();\n\tString dataId = zookeeperListener.getDataId();\n\tlogger.info(\"The ZookeeperListener is unsubscribing from the Zookeeper configuration. Group: {}, DataId: {}\", group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe();\n\t} catch (Exception e) {\n\t\tlogger.error(\"An error occurred while unsubscribing from the Zookeeper configuration. Group: {}, DataId: {}\", group, dataId, e);\n\t}\n}", "CodeBleu_score": 48.56546679099909}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\t\treturn zookeeperServer.getPayload().getMetadata();\n\t}\n\treturn new HashMap<String, String>();\n}", "CodeBleu_score": 62.856732555016514}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 38.497174905089544}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getServerMetadata();\n\t} else {\n\t\treturn new HashMap<String, String>();\n\t}\n}", "CodeBleu_score": 37.85867054783362}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.253405956323217}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.259896962984144}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.259896962984144}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(new ZookeeperServerList(config, serviceDiscovery));\n}", "CodeBleu_score": 18.62663589012862}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.64531523943103}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t}\n\tcatch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.64531523943103}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tif (zkClient == null) {\n\t\tthrow new IllegalStateException(\"ZookeeperClient is not initialized\");\n\t}\n\tString group = null;\n\tString dataId = null;\n\tif (globalConfig) {\n\t\tgroup = globalConfigGroup;\n\t\tdataId = globalConfigDataId;\n\t} else {\n\t\tgroup = configGroup;\n\t\tdataId = configDataId;\n\t}\n\tif (group == null || dataId == null) {\n\t\tthrow new IllegalArgumentException(\"group or dataId is null\");\n\t}\n\tString path = \"/\" + group + \"/\" + dataId;\n\tif (log.isInfoEnabled()) {\n\t\tlog.info(\"subscribeConfig: \" + path);\n\t}\n\tZookeeperListener listener = null;\n\ttry {\n\t\tlistener = zkClient.subscribeConfig(path, new ConfigListener());\n\t} catch (Exception e) {\n\t\tlog.error(\"subscribeConfig error\", e);\n\t}\n\treturn listener;\n}", "CodeBleu_score": 28.538602325688046}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t", "CodeBleu_score": 1.8238256829159356}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = getGroup();\n\tString dataId = getDataId();\n\tlog.info(\"Subscribe config, group: {}, dataId: {}\", group, dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, new ConfigListener(group, dataId, globalConfig));\n\t} catch (Exception e) {\n\t\tlog.error(\"Subscribe config failed, group: {}, dataId: {}\", group, dataId, e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 49.15289003056637}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(\n\t\t\tenvironment.getProperty(\"zookeeper.connection.string\"),\n\t\t\tInteger.parseInt(environment.getProperty(\"zookeeper.retry.count\")),\n\t\t\tInteger.parseInt(environment.getProperty(\"zookeeper.retry.sleep.time\")));\n\n\tcuratorFramework.start();\n\n\treturn curatorFramework;\n}", "CodeBleu_score": 19.26213498973018}, {"code": "public CuratorFramework curatorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(env.getProperty(\"discovery.zookeeper.connectionString\"))\n\t\t\t.retryPolicy(new ExponentialBackoffRetry(env.getProperty(\"discovery.zookeeper.retryCount\", Integer.class), env.getProperty(\"discovery.zookeeper.sleepTime\", Integer.class)))\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 26.54045172325074}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = getZookeeperConnectionString();\n\tif (StringUtils.isEmpty(connectionString)) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string not found.\");\n\t}\n\tCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n\tbuilder.connectString(connectionString);\n\tbuilder.retryPolicy(new ExponentialBackoffRetry(getRetryCount(), getSleepTime()));\n\tCuratorFramework curatorFramework = builder.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 23.377700658911365}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * @return GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 51.07095756322223}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The GatewayRouteZookeeperConfiguration#getGatewayStrategyRouteZookeeperProcessor method returns a new instance of GatewayStrategyRouteZookeeperProcessor.\n\t */\n\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 51.07095756322223}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t/**\n * The bean method for GatewayStrategyRouteZookeeperProcessor.\n * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n */\n@Bean\n@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\npublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\nreturn new GatewayStrategyRouteZookeeperProcessor(new ZookeeperDiscoveryClient(this.zookeeperClient));\n}\n}", "CodeBleu_score": 34.460919373122486}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(zookeeperProperties.getHosts())\n\t\t\t.retryPolicy(new ExponentialBackoffRetry(1000, 3))\n\t\t\t.namespace(zookeeperProperties.getNamespace())\n\t\t\t.build();\n\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 45.74769250151613}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zookeeperClientProperties.getHosts(),\n\t\t\tzookeeperClientProperties.getSessionTimeout(), zookeeperClientProperties.getNamespace(),\n\t\t\tnew ExponentialBackoffRetry(zookeeperClientProperties.getBaseSleepTime(),\n\t\t\t\t\tzookeeperClientProperties.getMaxRetries()));\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 44.233255645619046}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(this.zookeeperClientProperties.getConnectString())\n\t\t\t.retryPolicy(new ExponentialBackoffRetry(this.zookeeperClientProperties.getRetryPolicyBaseSleepTimeMs(), this.zookeeperClientProperties.getRetryPolicyMaxRetries()))\n\t\t\t.namespace(this.zookeeperClientProperties.getNamespace())\n\t\t\t.sessionTimeoutMs(this.zookeeperClientProperties.getSessionTimeoutMs())\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 49.94259185661147}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex mutex = null;\n\ttry {\n\t\tmutex = new InterProcessMutex(zk, path);\n\t\tif (!mutex.acquire(10000)) {\n\t\t\tthrow new DistributedLockException(\"Could not acquire lock for path \" + path);\n\t\t}\n\t\tlocksMap.put(path, mutex);\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Could not acquire lock for path \" + path, e);\n\t}\n}", "CodeBleu_score": 18.892962945168453}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex mutex = new InterProcessMutex(curator, path);\n\ttry {\n\t\tif (!mutex.acquire(lockTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\tthrow new DistributedLockException(\"Could not acquire lock for path: \" + path);\n\t\t}\n\t\tlocksMap.put(path, mutex);\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(\"Could not acquire lock for path: \" + path, e);\n\t}\n}", "CodeBleu_score": 18.57513680451325}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (locksMap.containsKey(path)) {\n\t\tInterProcessMutex lock = locksMap.get(path);\n\t\tlock.acquire();\n\t} else {\n\t\tInterProcessMutex lock = new InterProcessMutex(zk, path);\n\t\tlock.acquire();\n\t\tlocksMap.put(path, lock);\n\t}\n}", "CodeBleu_score": 18.512437791173657}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tString nodePath = nodePath(dtpProperties);\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tif (dtpProperties.getConfigType().equals(ConfigType.PROPERTIES)) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equals(ConfigType.JSON)) {\n\t\tString path = ZKPaths.makePath(nodePath, dtpProperties.getConfigKey());\n\t\tString value = getVal(path, curatorFramework);\n\t\tMap<Object, Object> properties = ConfigHandler.parseJson(value);\n\t\treturn properties;\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 48.556394197982975}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tMap<Object, Object> properties = null;\n\tif (dtpProperties.getConfigType().equals(ConfigType.PROPERTIES)) {\n\t\tproperties = genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType().equals(ConfigType.JSON)) {\n\t\tproperties = genJsonMap(nodePath, curatorFramework);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 41.74311344203174}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tMap<Object, Object> properties = null;\n\tif (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.PROPERTIES)) {\n\t\tproperties = genPropertiesTypeMap(nodePath(dtpProperties), getCuratorFramework(dtpProperties));\n\t} else if (dtpProperties.getConfigType().equals(DtpProperties.ConfigType.JSON)) {\n\t\tproperties = ConfigHandler.genPropertiesMap(dtpProperties);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 27.00378386616768}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t//        DtpProperties dtpProperties = DtpProperties.getDtpProperties();\n//        if (dtpProperties!= null) {\n//            Map<Object, Object> properties = dtpProperties.getProperties();\n//            if (checkPropertyExist(environment)) {\n//                createZkPropertySource(environment, properties);\n//            }\n//        }\n    }", "CodeBleu_score": 6.117834137123169}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\n//        DtpProperties dtpProperties = this.dtpProperties;\n//        if (dtpProperties!= null) {\n//            Map<Object, Object> properties = new HashMap<>();\n//            properties.putAll(dtpProperties.getProperties());\n//            if (checkPropertyExist(environment)) {\n//                createZkPropertySource(environment, properties);\n//            }\n//        }\n    }", "CodeBleu_score": 6.117834137123169}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = this.dtpProperties;\nif (dtpProperties!= null) {\nMap<Object, Object> properties = dtpProperties.getProperties();\nif (checkPropertyExist(environment)) {\ncreateZkPropertySource(environment, properties);\n}\n}\n}", "CodeBleu_score": 53.123760268644894}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tsterAdapter(c => new ZooKeeperRouteManager(c.Resolve<ISerializer>(), c.Resolve<IRouteFactory>(), c.Resolve<ILogger>(), c.Resolve<IZookeeperClientProvider>(), configInfo)).InstancePerLifetimeScope();\nreturn this;\n}", "CodeBleu_score": 29.88877882729724}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tisterAdapter(provider => new ZooKeeperRouteManager(provider.GetRequiredService<ISerializer>(), provider.GetRequiredService<IRouteFactory>(), provider.GetRequiredService<ILogger<ZooKeeperRouteManager>>(), provider.GetRequiredService<IZookeeperClientProvider>(), configInfo)).InstancePerLifetimeScope();\n\nreturn this;\n}", "CodeBleu_score": 40.781266115163795}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tsterAdapter(c => new ZookeeperRouteManager(c.Resolve<ISerializer>(), c.Resolve<IRouteFactory>(), c.Resolve<ILogger>(), c.Resolve<IZookeeperClientProvider>(), configInfo));\nreturn this;\n}", "CodeBleu_score": 28.812740042365704}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tigInfo = GetConfigInfo(config);\n  builder.RegisterAdapter(c => new ZookeeperServiceCommandManager(c.Resolve<IServiceProvider>(), configInfo));\n  return this;\n}", "CodeBleu_score": 31.76889614013253}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n return UseZooKeeperCommandManager(builder, config);\n }", "CodeBleu_score": 17.467811960483115}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tommandManager(builder, provider => new ZookeeperServiceCommandManager(GetConfigInfo(configInfo), provider));\n }", "CodeBleu_score": 14.78960627138703}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\treturn builder.AddZookeeperFile(provider, path, optional, reloadOnChange, null);\n}", "CodeBleu_score": 13.890077440550963}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"The path must not be null or empty.\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\treturn builder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n}", "CodeBleu_score": 39.232030967057575}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\n\tif (path == null) {\n\t\tthrow new ArgumentNullException(nameof(path));\n\t}\n\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\n\treturn builder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n}", "CodeBleu_score": 38.13371097285121}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\n}", "CodeBleu_score": 5.252912912894922}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\nawait _routes.RemoveAddressAsync(Address);\nawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 18.868098564024343}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\tawait EnterRoutes();\n\nvar routes = _routes.ToList();\nforeach (var route in routes)\n{\nroute.Addresses = route.Addresses.Except(Address).ToList();\n}\nawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 59.505187011997215}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tif (routes == null)\n{\nthrow new ArgumentNullException(nameof(routes));\n}\n\nif (hostAddr == null)\n{\nthrow new ArgumentNullException(nameof(hostAddr));\n}\n\nvar routePaths = routes.Select(route => route.RoutePath);\nvar zookeeperClients = await GetZookeeperClientsAsync().ConfigureAwait(false);\n\nforeach (var zookeeperClient in zookeeperClients)\n{\nvar existingRoutes = await zookeeperClient.GetChildrenAsync(routePaths.First()).ConfigureAwait(false);\nvar routesToDelete = existingRoutes.Except(routePaths);\n\nforeach (var routeToDelete in routesToDelete)\n{\nawait zookeeperClient.DeleteAsync(routeToDelete).ConfigureAwait(false);\n}\n}\n}", "CodeBleu_score": 27.240825635002576}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tvar routePaths = routes.Select(r => r.Path);\nvar routePathsToDel = new List<string>();\nforeach (var routePath in routePaths) {\nvar routePathToDel = routePath;\nvar routePathToDelWithHostAddr = routePathToDel.Replace(hostAddr.Address, hostAddr.Host);\nif (await this.zkClient.ExistsAsync(routePathToDelWithHostAddr)) {\nroutePathsToDel.Add(routePathToDel);\n}\n}\nawait this.zkClient.DeleteAsync(routePathsToDel);\n}", "CodeBleu_score": 20.278221733874314}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\tforeach (var route in routes) {\nvar path = GetRoutePath(route);\nvar client = await GetClientAsync(route.Host);\nif (client == null) {\ncontinue;\n}\n\nvar children = await client.GetChildrenAsync(path);\nif (children == null) {\ncontinue;\n}\n\nvar routeToRemove = children.FirstOrDefault(child => {\nvar childPath = GetRoutePath(child);\nreturn childPath.Contains(hostAddr.Host);\n});\n\nif (routeToRemove!= null) {\nawait client.DeleteAsync(path + \"/\" + routeToRemove);\n}\n}\n}", "CodeBleu_score": 20.204129760189737}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\n\tif (Logging.DebugEnabled) {\n\t\tLogging.Debug(\"GetRoute: \" + data);\n\t}\n\n\tServiceRouteDescriptor descriptor = null;\n\ttry {\n\t\tdescriptor = ServiceRouteDescriptor.Deserialize(data);\n\t} catch (Exception e) {\n\t\tLogging.Error(\"GetRoute: \" + e);\n\t\treturn null;\n\t}\n\n\tif (descriptor == null) {\n\t\treturn null;\n\t}\n\n\treturn await GetRoute(descriptor);\n}", "CodeBleu_score": 35.67170241402006}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t if (data == null) {\n return null;\n }\n\n if (log.IsDebugEnabled) {\n log.Debug(data);\n }\n\n var routeDescriptor = ServiceRouteDescriptor.Deserialize(data);\n\n return await serviceRouteFactory.CreateRouteAsync(routeDescriptor);\n}", "CodeBleu_score": 25.25209726624239}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null)\n\t\treturn null;\n\tif (Logger.IsEnabled(LogLevel.Debug))\n\t\tLogger.Debug(\"Retrieved route data: {0}\", data);\n\tvar routeDescriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n\tvar route = _serviceRouteFactory.CreateServiceRoute(routeDescriptor);\n\treturn route;\n}", "CodeBleu_score": 40.427399715477875}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t (oldData == null && newData == null) return;\nif (DataEquals(oldData, newData)) return;\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\nif (oldRoute == null || newRoute == null) return;\nlock (_routes) {\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n}\nOnChanged(oldRoute, newRoute);\n}", "CodeBleu_score": 29.45638046795333}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t (DataEquals(oldData, newData)) return;\nvar newRoute = await GetRoute(newData);\nvar oldRoute = await GetRoute(oldData);\nlock (_routes) {\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n}\nOnChanged(oldRoute, newRoute);\n}", "CodeBleu_score": 27.207375911998728}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tf (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u670d\u52a1\u8def\u7531\u53d8\u66f4\uff0c\u65e7\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(oldData)}\uff0c\u65b0\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nif (DataEquals(oldData, newData))\nreturn;\n\nvar oldRoute = await GetRoute(oldData);\nvar newRoute = await GetRoute(newData);\n\nif (oldRoute == null)\nthrow new Exception(\"The old route is null.\");\n\nif (newRoute == null)\nthrow new Exception(\"The new route is null.\");\n\nlock (_lock)\n{\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n}\n\nOnChanged(oldRoute, newRoute);\n}", "CodeBleu_score": 32.66862471714699}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar existingSubscribers = await GetSubscribers(subscribers.Select(s => s.Address));\n\tvar newSubscribers = subscribers.Where(s =>!existingSubscribers.Any(es => es.Address == s.Address)).ToArray();\n\tvar existingSubscribersAddresses = existingSubscribers.Select(s => s.Address).ToArray();\n\tvar updatedSubscribers = subscribers.Where(s => existingSubscribersAddresses.Contains(s.Address)).Select(s => {\n\t\tvar existingSubscriber = existingSubscribers.First(es => es.Address == s.Address);\n\t\treturn new ServiceSubscriber(existingSubscriber.Address, existingSubscriber.Priority, s.Addresses.Concat(existingSubscriber.Addresses.Except(s.Addresses)));\n\t}).ToArray();\n\tawait SetSubscribersAsync(updatedSubscribers.Concat(newSubscribers));\n}", "CodeBleu_score": 25.187820883877293}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tar existingSubscribers = await GetSubscribers(subscribers.Select(s => s.Path));\nvar updatedSubscribers = existingSubscribers.Select(s =>\n{\nvar newAddresses = subscribers.Where(s => s.Path == s.Path).SelectMany(s => s.Addresses);\ns.Addresses = s.Addresses.Union(newAddresses).ToArray();\nreturn s;\n}).ToArray();\nawait SetSubscribersAsync(updatedSubscribers);\n}", "CodeBleu_score": 21.16152702773287}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar existing = await GetSubscribers(subscribers.Select(x => x.Path));\n\tvar newSubscribers = existing.Union(subscribers).ToArray();\n\tawait base.SetSubscribersAsync(newSubscribers);\n}", "CodeBleu_score": 12.519994415014486}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar root = await _service.GetRootAsync();\n\nforeach (var child in childrens) {\nvar node = await _service.GetNodeAsync(root, child);\n\nvar path = node.GetRelativePathToRoot();\n\nvar subscriber = await _service.GetSubscriberAsync(path);\n\nsubscribers.Add(subscriber);\n}\n\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 32.15032046415474}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nvar rootPath = _service.RootPath;\nvar debug = _service.Debug;\nforeach (var child in childrens) {\nvar childPath = rootPath + child;\nif (debug) {\nConsole.WriteLine($\"Getting subscribers for {childPath}\"); } var sub = await _service.GetSubscriber(childPath); if (debug) { Console.WriteLine($\"Subscriber for {childPath} is {sub}\"); }\nsubscribers.Add(sub);\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 42.74552587488475}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\tvar subscribers = new List<ServiceSubscriber>();\nforeach (var child in childrens) {\nvar path = $\"{root}/{child}\";\nLog.Debug($\"Retrieving subscribers for child {child}\");\nvar subscribersNode = await _client.ReadNodeAsync(path);\nvar subscribersList = subscribersNode.Value.Value.ToList();\nforeach (var subscriber in subscribersList) {\nvar subscriberPath = $\"{path}/{subscriber}\";\nLog.Debug($\"Retrieving subscriber {subscriber} for child {child}\");\nvar subscriberNode = await _client.ReadNodeAsync(subscriberPath);\nvar subscriberValue = subscriberNode.Value.Value;\nvar subscriberInfo = new ServiceSubscriber(subscriber, subscriberValue);\nsubscribers.Add(subscriberInfo);\n}\n}\nreturn subscribers.ToArray();\n}", "CodeBleu_score": 40.14906749642366}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tf (_subscribers!= null)\nreturn;\n\nvar (waitHandle, zooKeeper) = await GetZooKeeper();\n\ntry {\nif (!await zooKeeper.ExistsAsync(_configInfo.SubscriberPath)) {\nif (_logger.IsEnabled(LogLevel.Warning))\n_logger.LogWarning($\"\u8ba2\u9605\u8005\u8282\u70b9\uff1a{_configInfo.SubscriberPath} \u4e0d\u5b58\u5728\u3002\");\n_subscribers = new ServiceSubscriber[0];\nreturn;\n}\n\nvar childrens = await zooKeeper.GetChildrenAsync(_configInfo.SubscriberPath);\n_subscribers = await GetSubscribers(childrens);\n}\ncatch (Exception ex) {\nif (_logger.IsEnabled(LogLevel.Error))\n_logger.LogError(ex, $\"\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u65f6\u53d1\u751f\u5f02\u5e38\u3002\");\n}\nfinally {\nwaitHandle.Set();\n}\n}", "CodeBleu_score": 51.99860150143123}, {"code": "private async Task EnterSubscribers(){\n\tf (_subscribers!= null)\nreturn;\n\nvar zooKeeper = await GetZooKeeper();\n\nvar subscriberPath = _configInfo.SubscriberPath;\nif (!subscriberPath.EndsWith(\"/\"))\nsubscriberPath += \"/\";\n\nvar subscriberPathExists = await zooKeeper.ExistsAsync(subscriberPath);\nif (!subscriberPathExists) {\n_logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84 {subscriberPath} \u4e0d\u5b58\u5728\u3002\");\n_subscribers = Array.Empty<ServiceSubscriber>();\nreturn;\n}\n\nvar children = await zooKeeper.GetChildrenAsync(subscriberPath);\n\n_subscribers = await GetSubscribers(children);\n}", "CodeBleu_score": 40.36936993165645}, {"code": "private async Task EnterSubscribers(){\n\tar (mre, zooKeeper) = await GetZooKeeper();\ntry {\nif (_subscribers!= null)\nreturn;\n\n_subscribers = await GetSubscribers(await zooKeeper.GetChildrenAsync(_configInfo.SubscriberPath));\n}\ncatch (Exception ex) {\nif (_logger.IsEnabled(LogLevel.Error))\n_logger.LogError(ex, \"Error while getting subscribers\");\n}\nfinally {\nmre.Set();\n}\n}", "CodeBleu_score": 33.08479381260809}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t (oldData!= null && newData!= null) {\nif (DataEquals(oldData, newData)) {\nreturn;\n}\n}\nvar serviceCommand = GetServiceCommand(newData);\nif (serviceCommand == null) {\nreturn;\n}\nvar serviceId = serviceCommand.ServiceId;\nvar serviceCommand2 = _serviceCommands.FirstOrDefault(x => x.ServiceId == serviceId);\nif (serviceCommand2!= null) {\n_serviceCommands.Remove(serviceCommand2);\n}\n_serviceCommands.Add(serviceCommand);\nOnChanged(serviceCommand, serviceCommand2);\n}", "CodeBleu_score": 29.758507970779824}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u8f6c\u6362\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(data)}\u3002\");\n\nif (data == null)\nreturn;\n\nvar descriptor = _serializer.Deserialize<byte[], ServiceCommandDescriptor>(data);\nreturn descriptor;\n}", "CodeBleu_score": 15.765893655277644}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tar oldDescriptor = GetServiceCommand(oldData);\n\tvar newDescriptor = GetServiceCommand(newData);\n\tif (oldDescriptor == null || newDescriptor == null)\n\t\treturn;\n\n\tif (oldDescriptor.ServiceId == newDescriptor.ServiceId &&!DataEquals(oldDescriptor.Data, newDescriptor.Data)) {\n\t\tvar oldCommand = GetCommand(oldDescriptor.ServiceId);\n\t\tvar newCommand = GetCommand(newDescriptor.ServiceId);\n\t\tif (oldCommand!= null) {\n\t\t\t_serviceCommands.Remove(oldCommand);\n\t\t\t_serviceCommands.Add(newCommand);\n\t\t}\n\t\tOnChanged(oldCommand, newCommand);\n\t}\n}", "CodeBleu_score": 30.50744150303012}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar data = await _client.GetDataAsync(watchedEvent.Path);\n\t\tvar action = _action;\n\t\taction(data, watchedEvent.Path);\n\t\t_client.ExistsAsync(watchedEvent.Path, this);\n\t}\n}", "CodeBleu_score": 42.24776599474925}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\t// Get the node data from the event\n\tvar nodeData = await _zooKeeper.GetDataAsync(watchedEvent.Path);\n\n\t// Execute the action with the new data\n\tawait _action(nodeData, watchedEvent);\n}", "CodeBleu_score": 36.15186486917942}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tvar nodePath = watchedEvent.Path;\n\tvar eventType = watchedEvent.Type;\n\tvar eventState = watchedEvent.State;\n\tvar eventStateValue = watchedEvent.State.ToString();\n\tvar eventTypeValue = watchedEvent.Type.ToString();\n\n\t// TODO: Add code here to handle the event.\n\n\t// Call the base ProcessImpl method to continue watching the node.\n\tawait base.ProcessImpl(watchedEvent);\n}", "CodeBleu_score": 16.869689666235548}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tices.AddSingleton<IZookeeperClientProvider>(new DefaultZookeeperClientProvider(configInfo));\nreturn builder;\n}", "CodeBleu_score": 23.64577147821498}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\ter.UseZookeeperClientProvider(GetConfigInfo(configInfo));\n}", "CodeBleu_score": 11.854851934621436}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tices.AddSingleton<IZookeeperClientProvider>(sp => new DefaultZookeeperClientProvider(configInfo, sp.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>()));\nreturn builder;\n}", "CodeBleu_score": 34.875596144706705}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tvar client = await this.GetZooKeeperClientAsync().ConfigureAwait(false);\n\ttry {\n\t\tawait this.CreateZooKeeperPathAsync(client, \"/mqtt/routes\").ConfigureAwait(false);\n\t\tforeach (var route in routes) {\n\t\t\tawait this.CreateOrUpdateZooKeeperNodeAsync(client, route).ConfigureAwait(false);\n\t\t}\n\t\tthis.Logger.LogInformation(\"Successfully set MQTT service routes.\");\n\t}\n\tcatch (Exception ex) {\n\t\tthis.Logger.LogError(ex, \"Error setting MQTT service routes.\");\n\t\tthrow;\n\t}\n}", "CodeBleu_score": 14.998253256396731}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tif (routes == null) {\n\t\tthrow new ArgumentNullException(nameof(routes));\n\t}\n\n\tif (routes.Count() == 0) {\n\t\treturn;\n\t}\n\n\tvar logger = _loggerFactory.CreateLogger(GetType());\n\tlogger.LogInformation(\"Setting MQTT routes\");\n\n\tvar clients = new List<IZooKeeper>();\n\tforeach (var route in routes) {\n\t\tvar client = await GetClient(route);\n\t\tclients.Add(client);\n\t}\n\n\tforeach (var client in clients) {\n\t\ttry {\n\t\t\tawait client.Create(MqttRoutesPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\tlogger.LogInformation(\"Created MQTT routes path\");\n\t\t}\n\t\tcatch (KeeperException.NodeExistsException) {\n\t\t\tlogger.LogInformation(\"MQTT routes path already exists\");\n\t\t}\n\n\t\tforeach (var route in routes) {\n\t\t\tvar path = GetPath(route);\n\t\t\ttry {\n\t\t\t\tawait client.Create(path, route.Serialize(), Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t\tlogger.LogInformation(\"Created MQTT route {0}\", path);\n\t\t\t}\n\t\t\tcatch (KeeperException.NodeExistsException) {\n\t\t\t\tlogger.LogInformation(\"MQTT route {0} already exists\", path);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.63567579465778}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tawait Task.Yield();\n}", "CodeBleu_score": 5.838751133402952}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tforeach (var client in this.clients) {\nvar path = this.GetRoutePath(client.Value.Id);\nvar existingRoutes = await client.Value.GetChildrenAsync(path);\nforeach (var route in existingRoutes) {\nvar routeAddr = new AddressModel(route);\nif (!routes.Any(r => r.Equals(routeAddr))) {\nvar routePath = $\"{path}/{route}\";\nawait client.Value.DeleteAsync(routePath);\n}\n}\n}\n}", "CodeBleu_score": 22.28425272039023}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t// Construct the route path\nstring routePath = MqttServiceRoute.GetRoutePath(routes);\n\n// Get the current Zookeeper clients\nList<ZookeeperClient> zookeeperClients = await GetZookeeperClientsAsync();\n\n// For each Zookeeper client, compare the existing routes with the new routes and identify routes to be deleted\nforeach (ZookeeperClient zookeeperClient in zookeeperClients) {\n// Get the current routes from Zookeeper\nList<MqttServiceRoute> currentRoutes = await zookeeperClient.GetRoutesAsync(routePath);\n\n// Identify routes to be deleted\nList<MqttServiceRoute> routesToDelete = currentRoutes.Except(routes).ToList();\n\n// If the addresses of the routes to be deleted contain the specified hostAddr, delete the corresponding node from Zookeeper\nif (routesToDelete.Any(route => route.Address.Contains(hostAddr))) {\nawait zookeeperClient.DeleteRoutesAsync(routePath, routesToDelete);\n}\n}\n}", "CodeBleu_score": 25.509440300124965}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\tif (routes == null) {\nthrow new ArgumentNullException(nameof(routes));\n}\n\nif (hostAddr == null) {\nthrow new ArgumentNullException(nameof(hostAddr));\n}\n\nvar routePaths = routes.Select(route => route.Path);\nvar currentRoutes = await GetRoutesAsync();\nvar existingRoutes = currentRoutes.Where(route => routePaths.Contains(route.Path));\nvar routesToBeDeleted = existingRoutes.Where(route =>!routes.Select(r => r.Path).Contains(route.Path));\nforeach (var route in routesToBeDeleted) {\nvar client = await GetZookeeperClientAsync(route.Address);\nvar path = route.Path;\nawait client.DeleteAsync(path, -1);\n}\n}", "CodeBleu_score": 28.656764723638222}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t", "CodeBleu_score": 1.0587007191288007}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tawait this.LogOperationAsync(new CacheOperation(CacheOperationType.SetCaches, cacheDescriptors));\n\tvar cachePath = this.GetCachePath();\n\tvar zookeeperClients = await this.GetZookeeperClientsAsync();\n\tforeach (var zookeeperClient in zookeeperClients) {\n\t\tawait this.EnsureCachePathExistsAsync(zookeeperClient, cachePath);\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cacheName = cacheDescriptor.Name;\n\t\t\tvar cacheData = this.Serialize(cacheDescriptor);\n\t\t\tvar cacheNodePath = this.GetCacheNodePath(cacheName);\n\t\t\tvar cacheNodeExists = await zookeeperClient.ExistsAsync(cacheNodePath);\n\t\t\tif (cacheNodeExists) {\n\t\t\t\tvar cacheNodeData = await zookeeperClient.GetDataAsync(cacheNodePath);\n\t\t\t\tif (cacheNodeData == cacheData) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tawait zookeeperClient.CreateAsync(cacheNodePath, cacheData, Ids.PERSISTENT);\n\t\t\tawait this.LogOperationAsync(new CacheOperation(CacheOperationType.SetCache, cacheName, cacheDescriptor));\n\t\t}\n\t}\n}", "CodeBleu_score": 31.69695550284247}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tLog.Info(\"Setting service cache descriptors.\");\n\tvar cachePaths = GetCachePaths(cacheDescriptors);\n\tvar zookeeperClients = await GetZookeeperClientsAsync();\n\tforeach (var zookeeperClient in zookeeperClients) {\n\t\tawait EnsureCachePathExistsAsync(zookeeperClient, cachePaths);\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cachePath = cachePaths[cacheDescriptor];\n\t\t\tvar cacheData = GetCacheData(cacheDescriptor);\n\t\t\tvar cacheNodeExists = await CheckIfCacheNodeExistsAsync(zookeeperClient, cachePath);\n\t\t\tif (cacheNodeExists) {\n\t\t\t\tawait UpdateCacheNodeDataAsync(zookeeperClient, cachePath, cacheData);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tawait CreateCacheNodeAsync(zookeeperClient, cachePath, cacheData);\n\t\t\t}\n\t\t}\n\t}\n\tLog.Info(\"Successfully set service cache descriptors.\");\n}", "CodeBleu_score": 28.28014663851105}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tvar (waitHandle, zooKeeperClient) = zooKeeper;\n\twaitHandle.WaitOne();\n\tif (await zooKeeperClient.ExistsAsync(path)) {\n\t\treturn;\n\t}\n\tawait zooKeeperClient.CreateAsync(path, null, ZooDefs.Ids.OpenAclUnrestricted, CreateMode.Persistent);\n\tvar parentPath = Path.GetDirectoryName(path);\n\tif (parentPath is not null) {\n\t\tawait CreateSubdirectory(zooKeeper, parentPath);\n\t}\n}", "CodeBleu_score": 29.04133113360572}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tvar (waitHandle, zk) = zooKeeper;\n\n\tvar nodeExists = await zk.ExistsAsync(path);\n\tif (nodeExists!= null) {\n\t\treturn;\n\t}\n\n\tvar nodeExistsPath = Path.GetDirectoryName(path);\n\tawait CreateSubdirectory(zooKeeper, nodeExistsPath);\n\n\tawait zk.CreateAsync(path, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n}", "CodeBleu_score": 24.26964331972036}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t// Wait for the manual reset event to be set.\nawait zooKeeper.Item1.WaitOneAsync();\n\n// Check if the path already exists.\nvar exists = await zooKeeper.Item2.ExistsAsync(path);\nif (exists) {\nreturn;\n}\n\n// Log the creation of the path.\nConsole.WriteLine($\"Creating path {path}.\"); // Create the parent path if it does not exist. var parentPath = Path.GetDirectoryName(path); if (parentPath!= null && parentPath!= path) { await CreateSubdirectory(zooKeeper, parentPath); } // Create the node. await zooKeeper.Item2.CreateAsync(path, new byte[0], Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent); }", "CodeBleu_score": 25.05008825071141}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar zooKeepers = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _config.Addresses)\n\t{\n\t\tvar (wait, zooKeeper) = CreateZooKeeper(address);\n\t\tzooKeepers.Add((wait, zooKeeper));\n\t}\n\n\tawait Task.WhenAll(zooKeepers.Select(async (zooKeeper) =>\n\t{\n\t\tawait zooKeeper.Item2.connectAsync();\n\t\tzooKeeper.Item1.Set();\n\t}));\n\n\treturn zooKeepers;\n}", "CodeBleu_score": 61.83261344525791}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.Addresses) {\nvar (connectionWait, zookeeper) = CreateZooKeeper(ipAddress);\nawait Task.Run(() => {\nif (zookeeper.State == ZooKeeper.States.CONNECTING) {\nconnectionWait.WaitOne();\n}\n});\nif (zookeeper.State == ZooKeeper.States.CONNECTED) {\nresult.Add((connectionWait, zookeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 61.980101512736766}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.IpAddresses)\n{\nvar (connectionWait, zookeeper) = CreateZooKeeper(ipAddress);\nawait Task.Run(() => zookeeper.getState());\nif (zookeeper.getState() == ZooKeeper.States.CONNECTED)\n{\nresult.Add((connectionWait, zookeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 62.48875307432061}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\teeper zooKeeper = null;\n\tsynchronized (lock) {\n\t\tif (zooKeeper == null) {\n\t\t\tzooKeeper = helper.getZooKeeper();\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 16.588286128347573}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\tooKeeper == null) {\n    synchronized (this) {\n        if (zooKeeper == null) {\n            zooKeeper = new ZooKeeper(getConnectionString(), getSessionTimeout(), this);\n        }\n    }\n}\nreturn zooKeeper;\n}", "CodeBleu_score": 29.943233420416053}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\tzooKeeper == null) {\n\t\tsynchronized (this) {\n\t\t\tif (zooKeeper == null) {\n\t\t\t\tzooKeeper = new ZooKeeper(getConnectionString(), getSessionTimeout(), this);\n\t\t\t}\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 27.17727238292198}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\ttry {\n\t\t\tthis.zk.close(waitForShutdownTimeoutMs);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 13.41912852565888}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\ttry {\n\t\t\tthis.zk.close();\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 12.2144921748339}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zk = null;\n\ttry {\n\t\tif (this.zk!= null) {\n\t\t\tzk = this.zk;\n\t\t} else {\n\t\t\tzk = this.helper.get();\n\t\t}\n\t\tif (zk!= null) {\n\t\t\tthis.zk = null;\n\t\t\tthis.helper.set(null);\n\t\t\tthis.helper.clear();\n\t\t\tif (this.defaultWatcher!= null) {\n\t\t\t\tzk.register(new Watcher() {\n\t\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\t}\n\t\t\t\t}, WatchedEvent.KeeperState.SyncConnected, true);\n\t\t\t}\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\ttry {\n\t\t\t\t\tzk.close();\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow e;\n\t} catch (Throwable e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 40.54652638184405}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tif (state.isConnected()) {\n\t\treturn true;\n\t}\n\n\tlong startTime = System.currentTimeMillis();\n\tlong waitTimeMs = connectionTimeoutMs;\n\twhile (!state.isConnected() && (waitTimeMs > 0)) {\n\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\tWatcher tempWatcher = new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t};\n\n\t\tstate.addParentWatcher(tempWatcher);\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\ttry {\n\t\t\tlatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\tstate.removeParentWatcher(tempWatcher);\n\t\t}\n\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\twaitTimeMs -= elapsed;\n\t}\n\n\tlong elapsed = System.currentTimeMillis() - startTime;\n\tif (state.isConnected()) {\n\t\tlogger.info(\"Client connected to ZooKeeper server in \" + elapsed + \"ms\");\n\t} else {\n\t\tlogger.info(\"Client failed to connect to ZooKeeper server in \" + elapsed + \"ms\");\n\t}\n\treturn state.isConnected();\n}", "CodeBleu_score": 31.39963181596922}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlong waitTimeMs = connectionTimeoutMs;\n\twhile (!state.isConnected() && (waitTimeMs > 0)) {\n\t\tfinal CountDownLatch latch = new CountDownLatch(1);\n\t\tWatcher tempWatcher = new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t};\n\n\t\tstate.addParentWatcher(tempWatcher);\n\t\tlong startTimeMs = System.currentTimeMillis();\n\t\tlong timeoutMs = Math.min(waitTimeMs, 1000);\n\t\ttry {\n\t\t\tlatch.await(timeoutMs, TimeUnit.MILLISECONDS);\n\t\t} finally {\n\t\t\tstate.removeParentWatcher(tempWatcher);\n\t\t}\n\t\tlong elapsed = Math.max(1, System.currentTimeMillis() - startTimeMs);\n\t\twaitTimeMs -= elapsed;\n\t}\n\treturn state.isConnected();\n}", "CodeBleu_score": 22.255436656892186}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\ttry {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\treturn true;\n\t} catch (InterruptedException e) {\n\t\tthrow e;\n\t} catch (Exception e) {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 14.084982486072334}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down service...\");\n\tif (started) {\n\t\tstarted = false;\n\t\ttry {\n\t\t\tservice.shutdown();\n\t\t\tif (!service.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\t\tlog.error(\"Timed out waiting for service to shut down\");\n\t\t\t\tservice.shutdownNow();\n\t\t\t\tif (!service.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n\t\t\t\t\tlog.error(\"Timed out waiting for service to shut down\");\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (InterruptedException ie) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tlog.error(\"Thread interrupted during shutdown\");\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error during shutdown\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 29.166174771927484}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t//        log.info(\"Closing service\");\n        if (started) {\n            started = false;\n            try {\n                if (waitForShutdownTimeoutMs > 0) {\n                    if (!service.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n                        log.warn(\"Service did not shut down in {}ms. Force shutting down.\", waitForShutdownTimeoutMs);\n                        service.shutdownNow();\n                    }\n                } else {\n                    service.shutdown();\n                }\n            } catch (InterruptedException e) {\n                log.warn(\"Service interrupted during shutdown. Force shutting down.\", e);\n                service.shutdownNow();\n            }\n        }\n    }", "CodeBleu_score": 26.412525660337938}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\ttry {\nif (started) {\nlog.info(\"Shutting down \" + getName());\nstarted = false;\nif (waitForShutdownTimeoutMs > 0) {\ntry {\nThread.sleep(waitForShutdownTimeoutMs);\n} catch (InterruptedException e) {\nlog.error(\"Interrupted while waiting for shutdown to complete\", e);\n}\n}\nif (started) {\nlog.error(\"Failed to shutdown \" + getName());\n}\n}\n} catch (IOException e) {\nif (Thread.currentThread().isInterrupted()) {\nlog.error(\"Interrupted while waiting for shutdown to complete\", e);\n} else {\nlog.error(\"Failed to shutdown \" + getName(), e);\n}\n}\n}", "CodeBleu_score": 51.18902629891382}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tfinal long timeout = 10000;\n\tfinal long start = System.currentTimeMillis();\n\tfinal CountDownLatch latch = new CountDownLatch(1);\n\tfinal AtomicBoolean connected = new AtomicBoolean(false);\n\tfinal AtomicBoolean timedOut = new AtomicBoolean(false);\n\n\tfinal Runnable watcher = new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tif (isConnectionStateConnected()) {\n\t\t\t\tconnected.set(true);\n\t\t\t\tlatch.countDown();\n\t\t\t} else if (System.currentTimeMillis() - start > timeout) {\n\t\t\t\ttimedOut.set(true);\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t}\n\t};\n\n\taddConnectionStateListener(new ConnectionStateListener() {\n\t\t@Override\n\t\tpublic void onConnectionStateChanged(ConnectionState connectionState) {\n\t\t\tremoveConnectionStateListener(this);\n\t\t\twatcher.run();\n\t\t}\n\t});\n\n\tlatch.await();\n\n\tremoveConnectionStateListener(watcher);\n\n\tif (timedOut.get()) {\n\t\tthrow new TimeoutException(\"Connection timed out\");\n\t}\n}", "CodeBleu_score": 32.26676344990399}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t// TODO: Implement this method\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tif (this.connectionState == ConnectionState.CONNECTED) {\n\t\treturn;\n\t}\n\n\tlong waitTime = this.connectionTimeout;\n\tif (waitTime <= 0) {\n\t\twaitTime = DEFAULT_CONNECTION_TIMEOUT;\n\t}\n\n\tfinal CountDownLatch latch = new CountDownLatch(1);\n\tfinal AtomicBoolean connectionStateChanged = new AtomicBoolean(false);\n\tfinal AtomicBoolean connectionTimeoutReached = new AtomicBoolean(false);\n\n\tthis.connectionStateWatcher = new Watcher() {\n\t\t@Override\n\t\tpublic void onEvent(Event event) {\n\t\t\tif (event instanceof ConnectionEvent) {\n\t\t\t\tConnectionEvent connectionEvent = (ConnectionEvent) event;\n\t\t\t\tif (connectionEvent.getConnectionState() == ConnectionState.CONNECTED) {\n\t\t\t\t\tconnectionStateChanged.set(true);\n\t\t\t\t\tlatch.countDown();\n\t\t\t\t}\n\t\t\t} else if (event instanceof TimeoutEvent) {\n\t\t\t\tconnectionTimeoutReached.set(true);\n\t\t\t\tlatch.countDown();\n\t\t\t}\n\t\t}\n\t};\n\n\tthis.connectionStateWatcher.add(this.connectionState);\n\tthis.connectionStateWatcher.add(this.connectionTimeout);\n\n\tlong startTime = System.currentTimeMillis();\n\twhile (this.connectionState!= ConnectionState.CONNECTED &&!connectionTimeoutReached.get()) {\n\t\tlong remainingWaitTime = waitTime - (System.currentTimeMillis() - startTime);\n\t\tif (remainingWaitTime <= 0) {\n\t\t\tbreak;\n\t\t}\n\t\tlatch.await(remainingWaitTime, TimeUnit.MILLISECONDS);\n\t}\n\n\tthis.connectionStateWatcher.remove(this.connectionState);\n\tthis.connectionStateWatcher.remove(this.connectionTimeout);\n\tthis.connectionStateWatcher.close();\n\tthis.connectionStateWatcher = null;\n\n\tif (connectionStateChanged.get()) {\n\t\treturn;\n\t}\n\n\tthrow new TimeoutException(\"Connection timeout reached\");\n}", "CodeBleu_score": 35.27645393555261}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\turatorFrameworkImpl client = this.client;\nCreateMode createMode = this.createMode;\nString foundNode = this.foundNode;\nif (foundNode!= null) {\n    if (client.getSessionId()!= foundNode.hashCode()) {\n        if (client.getSessionId() == 0) {\n            client.setSessionId(foundNode.hashCode());\n        } else {\n            client.setSessionId(foundNode.hashCode());\n            client.getZooKeeper().delete(foundNode, -1);\n            client.getZooKeeper().create(foundNode, \"\".getBytes(), Ids.OPEN_ACL_UNSAFE, createMode.getCreateMode());\n        }\n        client.log(Level.INFO, \"Session ID changed, deleting old node: \" + foundNode);\n    }\n}\nreturn foundNode;\n}", "CodeBleu_score": 43.538942267940264}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\ttring newSession = client.getSessionId();\nif (newSession!= null &&!newSession.equals(session)) {\n    log.info(\"Session changed from {} to {}\", session, newSession);\n    client.delete(foundNode, true);\n    session = newSession;\n    foundNode = client.create(createMode, session);\n}\nreturn foundNode;\n}", "CodeBleu_score": 28.12199155963707}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t/        String foundNode = client.getZooKeeper().create(path, data, acl, createMode);\n        if (foundNode!= null) {\n            if (doProtected()) {\n                if (client.getSessionId()!= protectedId) {\n                    client.log(\"Session ID changed from \" + protectedId + \" to \" + client.getSessionId() + \" while creating protected node \" + path);\n                    client.getZooKeeper().delete(foundNode, client.getSessionId());\n                    foundNode = client.getZooKeeper().create(path, data, acl, createMode);\n                }\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 44.888887809684896}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Stat stat = new Stat();\n\tfinal Trace trace = Trace.getTrace();\n\ttrace.start();\n\ttry {\n\t\treturn pathInForeground(path, aclList, stat);\n\t} finally {\n\t\ttrace.commit(stat);\n\t}\n}", "CodeBleu_score": 22.004740502804854}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.isLeader = false;\n\n\t// Validate the member ID\n\tif (thisId == null || thisId.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"Member ID cannot be null or empty\");\n\t}\n\n\t// Setup the cache\n\tcache = new CuratorCache(client, membershipPath, 10000);\n\tcache.getListenable().addListener(new CacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorFramework client, PathChildrenCacheEvent event) throws Exception {\n\t\t\t// If the event is a child added event, it means that a new member has joined the group\n\t\t\tif (event.getType() == PathChildrenCacheEvent.Type.CHILD_ADDED) {\n\t\t\t\t// Get the new member ID\n\t\t\t\tString newMemberId = event.getData().getPath().substring(membershipPath.length() + 1);\n\n\t\t\t\t// If the new member is not the current member, then it's a new member\n\t\t\t\tif (!newMemberId.equals(thisId)) {\n\t\t\t\t\t// Set the new member as the leader\n\t\t\t\t\tisLeader = false;\n\n\t\t\t\t\t// Create a new PersistentNode with ephemeral mode for the new member\n\t\t\t\t\tPersistentNode newMember = new PersistentNode(client, membershipPath + \"/\" + newMemberId);\n\t\t\t\t\tnewMember.setData(payload);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 38.68049073116414}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath, true);\n\tthis.cache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tif (event.getType() == CuratorCacheEvent.Type.NODE_UPDATED) {\n\t\t\t\tString newPayload = new String(event.getData().getData());\n\t\t\t\tif (!newPayload.equals(payload)) {\n\t\t\t\t\tpayload = newPayload.getBytes();\n\t\t\t\t\tif (payload == null) {\n\t\t\t\t\t\tthrow new NullPointerException(\"Payload is null\");\n\t\t\t\t\t}\n\t\t\t\t\tif (payload.length == 0) {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\"Payload is empty\");\n\t\t\t\t\t}\n\t\t\t\t\tif (payload.length > 1024) {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\"Payload is too long\");\n\t\t\t\t\t}\n\t\t\t\t\tif (!thisId.equals(new String(payload))) {\n\t\t\t\t\t\tthrow new IllegalArgumentException(\"Payload does not match thisId\");\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t});\n\tthis.node = new PersistentNode(client, membershipPath, payload);\n}", "CodeBleu_score": 38.5581552985333}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\tif (!isValidId(thisId)) {\n\t\tthrow new IllegalArgumentException(\"Member ID must be a valid Zookeeper node name\");\n\t}\n\n\tthis.cache = new CuratorCache(client, membershipPath);\n\tthis.cache.getListenable().addListener(new CuratorCacheListener() {\n\t\t@Override\n\t\tpublic void eventReceived(CuratorCacheEvent event) throws Exception {\n\t\t\tif (event.getType() == CuratorCacheEvent.Type.NODE_ADDED) {\n\t\t\t\tlogger.debug(\"Received a node added event for \" + membershipPath);\n\t\t\t\tmemberAdded(event);\n\t\t\t} else if (event.getType() == CuratorCacheEvent.Type.NODE_REMOVED) {\n\t\t\t\tlogger.debug(\"Received a node removed event for \" + membershipPath);\n\t\t\t\tmemberRemoved(event);\n\t\t\t} else if (event.getType() == CuratorCacheEvent.Type.CONNECTION_SUSPENDED) {\n\t\t\t\tlogger.debug(\"Received a connection suspended event for \" + membershipPath);\n\t\t\t\tmemberSuspended(event);\n\t\t\t} else if (event.getType() == CuratorCacheEvent.Type.CONNECTION_RECONNECTED) {\n\t\t\t\tlogger.debug(\"Received a connection reconnected event for \" + membershipPath);\n\t\t\t\tmemberReconnected(event);\n\t\t\t}\n\t\t}\n\t});\n\tthis.cache.start();\n\n\ttry {\n\t\tthis.node = client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).withACL(ZooDefs.Ids.OPEN_ACL_UNSAFE).forPath(membershipPath, payload);\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(\"Could not create the group member node\", e);\n\t}\n}", "CodeBleu_score": 39.25663882652752}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\tasync.setData().forPath(path, \"data\".getBytes()).whenComplete((data, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Updated node data is: \" + new String(data));\n\t\t\t\t\tasync.getData().forPath(path).whenComplete((data, exception) -> {\n\t\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\t\texception.printStackTrace();\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tSystem.out.println(\"Retrieved node data is: \" + new String(data));\n\t\t\t\t\t\t\tasync.setData().forPath(path, \"data2\".getBytes()).whenComplete((data, exception) -> {\n\t\t\t\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\t\t\t\texception.printStackTrace();\n\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\tSystem.out.println(\"Updated node data is: \" + new String(data));\n\t\t\t\t\t\t\t\t\tasync.getData().forPath(path).whenComplete((data, exception) -> {\n\t\t\t\t\t\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\t\t\t\t\t\texception.printStackTrace();\n\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\tSystem.out.println(\"Retrieved node data is: \" + new String(data));\n\t\t\t\t\t\t\t\t\t\t\tasync.delete().forPath(path).whenComplete((data, exception) -> {\n\t\t\t\t\t\t\t\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\t\t\t\t\t\t\t\texception.printStackTrace();\n\t\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\t\tSystem.out.println(\"Deleted node data is: \" + new String(data));\n\t\t\t\t\t\t\t\t\t\t\t\t\tasync.getData().forPath(path).whenComplete((data, exception) -> {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\tif (exception!= null) {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\texception.printStackTrace();\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tSystem.out.println(\"Retrieved node data is: \" + new String(data));\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t\t\t});\n\t\t\t\t\t\t\t\t}\n\t\t\t\t\t\t\t});\n\t\t\t\t\t\t}\n\t\t\t\t\t});\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 60.64373537042983}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\t// there was a problem\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\tasync.getData().usingWatcher(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\tSystem.out.println(\"Received event: \" + event);\n\t\t\t\t}\n\t\t\t}).forPath(path).whenComplete((data, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\t// there was a problem\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Data is: \" + new String(data));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 66.77766476934853}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t// create a node at the given path asynchronously\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\t// there was a problem\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\n\t\t\t// set up a watch on the node to handle future events\n\t\t\tasync.getData().usingWatcher(new Watcher() {\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t\tSystem.out.println(\"Received event: \" + event);\n\t\t\t\t}\n\t\t\t}).forPath(path).whenComplete((data, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\t// there was a problem\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Received data: \" + new String(data));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 66.89704789032284}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tPreconditions.checkState(!isCommitted, \"transaction already committed\");\n\n\tList<OpResult> results = new ArrayList<OpResult>();\n\tfor (Operation operation : operations) {\n\t\ttry {\n\t\t\tresults.add(operation.execute(client));\n\t\t} catch (KeeperException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\treturn results;\n}", "CodeBleu_score": 17.07366900667906}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = new ArrayList<>();\n\n\tfor (CuratorTransactionBridge.Operation operation : operations) {\n\t\ttry {\n\t\t\tresults.add(operation.execute(client));\n\t\t} catch (KeeperException.ConnectionLossException e) {\n\t\t\tthrow e;\n\t\t} catch (Exception e) {\n\t\t\tthrow new KeeperException.OperationTimeoutException(e);\n\t\t}\n\t}\n\n\treturn results;\n}", "CodeBleu_score": 17.542491627288374}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\t// TODO Auto-generated method stub\n\treturn null;\n}", "CodeBleu_score": 3.1210882854285353}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Query for all service names and their corresponding instances\nMap<String, List<ServiceInstance<InstanceDetails>>> instances = serviceDiscovery.queryForInstances(INSTANCE_SERVICE_NAME);\n\n// Print each service name and its instances\nfor (Map.Entry<String, List<ServiceInstance<InstanceDetails>>> entry : instances.entrySet()) {\n    System.out.println(\"Service: \" + entry.getKey());\n    for (ServiceInstance<InstanceDetails> instance : entry.getValue()) {\n        outputInstance(instance);\n    }\n}\n\n}", "CodeBleu_score": 35.482872837119366}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t// Query for all service names and their corresponding instances.\nMap<String, List<ServiceInstance<InstanceDetails>>> instances = serviceDiscovery.queryForInstances(\"service-name\");\n\n// Print the service names and their instances.\nfor (Map.Entry<String, List<ServiceInstance<InstanceDetails>>> entry : instances.entrySet()) {\n    System.out.println(\"Service: \" + entry.getKey());\n    for (ServiceInstance<InstanceDetails> instance : entry.getValue()) {\n        outputInstance(instance);\n    }\n}\n}", "CodeBleu_score": 34.73723397772837}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tSystem.out.println(\"Listing instances for all services...\");\n\tSet<String> services = serviceDiscovery.getServices();\n\tif (services.isEmpty()) {\n\t\tthrow new NoNodeException(\"No services found\");\n\t}\n\tfor (String service : services) {\n\t\tSystem.out.println(\"Service: \" + service);\n\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.getInstances(service);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.282835015795165}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tfilteredChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 28.406137772354217}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tfilteredChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 28.406137772354217}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.remove(READY_NODE);\n\tList<String> sortedChildren = new ArrayList<>(children);\n\tsortedChildren.sort(String::compareTo);\n\treturn sortedChildren;\n}", "CodeBleu_score": 20.49723572282766}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, zkTimeout, this);\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 20.57278875489269}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tif (newHost!= null) {\n\t\tzk = new ZooKeeper(newHost, ZK_TIMEOUT, this);\n\t} else {\n\t\tzk = new ZooKeeper(ZK_HOST, ZK_TIMEOUT, this);\n\t}\n\tif (readOnly) {\n\t\tzk.setReadOnly();\n\t}\n}", "CodeBleu_score": 25.941311012950997}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk!= null) {\nzk.close();\n}\n\nif (newHost!= null) {\nzk = new ZooKeeper(newHost, zkTimeout, this);\n}\nelse {\nzk = new ZooKeeper(zkHost, zkTimeout, this);\n}\n}", "CodeBleu_score": 22.88539091858145}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t//        List<ACL> acls = new ArrayList<ACL>();\n        List<ACL> acls = new ArrayList<>();\n        String[] aclParts = aclString.split(\",\");\n        for (String aclPart : aclParts) {\n            String[] aclPartParts = aclPart.split(\":\");\n            if (aclPartParts.length!= 3) {\n                outputStream.write((\"Invalid ACL format: \" + aclPart).getBytes());\n                continue;\n            }\n            String scheme = aclPartParts[0];\n            String id = aclPartParts[1];\n            String permString = aclPartParts[2];\n            int perm = getPermFromString(permString);\n            if (scheme.equals(ZooDefs.Ids.AUTH_IDS[0])) {\n                acls.add(new ACL(perm, new Id(scheme, id)));\n            } else if (scheme.equals(ZooDefs.Ids.AUTH_IDS[1])) {\n                acls.add(new ACL(perm, new Id(scheme, id)));\n            } else {\n                outputStream.write((\"Invalid ACL format: \" + aclPart).getBytes());\n            }\n        }\n        return acls;\n    }", "CodeBleu_score": 29.378359992677993}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> aclList = new ArrayList<ACL>();\nfor (String acl : aclString.split(\",\")) {\nString[] aclParts = acl.split(\":\");\nif (aclParts.length!= 3) {\noutputStream.write((\"Invalid ACL format: \" + acl).getBytes());\ncontinue;\n}\nint id;\ntry {\nid = Integer.parseInt(aclParts[1]);\n} catch (NumberFormatException e) {\noutputStream.write((\"Invalid ACL format: \" + acl).getBytes());\ncontinue;\n}\nint perm = 0;\nfor (int i = 0; i < aclParts[2].length(); i++) {\nswitch (aclParts[2].charAt(i)) {\ncase 'r':\nperm |= ZooDefs.Perms.READ;\nbreak;\ncase 'w':\nperm |= ZooDefs.Perms.WRITE;\nbreak;\ncase 'c':\nperm |= ZooDefs.Perms.CREATE;\nbreak;\ncase 'd':\nperm |= ZooDefs.Perms.DELETE;\nbreak;\ncase 'a':\nperm |= ZooDefs.Perms.ADMIN;\nbreak;\ndefault:\noutputStream.write((\"Unknown perm type: \" + aclParts[2].charAt(i)).getBytes());\n}\n}\nACL acl = new ACL(id, perm);\naclList.add(acl);\n}\nreturn aclList;\n}", "CodeBleu_score": 29.90288725975126}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> aclList = new ArrayList<ACL>();\n\tString[] aclSegments = aclString.split(\",\");\n\tfor (String aclSegment : aclSegments) {\n\t\tString[] aclSegmentParts = aclSegment.split(\":\");\n\t\tif (aclSegmentParts.length!= 3) {\n\t\t\toutputStream.write((\"Invalid ACL format: \" + aclSegment).getBytes());\n\t\t} else {\n\t\t\tString scheme = aclSegmentParts[0];\n\t\t\tString id = aclSegmentParts[1];\n\t\t\tString permissions = aclSegmentParts[2];\n\t\t\tACL acl = new ACL(getPermFromString(permissions));\n\t\t\tacl.setId(scheme + \":\" + id);\n\t\t\taclList.add(acl);\n\t\t}\n\t}\n\treturn aclList;\n}", "CodeBleu_score": 26.14864573251986}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to \" + url + \"...\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(Collections.emptyList())\n.maxRetries(10)\n.connectionTimeout(10000)\n.retryIntervalTime(1000)\n.sessionTimeout(10000)\n.build();\nvar connection = factory.createAsync(params, Collections.emptyList());\nwriter.write(\"Success\n\");\nvar zooKeeperMain = new ZooKeeperMain();\nreturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 40.552668499198205}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to \" + url + \"...\n\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(new ArrayList<ACL>())\n.maxRetries(3)\n.connectionTimeout(3000)\n.retryIntervalTime(1000)\n.sessionTimeout(3000)\n.build();\nvar connection = factory.createAsync(params, new ArrayList<ServerListener>());\nvar main = new ZooKeeperMain(connection);\nreturn new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 31.52036756814709}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tcting to Zookeeper instance: \" + id + \" at \" + url + \"\n\");\nvar factory = new CuratorZookeeperConnectionFactory();\nvar params = ZookeeperParams.builder()\n.id(id)\n.url(url)\n.aclList(Collections.emptyList())\n.maxRetries(3)\n.connectionTimeout(10000)\n.retryIntervalTime(1000)\n.sessionTimeout(10000)\n.build();\nvar connection = factory.createAsync(params, Collections.emptyList());\nwriter.write(\"Connection established\n\");\nvar zooKeeperMain = new ZooKeeperMain(id, connection);\nreturn new Terminal(id, url, zooKeeperMain, zooKeeperMain.getZookeeperClient());\n}", "CodeBleu_score": 61.12885193868056}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tf (!isConnected()) {\n\t\ttry {\n\t\t\tconnect();\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tclose();\n\t\t\tthrow new IllegalStateException(\"Unable to connect to \" + host + \":\" + port + \" after 6 attempts\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 17.49923247193556}, {"code": "public void blockUntilConnected(){\n\tnt tries = 0;\n\twhile (!isConnected()) {\n\t\ttry {\n\t\t\ttries++;\n\t\t\tif (tries > 6) {\n\t\t\t\tclose();\n\t\t\t\tthrow new IllegalStateException(\"Could not connect to SSH tunnel after 6 tries\");\n\t\t\t}\n\t\t\tlog.info(\"Connecting to SSH tunnel...\");\n\t\t\tconnect();\n\t\t\tlog.info(\"Connected to SSH tunnel.\");\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Could not connect to SSH tunnel: \" + e.getMessage());\n\t\t\tclose();\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException ex) {\n\t\t\t\t// ignore\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 38.029206705956234}, {"code": "public void blockUntilConnected(){\n\tnt attempt = 0;\n\twhile (true) {\n\t\ttry {\n\t\t\tconnect();\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tattempt++;\n\t\t\tif (attempt > 6) {\n\t\t\t\tclose();\n\t\t\t\tthrow new IllegalStateException(\"Failed to connect to SSH server after 6 attempts\");\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tthrow new IllegalStateException(e1);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 36.190510135510245}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tthis.zookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(e.getMessage());\n\t}\n}", "CodeBleu_score": 55.09615540092574}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tthis.zookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlogger.error(e.getMessage());\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 60.49885376875505}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Exception caught while attempting to delete node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(\"Exception caught while attempting to delete node: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 54.19907052784829}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\n    ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n    zookeeperDomainService.disconnect(serverConfiguration.getId());\n    treeItemCache.remove(id);\n});\n}", "CodeBleu_score": 90.41737480458565}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// TODO implement\n}", "CodeBleu_score": 3.9834435308745446}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t//TODO: Implement this method.\n}", "CodeBleu_score": 3.9834435308745446}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// Retrieve the server configuration\n\tServerConfig serverConfig = this.serverConfigService.getServerConfig(serverId);\n\t// Determine the connection URL based on whether SSH tunneling is enabled\n\tString connectionUrl = serverConfig.getSSHTunnelEnabled()? this.sshTunnelService.getTunnelUrl(serverId) : serverConfig.getConnectionUrl();\n\t// Start the terminal with the specified server ID and connection URL\n\tthis.zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 37.52997865476787}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tthis.zk.exec(id, command);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error executing command on server \" + id + \": \" + e.getMessage());\n\t\tSystem.out.println(\"Command: \" + command);\n\t\tSystem.out.println(\"Error: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 52.92090870795904}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tString serverId = id;\n\t\tString commandStr = command;\n\t\tSystem.out.println(\"Executing command: \" + commandStr + \" on server: \" + serverId);\n\t\tString commandResult = zooKeeper.execute(serverId, commandStr);\n\t\tSystem.out.println(\"Command result: \" + commandResult);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Command execution failed on server: \" + id + \" with command: \" + command + \". Error message: \" + e.getMessage());\n\t\tSystem.out.println(\"Command execution failed on server: \" + id + \" with command: \" + command + \". Error message: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 39.01477235796255}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tString result = zk.execute(id, command);\n\t\tSystem.out.println(\"Command executed on server \" + id + \": \" + result);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error executing command on server \" + id + \": \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 46.32807127933126}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tFile file = new File(System.getProperty(\"zookeeper.conf\"));\n\t\tif (file.exists()) {\n\t\t\tproperties.load(new FileInputStream(file));\n\t\t\tSystem.out.println(\"Loaded system properties from \" + file.getAbsolutePath());\n\t\t} else {\n\t\t\tSystem.out.println(\"Failed to load system properties from \" + file.getAbsolutePath() + \". File does not exist.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Failed to load system properties from \" + System.getProperty(\"zookeeper.conf\"));\n\t\te.printStackTrace();\n\t}\n\treturn properties;\n}", "CodeBleu_score": 37.19381898228132}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new FileInputStream(new File(\"zookeeper.properties\")));\n\t\tSystem.out.println(\"Loaded system properties from zookeeper.properties\");\n\t} catch (IOException e) {\n\t\tSystem.out.println(\"Failed to load system properties from zookeeper.properties\");\n\t}\n\treturn props;\n}", "CodeBleu_score": 24.46544415685436}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tproperties.load(new FileInputStream(System.getProperty(\"zookeeper.conf\")));\n\t} catch (IOException e) {\n\t\tSystem.out.println(\"Error reading zookeeper.conf file\");\n\t\treturn properties;\n\t}\n\treturn properties;\n}", "CodeBleu_score": 21.70819103772444}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties props = new Properties();\n\t\tprops.load(new StringReader(content));\n\t\tFile file = new File(SYS_PROP_PATH);\n\t\tif (!file.exists()) {\n\t\t\tfile.createNewFile();\n\t\t}\n\t\tprops.store(new FileOutputStream(file), null);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\tshowNotification(e.getMessage(), Notification.TYPE_ERROR_MESSAGE);\n\t}\n}", "CodeBleu_score": 17.490465527090013}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tZooKeeper.setSystemProperties(properties);\n\t} catch (Exception e) {\n\t\tLog.error(\"Failed to load Zookeeper system properties: \" + e.getMessage());\n\t\tNotification.show(new Notification(e.getMessage(), Notification.Type.ERROR_MESSAGE));\n\t}\n\ttry {\n\t\tZooKeeper.saveSystemProperties();\n\t} catch (Exception e) {\n\t\tLog.error(\"Failed to save Zookeeper system properties: \" + e.getMessage());\n\t\tNotification.show(new Notification(e.getMessage(), Notification.Type.ERROR_MESSAGE));\n\t}\n}", "CodeBleu_score": 34.9402346349544}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties properties = new Properties();\n\ttry {\n\t\tproperties.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\t// TODO Auto-generated catch block\n\t\te.printStackTrace();\n\t}\n\tString path = getSysPropPath();\n\ttry {\n\t\tproperties.store(new FileOutputStream(path), \"Zookeeper system properties\");\n\t} catch (IOException e) {\n\t\t// TODO Auto-generated catch block\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 22.887108866350964}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tString result = \"\";\n\tBufferedReader in = null;\n\ttry {\n\t\tin = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = in.readLine())!= null) {\n\t\t\tresult += line;\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from socket\", e);\n\t} finally {\n\t\tcleanup(in);\n\t\tcleanup(client);\n\t}\n\treturn result;\n}", "CodeBleu_score": 43.59156731554082}, {"code": "private String response(Socket client){\n\ttringBuilder response = new StringBuilder();\nBufferedReader in = null;\ntry {\nin = new BufferedReader(new InputStreamReader(client.getInputStream()));\nString line = null;\nwhile ((line = in.readLine())!= null) {\nresponse.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(\"Error reading response from client.\", e);\n} finally {\ncleanup(in);\ncleanup(client);\n}\nreturn response.toString();\n}", "CodeBleu_score": 48.23400352970453}, {"code": "private String response(Socket client){\n\ttringBuilder sb = new StringBuilder();\nBufferedReader br = null;\ntry {\nbr = new BufferedReader(new InputStreamReader(client.getInputStream()));\nString line = null;\nwhile ((line = br.readLine())!= null) {\nsb.append(line);\n}\n} catch (IOException e) {\nthrow new IllegalStateException(e);\n} finally {\ncleanup(br);\ncleanup(client);\n}\nreturn sb.toString();\n}", "CodeBleu_score": 53.223862225738415}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework curatorFramework = this.curatorFramework(params);\n\tcuratorFramework.start();\n\ttry {\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(\"Zookeeper connection failed\", e);\n\t}\n\treturn new CuratorZookeeperConnection(curatorFramework, params);\n}", "CodeBleu_score": 43.56056027226123}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework curatorFramework = curatorFramework(params);\n    curatorFramework.start();\n    curatorFramework.blockUntilConnected(5000, TimeUnit.MILLISECONDS);\n    return new CuratorZookeeperConnection<>(curatorFramework, params);\n}", "CodeBleu_score": 37.62043301956966}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tmework curatorFramework = curatorFramework(params);\ncuratorFramework.start();\n\ntry {\n    curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (Exception e) {\n    curatorFramework.close();\n    throw new ZookeeperException(\"Failed to establish connection to Zookeeper\", e);\n}\n\nreturn new CuratorZookeeperConnection<>(curatorFramework, params);\n}", "CodeBleu_score": 56.13005172542562}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t// Check if synchronization is already in progress.\nif (isSync.get()) {\nlog.info(\"ZookeeperSync is already in progress.\");\nreturn;\n}\n\n// Log the start of the synchronization process.\nlog.info(\"Starting ZookeeperSync.\");\n\n// Add a CuratorTreeCacheListener to the TreeCache.\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n@Override\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nif (event.getType() == TreeCacheEvent.Type.CHILD_ADDED) {\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeAdded(event.getData().getPath(), event.getData().getData());\n}\n} else if (event.getType() == TreeCacheEvent.Type.CHILD_UPDATED) {\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeUpdated(event.getData().getPath(), event.getData().getData());\n}\n} else if (event.getType() == TreeCacheEvent.Type.CHILD_REMOVED) {\nfor (ZookeeperNodeListener listener : listeners) {\nlistener.onNodeRemoved(event.getData().getPath());\n}\n}\n}\n});\n\n// Attempt to start the TreeCache.\ntry {\ntreeCache.start();\nisSync.set(true);\nlog.info(\"ZookeeperSync started.\");\n} catch (Exception e) {\nlog.error(\"ZookeeperSync failed to start.\", e);\ntreeCache.close();\n}\n}", "CodeBleu_score": 43.953442324230586}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.get()) {\nlog.info(\"Sync already in progress for {}\", this.id);\nreturn;\n}\n\nlog.info(\"Starting sync for {}\", this.id);\n\nthis.treeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n@Override\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nif (event.getType() == TreeCacheEvent.Type.NODE_ADDED) {\nlog.info(\"Node added: {}\", event.getData().getPath());\n} else if (event.getType() == TreeCacheEvent.Type.NODE_REMOVED) {\nlog.info(\"Node removed: {}\", event.getData().getPath());\n}\n}\n});\n\ntry {\nthis.treeCache.start();\n} catch (Exception e) {\nlog.error(\"Error starting TreeCache\", e);\nthis.treeCache.close();\n}\n\nisSync.set(true);\n}", "CodeBleu_score": 37.95078793548885}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.get()) {\nlog.info(\"Sync already in progress\");\nreturn;\n}\nlog.info(\"Starting sync\");\nthis.listeners = listeners;\ntreeCache = new CuratorTreeCache(curatorFramework, path);\ntreeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n@Override\npublic void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\nfor (ZookeeperNodeListener listener : listeners) {\nif (listener instanceof CuratorTreeCacheListener) {\n((CuratorTreeCacheListener) listener).childEvent(client, event);\n}\n}\n}\n});\ntreeCache.start();\nisSync.set(true);\n}", "CodeBleu_score": 34.712424450484136}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(zk, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 59.76736272083768}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(zk, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 59.76736272083768}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tlog.info(\"Unregistering service\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error deleting path \" + path, e);\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 50.36695374092734}, {"code": "public void unregisterService(){\n\t\tLOGGER.info(\"Unregistering service...\");\n\tfor (String path : paths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Error unregistering service: \" + e.getMessage());\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 54.93329639668245}, {"code": "public void unregisterService(){\n\t\tLOGGER.info(\"Unregistering service\");\n\ttry {\n\t\tcurator.delete().forPath(SERVICE_PATH);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error while deleting service path\", e);\n\t} finally {\n\t\tcurator.close();\n\t}\n}", "CodeBleu_score": 26.622701920917567}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t/        CompletableFuture.runAsync(this::makeClientReady);\n//        this.client.subscribeStateChanges(listener);\n    }", "CodeBleu_score": 5.82835402876755}, {"code": "public void addListener(IZkStateListener listener){\n\t/    this.stateListener = listener;\n    CompletableFuture.runAsync(this::makeClientReady);\n}", "CodeBleu_score": 15.361741958932301}, {"code": "public void addListener(IZkStateListener listener){\n\t/        this.client.subscribeStateChanges(listener);\n        CompletableFuture.runAsync(() -> makeClientReady(this.client, null), executor).whenComplete((a, b) -> {\n            if (b!= null) {\n                logger.error(\"Got an exception when trying to create zkclient instance, can not connect to zookeeper server, please check!\", b);\n            } else {\n                this.client.subscribeStateChanges(listener);\n            }\n        });\n    }", "CodeBleu_score": 41.65469015511923}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis(new ZookeeperClient(serverAddr, authority));\n}", "CodeBleu_score": 3.410257374014178}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t", "CodeBleu_score": 2.5861572201472476}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tthis(serverAddr, authority, new RetryOneTime(3));\n}", "CodeBleu_score": 3.6881777675079053}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (listener == null)\n\t\treturn;\n\tsynchronized (this) {\n\t\tif (listeners.containsKey(path)) {\n\t\t\tArrayList<ChildListener> list = listeners.get(path);\n\t\t\tlist.remove(listener);\n\t\t\tif (list.size() == 0)\n\t\t\t\tlisteners.remove(path);\n\t\t}\n\t}\n\tremoveTargetChildListener(path, listener);\n}", "CodeBleu_score": 45.48092203142624}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tsynchronized (childListeners) {\n\t\tMap<String, ChildListener> map = childListeners.get(path);\n\t\tif (map!= null) {\n\t\t\tmap.remove(listener);\n\t\t\tif (map.isEmpty()) {\n\t\t\t\tchildListeners.remove(path);\n\t\t\t\tremoveTargetChildListener(path, listener);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 49.15962657657991}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path cannot be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener cannot be null\");\n\t}\n\n\t// Get the listeners for the path\n\tMap<String, ChildListener> listeners = childListeners.get(path);\n\tif (listeners == null) {\n\t\treturn;\n\t}\n\n\t// Remove the listener from the map\n\tlisteners.remove(listener);\n\tif (listeners.isEmpty()) {\n\t\tchildListeners.remove(path);\n\t}\n\n\t// Remove the corresponding TargetChildListener\n\tremoveTargetChildListener(path, listener);\n}", "CodeBleu_score": 53.72303699037238}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: zh is null\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\t// 1. delete the old handle\n\tret = watcher_delete_handle(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: watcher_delete_handle failed, ret = %d\", ret);\n\t\treturn ret;\n\t}\n\t// 2. deserialize the IDC and host information\n\tret = watcher_deserialize_idc_and_hosts(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: watcher_deserialize_idc_and_hosts failed, ret = %d\", ret);\n\t\treturn ret;\n\t}\n\t// 3. initialize a new ZooKeeper handle\n\tret = watcher_initialize_handle(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: watcher_initialize_handle failed, ret = %d\", ret);\n\t\treturn ret;\n\t}\n\t// 4. initialize the environment for the new handle\n\tret = watcher_initialize_environment(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: watcher_initialize_environment failed, ret = %d\", ret);\n\t\treturn ret;\n\t}\n\t// 5. reset the table watcher\n\tret = watcher_reset_table_watcher(zh);\n\tif (ret!= QCONF_OK) {\n\t\tLOG_ERROR(\"watcher_reconnect_to_zookeeper: watcher_reset_table_watcher failed, ret = %d\", ret);\n\t\treturn ret;\n\t}\n\treturn QCONF_OK;\n}", "CodeBleu_score": 27.04559097334126}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_delete_idc_and_host(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_close_zookeeper(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_deserialize_idc_and_host(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_init_zookeeper(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_init_environment(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tif (watcher_init_table_watcher(zh)) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tret = QCONF_OK;\n\treturn ret;\n}", "CodeBleu_score": 18.324648495549447}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\t// delete the idc host information from the map\n\tlock_ht_delete(idc_host_map, idc_host_map_mu, zh);\n\t// close the old handle\n\tif (zh!= NULL) {\n\t\tzhandle_close(zh);\n\t}\n\t// deserialize the IDC and host information\n\tstring idc_host_str = \"\";\n\tif (lock_ht_find(idc_host_map, idc_host_map_mu, idc_host_key, idc_host_str) == QCONF_OK) {\n\t\t// initialize a new ZooKeeper handle with this information\n\t\tzh = zookeeper_init(idc_host_str.c_str(), watcher, ZOOKEEPER_SESSION_TIMEOUT, 0, 0, 0);\n\t\tif (zh == NULL) {\n\t\t\tQCONF_LOG_ERROR(\"zookeeper_init failed\");\n\t\t\treturn QCONF_ERR_OTHER;\n\t\t}\n\t\t// initialize the environment for the new handle\n\t\tret = watcher_init_environment(zh);\n\t\tif (ret!= QCONF_OK) {\n\t\t\tQCONF_LOG_ERROR(\"watcher_init_environment failed\");\n\t\t\treturn ret;\n\t\t}\n\t\t// reset the table watcher\n\t\tret = watcher_reset_table_watcher(zh);\n\t\tif (ret!= QCONF_OK) {\n\t\t\tQCONF_LOG_ERROR(\"watcher_reset_table_watcher failed\");\n\t\t\treturn ret;\n\t\t}\n\t} else {\n\t\tQCONF_LOG_ERROR(\"lock_ht_find failed\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\treturn ret;\n}", "CodeBleu_score": 40.47360394563532}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// Update internal tables with the handle and host information\n    // map<string, zhandle_t*> zk_handles;\n    // map<string, string> zk_hosts;\n    // zk_handles[idc] = zh;\n    // zk_hosts[idc] = idc_host;\n    // g_zk_handles = zk_handles;\n    // g_zk_hosts = zk_hosts;\n\n    // Check the connection state of the Zookeeper handle\n    // if (zh == nullptr) {\n    //     LOG(ERROR) << \"Zookeeper handle is null\";\n    //     return;\n    // }\n    // if (zhandle_state(zh)!= ZOO_CONNECTED_STATE) {\n    //     LOG(ERROR) << \"Zookeeper handle is not connected\";\n    //     return;\n    // }\n\n    // Register the current host on the Zookeeper server and set a watcher on the notify node\n    // string notify_node = \"/notify/\" + idc_host;\n    // int ret = zoo_aget_children(zh, notify_node.c_str(), 1, nullptr);\n    // if (ret == ZOK) {\n    //     LOG(ERROR) << \"Registering host on Zookeeper server failed\";\n    //     return;\n    // }\n    // if (zoo_awexists(zh, notify_node.c_str(), 1, nullptr)!= ZOK) {\n    //     LOG(ERROR) << \"Setting watcher on notify node failed\";\n    //     return;\n    // }\n}", "CodeBleu_score": 4.319947644130407}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// TODO: add your code here\n\tif (zh == NULL) {\n\t\treturn;\n\t}\n\n\t// update internal tables\n\tlock_ht_update(idc_zk_ht, idc_zk_mu, idc, zh);\n\tlock_ht_update(idc_host_ht, idc_host_mu, idc_host, zh);\n\n\t// check connection state\n\tint state = zoo_state(zh);\n\tif (state == ZOO_CONNECTED_STATE) {\n\t\t// register current host\n\t\tstring host = get_host();\n\t\tstring host_path = \"/\" + idc + \"/hosts/\" + host;\n\t\tint ret = zoo_acreate(zh, host_path.c_str(), host.c_str(), host.size(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\t\tif (ret!= ZOK) {\n\t\t\t// log an error\n\t\t\tstring err_msg = \"Error: failed to register host \" + host + \" to ZK\";\n\t\t\tlog_err(err_msg);\n\t\t} else {\n\t\t\t// set watcher on notify node\n\t\t\tstring notify_path = \"/\" + idc + \"/notify\";\n\t\t\tzoo_awexists(zh, notify_path.c_str(), 0, NULL, NULL);\n\t\t}\n\t} else {\n\t\t// log an error\n\t\tstring err_msg = \"Error: ZK handle is not connected\";\n\t\tlog_err(err_msg);\n\t}\n}", "CodeBleu_score": 49.10193347789888}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// update the handle and host information\n\tg_zk_handle = zh;\n\tg_zk_host = idc_host;\n\tg_zk_idc = idc;\n\t// check the connection state of the Zookeeper handle\n\tif (g_zk_handle == NULL) {\n\t\treturn;\n\t}\n\t// register the current host on the Zookeeper server\n\tint ret = zoo_acreate(g_zk_handle, g_zk_host.c_str(), NULL, 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (ret!= ZOK) {\n\t\tLOG(ERROR) << \"Error creating node \" << g_zk_host << \" on Zookeeper server: \" << zerror(ret);\n\t\treturn;\n\t}\n\t// set a watcher on the notify node\n\tret = zoo_awexists(g_zk_handle, g_zk_notify_node.c_str(), zk_notify_watcher, NULL, NULL);\n\tif (ret!= ZOK) {\n\t\tLOG(ERROR) << \"Error setting watcher on \" << g_zk_notify_node << \" on Zookeeper server: \" << zerror(ret);\n\t}\n}", "CodeBleu_score": 33.461241483674364}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + ':' + base64.b64encode(hashlib.sha1(password).digest())\n\n", "CodeBleu_score": 17.986475396407847}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    credential = base64.b64encode(hashlib.sha1(password.encode('utf-8')).digest()).decode('utf-8')\n    return f'{username}:{credential}'\n\n", "CodeBleu_score": 25.661840772362172}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    digest_acl_credential = hashlib.sha1(username + \":\" + password).hexdigest()\n    digest_acl_credential = base64.b64encode(digest_acl_credential)\n    digest_acl_credential = username + \":\" + digest_acl_credential\n    return digest_acl_credential\n\n", "CodeBleu_score": 32.00865504061463}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.get_lock_path()\n    if not self.zk.exists(lock_path):\n        return False\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 35.99781967687381}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.processing_element.get_lock_path()\n        if lock_path is None:\n            return False\n        else:\n            try:\n                lock_value = self.processing_element.zk_client.get(lock_path)[0]\n            except:\n                return False\n\n            return lock_value == self.instance_id\n\n", "CodeBleu_score": 40.43940400254862}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.processing_element.lock_path\n        try:\n            lock_value = self.processing_element.zk_client.get(lock_path)[0]\n        except NoNodeError:\n            return False\n        else:\n            return lock_value == self.processing_element.instance_id\n\n", "CodeBleu_score": 39.72232599330467}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    self.client.sync(lock_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value == self.id:\n        self.client.sync(self._lock_path)\n        self.client.retry(self.client.delete, lock_path)\n        self.client.sync(self._lock_path)\n        self.client.retry(self.client.delete, self._lock_path)\n        self.processing_element = None\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 51.62650942422245}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None:\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        value, stat = self.client.retry(self.client.get, lock_path)\n        if value == self.id:\n            self.client.sync(lock_path)\n            self.client.retry(self.client.delete, lock_path)\n            self.processing_element = None\n            return True\n    return False\n\n", "CodeBleu_score": 52.25211122212456}, {"code": "def consume(self)\n\t\n    try:\n        with self.lock:\n            if not self.holds_lock():\n                return False\n            self.processing_element = None\n            self.client.sync(self._lock_path)\n            self.client.retry(self.client.delete, self._lock_path)\n            self.client.sync(self._entry_path)\n            self.client.retry(self.client.delete, self._entry_path)\n            return True\n    except Exception as e:\n        logger.exception(e)\n        return False\n\n", "CodeBleu_score": 44.109944460724556}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t    self.logger.log(BLATHER, \"Reading from socket\")\n    while not self._stopped.is_set():\n        try:\n            header, buffer, offset = self._read_header(read_timeout)\n        except socket.timeout:\n            continue\n        except Exception:\n            self.logger.exception(\"Exception reading from socket\")\n            return\n\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \"Received ping\")\n            self._outstanding_ping.clear()\n            continue\n        elif header.xid == AUTH_XID:\n            self._read_auth_response(buffer, offset)\n            continue\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n            continue\n        else:\n            self._read_response(header, buffer, offset)\n            continue", "CodeBleu_score": 50.612371728394564}, {"code": "def _read_socket(self, read_timeout)\n\t    while not self._stopped.is_set():\n        try:\n            header, buffer, offset = self._read_header(read_timeout)\n        except Exception:\n            self.logger.exception(\"Exception reading header\")\n            return\n        self.logger.debug(\"Received header: %r\", header)\n        if header.xid == PING_XID:\n            self.logger.debug(\"Received ping\")\n            self._ping_outstanding = False\n        elif header.xid == AUTH_XID:\n            self.logger.debug(\"Received authentication response\")\n            try:\n                response = AuthResponse.deserialize(buffer, offset)\n            except Exception:\n                self.logger.exception(\"Exception deserializing response\")\n                self._stopped.set()\n                return\n            if response.err:\n                self.logger.error(\"Authentication failed: %s\", response.err)\n                self._stopped.set()\n                return\n            self._auth_data = response.data\n            self.logger.debug(\"Authentication successful\")\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self._read_response(header, buffer, offset)", "CodeBleu_score": 49.79086633510623}, {"code": "def _read_socket(self, read_timeout)\n\t    while not self._stopped.is_set():\n        try:\n            header, buffer, offset = self._read_header(read_timeout)\n        except Exception as exc:\n            self.logger.exception(\"Exception raised during read: %s\", exc)\n            break\n\n        if header.xid == PING_XID:\n            self.logger.debug(\"Received ping\")\n            self._ping_outstanding = False\n            continue\n\n        if header.xid == AUTH_XID:\n            self._handle_auth_response(header, buffer, offset)\n            continue\n\n        if header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n            continue\n\n        if header.xid in (\n            CREATE_XID,\n            DELETE_XID,\n            SET_XID,\n            EXISTS_XID,\n            GET_DATA_XID,\n            GET_DATA_2_XID,\n            GET_ACL_XID,\n            SET_ACL_XID,\n            CHECK_XID,\n            MULTI_XID,\n            REVISION_XID,\n            STATS_XID,\n            GET_CHILDREN_XID,\n            GET_CHILDREN_2_XID,\n            CLOSE_XID,\n        ):\n            self._read_response(header, buffer, offset)\n            continue\n\n        self.logger.warn(\"Received unknown xid %s\", header.xid)\n        break\n\n", "CodeBleu_score": 45.60778228345607}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    try:\n        self.logger.info(\"Attempting to connect to Zookeeper\")\n        self.zk = KazooClient(hosts=self.zk_hosts, timeout=self.zk_timeout, connection_retry=self.zk_retry)\n        self.zk.add_listener(self.zk_listener)\n        self.zk.start()\n        self.logger.info(\"Connected to Zookeeper\")\n    except Exception as e:\n        self.logger.warning(\"Failed to connect to Zookeeper: %s\", e)\n    self.connection_stopped.set()\n    self.zk_session_callback(self.zk.state)\n    self.logger.info(\"Stopped Zookeeper connection loop\")\n\n", "CodeBleu_score": 43.10814992475367}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting Zookeeper connection loop.\")\n    self.connection_stopped.clear()\n    while not self.stopped:\n        try:\n            self.log.info(\"Attempting to connect to Zookeeper.\")\n            self.zk = KazooClient(hosts=self.zk_hosts, timeout=self.zk_timeout)\n            self.zk.start()\n            self.log.info(\"Connected to Zookeeper.\")\n            self.zk.add_listener(self.zk_listener)\n            self.zk.stop()\n            self.log.info(\"Stopped Zookeeper connection.\")\n            self.zk_listener.connection_state = ZookeeperListener.STATE_CLOSED\n            self.zk_listener.session_callback(self.zk_listener.connection_state)\n            self.log.warning(\"Could not connect to Zookeeper.\")\n        except Exception as e:\n            self.log.warning(\"Could not connect to Zookeeper: %s\" % str(e))\n        finally:\n            self.connection_stopped.set()\n            self.log.info(\"Stopped Zookeeper connection loop.\")\n\n", "CodeBleu_score": 39.430927185943574}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Zookeeper connection loop started\")\n    self.connection_stopped.clear()\n    self.zk_client = self.zk_client_class(self.zk_hosts, self.zk_timeout, self.zk_connection_retry_policy, self.zk_session_retry_policy, self.zk_retry_attempts, self.zk_retry_delay, self.zk_retry_backoff, self.zk_retry_jitter, self.zk_retry_max_delay, self.zk_retry_on_connection_loss, self.zk_retry_on_session_lost, self.zk_retry_on_session_expired, self.zk_retry_on_no_server_response, self.zk_retry_on_connection_loss_callback, self.zk_retry_on_session_lost_callback, self.zk_retry_on_session_expired_callback, self.zk_retry_on_no_server_response_callback, self.zk_retry_on_connection_loss_args, self.zk_retry_on_session_lost_args, self.zk_retry_on_session_expired_args, self.zk_retry_on_no_server_response_args)\n    self.zk_client.start()\n    while not self.connection_stopped.is_set():\n        try:\n            self.zk_client.connect()\n            break\n        except (zk.KazooException, zk.NoServerException, zk.ConnectionLossException, zk.SessionExpiredException, zk.NoServerResponseException) as e:\n            self.log.warning(\"Zookeeper connection failed: %s\", e)\n            time.sleep(self.zk_retry_delay)\n    self.connection_stopped.set()\n    self.zk_client.stop()\n    self.log.info(\"Zookeeper connection stopped\")\n\n", "CodeBleu_score": 37.28072543640322}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]\n\n", "CodeBleu_score": 35.701061449925966}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    if identifier in sorted_members:\n        return sorted_partitions[sorted_members.index(identifier):]\n    else:\n        return []\n\n", "CodeBleu_score": 32.6335888103806}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    if identifier not in sorted_members:\n        raise ValueError('Identifier is not in the list of members')\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(sorted_members)]\n\n", "CodeBleu_score": 43.41938128504825}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self._best_effort_cleanup()\n    self.participating = False\n    self.client.retry(self.client.delete, self.create_path)\n", "CodeBleu_score": 34.55794671794343}, {"code": "def leave(self)\n\t\n    self._best_effort_cleanup()\n    self.participating = False\n    self.client.retry(self.client.delete, self.create_path)\n\n", "CodeBleu_score": 34.55794671794343}, {"code": "def leave(self)\n\t\n    self._best_effort_cleanup()\n    self._participating = False\n    self.client.retry(self.client.delete, self.create_path)\n\n", "CodeBleu_score": 28.417378416292934}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\treturn start(null);\n}", "CodeBleu_score": 4.527133060567189}, {"code": "public Result start(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (!isServerRunning()) {\n\t\t\tstartServer();\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 28.55714344881932}, {"code": "public Result start(){\n\t\ttry {\n\t\tif (this.isServerRunning()) {\n\t\t\treturn new Result(Result.SUCCESS, \"HDFS over FTP server is already running.\");\n\t\t}\n\t\tthis.startServer();\n\t\treturn new Result(Result.SUCCESS, \"HDFS over FTP server has been started successfully.\");\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\treturn new Result(Result.ERROR, \"Failed to start HDFS over FTP server: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 32.755887418261864}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tif (server!= null) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new Result(Result.SUCCESS, \"FTP server stopped\");\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Could not stop FTP server\", e);\n\t\t\treturn new Result(Result.FAILURE, \"Could not stop FTP server\");\n\t\t}\n\t} else {\n\t\treturn new Result(Result.FAILURE, \"FTP server not running\");\n\t}\n}", "CodeBleu_score": 28.592339392795967}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (server.isAlive()) {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"FTP server stopped successfully\");\n\t\t} else {\n\t\t\treturn new Result(false, \"FTP server is not running\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to stop the FTP server\", e);\n\t\treturn new Result(false, \"Failed to stop the FTP server\");\n\t}\n}", "CodeBleu_score": 33.50607318017641}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (ftpServer!= null) {\n\t\t\tftpServer.stop();\n\t\t\treturn Result.success();\n\t\t} else {\n\t\t\treturn Result.failure(\"The FTP server is not running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t\treturn Result.failure(\"The FTP server could not be stopped.\");\n\t}\n}", "CodeBleu_score": 30.630366466443203}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.0065609176613}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 51.9532858144934}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 51.9532858144934}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\thdfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 50.86398128586409}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(path.toUri().toString()), new Configuration());\n\t\tfs.rename(path, ftpFile.getPath());\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n\treturn true;\n}", "CodeBleu_score": 55.96139709998893}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = getFileSystem();\n\t\tfs.rename(path, ftpFile.getPath());\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 50.105667496428}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(path.toUri()), new Configuration());\n\t\tPath newPath = new Path(path.getParent().toString() + \"/\" + ftpFile.getName());\n\t\tfs.rename(path, newPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 60.0517876043144}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t// get the HDFS file system instance\n\tFileSystem fs = getFileSystem();\n\tif (fs == null) {\n\t\treturn null;\n\t}\n\n\t// get the HDFS directory instance\n\tPath dir = getDir();\n\tif (dir == null) {\n\t\treturn null;\n\t}\n\n\t// get the HDFS file status list\n\tFileStatus[] fileStatusList = null;\n\ttry {\n\t\tfileStatusList = fs.listStatus(dir);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files in directory \" + path.toString(), e);\n\t\treturn null;\n\t}\n\n\t// create an array of FtpFile objects\n\tFtpFile[] fileArray = new FtpFile[fileStatusList.length];\n\n\t// create a virtual file name for each file\n\tfor (int i = 0; i < fileStatusList.length; i++) {\n\t\tfileArray[i] = new FtpFile(this, fileStatusList[i]);\n\t}\n\n\t// return the array of FtpFile objects\n\treturn Collections.unmodifiableList(Arrays.asList(fileArray));\n}", "CodeBleu_score": 38.268633846078885}, {"code": "public List<FtpFile> listFiles(){\n\tList<FtpFile> list = new ArrayList<FtpFile>();\n\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(path.toString()), conf,\n\t\t\t\tnew Path(path.toString()));\n\t\tFileStatus[] files = fs.listStatus(path);\n\t\tfor (FileStatus file : files) {\n\t\t\tFtpFile f = new FtpFile(file, path.toString());\n\t\t\tlist.add(f);\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error listing files in directory: \" + path.toString(), e);\n\t}\n\treturn Collections.unmodifiableList(list);\n}", "CodeBleu_score": 26.07677566135671}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\t// get the HDFS file system instance\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\n\t\t// get the list of files in the directory\n\t\tRemoteIterator<LocatedFileStatus> it = fs.listFiles(path, true);\n\n\t\t// create an array of FtpFile objects\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\n\t\t// iterate through the list of files in the directory\n\t\twhile (it.hasNext()) {\n\t\t\tLocatedFileStatus file = it.next();\n\t\t\tFtpFile f = new FtpFile(file.getPath().toString(), file.getLen(), file.getModificationTime(), file.isDir());\n\t\t\tfiles.add(f);\n\t\t}\n\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\t// log the error and return null\n\t\tlogger.error(\"Unable to list files\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 33.70816993800681}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data\", e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 14.194204763582402}, {"code": "public void configure(){\n\t\ttry {\n\t\tloadUserData();\n\t\tconvertDeprecatedPropertyNames();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data from file: \" + userDataFile, e);\n\t}\n}", "CodeBleu_score": 16.19135094105955}, {"code": "public void configure(){\n\t\tif (configured) {\n\t\treturn;\n\t}\n\n\tconfigured = true;\n\n\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\"Failed to load user data\", e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 21.180112622063355}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tFile userFile = new File(this.userFile);\n\tif (!userFile.getParentFile().exists() &&!userFile.getParentFile().mkdirs()) {\n\t\tthrow new FtpException(FtpException.CONFIG_ERROR, \"Failed to create user data file directory.\");\n\t}\n\ttry (FileOutputStream fos = new FileOutputStream(userFile)) {\n\t\tfos.write(this.userData.getBytes());\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to write user data file.\", e);\n\t\tthrow new FtpException(FtpException.CONFIG_ERROR, \"Failed to write user data file.\");\n\t}\n}", "CodeBleu_score": 34.113578042540546}, {"code": "private void saveUserData() throws FtpException{\n\t\t// TODO Auto-generated method stub\n\n}", "CodeBleu_score": 1.2759762205190135}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile parent = new File(userDataFile.getParent());\n\tif (!parent.exists() &&!parent.mkdirs()) {\n\t\tthrow new FtpException(\"Error creating parent directory for user data file: \" + parent.getAbsolutePath());\n\t}\n\ttry (FileOutputStream out = new FileOutputStream(userDataFile)) {\n\t\tObjectOutputStream oos = new ObjectOutputStream(out);\n\t\toos.writeObject(userData);\n\t\toos.flush();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Error writing user data to file: \" + userDataFile.getAbsolutePath(), e);\n\t}\n}", "CodeBleu_score": 41.20473897860201}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 82.30052682501866}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 82.30052682501866}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 80.10398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\n//        LOG.info(\"Opening file: \" + path.toString() + \" with buffer size: \" + bufferSize);\n\n        Path qualified = qualify(path);\n        FSDataInputStream inputStream = null;\n\n        try {\n            inputStream = fs.open(qualified);\n        } catch (IOException e) {\n            LOG.warn(\"Failed to open file: \" + qualified.toString() + \" with buffer size: \" + bufferSize, e);\n        }\n\n        return inputStream;\n    }", "CodeBleu_score": 27.32673160057187}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tPath qualified = qualify(path);\nLOG.info(\"Opening \" + qualified + \" with buffer size \" + bufferSize);\nFSDataInputStream result = null;\ntry {\nresult = seaweedFileSystem.open(qualified, bufferSize);\n} catch (IOException e) {\nLOG.warn(\"Could not open \" + qualified + \" with buffer size \" + bufferSize + \". \" + e.getMessage());\n}\nreturn result;\n}", "CodeBleu_score": 28.387256251954014}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\tPath qualified = qualify(path);\nFSDataInputStream in = null;\ntry {\nin = fs.open(qualified, bufferSize);\n} catch (IOException e) {\nLOG.warn(\"Failed to open \" + qualified, e);\n}\nreturn in;\n}", "CodeBleu_score": 22.21849176182263}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t", "CodeBleu_score": 3.957500776646815}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 92.84785444656023}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 92.84785444656023}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.equalsIgnoreCase(\"HSYNC\")) {\n\t\treturn supportHsync;\n\t}\n\tif (capability.equalsIgnoreCase(\"HFLUSH\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 41.228170926528506}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}, {"code": "public boolean hasCapability(String capability){\n\t\tcapability = capability.toLowerCase();\n\tif (capability.equals(\"hsync\")) {\n\t\treturn supportHsync;\n\t} else if (capability.equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 30.084106462487327}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// If the offset is greater than the last flush offset, write metadata to the service.\n\tif (offset > lastFlushOffset) {\n\t\t// Write metadata to the service.\n\t\twriteMetadataToService();\n\t\t// Update the last flush offset.\n\t\tlastFlushOffset = offset;\n\t}\n}", "CodeBleu_score": 30.5052695560579}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\tt bytesWritten = 0;\nif (bufferToWrite.position()!= 0 || bufferToWrite.remaining()!= bufferToWrite.capacity()) {\nbufferToWrite.flip();\n}\n\nfinal int length = bufferToWrite.remaining();\n\nif (writePosition + length > totalLength) {\nthrow new IOException(\"Attempt to write beyond the end of the file.\");\n}\n\nif (writePosition + length > maxAppendLength) {\nmaxAppendLength = writePosition + length;\n}\n\nif (writeOperations.size() < maxWriteOperations) {\nfinal WriteOperation writeOperation = new WriteOperation(length, writePosition, bufferToWrite);\nwriteOperations.add(writeOperation);\n\nfinal FutureTask<Void> writeTask = new FutureTask<Void>(writeOperation.task);\ncompletionService.submit(writeTask);\n\nwriteOperation.task = writeTask;\n\nbytesWritten = length;\n}\n\nreturn bytesWritten;\n}", "CodeBleu_score": 36.93324083902851}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t (bufferToWrite == null) {\nthrow new NullPointerException(\"bufferToWrite\");\n}\n\nif (writePosition < 0) {\nthrow new IllegalArgumentException(\"writePosition\");\n}\n\nif (bufferToWrite.isReadOnly()) {\nthrow new IllegalArgumentException(\"bufferToWrite\");\n}\n\nif (writePosition > maxWritePosition) {\nthrow new IllegalArgumentException(\"writePosition\");\n}\n\nif (writeOperations.size() >= maxWriteOperations) {\nthrow new IOException(\"Too many write operations\");\n}\n\nbufferToWrite.flip();\nfinal int length = bufferToWrite.remaining();\nfinal long writeOffset = writePosition + lastTotalAppendOffset;\n\nfinal WriteOperation writeOperation = new WriteOperation(writeOffset, length, bufferToWrite);\nwriteOperations.add(writeOperation);\n\nfinal FutureTask<Void> task = new FutureTask<Void>(new WriteTask(writeOffset, length, bufferToWrite));\ncompletionService.submit(task);\n\nreturn length;\n}", "CodeBleu_score": 35.80414774791661}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t", "CodeBleu_score": 5.431302323101653}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\t// wait for the completion service to return no data\n\t\twhile (true) {\n\t\t\ttry {\n\t\t\t\t// wait for the completion service to return no data\n\t\t\t\tFuture<String> future = completionService.poll(1000, TimeUnit.MILLISECONDS);\n\t\t\t\tif (future!= null) {\n\t\t\t\t\t// if the completion service returns a future, it means a task completed\n\t\t\t\t\tString taskId = future.get();\n\t\t\t\t\t// log the task id and status\n\t\t\t\t\tlogger.debug(\"Task {} completed\", taskId);\n\t\t\t\t\t// remove the task from the completion service\n\t\t\t\t\tcompletionService.take();\n\t\t\t\t} else {\n\t\t\t\t\t// no data was returned, so no task completed\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\t// if the thread was interrupted, throw an IOException with the interruption details\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t}\n\t} catch (InterruptedException e) {\n\t\t// if the thread was interrupted, throw an IOException with the interruption details\n\t\tthrow new IOException(e);\n\t}\n}", "CodeBleu_score": 31.20924159256475}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\tif (this.completionService!= null) {\n\t\ttry {\n\t\t\tthis.completionService.take();\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 16.978777935668614}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\tList<Task> tasks = completionService.take().getTasks();\n\t\tif (tasks.isEmpty()) {\n\t\t\tbreak;\n\t\t}\n\t\tfor (Task task : tasks) {\n\t\t\tif (task.getStatus() == Task.Status.COMPLETED) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tthrow new IOException(\"Task did not complete: \" + task);\n\t\t}\n\t}\n}", "CodeBleu_score": 17.625529923687374}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tint i = 0;\n\twhile (i < writeQueue.size()) {\n\t\tif (writeQueue.get(i).isDone()) {\n\t\t\twriteQueue.remove(i);\n\t\t\ttotalAppendOffset += writeQueue.get(i).getLength();\n\t\t} else {\n\t\t\ti++;\n\t\t}\n\t}\n}", "CodeBleu_score": 24.002200997438315}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tint size = writeOperationQueue.size();\n\tfor (int i = 0; i < size; i++) {\n\t\tWriteOperation op = writeOperationQueue.poll();\n\t\tif (op.isDone()) {\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t\tif (op.getException()!= null) {\n\t\t\t\tthrow new IOException(op.getException());\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 22.708087106071513}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\t// iterate through the write queue\n\tfor (int i = 0; i < writeQueue.size(); i++) {\n\t\t// get the current write operation\n\t\tWriteOperation writeOperation = writeQueue.get(i);\n\t\t// check if the operation is done\n\t\tif (writeOperation.isDone()) {\n\t\t\t// remove the operation from the queue\n\t\t\twriteQueue.remove(i);\n\t\t\t// update the total append offset with the operation length\n\t\t\ttotalAppendOffset += writeOperation.getLength();\n\t\t\t// decrement the write queue size\n\t\t\twriteQueueSize--;\n\t\t\t// decrement the write queue index\n\t\t\twriteQueueIndex--;\n\t\t\t// decrement the i counter\n\t\t\ti--;\n\t\t}\n\t}\n}", "CodeBleu_score": 28.589364654445365}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 68.53742313318756}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n}", "CodeBleu_score": 44.788627262914936}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null || user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user or user's home directory cannot be null\");\n\t}\n\tthis.homePath = user.getHomeDirectory().getPath();\n\tthis.user = user;\n}", "CodeBleu_score": 55.40282318805113}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = new Path(dir);\n\tif (newPath.isAbsolute() && newPath.getParent()!= null) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t} else if (!newPath.isAbsolute() && newPath.getParent()!= null) {\n\t\tcurrentPath = currentPath.getParent().resolve(newPath);\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 17.598790990286606}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.equals(\"..\")) {\n\t\tif (currentPath.getParent() == null) {\n\t\t\treturn false;\n\t\t} else {\n\t\t\tcurrentPath = currentPath.getParent();\n\t\t\treturn true;\n\t\t}\n\t} else if (dir.equals(\".\")) {\n\t\treturn true;\n\t} else if (dir.equals(\"/\")) {\n\t\tcurrentPath = root;\n\t\treturn true;\n\t} else {\n\t\tPath newPath = currentPath.resolve(dir);\n\t\tif (newPath.isAbsolute()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 25.165589878016032}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath;\n\tif (dir.charAt(0) == '/') {\n\t\tnewPath = new Path(dir);\n\t} else {\n\t\tnewPath = new Path(currentPath.toString() + \"/\" + dir);\n\t}\n\tif (newPath.getParent()!= null) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 24.31231336214008}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(ConfigurationKeys.ACCESS_MODE, ConfigurationKeys.ACCESS_MODE_DEFAULT);\n\tthis.client = new FilerClient(host, port, grpcPort, accessMode);\n}", "CodeBleu_score": 29.790417094260025}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t", "CodeBleu_score": 9.364506810909306}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(\"seaweed.access.mode\", \"direct\");\n}", "CodeBleu_score": 21.65829973548748}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n//        if (path.getParent() == null) {\n//            throw new FileNotFoundException(\"Path must have a parent directory: \" + path);\n//        }\n//\n//        FilerProto.Entry entry = lookupEntry(path);\n//\n//        return new SeaweedHadoopInputStream(filerClient, entry, statistics, path);\n//\n//    }", "CodeBleu_score": 13.45879968329718}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n// TODO: implement this function\nthrow new UnsupportedOperationException(\"Not implemented yet.\");\n\n}", "CodeBleu_score": 16.099996202479577}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nfinal FilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\n    throw new FileNotFoundException(path.toString());\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 51.684790860570196}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostname = \"localhost\";\n\t}\n\tthis.threadPerMap = conf.getInt(\"mapred.job.map.tasks\", 1);\n\tthis.filesPerThread = conf.getInt(\"mapred.job.reduce.tasks\", 1);\n\tthis.threadPool = new ThreadPool(this.threadPerMap, this.filesPerThread);\n}", "CodeBleu_score": 37.08669222201899}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thostname = \"localhost\";\n\t}\n\tnumThreadsPerMap = conf.getInt(\"mapred.job.map.tasks\", 1);\n\tnumFilesPerThread = conf.getInt(\"mapred.job.map.files\", 1);\n\tthreadPool = new ThreadPoolExecutor(numThreadsPerMap, numThreadsPerMap, 0, TimeUnit.SECONDS, new LinkedBlockingQueue<Runnable>(), new ThreadFactory() {\n\t\t@Override\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 57.14577426485638}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.hostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostname = \"localhost\";\n\t}\n\tthis.threadsPerMap = conf.getInt(\"mapred.job.map.tasks\", 1);\n\tthis.filesPerThread = conf.getInt(\"mapred.job.files.per.thread\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(this.threadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread thread = new Thread(r);\n\t\t\tthread.setDaemon(true);\n\t\t\treturn thread;\n\t\t}\n\t});\n}", "CodeBleu_score": 45.52833713679574}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n  return;\n}\ntry {\n  UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n  emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n    JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n    fs.initialize(uri, conf);\n    return fs;\n  });\n  BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\n  throw new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 95.75608196582823}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\t//Create the method object\n\tjava.lang.reflect.Method methodObject = null;\n\ttry {\n\t\tmethodObject = classObject.getMethod(\"setContext\", new Class[] {String.class});\n\t} catch (NoSuchMethodException e) {\n\t\tthrow new Exception(\"The method setContext(String) does not exist in the class \" + classObject.getName());\n\t}\n\n\t//Call the method\n\tmethodObject.invoke(null, new Object[] {context});\n}", "CodeBleu_score": 25.197691043698377}, {"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null) {\n\t\tthrow new Exception(\"The context parameter is null.\");\n\t}\n\n\t// Get the current context\n\tString currentContext = getContext();\n\n\t// Check if the current context is valid\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\t// Create a new context if the current context is invalid or not set\n\t\tcurrentContext = context;\n\t} else {\n\t\t// Check if the current context already includes the provided context\n\t\tif (!currentContext.contains(context)) {\n\t\t\t// Append the new context to the existing one if it does not already exist\n\t\t\tcurrentContext += context;\n\t\t}\n\t}\n\n\t// Set the new context\n\tsetContext(currentContext);\n}", "CodeBleu_score": 24.1055356850841}, {"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getContext();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tsetContext(context);\n\t} else if (currentContext.contains(context)) {\n\t\treturn;\n\t} else {\n\t\tsetContext(currentContext + \" \" + context);\n\t}\n}", "CodeBleu_score": 22.175580375435448}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfs_ == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n\t}\n\t//hdfsFile file = hdfsOpenFile(hdfs_, uri.c_str(), O_RDONLY, 0, 0, 0);\n\thdfsFile file = hdfsOpenFile(hdfs_, uri.c_str(), O_WRONLY, 0, 0, 0);\n\tif (file == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to open file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfsDelete(hdfs_, uri.c_str(), 0)!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to delete file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->status());\n\thdfsCloseFile(hdfs_, file);\n\treturn Status::Ok();\n}", "CodeBleu_score": 45.80349493365296}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfs_ == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n\t}\n\tif (hdfsDelete(hdfs_, uri.path().c_str(), 0) == -1) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to delete file\"));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 48.29935459562954}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfs_ == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n\t}\n\thdfsFile file = hdfsOpenFile(hdfs_, uri.path().c_str(), O_WRONLY, 0, 0, 0);\n\tif (file == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not open file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->status());\n\tint rc = hdfsCloseFile(hdfs_, file);\n\tif (rc == -1) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not close file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->status());\n\treturn Status::Ok();\n}", "CodeBleu_score": 44.241066521520544}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY, 0, 0, 0);\n\tif (file == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Failed to open file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->hdfsFlush(file));\n\tRETURN_NOT_OK(libhdfs_->hdfsCloseFile(file));\n\treturn Status::Ok();\n}", "CodeBleu_score": 29.731040996784564}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not open file \" + uri.to_path()));\n\t}\n\tRETURN_NOT_OK(libhdfs_->hdfsFlush(file));\n\tRETURN_NOT_OK(libhdfs_->hdfsCloseFile(file));\n\treturn Status::Ok();\n}", "CodeBleu_score": 33.32608242965859}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Unable to open file\"));\n\t}\n\tRETURN_NOT_OK(libhdfs_->status());\n\tRETURN_NOT_OK(libhdfs_->hdfsFlush(file));\n\tRETURN_NOT_OK(libhdfs_->status());\n\tRETURN_NOT_OK(libhdfs_->hdfsCloseFile(file));\n\treturn Status::Ok();\n}", "CodeBleu_score": 34.26096584659441}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfs_ == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n\t}\n\thdfsFileInfo* info = hdfsGetPathInfo(hdfs_, uri.path().c_str());\n\tif (info == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not get file information\"));\n\t}\n\t*nbytes = info->mSize;\n\thdfsFreeFileInfo(info, 1);\n\treturn Status::Ok();\n}", "CodeBleu_score": 38.2293312303016}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  hdfsFileInfo* fileInfo = hdfsGetPathInfo(hdfs_, uri.c_str());\n  if (fileInfo == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Could not get file information\"));\n  }\n  *nbytes = fileInfo->mSize;\n  hdfsFreeFileInfo(fileInfo, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 41.70069852337961}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t\tRETURN_NOT_OK(libhdfs_->status());\n\tif (hdfs_ == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n\t}\n\thdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.path().c_str());\n\tif (file_info == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Error getting file info\"));\n\t}\n\t*nbytes = file_info->mSize;\n\thdfsFreeFileInfo(file_info, 0);\n\treturn Status::Ok();\n}", "CodeBleu_score": 38.089341709813326}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\t// Parse the configuration string\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\t// Extract the zookeeper quorum\n\tString quorum = hbaseCfg[0];\n\t// Extract the znode parent\n\tString znodeParent = (hbaseCfg.length > 1)? hbaseCfg[1] : HBASE_ZNODE_PARENT;\n\t// Ensure the quorum includes the port number\n\tif (!quorum.contains(\":\")) {\n\t\tquorum += \":\" + HBASE_DEFAULT_PORT;\n\t}\n\t// Return the pair\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 25.289016685092907}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tif (hbaseCfgString == null || hbaseCfgString.isEmpty()) {\n\t\treturn null;\n\t}\n\n\tString hbaseCfgStringLower = hbaseCfgString.toLowerCase();\n\tString quorum = \"\";\n\tString znodeParent = \"\";\n\n\t// Extract the quorum\n\tint quorumIndex = hbaseCfgStringLower.indexOf(\"zookeeper.znode.parent=\");\n\tif (quorumIndex!= -1) {\n\t\tquorum = hbaseCfgString.substring(quorumIndex + 24);\n\t\tquorum = quorum.substring(0, quorum.indexOf(\",\"));\n\t}\n\n\t// Extract the znode parent\n\tint znodeParentIndex = hbaseCfgStringLower.indexOf(\"hbase.rootdir=\");\n\tif (znodeParentIndex!= -1) {\n\t\tznodeParent = hbaseCfgString.substring(znodeParentIndex + 14);\n\t\tznodeParent = znodeParent.substring(0, znodeParent.indexOf(\",\"));\n\t}\n\n\t// Ensure the quorum includes the port number\n\tif (quorum.contains(\":\")) {\n\t\tquorum = quorum.substring(0, quorum.indexOf(\":\"));\n\t} else {\n\t\tquorum += \":2181\";\n\t}\n\n\t// Ensure the znode parent is not empty\n\tif (znodeParent.isEmpty()) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 35.824903468038805}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString hbaseCfgStringTrimmed = hbaseCfgString.trim();\n\tString[] hbaseCfgStringSplit = hbaseCfgStringTrimmed.split(\",\");\n\tString hbaseZookeeperQuorum = null;\n\tString hbaseZookeeperParent = null;\n\tif (hbaseCfgStringSplit.length == 0) {\n\t\tthrow new RuntimeException(\"HBase configuration string is empty.\");\n\t}\n\tif (hbaseCfgStringSplit.length == 1) {\n\t\thbaseZookeeperQuorum = hbaseCfgStringSplit[0];\n\t} else if (hbaseCfgStringSplit.length == 2) {\n\t\thbaseZookeeperQuorum = hbaseCfgStringSplit[0];\n\t\thbaseZookeeperParent = hbaseCfgStringSplit[1];\n\t} else {\n\t\tthrow new RuntimeException(\"HBase configuration string is malformed.\");\n\t}\n\tif (!hbaseZookeeperQuorum.contains(\":\")) {\n\t\thbaseZookeeperQuorum = hbaseZookeeperQuorum + \":2181\";\n\t}\n\tif (hbaseZookeeperParent == null) {\n\t\thbaseZookeeperParent = \"/hbase\";\n\t}\n\treturn new ImmutablePair<String, String>(hbaseZookeeperQuorum, hbaseZookeeperParent);\n}", "CodeBleu_score": 31.067253363056658}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\tonnection conn = null;\ntry {\nconn = getJdbcConnection(cfg);\n}\ncatch (AddaxException e) {\nthrow e;\n}\ncatch (Throwable e) {\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.GET_HBASE_CONNECTION_ERROR,\n\"Unable to connect to hbase cluster, please check the configuration and cluster status \", e);\n}\nfinally {\nif (conn!= null) {\ntry {\nconn.close();\n}\ncatch (SQLException e) {\nLOG.error(\"Failed to close the JDBC connection to HBase cluster\", e);\n}\n}\n}\n}", "CodeBleu_score": 20.183701518421728}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t// 1. Connect to the HBase cluster\n\tConnection conn = getJdbcConnection(cfg);\n\n\t// 2. Check the existence of the target table\n\tString fullTableName = cfg.getFullTableName();\n\tcheckTable(conn, cfg.getNamespace(), fullTableName, cfg.isThinClient());\n\n\t// 3. Retrieve the table schema and validate the configured columns\n\tPTable tableSchema = getTableSchema(conn, fullTableName);\n\tvalidateColumns(tableSchema, cfg.getColumns());\n\n\t// 4. Close the JDBC connection\n\ttry {\n\t\tconn.close();\n\t} catch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.GET_HBASE_CONNECTION_ERROR,\n\t\t\t\t\"Unable to close the JDBC connection\", e);\n\t}\n}", "CodeBleu_score": 25.372274481364066}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\ttry {\n\t\tSystem.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n\t\tSystem.setProperty(\"java.security.auth.login.config\", \"/etc/hadoop/conf/hadoop-kerberos.conf\");\n\t\tSystem.setProperty(\"hadoop.security.authentication\", \"kerberos\");\n\t\tConfiguration conf = new Configuration();\n\t\tUserGroupInformation.setConfiguration(conf);\n\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t} catch (IOException e) {\n\t\tLOGGER.error(\"Failed to login to Kerberos using the provided principal and keytab file path.\");\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 39.30981583105747}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosPrincipal!= null && kerberosKeytabFilePath!= null) {\n\t\ttry {\n\t\t\tSystem.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n\t\t\tSystem.setProperty(\"java.security.krb5.realm\", \"MYREALM\");\n\t\t\tSystem.setProperty(\"java.security.krb5.kdc\", \"MYKDC\");\n\t\t\tConfiguration conf = new Configuration();\n\t\t\tUserGroupInformation.setConfiguration(conf);\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Kerberos login failed: \" + e.getMessage());\n\t\t\tthrow new RuntimeException(\"Kerberos login failed: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.05138505820515}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosEnabled &&!kerberosPrincipal.isEmpty() &&!kerberosKeytabFilePath.isEmpty()) {\n\t\ttry {\n\t\t\tSystem.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n\t\t\tSystem.setProperty(\"java.security.auth.login.config\", \"/etc/hadoop/conf/krb5-jaas.conf\");\n\t\t\tConfiguration hadoopConf = new Configuration();\n\t\t\thadoopConf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\t\thadoopConf.set(\"hadoop.security.auth_to_local\", \"kerberos\");\n\t\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t\tSystem.out.println(\"Successfully logged in using Kerberos principal and keytab file.\");\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Failed to login using Kerberos principal and keytab file.\");\n\t\t\te.printStackTrace();\n\t\t\tthrow new RuntimeException(\"Failed to login using Kerberos principal and keytab file.\");\n\t\t}\n\t}\n}", "CodeBleu_score": 43.798468910441294}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tfor (int i = 1; i <= numCols; i++) {\n\t    String colName = rsmd.getColumnName(i);\n\t    int colType = rsmd.getColumnType(i);\n\t    ThinClientPTable.ThinClientPColumn col = null;\n\t    if (colName!= null && colType!= -1) {\n\t\tcol = new ThinClientPTable.ThinClientPColumn(colName, colType);\n\t    } else {\n\t\tthrow new SQLException(\"Column name or type is null\");\n\t    }\n\t    colMap.put(colName, col);\n\t}\n\treturn colMap;\n    }", "CodeBleu_score": 40.33770695904797}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> map = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint columnCount = rsmd.getColumnCount();\n\tfor (int i = 1; i <= columnCount; i++) {\n\t    String columnName = rsmd.getColumnName(i);\n\t    int columnType = rsmd.getColumnType(i);\n\t    ThinClientPTable.ThinClientPColumn column = new ThinClientPTable.ThinClientPColumn(columnName, columnType);\n\t    map.put(columnName, column);\n\t}\n\treturn map;\n    }", "CodeBleu_score": 33.093261541729255}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> result = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tfor (int i = 1; i <= numCols; i++) {\n\t    String columnName = rsmd.getColumnName(i);\n\t    int columnType = rsmd.getColumnType(i);\n\t    ThinClientPTable.ThinClientPColumn.DataType columnTypeData = null;\n\t    switch (columnType) {\n\t    case Types.CHAR:\n\t    case Types.VARCHAR:\n\t    case Types.LONGVARCHAR:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.STRING;\n\t\tbreak;\n\t    case Types.NUMERIC:\n\t    case Types.DECIMAL:\n\t    case Types.DOUBLE:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.DOUBLE;\n\t\tbreak;\n\t    case Types.INTEGER:\n\t    case Types.SMALLINT:\n\t    case Types.TINYINT:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.INTEGER;\n\t\tbreak;\n\t    case Types.DATE:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.DATE;\n\t\tbreak;\n\t    case Types.TIME:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.TIME;\n\t\tbreak;\n\t    case Types.TIMESTAMP:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.TIMESTAMP;\n\t\tbreak;\n\t    case Types.BINARY:\n\t    case Types.VARBINARY:\n\t    case Types.LONGVARBINARY:\n\t\tcolumnTypeData = ThinClientPTable.ThinClientPColumn.DataType.BINARY;\n\t\tbreak;\n\t    default:\n\t\tthrow new SQLException(\"Unsupported column type: \" + columnType);\n\t    }\n\t    ThinClientPTable.ThinClientPColumn column = new ThinClientPTable.ThinClientPColumn(columnName, columnTypeData);\n\t    result.put(columnName, column);\n\t}\n\treturn result;\n    }", "CodeBleu_score": 34.48825805295989}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\toenixConnection sqlConn;\nAdmin admin = null;\ntry {\nsqlConn = conn.unwrap(PhoenixConnection.class);\nadmin = sqlConn.getQueryServices().getAdmin();\n// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\ncheckTable(admin, tableName);\n// \u6e05\u7a7a\u8868\nadmin.disableTable(tableName);\nadmin.truncateTable(tableName, true);\nLOG.debug(\"Table {} has been truncated.\", tableName);\n}\ncatch (Throwable t) {\n// \u6e05\u7a7a\u8868\u5931\u8d25\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\"Failed to truncate \" + tableName + \".\", t);\n}\nfinally {\nif (admin!= null) {\ncloseAdmin(admin);\n}\n}\n}", "CodeBleu_score": 76.76746978209523}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\toenixConnection sqlConn;\nAdmin admin = null;\ntry {\nsqlConn = conn.unwrap(PhoenixConnection.class);\nadmin = sqlConn.getQueryServices().getAdmin();\n// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\ncheckTable(admin, tableName);\n// \u6e05\u7a7a\u8868\nadmin.disableTable(tableName);\nadmin.truncateTable(tableName, true);\nLOG.debug(\"Table {} has been truncated.\", tableName);\n}\ncatch (Throwable t) {\n// \u6e05\u7a7a\u8868\u5931\u8d25\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\"Failed to truncate \" + tableName + \".\", t);\n}\nfinally {\nif (admin!= null) {\ncloseAdmin(admin);\n}\n}\n}", "CodeBleu_score": 76.76746978209523}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn = conn.unwrap(PhoenixConnection.class);\n\tAdmin admin = null;\n\ttry {\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 77.35627983597777}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\ttry {\n\t\tif (checkHdfsFileType(filePath, fileType)) {\n\t\t\tLOG.info(\"add file {} to source file list\", filePath);\n\t\t\tsourceFiles.add(new Path(filePath));\n\t\t} else {\n\t\t\tLOG.error(\"file {} is not the specified file type, it only supports {}\", filePath, fileType);\n\t\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR,\n\t\t\t\t\tString.format(\"file %s is not the specified file type, it only supports %s\", filePath, fileType));\n\t\t}\n\t} catch (Exception e) {\n\t\tLOG.error(\"add file {} to source file list error\", filePath, e);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR,\n\t\t\t\tString.format(\"add file %s to source file list error\", filePath), e);\n\t}\n}", "CodeBleu_score": 32.545066016481464}, {"code": "private void addSourceFileByType(String filePath){\n\t\n//    String fileExtension = getFileExtension(filePath);\n//    if (fileExtension.equals(HdfsConstant.ORC)) {\n//        addOrcFile(filePath);\n//    }\n//    else if (fileExtension.equals(HdfsConstant.RC)) {\n//        addRcFile(filePath);\n//    }\n//    else if (fileExtension.equals(HdfsConstant.SEQ)) {\n//        addSequenceFile(filePath);\n//    }\n//    else if (fileExtension.equals(HdfsConstant.PARQUET)) {\n//        addParquetFile(filePath);\n//    }\n//    else if (fileExtension.equals(HdfsConstant.CSV) || fileExtension.equals(HdfsConstant.TEXT)) {\n//        addCsvFile(filePath);\n//    }\n//    else {\n//        String message = String.format(\"The file [%s] is not supported.\", filePath);\n//        LOG.error(message);\n//        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n//    }\n}", "CodeBleu_score": 2.1812566724741114}, {"code": "private void addSourceFileByType(String filePath){\n\t\nPath file = new Path(filePath);\n\ntry (FileSystem fs = FileSystem.get(hadoopConf); FSDataInputStream in = fs.open(file)) {\nif (isORCFile(file, fs, in)) {\nLOG.info(\"Add file \" + filePath + \" to source files list.\");\nsourceFiles.add(filePath);\n}\nelse if (isRCFile(filePath, in)) {\nLOG.info(\"Add file \" + filePath + \" to source files list.\");\nsourceFiles.add(filePath);\n}\nelse if (isSequenceFile(file, in)) {\nLOG.info(\"Add file \" + filePath + \" to source files list.\");\nsourceFiles.add(filePath);\n}\nelse if (isParquetFile(file)) {\nLOG.info(\"Add file \" + filePath + \" to source files list.\");\nsourceFiles.add(filePath);\n}\nelse if (StringUtils.equalsIgnoreCase(file.getName().substring(file.getName().lastIndexOf(\".\") + 1), HdfsConstant.CSV)\n|| StringUtils.equalsIgnoreCase(file.getName().substring(file.getName().lastIndexOf(\".\") + 1), HdfsConstant.TEXT)) {\nLOG.info(\"Add file \" + filePath + \" to source files list.\");\nsourceFiles.add(filePath);\n}\nelse {\nString message = String.format(\"Can not get the file format for [%s]\uff0cit only supports [%s].\",\nfilePath, HdfsConstant.SUPPORT_FILE_TYPE);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n}\n}\ncatch (Exception e) {\nString message = String.format(\"Can not get the file format for [%s]\uff0cit only supports [%s].\",\nfilePath, HdfsConstant.SUPPORT_FILE_TYPE);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message, e);\n}\n}", "CodeBleu_score": 34.15125304809782}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tlong startTime = System.currentTimeMillis();\n\t\tString sourceSequenceFilePathString = sourceSequenceFilePath;\n\t\tConfiguration readerSliceConfigString = readerSliceConfig;\n\t\tRecordSender recordSenderString = recordSender;\n\t\tTaskPluginCollector taskPluginCollectorString = taskPluginCollector;\n\t\t// Log the start of the reading process\n\t\tLOG.info(\"Starting sequence file reading from {} with slice config {} and record sender {} and task plugin collector {}\", sourceSequenceFilePathString, readerSliceConfigString, recordSenderString, taskPluginCollectorString);\n\t\t// Open the sequence file using the provided file path\n\t\tPath sourceSequenceFilePathPath = new Path(sourceSequenceFilePathString);\n\t\tFileSystem sourceSequenceFilePathFileSystem = sourceSequenceFilePathPath.getFileSystem(readerSliceConfigString);\n\t\tFSDataInputStream sourceSequenceFilePathInputStream = sourceSequenceFilePathFileSystem.open(sourceSequenceFilePathPath);\n\t\tSequenceFile.Reader sourceSequenceFilePathReader = new SequenceFile.Reader(sourceSequenceFilePathFileSystem, sourceSequenceFilePathPath, readerSliceConfigString);\n\t\t// Iterate through the file, reading key-value pairs\n\t\twhile (sourceSequenceFilePathReader.next(key, value)) {\n\t\t\t// For each non-blank value, transport the record using StorageReaderUtil\n\t\t\tif (value.toString().trim().length()!= 0) {\n\t\t\t\tStorageReaderUtil.transportRecord(key, value, recordSenderString, taskPluginCollectorString);\n\t\t\t}\n\t\t}\n\t\t// Close the sequence file reader\n\t\tsourceSequenceFilePathReader.close();\n\t\t// Log the end of the reading process\n\t\tlong endTime = System.currentTimeMillis();\n\t\tLOG.info(\"Sequence file reading from {} with slice config {} and record sender {} and task plugin collector {} completed in {} ms\", sourceSequenceFilePathString, readerSliceConfigString, recordSenderString, taskPluginCollectorString, (endTime - startTime));\n\t} catch (Exception e) {\n\t\tthrow new AddaxException(e);\n\t}\n}", "CodeBleu_score": 33.47819785386097}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\t// Log start of reading sequence file\n\tLOG.info(\"Start reading sequence file: \" + sourceSequenceFilePath);\n\t// Open the sequence file using the provided file path\n\tFileSystem fs = null;\n\ttry {\n\t\tfs = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\n\t\tFSDataInputStream in = fs.open(new Path(sourceSequenceFilePath));\n\t\t// Read key-value pairs from the file\n\t\twhile (in.available() > 0) {\n\t\t\t// Read the next key-value pair\n\t\t\tString line = in.readLine();\n\t\t\t// Ignore blank lines\n\t\t\tif (line!= null &&!line.trim().equals(\"\")) {\n\t\t\t\t// Transport the record using StorageReaderUtil\n\t\t\t\tRecord record = StorageReaderUtil.readRecord(line, readerSliceConfig);\n\t\t\t\tif (record!= null) {\n\t\t\t\t\trecordSender.sendToSender(record);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\tin.close();\n\t} catch (Exception e) {\n\t\t// Log error message and throw AddaxException\n\t\tLOG.error(\"Error reading sequence file: \" + sourceSequenceFilePath, e);\n\t\tthrow new AddaxException(e);\n\t} finally {\n\t\t// Close the file system\n\t\ttry {\n\t\t\tif (fs!= null) {\n\t\t\t\tfs.close();\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"Error closing file system\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 36.773736337280255}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tLOG.info(\"Starting to read sequence file \" + sourceSequenceFilePath);\n\t\tFileSystem fileSystem = FileSystem.get(new URI(sourceSequenceFilePath), readerSliceConfig);\n\t\tPath sourceSequenceFilePathPath = new Path(sourceSequenceFilePath);\n\t\tFSDataInputStream sequenceFileInputStream = fileSystem.open(sourceSequenceFilePathPath);\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(sequenceFileInputStream));\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine())!= null) {\n\t\t\tString[] keyValue = line.split(\"=\");\n\t\t\tif (keyValue.length!= 2) {\n\t\t\t\tLOG.error(\"Invalid line format in sequence file \" + sourceSequenceFilePath + \": \" + line);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tString key = keyValue[0];\n\t\t\tString value = keyValue[1];\n\t\t\tif (value.trim().length() == 0) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tRecord record = StorageReaderUtil.readRecord(key, value);\n\t\t\tif (record!= null) {\n\t\t\t\trecordSender.sendToChannel(record);\n\t\t\t}\n\t\t}\n\t\tbufferedReader.close();\n\t\tsequenceFileInputStream.close();\n\t\tLOG.info(\"Sequence file \" + sourceSequenceFilePath + \" has been read successfully.\");\n\t} catch (Exception e) {\n\t\tLOG.error(\"Error occurred while reading sequence file \" + sourceSequenceFilePath + \": \" + e.getMessage());\n\t\tthrow new AddaxException(e);\n\t}\n}", "CodeBleu_score": 38.282249836674545}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tif (StringUtils.isBlank(filepath) || StringUtils.isBlank(specifiedFileType)) {\n//        return false;\n//    }\n    if (StringUtils.isBlank(filepath)) {\n        return false;\n    }\n    boolean result = false;\n    try {\n        FileSystem fs = FileSystem.get(new URI(filepath), hadoopConf);\n        if (fs.exists(new Path(filepath))) {\n            if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_ORC)) {\n                result = isORCFile(new Path(filepath), fs, fs.open(new Path(filepath)));\n            }\n            else if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_RC)) {\n                result = isRCFile(filepath, fs.open(new Path(filepath)));\n            }\n            else if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_SEQUENCE)) {\n                result = isSequenceFile(new Path(filepath), fs.open(new Path(filepath)));\n            }\n            else if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_PARQUET)) {\n                result = isParquetFile(new Path(filepath));\n            }\n            else if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_CSV)) {\n                result = isCSVFile(new Path(filepath), fs.open(new Path(filepath)));\n            }\n            else if (specifiedFileType.equalsIgnoreCase(FILE_TYPE_TEXT)) {\n                result = isTextFile(new Path(filepath), fs.open(new Path(filepath)));\n            }\n            else {\n                LOG.info(\"The file [{}] is not supported file type.\", filepath);\n            }\n        }\n    }\n    catch (Exception e) {\n        LOG.info(\"The file [{}] is not supported file type.\", filepath);\n    }\n    return result;\n}", "CodeBleu_score": 36.71794893923543}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tDO Auto-generated method stub\n\treturn false;\n}", "CodeBleu_score": 4.117257662484625}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tan result = false;\n\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(filepath), hadoopConf);\n\t\tPath file = new Path(filepath);\n\t\tFSDataInputStream in = fs.open(file);\n\t\tif (specifiedFileType.equals(\"ORC\")) {\n\t\t\tresult = isORCFile(file, fs, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(\"RC\")) {\n\t\t\tresult = isRCFile(filepath, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(\"Sequence\")) {\n\t\t\tresult = isSequenceFile(file, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(\"Parquet\")) {\n\t\t\tresult = isParquetFile(file);\n\t\t}\n\t\telse if (specifiedFileType.equals(\"CSV\")) {\n\t\t\tresult = isCSVFile(file);\n\t\t}\n\t\telse if (specifiedFileType.equals(\"Text\")) {\n\t\t\tresult = isTextFile(file);\n\t\t}\n\t\telse {\n\t\t\tLOG.info(\"The file [{}] is not a supported file type.\", filepath);\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tLOG.info(\"The file [{}] is not a supported file type.\", filepath);\n\t}\n\treturn result;\n}", "CodeBleu_score": 35.245626873857795}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new HBaseException(HBaseException.HBASE_CONNECTION_CLOSE_ERROR, e);\n\t}\n}", "CodeBleu_score": 50.41620600873602}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new HBaseException(\"Error closing connection\", e);\n\t}\n}", "CodeBleu_score": 44.93729448823648}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new HBaseException(e.getMessage(), e, ErrorCode.HBASE_CONNECTION_CLOSE_ERROR);\n\t}\n}", "CodeBleu_score": 51.94973816663697}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 34.86308143269549}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 34.27050202110527}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 34.27050202110527}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\tString rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n\tString family = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n\tString qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n\tlong timestamp = cell.getTimestamp();\n\tbyte[] value = cell.getValueArray();\n\tint valueOffset = cell.getValueOffset();\n\tint valueLength = cell.getValueLength();\n\n\trecord.setRow(rowKey);\n\trecord.setFamily(family);\n\trecord.setQualifier(qualifier);\n\trecord.setTimestamp(timestamp);\n\n\tif (value!= null && valueLength > 0) {\n\t\tif (value[valueOffset] == 0) {\n\t\t\trecord.setBoolean(true);\n\t\t} else {\n\t\t\trecord.setBoolean(false);\n\t\t}\n\t}\n}", "CodeBleu_score": 26.671383506547407}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n//    String rowKey = cell.getRow().toString();\n//    long timestamp = cell.getTimestamp();\n//    String family = cell.getFamily().toString();\n//    String qualifier = cell.getQualifier().toString();\n//    String value = cell.getValue().toString();\n//\n//    record.addColumn(family, qualifier, timestamp, value);\n//\n//    if (rowKey.matches(rowKeyPattern)) {\n//        record.addColumn(\"rowKey\", rowKey, timestamp, rowKey);\n//    } else {\n//        throw new Exception(\"Row key does not match the expected pattern\");\n//    }\n}", "CodeBleu_score": 2.1029777907619387}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(Constants.START_ROWKEY, \"\");\n\treturn stringToBytes(userStartRowkey, isBinaryRowkey(configuration));\n}", "CodeBleu_score": 25.236873825902954}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(START_ROW_KEY);\n\tboolean isBinaryRowkey = configuration.getBoolean(IS_BINARY_ROWKEY, false);\n\treturn stringToBytes(startRowKey, isBinaryRowkey);\n}", "CodeBleu_score": 34.60760608960879}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HConstants.STARTROW, \"\");\n\treturn stringToBytes(startRowkey, configuration.getBoolean(HConstants.STARTROW_IS_BINARY, false));\n}", "CodeBleu_score": 29.576065049284367}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY_KEY, \"\");\n\tif (startRowkey.equals(\"\")) {\n\t\treturn new byte[0];\n\t} else {\n\t\treturn startRowkey.getBytes();\n\t}\n}", "CodeBleu_score": 38.869598642921}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROW_KEY_KEY);\n\tif (startRowkey == null || startRowkey.trim().length() == 0) {\n\t\treturn new byte[0];\n\t} else {\n\t\treturn startRowkey.getBytes();\n\t}\n}", "CodeBleu_score": 40.571421108747806}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(START_ROW_KEY_KEY);\n\tif (startRowKey == null || startRowKey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\treturn startRowKey.getBytes();\n}", "CodeBleu_score": 36.633915161471585}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders(record.headers());\n\tthis.data = record.value();\n}", "CodeBleu_score": 42.51346780929852}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders(record.headers());\n\tthis.data = record.value();\n}", "CodeBleu_score": 42.51346780929852}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders(record.headers());\n\tthis.data = record.value();\n}", "CodeBleu_score": 42.51346780929852}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(kafkaSettings.getProducerSettings());\n\tproducer.setClientId(kafkaSettings.getProducerSettings().getClientId() + \"-transport-notifications\");\n\tproducer.setTopic(transportNotificationSettings.getTopic());\n\tproducer.setAdmin(kafkaSettings.getAdmin());\n\treturn producer;\n}", "CodeBleu_score": 36.65721547227892}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>>();\n\tproducer.setKafkaSettings(kafkaSettings);\n\tproducer.setClientId(serviceId + \"-producer\");\n\tproducer.setTopicName(transportNotificationSettings.getTopicName());\n\tproducer.setAdmin(kafkaAdmin);\n\treturn producer;\n}", "CodeBleu_score": 39.69599176790316}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbProtoQueueMsgDecoder<ToCoreNotificationMsg> toCoreNotificationMsgDecoder = new TbProtoQueueMsgDecoder<ToCoreNotificationMsg>(ToCoreNotificationMsg.class);\n\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> toCoreNotificationMsgConsumerTemplate = new TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>>(toCoreNotificationMsgDecoder, KAFKA_TO_CORE_NOTIFICATIONS_TOPIC, KAFKA_CLIENT_ID, KAFKA_GROUP_ID);\n\ttoCoreNotificationMsgConsumerTemplate.setStatisticsService(statisticsService);\n\ttoCoreNotificationMsgConsumerTemplate.setAdmin(admin);\n\ttoCoreNotificationMsgConsumerTemplate.setQueueSize(QUEUE_SIZE);\n\treturn toCoreNotificationMsgConsumerTemplate;\n}", "CodeBleu_score": 24.178049942930812}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createToCoreNotificationsMsgConsumer(TB_KAFKA_CONSUMER_TEMPLATE_SETTINGS);\n}", "CodeBleu_score": 5.497812623099738}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t", "CodeBleu_score": 3.1900019824609216}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"No topics specified for subscription. No subscription will be performed.\");\n\t\treturn;\n\t}\n\tfor (String topicName : topicNames) {\n\t\tif (!topicExists(topicName)) {\n\t\t\tlog.info(\"Topic {} does not exist. Creating topic.\", topicName);\n\t\t\tcreateTopic(topicName);\n\t\t}\n\t\tlog.info(\"Subscribing to topic {}\", topicName);\n\t\tsubscribe(topicName);\n\t}\n}", "CodeBleu_score": 46.355807158168616}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"No topics to subscribe to\");\n\t\tdoUnsubscribe();\n\t} else {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (topicName.isEmpty()) {\n\t\t\t\tlog.warn(\"Skipping empty topic name\");\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tif (!topicService.exists(topicName)) {\n\t\t\t\t\tlog.info(\"Creating topic: \" + topicName);\n\t\t\t\t\ttopicService.create(topicName);\n\t\t\t\t}\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Failed to create topic: \" + topicName, e);\n\t\t\t}\n\t\t\ttry {\n\t\t\t\tlog.info(\"Subscribing to topic: \" + topicName);\n\t\t\t\tconsumer.subscribe(topicName);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.error(\"Failed to subscribe to topic: \" + topicName, e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 46.97016041131029}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tLOG.info(\"No topics to subscribe to, skipping subscription.\");\n\t\treturn;\n\t}\n\tfor (String topicName : topicNames) {\n\t\tif (topicName == null || topicName.isEmpty()) {\n\t\t\tLOG.warn(\"Topic name is empty, skipping subscription.\");\n\t\t\tcontinue;\n\t\t}\n\t\tif (!topics.containsKey(topicName)) {\n\t\t\tLOG.info(\"Topic \" + topicName + \" does not exist, creating it.\");\n\t\t\ttopics.put(topicName, new Topic(topicName));\n\t\t}\n\t}\n\tfor (String topicName : topics.keySet()) {\n\t\tif (topicNames.contains(topicName)) {\n\t\t\tLOG.info(\"Subscribing to topic \" + topicName);\n\t\t\ttopics.get(topicName).subscribe(consumer);\n\t\t} else {\n\t\t\tLOG.info(\"Unsubscribing from topic \" + topicName);\n\t\t\ttopics.get(topicName).unsubscribe(consumer);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.29567080341999}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlog.info(\"Topic: {}, Duration: {} ms\", topic, endTime - startTime);\n\treturn records;\n}", "CodeBleu_score": 27.16637409697161}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\t// Start the stopwatch to measure the polling time\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\n\t// Poll the consumer for records\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\n\t// Stop the stopwatch and log the total time taken\n\tstopwatch.stop();\n\tlog.info(\"Polled {} records from Kafka topic {} in {} ms\", records.size(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\n\t// Return the records\n\treturn records;\n}", "CodeBleu_score": 29.651135795406212}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\tlong endTime = System.currentTimeMillis();\n\tlong totalTime = endTime - startTime;\n\tlog.info(\"Poll time: \" + totalTime + \" ms\");\n\treturn records;\n}", "CodeBleu_score": 27.279746436275826}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t", "CodeBleu_score": 2.454125543921295}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (initFailed) {\n\t\t\tlog.error(\"[{}] Initialization failed. Not processing message.\", ctx.getSelfId());\n\t\t\treturn;\n\t\t}\n\n\t\tString topic = getTopic(msg);\n\t\tString key = getKey(msg);\n\t\tpublish(ctx, msg, topic, key);\n\t} catch (Exception e) {\n\t\tlog.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t}\n}", "CodeBleu_score": 20.405428980911516}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\t// 1. check if initialized\n\t\tif (!initialized) {\n\t\t\tlog.error(\"[{}] Failed to initialize Kafka producer\", ctx.getSelfId());\n\t\t\tctx.fireEvent(new TbMsg(ctx.getSelfId(), TB_EVENT_ERROR, new Exception(\"Failed to initialize Kafka producer\")));\n\t\t\treturn;\n\t\t}\n\n\t\t// 2. get topic and key\n\t\tString topic = msg.getMetaData().getOrDefault(TB_MSG_MD_TOPIC, null);\n\t\tString key = msg.getMetaData().getOrDefault(TB_MSG_MD_KEY, null);\n\n\t\t// 3. publish\n\t\tpublish(ctx, msg, topic, key);\n\t} catch (Exception e) {\n\t\tlog.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.fireEvent(new TbMsg(ctx.getSelfId(), TB_EVENT_ERROR, e));\n\t}\n}", "CodeBleu_score": 30.37499641185994}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t", "CodeBleu_score": 5.441118430176013}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tif (log.isDebugEnabled()) {\nlog.debug(\"Publishing message with context ID {} to topic {}\", ctx.getMsgId(), topic);\n}\n\ntry {\nif (metadata!= null) {\nMap<String, String> headers = new HashMap<>();\nfor (String key : metadata.keySet()) {\nheaders.put(key, metadata.get(key));\n}\n\nctx.put(TbContext.METADATA_HEADERS, headers);\n}\n\nproducer.send(new ProducerRecord<>(topic, key, msg.getPayload()), new Callback() {\n@Override\npublic void onCompletion(RecordMetadata metadata, Exception e) {\nprocessRecord(ctx, msg, metadata, e);\n}\n});\n} catch (Exception e) {\nlog.error(\"Failed to publish message with context ID {} to topic {}\", ctx.getMsgId(), topic, e);\ntellFailure(ctx, msg, e);\n}\n}", "CodeBleu_score": 42.72903854091095}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tpublish(ctx, msg, topic, key, null);\n}", "CodeBleu_score": 9.399555434179016}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 41.92371227788245}, {"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error occurred while closing the producer: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 41.18823907693715}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 61.31318402746789}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\t// Create the Kafka producer template builder\n\tTbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> kafkaProducerTemplateBuilder = new TbKafkaProducerTemplateBuilder<>();\n\n\t// Set the Kafka settings\n\tkafkaProducerTemplateBuilder.setKafkaSettings(kafkaSettings);\n\n\t// Set the client ID\n\tkafkaProducerTemplateBuilder.setClientId(serviceInfoProvider.getServiceId());\n\n\t// Set the default topic\n\tkafkaProducerTemplateBuilder.setDefaultTopic(kafkaSettings.getRuleEngineMsgTopic());\n\n\t// Set the admin\n\tkafkaProducerTemplateBuilder.setAdmin(kafkaSettings.getAdmin());\n\n\t// Build and return the Kafka producer\n\treturn kafkaProducerTemplateBuilder.build();\n}", "CodeBleu_score": 43.37927479654109}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = null;\n\ttry {\n\t\tTbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> producerTemplateBuilder = new TbKafkaProducerTemplateBuilder<>();\n\t\tproducerTemplateBuilder.setKafkaSettings(tbKafkaSettings);\n\t\tproducerTemplateBuilder.setClientId(tbServiceInfoProvider.getServiceId());\n\t\tproducerTemplateBuilder.setDefaultTopic(tbKafkaSettings.getRuleEngineMsgTopic());\n\t\tproducerTemplateBuilder.setAdmin(tbKafkaAdmin);\n\t\tproducer = producerTemplateBuilder.build();\n\t} catch (TbException e) {\n\t\ttbLog.error(\"Failed to create Rule Engine message producer: \" + e.getMessage());\n\t}\n\treturn producer;\n}", "CodeBleu_score": 42.34304919124745}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineMsgProducer = null;\n\ttry {\n\t\tKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineMsgProducerTemplateBuilder = new KafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>>();\n\t\truleEngineMsgProducerTemplateBuilder.setKafkaSettings(kafkaSettings);\n\t\truleEngineMsgProducerTemplateBuilder.setClientId(serviceInfoProvider.getServiceId());\n\t\truleEngineMsgProducerTemplateBuilder.setDefaultTopic(kafkaSettings.getRuleEngineMsgTopic());\n\t\truleEngineMsgProducerTemplateBuilder.setAdmin(kafkaAdmin);\n\t\truleEngineMsgProducer = ruleEngineMsgProducerTemplateBuilder.build();\n\t} catch (Exception e) {\n\t\tlog.error(\"Error while creating Rule Engine message producer: \" + e.getMessage());\n\t\tthrow new RuntimeException(\"Error while creating Rule Engine message producer: \" + e.getMessage());\n\t}\n\treturn ruleEngineMsgProducer;\n}", "CodeBleu_score": 39.2606038201169}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tget kafka consumer group offset and end offset\n\tMap<TopicPartition, Long> endOffsets = consumer.endOffsets(consumer.assignment());\n\tMap<TopicPartition, OffsetAndMetadata> groupOffsets = consumer.committed(consumer.assignment());\n\t// 2. get lagging topics\n\tList<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n\t// 3. print stats\n\tif (isStatsPrintRequired()) {\n\t\tfor (GroupTopicStats groupTopicStats : consumerGroupStats) {\n\t\t\tlog.info(\"Group {} has a lag on topic {} partition {} with offset {} and end offset {}.\",\n\t\t\t\t\tconsumer.groupId(), groupTopicStats.getTopic(), groupTopicStats.getPartition(),\n\t\t\t\t\tgroupTopicStats.getCommittedOffset(), groupTopicStats.getEndOffset());\n\t\t}\n\t}\n}", "CodeBleu_score": 19.9566498300618}, {"code": "private void startLogScheduling(){\n\to(\"Starting consumer group statistics logging scheduler\");\nlong timeout = kafkaConsumerConfig.getConsumerResponseTimeoutMs();\nif (timeout > 0) {\n    long delay = timeout / 2;\n    if (delay < 500) {\n        delay = 500;\n    }\n    log.info(\"Scheduling consumer group statistics logging task with timeout {} ms, delay {} ms\", timeout, delay);\n    ScheduledExecutorService scheduler = Executors.newSingleThreadScheduledExecutor();\n    scheduler.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            try {\n                if (isStatsPrintRequired()) {\n                    log.info(\"Checking consumer group statistics\");\n                    List<GroupTopicStats> consumerGroupStats = getConsumerGroupStats();\n                    if (consumerGroupStats.isEmpty()) {\n                        log.info(\"No consumer group statistics found\");\n                    } else {\n                        log.info(\"Found {} consumer group statistics\", consumerGroupStats.size());\n                        log.info(\"Consumer group statistics: {}\", consumerGroupStats);\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Error while checking consumer group statistics\", e);\n            }\n        }\n    }, delay, timeout, TimeUnit.MILLISECONDS);\n} else {\n    log.warn(\"Kafka consumer response timeout is not set, consumer group statistics logging is disabled\");\n}\n}", "CodeBleu_score": 29.494939484436557}, {"code": "private void startLogScheduling(){\n\t   final int logSchedulingPeriod = kafkaConfig.getLogSchedulingPeriod();\n        final int logSchedulingPeriod = 1000;\n        final int logSchedulingTimeout = kafkaConfig.getLogSchedulingTimeout();\n        final int logSchedulingTimeoutMillis = TimeUnit.MILLISECONDS.convert(logSchedulingTimeout, TimeUnit.SECONDS);\n        final int logSchedulingDelayMillis = TimeUnit.MILLISECONDS.convert(logSchedulingPeriod, TimeUnit.SECONDS);\n        final int logSchedulingDelayNanos = TimeUnit.NANOSECONDS.convert(logSchedulingDelayMillis, TimeUnit.MILLISECONDS);\n        log.info(\"Starting log scheduling for Kafka consumer groups with a period of {} seconds and a timeout of {} seconds\", logSchedulingPeriod, logSchedulingTimeout);\n        scheduler.scheduleAtFixedRate(() -> {\n            try {\n                if (isStatsPrintRequired()) {\n                    Map<String, Map<TopicPartition, Long>> endOffsets = getEndOffsets();\n                    Map<String, Map<TopicPartition, OffsetAndMetadata>> groupOffsets = getGroupOffsets();\n                    List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n                    if (!consumerGroupStats.isEmpty()) {\n                        log.info(\"Kafka consumer groups with lagging topics: {}\", consumerGroupStats);\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Error while logging Kafka consumer group statistics\", e);\n            }\n        }, logSchedulingDelayMillis, logSchedulingDelayMillis, TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 36.28865662984826}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, requestTimeoutMs);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);\nprops.put(AdminClientConfig.RETRY_MAX_ATTEMPTS_CONFIG, retryMaxAttempts);\nreturn props;\n}", "CodeBleu_score": 65.16413993234089}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent metricEvent = new MetricEvent(scopedName, tags);\n\tswitch (metric.getMetricType()) {\n\t\tcase COUNTER:\n\t\t\tcounterMetrics.add(metric);\n\t\t\tcounterEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase GAUGE:\n\t\t\tgaugeMetrics.add(metric);\n\t\t\tgaugeEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase HISTOGRAM:\n\t\t\thistogramMetrics.add(metric);\n\t\t\thistogramEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase METER:\n\t\t\tmeterMetrics.add(metric);\n\t\t\tmeterEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog.warn(\"Unknown metric type for metric {}: {}\", metricName, metric.getMetricType());\n\t\t\tbreak;\n\t}\n}", "CodeBleu_score": 33.554932866232654}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent metricEvent = new MetricEvent(scopedName, tags, metric.getValue());\n\tswitch (metric.getType()) {\n\t\tcase COUNTER:\n\t\t\tcounterMetrics.add(metric);\n\t\t\tcounterMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase GAUGE:\n\t\t\tgaugeMetrics.add(metric);\n\t\t\tgaugeMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase HISTOGRAM:\n\t\t\thistogramMetrics.add(metric);\n\t\t\thistogramMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tcase METER:\n\t\t\tmeterMetrics.add(metric);\n\t\t\tmeterMetricEvents.add(metricEvent);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tLOG.warn(\"Metric type {} is not supported\", metric.getType());\n\t}\n}", "CodeBleu_score": 33.64215579018337}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(scopedName, tags, metric.getValue());\n\tswitch (metric.getType()) {\n\t\tcase COUNTER:\n\t\t\tcounterEvents.add(event);\n\t\t\tbreak;\n\t\tcase GAUGE:\n\t\t\tgaugeEvents.add(event);\n\t\t\tbreak;\n\t\tcase HISTOGRAM:\n\t\t\thistogramEvents.add(event);\n\t\t\tbreak;\n\t\tcase METER:\n\t\t\tmeterEvents.add(event);\n\t\t\tbreak;\n\t\tdefault:\n\t\t\tlog.warn(\"Metric type {} is not supported.\", metric.getType());\n\t\t\tbreak;\n\t}\n}", "CodeBleu_score": 30.054448084251224}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (gauge.getValue()!= null) {\n\t\tif (metricEvent.getFields()!= null) {\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t} else {\n\t\t\tmetricEvent.setFields(new HashMap<String, Object>());\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 24.739770360068537}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() == null) {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tfields.put(field, gauge.getValue());\n\t\tmetricEvent.setFields(fields);\n\t} else {\n\t\tif (metricEvent.getFields().get(field) == null) {\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t} else {\n\t\t\tif (metricEvent.getFields().get(field) instanceof String) {\n\t\t\t\tmetricEvent.getFields().put(field, gauge.getValue().toString());\n\t\t\t} else {\n\t\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t\t}\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 43.069499160557605}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() == null) {\n\t\tMap<String, Object> fields = new HashMap<String, Object>();\n\t\tfields.put(field, gauge.getValue());\n\t\tmetricEvent.setFields(fields);\n\t} else {\n\t\tif (metricEvent.getFields().containsKey(field)) {\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t} else {\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t}\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 37.016205923749965}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties kafkaProps = buildKafkaProps();\nKafkaDeserializationSchema<MetricEvent> kafkaDeserializationSchema = new KafkaDeserializationSchema<>(new MetricEventSchema());\n\nKafkaSource<MetricEvent> kafkaSource = new FlinkKafkaConsumer<>(topic, kafkaDeserializationSchema, kafkaProps)\n.setStartFromEarliest()\n.setStartFromTimestamp(time);\n\nreturn env.addSource(kafkaSource);\n}", "CodeBleu_score": 36.00228183487026}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\tProperties props = buildKafkaProps(env.getConfig());\nprops.setProperty(\"group.id\", \"query_time_\" + time);\nKafkaConsumer<String, MetricEvent> consumer = new KafkaConsumer<>(props);\nList<PartitionInfo> partitionsFor = consumer.partitionsFor(topic);\nMap<TopicPartition, Long> partitionInfoLongMap = new HashMap<>();\nfor (PartitionInfo partitionInfo : partitionsFor) {\npartitionInfoLongMap.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n}\nMap<TopicPartition, OffsetAndTimestamp> offsetResult = consumer.offsetsForTimes(partitionInfoLongMap);\nMap<KafkaTopicPartition, Long> partitionOffset = new HashMap<>();\noffsetResult.forEach((key, value) -> partitionOffset.put(new KafkaTopicPartition(key.topic(), key.partition()), value.offset()));\n\nconsumer.close();\n\nenv.getConfig().setGlobalJobParameters(new GlobalJobParameters(partitionOffset));\nreturn env.addSource(new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props));\n}", "CodeBleu_score": 42.11219054669456}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t", "CodeBleu_score": 8.44308697353304}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\");\n\tString groupId = parameterTool.getRequired(\"group-id\");\n\tprops.put(\"group.id\", groupId);\n\tprops.put(\"auto.offset.reset\", \"earliest\");\n\tprops.put(\"enable.auto.commit\", \"false\");\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tList<KafkaTopicPartition> partitions = consumer.partitionsFor(topic);\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\tfor (KafkaTopicPartition partition : partitions) {\n\t\tpartitionOffsets.put(partition, time);\n\t}\n\tconsumer.close();\n\treturn partitionOffsets;\n}", "CodeBleu_score": 38.57784596827006}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\");\n\tString groupId = parameterTool.getRequired(\"groupId\");\n\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\tconsumer.subscribe(Collections.singleton(topic));\n\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\tList<TopicPartitionInfo> partitions = consumer.partitionsFor(topic);\n\tfor (TopicPartitionInfo partition : partitions) {\n\t\tpartitionOffsets.put(new KafkaTopicPartition(topic, partition.partition()), time);\n\t}\n\n\tconsumer.close();\n\treturn partitionOffsets;\n}", "CodeBleu_score": 38.08441513357383}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.get(\"topic\");\n\tString groupId = parameterTool.get(\"group\");\n\tString brokerList = parameterTool.get(\"brokers\");\n\tString offsetReset = parameterTool.get(\"offset-reset\");\n\tprops.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);\n\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n\tprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n\tprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class);\n\tprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, offsetReset);\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\n\tMap<KafkaTopicPartition, Long> offsets = new HashMap<KafkaTopicPartition, Long>();\n\tMap<String, Integer> partitions = consumer.partitionsFor(topic);\n\tfor (Map.Entry<String, Integer> partition : partitions.entrySet()) {\n\t\toffsets.put(new KafkaTopicPartition(topic, partition.getValue()), time);\n\t}\n\tconsumer.close();\n\treturn offsets;\n}", "CodeBleu_score": 35.10630318366961}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties properties = new Properties();\n\tproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\n\tproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\tproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, JsonSerializer.class.getName());\n\tKafkaProducer<String, MetricEvent> producer = new KafkaProducer<String, MetricEvent>(properties);\n\tMetricEvent metricEvent = new MetricEvent(System.currentTimeMillis(), \"test\", new HashMap<>(), new HashMap<>());\n\tProducerRecord<String, MetricEvent> record = new ProducerRecord<String, MetricEvent>(\"test\", metricEvent);\n\tproducer.send(record);\n\tproducer.flush();\n\tproducer.close();\n\tSystem.out.println(\"Data sent to Kafka topic.\");\n}", "CodeBleu_score": 41.673567608985515}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\t// Kafka producer properties\n\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n\t// Create Kafka producer\n\tKafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);\n\t// Create a MetricEvent\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test\");\n\tevent.setTags(new HashMap<>());\n\tevent.getTags().put(\"tag1\", \"value1\");\n\tevent.getTags().put(\"tag2\", \"value2\");\n\tevent.setFields(new HashMap<>());\n\tevent.getFields().put(\"field1\", 1);\n\tevent.getFields().put(\"field2\", 2);\n\t// Create a ProducerRecord with the serialized MetricEvent\n\tProducerRecord<String, byte[]> record = new ProducerRecord<>(\"topic\", event.serialize());\n\t// Send the record to the Kafka topic\n\tproducer.send(record);\n\tSystem.out.println(\"Sent data: \" + record.value());\n\t// Flush the producer to ensure all data is sent\n\tproducer.flush();\n\t// Close the producer\n\tproducer.close();\n}", "CodeBleu_score": 45.64521792597488}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"retries\", 0);\n\tprops.put(\"batch.size\", 16384);\n\tprops.put(\"linger.ms\", 1);\n\tprops.put(\"buffer.memory\", 33554432);\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\n\tMetricEvent event = new MetricEvent(System.currentTimeMillis(), \"test\", new HashMap<String, String>(), new HashMap<String, Double>());\n\tevent.addField(\"test_field\", 1.0);\n\n\tProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test\", event.toString());\n\n\tproducer.send(record);\n\tSystem.out.println(\"Sent: \" + record);\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 57.15702223792323}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\nString subAppend = subAppend(event);\nproducer.send(new ProducerRecord<>(topic, subAppend));\n}", "CodeBleu_score": 18.696150823306233}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t{\n\t\tif (event.getLevel().toString().equals(\"INFO\") || event.getLevel().toString().equals(\"WARN\") || event.getLevel().toString().equals(\"ERROR\")) {\n\t\t\tif (!event.getLoggerName().contains(\"xxx\")) {\n\t\t\t\tproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.warn(\"Error sending log event to Kafka topic\", e);\n\t}\n}", "CodeBleu_score": 56.56356344421201}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t{\n\t\tif (event.getLevel().toString().equals(\"WARN\") || event.getLevel().toString().equals(\"ERROR\")) {\n\t\t\tif (!event.getLoggerName().contains(\"xxx\")) {\n\t\t\t\tproducer.send(new ProducerRecord<>(topic, subAppend(event)));\n\t\t\t}\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, subAppend(event)));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.warn(\"Error sending log event to Kafka topic\", e);\n\t}\n}", "CodeBleu_score": 58.398711058262165}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"invalid topic suffix method: %s\", method)\n}", "CodeBleu_score": 85.88574623834042}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range topicSuffixMethods {\n\t\tif validMethod == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 84.19601265715382}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.New().String(), nil\n\t}\n\n\tif k.RoutingKey == \"\" {\n\t\treturn \"\", nil\n\t}\n\n\tif k.RoutingTag!= \"\" {\n\t\ttag, ok := metric.Tag(k.RoutingTag)\n\t\tif!ok {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %s not found in metric\", k.RoutingTag)\n\t\t}\n\t\treturn tag, nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 49.57572531555113}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.New().String(), nil\n\t} else if k.RoutingKey!= \"\" {\n\t\ttags := metric.GetTags()\n\t\tif tags == nil {\n\t\t\treturn k.RoutingKey, nil\n\t\t}\n\t\ttagValue, ok := tags[k.RoutingTag]\n\t\tif!ok {\n\t\t\treturn k.RoutingKey, nil\n\t\t}\n\t\treturn tagValue, nil\n\t}\n\treturn \"\", fmt.Errorf(\"routingKey must be set to either 'random' or a tag name\")\n}", "CodeBleu_score": 45.725740292793546}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.New().String(), nil\n\t} else if k.RoutingKey == \"\" {\n\t\treturn metric.Name(), nil\n\t} else if k.RoutingTag == \"\" {\n\t\treturn k.RoutingKey, nil\n\t} else {\n\t\ttagValue, ok := metric.Tag(k.RoutingTag)\n\t\tif!ok {\n\t\t\treturn k.RoutingKey, nil\n\t\t}\n\t\treturn tagValue, nil\n\t}\n}", "CodeBleu_score": 47.45991064803502}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\ttopicRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"invalid topic regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = topicRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.39756776157753}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tcompiledRegexp, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"error compiling topic regexp %s: %w\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = compiledRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 53.7434548582993}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(topicRegexp)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"Error compiling regular expression %s: %s\", topicRegexp, err)\n\t\t}\n\t\tk.topicRegexps[i] = regex\n\t}\n\treturn nil\n}", "CodeBleu_score": 55.44998462657602}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif!ok {\n\t\treturn\n\t}\n\n\tif msg.Delivered {\n\t\treturn\n\t}\n\n\tmsg.Delivered = true\n\th.session.MarkMessageAsDelivered(msg)\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release()\n}", "CodeBleu_score": 48.905114098719494}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tif msg, ok := h.undelivered[track.DeliveryID]; ok {\n\t\tif msg.delivered {\n\t\t\th.session.MarkMessageAsDelivered(msg)\n\t\t}\n\t\tdelete(h.undelivered, track.DeliveryID)\n\t\th.sem <- struct{}{}\n\t}\n}", "CodeBleu_score": 52.19240986576579}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\t// If the message is not found, the delivery is stale and should be ignored.\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif!ok {\n\t\treturn\n\t}\n\n\t// Mark the message as delivered.\n\tmsg.delivered = true\n\n\t// Mark the message as delivered in the session.\n\th.session.MarkMessage(msg.ID, true)\n\n\t// Remove the message from the undelivered map and release a semaphore slot.\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release()\n}", "CodeBleu_score": 47.88072407447789}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t", "CodeBleu_score": 3.1071579261949545}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\th.Logger.Info(\"Starting consumer group handler\")\n\tdefer h.Logger.Info(\"Stopping consumer group handler\")\n\n\tfor {\n\t\tselect {\n\t\tcase <-session.Context().Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif ok {\n\t\t\t\th.Logger.Infof(\"Received message: %s\", message.Value)\n\t\t\t\t// Do something with the message here\n\t\t\t\terr := h.HandleMessage(message)\n\t\t\t\tif err!= nil {\n\t\t\t\t\th.Logger.Errorf(\"Error handling message: %s\", err)\n\t\t\t\t}\n\t\t\t\tsession.MarkMessage(message, \"\")\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 52.923410637459014}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\th.wg.Add(1)\n\tdefer h.wg.Done()\n\n\t// Iterate over messages from the claim\n\tfor message := range claim.Messages() {\n\t\t// Handle the message\n\t\tif err := h.handleMessage(message); err!= nil {\n\t\t\t// Log the error\n\t\t\th.logger.Errorf(\"Error handling message: %v\", err)\n\t\t}\n\n\t\t// Mark the message as processed\n\t\tsession.MarkMessage(message, \"\")\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 35.983181799432224}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.nonEmpty, UtilError.LogkafkaIdIsEmpty)\ncheckCondition(logkafka_id!= \".\", UtilError.LogkafkaIdIsDot)\ncheckCondition(logkafka_id!= \"..\", UtilError.LogkafkaIdIsDotDot)\ncheckCondition(logkafka_id.length <= MAX_LOGKAFKA_ID_LENGTH, UtilError.LogkafkaIdIsTooLong)\ncheckCondition(logkafka_id.matches(LOGKAFKA_ID_REGEX), UtilError.LogkafkaIdContainsInvalidCharacters)\n}", "CodeBleu_score": 33.51479281653559}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t checkCondition(logkafka_id.length > 0, UtilError.IllegalCharacterInLogkafkaId)\n checkCondition(logkafka_id!= \".\", UtilError.IllegalCharacterInLogkafkaId)\n checkCondition(logkafka_id!= \"..\", UtilError.IllegalCharacterInLogkafkaId)\n checkCondition(logkafka_id.length <= MAX_LOGKAFKA_ID_LENGTH, UtilError.IllegalCharacterInLogkafkaId)\n checkCondition(logkafka_id.matches(LOGKAFKA_ID_REGEX), UtilError.IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 42.98713225569062}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id!= \"\", UtilError.IllegalEmptyLogkafkaId)\ncheckCondition(logkafka_id!= \".\", UtilError.IllegalDotLogkafkaId)\ncheckCondition(logkafka_id!= \"..\", UtilError.IllegalDotDotLogkafkaId)\ncheckCondition(logkafka_id.length <= 256, UtilError.IllegalLengthLogkafkaId)\ncheckCondition(logkafka_id.matches(\"^[a-zA-Z0-9_-]*$\"), UtilError.IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 31.2061069994117}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\twithKafkaManagerActor(msg, fn)\n  }", "CodeBleu_score": 8.641177864346234}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\tval responseFuture = KafkaManagerActor.sendReceive(msg)\n\tresponseFuture.flatMap(response => {\n\t  response match {\n\t    case ActorErrorResponse(error) => Future.failed(ApiError(error))\n\t    case output => fn(output)\n\t  }\n\t})\n  }", "CodeBleu_score": 25.17562965624245}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\tval future = kafkaManagerActor.ask(msg)\n\tfuture.map { response =>\n\t\tresponse match {\n\t\t\tcase response: ApiError => ApiError\n\t\t\tcase response: Output => fn(response)\n\t\t}\n\t}\n  }", "CodeBleu_score": 23.757384787823973}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t-    val request = KMClusterCommandRequest(clusterName, topics, KMClusterCommand.PreferredLeaderElection)\n-    val future = clusterContext.sendCommand(request)\n-    future.map {\n-      case ClusterContextResponse(ApiError.None, context) => context\n-      case ClusterContextResponse(error, _) => ApiError(error)\n-    }\n-  }", "CodeBleu_score": 34.69766648232924}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\tval request = new KMClusterCommandRequest(clusterName, KMClusterCommandRequest.PreferredLeaderElection, topics)\n\tsendCommand(request)\n  }", "CodeBleu_score": 16.87245981685594}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\ttryWithKafkaManagerActor(KMClusterCommandRequest(clusterName, CMRunPreferredLeaderElectionWithAllTopics)) { result: Future[CMCommandResult] =>\n  result.map(cmr => toDisjunction(cmr.result))\n}\n}", "CodeBleu_score": 10.79817122259924}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\tgetTopicList(clusterName) map {\n  case ApiError.Failure(e) => ApiError.Failure(e)\n  case ApiError.Success(TopicList(topics)) => runPreferredLeaderElection(clusterName, topics)\n}\n}", "CodeBleu_score": 17.798869350111787}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\trunPreferredLeaderElection(clusterName, getTopicList(clusterName).map(_.topics).getOrElse(Set.empty))\n}", "CodeBleu_score": 12.31626833794973}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nval result = tryWithKafkaManagerActor(KMClusterCommandRequest(clusterName, assignments)) {\n  case KMClusterCommandResponse(clusterName, assignments, errors) =>\n    if (errors.isEmpty) {\n      Success(clusterName)\n    } else {\n      Failure(errors)\n    }\n}\nresult\n}", "CodeBleu_score": 18.48083849307866}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\tval msg = KMClusterCommandRequest(clusterName, KMClusterCommand.ManualPartitionAssignments(assignments))\ntryWithKafkaManagerActor(msg) {\n  case ApiError.Success => ApiError.Success\n  case ApiError.Failure(errors) => ApiError.Failure(errors)\n}\n}", "CodeBleu_score": 16.326773811853275}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\tKMClusterCommandRequest(clusterName, assignments)\n}", "CodeBleu_score": 4.771967973432012}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tDescribeClusterResult clusterResult = admin.describeCluster();\n\tList<String> nodeIds = clusterResult.cluster().nodes().stream().map(Node::id).map(Node.Id::toString).collect(Collectors.toList());\n\tadmin.close();\n\tif (nodeIds.isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka broker available.\");\n\t}\n\tString nodeId = nodeIds.get(0);\n\tAdmin admin2 = AdminClient.create(Map.of(\"bootstrap.servers\", nodeId));\n\tDescribeClusterResult result = admin2.describeCluster();\n\tadmin2.close();\n\treturn result.cluster().nodes().get(nodeId).config();\n}", "CodeBleu_score": 46.46796961399631}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\tList<String> brokerIds = describeClusterResult.cluster().brokers().stream().map(Broker::id).map(String::valueOf).collect(Collectors.toList());\n\tif (brokerIds.isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka broker nodes available within the specified timeout.\");\n\t}\n\tString brokerId = brokerIds.get(0);\n\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, brokerId)));\n\tif (describeConfigsResult.all().isEmpty()) {\n\t\tthrow new ConnectException(\"No configurations available for the Kafka broker node.\");\n\t}\n\treturn describeConfigsResult.all().get(0).config();\n}", "CodeBleu_score": 52.93212665465615}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster to get the available nodes within a specified timeout.\n\tMap<Node, NodeDescription> nodeDescriptions = admin.describeNodes(5000);\n\tif (nodeDescriptions.size() == 0) {\n\t\tthrow new ConnectException(\"No nodes available in cluster\");\n\t}\n\n\t// Select the first node's ID and request its configuration.\n\tNode node = nodeDescriptions.keySet().iterator().next();\n\tConfig config = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.id().toString())), 5000);\n\tif (config.isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration received for node \" + node.id());\n\t}\n\n\treturn config.get(new ConfigResource(ConfigResource.Type.BROKER, node.id().toString()));\n}", "CodeBleu_score": 46.48567649694302}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Schema schema) {\n\t\t\treturn schema.getSchemaHistory() == SchemaHistory.KAFKA? validator.validate(schema) : 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 17.835393313091714}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final Configuration configuration) {\n\t\t\tif (configuration.getSchemaHistory() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n\t\t\t\treturn validator.validate(configuration);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 21.605488473006453}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic int validate(final SchemaHistory schemaHistory) {\n\t\t\tif (schemaHistory == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n\t\t\t\treturn validator.validate(schemaHistory);\n\t\t\t}\n\t\t\treturn 0;\n\t\t}\n\t};\n}", "CodeBleu_score": 20.05795940017277}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tif (this.topicCreationEnabled!= null) {\n\t\treturn this.topicCreationEnabled;\n\t}\n\tString version = config.get(ConfigDef.VERSION_PROPERTY);\n\tif (version == null) {\n\t\tthis.topicCreationEnabled = true;\n\t\treturn true;\n\t}\n\tthis.topicCreationEnabled = KafkaConnectConfig.parseVersion(version).compareTo(KafkaConnectConfig.MIN_TOPIC_CREATION_VERSION) >= 0;\n\treturn this.topicCreationEnabled;\n}", "CodeBleu_score": 36.75157069394207}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString version = config.get(ConfigDef.VERSION_CONFIG);\n\tif (version == null) {\n\t\tversion = \"0.0.0\";\n\t}\n\tVersion v = Version.parseVersion(version);\n\tif (v.compareTo(Version.parseVersion(\"0.10.0.0\")) < 0) {\n\t\treturn false;\n\t}\n\tBoolean enable = config.get(ConfigDef.TOPIC_CREATION_ENABLE_CONFIG);\n\treturn enable!= null && enable;\n}", "CodeBleu_score": 38.21160527393619}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// Parse the current Kafka Connect version and retrieve the \"topic.creation.enable\" property from the configuration, defaulting to true if not set.\n\tString kafkaConnectVersion = this.getKafkaConnectVersion();\n\tString topicCreationEnableProperty = config.getOrDefault(KafkaConnectSinkConnectorConfig.TOPIC_CREATION_ENABLE, \"true\").toString();\n\tBoolean topicCreationEnable = Boolean.parseBoolean(topicCreationEnableProperty);\n\n\t// Check if the Kafka Connect version is compatible with topic creation and the property is set to true.\n\treturn topicCreationEnable && Version.parse(kafkaConnectVersion).compareTo(Version.parse(\"2.7.0\")) >= 0;\n}", "CodeBleu_score": 44.23700788778552}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\tfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new IllegalArgumentException(\"Missing required configuration property: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n}\nfinal Properties adminProperties = new Properties();\nadminProperties.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.BOOTSTRAP_SERVERS_CONFIG));\nadminProperties.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\nfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProperties);\nreturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 37.29559667166116}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\nString clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\nif (clientId == null) {\nthrow new IllegalArgumentException(\"KafkaOffsetBackingStore requires a clientId\");\n}\n\nMap<String, Object> adminConfig = new HashMap<>();\nadminConfig.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.BOOTSTRAP_SERVERS_CONFIG));\nadminConfig.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\nadminConfig.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.REQUEST_TIMEOUT_MS_CONFIG));\nadminConfig.put(AdminClientConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG, config.get(KafkaOffsetBackingStoreConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG));\nadminConfig.put(AdminClientConfig.METADATA_MAX_AGE_CONFIG, config.get(KafkaOffsetBackingStoreConfig.METADATA_MAX_AGE_CONFIG));\n\nSharedAdmin admin = new SharedAdmin(new AdminConfig(adminConfig));\n\nJsonConverter converter = converterForOffsetStore();\n\nreturn new KafkaOffsetBackingStore(admin, clientId, converter);\n}", "CodeBleu_score": 36.331991137890924}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\n    JsonNode payload = node.get(PAYLOAD_FIELD);\n\n    // Schema + payload format\n    if (payload!= null) {\n        node = payload;\n    }\n    // Debezium envelope\n    if (config.asEnvelope()) {\n        return reader.readValue(node);\n    }\n    else if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n        return reader.readValue(node.get(config.sourceField()));\n    }\n    // Extracted format\n    else {\n        return reader.readValue(node);\n    }\n}\nelse {\n    throw new JsonMappingException(String.format(\"Expected a JSON object but got %s\", node.getNodeType()));\n}\n}", "CodeBleu_score": 40.57299832777423}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\nJsonNode payload = node.get(PAYLOAD_FIELD);\n\n// Schema + payload format\nif (payload!= null) {\nnode = payload;\n}\n// Debezium envelope\nelse if (config.asEnvelope()) {\nreturn reader.readValue(node);\n}\n// Extracted format\nelse {\nreturn reader.readValue(node);\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}", "CodeBleu_score": 31.7011596455955}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tf (node.isObject()) {\nif (node.has(PAYLOAD_FIELD)) {\nnode = node.get(PAYLOAD_FIELD);\n}\n\nif (config.keyIsSimple()) {\nreturn readSimpleKey(node);\n}\nelse {\nreturn readCompositeKey(node);\n}\n}\nelse {\nthrow new IOException(\"Expected object but got \" + node);\n}\n}", "CodeBleu_score": 26.263400920783486}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = topicNameFor(id);\nString sanitizedTopicName = sanitizeTopicName(topicName);\nif (!sanitizedTopicName.equals(topicName)) {\nlogger.warn(\"Topic name for {} is not valid: {}. Sanitized to: {}\", id, topicName, sanitizedTopicName);\n}\nreturn sanitizedTopicName;\n}", "CodeBleu_score": 17.449369415811425}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = topicNameFor(id);\nStringBuilder sb = new StringBuilder(topicName.length() + 16);\nsb.append(prefix);\nsb.append(delimiter);\nsb.append(id);\nsb.append(delimiter);\nsb.append(topicName);\nString sanitized = sanitizeTopicName(sb.toString());\nif (sanitized!= null) {\nlogger.warn(\"Topic name {} sanitized to {}\", topicName, sanitized);\nreturn sanitized;\n}\nreturn topicName;\n}", "CodeBleu_score": 28.83166785207692}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\treturn topicNameFor(id, prefix, delimiter, replacementCharacter);\n}", "CodeBleu_score": 5.699543562215667}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t", "CodeBleu_score": 10.29977892531036}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorType = connectorType;\nthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.replacedErrorHandler = replacedErrorHandler;\nthis.retries = replacedErrorHandler!= null? replacedErrorHandler.getRetries() : connectorConfig.getRetries();\n}", "CodeBleu_score": 44.57078027018521}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\tthis.connectorType = connectorType;\nthis.connectorConfig = connectorConfig;\nthis.queue = queue;\nthis.replacedErrorHandler = replacedErrorHandler;\nretries = connectorConfig.getRetries();\nif (replacedErrorHandler!= null) {\n    retries = replacedErrorHandler.getRetries();\n}\n}", "CodeBleu_score": 46.685986680430176}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 85.58077571905521}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 85.58077571905521}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 85.58077571905521}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 93.7937623835105}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader!= null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.59048304009488}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader!= null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.59048304009488}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source == null) {\n\t\treturn null;\n\t}\n\n\t// Check if the source schema contains the SNAPSHOT_KEY field with the expected enum logical name\n\tif (source.getSchema().getField(\"snapshotKey\") == null || source.getSchema().getField(\"snapshotKey\").getType()!= Schema.Type.STRING) {\n\t\treturn null;\n\t}\n\n\t// Check if the snapshotString is present\n\tString snapshotString = source.getString(\"snapshotKey\");\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\n\t// Convert the snapshotString to uppercase\n\tsnapshotString = snapshotString.toUpperCase();\n\n\t// Return the corresponding SnapshotRecord value\n\treturn SnapshotRecord.fromString(snapshotString);\n}", "CodeBleu_score": 41.9934870511073}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source == null) {\n\t\treturn null;\n\t}\n\n\t// Check if the source contains the SNAPSHOT_KEY field\n\tif (!source.containsKey(SNAPSHOT_KEY)) {\n\t\treturn null;\n\t}\n\n\t// Get the snapshotString value\n\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\n\t// Convert the snapshotString to uppercase\n\tsnapshotString = snapshotString.toUpperCase();\n\n\t// Check if the snapshotString is valid\n\tif (!SNAPSHOT_VALUES.contains(snapshotString)) {\n\t\treturn null;\n\t}\n\n\t// Create a new SnapshotRecord object\n\treturn new SnapshotRecord(snapshotString);\n}", "CodeBleu_score": 35.05662397220474}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.getStructType().getFields().size()!= 2) {\n\t\treturn null;\n\t}\n\n\tString snapshotString = source.getStructField(0).getString();\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\n\tsnapshotString = snapshotString.toUpperCase();\n\n\tif (snapshotString.equals(SNAPSHOT_RECORD_SNAPSHOT_RECORD_STRING)) {\n\t\treturn SnapshotRecord.SNAPSHOT_RECORD;\n\t} else if (snapshotString.equals(SNAPSHOT_RECORD_SNAPSHOT_STRING)) {\n\t\treturn SnapshotRecord.SNAPSHOT;\n\t} else if (snapshotString.equals(SNAPSHOT_RECORD_SNAPSHOT_STRING_WITH_SNAPSHOT_STRING)) {\n\t\treturn SnapshotRecord.SNAPSHOT_STRING;\n\t} else if (snapshotString.equals(SNAPSHOT_RECORD_SNAPSHOT_STRING_WITH_SNAPSHOT_RECORD_STRING)) {\n\t\treturn SnapshotRecord.SNAPSHOT_RECORD_STRING;\n\t} else if (snapshotString.equals(SNAPSHOT_RECORD_SNAPSHOT_STRING_WITH_SNAPSHOT_RECORD)) {\n\t\treturn SnapshotRecord.SNAPSHOT_RECORD;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 31.728900941863742}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\n\tString[] split = version.split(\"\\\\.\");\n\tif (split.length > 2) {\n\t\tsplit = new String[2];\n\t}\n\n\tString[] split2 = version.split(\"-\");\n\tif (split2.length > 1) {\n\t\tsplit2 = new String[1];\n\t}\n\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(split[0] + \".\" + split[1] + split2[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 53.57339336995955}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tif (parts.length > 2) {\n\t\t\tparts = new String[] { parts[0], parts[1] };\n\t\t}\n\t\tString[] hyphens = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(hyphens[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 62.422907201600985}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tif (parts.length > 2) {\n\t\t\tparts = new String[] { parts[0], parts[1] };\n\t\t}\n\t\tString[] hyphens = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(hyphens[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 62.422907201600985}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t", "CodeBleu_score": 6.624085789973376}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\talidateAccess(context).then(kafkaConnectService.updateConnectorState(getCluster(clusterName), connectName, connectorName, action).map(ResponseEntity::ok)).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 17.72258377876849}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tAction[] connectActions;\n\tif (RESTART_ACTIONS.contains(action)) {\n\t\tconnectActions = new ConnectAction[] { ConnectAction.VIEW, ConnectAction.RESTART };\n\t} else {\n\t\tconnectActions = new ConnectAction[] { ConnectAction.VIEW, ConnectAction.EDIT };\n\t}\n\n\tvar context = AccessContext.builder()\n\t\t.cluster(clusterName)\n\t\t.connect(connectName)\n\t\t.connectActions(connectActions)\n\t\t.operationName(\"updateConnectorState\")\n\t\t.operationParams(Map.of(CONNECTOR_NAME, connectorName))\n\t\t.build();\n\n\treturn validateAccess(context).then(\n\t\tkafkaConnectService\n\t\t\t.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n\t\t\t.map(ResponseEntity::ok)\n\t).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 88.09106751105276}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tOverride\n\tpublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n\t\tString clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody,\n\t\tServerWebExchange exchange) {\n\t\treturn kafkaConnectService\n\t\t\t.validateConnectorPluginConfig(\n\t\t\t\tgetCluster(clusterName), connectName, pluginName, requestBody)\n\t\t\t.map(ResponseEntity::ok);\n\t}\n}", "CodeBleu_score": 73.93058429352996}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\teturn kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody)\n\t.map(ResponseEntity::ok);\n}", "CodeBleu_score": 31.478939552952312}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tOverride\n\tpublic Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(String clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody, ServerWebExchange exchange) {\n\t\treturn kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody)\n\t\t\t\t.map(ResponseEntity::ok);\n\t}\n}", "CodeBleu_score": 66.6209485968301}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\tSpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n\tbuilder.sources(KafkaUiApplication.class);\n\tbuilder.initializers(new DynamicConfigurationPropertiesInitializer());\n\tConfigurableApplicationContext context = builder.run(args);\n\treturn context;\n}", "CodeBleu_score": 38.98896593806318}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class).initializers(new DynamicPropertiesInitializer()).run(args);\n}", "CodeBleu_score": 32.29004583587697}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new DynamicPropertySourceInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 39.203541212721504}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn search == null? null : (Predicate<FullConnectorInfoDTO>) fullConnectorInfo -> {\n  final Stream<String> strings = getStringsForSearch(fullConnectorInfo);\n  return strings.anyMatch(string -> string.contains(search));\n};\n}", "CodeBleu_score": 32.40143927889897}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\n  return (Predicate<FullConnectorInfoDTO>) (o) -> true;\n}\nreturn (Predicate<FullConnectorInfoDTO>) (o) -> {\n  FullConnectorInfoDTO fullConnectorInfoDTO = o;\n  return getStringsForSearch(fullConnectorInfoDTO).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n};\n}", "CodeBleu_score": 49.37694873810319}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn (search == null)?\n    (Predicate<FullConnectorInfoDTO>) (p) -> true :\n    (Predicate<FullConnectorInfoDTO>) (p) ->\n        getStringsForSearch(p).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 49.33912199901952}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\nIf the value is another map, it recursively flattens it with the new key as the prefix.\nOtherwise, it adds the key-value pair to the flattened map.\nFinally, it returns the flattened map.\n */\n    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        if (value instanceof Map) {\n          flattenedProperties.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n        } else {\n          flattenedProperties.put(prefix == null? key : prefix + \".\" + key, value);\n        }\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 51.48707522697007}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * The flattenClusterProperties function recursively flattens a nested map of cluster properties.\nIt takes an optional prefix and a properties map, initializing an empty map for the flattened result.\nFor each entry in the properties map, it constructs a new key by combining the prefix and the current key.\nIf the value is another map, it recursively flattens it with the new key as the prefix.\nOtherwise, it adds the key-value pair to the flattened map.\nFinally, it returns the flattened map.\n */\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        Map<String, Object> nestedMap = (Map<String, Object>) value;\n        String newPrefix = prefix == null? key : prefix + \".\" + key;\n        flattenedMap.putAll(flattenClusterProperties(newPrefix, nestedMap));\n      } else {\n        flattenedMap.put(prefix == null? key : prefix + \".\" + key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 47.54971302571808}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return null;\n//    }\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = prefix == null? entry.getKey() : prefix + \".\" + entry.getKey();\n      if (entry.getValue() instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattenedMap.put(key, entry.getValue());\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 49.25084487222082}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t ConfigDef configDef = new ConfigDef();\n configDef.define(KAFKA_SSL_KEY_PASSWORD, Type.PASSWORD, Importance.HIGH, \"Password for SSL key\");\n configDef.define(KAFKA_SASL_JAAS_CONFIG, Type.PASSWORD, Importance.HIGH, \"SASL JAAS config\");\n configDef.define(KAFKA_SASL_MECHANISM, Type.PASSWORD, Importance.HIGH, \"SASL mechanism\");\n return configDef.configKeys();\n }", "CodeBleu_score": 51.68174260429539}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn Mono.just(clusterDescription)\n\t\t.flatMap(cd -> Mono.just(cd.getAuthorizations()))\n\t\t.flatMap(authorizations -> Mono.just(authorizations.getOperations()))\n\t\t.flatMap(operations -> Mono.just(operations.get(0)))\n\t\t.flatMap(operation -> Mono.just(operation.getOperation()))\n\t\t.flatMap(operation -> Mono.just(operation.equals(\"Alter\")? ClusterFeature.KAFKA_ACL_EDIT : Mono.empty()))\n\t\t.filter(feature -> aclViewEnabled(adminClient) && aclView(adminClient).contains(feature));\n}", "CodeBleu_score": 28.581783503994306}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\tif (!aclViewEnabled(adminClient)) {\nreturn Mono.empty();\n}\nSet<String> authorizedOperations = clusterDescription.getAuthorizedOperations();\nreturn Mono.just(authorizedOperations.containsAll(Arrays.asList(\"alter\"))? ReactiveAdminClient.SupportedFeature.KAFKA_ACL_EDIT : ReactiveAdminClient.SupportedFeature.NONE);\n}", "CodeBleu_score": 31.140432876420082}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t", "CodeBleu_score": 4.927575001772918}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\n// Iterate over all topic partitions\nfor (TopicPartition topicPartition : prevRange.keySet()) {\n// Get the previous range for the current topic partition\nFromToOffset prevRangeForTopicPartition = prevRange.get(topicPartition);\n\n// Get the current offset for the current topic partition\nlong currentOffset = seekOperations.getCurrentOffset(topicPartition);\n\n// Get the beginning offset for the current topic partition\nlong beginningOffset = seekOperations.getBeginningOffset(topicPartition);\n\n// Get the number of messages to poll for the current topic partition\nint messagesToPoll = messagesToPollPerPartition(topicPartition);\n\n// Calculate the start offset for the current topic partition\nlong startOffset = Math.max(beginningOffset, currentOffset - messagesToPoll);\n\n// Create a new FromToOffset object with the start offset and the end offset\nFromToOffset newRangeForTopicPartition = new FromToOffset(startOffset, currentOffset);\n\n// Add the new range to the next range map\nnextRange.put(topicPartition, newRangeForTopicPartition);\n}\n\nreturn nextRange;\n}", "CodeBleu_score": 30.16297127447311}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\tfor (TopicPartition topicPartition : prevRange.keySet()) {\n\t\tFromToOffset fromToOffset = prevRange.get(topicPartition);\n\t\tlong startOffset = fromToOffset.from;\n\t\tlong endOffset = fromToOffset.to;\n\t\tlong numMessagesToPoll = endOffset - startOffset;\n\t\tif (numMessagesToPoll < 0) {\n\t\t\tnumMessagesToPoll = 0;\n\t\t}\n\t\tif (numMessagesToPoll > maxMessagesToPoll) {\n\t\t\tnumMessagesToPoll = maxMessagesToPoll;\n\t\t}\n\t\tlong newStartOffset = startOffset + numMessagesToPoll;\n\t\tnextRange.put(topicPartition, new FromToOffset(newStartOffset, endOffset));\n\t}\n\treturn nextRange;\n}", "CodeBleu_score": 25.45391714227914}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<TopicPartition, FromToOffset>();\n\tTreeMap<TopicPartition, FromToOffset> prevRangeCopy = new TreeMap<TopicPartition, FromToOffset>();\n\tif (prevRange!= null) {\n\t\tprevRangeCopy.putAll(prevRange);\n\t}\n\n\tif (seekOperations!= null) {\n\t\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRangeCopy.entrySet()) {\n\t\t\tTopicPartition topicPartition = entry.getKey();\n\t\t\tFromToOffset fromToOffset = entry.getValue();\n\t\t\tif (fromToOffset.from == null) {\n\t\t\t\tfromToOffset.from = seekOperations.getOffset(topicPartition);\n\t\t\t}\n\t\t}\n\t}\n\n\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRangeCopy.entrySet()) {\n\t\tTopicPartition topicPartition = entry.getKey();\n\t\tFromToOffset fromToOffset = entry.getValue();\n\t\tint numMessagesToPoll = this.numMessagesToPoll;\n\t\tif (fromToOffset.to!= null) {\n\t\t\tnumMessagesToPoll = (int) Math.min(numMessagesToPoll, fromToOffset.to - fromToOffset.from);\n\t\t}\n\n\t\tlong startOffset = fromToOffset.from;\n\t\tif (numMessagesToPoll > 0) {\n\t\t\tstartOffset += numMessagesToPoll;\n\t\t}\n\n\t\tnextRange.put(topicPartition, new FromToOffset(startOffset, null));\n\t}\n\n\treturn nextRange;\n}", "CodeBleu_score": 30.34880548879353}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\tf (configuration.getBoolean(CK_LEGACY)) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read every second\nexecutor.scheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n\n}", "CodeBleu_score": 17.665499762717403}, {"code": "public void doLaunch(final MessageInput input){\n\t        if (configuration.getBoolean(CK_LEGACY_MODE, false)) {\n//            doLaunchLegacy(input);\n//        } else {\n//            doLaunchConsumer(input);\n//        }\n        doLaunchConsumer(input);\n    }", "CodeBleu_score": 6.711626789708042}, {"code": "public void doLaunch(final MessageInput input){\n\tinal boolean legacy = configuration.getBoolean(CK_LEGACY);\n\nif (legacy) {\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n\n// update the last second bytes read every second\nexecutor.scheduleAtFixedRate(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 22.566774315514333}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tProperties customProps = new Properties();\n\t\tcustomProps.load(new StringReader(customProperties));\n\t\tprops.putAll(customProps);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading custom properties\", e);\n\t}\n}", "CodeBleu_score": 38.14902718884293}, {"code": "private void insertCustomProperties(Properties props){\n\t\t// TODO: Implement this function\n}", "CodeBleu_score": 3.0487516405470023}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tProperties customProps = new Properties();\n\t\tcustomProps.load(new StringReader(customProperties));\n\t\tprops.putAll(customProps);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error while loading custom properties: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 32.24327165306069}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n//        final long start = System.nanoTime();\n//        final int size = entries.size();\n//        final int nullCount = entries.stream().filter(Objects::isNull).collect(Collectors.toList()).size();\n//        final int nonNullCount = size - nullCount;\n//        final long bytes = entries.stream().filter(Objects::nonNull).mapToLong(RawMessageEvent::getMessageBytes).sum();\n//\n//        final long totalBytes = bytes + (nullCount * 4);\n//        final long totalMessages = nonNullCount + nullCount;\n//\n//        try {\n//            final long lastOffset = kafkaJournal.write(entries);\n//            LOG.debug(\"Processed batch, last journal offset: {}, signalling reader.\",\n//                    lastOffset);\n//            journalFilled.release();\n//\n//            messages.update(totalMessages);\n//            bytes.update(totalBytes);\n//\n//            final long end = System.nanoTime();\n//            LOG.debug(\"Processed {} messages in {} ms\", totalMessages, (end - start) / 1000000);\n//        } catch (final Exception e) {\n//            final long end = System.nanoTime();\n//            LOG.error(\"Failed to write to journal, retrying in {} ms\", (end - start) / 1000000, e);\n//            Thread.sleep(1000);\n//            write(entries);\n//        }\n    }", "CodeBleu_score": 2.81917294219152}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n/**\n * The journalFilled semaphore is used to signal the reader that the journal has been filled.\n */\nfinal Semaphore journalFilled = new Semaphore(0);\n\n/**\n * The journalWriter thread is used to write the entries to the journal.\n */\nfinal Thread journalWriter = new Thread(new Runnable() {\n    @Override\n    public void run() {\n        try {\n            writeToJournal(entries);\n        } catch (final Exception e) {\n            LOG.error(\"Failed to write to journal.\", e);\n        }\n    }\n});\n\n/**\n * The journalWriter thread is started.\n */\njournalWriter.start();\n\n/**\n * The journalFilled semaphore is acquired.\n */\njournalFilled.acquire();\n\n/**\n * The journalWriter thread is joined.\n */\njournalWriter.join();\n\n/**\n * The writtenMessages and writtenBytes metrics are updated.\n */\nmetrics.getCounter(Metrics.WRITTEN_MESSAGES).inc(entries.size());\nmetrics.getCounter(Metrics.WRITTEN_BYTES).inc(totalBytes);\n}", "CodeBleu_score": 32.885060699020194}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n//    if (entries.isEmpty()) {\n//        return;\n//    }\n//\n//    long totalMessageBytes = 0;\n//    List<Journal.Entry> journalEntries = new ArrayList<>(entries.size());\n//\n//    for (RawMessageEvent entry : entries) {\n//        if (entry == null) {\n//            continue;\n//        }\n//\n//        journalEntries.add(entry.toJournalEntry());\n//        totalMessageBytes += entry.getMessage().length;\n//    }\n//\n//    if (journalEntries.isEmpty()) {\n//        return;\n//    }\n//\n//    try {\n//        long lastOffset = kafkaJournal.write(journalEntries);\n//        LOG.debug(\"Processed batch, last journal offset: {}, signalling reader.\",\n//                lastOffset);\n//        journalFilled.release();\n//    } catch (Exception e) {\n//        LOG.error(\"Failed to write batch to journal.\", e);\n//        throw new MessageQueueException(e);\n//    }\n//\n//    messagesWritten.addAndGet(entries.size());\n//    bytesWritten.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 2.81917294219152}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\t//TODO implement this method\n}", "CodeBleu_score": 4.565461993424478}, {"code": "public void acknowledge(List<Message> messages){\n\t\t// TODO: Implement this function\n}", "CodeBleu_score": 4.565461993424478}, {"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages.size() == 0) {\n\t\treturn;\n\t}\n\tlong maxID = messages.get(0).getMsgID();\n\tfor (Message message : messages) {\n\t\tif (message.getMsgID() > maxID) {\n\t\t\tmaxID = message.getMsgID();\n\t\t}\n\t}\n\tif (maxID > 0) {\n\t\tacknowledge(maxID);\n\t}\n}", "CodeBleu_score": 22.647712763840712}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t", "CodeBleu_score": 0.9518287916731516}, {"code": "private void registerLegacyMetrics(){\n\t", "CodeBleu_score": 0.9518287916731516}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry registry = this.metrics;\n\tfinal String journalName = this.getClass().getSimpleName();\n\tfor (final MetricName metricName : registry.getNames()) {\n\t\tif (metricName.getName().startsWith(journalName)) {\n\t\t\tfinal String legacyName = metricName.getName().replace(journalName, \"kafka.log.LocalKafkaJournal\");\n\t\t\ttry {\n\t\t\t\tregistry.register(legacyName, registry.getMetrics().get(metricName));\n\t\t\t}\n\t\t\tcatch (final Exception e) {\n\t\t\t\tLOGGER.warn(\"Failed to register legacy metric {} as {}\", metricName, legacyName, e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 32.56753330431255}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = metricRegistry.timer(metricName);\n\tif (timer == null) {\n\t\ttimer = metricRegistry.timer(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 16.668191169871225}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.timer(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 26.949036002980463}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.timers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 31.51779924730711}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(name, new Gauge<Long>() {\n                public Long getValue() {\n                    try {\n                        return kafkaLog.size() == 0? 0 : kafkaLog.logEndOffset() - kafkaLog.committedOffset() == 0? kafkaLog.logEndOffset() - kafkaLog.logStartOffset() : kafkaLog.logEndOffset() - kafkaLog.committedOffset();\n                    } catch (Exception e) {\n                        return 0;\n                    }\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n    }", "CodeBleu_score": 54.057458705174845}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n        metricRegistry.register(name, new Gauge<Long>() {\n            public Long getValue() {\n                final long logEndOffset = getLogEndOffset();\n                final long logStartOffset = getLogStartOffset();\n                final long committedOffset = getCommittedOffset();\n                if (logEndOffset == logStartOffset) {\n                    return 0;\n                }\n                if (committedOffset == DEFAULT_COMMITTED_OFFSET) {\n                    return logEndOffset - logStartOffset;\n                }\n                return logEndOffset - committedOffset;\n            }\n        });\n    } catch (IllegalArgumentException e) {\n        // ignore\n    }\n}", "CodeBleu_score": 49.2591777115088}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n        metricRegistry.register(name, new Gauge<Long>() {\n            @Override\n            public Long getValue() {\n                if (size() == 0) {\n                    return 0L;\n                }\n                if (committedOffset == -1L) {\n                    return getLogEndOffset() - getLogStartOffset();\n                }\n                return getLogEndOffset() - committedOffset;\n            }\n        });\n    } catch (IllegalArgumentException e) {\n        // Ignore\n    }\n}", "CodeBleu_score": 65.39675785630489}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tlogger.debug(\"No messages to write to Kafka\");\n\t\treturn -1;\n\t}\n\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n\tlogger.debug(\"Writing {} messages to Kafka\", messageSet.size());\n\n\tlong offset = kafkaLog.append(messageSet);\n\tlogger.debug(\"Wrote {} messages to Kafka, offset: {}\", messageSet.size(), offset);\n\tmessagesWritten.addAndGet(messageSet.size());\n\treturn offset;\n}", "CodeBleu_score": 35.07765074128594}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\n//        if (messages.isEmpty()) {\n//            LOG.debug(\"No messages to write to Kafka.\");\n//            return -1;\n//        }\n//\n//        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n//        LOG.debug(\"Writing {} messages to Kafka.\", messageSet.size());\n//\n//        long offset = kafkaLog.append(messageSet);\n//        LOG.debug(\"Wrote {} messages to Kafka at offset {}.\", messageSet.size(), offset);\n//\n//        numMessagesWritten += messageSet.size();\n//        return offset;\n    return 0;\n}", "CodeBleu_score": 4.744935701325648}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tlogger.debug(\"No messages to write to Kafka\");\n\t\treturn 0;\n\t}\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n\tlogger.debug(\"Writing {} messages to Kafka\", messageSet.size());\n\tlong lastOffset = kafkaLog.append(messageSet);\n\tlogger.debug(\"Wrote {} messages to Kafka at offset {}\", messageSet.size(), lastOffset);\n\treturn lastOffset;\n}", "CodeBleu_score": 31.737436340387244}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\tsynchronized (adminClientMap) {\n\t\tList<AdminClient> adminClientList = adminClientMap.get(clusterPhyId);\n\t\tif (adminClientList == null) {\n\t\t\treturn;\n\t\t}\n\n\t\tLOGGER.info(\"Closing Kafka AdminClient instances for cluster ID {}.\", clusterPhyId);\n\n\t\tboolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n\n\t\tif (allSuccess) {\n\t\t\tLOGGER.info(\"Kafka AdminClient instances for cluster ID {} successfully closed.\", clusterPhyId);\n\t\t} else {\n\t\t\tLOGGER.error(\"Error closing Kafka AdminClient instances for cluster ID {}. Some clients may not have been closed successfully.\", clusterPhyId);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.5246090818145}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t//    synchronized (this.adminClientMap) {\n        List<AdminClient> adminClientList = this.adminClientMap.get(clusterPhyId);\n        if (adminClientList == null) {\n            return;\n        }\n\n        boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n        if (allSuccess) {\n            LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n        }\n//    }\n}", "CodeBleu_score": 49.88660271042382}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t//        LOGGER.info(\"close kafka admin client begin, clusterPhyId:{}\", clusterPhyId);\n        try {\n            this.adminClientMap.lock();\n            List<AdminClient> adminClientList = this.adminClientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n            boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n            if (allSuccess) {\n                LOGGER.info(\"close kafka admin client success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka admin client failed, clusterPhyId:{}\", clusterPhyId);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"close kafka admin client failed, clusterPhyId:{}\", clusterPhyId, e);\n        } finally {\n            this.adminClientMap.unlock();\n        }\n    }", "CodeBleu_score": 68.07712267843614}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList!= null) {\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close(30000);\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\"Error closing admin client for cluster \" + clusterPhyId + \": \" + e.getMessage());\n\t\t\t\tsuccess = false;\n\t\t\t}\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 46.1606954063518}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30000);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error closing admin client for cluster \" + clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 52.97183159596487}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList!= null) {\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close(30000);\n\t\t\t} catch (Exception e) {\n\t\t\t\tLOGGER.error(\"Error closing admin client for cluster \" + clusterPhyId + \": \" + e.getMessage());\n\t\t\t\tsuccess = false;\n\t\t\t}\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 46.1606954063518}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner();\n\teurekaServerRunner.setConfig(config);\n\teurekaServerRunner.setEnableTLS(true);\n\teurekaServerRunner.setKeystore(EurekaServerRunner.class.getResourceAsStream(\"/eureka-server.jks\"));\n\teurekaServerRunner.setKeystorePassword(\"\");\n\teurekaServerRunner.setTruststore(EurekaServerRunner.class.getResourceAsStream(\"/eureka-server.jks\"));\n\teurekaServerRunner.setTruststorePassword(\"\");\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 30.67150634263741}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n\teurekaServerRunner.enableTLS();\n\teurekaServerRunner.setKeystore(keystore);\n\teurekaServerRunner.setTruststore(truststore);\n\teurekaServerRunner.setKeystorePassword(keystorePassword);\n\teurekaServerRunner.setTruststorePassword(truststorePassword);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 34.39334465936489}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner eurekaServerRunner = new EurekaServerRunner();\n\teurekaServerRunner.setConfig(config);\n\teurekaServerRunner.enableTLS();\n\teurekaServerRunner.setKeystore(eurekaServerKeystore);\n\teurekaServerRunner.setTruststore(eurekaServerTruststore);\n\teurekaServerRunner.setKeystorePassword(eurekaServerKeystorePassword);\n\teurekaServerRunner.setTruststorePassword(eurekaServerTruststorePassword);\n\teurekaServerRunner.start();\n\treturn eurekaServerRunner;\n}", "CodeBleu_score": 26.891685019303}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 69.07605965516397}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 69.07605965516397}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 69.07605965516397}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t", "CodeBleu_score": 1.403125619965593}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA\n\tKeyAndCert ca = KeyAndCert.generate(CA_PASSWORD, CA_KEY_SIZE, CA_KEY_TYPE, CA_NAME);\n\tsaveCert(ca);\n\tsaveKeyAndCert(ca);\n\t// Create a server certificate signed by the CA\n\tKeyAndCert server = KeyAndCert.generate(SERVER_PASSWORD, SERVER_KEY_SIZE, SERVER_KEY_TYPE, SERVER_NAME, ca.subject());\n\tsaveCert(server);\n\tsaveKeyAndCert(server);\n\t// Create a client certificate signed by the CA\n\tKeyAndCert client = KeyAndCert.generate(CLIENT_PASSWORD, CLIENT_KEY_SIZE, CLIENT_KEY_TYPE, CLIENT_NAME, ca.subject());\n\tsaveCert(client);\n\tsaveKeyAndCert(client);\n\t// Create a second CA and client certificate pair\n\tKeyAndCert ca2 = KeyAndCert.generate(CA_PASSWORD, CA_KEY_SIZE, CA_KEY_TYPE, CA_NAME);\n\tsaveCert(ca2);\n\tsaveKeyAndCert(ca2);\n\tKeyAndCert client2 = KeyAndCert.generate(CLIENT_PASSWORD, CLIENT_KEY_SIZE, CLIENT_KEY_TYPE, CLIENT_NAME, ca2.subject());\n\tsaveCert(client2);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 28.720341515536933}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyAndCert ca = new KeyAndCert();\n\tKeyAndCert server = new KeyAndCert();\n\tKeyAndCert client = new KeyAndCert();\n\tKeyAndCert secondCa = new KeyAndCert();\n\tKeyAndCert secondClient = new KeyAndCert();\n\tsaveCert(ca);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveCert(secondCa);\n\tsaveKeyAndCert(secondClient);\n}", "CodeBleu_score": 23.886927292771055}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong endTime = startTime + seconds * 1000;\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 50.26697727619366}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong endTime = startTime + (seconds * 1000);\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 48.265048179621196}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong timeLimit = System.currentTimeMillis() + (seconds * 1000);\n\twhile (System.currentTimeMillis() < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 43.472411017807595}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate cert = signCert(certBuilder(keyPair.getPublic(), ca, ca), keyPair.getPrivate());\n\tcert.checkValidity();\n\treturn cert;\n}", "CodeBleu_score": 35.12805484181905}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPrivateKey privateKey = keyPair.getPrivate();\n\tPublicKey publicKey = keyPair.getPublic();\n\n\tJcaX509v3CertificateBuilder builder = certBuilder(publicKey, ca, ca);\n\n\tbuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\tX509Certificate signCert = signCert(builder, privateKey);\n\n\treturn signCert;\n}", "CodeBleu_score": 48.91574947029963}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tPublicKey publicKey = keyPair.getPublic();\n\tPrivateKey privateKey = keyPair.getPrivate();\n\tX509Certificate signCert = signCert(certBuilder(publicKey, ca, ca), privateKey);\n\treturn signCert;\n}", "CodeBleu_score": 33.7545938584616}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tEurekaHttpClient eurekaHttpClient = null;\n\ttry {\n\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\tfield.setAccessible(true);\n\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\tlogger.error(\"Could not access the EurekaHttpClient from the EurekaTransport instance. Error: \" + e.getMessage());\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 37.480569931648674}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) eurekaTransport.getClass().getDeclaredField(\"registrationClient\").get(eurekaTransport);\n\t\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\t\tlogger.error(\"Failed to get EurekaHttpClient instance\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 37.65831281691615}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField field = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tfield.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) field.get(eurekaTransport);\n\t\t} catch (NoSuchFieldException | IllegalAccessException e) {\n\t\t\tLOGGER.error(\"Unable to retrieve EurekaHttpClient instance\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 41.78679132741802}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications();\n\tif (applications!= null) {\n\t\tfor (Application application : applications) {\n\t\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\t\tservices.add(application.getName().toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 48.756025096413346}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tMap<String, List<InstanceInfo>> map = this.eurekaClient.getApplications();\n\tfor (Map.Entry<String, List<InstanceInfo>> entry : map.entrySet()) {\n\t\tservices.add(entry.getKey().toLowerCase());\n\t}\n\treturn services;\n}", "CodeBleu_score": 38.639880566045306}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications().getRegisteredApplications();\n\tfor (Application application : applications) {\n\t\tservices.addAll(application.getInstances().stream().map(InstanceInfo::getAppName).map(String::toLowerCase).collect(Collectors.toList()));\n\t}\n\treturn services;\n}", "CodeBleu_score": 47.86740052363635}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\thealthContributors.putAll(new HashMap<String, HealthContributor>());\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthIndicator indicator : compositeHealthContributor.getHealthIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 47.287284920457154}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tif (healthContributors == null) {\n\t\treturn;\n\t}\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthContributor indicator : composite.getHealthContributors()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.26027871704874}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\t// TODO: implement\n}", "CodeBleu_score": 2.685961577638928}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tString uri = discoveryClient.getInstances(\"provider-application\").stream().map(instance -> instance.getUri()).findFirst().orElseThrow(() -> new RuntimeException(\"No instances of provider-application were found\"));\n\treturn restTemplate.postForObject(uri + \"/echo\", \"Hello, World!\", String.class);\n}", "CodeBleu_score": 39.46471377922913}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances == null || instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances of provider-application were found\");\n\t}\n\tServiceInstance instance = instances.get(0);\n\tString uri = instance.getUri().toString();\n\tRestTemplate restTemplate = new RestTemplate();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n\treturn response;\n}", "CodeBleu_score": 58.757956502002685}, {"code": "public String hello(){\n\t\tList<ServiceInstance> serviceInstances = discoveryClient.getInstances(\"provider-application\");\n\tif (serviceInstances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances of provider-application are running\");\n\t}\n\tServiceInstance serviceInstance = serviceInstances.get(0);\n\tString uri = serviceInstance.getUri().toString();\n\tString response = restTemplate.postForObject(uri + \"/echo\", \"Hello, world!\", String.class);\n\treturn response;\n}", "CodeBleu_score": 69.00377039929533}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tString result = null;\n\ttry {\n\t\t// Build the URI to the service instance using a load balancer client\n\t\tURI uri = serviceInstance.getUri();\n\t\t// Send a POST request to the \"/echo\" endpoint of the service instance using a RestTemplate\n\t\tresult = restTemplate.postForObject(uri.toString() + \"/echo\", \"World\", String.class);\n\t} catch (Exception e) {\n\t\t// If no service instance is found, it throws a RuntimeException indicating the absence of the required service\n\t\tthrow new RuntimeException(\"Could not find service instance: provider-application\", e);\n\t}\n\treturn result;\n}", "CodeBleu_score": 45.3708076930948}, {"code": "public String world(){\n\t\tString uri = serviceInstance.getUri();\n\turi = uri.concat(\"/echo\");\n\tHttpHeaders headers = new HttpHeaders();\n\theaders.setContentType(MediaType.APPLICATION_JSON);\n\tHttpEntity<String> entity = new HttpEntity<String>(headers);\n\tRestTemplate restTemplate = new RestTemplate();\n\tResponseEntity<String> response = restTemplate.exchange(uri, HttpMethod.POST, entity, String.class);\n\treturn response.getBody();\n}", "CodeBleu_score": 40.48930715476502}, {"code": "public String world(){\n\t\ttry {\n\t\tURI uri = serviceInstance.getUri();\n\t\tString response = restTemplate.postForObject(uri.toString() + \"/echo\", \"Hello World!\", String.class);\n\t\treturn response;\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 46.61067241924937}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Registering service with name: \" + serviceName + \" at ip: \" + ip + \" and port: \" + port);\n\tif (!serverMap.containsKey(serviceName)) {\n\t\tlogger.info(\"Registering service with name: \" + serviceName);\n\t\tHashSet<Server> servers = new HashSet<Server>();\n\t\tservers.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, servers);\n\t\treturn true;\n\t}\n\telse {\n\t\tlogger.info(\"Service with name: \" + serviceName + \" already registered\");\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 46.24507893993229}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif(serverMap.containsKey(serviceName)) {\n\t\tHashSet<Server> servers = serverMap.get(serviceName);\n\t\tservers.add(new Server(ip, port));\n\t\treturn true;\n\t}\n\telse {\n\t\tHashSet<Server> servers = new HashSet<Server>();\n\t\tservers.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, servers);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 49.72351710649748}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tsynchronized (serverMap.get(serviceName)) {\n\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t\tlogger.info(\"Service \" + serviceName + \" has been registered with IP \" + ip + \" and port \" + port);\n\t\t\treturn true;\n\t\t}\n\t} else {\n\t\tsynchronized (serverMap) {\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t\tlogger.info(\"Service \" + serviceName + \" has been registered with IP \" + ip + \" and port \" + port);\n\t\t\treturn true;\n\t\t}\n\t}\n}", "CodeBleu_score": 45.90845697655666}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tif (serverMap.get(serviceName).remove(new Server(ip, port))) {\n\t\t\tlogger.info(\"Deregistered server \" + ip + \":\" + port + \" from service \" + serviceName);\n\t\t\treturn true;\n\t\t}\n\t}\n\tlogger.info(\"Server \" + ip + \":\" + port + \" not found in service \" + serviceName);\n\treturn false;\n}", "CodeBleu_score": 39.99808652051997}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// Get the set associated with the serviceName\n\tSet<Server> servers = serverMap.get(serviceName);\n\t// If the set is null, return false\n\tif (servers == null) {\n\t\tlogger.info(\"Deregistering a server from a non-existent service: \" + serviceName);\n\t\treturn false;\n\t}\n\t// Get the Server object that corresponds to the ip and port\n\tServer server = servers.stream().filter(s -> s.getIp().equals(ip) && s.getPort().equals(port)).findFirst().orElse(null);\n\t// If the server is null, return false\n\tif (server == null) {\n\t\tlogger.info(\"Deregistering a server that does not exist: \" + serviceName + \" \" + ip + \" \" + port);\n\t\treturn false;\n\t}\n\t// Remove the server from the set\n\tservers.remove(server);\n\t// Log the deregistration\n\tlogger.info(\"Deregistered server \" + ip + \" \" + port + \" from \" + serviceName);\n\treturn true;\n}", "CodeBleu_score": 42.67491660864891}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tServer server = serverMap.get(serviceName).stream().filter(s -> s.getIp().equals(ip) && s.getPort() == port).findAny().orElse(null);\n\t\tif (server!= null) {\n\t\t\tserverMap.get(serviceName).remove(server);\n\t\t\tlogger.info(\"Deregistering server with ip: \" + ip + \" and port: \" + port + \" from service: \" + serviceName);\n\t\t\treturn true;\n\t\t} else {\n\t\t\tlogger.info(\"Server with ip: \" + ip + \" and port: \" + port + \" does not exist in service: \" + serviceName);\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tlogger.info(\"Service: \" + serviceName + \" does not exist\");\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 41.96339785829263}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t/        RibbonClients annotation = metadata.getAnnotationAttributes(RibbonClients.class);\n//        if (annotation == null) {\n//            return;\n//        }\n//        Map<String, Object> clients = annotation.clients();\n//        for (Map.Entry<String, Object> entry : clients.entrySet()) {\n//            String name = entry.getKey();\n//            Object configuration = entry.getValue();\n//            if (configuration instanceof RibbonClientConfiguration) {\n//                registerClientConfiguration(registry, name, configuration);\n//            } else {\n//                throw new IllegalStateException(\"Invalid value for key \" + name + \" in annotation @RibbonClients. \" +\n//                        \"Expected a RibbonClientConfiguration object but found \" + configuration.getClass().getName() + \".\");\n//            }\n//        }\n    }", "CodeBleu_score": 13.973077308062987}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = getAttributes(metadata);\n\tif (attributes.containsKey(DEFAULT_CONFIGURATION)) {\n\t\tString name = attributes.get(DEFAULT_CONFIGURATION).toString();\n\t\tregisterClientConfiguration(registry, name, attributes.get(DEFAULT_CONFIGURATION));\n\t}\n}", "CodeBleu_score": 37.062746098749095}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tibbonClients clients = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nMap<String, Object> defaultConfiguration = clients.defaultConfiguration();\nif (defaultConfiguration!= null) {\nregisterClientConfiguration(registry, \"default\", defaultConfiguration);\n}\nfor (RibbonClient client : clients.clients()) {\nregisterClientConfiguration(registry, client.name(), client.configuration());\n}\n}", "CodeBleu_score": 41.744520778505986}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t", "CodeBleu_score": 9.97081270039238}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// TODO: Implement this method\n\treturn null;\n}", "CodeBleu_score": 11.883005940910579}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server cannot be null\");\n\t}\n\tif (original == null) {\n\t\tthrow new IllegalArgumentException(\"original cannot be null\");\n\t}\n\tif (server.getServiceId() == null) {\n\t\tthrow new IllegalArgumentException(\"server.getServiceId() cannot be null\");\n\t}\n\tif (server.getHost() == null) {\n\t\tthrow new IllegalArgumentException(\"server.getHost() cannot be null\");\n\t}\n\tif (server.getPort() == null) {\n\t\tthrow new IllegalArgumentException(\"server.getPort() cannot be null\");\n\t}\n\treturn original.resolve(String.format(\"%s:%d\", server.getHost(), server.getPort()));\n}", "CodeBleu_score": 20.84579241026082}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\ttry {\n\t\tString host = server.getHost();\n\t\tint port = server.getPort();\n\t\tString scheme = original.getScheme();\n\t\tString path = original.getPath();\n\t\tString query = original.getQuery();\n\t\treturn new URI(scheme, null, host, port, path, query, null);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Failed to construct URI\", e);\n\t}\n}", "CodeBleu_score": 32.423007208243895}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null) {\n\t\tthrow new IllegalArgumentException(\"server must not be null\");\n\t}\n\tif (original == null) {\n\t\tthrow new IllegalArgumentException(\"original must not be null\");\n\t}\n\ttry {\n\t\tURI reconstructed = new URI(original.getScheme(), original.getUserInfo(), original.getHost(), original.getPort(), original.getPath(), original.getQuery(), original.getFragment());\n\t\treturn reconstructed;\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 41.152661739152315}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> tutuServers = new ArrayList<TutuServer>();\n\tString url = \"http://\" + discoveryService + \"/list\";\n\tHttpGet httpGet = new HttpGet(url);\n\ttry {\n\t\tHttpResponse response = httpClient.execute(httpGet);\n\t\tif (response.getStatusLine().getStatusCode() == 200) {\n\t\t\tString responseBody = EntityUtils.toString(response.getEntity());\n\t\t\tJSONArray jsonArray = new JSONArray(responseBody);\n\t\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\t\t\t\tString ip = jsonObject.getString(\"ip\");\n\t\t\t\tint port = jsonObject.getInt(\"port\");\n\t\t\t\ttutuServers.add(new TutuServer(ip, port));\n\t\t\t}\n\t\t}\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n\treturn tutuServers;\n}", "CodeBleu_score": 35.21617515348767}, {"code": "private List<TutuServer> getServer(){\n\t\tString url = \"http://\"+serverIP+\"/list\";\n\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\ttry {\n\t\tURL tutuServerList = new URL(url);\n\t\tHttpURLConnection tutuServerConnection = (HttpURLConnection) tutuServerList.openConnection();\n\t\ttutuServerConnection.setRequestMethod(\"GET\");\n\t\ttutuServerConnection.setRequestProperty(\"Content-Type\", \"application/json\");\n\t\ttutuServerConnection.setRequestProperty(\"Accept\", \"application/json\");\n\t\ttutuServerConnection.setDoOutput(true);\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(tutuServerConnection.getInputStream()));\n\t\tString inputLine;\n\t\tStringBuffer tutuServerResponse = new StringBuffer();\n\t\twhile ((inputLine = in.readLine())!= null) {\n\t\t\ttutuServerResponse.append(inputLine);\n\t\t}\n\t\tin.close();\n\t\tJSONObject tutuServerJSON = new JSONObject(tutuServerResponse.toString());\n\t\tJSONArray tutuServerArray = tutuServerJSON.getJSONArray(\"servers\");\n\t\tfor (int i = 0; i < tutuServerArray.length(); i++) {\n\t\t\tJSONObject server = tutuServerArray.getJSONObject(i);\n\t\t\tString serverIP = server.getString(\"ip\");\n\t\t\tString serverPort = server.getString(\"port\");\n\t\t\tTutuServer tutuServer = new TutuServer(serverIP, serverPort);\n\t\t\tservers.add(tutuServer);\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn servers;\n}", "CodeBleu_score": 31.50562770107045}, {"code": "private List<TutuServer> getServer(){\n\t\tString url = \"http://\" + discoveryService + \"/list\";\n\tList<TutuServer> tutuServers = new ArrayList<TutuServer>();\n\n\ttry {\n\t\tURL tutuServerURL = new URL(url);\n\t\tHttpURLConnection connection = (HttpURLConnection) tutuServerURL.openConnection();\n\t\tconnection.setRequestMethod(\"GET\");\n\t\tconnection.connect();\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(connection.getInputStream()));\n\t\tString inputLine;\n\t\tStringBuffer tutuServerList = new StringBuffer();\n\t\twhile ((inputLine = in.readLine())!= null) {\n\t\t\ttutuServerList.append(inputLine);\n\t\t}\n\t\tin.close();\n\t\tconnection.disconnect();\n\n\t\tJSONObject json = new JSONObject(tutuServerList.toString());\n\t\tJSONArray jsonArray = json.getJSONArray(\"servers\");\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject jsonServer = jsonArray.getJSONObject(i);\n\t\t\ttutuServers.add(new TutuServer(jsonServer.getString(\"ip\"), jsonServer.getInt(\"port\")));\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn tutuServers;\n}", "CodeBleu_score": 29.88355353573326}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (Route route : routes) {\n\t\tif (pathMatcher.match(route.getPattern(), path)) {\n\t\t\treturn new Route(pathMatcher.extractPath(route.getPattern(), path), route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 21.411726443841232}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (Route route : this.routes) {\n\t\tif (this.pathMatcher.match(route.getPattern(), path)) {\n\t\t\tString targetPath = path.substring(route.getPattern().length());\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 32.914921216201584}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (this.routes == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : this.routes) {\n\t\tif (this.pathMatcher.match(route.getPattern(), path)) {\n\t\t\treturn new Route(path, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 21.701295750942172}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// 1. \u626b\u63cf\u5305\u4e0b\u6240\u6709\u5e26\u6709@FeignClient\u6ce8\u89e3\u7684\u7c7b\n\tSet<String> beanNames = new LinkedHashSet<>(this.feignClientScanner.scan(importingClassMetadata.getClassName()));\n\n\t// 2. \u904d\u5386\u626b\u63cf\u5230\u7684\u7c7b\uff0c\u521b\u5efaGenericBeanDefinition\n\tfor (String beanName : beanNames) {\n\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\tdefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\tdefinition.getConstructorArgumentValues().addGenericArgumentValue(beanName);\n\t\tdefinition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n\t\tdefinition.setInstanceSupplier(new FactoryBeanInstanceSupplier(definition));\n\t\tdefinition.setSource(importingClassMetadata);\n\t\tregistry.registerBeanDefinition(beanName, definition);\n\t}\n}", "CodeBleu_score": 33.56839293659518}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// Determine the set of FeignClients that are in the package of the importing class.\n\tSet<String> clientClassNames = new LinkedHashSet<>(\n\t\t\tClassPathScanningCandidateComponentProvider.getCandidateComponents(registry.getBeanDefinitionRegistry(),\n\t\t\t\t\timportingClassMetadata.getClassName()));\n\n\t// Create bean definitions for each of the FeignClients.\n\tfor (String clientClassName : clientClassNames) {\n\t\tGenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\t\tbeanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\tbeanDefinition.setScope(BeanDefinition.SCOPE_PROTOTYPE);\n\t\tbeanDefinition.setSource(importingClassMetadata);\n\n\t\t// Configure the bean definition with the FeignClient settings.\n\t\tFeignClientFactoryBean.configure(beanDefinition, clientClassName);\n\n\t\t// Register the bean definition with the BeanDefinitionRegistry using the class name as the bean name.\n\t\tregistry.registerBeanDefinition(clientClassName, beanDefinition);\n\t}\n}", "CodeBleu_score": 38.23425127408765}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
