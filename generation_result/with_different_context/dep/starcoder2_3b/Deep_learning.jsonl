{"instance_id": "1f9f4d85e825", "generation_result": [{"code": "def load_model_from_config(self, half_attention)\n\t\n    cache_path = os.path.join(self.model_path, \"model.bin\")\n    if os.path.exists(cache_path) and self.use_cache:\n        print(\"Loading model from cache\")\n        model = torch.load(cache_path, map_location=self.device)\n    else:\n        print(\"Loading model from\", self.model_path)\n        model = torch.jit.load(self.model_path, map_location=self.device)\n        if self.use_cache:\n            torch.save(model, cache_path)\n    model.eval()\n    if half_attention:\n        model = model.half()\n    if self.memory_format == \"NHWC\":\n        model = model.to(memory_format=torch.channels_last)\n    return model\n\n", "CodeBleu_score": 30.19835341353405}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    # Load the model from the specified path\n    model_path = self.model_path\n    model = torch.jit.load(model_path)\n    # Configure the model\n    model.half_attention = half_attention\n    model.memory_format = torch.channels_last if self.memory_format else torch.contiguous_format\n    # Move the model to the appropriate device\n    model = model.to(self.device)\n    # Ensure the model is in evaluation mode\n    model.eval()\n    # Cache the model for future use\n    self.cache_model(model)\n    return model\n\n", "CodeBleu_score": 2.76190750710995}, {"code": "def load_model_from_config(self, half_attention)\n\t\n    if self.model_config.cache_dir is not None:\n        cache_path = self.model_config.cache_dir / self.model_config.model_name\n        if cache_path.exists():\n            try:\n                self.model = torch.load(cache_path, map_location=self.device)\n            except RuntimeError:\n                logger.info(f\"Cached model {cache_path} is invalid, reloading from config\")\n            else:\n                logger.info(f\"Loaded cached model {cache_path}\")\n                return self.model\n    if self.model_config.model_path.endswith(\".safetensors\"):\n        self.model = torch.load(self.model_config.model_path, map_location=self.device)\n    else:\n        self.model = self.model_config.model_path\n    self.model.eval()\n    if self.model_config.half_attention:\n        self.model.half()\n    if self.model_config.memory_format == \"channels_last\":\n        torch.cuda.set_memory_format(torch.cuda.MemoryFormat.ChannelsLast)\n    return self.model\n\n", "CodeBleu_score": 29.45831724399174}]}
{"instance_id": "8dc955007aa2", "generation_result": [{"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n\n    batch_size = shape[0]\n    sampler = DDIMSampler(model, batch_size=batch_size, shape=shape, eta=eta, callback=callback,\n                          normals_sequence=normals_sequence, mask=mask, x0=x0,\n                          quantize_x0=quantize_x0, temperature=temperature, score_corrector=score_corrector,\n                          corrector_kwargs=corrector_kwargs, x_t=x_t)\n\n    samples = sampler.sample(steps)\n    return samples\n\n", "CodeBleu_score": 24.786734535682456}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n\n    batch_size = shape[0]\n    sampler = DDIMSampler(model, batch_size=batch_size, steps=steps, shape=shape, eta=eta, callback=callback, normals_sequence=normals_sequence, mask=mask, x0=x0, quantize_x0=quantize_x0, temperature=temperature, score_corrector=score_corrector, corrector_kwargs=corrector_kwargs, x_t=x_t)\n    samples = sampler.sample()\n    return samples\n\n", "CodeBleu_score": 21.419485907995135}, {"code": "def convsample_ddim(model, cond, steps, shape, eta=1.0, callback=None, normals_sequence=None,\n                    mask=None, x0=None, quantize_x0=False, temperature=1., score_corrector=None,\n                    corrector_kwargs=None, x_t=None\n                    )\n\t\n    batch_size = shape[0]\n    sampler = DDIMSampler(model, unconditional_guidance_scale=1.0, eta=eta, steps=steps,\n                        guidance_scale=1.0, batch_size=batch_size,\n                        callback=callback,\n                        )\n    samples = sampler.sample(\n        cond,\n        shape=shape,\n        return_dict=True,\n        x_t=x_t,\n        )\n    return samples\n\n", "CodeBleu_score": 19.01642115104238}]}
{"instance_id": "9bdcd9081480", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if context is not None:\n        context.set_ema_enabled(True)\n    try:\n        yield\n    finally:\n        if context is not None:\n            context.set_ema_enabled(False)\n\n", "CodeBleu_score": 27.14127892848022}, {"code": "def ema_scope(self, context=None)\n\t\n    pass\n\n", "CodeBleu_score": 3.425925925925926}, {"code": "def ema_scope(self, context=None)\n\t\n    self.model.train()\n    ema = EMA(self.model, decay=self.ema_decay)\n    ema.register()\n    if context is not None:\n        print(\"EMA is enabled. Switching to EMA weights.\")\n    with torch.no_grad():\n        self.model.eval()\n        self.model.apply(ema.ema_hook)\n        yield\n        ema.unregister()\n        if context is not None:\n            print(\"EMA is disabled. Switching to original weights.\")\n        self.model.apply(ema.ema_restore)\n        self.model.train()\n\n", "CodeBleu_score": 47.22696293045655}]}
{"instance_id": "14ab009e1c5c", "generation_result": [{"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    state_dict = torch.load(path, map_location=torch.device('cpu'))\n    self.load_state_dict(state_dict, strict=False)\n    if ignore_keys is not None:\n        for key in ignore_keys:\n            if key in self.state_dict():\n                del self.state_dict()[key]\n    print(self)\n\n", "CodeBleu_score": 18.623562757818238}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    if not os.path.isfile(path):\n        raise IOError(\"File {} doesn't exist.\".format(path))\n    state_dict = torch.load(path, map_location=self.device)\n    if ignore_keys is not None:\n        for key in ignore_keys:\n            if key in state_dict:\n                del state_dict[key]\n    self.load_state_dict(state_dict, strict=False)\n    print(\"Loaded model from checkpoint '{}'\".format(path))\n\n", "CodeBleu_score": 26.14784149367041}, {"code": "def init_from_ckpt(self, path, ignore_keys=None)\n\t\n    state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n    if ignore_keys is not None:\n        state_dict = {k: v for k, v in state_dict.items() if k not in ignore_keys}\n    self.load_state_dict(state_dict, strict=False)\n    print('Init from ckpt')\n\n", "CodeBleu_score": 19.41404351530313}]}
{"instance_id": "754176e27b81", "generation_result": [{"code": "def forward(self, input, return_pred_indices=False)\n\t\n    if self.training:\n        quant, emb_loss, info = self.encode(input)\n        dec = self.decode(quant)\n        if return_pred_indices:\n            return dec, info, quant\n        else:\n            return dec, emb_loss\n    else:\n        quant = self.encode(input)\n        dec = self.decode(quant)\n        if return_pred_indices:\n            return dec, None, quant\n        else:\n            return dec\n\n", "CodeBleu_score": 51.61107280144094}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    quant, emb_loss, info = self.encode(input)\n    dec = self.decode(quant)\n    if return_pred_indices:\n        pred_indices = self.pred_indices(quant)\n        return dec, pred_indices, emb_loss, info\n    else:\n        return dec, emb_loss, info\n", "CodeBleu_score": 34.746419739595964}, {"code": "def forward(self, input, return_pred_indices=False)\n\t\n    if not self.training:\n        return self.decode(self.encode(input)[0]), None\n    else:\n        quant, emb_loss, info = self.encode(input)\n        pred = self.decode(quant)\n        if return_pred_indices:\n            return pred, info\n        else:\n            return pred, emb_loss, info\n\n", "CodeBleu_score": 42.486644322117115}]}
{"instance_id": "443df6fdaf0d", "generation_result": [{"code": "def get_input(self, batch, k)\n\t\n    batch_size = batch.size(0)\n    batch = batch.view(batch_size, -1)\n    batch = batch.permute(1, 0)\n    batch = batch.contiguous().float()\n    if self.resize:\n        if self.resize_range is not None:\n            batch = F.interpolate(batch.unsqueeze(0), size=(self.resize_range[0], self.resize_range[1]), mode='bicubic', align_corners=False).squeeze()\n        else:\n            batch = F.interpolate(batch.unsqueeze(0), size=(self.resize_size, self.resize_size), mode='bicubic', align_corners=False).squeeze()\n    return batch.detach()\n\n", "CodeBleu_score": 31.107673600666164}, {"code": "def get_input(self, batch, k)\n\t\n    input = batch[k]\n    input = input.permute(0, 2, 3, 1)\n    input = input.contiguous().float()\n    if self.batch_resizing:\n        input = input.unsqueeze(0)\n        input = F.interpolate(input, size=(self.height, self.width), mode=\"bicubic\", align_corners=True)\n        input = input.squeeze(0)\n    return input.detach()\n\n", "CodeBleu_score": 23.35929701029237}, {"code": "def get_input(self, batch, k)\n\t\n    input_data = batch[k].permute(0, 2, 3, 1)\n    input_data = input_data.contiguous().float()\n    if self.batch_resize:\n        input_data = F.interpolate(input_data, size=self.input_size, mode='bicubic', align_corners=True)\n    return input_data.detach()\n\n", "CodeBleu_score": 18.101709982634894}]}
{"instance_id": "953a2632fc15", "generation_result": [{"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    if self.global_step == 0:\n        self.log(\"lr\", optimizer.param_groups[0][\"lr\"])\n    x = self.get_input(batch, \"x\")\n    x_hat = self.forward(x)\n    loss = None\n    if optimizer_idx == 0:\n        loss = self.autoencoder_loss(x, x_hat)\n        self.log(\"autoencoder_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    elif optimizer_idx == 1:\n        loss = self.discriminator_loss(x, x_hat)\n        self.log(\"discriminator_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n    return loss", "CodeBleu_score": 29.309572004765638}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    x = self.get_input(batch, 0)\n    y = self.get_input(batch, 1)\n    if self.encoder is not None:\n        z = self.encoder(x)\n    else:\n        z = x\n    if self.decoder is not None:\n        x_hat = self.decoder(z)\n    else:\n        x_hat = z\n    if self.discriminator is not None:\n        d_real = self.discriminator(x)\n        d_fake = self.discriminator(x_hat)\n    if optimizer_idx == 0:\n        loss_autoencoding = self.loss_autoencoding(x, x_hat)\n        if self.encoder is not None:\n            loss_encoder = self.loss_encoder(z)\n        else:\n            loss_encoder = torch.tensor(0.0).to(x.device)\n        if self.decoder is not None:\n            loss_decoder = self.loss_decoder(z, x_hat)\n        else:\n            loss_decoder = torch.tensor(0.0).to(x.device)\n        if self.discriminator is not None:\n            loss_discriminator = self.loss_discriminator(d_real, d_fake)\n        else:\n            loss_discriminator = torch.tensor(0.0).to(x.device)\n        loss = loss_autoencoding + loss_encoder + loss_decoder + loss_discriminator\n    else:\n        loss_discriminator = self.loss_discriminator(d_real, d_fake)\n        loss = loss_discriminator\n    self.log(\"loss\", loss)\n    self.log(\"loss_autoencoding\", loss_autoencoding)\n    self.log(\"loss_encoder\", loss_encoder)\n    self.log(\"loss_decoder\", loss_decoder)\n    self.log(\"loss_discriminator\", loss_discriminator)\n    return loss", "CodeBleu_score": 30.467539437505124}, {"code": "def training_step(self, batch, batch_idx, optimizer_idx)\n\t    if optimizer_idx == 0:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 1:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 2:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 3:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 4:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 5:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(x_hat, x)\n        self.log(\"train_loss\", loss)\n        return loss\n    elif optimizer_idx == 6:\n        x = self.get_input(batch, \"image\")\n        x_hat = self.encoder(x)\n        x_hat = self.decoder(x_hat)\n        loss = self.loss_function(", "CodeBleu_score": 25.385838648728793}]}
{"instance_id": "b449b5e8b77f", "generation_result": [{"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    if self.image_key not in batch:\n        return\n    if not self.log_images:\n        return\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model is not None:\n        ema_batch = self.ema_model.ema_model(batch)\n    else:\n        ema_batch = None\n    if self.ema_model is not None and self.ema_model.ema_model", "CodeBleu_score": 15.875285209691874}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    # TODO: consider using batch.get_input_tensor()\n    if not self.log_images:\n        return\n    if not self.log_images_as_images:\n        self.log_images_as_images = self.log_images\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images_as_images:\n        return\n    if not self.log_images", "CodeBleu_score": 10.763354482880075}, {"code": "def log_images(self, batch, only_inputs=False, plot_ema=False, **kwargs)\n\t    if not self.log_images:\n        return\n    if not self.log_images_interval:\n        return\n    if self.global_step % self.log_images_interval!= 0:\n        return\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self.ema_model is None:\n        plot_ema = False\n    if self", "CodeBleu_score": 10.760771067862631}]}
{"instance_id": "540d089e3481", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise ValueError(\"Unknown loss type. Please provide either 'l1' or 'l2'.\")\n\n", "CodeBleu_score": 35.22200730216512}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise ValueError(\"Unknown loss type.\")\n\n", "CodeBleu_score": 34.71419224910943}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss == 'l1':\n        loss = torch.mean(torch.abs(pred - target))\n        if mean:\n            return loss\n        else:\n            return loss.item()\n    elif self.loss == 'l2':\n        loss = torch.mean((pred - target)**2)\n        if mean:\n            return loss\n        else:\n            return loss.item()\n    else:\n        raise Exception('Unknown loss type:'+ self.loss)\n\n", "CodeBleu_score": 41.12772020703368}]}
{"instance_id": "63a08283666f", "generation_result": [{"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.time_step_mode == \"random\":\n        t = torch.randint(0, self.num_time_steps, (x.shape[0],), device=x.device)\n    elif self.time_step_mode == \"sequential\":\n        t = torch.arange(0, self.num_time_steps, device=x.device)\n    else:\n        raise NotImplementedError(f\"Time step mode {self.time_step_mode} not yet supported\")\n\n    if self.conditioning_mode == \"learned\":\n        c = self.get_learned_conditioning(c)\n\n    x = self.model(x, t, c, *args, **kwargs)\n    return x\n\n", "CodeBleu_score": 40.31726292494659}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    x = self.preprocess(x)\n    c = self.get_learned_conditioning(c)\n    if self.cond_stage_forward is None:\n        t = torch.randint(0, self.num_timesteps, (x.shape[0],), device=x.device)\n    else:\n        t = torch.arange(0, self.num_timesteps, device=x.device)\n        t = t.repeat(x.shape[0], 1).view(-1)\n    if self.training:\n        t = t.to(x.device)\n    return self.p_losses(x, t, c)", "CodeBleu_score": 37.560819594657836}, {"code": "def forward(self, x, c, *args, **kwargs)\n\t\n    if self.time_steps is None:\n        self.time_steps = torch.arange(x.shape[0])\n\n    if self.time_steps.shape[0] > 1:\n        time_steps = self.time_steps[torch.randperm(self.time_steps.shape[0])]\n    else:\n        time_steps = self.time_steps\n\n    if self.learned_conditioning is not None:\n        c = self.get_learned_conditioning(c)\n\n    x = x[time_steps]\n    if c is not None:\n        c = c[time_steps]\n\n    if self.cond_stage_forward is None:\n        x = self.model(x, c, *args, **kwargs)\n    else:\n        x = getattr(self.model, self.cond_stage_forward)(x, c, *args, **kwargs)\n\n    return x\n", "CodeBleu_score": 42.1775326304352}]}
{"instance_id": "4627e1e8ed62", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    if self.unmap_to_all:\n        return self.unmap_to_all(self, indices)\n    else:\n        return self.codebook[indices.reshape(-1)].reshape(shape)\n\n", "CodeBleu_score": 16.242425433963387}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    assert self.codebook is not None\n    indices = self.unmap_to_all(indices)\n    if self.re_embed > 0:\n        indices = self.unmap_to_all(indices)\n    indices = indices.reshape(indices.shape[0], -1)\n    back = torch.gather(self.codebook[None, :], 1, indices)\n    back = back.reshape(indices.shape + shape)\n    return back\n\n", "CodeBleu_score": 46.53710899009036}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    if self.unmap_to_all:\n        indices = self.unmap_to_all(indices)\n    return self.codebook[indices].view(shape)\n\n", "CodeBleu_score": 18.59915953408494}]}
{"instance_id": "c55d014827ef", "generation_result": [{"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor == -1:\n        factor = dimension\n    if factor > 0 and factor <= dimension:\n        m = factor\n        n = dimension // factor\n    else:\n        m = 1\n        n = dimension\n        while True:\n            if n <= factor:\n                break\n            if m > n:\n                break\n            if m * n > dimension:\n                break\n            if m * n % factor == 0:\n                break\n            m += 1\n            n -= 1\n    return m, n\n\n", "CodeBleu_score": 44.80624129067707}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor > 0:\n        m = dimension // factor\n        n = dimension // m\n        return m, n\n    elif factor < 0:\n        m = 1\n        n = dimension\n        while n > 0:\n            if dimension % m == 0:\n                return m, n\n            m += 1\n            n = dimension // m\n    return dimension, 1\n\n", "CodeBleu_score": 32.92755507045702}, {"code": "def factorization(dimension: int, factor:int=-1) -> tuple[int, int]\n\t\n    if factor < 0:\n        factor = 0\n    if factor > 0 and dimension % factor!= 0:\n        return 0, 0\n    m = 0\n    n = 0\n    if factor > 0:\n        m = factor\n        n = dimension // factor\n    else:\n        m = dimension\n        n = 1\n        while m > n:\n            m = m - n\n            if m < n:\n                m = n\n                n = n - 1\n    return m, n\n\n", "CodeBleu_score": 39.66800364388538}]}
{"instance_id": "5d613ec26036", "generation_result": [{"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    if updown == 1:\n        weight = self.up_weight\n        orig_weight = orig_weight.to(weight.device)\n        weight = weight.to(orig_weight.device)\n        weight = orig_weight * weight\n        weight = weight / torch.sum(weight)\n        weight = weight * self.up_weight_scale\n        weight = weight - orig_weight\n    else:\n        weight = self.down_weight\n        orig_weight = orig_weight.to(weight.device)\n        weight = weight.to(orig_weight.device)\n        weight = orig_weight * weight\n        weight = weight / torch.sum(weight)\n        weight = weight * self.down_weight_scale\n        weight = weight - orig_weight\n    return weight\n\n", "CodeBleu_score": 27.693894645187644}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n   ...\n", "CodeBleu_score": 1.049465240641711}, {"code": "def apply_weight_decompose(self, updown, orig_weight)\n\t\n    if updown == 1:\n        return (orig_weight + self.weight_up) / 2\n    elif updown == 2:\n        return (orig_weight + self.weight_down) / 2\n    else:\n        return orig_weight\n\n", "CodeBleu_score": 8.284470974326322}]}
{"instance_id": "c73d0d1cd3e5", "generation_result": [{"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t if ex_bias is None:\n        ex_bias = 0.0\n    if self.bias is not None:\n        updown = updown + self.bias.to(device=updown.device)\n    if self.output_shape is not None:\n        updown = updown.reshape(output_shape)\n    if orig_weight.numel() == updown.numel():\n        updown = updown.reshape(orig_weight.shape)\n    if self.multiplier is not None:\n        ex_bias = ex_bias * self.multiplier\n    if self.scale is not None:\n        updown = updown * self.scale\n        ex_bias = ex_bias * self.scale\n    if self.apply_weight_decompose:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n    return updown, ex_bias", "CodeBleu_score": 61.005861460843605}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t updown = updown.to(orig_weight.device)\n    if ex_bias is not None:\n        updown = updown + ex_bias\n    if updown.shape[1] == orig_weight.numel():\n        updown = updown.reshape(output_shape)\n    if self.multiplier is not None:\n        updown = updown * self.multiplier\n    if self.scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n    return updown, ex_bias", "CodeBleu_score": 44.137735126004294}, {"code": "def finalize_updown(self, updown, orig_weight, output_shape, ex_bias=None)\n\t # Match the device/dtype\n    orig_weight = orig_weight.to(updown.dtype)\n    dora_scale = self.dora_scale.to(device=orig_weight.device, dtype=updown.dtype)\n    updown = updown.to(orig_weight.device)\n\n    merged_scale1 = updown + orig_weight\n    merged_scale1_norm = (\n        merged_scale1.transpose(0, 1)\n       .reshape(merged_scale1.shape[1], -1)\n       .norm(dim=1, keepdim=True)\n       .reshape(merged_scale1.shape[1], *[1] * self.dora_norm_dims)\n       .transpose(0, 1)\n    )\n\n    dora_merged = (\n        merged_scale1 * (dora_scale / merged_scale1_norm)\n    )\n    final_updown = dora_merged - orig_weight\n\n    if self.bias is not None:\n        final_updown = final_updown + self.bias\n\n    if self.scale is not None:\n        final_updown = final_updown * self.scale\n\n    if ex_bias is not None:\n        final_updown = final_updown + ex_bias\n\n    if self.dim is not None and self.alpha is not None:\n        final_updown = final_updown * (self.alpha / self.dim)\n\n    final_updown = final_updown.reshape(output_shape)\n    return final_updown, ex_bias\n", "CodeBleu_score": 41.59221901393848}]}
{"instance_id": "c6a41665c62c", "generation_result": [{"code": "def calc_updown(self, orig_weight)\n\t\n\n    if self.updown_method == 'none':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype)\n\n    if self.updown_method == 'random':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'gaussian':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'uniform':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.rand_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'normal':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'orthogonal':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'xavier':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'kaiming':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'orthogonal_uniform':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'orthogonal_normal':\n        return orig_weight.to(self.device, dtype=orig_weight.dtype) + torch.randn_like(orig_weight) * self.updown_noise\n\n    if self.updown_method == 'orthogonal_xavier':\n        return orig_weight", "CodeBleu_score": 22.598355056344523}, {"code": "def calc_updown(self, orig_weight)\n\t\n\n    updown = self.updown.to(orig_weight.device, dtype=orig_weight.dtype)\n    if self.bias is not None:\n        updown = updown.reshape(self.bias.shape)\n        updown += self.bias.to(orig_weight.device, dtype=updown.dtype)\n        updown = updown.reshape(orig_weight.shape)\n\n    if len(orig_weight.shape) == 4:\n        updown = updown.reshape(orig_weight.shape)\n\n    if orig_weight.size().numel() == updown.size().numel():\n        updown = updown.reshape(orig_weight.shape)\n\n    if self.dora_scale is not None:\n        updown = self.apply_weight_decompose(updown, orig_weight)\n\n    return updown * self.calc_scale() * self.multiplier()\n\n", "CodeBleu_score": 36.77128930194463}, {"code": "def calc_updown(self, orig_weight)\n\t\n    updown = self.weight.to(orig_weight.device, dtype=orig_weight.dtype)\n    updown = updown.reshape(orig_weight.shape)\n    if self.bias is not None:\n        updown = updown.reshape(self.bias.shape)\n        updown += self.bias.to(orig_weight.device, dtype=updown.dtype)\n        updown = updown.reshape(orig_weight.shape)\n    updown = updown * self.calc_scale() * self.multiplier()\n    return updown\n\n", "CodeBleu_score": 38.286070111338844}]}
{"instance_id": "1bb9e5d94af8", "generation_result": [{"code": "def purge_networks_from_memory()\n\t\n    global network_count\n    if network_count > MAX_NETWORKS_IN_MEMORY:\n        print(\"Purging networks from memory...\")\n        for network in networks:\n            networks.remove(network)\n        network_count = 0\n        gc.collect()\n    else:\n        pass\n", "CodeBleu_score": 25.168486182682553}, {"code": "def purge_networks_from_memory()\n\t\n    global networks\n    if len(networks) > 1000:\n        networks = networks[100:]\n        gc.collect()\n", "CodeBleu_score": 17.909933169026484}, {"code": "def purge_networks_from_memory()\n\t\n    if len(networks) > 10:\n        for net in networks:\n            networks.remove(net)\n        gc.collect()\n\n", "CodeBleu_score": 20.37833459734121}]}
{"instance_id": "42b48ebf4d07", "generation_result": [{"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    if hasattr(self, 'backup_weights') and hasattr(self, 'backup_biases'):\n        self.weight.data = self.backup_weights\n        if hasattr(self, 'backup_biases'):\n            self.bias.data = self.backup_biases\n        else:\n            self.bias = None\n    if isinstance(self, torch.nn.MultiheadAttention):\n        if hasattr(self, 'backup_proj_weights') and hasattr(self, 'backup_proj_biases'):\n            self.in_proj_weight.data = self.backup_proj_weights\n            self.in_proj_bias.data = self.backup_proj_biases\n        if hasattr(self, 'backup_out_weights') and hasattr(self, 'backup_out_biases'):\n            self.out_proj.weight.data = self.backup_out_weights\n            self.out_proj.bias.data = self.backup_out_biases\n        if hasattr(self, 'backup_bias') and hasattr(self, 'backup_scale'):\n            self.out_proj.bias.data = self.backup_bias\n            self.out_proj.scale.data = self.backup_scale\n\n", "CodeBleu_score": 36.87811039213968}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n    backup_weights = self.get_backup_weights()\n    backup_bias = self.get_backup_bias()\n    if backup_weights is not None:\n        self.weight.data = backup_weights\n    if backup_bias is not None:\n        self.bias.data = backup_bias\n    if isinstance(self, torch.nn.MultiheadAttention):\n        backup_proj_weights = self.get_backup_proj_weights()\n        backup_proj_bias = self.get_backup_proj_bias()\n        if backup_proj_weights is not None:\n            self.in_proj_weight.data = backup_proj_weights\n        if backup_proj_bias is not None:\n            self.in_proj_bias.data = backup_proj_bias\n\n", "CodeBleu_score": 32.77416576138383}, {"code": "def network_restore_weights_from_backup(self: Union[torch.nn.Conv2d, torch.nn.Linear, torch.nn.GroupNorm, torch.nn.LayerNorm, torch.nn.MultiheadAttention]):\n\t\n   ...\n", "CodeBleu_score": 12.326435246995993}]}
{"instance_id": "c8fcd357131a", "generation_result": [{"code": "def network_forward(org_module, input, original_forward)\n\t\n    if org_module.network_weights_backup is None:\n        org_module.network_backup_weights()\n    if org_module.network_bias_backup is None:\n        org_module.network_backup_bias()\n    org_module.network_restore_weights_from_backup()\n    org_module.network_reset_cached_weight()\n    input = input.to(org_module.device)\n    output = original_forward(input)\n    for name, net in org_module.loaded_networks.items():\n        if name == org_module.current_name:\n            output = net(output)\n    return output\n", "CodeBleu_score": 33.542417449740846}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if org_module.network_weights_backup is None:\n        return original_forward(input)\n    else:\n        output = original_forward(input)\n        for i in range(len(org_module.network_current_names)):\n            output = org_module.network_current_names[i](output)\n        return output\n", "CodeBleu_score": 23.5613424599938}, {"code": "def network_forward(org_module, input, original_forward)\n\t\n    if not isinstance(org_module, nn.Module):\n        raise TypeError(\"The module must be of type nn.Module\")\n    if not isinstance(input, torch.Tensor):\n        raise TypeError(\"The input must be of type torch.Tensor\")\n    if not isinstance(original_forward, Callable):\n        raise TypeError(\"The original_forward must be of type Callable\")\n\n    if org_module.network_weights_backup is None:\n        org_module.network_restore_weights_from_backup()\n\n    input = input.to(org_module.device)\n    org_module.network_reset_cached_weight()\n    output = original_forward(input)\n\n    for loaded_network in org_module.loaded_networks:\n        if loaded_network.layer == org_module.layer:\n            output = loaded_network.forward(output)\n\n    return output\n\n", "CodeBleu_score": 36.71285043343791}]}
{"instance_id": "1070211f5c11", "generation_result": [{"code": "def trainables(self)\n\t\n   ...\n", "CodeBleu_score": 0.862068965517866}, {"code": "def trainables(self)\n\t\n   ...\n", "CodeBleu_score": 0.862068965517866}, {"code": "def trainables(self)\n\t\n   ...\n\n", "CodeBleu_score": 0.862068965517866}]}
{"instance_id": "0c3ba62c96a7", "generation_result": [{"code": "def load_hypernetworks(names, multipliers=None)\n\t\n    if multipliers is None:\n        multipliers = []\n\n    loaded_hypernetworks = []\n    for i in range(len(names)):\n        name = names[i]\n        multiplier = multipliers[i] if i < len(multipliers) else 1\n        hypernetwork = load_hypernetwork(name)\n\n        if hypernetwork is None:\n            errors.report(f\"Error loading hypernetwork {name}\")\n            continue\n\n        hypernetwork.set_multiplier(multiplier)\n        loaded_hypernetworks.append(hypernetwork)\n\n    shared.hypernetworks.clear()\n    shared.hypernetworks.update(loaded_hypernetworks)\n    return loaded_hypernetworks", "CodeBleu_score": 44.27771600925864}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    hypernetworks = []\n\n    for i, name in enumerate(names):\n        hypernetwork = load_hypernetwork(name)\n\n        if hypernetwork is None:\n            continue\n\n        hypernetwork.set_multiplier(multipliers[i])\n        hypernetworks.append(hypernetwork)\n\n    return hypernetworks", "CodeBleu_score": 34.20944159900779}, {"code": "def load_hypernetworks(names, multipliers=None)\n\t\n\n    if multipliers is None:\n        multipliers = [1] * len(names)\n\n    for name, multiplier in zip(names, multipliers):\n        hypernetwork = load_hypernetwork(name)\n        if hypernetwork is not None:\n            hypernetwork.set_multiplier(multiplier)\n            shared.hypernetworks.append(hypernetwork)\n\n    return shared.hypernetworks", "CodeBleu_score": 26.538304985200284}]}
{"instance_id": "bea3772ed532", "generation_result": [{"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer)\n    return context_k, context_v\n\n", "CodeBleu_score": 77.04946886953897}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k, context_v = context\n    for hypernetwork in hypernetworks:\n        context_k, context_v = apply_single_hypernetwork(hypernetwork, context_k, context_v, layer=layer)\n    return context_k, context_v", "CodeBleu_score": 57.71120728491728}, {"code": "\ndef apply_hypernetworks(hypernetworks, context, layer=None)\n\t\n    context_k = context\n    context_v = context\n\n    for context_k, context_v in zip(context_k, context_v):\n        context_k, context_v = apply_single_hypernetwork(hypernetworks[0], context_k, context_v, layer)\n\n    return context_k, context_v\n\n", "CodeBleu_score": 54.24761045943583}]}
{"instance_id": "922efa3e092f", "generation_result": [{"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    # print(\"attention_CrossAttention_forward\")\n    # print(\"x\", x.shape)\n    # print(\"context\", context.shape)\n    # print(\"mask\", mask.shape)\n    # print(\"self.query_size\", self.query_size)\n    # print(\"self.key_size\", self.key_size)\n    # print(\"self.value_size\", self.value_size)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.head_size\", self.head_size)\n    # print(\"self.max_length\", self.max_length)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num_heads\", self.num_heads)\n    # print(\"self.num_layers\", self.num_layers)\n    # print(\"self.num", "CodeBleu_score": 1.9834764933446987}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n\n    # x: (batch_size, num_heads, seq_len, dim_head)\n    # context: (batch_size, num_heads, context_seq_len, dim_head)\n    # mask: (batch_size, context_seq_len)\n\n    # x: (batch_size, seq_len, dim_head * num_heads)\n    # context: (batch_size, context_seq_len, dim_head * num_heads)\n    # mask: (batch_size, context_seq_len)\n\n    x = self.query_proj(x)\n    context = self.key_proj(context)\n    context = self.value_proj(context)\n\n    # x: (batch_size, seq_len, dim_head * num_heads)\n    # context: (batch_size, context_seq_len, dim_head * num_heads)\n    # mask: (batch_size, context_seq_len)\n\n    # x: (batch_size, num_heads, seq_len, dim_head)\n    # context: (batch_size, num_heads, context_seq_len, dim_head)\n    # mask: (batch_size, num_heads, context_seq_len)\n\n    x = x.permute(0, 2, 1, 3)\n    context = context.permute(0, 2, 1, 3)\n\n    # x: (batch_size, seq_len, num_heads, dim_head)\n    # context: (batch_size, context_seq_len, num_heads, dim_head)\n    # mask: (batch_size, num_heads, context_seq_len)\n\n    if mask is not None:\n        mask = mask.unsqueeze(1)\n\n    # x: (batch_size, seq_len, num_heads, dim_head)\n    # context: (batch_size, context_seq_len, num_heads, dim_head)\n    # mask: (batch_size, num_heads, context_seq_len)\n\n    # x: (batch_size * num_heads, seq_len, dim_head)\n    # context: (batch_size * num_heads, context_seq_len, dim_head)\n    # mask: (batch_size * num_heads, context_", "CodeBleu_score": 12.210422426423277}, {"code": "def attention_CrossAttention_forward(self, x, context=None, mask=None, **kwargs)\n\t\n    # Apply the hypernetworks to the context\n    context_k, context_v = apply_hypernetworks(self.hypernetworks, context, layer=self.layer)\n    # Reshape the context tensors for multi-head attention\n    context_k = reshape_for_multihead_attention(context_k)\n    context_v = reshape_for_multihead_attention(context_v)\n    # Compute scaled dot-product attention\n    attn_output, attn_output_weights = scaled_dot_product_attention(query=x, key=context_k, value=context_v, mask=mask)\n    # Reshape the attention output back to the original shape\n    attn_output = reshape_for_output(attn_output, self.num_heads)\n    # Apply the final linear layer\n    attn_output = self.final_linear(attn_output)\n    return attn_output\n\n", "CodeBleu_score": 14.414742792159686}]}
{"instance_id": "8b7455a03a0e", "generation_result": [{"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t    backup_hypernetwork = copy.deepcopy(hypernetwork)\n    backup_hypernetwork.sd_checkpoint = checkpoint\n    backup_hypernetwork.sd_checkpoint_name = hypernetwork_name\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        hypernetwork.sd_checkpoint = backup_hypernetwork.sd_checkpoint\n        hypernetwork.sd_checkpoint_name = backup_hypernetwork.sd_checkpoint_name\n        raise e\n\n", "CodeBleu_score": 26.591650397958382}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t    # Back up original attributes\n    orig_checkpoint = hypernetwork.sd_checkpoint\n    orig_checkpoint_name = hypernetwork.sd_checkpoint_name\n    orig_name = hypernetwork.name\n    orig_layer_structure = hypernetwork.layer_structure\n    orig_activation_func = hypernetwork.activation_func\n    orig_add_layer_norm = hypernetwork.add_layer_norm\n    orig_weight_init = hypernetwork.weight_init\n    orig_optimizer_name = hypernetwork.optimizer_name\n    orig_optimizer_state_dict = hypernetwork.optimizer_state_dict\n    orig_optional_info = hypernetwork.optional_info\n\n    # Update attributes with new checkpoint information\n    hypernetwork.sd_checkpoint = checkpoint\n    hypernetwork.sd_checkpoint_name = hypernetwork_name\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.layer_structure = hypernetwork.layer_structure\n    hypernetwork.activation_func = hypernetwork.activation_func\n    hypernetwork.add_layer_norm = hypernetwork.add_layer_norm\n    hypernetwork.weight_init = hypernetwork.weight_init\n    hypernetwork.optimizer_name = hypernetwork.optimizer_name\n    hypernetwork.optimizer_state_dict = hypernetwork.optimizer_state_dict\n    hypernetwork.optional_info = hypernetwork.optional_info\n\n    # Attempt to save the hypernetwork\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        # Restore original attributes\n        hypernetwork.sd_checkpoint = orig_checkpoint\n        hypernetwork.sd_checkpoint_name = orig_checkpoint_name\n        hypernetwork.name = orig_name\n        hypernetwork.layer_structure = orig_layer_structure\n        hypernetwork.activation_func = orig_activation_func\n        hypernetwork.add_layer_norm = orig_add_layer_norm\n        hypernetwork.weight_init = orig_weight_init\n        hypernetwork.optimizer_name = orig_optimizer_name\n        hypernetwork.optimizer_state_dict = orig_optimizer_state_dict\n        hypernetwork.optional_info = orig_optional_info\n\n        # Re-raise the exception\n        raise e\n\n", "CodeBleu_score": 35.222997169165914}, {"code": "def save_hypernetwork(hypernetwork, checkpoint, hypernetwork_name, filename)\n\t\n    # Backup original attributes\n    backup_name = hypernetwork.name\n    backup_layer_structure = hypernetwork.layer_structure\n    backup_activation_func = hypernetwork.activation_func\n    backup_add_layer_norm = hypernetwork.add_layer_norm\n    backup_weight_init = hypernetwork.weight_init\n    backup_sd_checkpoint = hypernetwork.sd_checkpoint\n    backup_sd_checkpoint_name = hypernetwork.sd_checkpoint_name\n    backup_activate_output = hypernetwork.activate_output\n    backup_use_dropout = hypernetwork.use_dropout\n    backup_dropout_structure = hypernetwork.dropout_structure\n    backup_last_layer_dropout = hypernetwork.last_layer_dropout\n    backup_optional_info = hypernetwork.optional_info\n\n    # Update attributes with new checkpoint data\n    hypernetwork.name = hypernetwork_name\n    hypernetwork.layer_structure = checkpoint['layer_structure']\n    hypernetwork.activation_func = checkpoint['activation_func']\n    hypernetwork.add_layer_norm = checkpoint['is_layer_norm']\n    hypernetwork.weight_init = checkpoint['weight_initialization']\n    hypernetwork.sd_checkpoint = checkpoint['sd_checkpoint']\n    hypernetwork.sd_checkpoint_name = checkpoint['sd_checkpoint_name']\n    hypernetwork.activate_output = checkpoint['activate_output']\n    hypernetwork.use_dropout = checkpoint['use_dropout']\n    hypernetwork.dropout_structure = checkpoint['dropout_structure']\n    hypernetwork.last_layer_dropout = checkpoint['last_layer_dropout']\n    hypernetwork.optional_info = checkpoint['optional_info']\n\n    # Save the hypernetwork\n    try:\n        hypernetwork.save(filename)\n    except Exception as e:\n        # Restore original attributes\n        hypernetwork.name = backup_name\n        hypernetwork.layer_structure = backup_layer_structure\n        hypernetwork.activation_func = backup_activation_func\n        hypernetwork.add_layer_norm = backup_add_layer_norm\n        hypernetwork.weight_init = backup_weight_init\n        hypernetwork.sd_checkpoint = backup_sd_checkpoint\n        hypernetwork.sd_checkpoint_name = backup_sd_checkpoint_name\n        hypernetwork.activate_output = backup_activate_output\n        hypernetwork.use_dropout = backup_use_dropout\n        hypernetwork.dropout_structure = backup_", "CodeBleu_score": 23.80954330270538}]}
{"instance_id": "3175f835140f", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if self._ema is None:\n        return\n    if context is None:\n        context = {}\n    if self._ema.is_enabled():\n        if self._ema.is_enabled_for_var(context):\n            self._ema.store_weights()\n        else:\n            self._ema.restore_weights()\n        return\n    if self._ema.is_enabled_for_var(context):\n        self._ema.store_weights()\n    else:\n        self._ema.restore_weights()\n    return\n\n", "CodeBleu_score": 45.781514165152835}, {"code": "def ema_scope(self, context=None)\n\t\n    # type: (Any) -> Any\n    return self._execute_op(\"ema_scope\", context)\n\n", "CodeBleu_score": 5.230099881748156}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = Context()\n    context.set_ema_scope(self)\n    return context\n\n", "CodeBleu_score": 13.377455182355142}]}
{"instance_id": "a7b5d5cd519a", "generation_result": [{"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_start, x_t, noise = self.encode(x, t)\n    posterior_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(x_start, x_t, t)\n    if clip_denoised:\n        denoised = self.predict_start_from_noise(x_t, t, noise)\n        denoised = torch.clamp(denoised, -1.0, 1.0)\n    else:\n        denoised = self.predict_start_from_noise(x_t, t, noise)\n    return denoised, posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 36.75671649789949}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_start, x_t = self.get_model_output(x, t)\n    if clip_denoised:\n        x_t = torch.clamp(x_t, -1, 1)\n    posterior_mean, posterior_variance, posterior_log_variance_clipped = self.q_posterior(x_start, x_t, t)\n    return posterior_mean, posterior_variance, posterior_log_variance_clipped\n\n", "CodeBleu_score": 22.83740712431034}, {"code": "def p_mean_variance(self, x, t, clip_denoised: bool)\n\t\n    x_start = extract_into_tensor(self.x_start, t, x.shape)\n    x_t = extract_into_tensor(self.x_t, t, x.shape)\n    x_start_mean, x_start_variance, x_start_log_variance_clipped = self.q_posterior(x_start, x_t, t)\n    x_t_mean, x_t_variance, x_t_log_variance_clipped = self.q_posterior(x_start, x_t, t)\n    x_start_mean = extract_into_tensor(self.x_start_mean, t, x.shape)\n    x_start_variance = extract_into_tensor(self.x_start_variance, t, x.shape)\n    x_start_log_variance_clipped = extract_into_tensor(self.x_start_log_variance_clipped, t, x.shape)\n    x_t_mean = extract_into_tensor(self.x_t_mean, t, x.shape)\n    x_t_variance = extract_into_tensor(self.x_t_variance, t, x.shape)\n    x_t_log_variance_clipped = extract_into_tensor(self.x_t_log_variance_clipped, t, x.shape)\n    posterior_mean = (\n            extract_into_tensor(self.posterior_mean_coef1, t, x.shape) * x_start_mean +\n            extract_into_tensor(self.posterior_mean_coef2, t, x.shape) * x_t_mean\n    )\n    posterior_variance = extract_into_tensor(self.posterior_variance, t, x.shape)\n    posterior_log_variance_clipped = extract_into_tensor(self.posterior_log_variance_clipped, t, x.shape)\n    return posterior_mean, posterior_variance, posterior_log_variance_clipped", "CodeBleu_score": 23.218013379511497}]}
{"instance_id": "a8652fa78473", "generation_result": [{"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        if mean:\n            return torch.mean(torch.abs(pred - target))\n        else:\n            return torch.abs(pred - target)\n    elif self.loss_type == 'l2':\n        if mean:\n            return torch.mean((pred - target) ** 2)\n        else:\n            return (pred - target) ** 2\n    else:\n        raise ValueError('Unknown loss type: {}'.format(self.loss_type))\n\n", "CodeBleu_score": 33.96004812577799}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss == 'l1':\n        loss = F.l1_loss(pred, target, reduction='mean') if mean else F.l1_loss(pred, target, reduction='none')\n    elif self.loss == 'l2':\n        loss = F.mse_loss(pred, target, reduction='mean') if mean else F.mse_loss(pred, target, reduction='none')\n    else:\n        raise ValueError('Unknown loss type: {}'.format(self.loss))\n    return loss\n\n", "CodeBleu_score": 38.45882991244228}, {"code": "def get_loss(self, pred, target, mean=True)\n\t\n    if self.loss_type == 'l1':\n        loss = F.l1_loss(pred, target, reduction='mean') if mean else F.l1_loss(pred, target, reduction='none')\n    elif self.loss_type == 'l2':\n        loss = F.mse_loss(pred, target, reduction='mean') if mean else F.mse_loss(pred, target, reduction='none')\n    else:\n        raise ValueError('Unknown loss type: {}'.format(self.loss_type))\n    return loss\n\n", "CodeBleu_score": 42.581645571296214}]}
{"instance_id": "d68e4f061349", "generation_result": [{"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.tensor(np.arange(self.num_diffusion_steps)).to(x_start.device)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    kl_divergence = torch.sum(0.5 * (log_variance - 2.0 * torch.log(variance) + variance + 1.0), dim=-1)\n    return torch.mean(kl_divergence) / np.log(2.0)\n\n", "CodeBleu_score": 29.03003811598947}, {"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.arange(self.T).to(x_start.device)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    log_normal_mean = torch.zeros(mean.shape).to(x_start.device)\n    log_normal_variance = torch.ones(variance.shape).to(x_start.device)\n    kl = (log_normal_variance - log_variance) + (variance / log_normal_variance) + ((mean - log_normal_mean) ** 2) / log_normal_variance - 1\n    return kl.sum(dim=(1, 2, 3, 4)).mean() / np.log(2)\n\n", "CodeBleu_score": 25.52841124325964}, {"code": "def _prior_bpd(self, x_start)\n\t    batch_size = x_start.shape[0]\n    t = torch.arange(0, self.num_diffusion_steps, dtype=torch.float32, device=x_start.device)\n    mean, variance, log_variance = self.q_mean_variance(x_start, t)\n    mean = mean.reshape(batch_size, -1)\n    variance = variance.reshape(batch_size, -1)\n    log_variance = log_variance.reshape(batch_size, -1)\n    kl_divergence = torch.distributions.kl.kl_divergence(\n        torch.distributions.normal.Normal(mean, variance.sqrt()),\n        torch.distributions.normal.Normal(0, 1)\n    )\n    return kl_divergence.sum(1).mean() / (np.log(2) * x_start.shape[1])\n\n", "CodeBleu_score": 28.06124840643538}]}
{"instance_id": "c695d93fdf2d", "generation_result": [{"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_dir = Path(os.path.join(os.path.expanduser(\"~\"), \".cache\", \"py-scraper\"))\n    cache_dir.mkdir(parents=True, exist_ok=True)\n    cache_path = os.path.join(cache_dir, f\"{subsection}.db\")\n    cache = diskcache.Cache(cache_path, size_limit=4_000_000_000, sqlite_pragmas={\"synchronous\": \"OFF\"})\n    return cache\n\n", "CodeBleu_score": 41.91857051096315}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    cache_path = os.path.join(CACHE_DIR, subsection)\n    return diskcache.Cache(cache_path, size_limit=4 * 1024 * 1024 * 1024, db_filename=\"sqlite\", db_size_limit=256 * 1024)\n\n", "CodeBleu_score": 50.295910784882444}, {"code": "def make_cache(subsection: str) -> diskcache.Cache\n\t\n    return diskcache.Cache(f\"cache/{subsection}\", size_limit=4294967296, min_file_size=262144)\n\n", "CodeBleu_score": 39.14930759518904}]}
{"instance_id": "ed4c543f0d38", "generation_result": [{"code": "def cache(subsection)\n\t\n    global caches\n    if subsection not in caches:\n        with cache_lock:\n            if subsection not in caches:\n                if not os.path.isdir(cache_dir):\n                    os.makedirs(cache_dir)\n                if not os.path.isfile(cache_filename):\n                    convert_old_cached_data()\n                if subsection not in caches:\n                    caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 42.97863614592173}, {"code": "def cache(subsection)\n\t\n    global caches\n    if subsection in caches:\n        return caches[subsection]\n\n    with cache_lock:\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n        if not os.path.isfile(cache_filename):\n            convert_old_cached_data()\n        if subsection not in caches:\n            caches[subsection] = make_cache(subsection)\n    return caches[subsection]\n\n", "CodeBleu_score": 48.315308624745526}, {"code": "def cache(subsection)\n\t\n    global caches\n    global cache_lock\n\n    with cache_lock:\n        if subsection in caches:\n            return caches[subsection]\n\n        if not os.path.exists(cache_dir):\n            os.makedirs(cache_dir)\n\n        if not os.path.isfile(cache_filename):\n            convert_old_cached_data()\n\n        if subsection not in caches:\n            caches[subsection] = make_cache(subsection)\n\n        return caches[subsection]\n\n", "CodeBleu_score": 47.106173548792775}]}
{"instance_id": "ccf5ea2d9fc1", "generation_result": [{"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache_obj = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    cache_entry = cache_obj.get(title)\n    if cache_entry:\n        cache_mtime = cache_entry[1]\n        if mtime > cache_mtime:\n            cache_obj.pop(title)\n            cache_obj.set(title, (func(), mtime))\n            dump_cache()\n            return cache_obj.get(title)[0]\n\n    cache_obj.set(title, (func(), mtime))\n    dump_cache()\n    return cache_obj.get(title)[0]\n\n", "CodeBleu_score": 27.47721762542917}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    cached_data = cache.get(title)\n    if cached_data:\n        if mtime > cached_data.mtime:\n            cache.invalidate(title)\n\n    if not cached_data:\n        data = func()\n        cache[title] = data.copy()\n        data.mtime = mtime\n        dump_cache()\n        cached_data = data\n\n    return cached_data\n\n", "CodeBleu_score": 25.4136603053212}, {"code": "def cached_data_for_file(subsection, title, filename, func)\n\t\n\n    cache = cache(subsection)\n    mtime = os.path.getmtime(filename)\n    cached_data = cache.get(title)\n    if cached_data and cached_data.mtime > mtime:\n        cache.invalidate(title)\n        cached_data = None\n\n    if not cached_data:\n        cached_data = func()\n        cache[title] = cached_data\n        cache.dump()\n\n    return cached_data\n\n", "CodeBleu_score": 25.314572398024808}]}
{"instance_id": "e01a2d4f0ac2", "generation_result": [{"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n\n    record_exception()\n\n    if exc_info:\n        print(f\"*** {message}\")\n        print(\"***\")\n        print(format_exception_only(type(exception_records[-1]), exception_records[-1]))\n        print(\"---\")\n    else:\n        print(f\"*** {message}\")\n\n", "CodeBleu_score": 28.490802556678098}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n\n    if exc_info:\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file=sys.stderr)\n        print(\"***\", file", "CodeBleu_score": 26.965904439506605}, {"code": "def report(message: str, *, exc_info: bool = False) -> None\n\t\n    record_exception()\n    print(\"***\", message, file=sys.stderr)\n    if exc_info:\n        print(\"---\", file=sys.stderr)\n        print(file=sys.stderr)\n        print(\"", "CodeBleu_score": 42.9652448576672}]}
{"instance_id": "125fb9d2320b", "generation_result": [{"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if not style.prompt or not style.negative_prompt:\n        return False, \"\", \"\"\n\n    positive_prompt, negative_prompt = prompt, negative_prompt\n\n    if style.prompt:\n        positive_prompt, negative_prompt = extract_style_text_from_prompt(style.prompt, prompt), extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n\n    if not positive_prompt or not negative_prompt:\n        return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 61.4907865155964}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n\n    if style.prompt == '' and style.negative_prompt == '':\n        return False, prompt, negative_prompt\n\n    positive_prompt, negative_prompt = prompt, negative_prompt\n    if style.prompt!= '':\n        is_positive_prompt_extracted, positive_prompt = extract_style_text_from_prompt(style.prompt, prompt)\n        if not is_positive_prompt_extracted:\n            return False, prompt, negative_prompt\n\n    if style.negative_prompt!= '':\n        is_negative_prompt_extracted, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n        if not is_negative_prompt_extracted:\n            return False, prompt, negative_prompt\n\n    return True, positive_prompt, negative_prompt\n", "CodeBleu_score": 63.87426226541446}, {"code": "def extract_original_prompts(style: PromptStyle, prompt, negative_prompt)\n\t\n    if not style.prompt or not style.negative_prompt:\n        return False, \"\", \"\"\n\n    positive_prompt, negative_prompt = prompt, negative_prompt\n\n    if style.prompt:\n        positive_prompt, negative_prompt = extract_style_text_from_prompt(style.prompt, positive_prompt)\n        if not positive_prompt:\n            return False, \"\", \"\"\n\n    if style.negative_prompt:\n        positive_prompt, negative_prompt = extract_style_text_from_prompt(style.negative_prompt, negative_prompt)\n        if not negative_prompt:\n            return False, \"\", \"\"\n\n    return True, positive_prompt, negative_prompt\n\n", "CodeBleu_score": 53.494861654999085}]}
{"instance_id": "0c5f729fbce2", "generation_result": [{"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n    return a\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n    return a\n\n", "CodeBleu_score": 94.20475781398312}, {"code": "def random_partial(self, count, n_frames)\n\t\n    if self.utterances is None:\n        self._load_utterances()\n    utterances = self.utterance_cycler.sample(count)\n    a = [(u,) + u.random_partial(n_frames) for u in utterances]\n    return a\n", "CodeBleu_score": 94.20475781398312}]}
{"instance_id": "31e8b27b8f94", "generation_result": [{"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"increase_only and decrease_only cannot both be True\")\n    if increase_only:\n        change_in_dBFS = target_dBFS - wav.dBFS\n        if change_in_dBFS > 0:\n            return wav\n        else:\n            return wav.apply_gain(change_in_dBFS)\n    elif decrease_only:\n        change_in_dBFS = wav.dBFS - target_dBFS\n        if change_in_dBFS < 0:\n            return wav\n        else:\n            return wav.apply_gain(change_in_dBFS)\n    else:\n        change_in_dBFS = target_dBFS - wav.dBFS\n        if change_in_dBFS > 0:\n            return wav.apply_gain(change_in_dBFS)\n        elif change_in_dBFS < 0:\n            return wav.apply_gain(change_in_dBFS)\n        else:\n            return wav\n\n", "CodeBleu_score": 28.467331780811712}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError(\"increase_only and decrease_only cannot both be True.\")\n    if increase_only:\n        change_dBFS = target_dBFS - wav.dBFS\n    elif decrease_only:\n        change_dBFS = target_dBFS - wav.dBFS\n    else:\n        change_dBFS = target_dBFS - max(wav.dBFS, target_dBFS)\n    return wav.apply_gain(change_dBFS)\n\n", "CodeBleu_score": 37.25685151787344}, {"code": "def normalize_volume(wav, target_dBFS, increase_only=False, decrease_only=False)\n\t\n    if increase_only and decrease_only:\n        raise ValueError('increase_only and decrease_only cannot both be True.')\n    if increase_only:\n        target_dBFS = max(target_dBFS, 0)\n        change_in_dBFS = target_dBFS - wav.dBFS\n        if change_in_dBFS <= 0:\n            return wav\n        else:\n            return wav.apply_gain(change_in_dBFS)\n    if decrease_only:\n        target_dBFS = min(target_dBFS, 0)\n        change_in_dBFS = target_dBFS - wav.dBFS\n        if change_in_dBFS >= 0:\n            return wav\n        else:\n            return wav.apply_gain(change_in_dBFS)\n    if wav.dBFS > target_dBFS:\n        return normalize_volume(wav, target_dBFS, decrease_only=True)\n    elif wav.dBFS < target_dBFS:\n        return normalize_volume(wav, target_dBFS, increase_only=True)\n    else:\n        return wav\n\n", "CodeBleu_score": 34.19334076245929}]}
{"instance_id": "2353831e9033", "generation_result": [{"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n    if device is None:\n        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath, map_location=device))\n    _model.eval()\n    print(f'Loaded model {weights_fpath} to device {device}')\n\n", "CodeBleu_score": 37.718395792977724}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n    global _model\n    if device is None:\n        if torch.cuda.is_available():\n            device = torch.device('cuda')\n        else:\n            device = torch.device('cpu')\n    _model = SpeakerEncoder(device=device)\n    _model.load_state_dict(torch.load(weights_fpath, map_location=device))\n    _model.eval()\n    print(f'Loaded model from {weights_fpath}')\n    print(f'Model is on {device}')\n\n", "CodeBleu_score": 38.06542028558621}, {"code": "def load_model(weights_fpath: Path, device=None)\n\t\n\n    global _model\n    if device is None:\n        if torch.cuda.is_available():\n            device = torch.device(\"cuda\")\n        else:\n            device = torch.device(\"cpu\")\n    _model = SpeakerEncoder(device=device).to(device)\n    _model.load_state_dict(torch.load(weights_fpath))\n    _model.eval()\n    print(f\"Loaded model from {weights_fpath}\")\n\n", "CodeBleu_score": 40.122352021600776}]}
{"instance_id": "3231ad480199", "generation_result": [{"code": "def embed_frames_batch(frames_batch)\n\t\n    if _model is None:\n        raise Exception('Model is not loaded. Please run load_model() first.')\n\n    # Convert the input frames_batch to a PyTorch tensor and transfer it to the appropriate device\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n\n    # Perform a forward pass through the model to compute the embeddings\n    with torch.no_grad():\n        embeddings = _model.forward(frames_batch)\n\n    # Detach the embeddings from the computation graph and move them to the CPU\n    embeddings = embeddings.cpu().numpy()\n\n    # Return the embeddings\n    return embeddings\n", "CodeBleu_score": 59.50454037075333}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    # Check if the model is loaded\n    if _model is None:\n        raise Exception(\"Model not loaded!\")\n    # Convert the frames_batch to a PyTorch tensor and transfer it to the appropriate device\n    frames_batch = torch.from_numpy(frames_batch).to(_device)\n    # Perform a forward pass through the model to compute the embeddings\n    with torch.no_grad():\n        embeds = _model.forward(frames_batch)\n    # Detach the embeddings from the computation graph\n    embeds = embeds.cpu().numpy()\n    # Return the embeddings\n    return embeds\n\n", "CodeBleu_score": 62.76552689590431}, {"code": "def embed_frames_batch(frames_batch)\n\t\n    # Check if the model is loaded\n    if not hasattr(embed_frames_batch, \"_model\"):\n        raise Exception(\"The model is not loaded. Please load it first.\")\n\n    # Check if the frames_batch is a NumPy array\n    if not isinstance(frames_batch, np.ndarray):\n        raise TypeError(\"The input frames_batch is not a NumPy array.\")\n\n    # Check if the frames_batch is a 3D array\n    if len(frames_batch.shape)!= 3:\n        raise ValueError(\"The input frames_batch is not a 3D array.\")\n\n    # Check if the frames_batch has the correct number of channels\n    if frames_batch.shape[2]!= 1:\n        raise ValueError(\"The input frames_batch has the wrong number of channels.\")\n\n    # Check if the frames_batch has the correct number of frames\n    if frames_batch.shape[1]!= 256:\n        raise ValueError(\"The input frames_batch has the wrong number of frames.\")\n\n    # Check if the frames_batch has the correct number of samples\n    if frames_batch.shape[0]!= 1:\n        raise ValueError(\"The input frames_batch has the wrong number of samples.\")\n\n    # Convert the frames_batch from a NumPy array to a PyTorch tensor\n    frames_batch = torch.from_numpy(frames_batch).float()\n\n    # Transfer the frames_batch to the appropriate device\n    frames_batch = frames_batch.to(embed_frames_batch._device)\n\n    # Perform a forward pass through the model to compute the embeddings\n    with torch.no_grad():\n        embeddings = embed_frames_batch._model.forward(frames_batch)\n\n    # Detach the embeddings from the computation graph\n    embeddings = embeddings.detach()\n\n    # Move the embeddings to the CPU\n    embeddings = embeddings.cpu()\n\n    # Convert the embeddings back to a NumPy array\n    embeddings = embeddings.numpy()\n\n    # Return the embeddings\n    return embeddings\n", "CodeBleu_score": 41.328559698179276}]}
{"instance_id": "117a41716c8d", "generation_result": [{"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert min_pad_coverage >= 0.0 and min_pad_coverage <= 1.0, \"min_pad_coverage must be between 0 and 1\"\n    assert overlap >= 0.0 and overlap <= 1.0, \"overlap must be between 0 and 1\"\n    assert n_samples >= 1, \"n_samples must be at least 1\"\n    assert partial_utterance_n_frames >= 1, \"partial_utterance_n_frames must be at least 1\"\n    assert partial_utterance_n_frames <= n_samples, \"partial_utterance_n_frames must be less than or equal to n_samples\"\n    frame_step = int(round(sr * overlap))\n    frame_length = int(round(sr * partial_utterance_n_frames))\n    wav_slices = []\n    mel_slices = []\n    for i in range(0, n_samples - partial_utterance_n_frames + 1, frame_step):\n        wav_slice = wav[i:i + frame_length]\n        mel_slice = mel[i:i + frame_length]\n        wav_slices.append(wav_slice)\n        mel_slices.append(mel_slice)\n    last_slice = wav_slices[-1]\n    last_slice_coverage = (last_slice.shape[0] / partial_utterance_n_frames) / partial_utterance_n_frames\n    if last_slice_coverage < min_pad_coverage and len(wav_slices) > 1:\n        wav_slices = wav_slices[:-1]\n        mel_slices = mel_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 34.38642135269281}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    assert 0.0 < overlap < 1.0, 'overlap must be in (0.0, 1.0)'\n    assert 0.0 < min_pad_coverage < 1.0,'min_pad_coverage must be in (0.0, 1.0)'\n    assert 0.0 <= partial_utterance_n_frames, 'partial_utterance_n_frames must be >= 0'\n    assert 0.0 <= n_samples, 'n_samples must be >= 0'\n    assert n_samples > 0, 'n_samples must be > 0'\n    assert partial_utterance_n_frames > 0, 'partial_utterance_n_frames must be > 0'\n    assert min_pad_coverage <= 1.0,'min_pad_coverage must be <= 1.0'\n    assert 0.0 <= min_pad_coverage,'min_pad_coverage must be >= 0.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >= overlap, 'overlap must be <= 1.0'\n    assert 0.0 <= overlap, 'overlap must be >= 0.0'\n    assert 1.0 >=", "CodeBleu_score": 10.306395662988855}, {"code": "def compute_partial_slices(n_samples, partial_utterance_n_frames=partials_n_frames,\n                           min_pad_coverage=0.75, overlap=0.5)\n\t\n    # Compute the number of frames and the frame step\n    sampling_rate = 16000\n    frame_step = int(np.round(sampling_rate * overlap))\n    n_frames = int(np.ceil((n_samples - partial_utterance_n_frames) / frame_step))\n    # Compute the wav and mel slices\n    wav_slices = []\n    mel_slices = []\n    for i in range(n_frames):\n        start = i * frame_step\n        end = start + partial_utterance_n_frames\n        wav_slice = audio[start:end]\n        mel_slice = mel[start:end]\n        wav_slices.append(wav_slice)\n        mel_slices.append(mel_slice)\n    # Evaluate the need for extra padding\n    if len(wav_slices) > 1:\n        last_wav_slice = wav_slices[-1]\n        last_mel_slice = mel_slices[-1]\n        last_wav_slice_coverage = np.sum(last_wav_slice!= 0) / partial_utterance_n_frames\n        last_mel_slice_coverage = np.sum(last_mel_slice!= 0) / partial_utterance_n_frames\n        if last_wav_slice_coverage < min_pad_coverage and last_mel_slice_coverage < min_pad_coverage:\n            wav_slices = wav_slices[:-1]\n            mel_slices = mel_slices[:-1]\n    return wav_slices, mel_slices\n\n", "CodeBleu_score": 37.671242029689076}]}
{"instance_id": "34fe5c864f1c", "generation_result": [{"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = int(np.sqrt(len(embed)))\n    ax.imshow(embed.reshape(shape, shape), cmap=\"viridis\")\n    ax.set_title(title)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    plt.colorbar(ticks=np.linspace(color_range[0], color_range[1], 5))\n    return ax\n\n", "CodeBleu_score": 38.33816326537836}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = int(np.sqrt(embed.shape[0]))\n    embed = embed.reshape((shape, shape))\n    ax.imshow(embed, cmap=\"hot\")\n    ax.set_title(title)\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    plt.colorbar(shrink=0.5)\n    plt.clim(color_range[0], color_range[1])\n\n", "CodeBleu_score": 42.4012507794636}, {"code": "def plot_embedding_as_heatmap(embed, ax=None, title=\"\", shape=None, color_range=(0, 0.30))\n\t\n    if ax is None:\n        ax = plt.gca()\n    if shape is None:\n        shape = int(np.sqrt(len(embed)))\n    embed = embed.reshape(shape, shape)\n    im = ax.imshow(embed, cmap=\"viridis\")\n    ax.set_title(title)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    cbar = plt.colorbar(im, ax=ax, fraction=0.046, pad=0.04)\n    cbar.set_ticks(np.linspace(color_range[0], color_range[1], 5))\n    cbar.ax.set_yticklabels([\"{:.2f}\".format(i) for i in np.linspace(color_range[0], color_range[1], 5)])\n\n", "CodeBleu_score": 62.502138938405714}]}
{"instance_id": "92e93d50b62b", "generation_result": [{"code": "def similarity_matrix(self, embeds)\n\t\n    n_speakers, n_utterances = embeds.shape[0], embeds.shape[1]\n    centroids_incl = embeds.mean(dim=1, keepdim=True)\n    centroids_excl = embeds - centroids_incl\n    centroids_incl = centroids_incl / centroids_incl.norm(dim=-1, keepdim=True)\n    centroids_excl = centroids_excl / centroids_excl.norm(dim=-1, keepdim=True)\n    mask = torch.eye(n_utterances, device=embeds.device, dtype=torch.bool)\n    similarity_matrix = torch.zeros((n_speakers, n_speakers), device=embeds.device)\n    for i in range(n_speakers):\n        centroids_incl_i = centroids_incl[i].unsqueeze(0)\n        centroids_excl_i = centroids_excl[i].unsqueeze(0)\n        similarity_matrix[i] = (\n            centroids_incl_i.repeat(n_speakers, 1)\n           .transpose(0, 1)\n           .matmul(centroids_excl_i)\n           .squeeze()\n        )\n        similarity_matrix[i, i] = 1.0\n    similarity_matrix = similarity_matrix * mask\n    similarity_matrix = similarity_matrix.masked_fill(\n        similarity_matrix == 0.0, -1e10\n    )\n    return similarity_matrix\n\n", "CodeBleu_score": 32.133795907642984}, {"code": "def similarity_matrix(self, embeds)\n\t\n    num_speakers, num_utterances = embeds.shape[0], embeds.shape[1]\n    centroids_incl = embeds.mean(dim=1)\n    centroids_excl = embeds.mean(dim=1, keepdim=True).expand(-1, num_utterances)\n    centroids_excl = centroids_excl - embeds\n    centroids_excl = centroids_excl.mean(dim=1)\n    centroids_excl = centroids_excl / centroids_excl.norm(dim=-1, keepdim=True)\n    centroids = torch.cat([centroids_incl, centroids_excl], dim=1)\n    mask = torch.ones(num_speakers, num_speakers)\n    mask = mask.to(self.device)\n    mask = mask.tril()\n    mask = mask.to(dtype=torch.bool)\n    sim_matrix = torch.zeros(num_speakers, num_speakers)\n    sim_matrix = sim_matrix.to(self.device)\n    for i in range(num_speakers):\n        for j in range(num_speakers):\n            if i!= j:\n                sim_matrix[i, j] = torch.dot(centroids[i], centroids[j])\n    sim_matrix = sim_matrix * mask\n    sim_matrix = sim_matrix / (num_utterances - 1)\n    return sim_matrix\n\n", "CodeBleu_score": 36.80759467880792}, {"code": "def similarity_matrix(self, embeds)\n\t\n    speaker_count, utterance_count = embeds.shape[0], embeds.shape[1]\n    centroids_incl = torch.mean(embeds, dim=1)\n    centroids_excl = torch.mean(embeds[:, 1:, :], dim=1)\n    centroids_excl = centroids_excl / torch.norm(centroids_excl, dim=1, keepdim=True)\n    centroids = torch.cat([centroids_incl.unsqueeze(1), centroids_excl], dim=1)\n    mask = torch.zeros(speaker_count, speaker_count, device=embeds.device)\n    mask.fill_diagonal_(1)\n    sim_mat = torch.zeros(speaker_count, speaker_count, device=embeds.device)\n    for i in range(speaker_count):\n        sim_mat[i, i] = 1\n    for i in range(speaker_count):\n        for j in range(i + 1, speaker_count):\n            sim_mat[i, j] = torch.dot(centroids[i], centroids[j])\n            sim_mat[j, i] = sim_mat[i, j]\n    sim_mat = sim_mat * mask\n    return sim_mat\n\n", "CodeBleu_score": 25.000835039028896}]}
{"instance_id": "a6eba54108a1", "generation_result": [{"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker,\n                                    speakers_per_batch)\n    labels = np.zeros(speakers_per_batch * utterances_per_speaker, dtype=np.int)\n    for i in range(speakers_per_batch):\n        labels[i * utterances_per_speaker: (i + 1) * utterances_per_speaker] = i\n    labels = torch.from_numpy(labels).to(self.loss_device)\n    loss = self.loss_function(sim_matrix, labels)\n    eer = self.eer(sim_matrix, labels)\n    return loss, eer\n\n", "CodeBleu_score": 34.56121835701924}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker, speakers_per_batch)\n    sim_matrix = sim_matrix.to(self.loss_device)\n    labels = torch.zeros(speakers_per_batch * utterances_per_speaker, dtype=torch.long).to(self.loss_device)\n    for i in range(speakers_per_batch):\n        labels[i * utterances_per_speaker: (i + 1) * utterances_per_speaker] = i\n    loss = self.loss_function(sim_matrix, labels)\n    eer = self.eer(sim_matrix, labels)\n    return loss, eer\n", "CodeBleu_score": 32.308925805007895}, {"code": "def loss(self, embeds)\n\t\n    speakers_per_batch, utterances_per_speaker = embeds.shape[:2]\n    sim_matrix = self.similarity_matrix(embeds)\n    sim_matrix = sim_matrix.reshape(speakers_per_batch * utterances_per_speaker,\n                                    speakers_per_batch)\n    labels = np.eye(speakers_per_batch * utterances_per_speaker)\n    labels = labels.reshape(speakers_per_batch * utterances_per_speaker,\n                            speakers_per_batch)\n    loss = self.loss_function(sim_matrix, labels)\n    sim_matrix = torch.from_numpy(sim_matrix)\n    labels = torch.from_numpy(labels)\n    fpr, tpr, thresholds = roc_curve(labels.flatten(), sim_matrix.flatten())\n    eer = brentq(lambda x: 1. - x - interp1d(fpr, tpr)(x), 0., 1.)\n    return loss, eer\n\n", "CodeBleu_score": 50.56510816327469}]}
{"instance_id": "ac7b74b9d1b1", "generation_result": [{"code": "def log_params(self)\n\t\n    if not self.disable_logging:\n        # Get parameter configurations\n        param_configs = self.get_param_configs()\n\n        # Get model parameters\n        model_params = self.get_model_params()\n\n        # Get data parameters\n        data_params = self.get_data_params()\n\n        # Format parameters\n        param_string = \"\"\n        for param_config in param_configs:\n            if param_config['type'] =='model':\n                param_string += f\"{param_config['name']}: {model_params[param_config['name']]}", "CodeBleu_score": 14.60701130157295}, {"code": "def log_params(self)\n\t\n    if self.params_log:\n        params = \"\"\n        for param in self.params:\n            params += f\"{param} = {self.params[param]}", "CodeBleu_score": 3.31859170067733}, {"code": "def log_params(self)\n\t\n    if self.params_log:\n        self.params_log.clear()\n        self.params_log.append(\"Parameters:\")\n        self.params_log.append(\"Model:\")\n        for name, value in self.model_params.items():\n            self.params_log.append(f\"{name}: {value}\")\n        self.params_log.append(\"Data:\")\n        for name, value in self.data_params.items():\n            self.params_log.append(f\"{name}: {value}\")\n\n", "CodeBleu_score": 15.903393194012155}]}
{"instance_id": "4726b7864386", "generation_result": [{"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if self.speaker_embeddings is None:\n        self.speaker_embeddings = self.model.get_speaker_embeddings()\n    if self.speaker_embeddings is None:\n        return\n    if self.speaker_embeddings.shape[0] > max_speakers:\n        self.speaker_embeddings = self.speaker_embeddings[:max_speakers]\n    self.speaker_embeddings = self.speaker_embeddings.reshape(\n        self.speaker_embeddings.shape[0], -1)\n    self.speaker_embeddings = self.speaker_embeddings.astype('float32')\n    umap_model = UMAP(n_neighbors=15,\n                      min_dist=0.0,\n                      metric='cosine')\n    umap_embeddings = umap_model.fit_transform(self.speaker_embeddings)\n    umap_embeddings = umap_embeddings.astype('float32')\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[0] > 10:\n        umap_embeddings = umap_embeddings[:10]\n    if self.speaker_embeddings.shape[", "CodeBleu_score": 26.422814632256163}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n    flattened_embeds = [embed for speaker_embeds in embeds for embed in speaker_embeds]\n    flattened_utterances_per_speaker = [utterances for speaker_utterances in utterances_per_speaker for utterances in speaker_utterances]\n    flattened_speakers = [speaker for speaker_utterances in utterances_per_speaker for speaker in speaker_utterances]\n    flattened_speakers = [speaker.split('/')[-1] for speaker in flattened_speakers]\n    flattened_speakers = [speaker[:10] for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace(' ', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('-', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('.', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('\\'', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace(':', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace(';', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace(',', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('?', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('!', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('(', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace(')', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('\"', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('/', '_') for speaker in flattened_speakers]\n    flattened_speakers = [speaker.replace('\\\\', '_') for speaker in flattened_speakers", "CodeBleu_score": 23.713170411802597}, {"code": "def draw_projections(self, embeds, utterances_per_speaker, step, out_fpath=None, max_speakers=10)\n\t\n    # Limit the number of speakers to plot\n    if len(embeds) > max_speakers:\n        embeds = embeds[:max_speakers]\n        utterances_per_speaker = utterances_per_speaker[:max_speakers]\n    # Flatten the embeddings\n    embeds = np.array(embeds).flatten()\n    # Assign colors based on speaker identity\n    colors = [self.speaker_colors[speaker] for speaker in self.speaker_ids]\n    # Reduce the dimensionality of the embeddings using UMAP\n    reducer = umap.UMAP(n_components=2, random_state=self.seed)\n    embeds = reducer.fit_transform(embeds)\n    # Plot the embeddings\n    plt.figure(figsize=(10, 10))\n    plt.scatter(embeds[:, 0], embeds[:, 1], c=colors)\n    plt.title(f\"Speaker embeddings at step {step}\")\n    plt.show()\n    # Save the plot to a file if specified\n    if out_fpath is not None:\n        plt.savefig(out_fpath)\n\n", "CodeBleu_score": 42.30921410944619}]}
{"instance_id": "274fa50985c0", "generation_result": [{"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    x_shape = x.get_shape().as_list()\n    speaker_embedding_shape = speaker_embedding.get_shape().as_list()\n    x_rank = len(x_shape)\n    speaker_embedding_rank = len(speaker_embedding_shape)\n    if speaker_embedding_rank == 1:\n        speaker_embedding = tf.tile(speaker_embedding, [x_shape[0]])\n        speaker_embedding = tf.reshape(speaker_embedding, [x_shape[0], speaker_embedding_shape[0], speaker_embedding_shape[1]])\n        speaker_embedding = tf.transpose(speaker_embedding, [1, 0, 2])\n        x = tf.concat([x, speaker_embedding], 2)\n    else:\n        x_dim = 1\n        for i in range(x_rank - 1):\n            x_dim *= x_shape[i]\n        x = tf.reshape(x, [x_dim, x_shape[-1]])\n        x_dim = 1\n        for i in range(speaker_embedding_rank - 1):\n            x_dim *= speaker_embedding_shape[i]\n        speaker_embedding = tf.reshape(speaker_embedding, [x_dim, speaker_embedding_shape[-1]])\n        x = tf.concat([x, speaker_embedding], 0)\n        x = tf.reshape(x, [x_shape[0], x_shape[1], x_shape[2] + speaker_embedding_shape[1]])\n    return x\n\n", "CodeBleu_score": 28.956071793276845}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    speaker_embedding_shape = speaker_embedding.shape\n    speaker_embedding_dim = speaker_embedding_shape[0]\n    x_shape = x.shape\n    x_dim = x_shape[0]\n    speaker_embedding_index = x_shape[1]\n    x = tf.reshape(x, [x_dim, -1])\n    x = tf.transpose(x, [1, 0])\n    x = tf.reshape(x, [1, -1, x_dim])\n    x = tf.tile(speaker_embedding, [x_dim, 1, 1])\n    x = tf.transpose(x, [1, 0, 2])\n    x = tf.reshape(x, [speaker_embedding_dim, -1])\n    x = tf.transpose(x, [1, 0])\n    x = tf.reshape(x, [speaker_embedding_shape[1], -1])\n    x = tf.concat([x, x], axis=0)\n    x = tf.reshape(x, [speaker_embedding_dim, -1])\n    x = tf.transpose(x, [1, 0])\n    return x\n\n", "CodeBleu_score": 14.376177258890186}, {"code": "def add_speaker_embedding(self, x, speaker_embedding)\n\t\n    self.x_dims = x.get_shape().as_list()\n    self.speaker_embedding_dim = speaker_embedding.get_shape().as_list()[1]\n    self.speaker_embedding_index = len(self.x_dims) - 1\n    self.speaker_embedding_shape = [self.x_dims[self.speaker_embedding_index], self.speaker_embedding_dim]\n    self.speaker_embedding_repeated = tf.tile(speaker_embedding, [self.x_dims[self.speaker_embedding_index]])\n    self.speaker_embedding_repeated_reshaped = tf.reshape(self.speaker_embedding_repeated, self.speaker_embedding_shape)\n    self.speaker_embedding_repeated_transposed = tf.transpose(self.speaker_embedding_repeated_reshaped, [1, 0])\n    self.x_with_speaker_embedding = tf.concat([self.speaker_embedding_repeated_transposed, x], self.speaker_embedding_index)\n    return self.x_with_speaker_embedding\n\n", "CodeBleu_score": 25.433796884466254}]}
{"instance_id": "e6742ea0fe5e", "generation_result": [{"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = next(self.parameters()).device\n    seq_len = encoder_seq_proj.shape[1]\n    self.cum_attn = torch.zeros(seq_len, seq_len, device=device)\n    self.attn = torch.zeros(seq_len, seq_len, device=device)\n\n", "CodeBleu_score": 22.613296143864808}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    device = encoder_seq_proj.device\n    batch_size = encoder_seq_proj.shape[0]\n    seq_len = encoder_seq_proj.shape[1]\n    self.cumulative_attention = torch.zeros(batch_size, seq_len).to(device)\n    self.attention_weights = torch.zeros(batch_size, seq_len).to(device)\n\n", "CodeBleu_score": 19.1088319465232}, {"code": "def init_attention(self, encoder_seq_proj)\n\t\n    self.device = next(self.parameters()).device\n    self.cum_attn = torch.zeros(1, self.batch_size, self.max_len, device=self.device)\n    self.attn = torch.zeros(1, self.batch_size, self.max_len, device=self.device)\n    self.attn_mask = torch.ones(self.max_len, self.max_len, device=self.device)\n    self.attn_mask = self.attn_mask.tril()\n\n", "CodeBleu_score": 28.989093357917227}]}
{"instance_id": "4e1fc1ed0ed7", "generation_result": [{"code": "def load(self, path, optimizer=None)\n\t\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}, {"code": "def load(self, path, optimizer=None)\n\t\n    # Use device of model params as location for loaded state\n    device = next(self.parameters()).device\n    checkpoint = torch.load(str(path), map_location=device)\n    self.load_state_dict(checkpoint[\"model_state\"])\n\n    if \"optimizer_state\" in checkpoint and optimizer is not None:\n        optimizer.load_state_dict(checkpoint[\"optimizer_state\"])\n\n", "CodeBleu_score": 67.98839425729693}]}
{"instance_id": "178e6aa16c0f", "generation_result": [{"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}, {"code": "def save(self, path, optimizer=None)\n\t\n    if optimizer is not None:\n        torch.save({\n            \"model_state\": self.state_dict(),\n            \"optimizer_state\": optimizer.state_dict(),\n        }, str(path))\n    else:\n        torch.save({\n            \"model_state\": self.state_dict(),\n        }, str(path))", "CodeBleu_score": 93.4714524643972}]}
{"instance_id": "6528fd80e87b", "generation_result": [{"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}, {"code": "def english_cleaners(text)\n\t\n    text = convert_to_ascii(text)\n    text = lowercase(text)\n    text = expand_numbers(text)\n    text = expand_abbreviations(text)\n    text = collapse_whitespace(text)\n    return text\n\n", "CodeBleu_score": 55.88611500274403}]}
{"instance_id": "8a4fe08e0985", "generation_result": [{"code": "def text_to_sequence(text, cleaner_names)\n\t\n    text = _clean_text(text, cleaner_names)\n    phones = _arpabet_to_sequence(text)\n    return phones + [_symbol_to_id[\" \"]]\n\n", "CodeBleu_score": 6.048908033293006}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    sequence = []\n    curly_count = 0\n    for segment in text.split():\n        if segment.startswith(\"{\"):\n            curly_count += 1\n            sequence.extend(_arpabet_to_sequence(segment[1:]))\n        else:\n            sequence.extend(_symbols_to_sequence(segment))\n            if curly_count > 0:\n                sequence.append(_symbol_to_id[\"}\"] + curly_count)\n                curly_count = 0\n    sequence.append(_symbol_to_id[\" \"])\n    sequence.extend(_symbols_to_sequence(clean_text(text, cleaner_names)))\n    sequence.append(_symbol_to_id[\" \"])\n    return sequence\n\n", "CodeBleu_score": 29.60165879047202}, {"code": "def text_to_sequence(text, cleaner_names)\n\t\n    text = _clean_text(text, cleaner_names)\n    arpabet = _arpabet_to_sequence(text)\n    sequence = arpabet + [_symbol_to_id[\" \"]]\n    return sequence\n\n", "CodeBleu_score": 8.337745015501742}]}
{"instance_id": "e1c25a37af1f", "generation_result": [{"code": "def sequence_to_text(sequence)\n\t\n    # Create a dictionary of symbols\n    symbols = {\n        '0':'',\n        '1': \"'\",\n        '2': 'E',\n        '3': 'F',\n        '4': 'M',\n        '5': 'P',\n        '6': 'S',\n        '7': 'V',\n        '8': 'W',\n        '9': 'X',\n        '10': 'Y',\n        '11': 'Z',\n        '12': 'e',\n        '13': 'f',\n        '14':'m',\n        '15': 'p',\n        '16':'s',\n        '17': 'v',\n        '18': 'w',\n        '19': 'x',\n        '20': 'y',\n        '21': 'z',\n        '22': 'A',\n        '23': 'B',\n        '24': 'D',\n        '25': 'G',\n        '26': 'K',\n        '27': 'L',\n        '28': 'N',\n        '29': 'R',\n        '30': 'a',\n        '31': 'b',\n        '32': 'd',\n        '33': 'g',\n        '34': 'k',\n        '35': 'l',\n        '36': 'n',\n        '37': 'r',\n        '38': 'H',\n        '39': 'I',\n        '40': 'J',\n        '41': 'O',\n        '42': 'U',\n        '43': 'h',\n        '44': 'i',\n        '45': 'j',\n        '46': 'o',\n        '47': 'u',\n        '48': 'c',\n        '49': 'x',\n        '50': '1',\n        '51': '2',\n        '52': '3',\n        '53': '4',\n        '54': '6',\n        '55': '8',\n        '56': '9',\n        '57': '0',\n        '58': '5',\n        '59': '7',\n        '60': '!',\n        '61': '?',\n        '62': ':',\n        '63': ',',\n        '64': '.',", "CodeBleu_score": 5.788366517151582}, {"code": "def sequence_to_text(sequence)\n\t\n    result = \"\"\n    for symbol in sequence:\n        if symbol in arpabet_dict:\n            result += \"{\" + arpabet_dict[symbol] + \"}\"\n        else:\n            result += \"{\" + str(symbol) + \"}\"\n    return result\n\n", "CodeBleu_score": 26.50757907577822}, {"code": "def sequence_to_text(sequence)\n\t\n    result = ''\n    for symbol_id in sequence:\n        symbol = arpabet_dict[symbol_id]\n        if symbol == '{':\n            result +=''\n        result += symbol\n    return result\n\n", "CodeBleu_score": 25.510783963838847}]}
{"instance_id": "7807cad4b05d", "generation_result": [{"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}, {"code": "def embed_utterance(fpaths, encoder_model_fpath)\n\t\n    if not encoder.is_loaded():\n        encoder.load_model(encoder_model_fpath)\n\n    # Compute the speaker embedding of the utterance\n    wav_fpath, embed_fpath = fpaths\n    wav = np.load(wav_fpath)\n    wav = encoder.preprocess_wav(wav)\n    embed = encoder.embed_utterance(wav)\n    np.save(embed_fpath, embed, allow_pickle=False)\n\n", "CodeBleu_score": 95.3261531719067}]}
{"instance_id": "9f860273a325", "generation_result": [{"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    if not synthesizer_root.exists():\n        raise FileNotFoundError(f\"Synthesizer root directory {synthesizer_root} does not exist.\")\n    if not encoder_model_fpath.exists():\n        raise FileNotFoundError(f\"Encoder model file {encoder_model_fpath} does not exist.\")\n    if not synthesizer_root.joinpath(\"metadata.csv\").exists():\n        raise FileNotFoundError(\"Metadata file does not exist.\")\n    if not synthesizer_root.joinpath(\"embeddings\").exists():\n        synthesizer_root.joinpath(\"embeddings\").mkdir(parents=True)\n    metadata_df = pd.read_csv(synthesizer_root.joinpath(\"metadata.csv\"))\n    audio_files = list(metadata_df[\"audio_file\"])\n    embedding_files = list(metadata_df[\"embedding_file\"])\n    audio_paths = [synthesizer_root.joinpath(audio_file) for audio_file in audio_files]\n    embedding_paths = [synthesizer_root.joinpath(\"embeddings\", embedding_file) for embedding_file in embedding_files]\n    if len(audio_files)!= len(embedding_files):\n        raise ValueError(\"Audio and embedding file lists are not of the same length.\")\n    if len(audio_files) == 0:\n        raise ValueError(\"No audio files found.\")\n    if len(audio_files)!= len(audio_paths):\n        raise ValueError(\"Audio file list is not of the same length as audio file paths.\")\n    if len(embedding_files)!= len(embedding_paths):\n        raise ValueError(\"Embedding file list is not of the same length as embedding file paths.\")\n    with mp.Pool(processes=n_processes) as pool:\n        for audio_path, embedding_path in zip(audio_paths, embedding_paths):\n            pool.apply_async(create_embedding, args=(synthesizer_root, encoder_model_fpath, audio_path, embedding_path))\n        pool.close()\n        pool.join()\n\n", "CodeBleu_score": 32.385530636453964}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n\n    # check if the synthesizer root directory exists\n    if not synthesizer_root.exists():\n        raise FileNotFoundError(f\"Synthesizer root directory {synthesizer_root} does not exist.\")\n\n    # check if the encoder model file exists\n    if not encoder_model_fpath.exists():\n        raise FileNotFoundError(f\"Encoder model file {encoder_model_fpath} does not exist.\")\n\n    # check if the embeddings directory exists\n    embeddings_dir = synthesizer_root / \"embeddings\"\n    if not embeddings_dir.exists():\n        raise FileNotFoundError(f\"Embeddings directory {embeddings_dir} does not exist.\")\n\n    # check if the metadata file exists\n    metadata_fpath = synthesizer_root / \"metadata.csv\"\n    if not metadata_fpath.exists():\n        raise FileNotFoundError(f\"Metadata file {metadata_fpath} does not exist.\")\n\n    # read metadata\n    metadata = pd.read_csv(metadata_fpath)\n\n    # get file paths for audio files and embeddings\n    audio_files = [synthesizer_root / \"audio\" / f\"{row['id']}.wav\" for _, row in metadata.iterrows()]\n    embeddings_files = [embeddings_dir / f\"{row['id']}.npy\" for _, row in metadata.iterrows()]\n\n    # create a multiprocessing pool\n    pool = multiprocessing.Pool(n_processes)\n\n    # create embeddings\n    for audio_file, embeddings_file in zip(audio_files, embeddings_files):\n        if not embeddings_file.exists():\n            pool.apply_async(create_embedding, args=(encoder_model_fpath, audio_file, embeddings_file))\n\n    # close the pool\n    pool.close()\n\n    # wait for all processes to finish\n    pool.join()\n\n    # print success message\n    print(f\"Embeddings successfully created for {len(audio_files)} audio files.\")\n\n", "CodeBleu_score": 28.545290076455075}, {"code": "def create_embeddings(synthesizer_root: Path, encoder_model_fpath: Path, n_processes: int)\n\t\n    synthesizer_root = synthesizer_root.resolve()\n    encoder_model_fpath = encoder_model_fpath.resolve()\n    encoder_model_fpath.parent.mkdir(parents=True, exist_ok=True)\n    encoder_model_fpath.parent.parent.mkdir(parents=True, exist_ok=True)\n\n    # Create the embeddings directory if it does not exist\n    embeddings_dir = synthesizer_root / \"embeddings\"\n    embeddings_dir.mkdir(parents=True, exist_ok=True)\n\n    # Create the metadata file if it does not exist\n    metadata_fpath = synthesizer_root / \"metadata.json\"\n    if not metadata_fpath.exists():\n        with open(metadata_fpath, \"w\") as f:\n            json.dump({}, f)\n\n    # Read the metadata file\n    with open(metadata_fpath, \"r\") as f:\n        metadata = json.load(f)\n\n    # Create a list of audio file paths\n    audio_files = []\n    for audio_file in synthesizer_root.glob(\"**/*.wav\"):\n        if audio_file.name not in metadata:\n            audio_files.append(audio_file)\n\n    # Create a list of embedding file paths\n    embedding_files = []\n    for embedding_file in embeddings_dir.glob(\"*.npy\"):\n        embedding_files.append(embedding_file)\n\n    # Create a list of audio file paths to skip\n    skip_files = []\n    for skip_file in synthesizer_root.glob(\"**/*.wav\"):\n        if skip_file.name in metadata:\n            skip_files.append(skip_file)\n\n    # Create a list of embedding file paths to skip\n    skip_embeddings = []\n    for skip_embedding in embeddings_dir.glob(\"*.npy\"):\n        skip_embeddings.append(skip_embedding)\n\n    # Create a list of file paths to skip\n    skip_paths = []\n    skip_paths.extend(skip_files)\n    skip_paths.extend(skip_embeddings)\n\n    # Create a list of file paths to process\n    process_paths = []\n    for process_path in audio_files:\n        if process_path not in skip_paths:\n            process_paths.append(process_path)\n\n    # Create a multiprocessing pool\n    pool = mp.Pool(n_processes)\n\n    # Create a", "CodeBleu_score": 30.086910411503926}]}
{"instance_id": "9eb0abda14a9", "generation_result": [{"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    attention_plot_path = os.path.join(plot_dir, f\"attention_plot_{sample_num}_{step}.png\")\n    mel_prediction_plot_path = os.path.join(mel_output_dir, f\"mel_prediction_{sample_num}_{step}.png\")\n    wav_path = os.path.join(wav_dir, f\"wav_{sample_num}_{step}.wav\")\n\n    # Save attention plot\n    save_attention(attention, attention_plot_path)\n\n    # Save mel prediction plot\n    plot_spectrogram(mel_prediction, mel_prediction_plot_path,\n                     f\"{hparams.model_type} Mel-Spectrogram Prediction at step {step} and sample {sample_num}\",\n                     auto_aspect=True)\n\n    # Save wav\n    mel_to_wav(mel_prediction, wav_path, hparams)\n\n    # Plot mel prediction vs target\n    plot_spectrogram(mel_prediction, mel_prediction_plot_path,\n                     f\"{hparams.model_type} Mel-Spectrogram Prediction vs Target at step {step} and sample {sample_num}\",\n                     target_spectrogram=target_spectrogram, auto_aspect=True)\n\n    # Print input sequence\n    print(f\"Input sequence:", "CodeBleu_score": 31.72037706843821}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save the attention plot\n    save_attention(attention, os.path.join(plot_dir, f\"attention_{sample_num}\"))\n\n    # Save the mel spectrogram\n    np.save(os.path.join(mel_output_dir, f\"mel_output_{sample_num}.npy\"), mel_prediction)\n\n    # Save the reconstructed waveform\n    wav = hparams.sample_rate * torch.istft(\n        mel_prediction,\n        hparams.hop_size,\n        hparams.win_size,\n        hparams.n_fft,\n        hparams.num_mels,\n        hparams.fmin,\n        hparams.fmax,\n        hparams.mel_fmin,\n        hparams.mel_fmax,\n        hparams.mel_n_mels,\n        hparams.mel_n_freqs,\n        hparams.mel_n_frames,\n        hparams.n_mels,\n        hparams.n_freqs,\n        hparams.n_frames,\n        hparams.power,\n        hparams.normalize,\n        hparams.pad,\n        hparams.center,\n        hparams.window,\n        hparams.pad_mode,\n        hparams.norm,\n        hparams.w_min_value,\n        hparams.w_min_freq,\n        hparams.w_min_n_mels,\n        hparams.w_min_n_freqs,\n        hparams.w_min_n_frames,\n        hparams.w_min_power,\n        hparams.w_min_normalize,\n        hparams.w_min_pad,\n        hparams.w_min_center,\n        hparams.w_min_window,\n        hparams.w_min_pad_mode,\n        hparams.w_min_norm,\n        hparams.w_min_pad_value,\n        hparams.w_min_pad_freq,\n        hparams.w_min_pad_n_mels,\n        hparams.w_min_pad_n_freqs,\n        hparams.w_min_pad_n_frames,\n        hparams.w_min_pad_power,\n        hparams.w_min_pad_normalize,\n        hparams.w_min_pad_pad,\n        hparams.w_min_pad_center", "CodeBleu_score": 13.08422876793458}, {"code": "def eval_model(attention, mel_prediction, target_spectrogram, input_seq, step,\n               plot_dir, mel_output_dir, wav_dir, sample_num, loss, hparams)\n\t\n    # Save attention plot\n    save_attention(attention, os.path.join(plot_dir, f\"attention_{step}_{sample_num}\"))\n\n    # Save mel spectrogram\n    plot_spectrogram(mel_prediction, os.path.join(mel_output_dir, f\"mel_output_{step}_{sample_num}\"),\n                     title=f\"Mel-Spectrogram Prediction at Step {step}\",\n                     target_spectrogram=target_spectrogram,\n                     max_len=hparams.max_mel_len,\n                     auto_aspect=True)\n\n    # Save wav\n    wav = spectrogram_to_wav(mel_prediction)\n    save_wav(wav, os.path.join(wav_dir, f\"wav_{step}_{sample_num}\"))\n\n    # Plot target and prediction mel spectrograms\n    plot_spectrogram(mel_prediction, os.path.join(plot_dir, f\"mel_output_{step}_{sample_num}\"),\n                     title=f\"Mel-Spectrogram Prediction at Step {step}\",\n                     target_spectrogram=target_spectrogram,\n                     max_len=hparams.max_mel_len,\n                     auto_aspect=True)\n\n    # Print input sequence\n    print(f\"Input: {sequence_to_text(input_seq)}\")\n    print(f\"Loss: {loss}\")\n", "CodeBleu_score": 29.13438191269904}]}
{"instance_id": "6bad4f500286", "generation_result": [{"code": "def num_params(self)\n\t\n    trainable_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f'{trainable_params/1e6:.3f}M parameters')\n\n", "CodeBleu_score": 13.156814429299658}, {"code": "def num_params(self)\n\t\n    total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f'{total_params/1000000:.3f}M')\n\n", "CodeBleu_score": 11.054232103273561}, {"code": "def num_params(self)\n\t\n    total_params = sum(p.numel() for p in self.parameters() if p.requires_grad)\n    print(f'The model has {total_params:,} trainable parameters')\n    return total_params\n\n", "CodeBleu_score": 15.900593591979073}]}
{"instance_id": "78b876054bd4", "generation_result": [{"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'before':\n        x = torch.cat((torch.zeros(x.shape[0], pad[0], x.shape[2], x.shape[3]), x), dim=1)\n    elif side == 'after':\n        x = torch.cat((x, torch.zeros(x.shape[0], pad[1], x.shape[2], x.shape[3])), dim=1)\n    elif side == 'both':\n        x = torch.cat((torch.zeros(x.shape[0], pad[0], x.shape[2], x.shape[3]), x, torch.zeros(x.shape[0], pad[1], x.shape[2], x.shape[3])), dim=1)\n    else:\n        raise ValueError(\"The specified side is not valid. Please choose between 'before', 'after', or 'both'.\")\n    return x\n\n", "CodeBleu_score": 30.825103836370538}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'before':\n        new_size = x.shape[0] + pad[0]\n        x_padded = torch.zeros(new_size, *x.shape[1:], device=x.device)\n        x_padded[pad[0]:,...] = x\n    elif side == 'after':\n        new_size = x.shape[0] + pad[1]\n        x_padded = torch.zeros(new_size, *x.shape[1:], device=x.device)\n        x_padded[:x.shape[0],...] = x\n    else:\n        new_size = x.shape[0] + pad[0] + pad[1]\n        x_padded = torch.zeros(new_size, *x.shape[1:], device=x.device)\n        x_padded[pad[0]:x.shape[0] + pad[0],...] = x\n    return x_padded\n\n", "CodeBleu_score": 31.438620533874882}, {"code": "def pad_tensor(self, x, pad, side='both')\n\t\n    if side == 'before':\n        pad_left = pad\n        pad_right = 0\n    elif side == 'after':\n        pad_left = 0\n        pad_right = pad\n    elif side == 'both':\n        pad_left = pad\n        pad_right = pad\n    else:\n        raise ValueError('Invalid side:'+ side)\n    new_size = x.shape[0] + pad_left + pad_right\n    if self.is_cuda:\n        padded_tensor = torch.zeros(new_size, *x.shape[1:]).cuda()\n    else:\n        padded_tensor = torch.zeros(new_size, *x.shape[1:])\n    padded_tensor[pad_left:pad_left + x.shape[0],...] = x\n    return padded_tensor\n\n", "CodeBleu_score": 28.758206286829928}]}
{"instance_id": "a7ed1715a3df", "generation_result": [{"code": "def save_attention(attn, path)\n\t    fig = plt.figure()\n    plt.imshow(attn)\n    plt.axis('off')\n    fig.savefig(path)\n    plt.close()\n\n", "CodeBleu_score": 23.00242526086695}, {"code": "def save_attention(attn, path)\n\t    fig = plt.figure(figsize=(10, 10))\n    plt.imshow(attn)\n    plt.axis('off')\n    plt.savefig(path)\n    plt.close(fig)\n\n", "CodeBleu_score": 34.381519360825685}, {"code": "def save_attention(attn, path)\n\t    fig, ax = plt.subplots()\n    ax.imshow(attn, cmap='gray', interpolation='nearest')\n    ax.axis('off')\n    fig.savefig(path, dpi=fig.dpi)\n    plt.close(fig)\n\n", "CodeBleu_score": 34.58668997353565}]}
{"instance_id": "19375c9f44a2", "generation_result": [{"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}, {"code": "def plot(array)\n\t\n    import matplotlib.pyplot as plt\n\n    fig = plt.figure(figsize=(30, 5))\n    ax = fig.add_subplot(111)\n    ax.xaxis.label.set_color('grey')\n    ax.yaxis.label.set_color('grey')\n    ax.xaxis.label.set_fontsize(23)\n    ax.yaxis.label.set_fontsize(23)\n    ax.tick_params(axis='x', colors='grey', labelsize=23)\n    ax.tick_params(axis='y', colors='grey', labelsize=23)\n    plt.plot(array)\n\n", "CodeBleu_score": 77.73415655580472}]}
{"instance_id": "ff94c425920c", "generation_result": [{"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    if not os.path.exists(CSV_FILE):\n        with open(CSV_FILE, 'w', newline='') as csv_file:\n            fieldnames = ['image_name', 'prediction', 'confidence']\n            writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n            writer.writeheader()\n    with open(CSV_FILE, 'a', newline='') as csv_file:\n        fieldnames = ['image_name', 'prediction', 'confidence']\n        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n        writer.writerow({'image_name': image_name, 'prediction': prediction, 'confidence': confidence})\n\n", "CodeBleu_score": 43.425161534718356}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    if os.path.exists(csv_file_path):\n        with open(csv_file_path, 'a') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerow([image_name, prediction, confidence])\n    else:\n        with open(csv_file_path, 'w') as csvfile:\n            writer = csv.writer(csvfile)\n            writer.writerow(['image_name', 'prediction', 'confidence'])\n            writer.writerow([image_name, prediction, confidence])\n\n", "CodeBleu_score": 30.198500291819645}, {"code": "def write_to_csv(image_name, prediction, confidence)\n\t\n    data = {\n        'image_name': image_name,\n        'prediction': prediction,\n        'confidence': confidence\n    }\n    with open('predictions.csv', 'a', newline='') as csvfile:\n        fieldnames = ['image_name', 'prediction', 'confidence']\n        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n        if not os.path.isfile('predictions.csv'):\n            writer.writeheader()\n        writer.writerow(data)\n\n", "CodeBleu_score": 45.79420679038222}]}
{"instance_id": "436161602009", "generation_result": [{"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    if not isinstance(model, torch.jit.ScriptModule):\n        raise TypeError(f\"{prefix} model must be of type torch.jit.ScriptModule, got {type(model)}\")\n    if not isinstance(im, torch.Tensor):\n        raise TypeError(f\"{prefix} image must be of type torch.Tensor, got {type(im)}\")\n    if not im.is_cuda:\n        raise ValueError(f\"{prefix} image must be on the GPU, got {im.device}\")\n    if im.shape[0]!= 3:\n        raise ValueError(f\"{prefix} image must have 3 channels, got {im.shape[0]}\")\n    if im.shape[1:]!= model.input_size:\n        raise ValueError(f\"{prefix} model input size {model.input_size} does not match image size {im.shape[1:]}\")\n    if optimize:\n        LOGGER.info(f\"{prefix} optimizing model...\")\n        model = torch.jit.optimize_for_mobile(model)\n    else:\n        LOGGER.info(f\"{prefix} saving model...\")\n    torch.jit.save(model, file)\n    LOGGER.info(f\"{prefix} saved model to {file}\")\n    return file, None\n\n", "CodeBleu_score": 29.285442905617952}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    if optimize:\n        model = torch.jit.script(model)\n        torch.jit.save(model, f\"{file}.pt\")\n        torch.jit.save_for_mobile(model, f\"{file}.ptm\")\n        print(f\"{prefix} Optimized model saved: {file}.pt\")\n        print(f\"{prefix} Mobile optimized model saved: {file}.ptm\")\n    else:\n        torch.jit.save(model, f\"{file}.pt\")\n        print(f\"{prefix} Model saved: {file}.pt\")\n    return f\"{file}.pt\", None\n\n", "CodeBleu_score": 25.65618013682268}, {"code": "def export_torchscript(model, im, file, optimize, prefix=colorstr(\"TorchScript:\"))\n\t\n    model_info(self, verbose, img_size)\n\n    if not torch.jit.is_scripting_available():\n        raise ValueError(\"TorchScript not available\")\n    if not torch.jit.is_tracing_available():\n        raise ValueError(\"Tracing not available\")\n    if not torch.jit.is_debug_build():\n        raise ValueError(\"TorchScript debug build not available\")\n    if not torch.jit.is_in_trace_mode():\n        raise ValueError(\"Tracing not enabled\")\n\n    if not isinstance(model, torch.jit.ScriptModule):\n        model = torch.jit.trace(model, im)\n\n    if optimize:\n        model = torch.jit.optimize_for_mobile(model)\n\n    torch.jit.save(model, file)\n    return file, None\n\n", "CodeBleu_score": 28.66811662901497}]}
{"instance_id": "78335487ac1c", "generation_result": [{"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    LOGGER.info:  info(self, verbose=False, img_size=640):\n        \"\"\"Prints model information given verbosity and image size, e.g., `info(verbose=True, img_size=640)`.\"\"\"\n        model_info(self, verbose, img_size)\n\n \n\n", "CodeBleu_score": 9.443580292930054}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    if not coremltools:\n        raise ValueError(\"coremltools is not installed. Please install it with `pip install coremltools`\")\n    LOGGER.info(f\"{prefix} Exporting to CoreML\")\n    if nms:\n        model = iOSModel(model)\n    if int8:\n        model = torch.quantize_per_tensor(model, torch.quint8, 0, 255)\n    if half:\n        model = torch.quantize_per_tensor(model, torch.qint8, 0, 127)\n    torch.onnx.export(model, im, file, verbose=False, input_names=[\"image\"], output_names=[\"output\"])\n    coreml_model = coremltools.converters.onnx.convert(file, minimum_ios_deployment_target=\"13\")\n    file = file[:-5] + \".mlmodel\"\n    coreml_model.save(file)\n    return file, coreml_model\n\n", "CodeBleu_score": 31.031175311467173}, {"code": "def export_coreml(model, im, file, int8, half, nms, prefix=colorstr(\"CoreML:\")):\n\t    \"\"\"The function exports a PyTorch model to CoreML format.", "CodeBleu_score": 5.954874678899716}]}
{"instance_id": "80233cf71580", "generation_result": [{"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}, {"code": "def generate_individual(input_ranges, individual_length)\n\t\n    individual = []\n    for i in range(individual_length):\n        individual.append(random.uniform(input_ranges[i][0], input_ranges[i][1]))\n    return individual\n\n", "CodeBleu_score": 47.630972577458174}]}
{"instance_id": "5ea979cb4a8e", "generation_result": [{"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule == 'discrete':\n        return torch.log(self.alpha_t)\n    elif self.schedule == 'linear':\n        return self.alpha_t * t + self.alpha_0 - self.alpha_0 * t\n    elif self.schedule == 'cosine':\n        return self.alpha_t * 0.5 * (1.0 + torch.cos(t * math.pi)) + self.alpha_0 - 0.5 * self.alpha_t\n    else:\n        raise ValueError('Unknown schedule type:'+ self.schedule)\n\n", "CodeBleu_score": 37.079474886089784}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return self.log_alpha_discrete(t)\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_linear(t)\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_cosine(t)\n    else:\n        raise NotImplementedError('Unsupported schedule type:'+ self.schedule_type)\n\n", "CodeBleu_score": 25.1808501455003}, {"code": "def marginal_log_mean_coeff(self, t)\n\t\n    if self.schedule_type == 'discrete':\n        return self.log_alpha_t[t]\n    elif self.schedule_type == 'linear':\n        return self.log_alpha_t[t] + (self.log_alpha_t[t + 1] - self.log_alpha_t[t]) * t / (self.T - 1)\n    elif self.schedule_type == 'cosine':\n        return self.log_alpha_t[t] + (self.log_alpha_t[t + 1] - self.log_alpha_t[t]) * (1 + math.cos(math.pi * t / (self.T - 1))) / 2\n    else:\n        raise ValueError(f\"Unknown schedule type: {self.schedule_type}\")\n\n", "CodeBleu_score": 33.98517906236029}]}
{"instance_id": "7da4fae5a278", "generation_result": [{"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        T = self.T\n        beta = self.beta\n        t = beta * torch.log(lamb) / torch.log(10)\n        return torch.where(torch.eq(t, 0), torch.tensor(1e-05, device=t.device), t)\n    elif self.schedule == 'discrete':\n        log_alpha = self.log_alpha\n        t = torch.log(lamb) / torch.log(10)\n        return torch.where(torch.eq(t, 0), torch.tensor(1e-05, device=t.device), torch.acos(log_alpha) * t / T)\n    else:\n        log_alpha = self.log_alpha\n        t = torch.log(lamb) / torch.log(10)\n        return torch.where(torch.eq(t, 0), torch.tensor(1e-05, device=t.device), torch.acos(log_alpha) * t / T)\n\n", "CodeBleu_score": 28.993963093609683}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        beta = self.beta\n        t = (1 - beta) * lamb + beta\n    elif self.schedule == 'discrete':\n        log_alpha = torch.log(self.alpha)\n        t = torch.acos(torch.clamp(lamb, -1, 1)) / log_alpha\n    else:\n        log_alpha = torch.log(self.alpha)\n        t = torch.acos(torch.clamp(lamb, -1, 1)) / log_alpha\n    return t\n\n", "CodeBleu_score": 20.918854539351084}, {"code": "def inverse_lambda(self, lamb)\n\t\n    if self.schedule == 'linear':\n        t = torch.sum(self.beta * lamb, dim=1)\n    elif self.schedule == 'discrete':\n        log_alpha = torch.log(self.alpha)\n        t = torch.sum(log_alpha * lamb, dim=1)\n    else:\n        log_alpha = torch.log(self.alpha)\n        t = torch.sum(log_alpha * lamb, dim=1)\n        t = torch.acos(torch.clamp(t, -1.0 + 1e-08, 1.0 - 1e-08)) / (2 * np.pi) * self.T\n    return t\n\n", "CodeBleu_score": 24.528018471583447}]}
{"instance_id": "a519c853a2b2", "generation_result": [{"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\tif cond is not None:\n        x = torch.cat([x, cond], dim=-1)\n    x = x.expand(x.size(0), -1, -1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous", "CodeBleu_score": 17.29340669907418}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\tif cond is not None:\n        x = torch.cat((x, cond), dim=-1)\n    x = expand_dims(x, 1)\n    if t_continuous is not None:\n        t_continuous = expand_dims(t_continuous, 1)\n    if self.model_type == \"rnn\":\n        x, h = self.model(x, t_continuous)\n        return x, h\n    elif self.model_type == \"lstm\":\n        x, (h, c) = self.model(x, t_continuous)\n        return x, (h, c)\n    elif self.model_type == \"gru\":\n        x, h = self.model(x, t_continuous)\n        return x, h\n    elif self.model_type == \"transformer\":\n        x, h = self.model(x, t_continuous)\n        return x, h\n    else:\n        raise NotImplementedError(f\"Model type {self.model_type} is not implemented.\")\n", "CodeBleu_score": 23.421733108924798}, {"code": "def noise_pred_fn(x, t_continuous, cond=None)\n\tif cond is None:\n        cond = x\n    if cond.dim() == x.dim():\n        cond = expand_dims(cond, x.dim())\n    if cond.dim() == x.dim() + 1:\n        cond = expand_dims(cond, x.dim() + 1)\n    if cond.dim() == x.dim() + 2:\n        cond = expand_dims(cond, x.dim() + 2)\n    if cond.dim() == x.dim() + 3:\n        cond = expand_dims(cond, x.dim() + 3)\n    if cond.dim() == x.dim() + 4:\n        cond = expand_dims(cond, x.dim() + 4)\n    if cond.dim() == x.dim() + 5:\n        cond = expand_dims(cond, x.dim() + 5)\n    if cond.dim() == x.dim() + 6:\n        cond = expand_dims(cond, x.dim() + 6)\n    if cond.dim() == x.dim() + 7:\n        cond = expand_dims(cond, x.dim() + 7)\n    if cond.dim() == x.dim() + 8:\n        cond = expand_dims(cond, x.dim() + 8)\n    if cond.dim() == x.dim() + 9:\n        cond = expand_dims(cond, x.dim() + 9)\n    if cond.dim() == x.dim() + 10:\n        cond = expand_dims(cond, x.dim() + 10)\n    if cond.dim() == x.dim() + 11:\n        cond = expand_dims(cond, x.dim() + 11)\n    if cond.dim() == x.dim() + 12:\n        cond = expand_dims(cond, x.dim() + 12)\n    if cond.dim() == x.dim() + 13:\n        cond = expand_dims(cond, x.dim() + 13)\n    if cond.dim() == x.dim() + 14:\n        cond = expand_dims(cond, x.dim() + 14)\n    if cond.dim() == x.dim() + 15:\n        cond = expand", "CodeBleu_score": 17.525439009619927}]}
{"instance_id": "96a9b7d54823", "generation_result": [{"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    if t is None:\n        t = self.threshold\n    x = x0.abs()\n    q = x.kthvalue(x.numel() - 1)[0].item()\n    if q == 0:\n        return x0\n    scale = t / q\n    return x * scale\n\n", "CodeBleu_score": 23.165411079298337}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    if t is None:\n        t = self.t\n    if t == 0:\n        return x0\n    if t == 1:\n        return x0.clamp(min=0)\n    if t == 2:\n        return x0.clamp(max=0)\n    if t == 3:\n        return x0.clamp(min=-1, max=1)\n    if t == 4:\n        return x0.clamp(min=1)\n    if t == 5:\n        return x0.clamp(max=-1)\n    if t == 6:\n        return x0.clamp(min=-2, max=2)\n    if t == 7:\n        return x0.clamp(min=2)\n    if t == 8:\n        return x0.clamp(max=2)\n    if t == 9:\n        return x0.clamp(min=-3, max=3)\n    if t == 10:\n        return x0.clamp(min=3)\n    if t == 11:\n        return x0.clamp(max=3)\n    if t == 12:\n        return x0.clamp(min=-4, max=4)\n    if t == 13:\n        return x0.clamp(min=4)\n    if t == 14:\n        return x0.clamp(max=4)\n    if t == 15:\n        return x0.clamp(min=-5, max=5)\n    if t == 16:\n        return x0.clamp(min=5)\n    if t == 17:\n        return x0.clamp(max=5)\n    if t == 18:\n        return x0.clamp(min=-6, max=6)\n    if t == 19:\n        return x0.clamp(min=6)\n    if t == 20:\n        return x0.clamp(max=6)\n    if t == 21:\n        return x0.clamp(min=-7, max=7)\n    if t == 22:\n        return x0.clamp(min=7)\n    if t == 23:\n        return x0.clamp(max=7)\n    if t == 24:\n        return x0.clamp(min=-8, max=8)\n    if t == 25:\n        return", "CodeBleu_score": 13.39182351201615}, {"code": "def dynamic_thresholding_fn(self, x0, t=None)\n\t    x0 = x0.abs()\n    if t is None:\n        t = self.t\n    q = torch.quantile(x0, t, dim=self.axis)\n    scale = q / (self.scale_factor * self.eps)\n    x0 = x0.clamp(-scale, scale)\n    return x0 * self.scale_factor\n\n", "CodeBleu_score": 26.429971715679024}]}
{"instance_id": "59c6ec6d7a6a", "generation_result": [{"code": "def data_prediction_fn(self, x, t)\n\t  return torch.clamp(x / self.threshold_ratio, 0., self.max_threshold)", "CodeBleu_score": 1.600706850743336}, {"code": "def data_prediction_fn(self, x, t)\n\t  return torch.clamp(x / self.dynamic_thresholding_ratio, max=self.max_threshold) / self.max_threshold", "CodeBleu_score": 6.355293883169233}, {"code": "def data_prediction_fn(self, x, t)\n\t  threshold = self.threshold_ratio * self.max_threshold\n    return torch.clamp(x / threshold, 0., 1.)", "CodeBleu_score": 5.96922927706164}]}
{"instance_id": "65e3618468a2", "generation_result": [{"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = np.reshape(sigma_in, input.shape)\n    input_scaled = scale_input(input, model.scaler)\n    eps = model.predict(input_scaled)\n    eps = eps * sigma_in\n    return eps\n\n", "CodeBleu_score": 19.534254494288582}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma_in = sigma_in.reshape(input.shape)\n    scaled_input = scale_input(input, model.input_scale)\n    scaled_sigma = scale_input(sigma_in, model.input_scale)\n    prediction = model.predict(scaled_input)\n    prediction_adjusted = prediction - scaled_input * prediction\n    prediction_adjusted = prediction_adjusted + scaled_sigma\n    return prediction_adjusted\n\n", "CodeBleu_score": 16.902322637253047}, {"code": "def predict_eps_sigma(model, input, sigma_in, **kwargs)\n\t\n    sigma = sigma_in.reshape(input.shape)\n    input_scaled = scale_input(input, model.input_mean, model.input_std)\n    prediction = model.predict(input_scaled) + sigma * input_scaled\n    return prediction\n\n", "CodeBleu_score": 18.77459033818377}]}
{"instance_id": "b35846dfbc66", "generation_result": [{"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().requires_grad_(True)\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        grad_log_alpha = torch.autograd.grad(log_alpha, taus, retain_graph=True, create_graph=True)[0]\n        integrand = (alpha ** 2 * grad_log_alpha ** 2).sum()\n    return integrand\n\n", "CodeBleu_score": 45.84582597540579}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        taus = taus.clone().requires_grad_(True)\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        grad_log_alpha = torch.autograd.grad(log_alpha, taus)[0]\n        integrand = (\n            torch.exp(-0.5 * taus ** 2 * (beta_1 - beta_0) - taus * beta_0)\n            * grad_log_alpha\n        )\n    return integrand\n\n", "CodeBleu_score": 48.684946302465704}, {"code": "def cal_intergrand(beta_0, beta_1, taus)\n\t\n    with torch.enable_grad():\n        alpha = t2alpha_fn(beta_0, beta_1, taus)\n        log_alpha = torch.log(alpha)\n        log_alpha.backward(torch.ones_like(taus))\n        grad_log_alpha = taus.grad\n        return alpha * grad_log_alpha\n\n", "CodeBleu_score": 27.42254289157964}]}
{"instance_id": "5f3667566a10", "generation_result": [{"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if not noise_sampler:\n        noise_sampler = default_noise_sampler(x)\n    if extra_args is None:\n        extra_args = {}\n    if disable is None:\n        disable = []\n    if callback is None:\n        callback = lambda x, sigma, denoised: None\n    for sigma_from, sigma_to in zip(sigmas, sigmas[1:]):\n        sigma_down, sigma_up = get_ancestral_step(sigma_from, sigma_to, eta=eta)\n        sigma = torch.stack([sigma_down, sigma_up], dim=-1)\n        if sigma_down:\n            denoised = model(x, sigma_down, **extra_args)\n        else:\n            denoised = x\n        for i in range(int(eta)):\n            x = x + sigma_up * to_d(x, sigma, denoised)\n            denoised = model(x, sigma_up, **extra_args)\n            if callback:\n                callback(x, sigma, denoised)\n        x = x + sigma_down * to_d(x, sigma, denoised)\n        if sigma_down:\n            denoised = model(x, sigma_down, **extra_args)\n        else:\n            denoised = x\n        if not sigma_up:\n            break\n        x = x + sigma_up * to_d(x, sigma, denoised)\n        if sigma_down:\n            denoised = model(x, sigma_up, **extra_args)\n        else:\n            denoised = x\n        if callback:\n            callback(x, sigma, denoised)\n    if s_noise:\n        x = x + s_noise * noise_sampler(x.shape, x.dtype)\n    return x\n\n", "CodeBleu_score": 32.56552427800652}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if disable:\n        return x\n    if not extra_args:\n        extra_args = {}\n    if not noise_sampler:\n        noise_sampler = default_noise_sampler\n    if not callback:\n        callback = lambda x: x\n    if not s_noise:\n        s_noise = 1.\n    sigmas = utils.to_tensor(sigmas)\n    x = utils.to_tensor(x)\n    if not x.shape:\n        x = x.unsqueeze(0)\n    sigmas = utils.append_dims(sigmas, x.ndim)\n    x = x.clone()\n    for sigma in sigmas:\n        sigma_next = sigma + s_noise\n        sigma_down, sigma_up = get_ancestral_step(sigma, sigma_next, eta)\n        x = x + sigma_down * to_d(x, sigma, model(x, **extra_args))\n        x = x + sigma_up * noise_sampler(sigma, sigma_next)(sigma_next)\n        x = callback(x)\n    return x\n\n", "CodeBleu_score": 33.33698932806485}, {"code": "def sample_euler_ancestral(model, x, sigmas, extra_args=None, callback=None, disable=None, eta=1., s_noise=1., noise_sampler=None)\n\t\n    if not noise_sampler:\n        noise_sampler = default_noise_sampler(x)\n    if not extra_args:\n        extra_args = {}\n    if not disable:\n        disable = []\n    if not callback:\n        callback = lambda x, sigma, denoised: None\n    sigma_from = sigmas[0]\n    for sigma_to in sigmas[1:]:\n        sigma_down, sigma_up = get_ancestral_step(sigma_from, sigma_to, eta=eta)\n        if sigma_down:\n            x = utils.update(x, to_d(x, sigma_down, model(x, **extra_args)), sigma_down)\n        sigma_from = sigma_to\n        if sigma_up:\n            noise = noise_sampler(sigma_up, sigma_to)\n            x = utils.update(x, to_d(x, sigma_up, model(x + noise, **extra_args)), sigma_up)\n            if s_noise:\n                x = utils.update(x, to_d(x, s_noise, x + noise), s_noise)\n        callback(x, sigma_to, model(x, **extra_args))\n    return x\n\n", "CodeBleu_score": 33.96680378782858}]}
{"instance_id": "6261ded88df2", "generation_result": [{"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product(t, i, j):\n        return (t[i+1] - t[i]) * (t[i+1] - t[j])\n    if order > len(t) - 1:\n        raise ValueError(\"The order is too high for the step index.\")\n    return integrate.quad(product, t[i], t[i+1], args=(i, j))[0]\n\n", "CodeBleu_score": 21.685431074737593}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def product(k):\n        \"\"\"The function computes the product term for the linear multistep coefficient, excluding the j-th term.\"\"\"\n        if k == i:\n            return 1\n        elif k == j:\n            return 0\n        else:\n            return t[k] / (t[k] - t[j])\n    return integrate.quad(product, i, j + 1)[0]\n\n", "CodeBleu_score": 18.868670822168422}, {"code": "def linear_multistep_coeff(order, t, i, j)\n\t\n    def prod_term(k):\n        if k == j:\n            return 1\n        elif k == i:\n            return 0\n        else:\n            return t[k] / (t[k] - t[i])\n    return integrate.quad(prod_term, i, i+1)[0]\n\n", "CodeBleu_score": 18.928570785724162}]}
{"instance_id": "4ee025e33ab1", "generation_result": [{"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n    if disable is None:\n        disable = []\n    if callback is None:\n        callback = lambda x: None\n    x = x.detach().clone()\n    for sigma in sigmas:\n        if sigma > 0:\n            noise = noise_sampler(sigma, sigma)\n            x = model(x, **extra_args)\n            x = x + noise * sigma\n        else:\n            x = model(x, **extra_args)\n        callback(x)\n    return x\n\n", "CodeBleu_score": 30.865164608497064}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n    for sigma in sigmas:\n        if sigma == 0:\n            continue\n        x = model(x, **extra_args)\n        if disable is not None:\n            x = disable(x)\n        x = x + sigma * noise_sampler(sigma, sigma_next=sigmas[sigmas.index(sigma) + 1])\n        if callback is not None:\n            callback(x, sigma)\n    return x\n", "CodeBleu_score": 30.41213561495265}, {"code": "def sample_lcm(model, x, sigmas, extra_args=None, callback=None, disable=None, noise_sampler=None)\n\t\n    if extra_args is None:\n        extra_args = {}\n    if disable is None:\n        disable = []\n    if noise_sampler is None:\n        noise_sampler = default_noise_sampler(x)\n    if callback is None:\n        callback = lambda x, y: None\n    x = x.clone()\n    for sigma in sigmas:\n        if sigma <= 0:\n            break\n        if sigma not in disable:\n            sigma_next = sigmas[sigmas.index(sigma) + 1]\n            if sigma_next is None:\n                sigma_next = 0\n            noise = noise_sampler(sigma, sigma_next)\n            x = model(x, sigma, extra_args=extra_args, noise=noise)\n            callback(x, sigma)\n            if sigma_next > 0:\n                x = x * (1 - sigma_next) + noise * sigma_next\n    return x\n\n", "CodeBleu_score": 32.95377527421531}]}
{"instance_id": "cb51f91da606", "generation_result": [{"code": "def append_dims(x, target_dims)\n\t    if x.ndim < len(target_dims):\n        raise ValueError(f\"The target dimensions {target_dims} are fewer than the current dimensions {x.ndim}.\")\n    if x.ndim == len(target_dims):\n        return x\n    if x.device.type == \"mps\":\n        return x.expand(target_dims)\n    return x.expand(target_dims)\n\n", "CodeBleu_score": 25.571387124081596}, {"code": "def append_dims(x, target_dims)\n\t    if isinstance(x, torch.Tensor):\n        if x.ndim == len(target_dims):\n            return x\n        else:\n            if x.device.type =='mps':\n                x = x.detach()\n            n_dims = len(target_dims) - x.ndim\n            if n_dims < 0:\n                raise ValueError(f'The target dimensions {target_dims} are fewer than the current dimensions {x.ndim}.')\n            else:\n                x = torch.unsqueeze(x, dim=list(range(n_dims, len(target_dims))))\n                return x\n    else:\n        return x\n\n", "CodeBleu_score": 34.28227351311621}, {"code": "def append_dims(x, target_dims)\n\t    if isinstance(x, torch.Tensor):\n        if x.is_sparse:\n            return x.coalesce()\n        if x.is_cuda:\n            if torch.cuda.get_device_properties(x.device.index).multi_process:\n                return x.expand(target_dims)\n            else:\n                return x.expand_as(x)\n        else:\n            return x.expand(target_dims)\n    else:\n        return x\n\n", "CodeBleu_score": 17.42867697561913}]}
{"instance_id": "9fac874a3bc7", "generation_result": [{"code": "def download_file(path, url, digest=None)\n\t\n    if not os.path.exists(path):\n        os.makedirs(os.path.dirname(path))\n        response = requests.get(url, stream=True)\n        with open(path, 'wb') as f:\n            for chunk in response.iter_content(chunk_size=1024):\n                if chunk:\n                    f.write(chunk)\n    else:\n        print('File already exists.')\n    if digest:\n        if not hashlib.sha256(open(path, 'rb').read()).hexdigest() == digest:\n            raise ValueError('File hash mismatch.')\n    return path\n\n", "CodeBleu_score": 42.508382754310325}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not os.path.exists(path):\n        os.makedirs(os.path.dirname(path))\n    if not os.path.exists(path):\n        raise Exception(f\"Failed to create directory {path}\")\n    if os.path.exists(path) and os.path.getsize(path) > 0:\n        return path\n    if url.startswith(\"http\"):\n        r = requests.get(url, stream=True)\n        if r.status_code!= 200:\n            raise Exception(f\"Failed to download file from {url} with status code {r.status_code}\")\n        with open(path, \"wb\") as f:\n            for chunk in r.iter_content(chunk_size=1024):\n                if chunk:\n                    f.write(chunk)\n    else:\n        raise Exception(f\"Failed to download file from {url}\")\n    if digest is not None:\n        file_hash = hashlib.sha256()\n        with open(path, \"rb\") as f:\n            for chunk in iter(lambda: f.read(1024), b\"\"):\n                file_hash.update(chunk)\n        if file_hash.hexdigest()!= digest:\n            raise Exception(f\"Downloaded file {path} has incorrect hash\")\n    return path\n\n", "CodeBleu_score": 40.79404395303715}, {"code": "def download_file(path, url, digest=None)\n\t\n    if not os.path.exists(path):\n        os.makedirs(os.path.dirname(path))\n    if not os.path.exists(path):\n        print('Downloading file from {} to {}'.format(url, path))\n        urllib.request.urlretrieve(url, path)\n    else:\n        print('File already exists at {}'.format(path))\n    if digest:\n        with open(path, 'rb') as f:\n            hash = hashlib.sha256(f.read()).hexdigest()\n        if hash!= digest:\n            raise RuntimeError('File {} has an invalid hash: expected {}, got {}'.format(path, digest, hash))\n    return path\n\n", "CodeBleu_score": 45.55655345459111}]}
{"instance_id": "f23165e897ce", "generation_result": [{"code": "def train_mode(model, mode=True)\n\t\n    if mode:\n        model.train()\n    else:\n        model.eval()\n    return model\n\n", "CodeBleu_score": 14.524436844388436}, {"code": "def train_mode(model, mode=True)\n\t\n    original_modes = []\n    for module in model.modules():\n        original_modes.append(module.training)\n        module.train(mode)\n    yield\n    for i, module in enumerate(model.modules()):\n        module.train(original_modes[i])\n\n", "CodeBleu_score": 45.63033276685135}, {"code": "def train_mode(model, mode=True)\n\t\n    original_modes = {}\n    for name, module in model.named_modules():\n        original_modes[name] = module.training\n        module.train(mode)\n\n    def _restore_mode():\n        for name, module in model.named_modules():\n            module.train(original_modes[name])\n\n    return _restore_mode()\n\n", "CodeBleu_score": 31.74169741248038}]}
{"instance_id": "c6d59c6cb8e1", "generation_result": [{"code": "def ema_update(model, averaged_model, decay)\n\t\n    for param, averaged_param in zip(model.parameters(), averaged_model.parameters()):\n        if averaged_param.data.ne(averaged_param.data).sum() > 0:\n            averaged_param.data.copy_(averaged_param.data * decay + param.data * (1 - decay))\n    for buffer, averaged_buffer in zip(model.buffers(), averaged_model.buffers()):\n        if averaged_buffer.data.ne(averaged_buffer.data).sum() > 0:\n            averaged_buffer.data.copy_(averaged_buffer.data * decay + buffer.data * (1 - decay))\n\n", "CodeBleu_score": 35.69856352632802}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    for p_averaged, p_current in zip(averaged_model.parameters(), model.parameters()):\n        p_averaged.data.mul_(decay).add_(1 - decay, p_current.data)\n    for p_averaged, p_current in zip(averaged_model.buffers(), model.buffers()):\n        p_averaged.data.copy_(p_current.data)\n\n", "CodeBleu_score": 26.186059363197057}, {"code": "def ema_update(model, averaged_model, decay)\n\t\n    for p, p_avg in zip(model.parameters(), averaged_model.parameters()):\n        if p_avg.data.is_sparse:\n            assert p.data.is_sparse\n            p_avg.data = p_avg.data + decay * (p.data - p_avg.data)\n        else:\n            p_avg.data.mul_(decay).add_(1 - decay, p.data)\n    for buffer, buffer_avg in zip(model.buffers(), averaged_model.buffers()):\n        buffer_avg.data.copy_(buffer)\n\n", "CodeBleu_score": 30.577994944599755}]}
{"instance_id": "600c39a30798", "generation_result": [{"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.tensor(max_value, device=device, dtype=dtype)\n    shape = torch.tensor(shape, device=device, dtype=torch.int64)\n    loc = torch.tensor(loc, device=device, dtype=dtype)\n    scale = torch.tensor(scale, device=device, dtype=dtype)\n    uniform_random_values = torch.rand(shape, device=device, dtype=dtype)\n    logit_uniform_random_values = torch.log(uniform_random_values / (1 - uniform_random_values))\n    log_logistic_values = logit_uniform_random_values * scale + loc\n    log_logistic_values = torch.clamp(log_logistic_values, min_value, max_value)\n    logistic_values = torch.exp(log_logistic_values)\n    return logistic_values\n\n", "CodeBleu_score": 28.4943543122805}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.tensor(max_value, device=device, dtype=dtype)\n    cdf_min = torch.log(min_value / scale - loc) / scale\n    cdf_max = torch.log(max_value / scale - loc) / scale\n    u = torch.rand(shape, device=device, dtype=dtype)\n    return torch.exp(cdf_min + (cdf_max - cdf_min) * torch.log(u))\n\n", "CodeBleu_score": 33.625262239050144}, {"code": "def rand_log_logistic(shape, loc=0., scale=1., min_value=0., max_value=float('inf'), device='cpu', dtype=torch.float32)\n\t\n    min_value = torch.tensor(min_value, device=device, dtype=dtype)\n    max_value = torch.tensor(max_value, device=device, dtype=dtype)\n    loc = torch.tensor(loc, device=device, dtype=dtype)\n    scale = torch.tensor(scale, device=device, dtype=dtype)\n    u = torch.rand(shape, device=device, dtype=dtype)\n    cdf_min_value = torch.log(min_value / (max_value - min_value))\n    cdf_max_value = torch.log(max_value / (max_value - min_value))\n    cdf_u = torch.log(u / (1 - u))\n    cdf_u = torch.where(cdf_u < cdf_min_value, cdf_min_value, cdf_u)\n    cdf_u = torch.where(cdf_u > cdf_max_value, cdf_max_value, cdf_u)\n    cdf_u = (cdf_u - cdf_min_value) / (cdf_max_value - cdf_min_value)\n    logit_cdf_u = torch.log(cdf_u / (1 - cdf_u))\n    logit_cdf_u = (logit_cdf_u - torch.log(0.5)) / (torch.log(0.5) - torch.log(0.5))\n    logit_cdf_u = torch.where(logit_cdf_u < 0, 0, logit_cdf_u)\n    logit_cdf_u = torch.where(logit_cdf_u > 1, 1, logit_cdf_u)\n    logit_cdf_u = torch.log(logit_cdf_u / (1 - logit_cdf_u))\n    logit_cdf_u = logit_cdf_u * (torch.log(0.5) - torch.log(0.5))\n    logit_cdf_u = torch.where(logit_cdf_u < torch.log(0.5), torch.log(0.5), logit_cdf_u)\n    logit_cdf_u = torch.where(logit_cdf_u", "CodeBleu_score": 24.36411925991935}]}
{"instance_id": "75e2def2467f", "generation_result": [{"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU(inplace=True)\n    if activation == \"snake\":\n        return SnakeBeta(channels)\n    if activation == \"none\":\n        return Identity()\n    if antialias:\n        return Activation1d(activation)\n    return activation\n\n", "CodeBleu_score": 38.00041351782312}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU(inplace=True)\n    if activation == \"snake\":\n        return SnakeBeta(channels=channels)\n    if activation == \"none\":\n        return nn.Identity()\n    if antialias:\n        return Activation1d(activation=activation)\n    return activation\n\n", "CodeBleu_score": 37.09770141112333}, {"code": "def get_activation(activation: Literal[\"elu\", \"snake\", \"none\"], antialias=False, channels=None) -> nn.Module\n\t\n    if activation == \"elu\":\n        return nn.ELU(inplace=True)\n    elif activation == \"snake\":\n        return SnakeBeta(channels=channels)\n    elif activation == \"none\":\n        return Identity()\n    else:\n        raise ValueError(f\"Unknown activation type: {activation}\")\n\n", "CodeBleu_score": 41.99147094838359}]}
{"instance_id": "ef1714c79e51", "generation_result": [{"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float", "CodeBleu_score": 14.211857691823868}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float()\n    if t.dtype == torch.float64:\n        t = t.float()\n    if t.dtype == torch.float16:\n        t = t.float()\n    if t.dtype == torch.float32:\n        t = t.float", "CodeBleu_score": 14.211857691823868}, {"code": "def apply_rotary_pos_emb(t, freqs, scale = 1)\n\t    t = t.float()\n    freqs = freqs.float()\n    freqs = freqs.to(t.device)\n    freqs = rearrange(freqs, 'd -> () d ()')\n    t = rearrange(t, '... (d j) ->... j d', j = 2)\n    t = t * scale\n    t1, t2 = t.unbind(dim = -2)\n    freqs1, freqs2 = freqs.unbind(dim = 0)\n    t1 = t1 + freqs1 * t2\n    t2 = t2 * freqs2\n    t = torch.cat((t1, t2), dim = -1)\n    return rearrange(t, '... j d ->... (j d)')\n\n", "CodeBleu_score": 26.369968891623373}]}
{"instance_id": "a7a5f178c6f6", "generation_result": [{"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.vq_embeddings(self.vq_codebook.select_indices(idx, dim))\n\n", "CodeBleu_score": 18.751325758910994}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.vq_codebook.idx2vq(idx, dim)\n\n", "CodeBleu_score": 17.17487311935789}, {"code": "def idx2vq(self, idx, dim=-1)\n\t\n    return self.vq_codebook.idx2vq(idx, dim)\n\n", "CodeBleu_score": 17.17487311935789}]}
{"instance_id": "4104c041fb20", "generation_result": [{"code": "def encode(self, x, quantize=False)\n\t   z_e_x = x.contiguous().view(-1, x.size(-1)) if len(x.shape) > 2 else x\n    z_q_x, (vq_loss, commit_loss), indices = self.vq(z_e_x) if quantize else (z_e_x, None, None)\n    if quantize:\n        return z_q_x, z_e_x, indices, (vq_loss, commit_loss)\n    return z_q_x\n\n", "CodeBleu_score": 34.70087665380201}, {"code": "def encode(self, x, quantize=False)\n\t   z_q_x = x\n    for block in self.blocks:\n        z_q_x, _, _ = block(z_q_x)\n    if quantize:\n        z_q_x, (vq_loss, commit_loss), indices = self.vq(z_q_x, self.codebook.weight.detach())\n        return z_q_x, x, indices, (vq_loss, commit_loss)\n    else:\n        return z_q_x\n\n", "CodeBleu_score": 39.68996134585752}, {"code": "def encode(self, x, quantize=False)\n\t   z_q_x, (vq_loss, commit_loss), indices = self.forward(x, get_losses=True)\n    if quantize:\n        return z_q_x, x, indices, vq_loss + commit_loss\n    return z_q_x\n\n", "CodeBleu_score": 29.118355048594175}]}
{"instance_id": "403c52ba2d3b", "generation_result": [{"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        return EMAContext(self)\n    else:\n        with EMAContext(self) as ema_context:\n            context.run(ema_context)\n\n", "CodeBleu_score": 11.088120025240492}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = self.ema_context(self.model.parameters())\n    with context:\n        pass\n\n", "CodeBleu_score": 20.767255566122383}, {"code": "def ema_scope(self, context=None)\n\t\n    if context is None:\n        context = self\n    with context:\n        self.store(context.parameters())\n        self.copy_to(context.model)\n        if self.log_switch:\n            self.log_switch(context.model)\n", "CodeBleu_score": 28.157901602566106}]}
{"instance_id": "94b7467f98e4", "generation_result": [{"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    if self.pre_only:\n        return x\n    x = x + attn\n    x = self.proj(x)\n    x = self.proj_drop(x)\n    if self.shift_msa is not None:\n        x = modulate(x, self.shift_msa(gate_msa), self.scale_msa(gate_msa))\n    if self.gate_msa is not None:\n        x = self.gate_msa(x)\n    if self.shift_mlp is not None:\n        x = modulate(x, self.shift_mlp(gate_mlp), self.scale_mlp(gate_mlp))\n    if self.gate_mlp is not None:\n        x = self.gate_mlp(x)\n    return x\n", "CodeBleu_score": 38.875010531375125}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    attn = attn.permute(0, 2, 1)\n    x = x + self.attn_drop(attn)\n    x = self.norm1(x)\n    x = modulate(x, shift_mlp(x), scale_mlp(x))\n    x = self.mlp_drop(self.mlp(x))\n    return x\n\n", "CodeBleu_score": 45.273362289061374}, {"code": "def post_attention(self, attn, x, gate_msa, shift_mlp, scale_mlp, gate_mlp)\n\t\n    assert not self.pre_only\n    attn = attn.masked_fill(attn.eq(0), float('-inf'))\n    attn = F.softmax(attn, dim=-1)\n    attn = attn.masked_fill(attn.eq(0), 0)\n    attn = F.dropout(attn, p=self.attn_pdrop, training=self.training)\n    x = x + self.attn_drop(attn)\n    x = self.proj(x)\n    x = self.proj_drop(x)\n    x = self.norm(x)\n    if self.shift_msa is not None:\n        shift = self.shift_msa(x)\n    else:\n        shift = None\n    if self.scale_msa is not None:\n        scale = self.scale_msa(x)\n    else:\n        scale = None\n    x = modulate(x, shift, scale)\n    if self.gate_msa is not None:\n        gate = self.gate_msa(x)\n        x = gate * x\n    if self.shift_mlp is not None:\n        shift = self.shift_mlp(x)\n    else:\n        shift = None\n    if self.scale_mlp is not None:\n        scale = self.scale_mlp(x)\n    else:\n        scale = None\n    x = modulate(x, shift, scale)\n    if self.gate_mlp is not None:\n        gate = self.gate_mlp(x)\n        x = gate * x\n    return x\n\n", "CodeBleu_score": 40.96867647085871}]}
{"instance_id": "d9fdc05542a2", "generation_result": [{"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    qkv = context_block.pre_attention(context)\n    x = x_block.pre_attention(x)\n    qkv = torch.cat([qkv[0], qkv[1], qkv[2], x], dim=-1)\n    qkv = optimized_attention(qkv, c.num_heads)\n    qkv = split_qkv(qkv, c.head_dim)\n    context = context_block.post_attention(qkv[0])\n    x = x_block.post_attention(qkv[1])\n    return context, x\n\n", "CodeBleu_score": 12.333933900568015}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    context = context_block.pre_attention(context)\n    x = x_block.pre_attention(x)\n    context_qkv = torch.cat([context[0], x[0]], dim=-1)\n    x_qkv = torch.cat([x[1], context[1]], dim=-1)\n    context_qkv, x_qkv = optimized_attention(context_qkv, c)\n    context = (context[2], x_qkv[:, :context[1].shape[1], :])\n    x = (x[2], context_qkv[:, context[1].shape[1]:, :])\n    context = context_block.post_attention(context)\n    x = x_block.post_attention(x)\n    return context, x\n\n", "CodeBleu_score": 21.195425428170918}, {"code": "def _block_mixing(context, x, context_block, x_block, c)\n\t\n    context_qkv = context_block.pre_attention(context)\n    x_qkv = x_block.pre_attention(x)\n    qkv = torch.cat([context_qkv[0], x_qkv[0]], dim=1)\n    qkv = optimized_attention(qkv, c.num_heads)\n    context_part, x_part = split_qkv(qkv, c.num_heads)\n    context = context_block.post_attention(context_part)\n    x = x_block.post_attention(x_part)\n    return context, x\n", "CodeBleu_score": 13.917868897182705}]}
{"instance_id": "b219bce30160", "generation_result": [{"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    timesteps = tf.convert_to_tensor(timesteps, dtype=tf.int32)\n    if len(timesteps.shape)!= 1:\n        raise ValueError(\"The input timesteps must be one-dimensional.\")\n    num_timesteps = tf.shape(timesteps)[0]\n    position_embedding = tf.convert_to_tensor(\n        tf.concat(\n            [\n                tf.math.sin(tf.range(num_timesteps) * tf.math.pow(10000, tf.range(embedding_dim // 2) / embedding_dim)),\n                tf.math.cos(tf.range(num_timesteps) * tf.math.pow(10000, tf.range(embedding_dim // 2) / embedding_dim)),\n            ],\n            axis=0,\n        ),\n        dtype=tf.float32,\n    )\n    if embedding_dim % 2!= 0:\n        position_embedding = tf.pad(position_embedding, [[0, 1], [0, 0]])\n    return position_embedding\n\n", "CodeBleu_score": 32.20068375300714}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    if timesteps.ndim!= 1:\n        timesteps = timesteps.flatten()\n    position_embedding = np.zeros((len(timesteps), embedding_dim))\n    position_embedding[:, 0::2] = np.sin(timesteps[:, np.newaxis] / (10000 ** (np.arange(0, embedding_dim, 2) / embedding_dim)))\n    position_embedding[:, 1::2] = np.cos(timesteps[:, np.newaxis] / (10000 ** (np.arange(1, embedding_dim, 2) / embedding_dim)))\n    position_embedding = torch.from_numpy(position_embedding)\n    return position_embedding\n\n", "CodeBleu_score": 28.138575106701058}, {"code": "def get_timestep_embedding(timesteps, embedding_dim)\n\t\n    if timesteps.ndim == 1:\n        timesteps = timesteps[:, None]\n    else:\n        raise ValueError('Timesteps input must be one-dimensional.')\n    # Calculate the positional embedding\n    pos_emb = torch.zeros(timesteps.shape[0], embedding_dim)\n    for i in range(embedding_dim):\n        if i % 2 == 0:\n            pos_emb[:, i] = torch.sin(timesteps / (10000 ** (i / embedding_dim)))\n        else:\n            pos_emb[:, i] = torch.cos(timesteps / (10000 ** ((i - 1) / embedding_dim)))\n    # Scale the embedding by a logarithmic factor\n    log_scale = torch.log(torch.tensor(10000.0)) / (embedding_dim // 2)\n    pos_emb *= torch.exp(log_scale)\n    # Zero-pad the embedding to match the specified dimension\n    if embedding_dim % 2 == 1:\n        pos_emb = torch.cat([pos_emb, torch.zeros(pos_emb.shape[0], 1)], dim=1)\n    # Concatenate the embedding to the original input\n    embedding = torch.cat([timesteps, pos_emb], dim=1)\n    return embedding\n\n", "CodeBleu_score": 36.645880343578476}]}
{"instance_id": "6ae8453c86be", "generation_result": [{"code": "def pytorch_attention(q, k, v)\n\t\n    q = q.reshape(q.shape[0], q.shape[1], 1, q.shape[2])\n    k = k.reshape(k.shape[0], k.shape[1], k.shape[2], 1)\n    v = v.reshape(v.shape[0], v.shape[1], v.shape[2], 1)\n\n    q = q.permute(0, 2, 1, 3)\n    k = k.permute(0, 2, 3, 1)\n    v = v.permute(0, 2, 3, 1)\n\n    if q.element_size() == 2:\n        return slice_attention(q, k, v)\n\n    r1 = torch.matmul(q, k)\n    del q\n    del k\n\n    scale = (int(r1.shape[-1]) ** (-0.5))\n    r1 = r1 * scale\n\n    r1 = torch.nn.functional.softmax(r1, dim=-1)\n    del r1\n\n    r2 = torch.matmul(r1, v)\n    del r1\n    del v\n\n    r2 = r2.permute(0, 2, 1, 3)\n    del r2\n\n    r2 = r2.reshape(r2.shape[0], r2.shape[1], r2.shape[2])\n    return r2\n\n", "CodeBleu_score": 28.675900884419264}, {"code": "def pytorch_attention(q, k, v)\n\t\n    scale = (int(q.shape[-1])**(-0.5))\n\n    mem_free_total = model_management.get_free_memory(q.device)\n\n    gb = 1024 ** 3\n    tensor_size = q.shape[0] * q.shape[1] * k.shape[2] * q.element_size()\n    modifier = 3 if q.element_size() == 2 else 2.5\n    mem_required = tensor_size * modifier\n    steps = 1\n\n    if mem_required > mem_free_total:\n        steps = 2**(math.ceil(math.log(mem_required / mem_free_total, 2)))\n\n    while True:\n        try:\n            slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n            for i in range(0, q.shape[1], slice_size):\n                end = i + slice_size\n                s1 = torch.bmm(q[:, i:end], k) * scale\n\n                s2 = torch.nn.functional.softmax(s1, dim=2).permute(0,2,1)\n                del s1\n\n                r1 = torch.bmm(v, s2)\n                del s2\n            break\n        except model_management.OOM_EXCEPTION as e:\n            model_management.soft_empty_cache(True)\n            steps *= 2\n            if steps > 128:\n                raise e\n            logging.warning(\"out of memory error, increasing steps and trying again {}\".format(steps))\n\n    return r1\n\n", "CodeBleu_score": 24.021658405360455}, {"code": "def pytorch_attention(q, k, v)\n\t\n    r1 = torch.zeros_like(k, device=q.device)\n    scale = (int(q.shape[-1])**(-0.5))\n\n    mem_free_total = model_management.get_free_memory(q.device)\n\n    gb = 1024 ** 3\n    tensor_size = q.shape[0] * q.shape[1] * k.shape[2] * q.element_size()\n    modifier = 3 if q.element_size() == 2 else 2.5\n    mem_required = tensor_size * modifier\n    steps = 1\n\n    if mem_required > mem_free_total:\n        steps = 2**(math.ceil(math.log(mem_required / mem_free_total, 2)))\n\n    while True:\n        try:\n            slice_size = q.shape[1] // steps if (q.shape[1] % steps) == 0 else q.shape[1]\n            for i in range(0, q.shape[1], slice_size):\n                end = i + slice_size\n                s1 = torch.bmm(q[:, i:end], k) * scale\n\n                s2 = torch.nn.functional.softmax(s1, dim=2).permute(0,2,1)\n                del s1\n\n                r1[:, :, i:end] = torch.bmm(v, s2)\n                del s2\n            break\n        except model_management.OOM_EXCEPTION as e:\n            model_management.soft_empty_cache(True)\n            steps *= 2\n            if steps > 128:\n                raise e\n            logging.warning(\"out of memory error, increasing steps and trying again {}\".format(steps))\n\n    return r1\n\n", "CodeBleu_score": 24.964222891117227}]}
{"instance_id": "fe4433c987ad", "generation_result": [{"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        if control.name == name:\n            if control.add(h):\n                return h\n            else:\n                log.warning('Failed to add control to h.')\n    return h\n\n", "CodeBleu_score": 26.09177402853152}, {"code": "def apply_control(h, control, name)\n\t\n    if name in control:\n        if not h.has_control(name):\n            h.add_control(control.pop(name))\n        else:\n            h.set_control(name, control.pop(name))\n    else:\n        logger.warning(\"Control %s not found in %s\", name, control)\n\n", "CodeBleu_score": 26.34841702733007}, {"code": "def apply_control(h, control, name)\n\t\n    if control and name:\n        try:\n            h = h.add_control(control, name)\n        except Exception as e:\n            log.warning(\"Could not add control %s to %s: %s\" % (name, h, e))\n    return h\n\n", "CodeBleu_score": 32.60178508593082}]}
{"instance_id": "56da4547c101", "generation_result": [{"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # get the one-hot encoding of the indices\n    one_hot = tf.one_hot(indices, self.num_embeddings)\n    # multiply the one-hot encoding with the embedding weights\n    quantized_vectors = tf.matmul(one_hot, self.embedding_weights)\n    # reshape and permute the quantized vectors if a shape is provided\n    if shape is not None:\n        quantized_vectors = tf.reshape(quantized_vectors, shape)\n        quantized_vectors = tf.transpose(quantized_vectors, perm=[0, 2, 1, 3])\n    return quantized_vectors\n\n", "CodeBleu_score": 30.994232641009955}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    indices = indices.unsqueeze(-1).unsqueeze(-1)\n    one_hot = torch.zeros(indices.size() + (shape[-1],), device=indices.device)\n    one_hot.scatter_(-1, indices, 1)\n    return one_hot.matmul(self.embedding.weight).permute(0, 3, 1, 2)\n\n", "CodeBleu_score": 14.778957698777507}, {"code": "def get_codebook_entry(self, indices, shape)\n\t\n    # one-hot encoding\n    one_hot_encoding = tf.one_hot(indices, depth=self.num_embeddings)\n    # multiplying one-hot encoding with embedding weights\n    quantized_vectors = tf.matmul(one_hot_encoding, self.embedding_weights)\n    # reshaping and permuting the quantized vectors\n    if shape is not None:\n        quantized_vectors = tf.reshape(quantized_vectors, shape)\n        quantized_vectors = tf.transpose(quantized_vectors, perm=[0, 2, 1, 3])\n    return quantized_vectors\n\n", "CodeBleu_score": 31.82667459070162}]}
{"instance_id": "548f8a1fb37d", "generation_result": [{"code": "def make_noise(self)\n\t\n    noise = [torch.randn(4, 4, device=self.device)]\n    for i in range(3, self.log_size + 1):\n        noise.append(torch.randn(2 ** i, 2 ** i, device=self.device))\n    return noise\n\n", "CodeBleu_score": 29.43234279200515}, {"code": "def make_noise(self)\n\t\n    noise = [torch.zeros(4, 4, device=self.device)]\n    for i in range(3, self.log_size + 1):\n        noise.append(torch.zeros(2**i, 2**i, device=self.device))\n    return noise\n\n", "CodeBleu_score": 28.828110832925173}, {"code": "def make_noise(self)\n\t\n    noise_list = [torch.zeros(4, 4).to(self.device)]\n    for i in range(3, self.log_size + 1):\n        noise_list.append(torch.zeros(2 ** i, 2 ** i).to(self.device))\n    return noise_list\n\n", "CodeBleu_score": 27.319905361332285}]}
{"instance_id": "42fd805563c6", "generation_result": [{"code": "def mean_latent(self, num_latent)\n\t\n    latent = tf.random.normal([1, num_latent])\n    latent = self.style_mlp(latent)\n    latent = tf.reduce_mean(latent, axis=0)\n    return latent\n\n", "CodeBleu_score": 17.353143705098365}, {"code": "def mean_latent(self, num_latent)\n\t\n    # Create random latent inputs\n    latent_inputs = tf.random.normal(shape=(1, num_latent))\n    # Process the latent inputs through the style MLP\n    mean_latent = self.style_mlp(latent_inputs)\n    # Return the mean latent vector\n    return mean_latent\n", "CodeBleu_score": 18.132839878866346}, {"code": "def mean_latent(self, num_latent)\n\t\n    mean_latent = torch.randn(num_latent, self.latent_dim)\n    mean_latent = self.latent_mlp(mean_latent)\n    mean_latent = torch.mean(mean_latent, dim=0)\n    return mean_latent\n\n", "CodeBleu_score": 19.054683458863952}]}
{"instance_id": "2f485fd924af", "generation_result": [{"code": "def color_jitter(img, shift)\n\t\n    img = img.astype(np.float32)\n    for i in range(3):\n        img[:, :, i] += np.random.uniform(-shift, shift)\n    img = np.clip(img, 0, 1)\n    return img\n\n", "CodeBleu_score": 50.85690726692521}, {"code": "def color_jitter(img, shift)\n\t\n    # Get the shape of the image\n    height, width, channels = img.shape\n    # Get the range of values to shift the RGB channels by\n    shift_range = shift * 255\n    # Generate random values for each RGB channel\n    r_shift = np.random.randint(-shift_range, shift_range)\n    g_shift = np.random.randint(-shift_range, shift_range)\n    b_shift = np.random.randint(-shift_range, shift_range)\n    # Shift the RGB channels by the random values\n    img[:, :, 0] = np.clip(img[:, :, 0] + r_shift, 0, 255)\n    img[:, :, 1] = np.clip(img[:, :, 1] + g_shift, 0, 255)\n    img[:, :, 2] = np.clip(img[:, :, 2] + b_shift, 0, 255)\n    return img\n\n", "CodeBleu_score": 32.106021720971675}, {"code": "def color_jitter(img, shift)\n\t\n    # Generate random jitter values for each RGB channel\n    jitter = np.random.uniform(-shift, shift, size=(3,))\n\n    # Add the jitter values to the image\n    jittered_img = np.clip(img + jitter, 0, 1)\n\n    return jittered_img\n\n", "CodeBleu_score": 35.076573098295725}]}
{"instance_id": "c87ccf1fbf48", "generation_result": [{"code": "def feed_data(self, data)\n\t\n    if self.device == 'cpu':\n        self.lq = data['lq'].to(self.device)\n        if 'gt' in data:\n            self.gt = data['gt'].to(self.device)\n        if 'lefteye' in data:\n            self.lefteye = data['lefteye'].to(self.device)\n        if 'righteye' in data:\n            self.righteye = data['righteye'].to(self.device)\n        if'mouth' in data:\n            self.mouth = data['mouth'].to(self.device)\n    elif self.device == 'gpu':\n        self.lq = data['lq'].cuda()\n        if 'gt' in data:\n            self.gt = data['gt'].cuda()\n        if 'lefteye' in data:\n            self.lefteye = data['lefteye'].cuda()\n        if 'righteye' in data:\n            self.righteye = data['righteye'].cuda()\n        if'mouth' in data:\n            self.mouth = data['mouth'].cuda()\n    else:\n        raise NotImplementedError\n\n", "CodeBleu_score": 47.25939436849685}, {"code": "def feed_data(self, data)\n\t\n    if self.device == 'cpu':\n        self.lq = data['lq'].to(self.device)\n        if 'gt' in data:\n            self.gt = data['gt'].to(self.device)\n        if 'eyes' in data:\n            self.eyes = data['eyes'].to(self.device)\n        if'mouth' in data:\n            self.mouth = data['mouth'].to(self.device)\n    elif self.device == 'cuda':\n        self.lq = data['lq'].cuda()\n        if 'gt' in data:\n            self.gt = data['gt'].cuda()\n        if 'eyes' in data:\n            self.eyes = data['eyes'].cuda()\n        if'mouth' in data:\n            self.mouth = data['mouth'].cuda()\n\n", "CodeBleu_score": 49.52682563374051}, {"code": "def feed_data(self, data)\n\t\n    if self.use_cuda:\n        data = data.cuda()\n    self.lq = data['lq'].type(self.Tensor)\n    self.gt = data['gt'].type(self.Tensor)\n    self.eyes = data['eyes']\n    self.eyes_mask = data['eyes_mask']\n    self.eyes_mask_inv = data['eyes_mask_inv']\n    self.eyes_mask_inv_cuda = data['eyes_mask_inv_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_inv_cuda = data['eyes_mask_inv_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_mask_cuda']\n    self.eyes_mask_cuda = data['eyes_", "CodeBleu_score": 32.4542878344855}]}
{"instance_id": "8f8c7cb13037", "generation_result": [{"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.img_gt]\n    for i in range(self.num_pyramid_levels):\n        img_pyramid.insert(0, cv2.resize(img_pyramid[0], (0, 0), fx=self.downscale_factor, fy=self.downscale_factor, interpolation=cv2.INTER_LINEAR))\n    return img_pyramid\n\n", "CodeBleu_score": 20.549593172024753}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = [self.img_gt]\n    for i in range(self.num_scales):\n        img_pyramid.insert(0, cv2.resize(img_pyramid[0], (self.img_gt.shape[1] // 2, self.img_gt.shape[0] // 2), interpolation=cv2.INTER_LINEAR))\n    return img_pyramid\n\n", "CodeBleu_score": 19.997153280656583}, {"code": "def construct_img_pyramid(self)\n\t\n    img_pyramid = []\n    img_pyramid.append(self.img)\n    for i in range(self.num_levels):\n        img_pyramid.append(cv2.resize(img_pyramid[i], (0, 0), fx=0.5, fy=0.5, interpolation=cv2.INTER_LINEAR))\n    return img_pyramid\n\n", "CodeBleu_score": 19.577031087979766}]}
{"instance_id": "51247274d40c", "generation_result": [{"code": "def save(self, epoch, current_iter)\n\t\n    state = {\n        'epoch': epoch,\n        'iter': current_iter,\n        'G_state_dict': self.G.state_dict(),\n        'G_ema_state_dict': self.G_ema.state_dict(),\n        'D_state_dict': self.D.state_dict(),\n        'D_ema_state_dict': self.D_ema.state_dict(),\n        'D_l_state_dict': self.D_l.state_dict(),\n        'D_r_state_dict': self.D_r.state_dict(),\n        'D_m_state_dict': self.D_m.state_dict(),\n        'G_optimizer_state_dict': self.G_optimizer.state_dict(),\n        'D_optimizer_state_dict': self.D_optimizer.state_dict(),\n        'D_l_optimizer_state_dict': self.D_l_optimizer.state_dict(),\n        'D_r_optimizer_state_dict': self.D_r_optimizer.state_dict(),\n        'D_m_optimizer_state_dict': self.D_m_optimizer.state_dict(),\n        'training_state': self.training_state,\n        'G_ema_training_state': self.G_ema_training_state,\n        'D_ema_training_state': self.D_ema_training_state,\n        'D_l_ema_training_state': self.D_l_ema_training_state,\n        'D_r_ema_training_state': self.D_r_ema_training_state,\n        'D_m_ema_training_state': self.D_m_ema_training_state,\n        'G_ema_lambda': self.G_ema_lambda,\n        'D_ema_lambda': self.D_ema_lambda,\n        'D_l_ema_lambda': self.D_l_ema_lambda,\n        'D_r_ema_lambda': self.D_r_ema_lambda,\n        'D_m_ema_lambda': self.D_m_ema_lambda,\n        'G_ema_steps': self.G_ema_steps,\n        'D_ema_steps': self.D_ema_steps,\n        '", "CodeBleu_score": 25.074012410855907}, {"code": "def save(self, epoch, current_iter)\n\t\n    print(\"Saving model...\")\n    torch.save({\n        'generator': self.generator.state_dict(),\n        'generator_ema': self.generator_ema.state_dict(),\n        'discriminator': self.discriminator.state_dict(),\n        'epoch': epoch,\n        'iter': current_iter,\n        'training_state': self.training_state,\n        'discriminator_left': self.discriminator_left.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_right': self.discriminator_right.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_mouth': self.discriminator_mouth.state_dict() if self.use_facial_discriminator else None,\n        'generator_optimizer': self.generator_optimizer.state_dict(),\n        'discriminator_optimizer': self.discriminator_optimizer.state_dict(),\n        'generator_ema_optimizer': self.generator_ema_optimizer.state_dict(),\n        'discriminator_left_optimizer': self.discriminator_left_optimizer.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_right_optimizer': self.discriminator_right_optimizer.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_mouth_optimizer': self.discriminator_mouth_optimizer.state_dict() if self.use_facial_discriminator else None,\n        'generator_lr_scheduler': self.generator_lr_scheduler.state_dict(),\n        'discriminator_lr_scheduler': self.discriminator_lr_scheduler.state_dict(),\n        'generator_ema_lr_scheduler': self.generator_ema_lr_scheduler.state_dict(),\n        'discriminator_left_lr_scheduler': self.discriminator_left_lr_scheduler.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_right_lr_scheduler': self.discriminator_right_lr_scheduler.state_dict() if self.use_facial_discriminator else None,\n        'discriminator_mouth_lr_scheduler': self.discriminator_mouth_lr_scheduler.state_dict() if self.use_", "CodeBleu_score": 32.661858783167915}, {"code": "def save(self, epoch, current_iter)\n\t\n    if self.use_facial_discriminators:\n        save_path = os.path.join(self.checkpoint_dir, 'epoch_{}_iter_{}'.format(epoch, current_iter))\n        torch.save(self.generator, os.path.join(save_path, 'generator.pt'))\n        torch.save(self.generator_ema, os.path.join(save_path, 'generator_ema.pt'))\n        torch.save(self.discriminator, os.path.join(save_path, 'discriminator.pt'))\n        torch.save(self.discriminator_eye, os.path.join(save_path, 'discriminator_eye.pt'))\n        torch.save(self.discriminator_mouth, os.path.join(save_path, 'discriminator_mouth.pt'))\n        torch.save(self.discriminator_eye_mouth, os.path.join(save_path, 'discriminator_eye_mouth.pt'))\n        torch.save(self.state_dict(), os.path.join(save_path,'state_dict.pt'))\n    else:\n        save_path = os.path.join(self.checkpoint_dir, 'epoch_{}_iter_{}'.format(epoch, current_iter))\n        torch.save(self.generator, os.path.join(save_path, 'generator.pt'))\n        torch.save(self.generator_ema, os.path.join(save_path, 'generator_ema.pt'))\n        torch.save(self.discriminator, os.path.join(save_path, 'discriminator.pt'))\n        torch.save(self.state_dict(), os.path.join(save_path,'state_dict.pt'))\n\n", "CodeBleu_score": 31.827610448456507}]}
{"instance_id": "afa0dc8128c1", "generation_result": [{"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print('Failed to delete %s. Reason: %s' % (item_path, e))\n\n", "CodeBleu_score": 45.573796972052385}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        try:\n            if os.path.isfile(item_path):\n                os.unlink(item_path)\n            elif os.path.isdir(item_path):\n                shutil.rmtree(item_path)\n        except Exception as e:\n            print(f\"Error: {e}", "CodeBleu_score": 41.263792541486424}, {"code": "def clean_folder(folder)\n\t\n    for item in os.listdir(folder):\n        item_path = os.path.join(folder, item)\n        if os.path.isfile(item_path):\n            try:\n                os.unlink(item_path)\n            except Exception as e:\n                print(f\"Error while deleting {item_path}: {e}\")\n        elif os.path.isdir(item_path):\n            try:\n                shutil.rmtree(item_path)\n            except Exception as e:\n                print(f\"Error while deleting {item_path}: {e}\")\n\n", "CodeBleu_score": 45.96154824108699}]}
{"instance_id": "53588b481bdd", "generation_result": [{"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > self.num_experiences:\n        sample_size = self.num_experiences\n    batch_indices = np.random.choice(self.num_experiences, sample_size)\n    batch_states = np.array([self.states[i] for i in batch_indices])\n    batch_actions = np.array([self.actions[i] for i in batch_indices])\n    batch_rewards = np.array([self.rewards[i] for i in batch_indices])\n    batch_next_states = np.array([self.next_states[i] for i in batch_indices])\n    batch_dones = np.array([self.dones[i] for i in batch_indices])\n    self.states = np.delete(self.states, batch_indices, axis=0)\n    self.actions = np.delete(self.actions, batch_indices, axis=0)\n    self.rewards = np.delete(self.rewards, batch_indices, axis=0)\n    self.next_states = np.delete(self.next_states, batch_indices, axis=0)\n    self.dones = np.delete(self.dones, batch_indices, axis=0)\n    return batch_states, batch_actions, batch_rewards, batch_next_states, batch_dones\n\n", "CodeBleu_score": 28.698954527702234}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.memory):\n        sample_size = len(self.memory)\n    return random.sample(self.memory, sample_size)\n\n", "CodeBleu_score": 32.782246025742744}, {"code": "def next_batch(self, sample_size=1)\n\t\n    if sample_size > len(self.memory):\n        sample_size = len(self.memory)\n    batch = random.sample(self.memory, sample_size)\n    return batch\n\n", "CodeBleu_score": 44.09666993059672}]}
{"instance_id": "6bfa6a4e621c", "generation_result": [{"code": "def find_estimated_top_configs(self)\n\t\n    # flatten all_configs\n    all_configs_flat = [config for config in self.all_configs]\n    for config in self.all_configs:\n        for subconfig in config:\n            all_configs_flat.append(subconfig)\n\n    # collect numerical values\n    all_configs_num = np.array([self.numerical_value(config) for config in all_configs_flat])\n\n    # sort indices\n    sorted_indices = np.argsort(all_configs_num)\n\n    # return indices of top configs\n    return sorted_indices[::-1][:self.top_configs]\n\n", "CodeBleu_score": 21.313578067087786}, {"code": "def find_estimated_top_configs(self)\n\t\n    if self.cost_model is not None:\n        all_configs = self.all_configs\n        all_configs_numerical = np.array(\n            [\n                self.cost_model.get_numerical_values(config)\n                for config in all_configs\n            ]\n        )\n        sorted_indices = np.argsort(all_configs_numerical, axis=0)\n        top_configs = all_configs[sorted_indices[-self.num_top_configs :]]\n        return top_configs\n    else:\n        return self.all_configs\n\n", "CodeBleu_score": 25.514849249330503}, {"code": "def find_estimated_top_configs(self)\n\t\n    all_configs = self.all_configs\n    metric = self.metric\n    cost_model = self.cost_model\n    if self.cost_model is None:\n        raise ValueError(\"No cost model was provided.\")\n    if self.metric is None:\n        raise ValueError(\"No metric was provided.\")\n    if self.metric not in [\"cost\", \"accuracy\", \"precision\", \"recall\"]:\n        raise ValueError(\"Metric must be one of 'cost', 'accuracy', 'precision', or'recall'.\")\n    if self.metric == \"cost\":\n        metric_name = \"cost\"\n    elif self.metric == \"accuracy\":\n        metric_name = \"accuracy\"\n    elif self.metric == \"precision\":\n        metric_name = \"precision\"\n    elif self.metric == \"recall\":\n        metric_name = \"recall\"\n    if len(all_configs) == 0:\n        raise ValueError(\"No configurations were provided.\")\n    all_configs = self.flatten_configs(all_configs)\n    if len(all_configs) == 0:\n        raise ValueError(\"No configurations were provided.\")\n    if self.metric == \"cost\":\n        all_configs = np.array(all_configs)\n        all_configs = all_configs[:, 1:]\n        all_configs = all_configs.astype(float)\n    else:\n        all_configs = np.array(all_configs)\n        all_configs = all_configs[:, 2:]\n        all_configs = all_configs.astype(float)\n    if self.metric == \"cost\":\n        all_configs = all_configs[:, 1:]\n        all_configs = all_configs.astype(float)\n    else:\n        all_configs = all_configs[:, 2:]\n        all_configs = all_configs.astype(float)\n    if self.metric == \"cost\":\n        all_configs = all_configs[:, 1:]\n        all_configs = all_configs.astype(float)\n    else:\n        all_configs = all_configs[:, 2:]\n        all_configs = all_configs.astype(float)\n    if self.metric == \"cost\":\n        all_configs = all_configs[:, 1:]\n        all_configs = all_configs.astype(float)\n    else:\n        all_configs = all_configs[:, 2:]\n        all_configs = all_configs.astype(float)\n    if self.metric == \"cost", "CodeBleu_score": 18.773221994116344}]}
{"instance_id": "d4cf48413a57", "generation_result": [{"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}, {"code": "def flatten(d, parent_key='', sep='_')\n\t\n    items = []\n    for k, v in d.items():\n        new_key = parent_key + sep + k if parent_key else k\n        if isinstance(v, collections.abc.MutableMapping):\n            items.extend(flatten(v, new_key, sep=sep).items())\n        else:\n            items.append((new_key, v))\n    return dict(items)\n\n", "CodeBleu_score": 83.2096634628176}]}
{"instance_id": "c2a514249c25", "generation_result": [{"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd:\n        self.logger.info('Running optimal command: %s' % self.optimal_cmd)\n        p = subprocess.Popen(self.optimal_cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n        p.wait()\n        self.logger.info('Command completed successfully.')\n    else:\n        self.logger.info('Autotuning did not find an optimal configuration.')\n\n", "CodeBleu_score": 47.354696668701116}, {"code": "def run_after_tuning(self)\n\t\n    if self.optimal_cmd is not None:\n        self.log.info(\"Running optimal command: \" + self.optimal_cmd)\n        process = subprocess.Popen(self.optimal_cmd, shell=True)\n        process.wait()\n        self.log.info(\"Optimal command completed.\")\n    else:\n        self.log.info(\"No optimal command found.\")\n\n", "CodeBleu_score": 48.037381606094655}, {"code": "def run_after_tuning(self)\n\t\n    if hasattr(self, 'optimal_cmd'):\n        try:\n            self.logger.info(\"Running optimal command: %s\", self.optimal_cmd)\n            subprocess.Popen(self.optimal_cmd, shell=True)\n            self.logger.info(\"Command finished.\")\n        except OSError:\n            self.logger.error(\"Error running optimal command: %s\", self.optimal_cmd)\n    else:\n        self.logger.info(\"No optimal command found.\")\n\n", "CodeBleu_score": 36.822149764608504}]}
{"instance_id": "61802de52df0", "generation_result": [{"code": "def run_job(self, exp: dict, reservations)\n\t\n    # Set the experiment's master port and result directory.\n    self.master_port = self.master_port_prefix + str(self.master_port_counter)\n    self.result_dir = self.result_dir_prefix + str(self.result_dir_counter)\n    self.master_port_counter += 1\n    self.result_dir_counter += 1\n    # Update user arguments based on argument mappings.\n    for arg_name, arg_value in exp['arg_mappings'].items():\n        if arg_value is None:\n            continue\n        if arg_name in self.args:\n            self.args[arg_name] = arg_value\n        else:\n            raise Exception(f\"Argument '{arg_name}' is not in the list of user arguments.\")\n    # Start the experiment in a new thread.\n    thread = threading.Thread(target=self.run_experiment, args=(exp, reservations))\n    thread.start()\n    # Store the running experiment details.\n    self.running_experiments[exp['name']] = {\n        'thread': thread,\n        'exp': exp,\n       'reservations': reservations\n    }\n\n", "CodeBleu_score": 28.662214748091664}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    self.logger.info(f\"Starting experiment: {exp['name']}\")\n    exp['master_port'] = self.master_port\n    exp['result_dir'] = self.result_dir\n    exp['args'] = self.update_args(exp['args'], reservations)\n    self.logger.debug(f\"Experiment arguments: {exp['args']}\")\n    exp['thread'] = threading.Thread(target=self.run_experiment, args=(exp,))\n    exp['thread'].start()\n    self.running_experiments.append(exp)\n    self.logger.debug(f\"Running experiments: {self.running_experiments}\")\n    return exp['thread']\n\n", "CodeBleu_score": 24.397726080532117}, {"code": "def run_job(self, exp: dict, reservations)\n\t\n    # Create a new thread to run the experiment\n    thread = threading.Thread(target=self.run_experiment, args=(exp, reservations))\n    # Start the thread\n    thread.start()\n    # Update the running experiments list with the experiment's details\n    self.running_experiments.append({\n        \"experiment\": exp,\n        \"thread\": thread,\n        \"start_time\": datetime.now(),\n        \"master_port\": self.master_port\n    })\n    # Increment the master port for the next experiment\n    self.master_port += 1\n\n", "CodeBleu_score": 13.429381014193464}]}
{"instance_id": "4884e2e9665c", "generation_result": [{"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if not self.distributed_training:\n        return\n    if self.logging_permitted:\n        message = self.rank + message\n        self.save_to_file(message, path)\n\n", "CodeBleu_score": 10.975576393868167}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if self.distributed:\n        rank = self.get_rank()\n        if rank == 0:\n            if path is not None:\n                with open(path, 'a+') as f:\n                    f.write(message)\n                    f.write('", "CodeBleu_score": 19.832531585692166}, {"code": "def save_exp_results_to_database(self, message, ranks=None, path=None):\n\t\n    if self.distributed_initialized and self.distributed_rank == 0:\n        if self.distributed_initialized and self.distributed_rank == 0:\n            self.log_message(message, ranks, path)\n            self.log_message(message, ranks, path)\n        else:\n            self.log_message(message, ranks, path)\n\n", "CodeBleu_score": 18.051501243607483}]}
{"instance_id": "0429344c3c4d", "generation_result": [{"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if self.tp_degree == 1:\n        return {0: [layer_index]}\n    layer_prefix = self.layer_prefix\n    layer_files = self.get_layer_files(layer_index)\n    if not layer_files:\n        return {}\n    layer_files = sorted(layer_files)\n    layer_files_len = len(layer_files)\n    layer_files_per_partition = int(layer_files_len / self.tp_degree)\n    layer_files_per_partition_remainder = layer_files_len % self.tp_degree\n    layer_files_per_partition_list = [layer_files_per_partition for _ in range(self.tp_degree)]\n    if layer_files_per_partition_remainder:\n        layer_files_per_partition_list[0] += layer_files_per_partition_remainder\n    layer_files_per_partition_dict = dict(zip(range(self.tp_degree), layer_files_per_partition_list))\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    if layer_files_per_partition_dict_sum!= layer_files_len:\n        raise RuntimeError(\"Layer files per partition dictionary sum is not equal to the layer files length.\")\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_per_partition_dict_sum = sum(layer_files_per_partition_dict.values())\n    layer_files_", "CodeBleu_score": 27.929617669010625}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n\n    # Check if there are any layer files\n    if not self.layer_files:\n        raise RuntimeError(\"No layer files found.\")\n\n    # Verify the layer index\n    if layer_index < 0 or layer_index >= self.num_layers:\n        raise ValueError(f\"Invalid layer index: {layer_index}\")\n\n    # Retrieve files with a specific prefix for the given layer\n    layer_prefix = f\"layer_{layer_index}\"\n    layer_files = [file for file in self.layer_files if file.startswith(layer_prefix)]\n\n    # Partition files based on tp_degree\n    tp_degree = self.tp_degree\n    tp_other_layer_map = {i: [] for i in range(tp_degree)}\n    for file in layer_files:\n        tp_index = int(file[len(layer_prefix) + 1 :])\n        tp_other_layer_map[tp_index].append(file)\n\n    return tp_other_layer_map\n\n", "CodeBleu_score": 30.267328901212032}, {"code": "def _build_tp_other_layer_map(self, layer_index: int)\n\t\n    if not self.tp_other_layer_files:\n        return None\n    if layer_index < 0 or layer_index >= len(self.tp_other_layer_files):\n        return None\n    layer_files = self.tp_other_layer_files[layer_index]\n    layer_prefix = self.tp_other_layer_prefix[layer_index]\n    layer_map = {}\n    for i in range(self.tp_degree):\n        layer_map[i] = []\n    for f in layer_files:\n        if f.startswith(layer_prefix):\n            partition_index = int(f[len(layer_prefix):])\n            layer_map[partition_index].append(f)\n    return layer_map\n\n", "CodeBleu_score": 38.3083901053091}]}
{"instance_id": "1b65ecb9be93", "generation_result": [{"code": "def system_info()\n\t\n    system_info = {}\n    system_info[\"OS\"] = platform.system()\n    system_info[\"Architecture\"] = platform.architecture()[0]\n    system_info[\"Version\"] = platform.version()\n    system_info[\"Processor\"] = platform.processor()\n    system_info[\"Python Version\"] = platform.python_version()\n    return system_info\n\n", "CodeBleu_score": 40.79005840979429}, {"code": "def system_info()\n\t\n    system_info = {\n        \"OS\": platform.system(),\n        \"Architecture\": platform.architecture(),\n        \"Version\": platform.version(),\n        \"Processor\": platform.processor(),\n        \"Python Version\": platform.python_version()\n    }\n    return system_info\n\n", "CodeBleu_score": 54.31651943402144}, {"code": "def system_info()\n\t\n\n    info = {}\n    info['OS'] = platform.system()\n    info['ARCH'] = platform.architecture()[0]\n    info['VERSION'] = platform.version()\n    info['PROCESSOR'] = platform.processor()\n    info['PYTHON'] = platform.python_version()\n\n    return info\n\n", "CodeBleu_score": 41.43460165177775}]}
{"instance_id": "969bcc5cf3b5", "generation_result": [{"code": "def cuda_info()\n\t\n    if torch.cuda.is_available():\n        device_names = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n        return device_names\n    else:\n        return \"CUDA is not available\"\n\n", "CodeBleu_score": 60.05039074003706}, {"code": "def cuda_info()\n\t\n    device_names = [\n        gpu.name for gpu in GPUtil.getGPUs()\n    ]\n    cuda_avail = torch.cuda.is_available()\n    cuda_version = torch.version.cuda\n    return device_names, cuda_avail, cuda_version\n\n", "CodeBleu_score": 29.157945050934725}, {"code": "def cuda_info()\n\t\n    gpu_info = []\n    cuda_info = []\n    cuda_version = []\n    cuda_avail = []\n    cuda_name = []\n    cuda_name = [torch.cuda.get_device_name(i) for i in range(torch.cuda.device_count())]\n    cuda_avail = [torch.cuda.is_available() for i in range(torch.cuda.device_count())]\n    cuda_version = [torch.version.cuda for i in range(torch.cuda.device_count())]\n    for i in range(torch.cuda.device_count()):\n        gpu_info.append(\n            \"Device \"\n            + str(i)\n            + \": \"\n            + cuda_name[i]\n            + \" is available: \"\n            + str(cuda_avail[i])\n            + \" and the CUDA version is: \"\n            + str(cuda_version[i])\n        )\n    return gpu_info\n\n", "CodeBleu_score": 49.8924892791541}]}
{"instance_id": "a2ba908a4c70", "generation_result": [{"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    if encoder_manager.config.encoder_accuracy_criteria is None:\n        return\n    print(\"Computing encoder accuracy for\", encoder_manager.config.encoder_accuracy_criteria)\n    if encoder_manager.config.encoder_accuracy_criteria == \"class_name\":\n        if encoder_manager.config.encoder_accuracy_class_id_to_class_name_mapping is None:\n            print(\"No class ID to class name mapping is available. Please provide a mapping in the configuration file.\")\n            return\n        class_id_to_class_name_mapping = encoder_manager.config.encoder_accuracy_class_id_to_class_name_mapping\n    else:\n        class_id_to_class_name_mapping = None\n    if encoder_manager.config.encoder_accuracy_class_id_to_class_name_mapping is not None:\n        if encoder_manager.config.encoder_accuracy_class_id_to_class_name_mapping.startswith(\"file:\"):\n            class_id_to_class_name_mapping = load_json(encoder_manager.config.encoder_accuracy_class_id_to_class_name_mapping)\n    for item in dataset_items:\n        if not item.audio_file:\n            print(\"No audio file is available for item\", item.item_id)\n            continue\n        audio_file = item.audio_file\n        embedding = encoder_manager.compute_embedding(audio_file)\n        if embedding is None:\n            print(\"No embedding is available for item\", item.item_id)\n            continue\n        if encoder_manager.config.encoder_accuracy_criteria == \"class_name\":\n            if class_id_to_class_name_mapping is None:\n                print(\"No class ID to class name mapping is available. Please provide a mapping in the configuration file.\")\n                return\n            class_name = class_id_to_class_name_mapping.get(item.class_id)\n            if class_name is None:\n                print(\"No class name is available for class ID\", item.class_id)\n                continue\n        else:\n            class_name = item.class_name\n        prediction = encoder_manager.predict(embedding)\n        if prediction is None:\n            print(\"No prediction is available for item\", item.item_id)\n            continue\n        if prediction.class_name == class_name:\n           ", "CodeBleu_score": 26.207439252653252}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    print(\"Computing encoder accuracy...\")\n    print(\"Dataset items: {}\".format(len(dataset_items)))\n\n    class_name_key_to_id = encoder_manager.get_class_name_key_to_id()\n    class_name_id_to_name = encoder_manager.get_class_name_id_to_name()\n\n    class_name_key_to_id_map = encoder_manager.get_class_name_key_to_id_map()\n    class_name_id_to_name_map = encoder_manager.get_class_name_id_to_name_map()\n\n    accuracy_per_class = {}\n    accuracy_per_class_map = {}\n    total_accuracy = 0\n    total_accuracy_map = 0\n\n    for item in dataset_items:\n        audio_file = item.get_audio_file()\n        audio_file_path = os.path.join(encoder_manager.get_audio_dir(), audio_file)\n        if not os.path.isfile(audio_file_path):\n            print(\"Audio file not found: {}\".format(audio_file_path))\n            continue\n\n        embedding = encoder_manager.compute_embedding(audio_file_path)\n        if embedding is None:\n            print(\"Failed to compute embedding for audio file: {}\".format(audio_file_path))\n            continue\n\n        if class_name_key_to_id is not None and class_name_id_to_name is not None:\n            class_name_key = item.get_class_name_key()\n            class_name_id = class_name_key_to_id.get(class_name_key)\n            if class_name_id is None:\n                print(\"Class name key not found in class name key to ID mapping: {}\".format(class_name_key))\n                continue\n\n            class_name = class_name_id_to_name.get(class_name_id)\n            if class_name is None:\n                print(\"Class name ID not found in class name ID to name mapping: {}\".format(class_name_id))\n                continue\n\n            predicted_class_name_key = encoder_manager.predict(embedding)\n            predicted_class_name_id = class_name_key_to_id.get(predicted_class_name_key)\n           ", "CodeBleu_score": 28.920690060538355}, {"code": "def compute_encoder_accuracy(dataset_items, encoder_manager)\n\t\n    if encoder_manager.config.get('class_name_key', None) is None:\n        raise ValueError('Class name key is not set in the encoder manager configuration.')\n    class_name_key = encoder_manager.config.get('class_name_key')\n    class_name_id_map = encoder_manager.config.get('class_name_id_map', None)\n    if class_name_id_map is None:\n        class_name_id_map = {}\n    accuracy_dict = {}\n    for item in dataset_items:\n        audio_file = item[encoder_manager.config.get('audio_file_key')]\n        embedding = encoder_manager.compute_embedding(audio_file)\n        if encoder_manager.config.get('class_id_key', None) is None:\n            class_name = item[class_name_key]\n            class_id = class_name_id_map.get(class_name, None)\n            if class_id is None:\n                raise ValueError(f'Class name {class_name} is not found in the class name ID map.')\n            predicted_class_name = encoder_manager.predict(embedding, class_id)\n        else:\n            class_id = item[encoder_manager.config.get('class_id_key')]\n            predicted_class_name = encoder_manager.predict(embedding, class_id)\n        true_class_name = item[class_name_key]\n        if true_class_name not in accuracy_dict:\n            accuracy_dict[true_class_name] = 0\n        accuracy_dict[true_class_name] += 1 if predicted_class_name == true_class_name else 0\n    for class_name in accuracy_dict:\n        accuracy = accuracy_dict[class_name] / len(dataset_items)\n        print(f'Accuracy for class {class_name}: {accuracy:.4f}')\n    average_accuracy = sum(accuracy_dict.values()) / len(accuracy_dict)\n    print(f'Average accuracy: {average_accuracy:.4f}')\n\n", "CodeBleu_score": 35.91012476132397}]}
{"instance_id": "e01ec69ad58a", "generation_result": [{"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the output path\n    output_path = os.path.join(output_dir, os.path.basename(audio_path))\n\n    # check if the file already exists\n    if os.path.exists(output_path) and not force:\n        print(f\"> The file {output_path} already exists. Use force=True to overwrite the file.\")\n        return output_path, False\n\n    # create the output directory if it does not exist\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    # remove silence from the audio\n    output_path, is_speech = remove_silence(model_and_utils, audio_path, output_path, vad_sample_rate, trim_just_beginning_and_end, use_cuda)\n\n    return output_path, is_speech\n\n", "CodeBleu_score": 40.163884703143424}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the output path\n    out_path = audio_path.replace(\n        \"/input/\", \"/output/\"\n    )  # replace the input directory path with the output directory path\n    out_path = os.path.join(out_path, os.path.basename(audio_path))  # join the output directory path with the file name\n\n    # if the file already exists and force is not specified, return the output path and a False flag\n    if os.path.exists(out_path) and not force:\n        return out_path, False\n\n    # create the necessary directory structure\n    if not os.path.exists(os.path.dirname(out_path)):\n        os.makedirs(os.path.dirname(out_path))\n\n    # remove silence from the audio and save the processed audio\n    out_path, is_speech = remove_silence(\n        model_and_utils=model_and_utils, audio_path=audio_path, out_path=out_path, vad_sample_rate=8000, use_cuda=False\n    )\n\n    return out_path, is_speech\n", "CodeBleu_score": 37.262429336897874}, {"code": "def adjust_path_and_remove_silence(audio_path)\n\t   # get the file name and extension\n    file_name, file_extension = os.path.splitext(os.path.basename(audio_path))\n\n    # get the output path\n    output_path = os.path.join(output_dir, file_name + \"_processed\" + file_extension)\n\n    # check if the file already exists\n    if os.path.exists(output_path):\n        if not force:\n            print(f\"> The file {output_path} already exists. Please use the force parameter to overwrite the existing file.\")\n            return output_path, False\n        else:\n            print(f\"> The file {output_path} already exists. Overwriting...\")\n\n    # get the audio path\n    audio_path = os.path.join(input_dir, audio_path)\n\n    # check if the file exists\n    if not os.path.exists(audio_path):\n        print(f\"> \u2757 The file {audio_path} does not exist.\")\n        return None, False\n\n    # remove silence from the audio\n    _, is_speech = remove_silence(model_and_utils, audio_path, output_path, trim_just_beginning_and_end=True)\n\n    return output_path, is_speech\n\n", "CodeBleu_score": 36.65004580428286}]}
{"instance_id": "7e0bdb0feff8", "generation_result": [{"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    if not os.path.isdir(output_dir):\n        os.mkdir(output_dir)\n    os.chdir(input_dir)\n    files = glob.glob(\"*.\" + file_ext)\n    if len(files) == 0:\n        print(\"No files found.\")\n        return\n    print(\"Resampling {} files...\".format(len(files)))\n    with Pool(n_jobs) as p:\n        p.map(resample_file, files)\n    print(\"Resampling complete.\")\n\n", "CodeBleu_score": 27.306224314999465}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n    if output_dir is None:\n        output_dir = input_dir\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    if not os.path.exists(input_dir):\n        print(\"Input directory does not exist.\")\n        return\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n    file_list = glob.glob(os.path.join(input_dir, f\"**/*.{file_ext}\"), recursive=True)\n    file_list = [file for file in file_list if os.path.isfile(file)]\n    if len(file_list) == 0:\n        print(\"No audio files found.\")\n        return\n    print(f\"Found {len(file_list)} audio files.\")\n    if n_jobs > 1:\n        with Pool(n_jobs) as p:\n            p.map(resample_file, file_list)\n    else:\n        for file in file_list:\n            resample_file(file)\n    print(f\"Resampled audio files to {output_sr} Hz.\")\n\n", "CodeBleu_score": 42.93386605781717}, {"code": "def resample_files(input_dir, output_sr, output_dir=None, file_ext=\"wav\", n_jobs=10)\n\t\n\n    if output_dir is None:\n        output_dir = input_dir\n\n    if not os.path.exists(output_dir):\n        os.makedirs(output_dir)\n\n    input_files = glob.glob(os.path.join(input_dir, \"*\" + file_ext))\n    input_files.sort()\n\n    output_files = [os.path.join(output_dir, os.path.basename(f)) for f in input_files]\n\n    # create a progress bar\n    pbar = tqdm(total=len(input_files))\n\n    # resample files in parallel\n    with Pool(n_jobs) as p:\n        p.starmap(resample_file, zip(input_files, output_files, repeat(output_sr)))\n\n    # print completion message\n    print(f\"Resampled {len(input_files)} files to {output_sr}Hz\")\n\n    # close progress bar\n    pbar.close()\n\n", "CodeBleu_score": 38.449948924115354}]}
{"instance_id": "a1351834ca57", "generation_result": [{"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    with torch.no_grad():\n        total_loss = 0\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            # reshape inputs to group samples of each class\n            inputs = inputs.reshape(num_classes_in_batch, num_utter_per_class, -1)\n            labels = labels.reshape(num_classes_in_batch, num_utter_per_class)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n        avg_loss = total_loss / (batch_idx + 1)\n        logger.info(f\"Evaluation loss: {avg_loss}\")\n        plot_embeddings(outputs.cpu().numpy(), num_classes_in_batch)\n    return avg_loss\n\n", "CodeBleu_score": 29.350209566022446}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    eval_loss = 0\n    with torch.no_grad():\n        for i, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            inputs = inputs.reshape(labels.size(0), -1)\n            labels = labels.reshape(-1)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            eval_loss += loss.item()\n            if i == 0:\n                embeddings = outputs.cpu().numpy()\n                ground_truth = labels.cpu().numpy()\n                num_classes_in_batch = len(np.unique(ground_truth))\n                fig = plot_embeddings(embeddings, num_classes_in_batch)\n                plt.show()\n    return eval_loss / len(data_loader)\n\n", "CodeBleu_score": 31.668303139575944}, {"code": "def evaluation(model, criterion, data_loader, global_step)\n\t\n    model.eval()\n    with torch.no_grad():\n        total_loss = 0\n        for batch_idx, (inputs, labels) in enumerate(data_loader):\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            inputs = inputs.view(-1, 1, 28, 28)\n            labels = labels.view(-1)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n        average_loss = total_loss / (batch_idx + 1)\n        print(\"Evaluation loss at step {}: {:.4f}\".format(global_step, average_loss))\n        embeddings = outputs.detach().cpu().numpy()\n        num_classes_in_batch = len(set(labels.numpy()))\n        plot_embeddings(embeddings, num_classes_in_batch)\n    return average_loss\n\n", "CodeBleu_score": 31.64670781603173}]}
{"instance_id": "565f8ed09916", "generation_result": [{"code": "def register_config(model_name: str) -> Coqpit\n\t\n    if model_name == \"xtts\":\n        from.xtts_config import XttsConfig\n        return XttsConfig\n    else:\n        try:\n            module_path = find_module(model_name, \"config\")\n            class_name = to_camel(model_name)\n            return getattr(module_path, class_name)\n        except ModuleNotFoundError:\n            raise ModuleNotFoundError(f\"No configuration class found for model {model_name}\")\n\n", "CodeBleu_score": 31.750621903392474}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    model_name = model_name.lower()\n    if model_name == \"xtts\":\n        from. import xtts_config\n        return xtts_config.XTTSConfig\n    else:\n        module_path = \"coqpit.models.\" + model_name + \".config\"\n        module = importlib.import_module(module_path)\n        class_name = to_camel(model_name)\n        return getattr(module, class_name)\n\n", "CodeBleu_score": 26.984563942692635}, {"code": "def register_config(model_name: str) -> Coqpit\n\t\n    model_name = model_name.lower()\n    if model_name == \"xtts\":\n        from.xtts import XttsConfig\n        return XttsConfig\n    config_name = to_camel(model_name) + \"Config\"\n    try:\n        config = importlib.import_module(f\"coqpit.{model_name}.config\")\n    except ModuleNotFoundError:\n        config = importlib.import_module(f\"coqpit.config\")\n    try:\n        config_class = getattr(config, config_name)\n    except AttributeError:\n        raise ModuleNotFoundError(f\"The {model_name} model does not have a configuration class.\")\n    return config_class\n\n", "CodeBleu_score": 44.377663402379895}]}
{"instance_id": "0ea7862506a7", "generation_result": [{"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = _read_json_with_comments(config_path)\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config_obj = config_class(config_dict)\n    return config_obj\n\n", "CodeBleu_score": 8.444302288202108}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = None\n    config_name = config_path.split(\".\")[-1]\n    if config_name == \"json\":\n        config_dict = read_json_with_comments(config_path)\n    elif config_name == \"yaml\":\n        with open(config_path, \"r\", encoding=\"utf-8\") as f:\n            config_dict = yaml.safe_load(f)\n    else:\n        raise ValueError(f\" [!] Unknown config file type {config_name}.\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config_obj = config_class()\n    config_obj.set_dict(config_dict)\n    return config_obj", "CodeBleu_score": 43.205619076976745}, {"code": "def load_config(config_path: str) -> Coqpit\n\t\n    config_dict = None\n    config_path = os.path.expanduser(config_path)\n    config_path = os.path.abspath(config_path)\n    if not os.path.exists(config_path):\n        raise FileNotFoundError(f\" [!] Config file {config_path} not found.\")\n    config_name = os.path.basename(config_path)\n    config_name = config_name.split(\".\")[0]\n    ext = config_name.split(\".\")[-1]\n    if ext == \"yaml\" or ext == \"yml\":\n        with open(config_path, \"r\") as f:\n            config_dict = yaml.safe_load(f)\n    elif ext == \"json\":\n        config_dict = read_json_with_comments(config_path)\n    else:\n        raise TypeError(f\" [!] Unknown config file extension {ext}.\")\n    model_name = _process_model_name(config_dict)\n    config_class = register_config(model_name)\n    config_obj = config_class()\n    config_obj.update_params(config_dict)\n    return config_obj", "CodeBleu_score": 55.17457294751791}]}
{"instance_id": "e0db68b63143", "generation_result": [{"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    # Recursively walk through the base directory and process each file\n    for root, dirs, files in os.walk(basePath):\n        for file in files:\n            # Check if the file contains the specified string\n            if contains is not None and contains not in file:\n                continue\n\n            # Check the file extension against valid extensions\n            if validExts is not None and file.split(\".\")[-1] not in validExts:\n                continue\n\n            # Construct and yield the full file path\n            fullPath = os.path.join(root, file)\n            yield fullPath\n\n", "CodeBleu_score": 40.40207842820959}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for root, dirs, files in os.walk(basePath):\n        for file in files:\n            if contains is not None and contains not in file:\n                continue\n            ext = os.path.splitext(file)[-1].lower()\n            if validExts is not None and ext not in validExts:\n                continue\n            yield os.path.join(root, file)\n\n", "CodeBleu_score": 40.20168512108912}, {"code": "def list_files(basePath, validExts=None, contains=None)\n\t\n    for root, dirs, files in os.walk(basePath):\n        for filename in files:\n            if contains is not None and contains not in filename:\n                continue\n            if validExts is not None and os.path.splitext(filename)[1][1:] not in validExts:\n                continue\n            yield os.path.join(root, filename)\n\n", "CodeBleu_score": 39.15275221394417}]}
{"instance_id": "b836fcaf0a27", "generation_result": [{"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    # clear the GPU cache\n    clear_gpu_cache()\n    # check if the required paths are provided\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: The required paths for checkpoint, config, and vocab are not provided.\"\n    # load the configuration from the provided path\n    config = load_config(xtts_config)\n    # initialize the XTTS model\n    model = XTTS(config)\n    # load the model checkpoint and vocabulary\n    model.load_checkpoint(checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab)\n    # move the model to the GPU if available\n    if torch.cuda.is_available():\n        model.cuda()\n    # print the loading progress message\n    print(\"XTTS model loaded successfully.\")\n    # return a success message\n    return \"XTTS model loaded successfully.\"\n\n", "CodeBleu_score": 47.02033270367713}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    clear_gpu_cache()\n    if not xtts_checkpoint or not xtts_config or not xtts_vocab:\n        return \"Error: Provide the required paths for the XTTS model, config, and vocab files.\"\n    config = load_config(xtts_config)\n    model = XTTSModel(config)\n    model.load_checkpoint(checkpoint_path=xtts_checkpoint, vocab_path=xtts_vocab)\n    if torch.cuda.is_available():\n        model.cuda()\n    print(\"XTTS model loaded successfully!\")\n    return model\n\n", "CodeBleu_score": 41.40085509763964}, {"code": "def load_model(xtts_checkpoint, xtts_config, xtts_vocab)\n\t\n    # clear the GPU cache\n    clear_gpu_cache()\n    # check if required paths are provided\n    if xtts_checkpoint is None or xtts_config is None or xtts_vocab is None:\n        return \"Error: Required paths not provided.\"\n    # load configuration from the provided path\n    config = load_config(xtts_config)\n    # initialize the XTTS model\n    model = XTTSModel(config)\n    # load the model checkpoint and vocabulary\n    model.load_checkpoint(\n        config,\n        checkpoint_dir=xtts_checkpoint,\n        vocab_path=xtts_vocab,\n        eval=True,\n        strict=True,\n    )\n    # move the model to the GPU if available\n    if torch.cuda.is_available():\n        model.cuda()\n    # print messages indicating the loading progress\n    print(\"Model loaded successfully.\")\n    return model\n\n", "CodeBleu_score": 49.06873328909198}]}
{"instance_id": "c5d63aa0df26", "generation_result": [{"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    if self.hop_length > 1:\n        num_frames = int(np.ceil(x.shape[0] / self.hop_length))\n    num_frames = min(num_frames, num_eval)\n    num_eval = min(num_frames, num_eval)\n    offsets = np.linspace(0, x.shape[0] - num_frames, num_eval, dtype=np.int)\n    x = x.unsqueeze(0)\n    x = x.expand(num_eval, -1)\n    x = torch.from_numpy(x).float()\n    x = self.preprocess(x)\n    x = x.cuda()\n    embeddings = self.inference(x)\n    if return_mean:\n        embeddings = embeddings.mean(dim=0)\n    if l2_norm:\n        embeddings = embeddings / torch.norm(embeddings)\n    return embeddings\n\n", "CodeBleu_score": 37.70236550088191}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    hop_length = self.hop_length\n    if self.use_torch:\n        num_frames = int(x.shape[0] / hop_length)\n    if num_frames > self.input_length:\n        num_frames = self.input_length\n    if num_frames < 1:\n        num_frames = 1\n    num_eval = min(num_eval, num_frames)\n    offset = np.linspace(0, num_frames - 1, num_eval, dtype=int)\n    embeddings = []\n    for i in offset:\n        if self.use_torch:\n            embedding = self.inference(x[i * hop_length: (i + 1) * hop_length])\n        else:\n            embedding = self.inference(x[i * hop_length: (i + 1) * hop_length].reshape(1, -1))\n        embeddings.append(embedding)\n    embeddings = torch.cat(embeddings, dim=0)\n    if return_mean:\n        embedding = embeddings.mean(dim=0)\n        if l2_norm:\n            embedding = embedding / torch.norm(embedding)\n        return embedding\n    else:\n        return embeddings\n\n", "CodeBleu_score": 38.62085169856767}, {"code": "def compute_embedding(self, x, num_frames=250, num_eval=10, return_mean=True, l2_norm=True)\n\t\n    hop_length = self.hop_length\n    if self.use_torch:\n        if num_frames is None:\n            num_frames = x.shape[0]\n        elif num_frames > x.shape[0]:\n            num_frames = x.shape[0]\n        else:\n            num_frames = int(num_frames)\n        if num_eval is None:\n            num_eval = int(num_frames / 2)\n        else:\n            num_eval = int(num_eval)\n        offset = np.linspace(0, num_frames - num_eval, num_eval, endpoint=False, dtype=np.int)\n        if self.use_cuda:\n            x = x.cuda()\n        else:\n            x = x.cpu()\n        x = x.reshape(1, 1, num_frames, 1)\n        x = torch.from_numpy(x)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(0, 2, 1, 3)\n        x = x.reshape(1, 1, num_eval, num_frames)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(0, 2, 1, 3)\n        x = x.reshape(1, 1, num_eval * num_frames)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(0, 2, 1)\n        x = x.reshape(1, num_eval * num_frames)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(1, 0)\n        x = x.reshape(num_eval * num_frames, 1)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(1, 0)\n        x = x.reshape(num_eval, num_frames)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(1, 0)\n        x = x.reshape(num_frames, num_eval)\n        x = x.type(torch.FloatTensor)\n        x = x.permute(1, 0)\n        x = x.reshape(num_frames, 1)\n        x = x.type(", "CodeBleu_score": 29.83648010298856}]}
{"instance_id": "06f5b0335b26", "generation_result": [{"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.54080921158837}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.54080921158837}, {"code": "def create_layer(self, block, planes, blocks, stride=1)\n\t\n    downsample = None\n    if stride!= 1 or self.inplanes!= planes * block.expansion:\n        downsample = nn.Sequential(\n            nn.Conv2d(self.inplanes, planes * block.expansion,\n                      kernel_size=1, stride=stride, bias=False),\n            nn.BatchNorm2d(planes * block.expansion),\n        )\n\n    layers = []\n    layers.append(block(self.inplanes, planes, stride, downsample))\n    self.inplanes = planes * block.expansion\n    for i in range(1, blocks):\n        layers.append(block(self.inplanes, planes))\n\n    return nn.Sequential(*layers)\n\n", "CodeBleu_score": 85.54080921158837}]}
{"instance_id": "9ac60597b633", "generation_result": [{"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    if num_classes_in_batch <= 10:\n        num_classes = num_classes_in_batch\n    else:\n        num_classes = 10\n    umap_transform = umap.UMAP(n_components=2, random_state=42)\n    umap_result = umap_transform.fit_transform(embeddings)\n    plt.figure(figsize=(10, 10))\n    plt.title(\"UMAP projection\", fontsize=24)\n    plt.scatter(\n        umap_result[:, 0],\n        umap_result[:, 1],\n        c=num_classes_in_batch,\n        s=0.1,\n        cmap=\"Spectral\",\n        alpha=0.5,\n    )\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    plt.colorbar(boundaries=np.arange(11) - 0.5).set_ticks(np.arange(10))\n    plt.savefig(\"umap.png\", dpi=300)\n    return plt\n\n", "CodeBleu_score": 33.06798967179756}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_classes = embeddings.shape[0] // num_classes_in_batch\n    if num_classes > 10:\n        num_classes = 10\n    # Create a UMAP object and fit it to the embeddings\n    umap_obj = UMAP(n_components=2)\n    umap_obj.fit(embeddings)\n    # Transform the embeddings\n    transformed_embeddings = umap_obj.transform(embeddings)\n    # Create a figure\n    fig = plt.figure(figsize=(10, 10))\n    # Plot the transformed embeddings\n    plt.scatter(transformed_embeddings[:, 0], transformed_embeddings[:, 1], c=range(num_classes), cmap=\"tab10\")\n    # Set the title\n    plt.title(\"UMAP projection\")\n    # Adjust the aspect ratio\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    # Save the figure\n    plt.savefig(\"umap.png\")\n    # Return the figure\n    return fig\n\n", "CodeBleu_score": 37.19091765795092}, {"code": "def plot_embeddings(embeddings, num_classes_in_batch)\n\t\n    # Calculate the number of utterances per class\n    num_per_class = embeddings.shape[0] // num_classes_in_batch\n    # Limit the number of classes to 10 if necessary\n    if num_classes_in_batch > 10:\n        num_classes_in_batch = 10\n    # Create the UMAP projection\n    reducer = umap.UMAP(n_components=2, random_state=42)\n    embedding = reducer.fit_transform(embeddings)\n    # Create the scatter plot\n    fig = plt.figure(figsize=(10, 10))\n    plt.scatter(embedding[:, 0], embedding[:, 1], c=y, cmap=\"tab10\")\n    plt.title(\"UMAP projection\", fontsize=24)\n    plt.axis(\"off\")\n    # Adjust the aspect ratio to equal\n    plt.gca().set_aspect(\"equal\", \"datalim\")\n    # Save the plot as an image\n    plt.savefig(\"umap.png\", bbox_inches=\"tight\")\n    # Return the figure\n    return fig\n\n", "CodeBleu_score": 42.669519137286585}]}
{"instance_id": "19c2b4af256d", "generation_result": [{"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    cosine_sim = []\n    for spkr in range(dvecs.shape[0]):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, 0)\n        for utt in range(1, dvecs.shape[1]):\n            new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n            cosine_sim.append(\n                torch.clamp(\n                    torch.sum(dvecs[spkr, utt] * new_centroids, dim=1) /\n                    (torch.norm(dvecs[spkr, utt]) * torch.norm(new_centroids, dim=1)),\n                    1e-10,\n                    1.0,\n                )\n            )\n    return torch.stack(cosine_sim).transpose(0, 1)\n\n", "CodeBleu_score": 38.94705622861478}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    sim_mat = []\n    for spkr in range(dvecs.size(0)):\n        excl = torch.cat(\n            (dvecs[spkr, :], dvecs[spkr, spkr + 1 :])\n        )  # exclude the current utterance\n        excl = torch.mean(excl, 0)\n        new_centroids = []\n        for i, centroid in enumerate(centroids):\n            if i == spkr:\n                new_centroids.append(excl)\n            else:\n                new_centroids.append(centroid)\n        new_centroids = torch.stack(new_centroids)\n        sim = torch.mm(dvecs[spkr], new_centroids.t())\n        sim = torch.clamp(sim, 0, 1)\n        sim_mat.append(sim)\n    sim_mat = torch.stack(sim_mat)\n    return sim_mat\n\n", "CodeBleu_score": 35.188286559257556}, {"code": "def calc_cosine_sim(self, dvecs, centroids)\n\t\n    sim_mat = []\n    for spkr in range(len(centroids)):\n        new_centroids = self.calc_new_centroids(dvecs, centroids, spkr, utt)\n        sim_mat.append(\n            torch.clamp(\n                torch.cosine_similarity(dvecs[spkr, :], new_centroids, dim=0),\n                min=1e-6,\n                max=1 - 1e-6,\n            )\n        )\n    return torch.stack(sim_mat)\n\n", "CodeBleu_score": 29.16805687861305}]}
{"instance_id": "c525b411a1e7", "generation_result": [{"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    losses = []\n    for i in range(self.num_embeddings):\n      dvec = dvecs[i]\n      cos_sim_matrix_i = cos_sim_matrix[i]\n      loss = self.compute_loss_softmax(dvec, cos_sim_matrix_i)\n      losses.append(loss)\n    return torch.stack(losses)\n\n\n def compute_loss_softmax(self, dvec, cos_sim_matrix):\n    \"\"\"The function calculates the negative log softmax of the cosine similarity matrix for a given embedding.", "CodeBleu_score": 31.741869232513142}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    # cos_sim_matrix = cos_sim_matrix.cpu()\n    # dvecs = dvecs.cpu()\n    # print(cos_sim_matrix.shape)\n    # print(dvecs.shape)\n    # print(cos_sim_matrix.device)\n    # print(dvecs.device)\n    # print(cos_sim_matrix)\n    # print(dvecs)\n    # print(cos_sim_matrix.dtype)\n    # print(dvecs.dtype)\n    # print(cos_sim_matrix.is_cuda)\n    # print(dvecs.is_cuda)\n    # print(cos_sim_matrix.device)\n    # print(dvecs.device)\n    # print(cos_sim_matrix.is_contiguous())\n    # print(dvecs.is_contiguous())\n    # print(cos_sim_matrix.requires_grad)\n    # print(dvecs.requires_grad)\n    # print(cos_sim_matrix.requires_grad)\n    # print(dvecs.requires_grad)\n    # print(cos_sim_matrix.grad)\n    # print(dvecs.grad)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)\n    # print(dvecs.grad_fn)\n    # print(cos_sim_matrix.grad_fn)", "CodeBleu_score": 2.26010101010101}, {"code": " def embed_loss_softmax(self, dvecs, cos_sim_matrix)\n\t\n    # calculate the loss for each embedding\n    loss_tensor = []\n    for i in range(self.n_embeddings):\n      loss_tensor.append(tf.nn.softmax_cross_entropy_with_logits_v2(labels=cos_sim_matrix[i], logits=dvecs[i]))\n\n    # stack the loss for each embedding\n    loss_tensor = tf.stack(loss_tensor)\n\n    # sum the loss for each embedding\n    loss_tensor = tf.reduce_sum(loss_tensor, axis=0)\n\n    return loss_tensor\n\n\n def embed_loss_cosine(self, dvecs, cos_sim_matrix):\n    \"\"\"The function calculates the embedding loss using cosine similarity.", "CodeBleu_score": 27.976359651335386}]}
{"instance_id": "25ac3945da2e", "generation_result": [{"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    embedding_loss = torch.zeros(len(dvecs), len(dvecs))\n    for i, dvec in enumerate(dvecs):\n        sigmoid_cos_sim = torch.sigmoid(cos_sim_matrix[i])\n        sigmoid_cos_sim[i] = 0\n        embedding_loss[i] = torch.sum(sigmoid_cos_sim, dim=1)\n    return embedding_loss\n\n", "CodeBleu_score": 14.763663170642538}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    loss_row = []\n    for i in range(dvecs.shape[0]):\n        row = []\n        for j in range(dvecs.shape[0]):\n            if i!= j:\n                row.append(torch.sigmoid(cos_sim_matrix[i, j]))\n            else:\n                row.append(0)\n        loss_row.append(row)\n    return torch.stack(loss_row)\n\n", "CodeBleu_score": 30.858885505403794}, {"code": "def embed_loss_contrast(self, dvecs, cos_sim_matrix)\n\t\n    loss_row = []\n    for i, dvec in enumerate(dvecs):\n        centroid_idxs = [j for j in range(len(dvecs)) if j!= i]\n        centroid_dvecs = dvecs[centroid_idxs]\n        centroid_cos_sim_matrix = cos_sim_matrix[centroid_idxs]\n        centroid_cos_sim_matrix = torch.sigmoid(centroid_cos_sim_matrix)\n        centroid_cos_sim_matrix = centroid_cos_sim_matrix.unsqueeze(0)\n        dvec = dvec.unsqueeze(0)\n        loss = torch.sum(centroid_cos_sim_matrix * (1 - dvec), dim=1)\n        loss_row.append(loss)\n    return torch.stack(loss_row, dim=0)\n\n", "CodeBleu_score": 29.56954309639281}]}
{"instance_id": "878d14ffabd2", "generation_result": [{"code": "def forward(self, x, _label=None)\n\t\n    if x.size(1) < 2:\n        raise ValueError(\"The input must have at least two utterances per speaker.\")\n    # make the cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, self.centroids)\n    # scale the cosine similarity matrix\n    cos_sim_matrix = self.scale_cos_sim_matrix(cos_sim_matrix)\n    # shift the cosine similarity matrix\n    cos_sim_matrix = self.shift_cos_sim_matrix(cos_sim_matrix)\n    # compute the embedding loss\n    embedding_loss = self.calc_embedding_loss(cos_sim_matrix)\n    # average the embedding loss\n    embedding_loss = embedding_loss.mean()\n    return embedding_loss\n\n", "CodeBleu_score": 36.125374539473235}, {"code": "def forward(self, x, _label=None)\n\t\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers < 2:\n        raise ValueError(\"The number of speakers must be greater than 1\")\n    if self.num_speakers", "CodeBleu_score": 13.193578787237783}, {"code": "def forward(self, x, _label=None)\n\t\n    # get the dimensions of the input data\n    num_speakers, num_utts_per_speaker, dvec_feats = x.size()\n    # ensure that there are at least two utterances per speaker\n    assert (\n        num_utts_per_speaker >= 2\n    ), \"Number of utterances per speaker must be at least 2.\"\n    # calculate the centroids\n    centroids = self.calc_centroids(x)\n    # calculate the cosine similarity matrix\n    cos_sim_matrix = self.calc_cosine_sim(x, centroids)\n    # scale and shift the cosine similarity matrix\n    scaled_cos_sim_matrix = self.scale_and_shift_cos_sim(cos_sim_matrix)\n    # calculate the embedding loss\n    embedding_loss = self.calc_embedding_loss(scaled_cos_sim_matrix)\n    # calculate the mean embedding loss\n    mean_embedding_loss = embedding_loss.mean()\n    return mean_embedding_loss", "CodeBleu_score": 22.82031531839579}]}
{"instance_id": "86a364c72caa", "generation_result": [{"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toices = {}\n    for voice_dir in extra_voice_dirs:\n        for root, dirs, files in os.walk(voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    voice_dir_name = os.path.basename(root)\n                    voices[voice_dir_name] = os.path.join(root, file)\n                elif file.endswith(\".wav\"):\n                    voice_dir_name = os.path.basename(root)\n                    voices[voice_dir_name] = os.path.join(root, file)\n                elif file.endswith(\".mp3\"):\n                    voice_dir_name = os.path.basename(root)\n                    voices[voice_dir_name] = os.path.join(root, file)\n    return voices\n\n", "CodeBleu_score": 28.277421358468885}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toice_dirs = get_voice_dirs()\n    for voice_dir in voice_dirs:\n        for root, dirs, files in os.walk(voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n                elif file.endswith(\".wav\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n                elif file.endswith(\".mp3\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n    for extra_voice_dir in extra_voice_dirs:\n        for root, dirs, files in os.walk(extra_voice_dir):\n            for file in files:\n                if file.endswith(\".npz\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n                elif file.endswith(\".wav\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n                elif file.endswith(\".mp3\"):\n                    voice_files[root] = voice_files.get(root, []) + [os.path.join(root, file)]\n    return voice_files\n\n", "CodeBleu_score": 21.7786998617715}, {"code": "def get_voices(extra_voice_dirs: List[str] = [])\n\toices = {}\n    for voice_dir in extra_voice_dirs:\n        voice_dir = Path(voice_dir)\n        if voice_dir.is_dir():\n            for subdir in voice_dir.iterdir():\n                if subdir.is_dir():\n                    voices[subdir.name] = []\n                    for file in subdir.iterdir():\n                        if file.is_file():\n                            if file.suffix == \".npz\":\n                                voices[subdir.name].append(str(file))\n                            elif file.suffix == \".wav\":\n                                voices[subdir.name].append(str(file))\n                            elif file.suffix == \".mp3\":\n                                voices[subdir.name].append(str(file))\n    return voices\n\n", "CodeBleu_score": 24.818600608417444}]}
{"instance_id": "02f20c8917e6", "generation_result": [{"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}, {"code": "def load_voice(model, voice: str, extra_voice_dirs: List[str] = [])\n\t  if voice == \"random\":\n        return None, None, None\n\n    voices = get_voices(extra_voice_dirs)\n    paths = voices[voice]\n\n    # bark only uses a single sample for cloning\n    if len(paths) > 1:\n        raise ValueError(f\"Voice {voice} has multiple paths: {paths}\")\n\n    try:\n        path = voices[voice]\n    except KeyError as e:\n        raise KeyError(f\"Voice {voice} not found in {extra_voice_dirs}\") from e\n\n    if len(paths) == 1 and paths[0].endswith(\".npz\"):\n        return load_npz(path[0])\n\n    audio_path = paths[0]\n    # replace the file extension with.npz\n    output_path = os.path.splitext(audio_path)[0] + \".npz\"\n    generate_voice(audio=audio_path, model=model, output_path=output_path)\n    return load_voice(model, voice, extra_voice_dirs)\n\n", "CodeBleu_score": 96.09328500721692}]}
{"instance_id": "9458e981389f", "generation_result": [{"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    dim = pos_score.size()\n    zeros = torch.zeros(dim[0], dim[1], 1).to(pos_score.device)\n    pos_score = torch.cat((zeros, pos_score), dim=2)\n    pos_score = pos_score.reshape(-1, dim[2] + 1)\n    pos_score = pos_score[:, 1:]\n    return pos_score\n\n", "CodeBleu_score": 23.451872317402756}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    dim = pos_score.dim()\n    zero = torch.zeros(1, *pos_score.shape[1:])\n    zero = zero.expand(dim, *pos_score.shape[1:])\n    return torch.cat([zero, pos_score], dim=0)[:, 1:]\n\n", "CodeBleu_score": 15.474102335940051}, {"code": "def _relative_shift(self, pos_score: torch.Tensor) -> torch.Tensor\n\t\n    return pos_score.view(*pos_score.shape, 1) + pos_score.view(1, *pos_score.shape)\n\n", "CodeBleu_score": 8.475247042719527}]}
{"instance_id": "c046d4f00e80", "generation_result": [{"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_len = context.shape[1]\n    if context_len < lens[0]:\n        context = F.pad(context, (0, 0, 0, lens[0] - context_len), value=0)\n    elif context_len > lens[0]:\n        context = context[:, :lens[0]]\n    for layer in self.layers:\n        context = layer(context)\n        if self.dropout > 0:\n            context = F.dropout(context, self.dropout, training=self.training)\n    return context\n\n", "CodeBleu_score": 23.950860360828557}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    context_output = self.conv_layers(context)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers2(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers3(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers4(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers5(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers6(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers7(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers8(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers9(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers10(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers11(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv_layers12(context_output)\n    context_output = torch.relu(context_output)\n    context_output = self.dropout(context_output)\n    context_output = self.conv", "CodeBleu_score": 6.180981117790281}, {"code": "def run_padded_sequence(self, context, lens)\n\t\n    return self.padded_sequence(context, lens)\n\n", "CodeBleu_score": 1.6537232163611297}]}
{"instance_id": "db2644f3c681", "generation_result": [{"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    if not isinstance(lens, torch.Tensor):\n        lens = torch.as_tensor(lens, device=context.device)\n    lens, indices = lens.sort(descending=True)\n    context = context[indices]\n    result = fn(context)\n    result = result[indices]\n    return result\n\n", "CodeBleu_score": 19.529217031020572}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    lengths = [len(x) for x in context]\n    sorted_indices = np.argsort(lengths)\n    sorted_context = [context[i] for i in sorted_indices]\n    sorted_lens = [lens[i] for i in sorted_indices]\n    packed_context = self.pack_sequence(sorted_context)\n    results = fn(packed_context, sorted_lens)\n    unpacked_results = self.unpack_sequence(results, sorted_lens)\n    unsorted_results = [unpacked_results[i] for i in sorted_indices]\n    return unsorted_results\n\n", "CodeBleu_score": 16.49516223414674}, {"code": "def run_unsorted_inputs(self, fn, context, lens)\n\t\n    # Sort the inputs based on their lengths\n    sorted_lengths, sorted_indices = torch.sort(lens, descending=True)\n    sorted_context = context[sorted_indices]\n    # Apply the function to the sorted inputs\n    results = fn(sorted_context)\n    # Unsort the results based on the original indices\n    unsorted_indices = torch.argsort(sorted_indices)\n    unsorted_results = results[unsorted_indices]\n    # Map the results back to the original indices\n    return unsorted_results\n\n", "CodeBleu_score": 8.479242512994261}]}
{"instance_id": "ced082bffc63", "generation_result": [{"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n", "CodeBleu_score": 70.15353357610886}, {"code": "def remove_weight_norm(self)\n\t\n    self.kernel_predictor.remove_weight_norm()\n    parametrize.remove_parametrizations(self.convt_pre[1], \"weight\")\n    for block in self.conv_blocks:\n        parametrize.remove_parametrizations(block[1], \"weight\")\n\n", "CodeBleu_score": 70.15353357610886}]}
{"instance_id": "b5a39fd97061", "generation_result": [{"code": "def map_mx_to_torch_model(mx_name)\n\t   if'se_' in mx_name:\n        return 'gluon_se_' + mx_name[mx_name.index('se_') + 3:]\n    if'senet_' in mx_name:\n        return 'gluon_senet_' + mx_name[mx_name.index('senet_') + 6:]\n    if 'inceptionv3' in mx_name:\n        return 'gluon_inceptionv3_' + mx_name[mx_name.index('inceptionv3') + 11:]\n    return 'gluon_' + mx_name.lower()\n\n", "CodeBleu_score": 26.928395135943017}, {"code": "def map_mx_to_torch_model(mx_name)\n\t   if mx_name.startswith('se_'):\n        mx_name = mx_name.replace('se_','senet_')\n    elif mx_name.startswith('senet_'):\n        mx_name = mx_name.replace('senet_','senet_')\n    elif mx_name.startswith('inceptionv3'):\n        mx_name = mx_name.replace('inceptionv3', 'inception_v3')\n    return 'gluon_' + mx_name.lower()\n\n", "CodeBleu_score": 45.337568528111206}, {"code": "def map_mx_to_torch_model(mx_name)\n\t   if mx_name.startswith('se_'):\n        return 'gluon_se_' + mx_name[3:]\n    elif mx_name.startswith('senet_'):\n        return 'gluon_senet_' + mx_name[6:]\n    elif mx_name.startswith('inceptionv3'):\n        return 'gluon_inceptionv3_' + mx_name[12:]\n    else:\n        return 'gluon_' + mx_name.lower()\n\n", "CodeBleu_score": 27.22766100826729}]}
{"instance_id": "7eee5efdbf67", "generation_result": [{"code": "def _num_samples_per_worker(self)\n\t\n    num_samples = self.num_samples\n    if self.num_workers > 0:\n        num_samples_per_worker = num_samples // self.num_workers\n        if self.num_samples % self.num_workers!= 0:\n            num_samples_per_worker += 1\n    else:\n        num_samples_per_worker = 1\n    if self.batch_size > 0:\n        num_samples_per_worker = (num_samples_per_worker // self.batch_size) * self.batch_size\n    return num_samples_per_worker\n\n", "CodeBleu_score": 31.40285664146892}, {"code": "def _num_samples_per_worker(self)\n\t\n    repeats = self.get_config('repeats')\n    total_samples = self.get_config('total_samples')\n    workers = self.get_config('workers')\n    if workers is None:\n        workers = 1\n    if workers > 1:\n        samples_per_worker = math.ceil(total_samples / workers)\n    else:\n        samples_per_worker = total_samples\n    if repeats is not None:\n        samples_per_worker *= repeats\n    if self.get_config('batch_size') is not None:\n        samples_per_worker = math.ceil(samples_per_worker / self.get_config('batch_size'))\n    return samples_per_worker\n\n", "CodeBleu_score": 29.150159274733006}, {"code": "def _num_samples_per_worker(self)\n\t\n    if self.num_workers is None:\n        num_samples = self.num_samples\n        if self.num_replicas > 1:\n            num_samples = math.ceil(num_samples / self.num_replicas)\n        if self.batch_size is not None:\n            num_samples = math.ceil(num_samples / self.batch_size)\n        return num_samples\n    else:\n        return self.num_samples\n\n", "CodeBleu_score": 35.249600403008586}]}
{"instance_id": "a698d65ae190", "generation_result": [{"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = [\".jpg\", \".png\", \".jpeg\"]\n    if class_to_idx is None:\n        class_to_idx = {}\n    images = []\n    targets = []\n    for root, dirs, files in os.walk(folder):\n        for file in files:\n            if file.lower().endswith(tuple(types)):\n                images.append(os.path.join(root, file))\n                if leaf_name_only:\n                    targets.append(os.path.basename(root))\n                else:\n                    targets.append(root)\n    if sort:\n        images, targets = zip(*sorted(zip(images, targets)))\n    for i, target in enumerate(targets):\n        if target not in class_to_idx:\n            class_to_idx[target] = i\n    return images, targets, class_to_idx\n\n", "CodeBleu_score": 34.28517415045373}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = ['jpg', 'jpeg', 'png']\n    if class_to_idx is None:\n        class_to_idx = {}\n    folder_path = Path(folder)\n    if not folder_path.is_dir():\n        raise ValueError(f\"The folder {folder} does not exist.\")\n    image_paths = []\n    image_classes = []\n    for root, _, files in os.walk(folder):\n        for file in files:\n            if file.split('.')[-1].lower() in types:\n                image_paths.append(os.path.join(root, file))\n                image_classes.append(root.split(os.path.sep)[-1])\n    image_paths = np.array(image_paths)\n    image_classes = np.array(image_classes)\n    if sort:\n        idx = np.argsort(image_classes)\n        image_paths = image_paths[idx]\n        image_classes = image_classes[idx]\n    if leaf_name_only:\n        image_classes = [os.path.split(path)[-1] for path in image_paths]\n    for label in image_classes:\n        if label not in class_to_idx:\n            class_to_idx[label] = len(class_to_idx)\n    image_classes = [class_to_idx[label] for label in image_classes]\n    return image_paths, image_classes, class_to_idx\n\n", "CodeBleu_score": 38.972715724830216}, {"code": "def find_images_and_targets(\n        folder: str,\n        types: Optional[Union[List, Tuple, Set]] = None,\n        class_to_idx: Optional[Dict] = None,\n        leaf_name_only: bool = True,\n        sort: bool = True\n)\n\t\n    if types is None:\n        types = ['jpg', 'jpeg', 'png']\n    if class_to_idx is None:\n        class_to_idx = {}\n\n    def get_class_to_idx(folder: str, types: List[str], class_to_idx: Dict):\n        for root, _, files in os.walk(folder):\n            for file in files:\n                if file.split('.')[-1] in types:\n                    class_name = os.path.basename(root)\n                    if class_name not in class_to_idx:\n                        class_to_idx[class_name] = len(class_to_idx)\n        return class_to_idx\n\n    def get_files_and_labels(folder: str, types: List[str], class_to_idx: Dict):\n        files_and_labels = []\n        for root, _, files in os.walk(folder):\n            for file in files:\n                if file.split('.')[-1] in types:\n                    class_name = os.path.basename(root)\n                    if class_name in class_to_idx:\n                        files_and_labels.append((os.path.join(root, file), class_to_idx[class_name]))\n        return files_and_labels\n\n    class_to_idx = get_class_to_idx(folder, types, class_to_idx)\n    files_and_labels = get_files_and_labels(folder, types, class_to_idx)\n\n    if sort:\n        files_and_labels.sort(key=natural_key)\n\n    if leaf_name_only:\n        files_and_labels = [file for file, _ in files_and_labels]\n\n    return files_and_labels, class_to_idx\n\n", "CodeBleu_score": 34.48624570765719}]}
{"instance_id": "e7fe43bdecdc", "generation_result": [{"code": "def pytorch_worker_seed()\n\t\n    return _pytorch_worker_seed()\n\n", "CodeBleu_score": 2.761889457221136}, {"code": "def pytorch_worker_seed()\n\t\n    return _pytorch_worker_seed()\n\n", "CodeBleu_score": 2.761889457221136}, {"code": "def pytorch_worker_seed()\n\t\n    return _pytorch_worker_seed\n\n", "CodeBleu_score": 2.545860912591809}]}
{"instance_id": "0ffc7e7ded25", "generation_result": [{"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in [\"L\", \"RGB\"]:\n        return img\n    if img.mode == \"L\":\n        return img.point(lambda p: p + add if p < thresh else p)\n    return img.point(lambda p: (p[0] + add[0], p[1] + add[1], p[2] + add[2]))\n\n", "CodeBleu_score": 27.411368134899867}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    if img.mode not in (\"L\", \"RGB\"):\n        return img\n\n    def _solarize_add(img, add, thresh):\n        img = img.convert(\"L\")\n        lut = [0] * 256\n        for i in range(256):\n            lut[i] = min(255, max(0, i + add))\n        return img.point(lut, \"1\")\n\n    return _solarize_add(img, add, thresh)\n\n", "CodeBleu_score": 35.12922497996268}, {"code": "def solarize_add(img, add, thresh=128, **__)\n\t\n    return img.point(lambda p: p + add if p < thresh else p)\n\n", "CodeBleu_score": 8.408023089807246}]}
{"instance_id": "5a0d29577a21", "generation_result": [{"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    weighted_transforms = []\n    for transform_name, transform_prob in transforms.items():\n        weighted_transforms.append(transform_name)\n        weighted_transforms.append(transform_prob)\n    return tuple(weighted_transforms)\n\n", "CodeBleu_score": 23.473168579975447}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    transform_names = []\n    transform_probabilities = []\n    for transform_name, transform_probability in transforms.items():\n        transform_names.append(transform_name)\n        transform_probabilities.append(transform_probability)\n    transform_probabilities = np.array(transform_probabilities)\n    transform_probabilities = transform_probabilities / transform_probabilities.sum()\n    return transform_names, transform_probabilities\n\n", "CodeBleu_score": 30.748467260689928}, {"code": "def _get_weighted_transforms(transforms: Dict)\n\t\n    weighted_transforms = []\n    weighted_probabilities = []\n    for transform, probability in transforms.items():\n        weighted_transforms.append(transform)\n        weighted_probabilities.append(probability)\n    weighted_probabilities = np.array(weighted_probabilities) / np.sum(weighted_probabilities)\n    return weighted_transforms, weighted_probabilities\n\n", "CodeBleu_score": 30.78119677620786}]}
{"instance_id": "84bc5658c135", "generation_result": [{"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed_img = np.zeros(img.shape)\n    for i, w in enumerate(mixing_weights):\n        aug_img = img.copy()\n        for _ in range(m):\n            aug_img = self.augment(aug_img)\n        mixed_img = np.clip(mixed_img * (1 - w) + aug_img * w, 0, 1)\n    return mixed_img\n\n", "CodeBleu_score": 18.408795449947423}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed_img = np.zeros(img.shape)\n    for i, weight in enumerate(mixing_weights):\n        ops = _get_ops(weight)\n        for op in ops:\n            img = op(img)\n        mixed_img = mixed_img * (1 - weight) + img * weight\n    mixed_img = np.clip(mixed_img, 0, 1)\n    mixed_img = (mixed_img * 255).astype(np.uint8)\n    return Image.fromarray(mixed_img)\n\n", "CodeBleu_score": 25.87465816711003}, {"code": "def _apply_basic(self, img, mixing_weights, m)\n\t\n    mixed_img = np.zeros(img.shape)\n    for w in mixing_weights:\n        mixed_img += w * self._apply_random_sequence(img, m)\n    mixed_img = np.clip(mixed_img, 0, 255)\n    return cv2.cvtColor(mixed_img.astype(np.uint8), cv2.COLOR_BGR2RGB)\n\n", "CodeBleu_score": 16.173856940088395}]}
{"instance_id": "84b5b752ff04", "generation_result": [{"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (tuple, list)):\n        x = tuple([x] * n)\n    elif len(x)!= n:\n        x = tuple([np.mean(x)] * n)\n    else:\n        assert len(x) == n\n    return x\n\n", "CodeBleu_score": 34.25797193938448}, {"code": "def adapt_to_chs(x, n)\n\t\n    if not isinstance(x, (list, tuple)):\n        x = (x,) * n\n    elif len(x)!= n:\n        x = (np.mean(x),) * n\n    else:\n        assert len(x) == n\n    return x\n\n", "CodeBleu_score": 31.76158189324547}, {"code": "def adapt_to_chs(x, n)\n\t\n    if isinstance(x, tuple) or isinstance(x, list):\n        if len(x) == n:\n            return x\n        elif len(x) > n:\n            return tuple(x[:n])\n        else:\n            mean = np.mean(x, axis=0)\n            return tuple(mean for _ in range(n))\n    else:\n        return tuple(x for _ in range(n))\n\n", "CodeBleu_score": 32.7279137752749}]}
{"instance_id": "54754b6ba394", "generation_result": [{"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = torch.utils.data.get_worker_info()\n    if worker_info is None:\n        return\n    worker_id = worker_info.id\n    if worker_seeding == 'all':\n        worker_seed = worker_info.seed\n        if worker_seed is None:\n            worker_seed = random.randint(0, 2 ** 31 - 1)\n        torch.manual_seed(worker_seed)\n        np.random.seed(worker_seed)\n        random.seed(worker_seed)\n    elif isinstance(worker_seeding, str):\n        np.random.seed(worker_info.seed)\n    elif callable(worker_seeding):\n        worker_seeding(worker_id)\n\n", "CodeBleu_score": 49.37887972154896}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = torch.utils.data.get_worker_info()\n    if worker_info is None:\n        return\n    if worker_id >= worker_info.num_workers:\n        return\n    worker_info.seed = worker_info.seed * 10 + worker_id\n    if worker_seeding == 'all':\n        seed = worker_info.seed\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        np.random.seed(seed)\n    elif isinstance(worker_seeding, str):\n        np.random.seed(worker_info.seed)\n    elif callable(worker_seeding):\n        worker_seeding(worker_info.seed)\n    else:\n        raise ValueError('worker_seeding should be either a string or a callable')\n\n", "CodeBleu_score": 43.55422846574618}, {"code": "def _worker_init(worker_id, worker_seeding='all')\n\t\n    worker_info = torch.utils.data.get_worker_info()\n    if worker_info is None:\n        return\n    worker_id = worker_info.id\n    if worker_id >= worker_info.num_workers:\n        return\n    if isinstance(worker_seeding, str):\n        if worker_seeding == 'all':\n            np.random.seed(worker_info.seed)\n        else:\n            raise ValueError('Invalid worker_seeding: {}'.format(worker_seeding))\n    elif callable(worker_seeding):\n        worker_seeding(worker_info.seed)\n    else:\n        raise ValueError('Invalid worker_seeding: {}'.format(worker_seeding))\n\n", "CodeBleu_score": 38.378649512830556}]}
{"instance_id": "81dfdce940db", "generation_result": [{"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image = tf.io.decode_jpeg(image_bytes, channels=3)\n    image_shape = tf.shape(image)\n    padded_center_crop_size = tf.cast(\n        tf.math.ceil(\n            (image_size / (image_size + 1)) * tf.cast(tf.reduce_min(image_shape[0:2]), tf.float32)\n        ),\n        tf.int32,\n    )\n    offset_height = ((image_shape[0] - padded_center_crop_size) + 1) // 2\n    offset_width = ((image_shape[1] - padded_center_crop_size) + 1) // 2\n    image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, padded_center_crop_size, padded_center_crop_size\n    )\n    image = tf.image.resize(image, [image_size, image_size], method=resize_method)\n    return image\n\n", "CodeBleu_score": 35.36145704904129}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image = tf.image.decode_jpeg(image_bytes, channels=3)\n    shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n    height = shape[0]\n    width = shape[1]\n    image_size = tf.cast(image_size, tf.float32)\n    padded_center_crop_size = tf.cast(\n        tf.math.minimum(height, width) * (1 + 0.1), tf.int32)\n    offset_height = ((height - padded_center_crop_size) + 1) // 2\n    offset_width = ((width - padded_center_crop_size) + 1) // 2\n    image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, padded_center_crop_size,\n        padded_center_crop_size)\n    image = tf.image.resize(image, image_size, method=resize_method)\n    return image\n\n", "CodeBleu_score": 37.382283273070996}, {"code": "def _decode_and_center_crop(image_bytes, image_size, resize_method)\n\t\n    image = tf.io.decode_jpeg(image_bytes, channels=3)\n    shape = tf.cast(tf.shape(image)[:-1], tf.float32)\n    padded_center_crop_size = tf.cast(\n        tf.math.ceil(image_size / (1 + 2 * CROP_PADDING)), tf.int32)\n    crop_window = tf.stack([padded_center_crop_size, padded_center_crop_size, 3])\n    offset_height = ((shape[0] + 1) // 2) - padded_center_crop_size\n    offset_width = ((shape[1] + 1) // 2) - padded_center_crop_size\n    image = tf.image.crop_to_bounding_box(\n        image, offset_height, offset_width, padded_center_crop_size,\n        padded_center_crop_size)\n    image = tf.image.resize(image, image_size, resize_method)\n    return image\n\n", "CodeBleu_score": 25.14003913719987}]}
{"instance_id": "cf16a6d37111", "generation_result": [{"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.image.resize_bicubic([image], [image_size, image_size])[0]\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.reshape(image, [image_size, image_size, 3])\n    image = tf.image.random_brightness(image, max_delta=32. / 255.)\n    image = tf.image.random_saturation(image, lower=0.5, upper=1.5)\n    image = tf.image.random_hue(image, max_delta=0.2)\n    image = tf.image.random_contrast(image, lower=0.5, upper=1.5)\n    image = tf.clip_by_value(image, 0.0, 1.0)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    else:\n        image = tf.cast(image, dtype=tf.float32)\n    return image\n\n", "CodeBleu_score": 37.6040046832863}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.image.resize_bicubic([image], [image_size, image_size])[0]\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n    return image\n\n", "CodeBleu_score": 37.45053150959379}, {"code": "def preprocess_for_train(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_random_crop(image_bytes, image_size, interpolation)\n    image = _flip(image)\n    image = tf.image.resize_bicubic(image, [image_size, image_size], preserve_aspect_ratio=False)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    image = tf.cond(\n        use_bfloat16,\n        lambda: tf.cast(image, dtype=tf.bfloat16),\n        lambda: tf.cast(image, dtype=tf.float32))\n    return image\n\n", "CodeBleu_score": 36.86924089017219}]}
{"instance_id": "78b2a3bd2142", "generation_result": [{"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n\n    if use_bfloat16:\n        image = tf.cast(image, dtype=tf.bfloat16)\n\n    return image\n\n", "CodeBleu_score": 29.83411034599408}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    if use_bfloat16:\n        image = tf.image.decode_and_crop_jpeg(image_bytes, tf.stack([0, 0, image_size, image_size]), channels=3)\n        image = tf.image.resize([image], [image_size, image_size], interpolation)[0]\n        image = tf.image.convert_image_dtype(image, dtype=tf.bfloat16)\n    else:\n        image = _decode_and_center_crop(image_bytes, image_size, interpolation)\n        image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n\n    return image\n\n", "CodeBleu_score": 46.23053153231736}, {"code": "def preprocess_for_eval(image_bytes, use_bfloat16, image_size=IMAGE_SIZE, interpolation='bicubic')\n\t\n    if use_bfloat16:\n        image = tf.image.convert_image_dtype(\n            _decode_and_center_crop(image_bytes, image_size, interpolation), tf.bfloat16)\n    else:\n        image = tf.image.convert_image_dtype(\n            _decode_and_center_crop(image_bytes, image_size, interpolation), tf.float32)\n\n    return image\n\n", "CodeBleu_score": 36.64908790973668}]}
{"instance_id": "8bd4364a9a0e", "generation_result": [{"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n\n    # Set the model in evaluation mode\n    model.eval()\n\n    # Initialize the prediction list\n    predictions = []\n\n    # Iterate over the evaluation dataloader\n    for batch in eval_dataloader:\n        # Move the batch to the appropriate device\n        batch = {k: v.to(self.device) for k, v in batch.items()}\n\n        # Generate predictions for the current batch\n        with torch.no_grad():\n            outputs = model(**batch)\n\n        # Save the predictions to the predictions list\n        predictions.extend(outputs[\"logits\"])\n\n    # Save the predictions to a file\n    with open(output_file, \"w\") as f:\n        for prediction in predictions:\n            f.write(str(prediction) + \"", "CodeBleu_score": 41.886870124347055}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n    model.eval()\n    predictions = []\n    for batch in tqdm(eval_dataloader):\n        batch = tuple(t.to(self.device) for t in batch)\n        with torch.no_grad():\n            inputs = {\n                \"input_ids\": batch[0],\n                \"attention_mask\": batch[1],\n                \"labels\": batch[2],\n            }\n            outputs = model(**inputs)\n            logits = outputs[0]\n            logits = logits.detach().cpu().numpy()\n            predictions.extend(logits)\n    predictions = np.array(predictions)\n    predictions = np.argmax(predictions, axis=1)\n    predictions = predictions.astype(int)\n    if output_file is not None:\n        np.save(output_file, predictions)\n    return predictions\n\n", "CodeBleu_score": 40.99195231703735}, {"code": "def evaluate(self, model, eval_dataloader=None, output_file=\"merged\")\n\t\n    # If no dataloader is specified, use the default evaluation dataloader\n    if eval_dataloader is None:\n        eval_dataloader = self.eval_dataloader\n\n    # Get the model's prediction loop\n    prediction_loop = self.prediction_loop(model)\n\n    # Create a file to save the predictions to\n    output_file = self.output_dir + \"/\" + output_file + \".json\"\n    with open(output_file, \"w\") as f:\n        f.write(\"{", "CodeBleu_score": 50.32978497114768}]}
{"instance_id": "22d682c958c0", "generation_result": [{"code": " def print_computed_metrics(self, metrics)\n\t\n    print(\"Rank1: %.4f\" % metrics[\"rank1\"])\n    print(\"Rank5: %.4f\" % metrics[\"rank5\"])\n    print(\"mIoU: %.4f\" % metrics[\"miou\"])\n\n", "CodeBleu_score": 20.388746676458346}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    print(f\"Rank1: {metrics['rank1']:.4f}\")\n    print(f\"Rank5: {metrics['rank5']:.4f}\")\n    print(f\"mIoU: {metrics['miou']:.4f}\")\n\n", "CodeBleu_score": 18.579754787867735}, {"code": " def print_computed_metrics(self, metrics)\n\t\n    print(\"Rank-1: \" + \"{:.4f}\".format(metrics[\"rank1\"]))\n    print(\"Rank-5: \" + \"{:.4f}\".format(metrics[\"rank5\"]))\n    print(\"mIoU: \" + \"{:.4f}\".format(metrics[\"miou\"]))\n\n\n def print_model_performance(self, model, input_shape):\n    \"\"\"The function prints the model performance on a 2D image of the given shape.", "CodeBleu_score": 25.4083230840844}]}
{"instance_id": "39c1a50b7e7d", "generation_result": [{"code": "def _eval_predictions(self, segments, data)\n\t\n    # Get ground truth data\n    gt_data = data.get_ground_truth()\n    # Get predictions\n    pred_data = data.get_predictions()\n    # Get IoU and rank for each prediction\n    iou_rank = []\n    for pred in pred_data:\n        for gt in gt_data:\n            iou = self._iou(pred, gt)\n            rank = self._rank(pred, gt)\n            iou_rank.append((iou, rank))\n    # Get rank 1 and rank 5\n    rank1 = 0\n    rank5 = 0\n    # Get mean IoU\n    mean_iou = 0\n    # Iterate over iou_rank\n    for iou, rank in iou_rank:\n        # Update rank1 and rank5\n        if rank == 1:\n            rank1 += 1\n        if rank <= 5:\n            rank5 += 1\n        # Update mean IoU\n        mean_iou += iou\n    # Return rank1, rank5, and mean IoU\n    return rank1/len(iou_rank), rank5/len(iou_rank), mean_iou/len(iou_rank)\n\n", "CodeBleu_score": 24.441568733453277}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    rank1 = 0\n    rank5 = 0\n    mean_iou = 0\n    for segment, data in zip(segments, data):\n        iou = self._iou(segment, data)\n        rank = self._rank(segment, data)\n        rank1 += iou * (rank <= 1)\n        rank5 += iou * (rank <= 5)\n        mean_iou += iou\n    return rank1, rank5, mean_iou/len(segments)\n", "CodeBleu_score": 20.12416319507662}, {"code": "def _eval_predictions(self, segments, data)\n\t\n    iou_values = []\n    rank_values = []\n    for segment, data_point in zip(segments, data):\n        iou_value = self._iou(segment, data_point)\n        rank_value = self._rank(segment, data_point)\n        iou_values.append(iou_value)\n        rank_values.append(rank_value)\n    rank1 = np.mean(np.array(rank_values) == 1)\n    rank5 = np.mean(np.array(rank_values) <= 5)\n    mean_iou = np.mean(iou_values)\n    return rank1, rank5, mean_iou\n", "CodeBleu_score": 27.054336990849798}]}
{"instance_id": "8ccf84f8d034", "generation_result": [{"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    self.to_ctx: def to_ctx(self, data, ctx=0, dtype=None):\n        if isinstance(data, dict):\n            for key in data:\n                if torch.is_tensor(data[key]):\n                    if dtype is not None and data[key].dtype == torch.float32:\n                        data[key] = data[key].to(dtype)\n                    data[key] = data[key].to(ctx)\n            return data\n        else:\n            raise ValueError(\"non-dict type of batch is not supported yet.\")\n    self.finalize: def finalize(self, output_file):\n        pass\n    self.predict_loop: def predict_loop(self, model, eval_dataloader, output_file=None):\n        \"\"\"The function performs on-the-fly predictions using a given model and evaluation dataloader on a single GPU.", "CodeBleu_score": 25.53034396926515}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    self.model.eval()\n    self.model.to(self.ctx)\n    with torch.no_grad():\n        for batch in eval_dataloader:\n            batch = self.to_ctx(batch)\n            output = self.model(batch)\n            self.finalize(output)\n            self.scores.append(output)\n        if output_file is not None:\n            self.finalize(output_file)\n        return self.scores\n", "CodeBleu_score": 36.96068606563935}, {"code": "def predict_loop(self, model, eval_dataloader, output_file=None)\n\t\n    self.eval_dataloader: def eval_dataloader(self):\n        return self.eval_dataloader\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self.model: def model(self):\n        return self.model\n\n    self.output_file: def output_file(self):\n        return self.output_file\n\n    self", "CodeBleu_score": 14.27899879395555}]}
{"instance_id": "e68529ad727d", "generation_result": [{"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2, 'Expected two scores, got %d' % len(scores)\n    video_scores, text_scores = scores\n    video_scores = tf.concat(video_scores, axis=0)\n    text_scores = tf.concat(text_scores, axis=0)\n    self.full_scores = None\n    return tf.reduce_sum(video_scores * text_scores, axis=1)\n\n", "CodeBleu_score": 35.25577010340313}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2, \"The number of scores must be two.\"\n    full_scores = np.concatenate((scores[0], scores[1]), axis=1)\n    self.full_scores = full_scores\n    return np.dot(full_scores[0], full_scores[1])\n\n", "CodeBleu_score": 37.61148372058187}, {"code": "def _aggregate_scores(self, scores)\n\t\n    assert len(scores) == 2\n    video_scores, text_scores = scores\n    video_scores = tf.concat(video_scores, axis=0)\n    text_scores = tf.concat(text_scores, axis=0)\n    self.full_scores = None\n    return tf.reduce_sum(video_scores * text_scores, axis=1)\n\n", "CodeBleu_score": 37.05670901121437}]}
{"instance_id": "e4e1861fc357", "generation_result": [{"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred = np.asarray(Y_pred)\n    Y_true = np.asarray(Y_true)\n    if len(Y_pred.shape) == 1:\n        Y_pred = Y_pred.reshape(-1, 1)\n    if len(Y_true.shape) == 1:\n        Y_true = Y_true.reshape(-1, 1)\n    if Y_pred.shape[0]!= Y_true.shape[0]:\n        raise ValueError(\"The number of predicted and true labels must be the same.\")\n    if Y_pred.shape[1]!= Y_true.shape[1]:\n        raise ValueError(\"The number of predicted and true labels must be the same.\")\n    if self.verbose:\n        print(\"The number of predicted and true labels is: \" + str(Y_pred.shape[0]))\n    if self.verbose:\n        print(\"The number of predicted labels is: \" + str(Y_pred.shape[1]))\n    if self.verbose:\n        print(\"The number of true labels is: \" + str(Y_true.shape[1]))\n    if self.verbose:\n        print(\"The number of classes is: \" + str(self.n_classes))\n    if self.verbose:\n        print(\"The number of samples is: \" + str(Y_true.shape[0]))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if self.verbose:\n        print(\"The number of samples per class is: \" + str(Y_true.shape[0] / self.n_classes))\n    if", "CodeBleu_score": 25.39911999858958}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    if self.verbose:\n        print(\"Finalizing predictions...\")\n    Y_pred = np.array(Y_pred)\n    Y_true = np.array(Y_true)\n    if self.verbose:\n        print(\"Predictions and true labels finalized.\")\n        print(\"Computing prediction errors...\")\n    if self.verbose:\n        print(\"Computing prediction errors...\")\n    self.compute_errors(Y_pred, Y_true)\n    if self.verbose:\n        print(\"Prediction errors computed.\")\n    if self.verbose:\n        print(\"Printing samples of prediction errors...\")\n    self.print_errors()\n    if self.verbose:\n        print(\"Samples of prediction errors printed.\")\n    if output_file:\n        if self.verbose:\n            print(\"Saving predictions and true labels...\")\n        self.save_predictions(Y_pred, Y_true, output_file)\n        if self.verbose:\n            print(\"Predictions and true labels saved.\")\n    return {'Y_pred': Y_pred, 'Y_true': Y_true}\n\n", "CodeBleu_score": 30.024965106277968}, {"code": "def finalize(self, Y_pred, Y_true, output_file=None)\n\t\n    Y_pred_final = np.concatenate(Y_pred)\n    Y_true_final = np.concatenate(Y_true)\n    Y_pred_final = np.array(Y_pred_final, dtype=int)\n    Y_true_final = np.array(Y_true_final, dtype=int)\n    if output_file is not None:\n        pickle.dump([Y_pred_final, Y_true_final], open(output_file, 'wb'))\n    print(\"Number of errors: \", np.sum(Y_pred_final!= Y_true_final))\n    print(\"Number of samples: \", len(Y_pred_final))\n    print(\"Error rate: \", np.sum(Y_pred_final!= Y_true_final) / len(Y_pred_final))\n    print(\"Samples of errors: \")\n    for i in range(len(Y_pred_final)):\n        if Y_pred_final[i]!= Y_true_final[i]:\n            print(\"Predicted label: \", Y_pred_final[i], \"True label: \", Y_true_final[i])\n    return {\"Y_pred\": Y_pred_final, \"Y_true\": Y_true_final}\n\n", "CodeBleu_score": 35.83014978792475}]}
{"instance_id": "7df9ab9a4920", "generation_result": [{"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get('loss', 0) for log in logging_outputs)\n    n_samples = sum(log.get('n_samples', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / n_samples, n_samples)\n\n", "CodeBleu_score": 46.9331365160798}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get('loss', 0) for log in logging_outputs)\n    sample_size = sum(log.get('sample_size', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / sample_size, sample_size)\n\n", "CodeBleu_score": 52.43444143222652}, {"code": "def reduce_metrics(logging_outputs) -> None\n\t\n    loss_sum = sum(log.get('loss', 0) for log in logging_outputs)\n    n_samples = sum(log.get('n_samples', 0) for log in logging_outputs)\n    metrics.log_scalar('loss', loss_sum / n_samples, n_samples)\n\n", "CodeBleu_score": 46.9331365160798}]}
{"instance_id": "7f9c326a96f7", "generation_result": [{"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n    token_type_ids = torch.cat([cmasks[:, :1], vmasks, cmasks[:, 1:]], dim=1)\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 32.16245647796575}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n    assert cmasks.size(0) == vmasks.size(0), \"{}, {}, {}, {}\".format(\n        str(cmasks.size()),\n        str(vmasks.size()),\n        str(cmasks.size(0)),\n        str(vmasks.size(0)),\n    )\n\n    mm_mask = torch.cat([cmasks[:, :1], vmasks, cmasks[:, 1:]], dim=1)\n    if self.last_iso_layer == 0:\n        # hard attention mask.\n        return mm_mask\n    else:\n        # a gpu iso mask; 0 : num_iso_layer is isolated;\n        # num_iso_layer: are MM-fused.\n        # make an iso layer\n        batch_size = cmasks.size(0)\n        iso_mask = self._make_iso_mask(batch_size, cmasks, vmasks)\n        mm_mask = mm_mask[:, None, :].repeat(1, mm_mask.size(-1), 1)\n        iso_mm_masks = []\n        # hard attention mask.\n        iso_mask = iso_mask[:, None, :, :].repeat(\n            1, self.last_iso_layer, 1, 1)\n        iso_mm_masks.append(iso_mask)\n        if self.last_iso_layer < self.num_hidden_layers:\n            mm_mask = mm_mask[:, None, :, :].repeat(\n                1, self.num_hidden_layers - self.last_iso_layer, 1, 1\n            )\n            iso_mm_masks.append(mm_mask)\n        iso_mm_masks = torch.cat(iso_mm_masks, dim=1)\n        return iso_mm_masks\n\n", "CodeBleu_score": 37.50259280088714}, {"code": "def _mm_on_the_fly(\n        self,\n        cmasks,\n        vmasks,\n        attention_mask\n    )\n\t\n\n    # generate the attention mask\n    if attention_mask is None:\n        attention_mask = self._mm_attention_mask(cmasks, vmasks)\n\n    # generate the token type IDs\n    token_type_ids = torch.cat([cmasks[:, :1], vmasks, cmasks[:, 1:]], dim=1)\n\n    return attention_mask, token_type_ids\n\n", "CodeBleu_score": 32.16245647796575}]}
{"instance_id": "fa99d2a148a5", "generation_result": [{"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # If the input_ids are not provided, the function returns the original input_ids.\n    if input_ids is None:\n        return model_kwargs\n\n    # If the input_video_embeds are not provided, the function returns the original input_video_embeds.\n    if input_video_embeds is None:\n        return model_kwargs\n\n    # The combined length of input_ids and input_video_embeds is the sequence length.\n    sequence_length = len(input_ids) + len(input_video_embeds)\n\n    # If the sequence length is greater than the maximum sequence length, the function returns the original input_ids.\n    if sequence_length > self.config.max_length:\n        return model_kwargs\n\n    # If the sequence length is less than the maximum sequence length, the function modifies the attention_mask and token_type_ids.\n    if attention_mask is None:\n        attention_mask = torch.ones(sequence_length, dtype=torch.long, device=self.device)\n    else:\n        attention_mask = attention_mask.to(self.device)\n\n    if token_type_ids is None:\n        token_type_ids = torch.zeros(sequence_length, dtype=torch.long, device=self.device)\n    else:\n        token_type_ids = token_type_ids.to(self.device)\n\n    # The function modifies the input_ids to fit the new sequence length.\n    input_ids = input_ids + [self.config.pad_token_id] * (sequence_length - len(input_ids))\n\n    # The function modifies the input_video_embeds to fit the new sequence length.\n    input_video_embeds = input_video_embeds + [torch.zeros(self.config.hidden_size, dtype=torch.float, device=self.device)] * (sequence_length - len(input_video_embeds))\n\n    # The function modifies the attention_mask to fit the new sequence length.\n    attention_mask = attention_mask[:sequence_length]\n\n    # The function modifies the token_type_ids to fit the new sequence length.\n    token_type_ids = token_type_ids[:sequence_length]\n\n    # The function returns the updated input_ids, input_video_embeds, attention_mask, and token", "CodeBleu_score": 30.156997177886346}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # Get the combined length of input_ids and input_video_embeds\n    combined_length = len(input_ids) + len(input_video_embeds)\n    # Adjust the sequence length to match the combined length of input_ids and input_video_embeds\n    new_sequence_length = self.config.model_max_length\n    if combined_length < new_sequence_length:\n        new_sequence_length = combined_length\n    # Update the input_ids and input_video_embeds\n    input_ids = input_ids + [self.config.pad_token_id] * (new_sequence_length - len(input_ids))\n    input_video_embeds = input_video_embeds + [0] * (new_sequence_length - len(input_video_embeds))\n    # Update the attention_mask and token_type_ids\n    if attention_mask is None:\n        attention_mask = [1] * new_sequence_length\n    else:\n        attention_mask = attention_mask + [0] * (new_sequence_length - len(attention_mask))\n    if token_type_ids is None:\n        token_type_ids = [0] * new_sequence_length\n    else:\n        token_type_ids = token_type_ids + [0] * (new_sequence_length - len(token_type_ids))\n    # Update the model kwargs\n    model_kwargs[\"input_ids\"] = input_ids\n    model_kwargs[\"input_video_embeds\"] = input_video_embeds\n    model_kwargs[\"attention_mask\"] = attention_mask\n    model_kwargs[\"token_type_ids\"] = token_type_ids\n    return model_kwargs\n\n", "CodeBleu_score": 28.366380258082753}, {"code": "def prepare_inputs_for_generation(\n        self,\n        input_ids,\n        input_video_embeds,\n        attention_mask=None,\n        token_type_ids=None,\n        **model_kwargs\n    )\n\t\n    # Calculate the combined length of input_ids and input_video_embeds\n    combined_length = len(input_ids) + len(input_video_embeds)\n    # Create a new sequence of the same length as the combined sequence\n    new_input_ids = input_ids + [0] * (combined_length - len(input_ids))\n    new_input_video_embeds = input_video_embeds + [0] * (combined_length - len(input_video_embeds))\n    # Calculate the new attention_mask and token_type_ids\n    new_attention_mask = [1] * combined_length\n    new_token_type_ids = [0] * combined_length\n    # Update the input_ids, input_video_embeds, attention_mask, and token_type_ids\n    model_kwargs[\"input_ids\"] = new_input_ids\n    model_kwargs[\"input_video_embeds\"] = new_input_video_embeds\n    model_kwargs[\"attention_mask\"] = new_attention_mask\n    model_kwargs[\"token_type_ids\"] = new_token_type_ids\n    return model_kwargs\n\n", "CodeBleu_score": 24.06332477403723}]}
{"instance_id": "b1b0d25fe620", "generation_result": [{"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    pipeline = Compose(cfg.pipeline)\n    if 'img_id' in pipeline.meta_keys:\n        pipeline.meta_keys.remove('img_id')\n    load_idx = self._get_transform_idx(pipeline, ('LoadImageFromFile', type(None)))\n    if load_idx == -1:\n        raise ValueError('Cannot find LoadImageFromFile transform in pipeline.')\n    pipeline[load_idx]['type'] ='mmdet.InferencerLoader'\n    return pipeline\n\n", "CodeBleu_score": 33.90480966315203}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    # Remove 'img_id' key from meta_keys if present\n    if 'img_id' in cfg.data.pipeline.meta_keys:\n        cfg.data.pipeline.meta_keys.remove('img_id')\n    # Find the index of the 'LoadImageFromFile' transform\n    load_img_idx = self._get_transform_idx(cfg.data.pipeline, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise ValueError(\n            'The \"LoadImageFromFile\" transform is not found in the pipeline.')\n    # Update the transform type to'mmdet.InferencerLoader'\n    cfg.data.pipeline[load_img_idx]['type'] ='mmdet.InferencerLoader'\n    # Return the modified pipeline configuration wrapped in a Compose object\n    return Compose(cfg.data.pipeline)\n\n", "CodeBleu_score": 38.203230162612286}, {"code": "def _init_pipeline(self, cfg: ConfigType) -> Compose\n\t    cfg = copy.deepcopy(cfg)\n    if 'img_id' in cfg.meta_keys:\n        cfg.meta_keys.remove('img_id')\n    load_img_idx = self._get_transform_idx(cfg, 'LoadImageFromFile')\n    if load_img_idx == -1:\n        raise ValueError(f'Could not find the \"LoadImageFromFile\" transform in the pipeline. '\n                         f'Please make sure the \"LoadImageFromFile\" transform is present in the pipeline.')\n    cfg[load_img_idx]['type'] ='mmdet.InferencerLoader'\n    return Compose(cfg)\n\n", "CodeBleu_score": 36.75718801670335}]}
{"instance_id": "7967962856eb", "generation_result": [{"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        inputs = os.listdir(inputs)\n    if not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 30.72354936769395}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        inputs = glob.glob(os.path.join(inputs, '*.jpg'))\n        if not inputs:\n            raise FileNotFoundError(f'No images found in {inputs}')\n    if not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 39.44440172174317}, {"code": "def _inputs_to_list(self, inputs: InputsType) -> list\n\t\n    if isinstance(inputs, str):\n        inputs = glob.glob(inputs)\n    elif not isinstance(inputs, (list, tuple)):\n        inputs = [inputs]\n    return inputs\n\n", "CodeBleu_score": 28.150066212962134}]}
{"instance_id": "74f727f06fa0", "generation_result": [{"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk = []\n    for input in inputs:\n        if isinstance(input, dict):\n            if 'img' in input:\n                chunk.append(input)\n            elif 'img_path' in input:\n                chunk.append(input)\n        else:\n            chunk.append(input)\n        if len(chunk) == chunk_size:\n            yield self.pipeline(chunk)\n            chunk = []\n    if chunk:\n        yield self.pipeline(chunk)\n\n", "CodeBleu_score": 26.34108489928345}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk_data = []\n    for input in inputs:\n        if isinstance(input, dict):\n            if 'img' in input:\n                chunk_data.append(input)\n            elif 'img_path' in input:\n                img = cv2.imread(input['img_path'])\n                if img is not None:\n                    input['img'] = img\n                    chunk_data.append(input)\n        else:\n            chunk_data.append(input)\n        if len(chunk_data) == chunk_size:\n            yield self._process_chunk(chunk_data)\n            chunk_data = []\n    if chunk_data:\n        yield self._process_chunk(chunk_data)\n\n", "CodeBleu_score": 37.18005686204244}, {"code": "def _get_chunk_data(self, inputs: Iterable, chunk_size: int)\n\t\n    chunk = []\n    for input_ in inputs:\n        if isinstance(input_, dict) and 'img' in input_ or 'img_path' in input_:\n            chunk.append(input_)\n            if len(chunk) == chunk_size:\n                yield self._process_chunk(chunk)\n                chunk = []\n        else:\n            yield self._process_chunk([input_])\n    if chunk:\n        yield self._process_chunk(chunk)\n\n", "CodeBleu_score": 22.196906421318523}]}
{"instance_id": "a43ab51afa59", "generation_result": [{"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    if return_datasamples:\n        if pred_out_dir!= '':\n            warnings.warn(\n                'Saving predictions as datasamples is not supported. '\n                'Please set pred_out_dir to an empty string to disable saving '\n                'predictions as datasamples.')\n        return_datasamples = False\n\n    if not no_save_pred and pred_out_dir!= '':\n        if not osp.isdir(pred_out_dir):\n            os.makedirs(pred_out_dir, exist_ok=True)\n        if return_datasamples:\n            os.makedirs(osp.join(pred_out_dir, 'preds'), exist_ok=True)\n\n    if isinstance(preds, dict):\n        results = preds\n    else:\n        results = self.pred2dict(preds)\n\n    if return_datasamples:\n        results['datasamples'] = preds\n    if visualization is not None:\n        results['visualization'] = visualization\n    if print_result:\n        self.print_result(results)\n\n    return results\n\n", "CodeBleu_score": 46.7973742090925}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    if not no_save_pred:\n        if pred_out_dir == '':\n            raise RuntimeError('pred_out_dir must be set when saving predictions.')\n        if return_datasamples:\n            raise RuntimeError(\n                'Saving datasamples is not supported when return_datasamples is True.')\n\n    results = {}\n    if preds is None:\n        return results\n    if isinstance(preds, dict):\n        if return_datasamples:\n            raise RuntimeError(\n                'Saving datasamples is not supported when return_datasamples is True.')\n        if print_result:\n            self._print_result(preds)\n        results = preds\n    elif isinstance(preds, list):\n        for idx, pred in enumerate(preds):\n            if return_datasamples:\n                raise RuntimeError(\n                    'Saving datasamples is not supported when return_datasamples is True.')\n            if print_result:\n                self._print_result(pred)\n            results[idx] = pred\n    else:\n        if return_datasamples:\n            raise RuntimeError(\n                'Saving datasamples is not supported when return_datasamples is True.')\n        if print_result:\n            self._print_result(preds)\n        results[0] = preds\n\n    if visualization is not None:\n        results['visualization'] = visualization\n\n    if not no_save_pred:\n        self._save_result(results, pred_out_dir)\n\n    return results\n\n", "CodeBleu_score": 42.42323007232224}, {"code": "def postprocess(\n        self,\n        preds: PredType,\n        visualization: Optional[List[np.ndarray]] = None,\n        return_datasamples: bool = False,\n        print_result: bool = False,\n        no_save_pred: bool = False,\n        pred_out_dir: str = '',\n        **kwargs,\n    ) -> Dict\n\t    if not no_save_pred:\n        if pred_out_dir == '':\n            raise ValueError('pred_out_dir should not be empty.')\n        if return_datasamples:\n            raise ValueError(\n                'Saving datasamples is not supported when return_datasamples is True.'\n            )\n    results = {}\n    for idx, pred in enumerate(preds):\n        if isinstance(pred, DetDataSample):\n            if return_datasamples:\n                results[idx] = pred\n            else:\n                results[idx] = self.pred2dict(pred, pred_out_dir)\n        else:\n            results[idx] = self.pred2dict(pred, pred_out_dir)\n    if visualization is not None:\n        results['visualization'] = visualization\n    if print_result:\n        print(results)\n    return results\n\n", "CodeBleu_score": 47.58342363735038}]}
{"instance_id": "a3c2561f199c", "generation_result": [{"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    dataset_pipeline = cfg.dataset_pipeline\n    first_transform = dataset_pipeline[0]\n    # Modify the first transform to include only the 'Resize' transform\n    new_first_transform = first_transform.copy()\n    new_first_transform.transforms = [Resize]\n    # Copy the last transform in the pipeline\n    last_transform = dataset_pipeline[-1]\n    # Combine the modified first transform and the copied last transform into a new test pipeline\n    new_pipeline = [new_first_transform, last_transform]\n    test_pipeline = Compose(new_pipeline)\n    return test_pipeline\n\n", "CodeBleu_score": 21.047796806812013}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # copy the first transform in the dataset pipeline\n    transform_first = cfg.dataset_pipeline[0]\n\n    # modify the first transform to include only the 'Resize' transform\n    transform_first = transform_first.copy(\n        transforms=[Resize(size=cfg.dataset.test.resize_size)]\n    )\n\n    # copy the last transform in the dataset pipeline\n    transform_last = cfg.dataset_pipeline[-1]\n\n    # combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose([transform_first, transform_last])\n\n    # return the constructed test pipeline\n    return test_pipeline\n\n", "CodeBleu_score": 24.31836366490882}, {"code": "def build_test_pipeline(cfg: ConfigType) -> ConfigType\n\t\n    # Copy the first transform in the dataset pipeline\n    transform1 = cfg[\"dataset\"][\"transforms\"][0]\n    # Modify the first transform to include only the 'Resize' transform\n    transform1[\"transforms\"] = [\"Resize\"]\n    # Copy the last transform in the dataset pipeline\n    transform2 = cfg[\"dataset\"][\"transforms\"][-1]\n    # Combine the modified first and copied last transforms into a new test pipeline using Compose\n    test_pipeline = Compose([transform1, transform2])\n    # Return the constructed test pipeline\n    return test_pipeline\n\n", "CodeBleu_score": 17.893161925768805}]}
{"instance_id": "48a358ab5a38", "generation_result": [{"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare input data\n    input_dict = dict(\n        img=img,\n        frame_id=frame_id,\n        ori_shape=(img.shape[0], img.shape[1]),\n        img_id=0,\n        video_len=video_len,\n    )\n\n    # build test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n\n    # prepare data\n    data = DataSample(\n        metainfo=dict(\n            frame_id=frame_id,\n            ori_shape=input_dict['ori_shape'],\n            img_id=input_dict['img_id'],\n            video_len=input_dict['video_len'],\n        ),\n        inputs=input_dict,\n        data_samples=None,\n    )\n    data = test_pipeline(data)\n\n    # do inference\n    with torch.no_grad():\n        outputs = model.forward(data)\n\n    return outputs\n\n", "CodeBleu_score": 32.40487324422714}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    # prepare the input data\n    model.cpu()\n    model.eval()\n    ori_shape = img.shape\n    img = img[np.newaxis,...]\n    img = img.astype(np.float32)\n    img = torch.from_numpy(img)\n    img = img.permute(0, 3, 1, 2)\n    img = img.cuda()\n    frame_id = torch.tensor(frame_id)\n    frame_id = frame_id.cuda()\n    video_len = torch.tensor(video_len)\n    video_len = video_len.cuda()\n    img_id = torch.tensor(0)\n    img_id = img_id.cuda()\n    ori_shape = torch.tensor(ori_shape)\n    ori_shape = ori_shape.cuda()\n\n    # prepare the test pipeline\n    test_pipeline = build_test_pipeline(model.cfg)\n    test_pipeline = test_pipeline.transform(\n        dict(\n            img=img,\n            img_shape=ori_shape,\n            frame_id=frame_id,\n            video_len=video_len,\n            img_id=img_id,\n        )\n    )\n\n    # forward pass\n    with torch.no_grad():\n        result = model(test_pipeline)\n\n    # convert to list\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to(torch.device('cpu'))\n    result = result.to", "CodeBleu_score": 28.384748419343296}, {"code": "def inference_mot(model: nn.Module, img: np.ndarray, frame_id: int,\n                  video_len: int) -> SampleList\n\t\n    cfg = model.cfg\n    if cfg.model.roi_head.type == 'RoIHead':\n        if not isinstance(model, RoIHead):\n            raise ValueError(\n                'Only support RoIHead as the model head in the inference process.')\n        # the original shape of the image\n        ori_shape = np.array(img.shape[:2][::-1], dtype=np.float32)\n        # the original image ID\n        image_id = np.array([0], dtype=np.int64)\n        # the original video length\n        video_len = np.array([video_len], dtype=np.int64)\n        # the frame ID\n        frame_id = np.array([frame_id], dtype=np.int64)\n        # the input data\n        data = dict(\n            img=img,\n            ori_shape=ori_shape,\n            image_id=image_id,\n            frame_id=frame_id,\n            video_len=video_len)\n        # the test pipeline\n        test_pipeline = build_test_pipeline(cfg)\n        # the model's configuration\n        model_cfg = cfg.model\n        # the model's state dict\n        model_state_dict = model.state_dict()\n        # the model's device\n        model_device = next(model.parameters()).device\n        # the model's output\n        model_output = model.inference_mode(data, test_pipeline, model_cfg,\n                                            model_state_dict, model_device)\n        return model_output\n    else:\n        raise NotImplementedError('Only support RoIHead as the model head.')\n\n", "CodeBleu_score": 44.45335938105296}]}
{"instance_id": "6c4ea2ce1787", "generation_result": [{"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 77.02217016729102}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 77.02217016729102}, {"code": "def truncate_seq_pair(tokens_a, tokens_b, max_num_tokens, rng)\n\t\n    while True:\n        total_length = len(tokens_a) + len(tokens_b)\n        if total_length <= max_num_tokens:\n            break\n        trunc_tokens = tokens_a if len(tokens_a) > len(tokens_b) else tokens_b\n        assert len(trunc_tokens) >= 1\n        # We want to sometimes truncate from the front and sometimes from the\n        # back to add more randomness and avoid biases.\n        if rng.random() < 0.5:\n            del trunc_tokens[0]\n        else:\n            trunc_tokens.pop()\n\n", "CodeBleu_score": 77.02217016729102}]}
{"instance_id": "007181b6729d", "generation_result": [{"code": "def get_activation(activation_string)\n\t\n    if type(activation_string)!= str:\n        return activation_string\n    if activation_string == '':\n        return None\n    if activation_string =='relu':\n        return nn.ReLU()\n    if activation_string =='sigmoid':\n        return nn.Sigmoid()\n    if activation_string == 'tanh':\n        return nn.Tanh()\n    if activation_string =='softmax':\n        return nn.Softmax()\n    if activation_string == 'elu':\n        return nn.ELU()\n    if activation_string == 'leaky_relu':\n        return nn.LeakyReLU()\n    if activation_string =='selu':\n        return nn.SELU()\n    if activation_string == 'prelu':\n        return nn.PReLU()\n    if activation_string == 'rrelu':\n        return nn.RReLU()\n    if activation_string == 'celu':\n        return nn.CELU()\n    if activation_string == 'glu':\n        return nn.GLU()\n    if activation_string == 'hardtanh':\n        return nn.Hardtanh()\n    if activation_string == 'log_sigmoid':\n        return nn.LogSigmoid()\n    if activation_string =='softplus':\n        return nn.Softplus()\n    if activation_string =='softmin':\n        return nn.Softmin()\n    if activation_string =='softshrink':\n        return nn.Softshrink()\n    if activation_string == 'dropout':\n        return nn.Dropout()\n    if activation_string == 'alpha_dropout':\n        return nn.AlphaDropout()\n    if activation_string == 'bernoulli_dropout':\n        return nn.BernoulliDropout()\n    if activation_string == 'gaussian_dropout':\n        return nn.GaussianDropout()\n    if activation_string == 'instance_norm':\n        return nn.InstanceNorm1d()\n    if activation_string == 'layer_norm':\n        return nn.LayerNorm()\n    if activation_string == 'batch_norm':\n        return nn.BatchNorm1d()\n    if activation_string == 'group_norm':\n        return nn.GroupNorm()\n    if activation_string == 'affine_grid':\n        return nn.AffineGrid()\n    if activation_string == 'pixel_shuffle':\n        return nn.PixelShuffle()\n    if activation_string == 'upsample_bilinear':\n        return nn.Upsample(scale_factor=2,", "CodeBleu_score": 22.91616962037605}, {"code": "def get_activation(activation_string)\n\t\n\n    if isinstance(activation_string, str):\n        if activation_string == \"\":\n            return None\n        elif activation_string == \"relu\":\n            return tf.nn.relu\n        elif activation_string == \"sigmoid\":\n            return tf.nn.sigmoid\n        elif activation_string == \"tanh\":\n            return tf.nn.tanh\n        elif activation_string == \"softmax\":\n            return tf.nn.softmax\n        else:\n            raise ValueError(\"Unsupported activation function: \" + activation_string)\n    else:\n        return activation_string\n\n", "CodeBleu_score": 36.77374587914397}, {"code": "def get_activation(activation_string)\n\t\n    if not isinstance(activation_string, str):\n        return activation_string\n    if activation_string == \"\":\n        return None\n    elif activation_string == \"linear\":\n        return tf.keras.activations.linear\n    elif activation_string == \"relu\":\n        return tf.keras.activations.relu\n    elif activation_string == \"sigmoid\":\n        return tf.keras.activations.sigmoid\n    elif activation_string == \"tanh\":\n        return tf.keras.activations.tanh\n    elif activation_string == \"softmax\":\n        return tf.keras.activations.softmax\n    elif activation_string == \"elu\":\n        return tf.keras.activations.elu\n    elif activation_string == \"selu\":\n        return tf.keras.activations.selu\n    elif activation_string == \"softplus\":\n        return tf.keras.activations.softplus\n    elif activation_string == \"softsign\":\n        return tf.keras.activations.softsign\n    elif activation_string == \"relu6\":\n        return tf.keras.activations.relu6\n    elif activation_string == \"crelu\":\n        return tf.keras.activations.crelu\n    elif activation_string == \"exponential\":\n        return tf.keras.activations.exponential\n    elif activation_string == \"hard_sigmoid\":\n        return tf.keras.activations.hard_sigmoid\n    elif activation_string == \"exponential\":\n        return tf.keras.activations.exponential\n    elif activation_string == \"linear\":\n        return tf.keras.activations.linear\n    elif activation_string == \"leaky_relu\":\n        return tf.keras.activations.leaky_relu\n    else:\n        raise ValueError(f\"Unsupported activation function: {activation_string}\")\n\n", "CodeBleu_score": 22.63284735776087}]}
{"instance_id": "d5d6e0315899", "generation_result": [{"code": "def dropout(input_tensor, dropout_prob)\n\t\n    return dropout_layer(input_tensor, dropout_prob)\n\n", "CodeBleu_score": 12.411610603740188}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}, {"code": "def dropout(input_tensor, dropout_prob)\n\t\n    if dropout_prob is None or dropout_prob == 0.0:\n        return input_tensor\n    output = tf.nn.dropout(input_tensor, 1.0 - dropout_prob)\n    return output\n\n", "CodeBleu_score": 87.51451468041077}]}
{"instance_id": "828917b9ac53", "generation_result": [{"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(\n      tf.shape(from_tensor)[0], tf.float32)\n    attention_mask = (1.0 - to_mask) * -1e9\n    return attention_mask", "CodeBleu_score": 49.94635441000407}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=2)\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(\n      tf.reshape(tf.range(0, limit=from_seq_length), [from_seq_length, 1]),\n      tf.float32)\n    m = tf.cast(\n      tf.reshape(tf.range(0, limit=to_seq_length), [1, to_seq_length]),\n      tf.float32)\n\n    mask = tf.cast(n >= m, tf.float32)\n    mask = tf.reshape(mask, [from_seq_length, to_seq_length])\n    mask = tf.expand_dims(mask, axis=0)\n    mask = tf.tile(mask, [batch_size, 1, 1])\n    return mask", "CodeBleu_score": 49.92527302655269}, {"code": "def create_attention_mask_from_input_mask(from_tensor, to_mask)\n\t\n    from_shape = get_shape_list(from_tensor, expected_rank=[2, 3])\n    batch_size = from_shape[0]\n    from_seq_length = from_shape[1]\n\n    to_shape = get_shape_list(to_mask, expected_rank=2)\n    to_seq_length = to_shape[1]\n\n    to_mask = tf.cast(\n      tf.reshape(to_mask, [batch_size, 1, to_seq_length]), tf.float32)\n\n    n = tf.cast(tf.shape(from_tensor)[1], tf.float32)\n   attention_mask = (1.0 - tf.expand_dims(to_mask, 1)) * tf.cast(\n      tf.equal(tf.tile(tf.expand_dims(tf.range(n), 0), [batch_size, 1]),\n               tf.tile(tf.expand_dims(tf.range(n), 1), [1, from_seq_length])),\n      tf.float32)\n\n    return attention_mask", "CodeBleu_score": 53.59129763996937}]}
{"instance_id": "d7798e41a723", "generation_result": [{"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n", "CodeBleu_score": 54.22065594588168}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}, {"code": "def transpose_for_scores(input_tensor, batch_size, num_attention_heads,\n                           seq_length, width)\n\t\n    output_tensor = tf.reshape(\n        input_tensor, [batch_size, seq_length, num_attention_heads, width])\n    output_tensor = tf.transpose(output_tensor, [0, 2, 1, 3])\n    return output_tensor\n\n", "CodeBleu_score": 59.99845781533536}]}
{"instance_id": "711d466ace09", "generation_result": [{"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims is None:\n        raise ValueError('Cannot reshape a tensor with unknown rank.')\n    if input_tensor.shape.ndims < 2:\n        raise ValueError('Cannot reshape a tensor with less than 2 dimensions.')\n    if input_tensor.shape.ndims == 2:\n        return input_tensor\n    return tf.reshape(input_tensor, [-1, input_tensor.shape[-1]])\n\n", "CodeBleu_score": 33.352468665818485}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if len(input_tensor.get_shape()) < 2:\n        raise ValueError(\"Input tensor must have at least 2 dimensions.\")\n    if len(input_tensor.get_shape()) == 2:\n        return input_tensor\n    return tf.reshape(input_tensor, [-1, input_tensor.get_shape()[-1]])\n\n", "CodeBleu_score": 34.677344965765855}, {"code": "def reshape_to_matrix(input_tensor)\n\t\n    if input_tensor.shape.ndims == 2:\n        return input_tensor\n    else:\n        return tf.reshape(input_tensor, [-1, input_tensor.shape[-1]])\n\n", "CodeBleu_score": 16.99760026860185}]}
{"instance_id": "7adcd08f531e", "generation_result": [{"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    with open(os.path.join(data_dir, \"train.tsv\")) as f:\n        for (i, line) in enumerate(f):\n            if i == 0:\n                continue\n            guid = \"%s-%s\" % (self.task_name, i)\n            text_a = tokenization.convert_to_unicode(line[3])\n            text_b = tokenization.convert_to_unicode(line[4])\n            label = tokenization.convert_to_unicode(line[5])\n            if label == \"contradictory\":\n                label = \"contradiction\"\n            examples.append(\n                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n    return examples\n\n", "CodeBleu_score": 48.44514959314486}, {"code": "def get_train_examples(self, data_dir)\n\t\n    examples = []\n    with open(os.path.join(data_dir, \"train.tsv\"), \"r\", encoding=\"utf-8\") as f:\n        reader = csv.reader(f, delimiter=\"\\t\", quotechar=None)\n        next(reader)\n        for line in reader:\n            guid = \"%s-%s\" % (line[0], line[1])\n            text_a = convert_to_unicode(line[3])\n            text_b = convert_to_unicode(line[4])\n            label = convert_to_unicode(line[5])\n            if label == \"contradictory\":\n                label = \"contradiction\"\n            examples.append(\n                InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label)\n            )\n    return examples\n\n", "CodeBleu_score": 39.63675602652705}, {"code": "def get_train_examples(self, data_dir)\n\t\n    logger.info(\"LOOKING AT {}\".format(os.path.join(data_dir, \"train.tsv\")))\n    return self._create_examples(\n        self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")", "CodeBleu_score": 8.437571433423946}]}
{"instance_id": "26a0bb96dab9", "generation_result": [{"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create a mask to avoid NaN's in the loss calculation\n    is_not_real = tf.to_float(tf.logical_not(is_real_example))\n    per_example_loss = tf.multiply(per_example_loss, is_not_real)\n    # Calculate the mean loss across the batch\n    mean_loss = tf.reduce_mean(per_example_loss)\n    # Calculate the accuracy\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids, predictions=tf.argmax(logits, axis=-1), weights=is_not_real)\n    # Return the metrics\n    return {\n        \"eval_accuracy\": accuracy,\n        \"eval_loss\": mean_loss,\n    }\n\n", "CodeBleu_score": 42.55008317797848}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create predictions\n    pred_labels = tf.math.argmax(logits, axis=-1)\n    # Create accuracy\n    accuracy = tf.metrics.accuracy(\n        labels=tf.reshape(label_ids, shape=(-1,)),\n        predictions=tf.reshape(pred_labels, shape=(-1,)),\n        weights=tf.cast(is_real_example, tf.float32),\n    )[1]  # Return (total, count)\n    # Create loss\n    per_example_loss = tf.reshape(per_example_loss, shape=(-1,))\n    loss = tf.metrics.mean(\n        values=per_example_loss, weights=tf.cast(is_real_example, tf.float32)\n    )[0]  # Return tensor\n    return {\"eval_accuracy\": accuracy, \"eval_loss\": loss}\n\n", "CodeBleu_score": 39.9816344418911}, {"code": "def metric_fn(per_example_loss, label_ids, logits, is_real_example)\n\t\n    # Create a mask to avoid performing a division by zero\n    mask = tf.cast(is_real_example, dtype=tf.float32)\n    # Calculate the accuracy of the model\n    accuracy = tf.metrics.accuracy(\n        labels=label_ids,\n        predictions=tf.argmax(input=logits, axis=-1),\n        weights=mask)\n    # Calculate the mean loss of the model\n    loss = tf.metrics.mean(values=per_example_loss, weights=mask)\n    return {\"eval_accuracy\": accuracy, \"eval_loss\": loss}\n\n", "CodeBleu_score": 48.52112345874956}]}
{"instance_id": "6154e4d28509", "generation_result": [{"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t  features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 81.70176627337192}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t  features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n\n", "CodeBleu_score": 81.70176627337192}, {"code": "def convert_examples_to_features(examples, label_list, max_seq_length,\n                                 tokenizer)\n\t  features = []\n    for (ex_index, example) in enumerate(examples):\n        if ex_index % 10000 == 0:\n            tf.logging.info(\"Writing example %d of %d\" % (ex_index, len(examples)))\n        feature = convert_single_example(ex_index, example, label_list,\n                                         max_seq_length, tokenizer)\n\n        features.append(feature)\n    return features\n", "CodeBleu_score": 81.70176627337192}]}
{"instance_id": "e09c0db71ebb", "generation_result": [{"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\", [2, bert_config.hidden_size],\n            initializer=create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    probabilities = tf.nn.softmax(logits, axis=-1)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n    return (loss, per_example_loss, logits, probabilities)\n\n", "CodeBleu_score": 72.3108671823971}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\", [2, bert_config.hidden_size],\n            initializer=create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    probabilities = tf.nn.softmax(logits, axis=-1)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n    return (loss, per_example_loss, logits, probabilities)\n\n", "CodeBleu_score": 72.3108671823971}, {"code": "def get_next_sentence_output(bert_config, input_tensor, labels)\n\t\n    with tf.variable_scope(\"cls/seq_relationship\"):\n        output_weights = tf.get_variable(\n            \"output_weights\", [2, bert_config.hidden_size],\n            initializer=create_initializer(bert_config.initializer_range))\n        output_bias = tf.get_variable(\n            \"output_bias\", [2], initializer=tf.zeros_initializer())\n\n    logits = tf.matmul(input_tensor, output_weights, transpose_b=True)\n    logits = tf.nn.bias_add(logits, output_bias)\n    log_probs = tf.nn.log_softmax(logits, axis=-1)\n    labels = tf.reshape(labels, [-1])\n    one_hot_labels = tf.one_hot(labels, depth=2, dtype=tf.float32)\n    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n    loss = tf.reduce_mean(per_example_loss)\n    return (loss, per_example_loss, log_probs)\n\n", "CodeBleu_score": 80.04427325067216}]}
{"instance_id": "1f66b020f485", "generation_result": [{"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.404511250960866}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(\n        tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                      [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.404511250960866}, {"code": "def gather_indexes(sequence_tensor, positions)\n\t\n    sequence_shape = modeling.get_shape_list(sequence_tensor, expected_rank=3)\n    batch_size = sequence_shape[0]\n    seq_length = sequence_shape[1]\n    width = sequence_shape[2]\n\n    flat_offsets = tf.reshape(tf.range(0, batch_size, dtype=tf.int32) * seq_length, [-1, 1])\n    flat_positions = tf.reshape(positions + flat_offsets, [-1])\n    flat_sequence_tensor = tf.reshape(sequence_tensor,\n                                    [batch_size * seq_length, width])\n    output_tensor = tf.gather(flat_sequence_tensor, flat_positions)\n    return output_tensor\n\n", "CodeBleu_score": 56.04245052903103}]}
{"instance_id": "956bffee9a33", "generation_result": [{"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    # tf.Example only supports tf.int64, but the TPU only supports tf.int32. So cast all int64 to int32.\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 60.19566542534298}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 60.19566542534298}, {"code": "def _decode_record(record, name_to_features)\n\t\n    example = tf.io.parse_single_example(record, name_to_features)\n    for name in list(example.keys()):\n        t = example[name]\n        if t.dtype == tf.int64:\n            t = tf.cast(t, tf.int32)\n        example[name] = t\n    return example\n\n", "CodeBleu_score": 60.19566542534298}]}
{"instance_id": "6b97f354e641", "generation_result": [{"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 79.51593464740901}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 79.51593464740901}, {"code": "def _improve_answer_span(doc_tokens, input_start, input_end, tokenizer,\n                         orig_answer_text)\n\t\n    tok_answer_text = \" \".join(tokenizer.tokenize(orig_answer_text))\n\n    for new_start in range(input_start, input_end + 1):\n        for new_end in range(input_end, new_start - 1, -1):\n            text_span = \" \".join(doc_tokens[new_start:(new_end + 1)])\n            if text_span == tok_answer_text:\n                return (new_start, new_end)\n\n    return (input_start, input_end)\n\n", "CodeBleu_score": 79.51593464740901}]}
{"instance_id": "aba334b92b34", "generation_result": [{"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}, {"code": "def _check_is_max_context(doc_spans, cur_span_index, position)\n\t\n    best_score = None\n    best_span_index = None\n    for (span_index, doc_span) in enumerate(doc_spans):\n        end = doc_span.start + doc_span.length - 1\n        if position < doc_span.start:\n            continue\n        if position > end:\n            continue\n        num_left_context = position - doc_span.start\n        num_right_context = end - position\n        score = min(num_left_context, num_right_context) + 0.01 * doc_span.length\n        if best_score is None or score > best_score:\n            best_score = score\n            best_span_index = span_index\n\n    return cur_span_index == best_span_index\n\n", "CodeBleu_score": 78.23889503357583}]}
{"instance_id": "cf92ad509f6a", "generation_result": [{"code": "def load_vocab(vocab_file)\n\t\n    vocab = OrderedDict()\n    index = 0\n    with codecs.open(vocab_file, \"r\", \"utf-8\") as reader:\n        for token in reader:\n            token = convert_to_unicode(token)\n            token = token.strip()\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 48.440398030066696}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = OrderedDict()\n    index = 0\n    with codecs.open(vocab_file, \"r\", \"utf-8\") as reader:\n        for line in reader:\n            token = convert_to_unicode(line.strip())\n            if not token:\n                continue\n            if token in vocab:\n                raise ValueError(\"Duplicated token in vocabulary file: %s\" % (token))\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 45.0525282496923}, {"code": "def load_vocab(vocab_file)\n\t\n    vocab = OrderedDict()\n    index = 0\n    with open(vocab_file, \"r\", encoding=\"utf-8\") as reader:\n        for token in reader:\n            token = convert_to_unicode(token.strip())\n            vocab[token] = index\n            index += 1\n    return vocab\n\n", "CodeBleu_score": 44.31027839112583}]}
{"instance_id": "6c865803ac12", "generation_result": [{"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        if item in vocab:\n            output.append(vocab[item])\n        else:\n            output.append(vocab[\"[UNK]\"])\n    return output\n\n", "CodeBleu_score": 61.18432676764351}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        if vocab.get(item) is not None:\n            output.append(vocab[item])\n        else:\n            output.append(vocab[\"[UNK]\"])\n    return output\n\n", "CodeBleu_score": 60.344055442402734}, {"code": "def convert_by_vocab(vocab, items)\n\t\n    output = []\n    for item in items:\n        if vocab.get(item) is not None:\n            output.append(vocab.get(item))\n    return output\n\n", "CodeBleu_score": 54.877697513209625}]}
{"instance_id": "e93b9200dc4a", "generation_result": [{"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    sub_tokens = []\n    for token in tokens:\n        sub_tokens.extend(self.wordpiece_tokenizer.tokenize(token))\n    return sub_tokens\n\n", "CodeBleu_score": 41.90409511360668}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    tokens = self.wordpiece_tokenizer.tokenize(tokens)\n    return tokens\n\n", "CodeBleu_score": 17.78552294320165}, {"code": "def tokenize(self, text)\n\t\n    tokens = self.basic_tokenizer.tokenize(text)\n    tokens = self.wordpiece_tokenizer.tokenize(tokens)\n    return tokens\n\n", "CodeBleu_score": 17.78552294320165}]}
{"instance_id": "2ff6f6db53c9", "generation_result": [{"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        data, _ = librosa.load(path, sr=sample_rate, mono=True, offset=offset, duration=duration)\n        return data, False\n    except Exception as e:\n        print(f\"Error loading file {path}: {e}\")\n        return -1.0, True\n\n", "CodeBleu_score": 28.77749237853633}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        data, _ = librosa.load(path, sr=sample_rate, mono=True, offset=offset, duration=duration)\n        data = data.astype(dtype)\n        return data, False\n    except Exception as e:\n        print(e)\n        return -1.0, True\n\n", "CodeBleu_score": 27.989509468167906}, {"code": "def safe_load(path, offset, duration, sample_rate, dtype)\n\t\n    try:\n        data, _ = librosa.load(path, sr=sample_rate, mono=True, offset=offset, duration=duration)\n        return data, False\n    except Exception as e:\n        print(\"Error loading audio file: \", e)\n        return -1.0, True\n\n", "CodeBleu_score": 29.15793922620937}]}
{"instance_id": "12fbe1f03d8f", "generation_result": [{"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    # TODO: Check if the waveform has more or equal channels than n_channels.\n    # TODO: If so, trim the waveform to the desired number of channels.\n    # TODO: If not, tile the waveform to increase the channels and then trim it.\n    # TODO: Return the adjusted waveform tensor.\n    pass\n\n", "CodeBleu_score": 19.62669684134857}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    if waveform.shape[0] == n_channels:\n        return waveform\n    if waveform.shape[0] < n_channels:\n        return tf.tile(waveform, [n_channels // waveform.shape[0]])[:n_channels]\n    return waveform[:n_channels]\n\n", "CodeBleu_score": 45.47757717900128}, {"code": "def to_n_channels(waveform: tf.Tensor, n_channels: int) -> tf.Tensor\n\t\n    waveform_shape = waveform.shape\n    waveform_channels = waveform_shape[-1]\n    if waveform_channels >= n_channels:\n        return waveform[..., :n_channels]\n    else:\n        return tf.tile(waveform, [1, 1, 1, n_channels - waveform_channels])\n\n", "CodeBleu_score": 39.153817366162656}]}
{"instance_id": "5e215f029b2e", "generation_result": [{"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return tf.clip_by_value(\n        tf.cast(\n            tf.round(\n                gain_to_db(\n                    spectrogram, **kwargs\n                )\n            ),\n            tf.uint8,\n        ),\n        -db_range,\n        db_range,\n    )\n\n", "CodeBleu_score": 34.01170483094463}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return tf.clip_by_value(\n        gain_to_db(spectrogram, **kwargs),\n        -db_range,\n        db_range,\n    ).numpy().astype(np.uint8)\n\n", "CodeBleu_score": 28.807088083998988}, {"code": "def spectrogram_to_db_uint(\n    spectrogram: tf.Tensor, db_range: float = 100.0, **kwargs\n) -> tf.Tensor\n\t\n    return tf.cast(\n        tf.clip_by_value(\n            tf.cast(\n                tf.math.floor(\n                    gain_to_db(spectrogram, **kwargs)\n                    + tf.math.log(tf.constant(db_range))\n                    / tf.math.log(tf.constant(10.0))\n                ),\n                dtype=tf.uint8,\n            ),\n            max=db_range,\n        ),\n        dtype=tf.uint8,\n    )\n\n", "CodeBleu_score": 38.645762586858424}]}
{"instance_id": "b65c0968dae7", "generation_result": [{"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window = tf.signal.hann_window(frame_length, periodic=True)\n    window = tf.pow(window, window_exponent)\n    stft = tf.signal.stft(\n        waveform, frame_length, frame_step, window=window, pad_end=True\n    )\n    spectrogram = tf.pow(tf.abs(stft), spec_exponent)\n    return spectrogram\n\n", "CodeBleu_score": 36.847692481908275}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    # Apply Hann window function\n    window = tf.signal.hann_window(frame_length, periodic=True)\n    window = tf.expand_dims(window, axis=0)\n    window = tf.tile(window, [waveform.shape[0], 1])\n    waveform = waveform * window\n    # Perform STFT\n    stft = tf.signal.stft(\n        waveform, frame_length, frame_step, window_fn=tf.signal.hann_window\n    )\n    # Transpose and raise to power\n    stft = tf.transpose(stft, [1, 2, 0])\n    stft = tf.abs(stft) ** spec_exponent\n    # Transpose and raise to power\n    stft = tf.transpose(stft, [2, 0, 1])\n    stft = tf.abs(stft) ** window_exponent\n    return stft\n\n", "CodeBleu_score": 39.18902060714084}, {"code": "def compute_spectrogram_tf(\n    waveform: tf.Tensor,\n    frame_length: int = 2048,\n    frame_step: int = 512,\n    spec_exponent: float = 1.0,\n    window_exponent: float = 1.0,\n) -> tf.Tensor\n\t\n    window = tf.signal.hann_window(frame_length)\n    window = tf.pow(window, window_exponent)\n    stft = tf.signal.stft(waveform, frame_length, frame_step, window=window)\n    spectrogram = tf.abs(stft)\n    spectrogram = tf.pow(spectrogram, spec_exponent)\n    return spectrogram\n\n", "CodeBleu_score": 32.858505527168326}]}
{"instance_id": "a4686140a634", "generation_result": [{"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    if factor < 1.0:\n        raise ValueError(\"Factor must be >= 1.0\")\n    if factor == 1.0:\n        return spectrogram\n    if factor == 2.0:\n        return tf.image.resize(\n            spectrogram,\n            [tf.shape(spectrogram)[0] * 2, tf.shape(spectrogram)[1]],\n            method=method,\n        )\n    new_time_dim = tf.cast(tf.shape(spectrogram)[1] * factor, tf.int32)\n    return tf.image.resize(\n        spectrogram,\n        [tf.shape(spectrogram)[0], new_time_dim],\n        method=method,\n    )\n\n", "CodeBleu_score": 37.39689641189624}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    return tf.image.resize(\n        spectrogram,\n        [int(tf.math.ceil(spectrogram.shape[0] * factor)), spectrogram.shape[1]],\n        method,\n    )\n\n", "CodeBleu_score": 24.28054915363646}, {"code": "def time_stretch(\n    spectrogram: tf.Tensor,\n    factor: float = 1.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    new_time = int(spectrogram.shape[1] * factor)\n    resized = tf.image.resize(\n        spectrogram, [spectrogram.shape[0], new_time], method=method\n    )\n    if new_time > spectrogram.shape[1]:\n        resized = resized[:, : spectrogram.shape[1]]\n    else:\n        resized = resized[:, : new_time]\n    return resized\n\n", "CodeBleu_score": 33.97152847085192}]}
{"instance_id": "6dd01101d4ae", "generation_result": [{"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor based on the semitone shift factor\n    resizing_factor = 2 ** (semitone_shift / 12)\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=(tf.shape(spectrogram)[0], tf.cast(tf.shape(spectrogram)[1] * resizing_factor, tf.int32)),\n        method=method,\n    )\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[0, 0], [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]], [0, 0]],\n    )\n    return padded_spectrogram\n\n", "CodeBleu_score": 34.79056026300441}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    if semitone_shift == 0.0:\n        return spectrogram\n\n    # Calculate the resizing factor based on the semitone shift\n    resize_factor = tf.exp(semitone_shift * np.log(2) / 12)\n\n    # Resize the spectrogram along the frequency axis using the specified method\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        size=(tf.shape(spectrogram)[0], tf.cast(tf.shape(spectrogram)[1] * resize_factor, tf.int32)),\n        method=method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        paddings=[\n            [0, 0],\n            [0, tf.shape(spectrogram)[1] - tf.shape(resized_spectrogram)[1]],\n        ],\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 40.14193813154626}, {"code": "def pitch_shift(\n    spectrogram: tf.Tensor,\n    semitone_shift: float = 0.0,\n    method: tf.image.ResizeMethod = tf.image.ResizeMethod.BILINEAR,\n) -> tf.Tensor\n\t\n    # Calculate the resizing factor\n    resize_factor = 2 ** (semitone_shift / 12)\n\n    # Resize the spectrogram along the frequency axis\n    resized_spectrogram = tf.image.resize(\n        spectrogram,\n        [\n            tf.cast(tf.shape(spectrogram)[0] * resize_factor, tf.int32),\n            tf.shape(spectrogram)[1],\n        ],\n        method,\n    )\n\n    # Pad the resized spectrogram to maintain the original dimensions\n    padded_spectrogram = tf.pad(\n        resized_spectrogram,\n        [[0, 0], [0, 0], [0, 0]],\n        constant_values=0,\n    )\n\n    return padded_spectrogram\n\n", "CodeBleu_score": 33.81692442378107}]}
{"instance_id": "612f0826e56a", "generation_result": [{"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    activation = params.get(\"conv_activation\")\n    if activation == \"relu\":\n        return nn.ReLU()\n    elif activation == \"elu\":\n        return nn.ELU(alpha=1.0)\n    elif activation == \"leaky_relu\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(\n            \"The provided conv_activation parameter is invalid. Please provide a valid activation layer.\"\n        )\n\n", "CodeBleu_score": 31.80259225321284}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params[\"conv_activation\"] == \"relu\":\n        return nn.ReLU()\n    elif params[\"conv_activation\"] == \"elu\":\n        return nn.ELU()\n    elif params[\"conv_activation\"] == \"leaky_relu\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(f\"The value of the \\\"conv_activation\\\" parameter is not valid: {params['conv_activation']}.\")\n\n", "CodeBleu_score": 28.554524280789273}, {"code": "def _get_conv_activation_layer(params: Dict) -> Any\n\t\n    if params[\"conv_activation\"] == \"ReLU\":\n        return nn.ReLU()\n    elif params[\"conv_activation\"] == \"ELU\":\n        return nn.ELU(alpha=1.0)\n    elif params[\"conv_activation\"] == \"LeakyReLU\":\n        return nn.LeakyReLU(negative_slope=0.2)\n    else:\n        raise ValueError(\"Unknown activation function.\")\n\n", "CodeBleu_score": 33.71969280747897}]}
{"instance_id": "2f8b5a2fc0f2", "generation_result": [{"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    output_dict = {}\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        logit_output = apply_unet(\n            input_tensor=input_tensor,\n            output_name=output_name,\n            params=params,\n            output_mask_logit=True,\n        )\n        output_dict[instrument] = logit_output\n    #\n    logit_mask = tf.stack(list(output_dict.values()), axis=4)\n    logit_mask = tf.reduce_max(logit_mask, axis=4)\n    #\n    logit_mask = tf.nn.softmax(logit_mask, axis=4)\n    #\n    output_dict = {}\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        logit_output = output_dict[instrument]\n        output_dict[instrument] = Multiply(name=output_name)([logit_output, logit_mask])\n    return output_dict\n\n", "CodeBleu_score": 46.59706907218759}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    output_dict = {}\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        output_mask_logit = params.get(\n            f\"{instrument}_output_mask_logit\", False\n        )  # default to False\n        output_tensor = apply_unet(\n            input_tensor,\n            output_name=output_name,\n            params=params,\n            output_mask_logit=output_mask_logit,\n        )\n        output_dict[instrument] = output_tensor\n    return output_dict\n\n", "CodeBleu_score": 38.94030279051007}, {"code": "def softmax_unet(\n    input_tensor: tf.Tensor, instruments: Iterable[str], params: Dict = {}\n) -> Dict\n\t\n    output_dict = {}\n    for instrument in instruments:\n        output_name = f\"{instrument}_output\"\n        output_mask_logit = params.get(\"output_mask_logit\", False)\n        output = apply_unet(\n            input_tensor=input_tensor,\n            output_name=output_name,\n            params=params,\n            output_mask_logit=output_mask_logit,\n        )\n        output_dict[instrument] = output\n    return output_dict\n\n", "CodeBleu_score": 36.34976644691301}]}
{"instance_id": "400b19ce8520", "generation_result": [{"code": "def compute_file_checksum(path)\n\t\n    sha256_hash = hashlib.sha256()\n    with open(path, 'rb') as f:\n        for byte_block in iter(lambda: f.read(4096), b\"\"):\n            sha256_hash.update(byte_block)\n    return sha256_hash.hexdigest()\n\n", "CodeBleu_score": 48.40393939054971}, {"code": "def compute_file_checksum(path)\n\t\n    hasher = hashlib.sha256()\n    with open(path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(4096), b\"\"):\n            hasher.update(chunk)\n    return hasher.hexdigest()\n\n", "CodeBleu_score": 55.959897418494876}, {"code": "def compute_file_checksum(path)\n\t\n    hasher = hashlib.sha256()\n    with open(path, 'rb') as afile:\n        buf = afile.read(65536)\n        while len(buf) > 0:\n            hasher.update(buf)\n            buf = afile.read(65536)\n    return hasher.hexdigest()\n\n", "CodeBleu_score": 35.57832999795482}]}
{"instance_id": "5f2e9c6e15f1", "generation_result": [{"code": "def checksum(self, name: str) -> str\n\t\n   ...\n\n", "CodeBleu_score": 5.319148936170212}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = f\"{self.host}/{self.repository}/{self.release_path}/{self.checksum_index}\"\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise Exception(f\"Failed to retrieve checksum for model {name} from {url}.\")\n    data = response.json()\n    if name not in data:\n        raise ValueError(f\"Model {name} not found in checksum index.\")\n    return data[name]\n\n", "CodeBleu_score": 38.34374727014257}, {"code": "def checksum(self, name: str) -> str\n\t\n    url = self.host + self.repository + self.release_path + self.checksum_index\n    response = requests.get(url)\n    if response.status_code!= 200:\n        raise ValueError(\"Failed to retrieve checksum for model \" + name)\n    json_response = response.json()\n    if name not in json_response:\n        raise ValueError(\"Model \" + name + \" not found in index\")\n    return json_response[name]\n\n", "CodeBleu_score": 39.237676607689295}]}
{"instance_id": "9312c8b6032e", "generation_result": [{"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            self.MODEL_ARCHIVES,\n            name,\n        )\n    )\n    response: httpx.Response = httpx.get(url)\n    response.raise_for_status()\n    archive: bytes = response.content\n    checksum: str = self.checksum(name)\n    if compute_file_checksum(archive)!= checksum:\n        raise ValueError(\"Checksum mismatch\")\n    with tempfile.NamedTemporaryFile(delete=False) as tmp:\n        tmp.write(archive)\n        with zipfile.ZipFile(tmp.name, \"r\") as zip:\n            zip.extractall(path)\n        os.remove(tmp.name)\n    logger.info(f\"Downloaded {name} model to {path}\")", "CodeBleu_score": 39.13314261362364}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            name,\n        )\n    )\n    response: httpx.Response = httpx.get(url, stream=True)\n    response.raise_for_status()\n    file_size: int = int(response.headers[\"content-length\"])\n    file_name: str = os.path.basename(url)\n    file_path: str = os.path.join(path, file_name)\n    file_temp: str = file_path + \".tmp\"\n    with open(file_temp, \"wb\") as file:\n        for chunk in response.iter_bytes(chunk_size=4096):\n            file.write(chunk)\n    if compute_file_checksum(file_path)!= self.checksum(name):\n        raise ValueError(\"Checksum mismatch\")\n    with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n        zip_ref.extractall(path)\n    os.remove(file_temp)", "CodeBleu_score": 40.35317528592851}, {"code": "def download(self, name: str, path: str) -> None:\n\t\n    url: str = \"/\".join(\n        (\n            self._host,\n            self._repository,\n            self.RELEASE_PATH,\n            self._release,\n            name,\n        )\n    )\n    response: httpx.Response = httpx.get(url)\n    response.raise_for_status()\n    response.stream()\n    checksum: str = self.checksum(name)\n    if compute_file_checksum(path)!= checksum:\n        raise ValueError(f\"Checksum mismatch for {name}\")\n    with tarfile.open(path, \"r:gz\") as archive:\n        archive.extractall(self._path)\n    os.remove(path)", "CodeBleu_score": 32.92041384525785}]}
{"instance_id": "ee9493f37d77", "generation_result": [{"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded:\"):\n        name = descriptor[len(\"embedded:\"):]\n        return json.loads(get_resource(name))\n    if os.path.exists(descriptor):\n        with open(descriptor) as f:\n            return json.load(f)\n    raise FileNotFoundError(f\"Configuration file {descriptor} not found\")\n\n", "CodeBleu_score": 39.25455697411904}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded://\"):\n        descriptor = descriptor[11:]\n        embedded_config = get_embedded_config(descriptor)\n        return json.loads(embedded_config)\n    elif os.path.isfile(descriptor):\n        if not os.path.exists(descriptor):\n            raise FileNotFoundError(f\"Configuration file '{descriptor}' not found.\")\n        with open(descriptor) as file:\n            return json.load(file)\n    else:\n        raise ValueError(f\"Configuration descriptor '{descriptor}' is not a valid path or embedded configuration.\")\n\n", "CodeBleu_score": 44.96865657718065}, {"code": "def load_configuration(descriptor: str) -> Dict\n\t\n    if descriptor.startswith(\"embedded:\"):\n        name = descriptor[len(\"embedded:\"):]\n        try:\n            with open(f\"embedded/{name}.json\") as f:\n                return json.load(f)\n        except FileNotFoundError:\n            raise ValueError(f\"Embedded configuration {name} not found.\")\n    else:\n        if not os.path.isfile(descriptor):\n            raise ValueError(f\"File {descriptor} not found.\")\n        with open(descriptor) as f:\n            return json.load(f)\n\n", "CodeBleu_score": 48.90680487961855}]}
{"instance_id": "546134b67fbc", "generation_result": [{"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(\n            f\"The concatenation axis must be either 0 or 1, but it is {concat_axis}.\"\n        )\n    for key, tensor in tensor_dict.items():\n        if tensor.shape[concat_axis]!= 1:\n            raise ValueError(\n                f\"The concatenation axis must be 0 or 1, but the tensor {key} has shape {tensor.shape}.\"\n            )\n    if concat_axis == 0:\n        concat_tensor = tf.concat([tensor for tensor in tensor_dict.values()], axis=0)\n        processed_tensor = func(concat_tensor)\n        split_tensor_dict = {\n            key: processed_tensor[\n                i : i + tensor_dict[key].shape[0]\n            ]  # type: ignore\n            for i, key in enumerate(tensor_dict.keys())\n        }\n    else:\n        concat_tensor = tf.concat([tensor for tensor in tensor_dict.values()], axis=1)\n        processed_tensor = func(concat_tensor)\n        split_tensor_dict = {\n            key: processed_tensor[\n                i : i + tensor_dict[key].shape[1]\n            ]  # type: ignore\n            for i, key in enumerate(tensor_dict.keys())\n        }\n    return split_tensor_dict\n\n", "CodeBleu_score": 40.94651949520792}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(f\"Concatenate axis must be either 0 or 1, not {concat_axis}.\")\n    concat_axis = 0 if concat_axis == 1 else 1\n    # Concatenate the tensors along the specified axis\n    tensors = [\n        tf.concat([tensor_dict[key] for key in sorted(tensor_dict.keys())], axis=concat_axis)\n        for key in sorted(tensor_dict.keys())\n    ]\n    # Apply the function to the concatenated tensor\n    processed_tensors = [func(tensor) for tensor in tensors]\n    # Split the processed tensors back into the original dictionary format based on the concatenation axis\n    processed_tensor_dict = {\n        key: tf.split(processed_tensor, len(tensor_dict[key]), axis=concat_axis)\n        for key, processed_tensor in zip(sorted(tensor_dict.keys()), processed_tensors)\n    }\n    return processed_tensor_dict\n\n", "CodeBleu_score": 40.34048506416463}, {"code": "def sync_apply(\n    tensor_dict: Dict[str, tf.Tensor], func: Callable, concat_axis: int = 1\n) -> Dict[str, tf.Tensor]\n\t\n    if concat_axis not in [0, 1]:\n        raise ValueError(\"The concatenation axis must be either 0 or 1.\")\n\n    if concat_axis == 0:\n        tensor_list = [tensor_dict[key] for key in tensor_dict.keys()]\n        tensor_concat = tf.concat(tensor_list, axis=0)\n        tensor_concat = func(tensor_concat)\n        tensor_list_processed = tf.split(tensor_concat, len(tensor_list), axis=0)\n        tensor_dict_processed = {}\n        for i, key in enumerate(tensor_dict.keys()):\n            tensor_dict_processed[key] = tensor_list_processed[i]\n    else:\n        tensor_list = [tensor_dict[key] for key in tensor_dict.keys()]\n        tensor_concat = tf.concat(tensor_list, axis=1)\n        tensor_concat = func(tensor_concat)\n        tensor_list_processed = tf.split(tensor_concat, len(tensor_list), axis=1)\n        tensor_dict_processed = {}\n        for i, key in enumerate(tensor_dict.keys()):\n            tensor_dict_processed[key] = tensor_list_processed[i]\n\n    return tensor_dict_processed\n\n", "CodeBleu_score": 41.97804887377339}]}
{"instance_id": "df48e78d46d2", "generation_result": [{"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    min_value = tf.reduce_min(tensor)\n    max_value = tf.reduce_max(tensor)\n\n    tensor = tf.math.divide(tensor, max_value)\n    tensor = tf.math.multiply(tensor, 255)\n\n    return {\n        tensor_key: tensor,\n        min_key: min_value,\n        max_key: max_value,\n    }\n\n", "CodeBleu_score": 43.17702527493463}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    tensor = tf.convert_to_tensor(tensor)\n    tensor_min = tf.reduce_min(tensor)\n    tensor_max = tf.reduce_max(tensor)\n    tensor_scaled = tf.cast(\n        tf.round(\n            tf.cast(\n                (tensor - tensor_min) / (tensor_max - tensor_min), tf.float32\n            )\n            * 255\n        ),\n        tf.uint8,\n    )\n    return {\n        tensor_key: tensor_scaled,\n        min_key: tensor_min,\n        max_key: tensor_max,\n    }\n\n", "CodeBleu_score": 55.94906125139726}, {"code": "def from_float32_to_uint8(\n    tensor: tf.Tensor,\n    tensor_key: str = \"tensor\",\n    min_key: str = \"min\",\n    max_key: str = \"max\",\n) -> tf.Tensor\n\t\n    tensor_min = tensor.numpy().min()\n    tensor_max = tensor.numpy().max()\n    tensor_min_key = tensor_key + \"_\" + min_key\n    tensor_max_key = tensor_key + \"_\" + max_key\n    tensor_min_value = tensor.numpy().min()\n    tensor_max_value = tensor.numpy().max()\n    tensor_min_dict = {tensor_min_key: tensor_min_value}\n    tensor_max_dict = {tensor_max_key: tensor_max_value}\n    tensor_scaled = (tensor - tensor_min) / (tensor_max - tensor_min)\n    tensor_scaled = tensor_scaled * 255\n    tensor_scaled = tensor_scaled.astype(np.uint8)\n    tensor_scaled_dict = {tensor_key: tensor_scaled}\n    return {**tensor_scaled_dict, **tensor_min_dict, **tensor_max_dict}\n\n", "CodeBleu_score": 42.0657384769501}]}
{"instance_id": "7f479e5de492", "generation_result": [{"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    pad_len = segment_len - tf.shape(tensor)[0] % segment_len\n    padded_tensor = tf.pad(tensor, [[0, pad_len]])\n    return tf.reshape(padded_tensor, [-1, segment_len])\n\n", "CodeBleu_score": 19.0169851952837}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    pad_needed = segment_len - tf.math.mod(tf.shape(tensor)[0], segment_len)\n    padded_tensor = tf.pad(tensor, [[0, pad_needed]])\n    reshaped_tensor = tf.reshape(padded_tensor, [-1, segment_len])\n    return reshaped_tensor\n\n", "CodeBleu_score": 24.733646019431525}, {"code": "def pad_and_partition(tensor: tf.Tensor, segment_len: int) -> tf.Tensor\n\t\n    padding = segment_len - tensor.shape[0] % segment_len\n    tensor = tf.pad(tensor, [[0, padding]], constant_values=0)\n    tensor = tf.reshape(tensor, [-1, segment_len])\n    return tensor\n\n", "CodeBleu_score": 18.04599541405133}]}
{"instance_id": "1789fae7253f", "generation_result": [{"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    num_rows_to_pad = frame_length - instr_spec.shape[1]\n    if num_rows_to_pad > 0:\n        instr_spec = tf.pad(instr_spec, [[0, 0], [0, num_rows_to_pad], [0, 0]])\n    instr_spec = tf.reshape(instr_spec, [1, -1, F])\n    return instr_spec\n\n", "CodeBleu_score": 16.655780577596214}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    n_rows = instr_spec.shape[0]\n    n_cols = instr_spec.shape[1]\n    n_rows_pad = frame_length - n_rows % frame_length\n    n_cols_pad = frame_length - n_cols % frame_length\n    instr_spec = np.pad(instr_spec, ((0, n_rows_pad), (0, n_cols_pad)), mode='constant', constant_values=0)\n    instr_spec = instr_spec.reshape(instr_spec.shape[0] // frame_length, frame_length, instr_spec.shape[1] // frame_length, frame_length)\n    instr_spec = instr_spec.transpose(0, 2, 1, 3).reshape(instr_spec.shape[0] * instr_spec.shape[1], frame_length, frame_length)\n    return instr_spec\n\n", "CodeBleu_score": 17.98848885502283}, {"code": "def pad_and_reshape(instr_spec, frame_length, F) -> Any\n\t\n    pad_size = frame_length - F.shape[1] % frame_length\n    pad_size = pad_size if pad_size > 0 else frame_length\n    pad = F.new_zeros(F.shape[0], 1, pad_size, F.shape[3])\n    F_pad = torch.cat([F, pad], dim=2)\n    F_reshape = F_pad.reshape(F_pad.shape[0], F_pad.shape[1], -1)\n    return F_reshape\n\n", "CodeBleu_score": 14.643493394465986}]}
{"instance_id": "8a4f4658d97c", "generation_result": [{"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path)\n    return tf.data.Dataset.from_tensor_slices(dict(df))\n\n", "CodeBleu_score": 17.895501042571066}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    dataframe = pd.read_csv(csv_path)\n    return tf.data.Dataset.from_tensor_slices(dataframe.values)\n\n", "CodeBleu_score": 21.76665829688156}, {"code": "def dataset_from_csv(csv_path: str, **kwargs) -> Any\n\t\n    df = pd.read_csv(csv_path)\n    return tf.data.Dataset.from_tensor_slices(df)\n\n", "CodeBleu_score": 17.232156492595102}]}
{"instance_id": "9a16e81b182f", "generation_result": [{"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for i in range(len(target_shape)):\n        result = result and tf.equal(tf.shape(tensor_tf)[i], target_shape[i])\n    return result\n\n", "CodeBleu_score": 31.983382699885066}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for dim, target_dim in zip(tensor_tf.shape, target_shape):\n        result = result and dim == target_dim\n    return result\n\n", "CodeBleu_score": 22.813212633768735}, {"code": "def check_tensor_shape(tensor_tf: tf.Tensor, target_shape: Any) -> bool\n\t\n    result = True\n    for dim in target_shape:\n        if isinstance(dim, int):\n            result = result and tensor_tf.shape[dim] == dim\n    return result\n\n", "CodeBleu_score": 25.782102474336344}]}
{"instance_id": "49d5d3084b3a", "generation_result": [{"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\tbuilder = DatasetBuilder(audio_params)\n    dataset = builder.build(\n        train_csv,\n        batch_size=audio_params[\"batch_size\"],\n        convert_to_uint=audio_params[\"convert_to_uint\"],\n        random_data_augmentation=audio_params[\"random_data_augmentation\"],\n        random_time_crop=audio_params[\"random_time_crop\"],\n        infinite_generator=audio_params[\"infinite_generator\"],\n        cache_directory=audio_params[\"cache_directory\"],\n        wait_for_cache=audio_params[\"wait_for_cache\"],\n        num_parallel_calls=audio_params[\"num_parallel_calls\"],\n        n_chunks_per_song=audio_params[\"n_chunks_per_song\"],\n    )\n    return dataset\n\n", "CodeBleu_score": 32.184211017023465}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\tdataset_builder = DatasetBuilder(\n        audio_params=audio_params,\n        audio_adapter=audio_adapter,\n        random_seed=42,\n        chunk_duration=11.88,\n    )\n    train_dataset = dataset_builder.build(\n        csv_path=audio_path,\n        batch_size=16,\n        shuffle=True,\n        convert_to_uint=True,\n        random_data_augmentation=True,\n        random_time_crop=True,\n        infinite_generator=True,\n        cache_directory=None,\n        wait_for_cache=True,\n        num_parallel_calls=8,\n        n_chunks_per_song=2,\n    )\n    return train_dataset\n\n", "CodeBleu_score": 30.089659495388375}, {"code": "def get_training_dataset(\n    audio_params: Dict, audio_adapter: AudioAdapter, audio_path: str\n) -> Any\n\t# Initialize DatasetBuilder\n    builder = DatasetBuilder(audio_params)\n    # Build training dataset\n    dataset = builder.build(\n        audio_path + \"/train.csv\",\n        batch_size=audio_params[\"batch_size\"],\n        shuffle=True,\n        random_data_augmentation=audio_params[\"random_data_augmentation\"],\n        random_time_crop=audio_params[\"random_time_crop\"],\n        infinite_generator=True,\n        cache_directory=audio_params[\"cache_directory\"],\n        wait_for_cache=audio_params[\"wait_for_cache\"],\n        num_parallel_calls=audio_params[\"num_parallel_calls\"],\n        n_chunks_per_song=audio_params[\"n_chunks_per_song\"],\n    )\n    return dataset\n\n", "CodeBleu_score": 32.94456847631261}]}
{"instance_id": "fe8bbbba06e3", "generation_result": [{"code": "def instruments(self) -> Any\n\t\n    if self.instrument_builders is None:\n        self.instrument_builders = [\n            InstrumentDatasetBuilder(self.data_dir, self.instruments[instrument_name])\n            for instrument_name in self.instruments.keys()\n        ]\n    for builder in self.instrument_builders:\n        yield builder\n\n", "CodeBleu_score": 37.23543641118569}, {"code": "def instruments(self) -> Any\n\t\n    if not self.instrument_builders:\n        for instrument in self.instruments:\n            self.instrument_builders.append(InstrumentDatasetBuilder(self, instrument))\n    for instrument_builder in self.instrument_builders:\n        yield instrument_builder\n\n", "CodeBleu_score": 44.85198340491184}, {"code": "def instruments(self) -> Any\n\t\n    if self.instrument_builders is None:\n        self.instrument_builders = []\n        for instrument in self.instruments_list:\n            self.instrument_builders.append(InstrumentDatasetBuilder(instrument))\n    for instrument_builder in self.instrument_builders:\n        yield instrument_builder\n\n", "CodeBleu_score": 49.92283026920172}]}
{"instance_id": "438b57fd3413", "generation_result": [{"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}, {"code": "def cache(self, dataset: Any, cache: Optional[str], wait: bool) -> Any\n\t\n    if cache is not None:\n        if wait:\n            while not exists(f\"{cache}.index\"):\n                logger.info(f\"Cache not available, wait {self.WAIT_PERIOD}\")\n                time.sleep(self.WAIT_PERIOD)\n        cache_path = os.path.split(cache)[0]\n        os.makedirs(cache_path, exist_ok=True)\n        return dataset.cache(cache)\n    return dataset\n\n", "CodeBleu_score": 93.65648279369884}]}
{"instance_id": "8838a3a09a66", "generation_result": [{"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    # load model directory\n    model_dir = ModelProvider(params[\"model_dir\"])\n    # update parameters\n    params.update(model_dir.params)\n    # set up session configuration\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    # create RunConfig\n    run_config = tf.estimator.RunConfig(session_config=config)\n    # initialize and return a TensorFlow estimator\n    return tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir.model_dir, params=params, config=run_config)\n\n", "CodeBleu_score": 27.792738459630726}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    model_provider = ModelProvider(params['model_dir'])\n    params = model_provider.update_params(params)\n    session_config = tf.ConfigProto(gpu_options=tf.GPUOptions(allow_growth=True))\n    run_config = tf.estimator.RunConfig(session_config=session_config)\n    if MWF:\n        model_fn = model_provider.get_model_fn(params['model_name'], params['model_version'])\n        estimator = tf.estimator.Estimator(model_fn=model_fn, model_dir=params['model_dir'], config=run_config)\n    else:\n        estimator = tf.estimator.Estimator(model_fn=model_provider.get_model_fn(params['model_name'], params['model_version']), model_dir=params['model_dir'], config=run_config)\n    return estimator\n\n", "CodeBleu_score": 38.747512364756275}, {"code": "def create_estimator(params: Dict, MWF: bool) -> tf.Tensor\n\t\n    # TODO: add MWF flag\n    model_provider = ModelProvider(params)\n    model_dir = model_provider.get_model_dir()\n    params = model_provider.get_params()\n    params[\"batch_size\"] = 1\n    params[\"num_epochs\"] = 1\n    params[\"learning_rate\"] = 0.001\n    params[\"train_steps\"] = 100\n    params[\"eval_steps\"] = 100\n    params[\"num_parallel_calls\"] = 1\n    params[\"num_classes\"] = 10\n    params[\"image_size\"] = (28, 28)\n    params[\"num_channels\"] = 1\n    params[\"model_type\"] = \"mnist\"\n    params[\"model_name\"] = \"mnist\"\n    params[\"model_version\"] = \"1\"\n    params[\"model_dir\"] = model_dir\n    params[\"data_dir\"] = os.path.join(model_dir, \"data\")\n    params[\"data_format\"] = \"channels_last\"\n    params[\"data_type\"] = \"float32\"\n    params[\"dtype\"] = \"float32\"\n    params[\"save_checkpoints_steps\"] = 100\n    params[\"save_summary_steps\"] = 100\n    params[\"keep_checkpoint_max\"] = 100\n    params[\"keep_checkpoint_every_n_hours\"] = 10000\n    params[\"log_step_count_steps\"] = 100\n    params[\"save_summary_steps\"] = 100\n    params[\"save_checkpoints_steps\"] = 100\n    params[\"log_step_count_steps\"] = 100\n    params[\"session_config\"] = tf.ConfigProto(\n        allow_soft_placement=True, log_device_placement=True\n    )\n    params[\"session_config\"].gpu_options.allow_growth = True\n    run_config = RunConfig(session_config=params[\"session_config\"])\n    estimator = tf.estimator.Estimator(\n        model_fn=model_fn,\n        model_dir=params[\"model_dir\"],\n        params=params,\n        config=run_config,\n    )\n    return estimator\n\n", "CodeBleu_score": 30.824911031550656}]}
{"instance_id": "779c812bf2cb", "generation_result": [{"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = _ensure_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self.update_data((waveform, audio_descriptor))\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction\n\n", "CodeBleu_score": 43.304946970915}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    if waveform.shape[1] == 1:\n        waveform = np.concatenate([waveform, waveform], axis=1)\n    self._data_generator = DataGenerator(waveform, audio_descriptor)\n    prediction_generator = self._get_prediction_generator()\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction", "CodeBleu_score": 63.39632343072048}, {"code": "def _separate_tensorflow(\n        self, waveform: np.ndarray, audio_descriptor: AudioDescriptor\n    ) -> Dict\n\t\n    waveform = _ensure_stereo(waveform)\n    prediction_generator = self._get_prediction_generator()\n    self._data_generator.update_data((waveform, audio_descriptor))\n    prediction = next(prediction_generator)\n    prediction.pop(\"audio_id\")\n    return prediction", "CodeBleu_score": 44.81995773150508}]}
{"instance_id": "cf580cd2ed93", "generation_result": [{"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    elif config.BACKBONE == \"resnet50\":\n        assert (\n            image_shape[0] % 32 == 0\n        ), \"Image size must be divisible by 32 when using the ResNet50 backbone.\"\n        return np.array(\n            [\n                [\n                    int(math.ceil(image_shape[0] / stride))\n                    for stride in config.BACKBONE_STRIDES\n                ],\n                [\n                    int(math.ceil(image_shape[1] / stride))\n                    for stride in config.BACKBONE_STRIDES\n                ],\n            ]\n        )\n    elif config.BACKBONE == \"resnet101\":\n        assert (\n            image_shape[0] % 32 == 0\n        ), \"Image size must be divisible by 32 when using the ResNet101 backbone.\"\n        return np.array(\n            [\n                [\n                    int(math.ceil(image_shape[0] / stride))\n                    for stride in config.BACKBONE_STRIDES\n                ],\n                [\n                    int(math.ceil(image_shape[1] / stride))\n                    for stride in config.BACKBONE_STRIDES\n                ],\n            ]\n        )\n    else:\n        raise ValueError(\n            \"Backbone must be one of: resnet50, resnet101. Received: {}\".format(\n                config.BACKBONE\n            )\n        )\n\n", "CodeBleu_score": 51.66651447976087}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    if config.BACKBONE == \"resnet50\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    if config.BACKBONE == \"resnet101\":\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))]\n             for stride in config.BACKBONE_STRIDES])\n    raise ValueError(\"Backbone name is not recognized\")\n\n", "CodeBleu_score": 72.7578044569817}, {"code": "def compute_backbone_shapes(config, image_shape)\n\t\n    if callable(config.BACKBONE):\n        return config.COMPUTE_BACKBONE_SHAPE(image_shape)\n    else:\n        assert config.BACKBONE in [\"resnet50\", \"resnet101\"]\n        return np.array(\n            [[int(math.ceil(image_shape[0] / stride)), int(math.ceil(image_shape[1] / stride))] for stride in config.BACKBONE_STRIDES]\n        )\n\n", "CodeBleu_score": 89.23569476063783}]}
{"instance_id": "ebd61a2e59ca", "generation_result": [{"code": "def clip_boxes_graph(boxes, window)\n\t\n    # Split window (y1, x1, y2, x2) into an array\n    # [(y1_start, y2_end), (x1_start, x2_end)]\n    window = tf.cast(window, tf.float32)\n    (y1, x1, y2, x2) = tf.split(window, 4)\n    (h, w) = tf.split(tf.cast(tf.shape(boxes)[:2], tf.float32), 2)\n    # Clip boxes. The 2 here is because we want to ignore the last two components\n    clipped_boxes = tf.minimum(tf.maximum(boxes[:, :2], y1), y2)\n    clipped_boxes = tf.minimum(tf.maximum(clipped_boxes[:, :2], x1), x2)\n    clipped_boxes = tf.maximum(tf.minimum(clipped_boxes[:, :2], y2), y1)\n    clipped_boxes = tf.maximum(tf.minimum(clipped_boxes[:, :2], x2), x1)\n    clipped_boxes = tf.minimum(clipped_boxes, tf.stack([y2, x2]))\n    clipped_boxes = tf.maximum(clipped_boxes, tf.stack([y1, x1]))\n    clipped_boxes = tf.maximum(clipped_boxes, 0.0)\n    clipped_boxes /= tf.stack([h, w])\n    return clipped_boxes\n\n", "CodeBleu_score": 22.408934459701577}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n    window_shape = tf.shape(window)\n    height = window_shape[0]\n    width = window_shape[1]\n    x1 = tf.maximum(tf.minimum(boxes[:, :, 0], width), 0)\n    y1 = tf.maximum(tf.minimum(boxes[:, :, 1], height), 0)\n    x2 = tf.maximum(tf.minimum(boxes[:, :, 2], width), 0)\n    y2 = tf.maximum(tf.minimum(boxes[:, :, 3], height), 0)\n    clipped_boxes = tf.concat([x1[:, :, tf.newaxis], y1[:, :, tf.newaxis], x2[:, :, tf.newaxis], y2[:, :, tf.newaxis]], axis=-1)\n    clipped_boxes = tf.clip_by_value(clipped_boxes, 0, 1)\n    return clipped_boxes\n\n", "CodeBleu_score": 22.14579697566188}, {"code": "def clip_boxes_graph(boxes, window)\n\t\n\n    # Split window (y1, x1, y2, x2) into an array of y1, x1, y2, x2\n    window = tf.stack([window[0], window[1], window[2], window[3]])\n\n    # Split boxes (y1, x1, y2, x2) into an array of y1, x1, y2, x2\n    boxes = tf.stack([boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]])\n\n    # Clip the window with the boxes\n    clipped_window = tf.clip_by_value(window, tf.reduce_min(boxes), tf.reduce_max(boxes))\n\n    # Split clipped window (y1, x1, y2, x2) into an array of y1, x1, y2, x2\n    clipped_window = tf.stack([clipped_window[0], clipped_window[1], clipped_window[2], clipped_window[3]])\n\n    # Split clipped boxes (y1, x1, y2, x2) into an array of y1, x1, y2, x2\n    clipped_boxes = tf.stack([boxes[:, 0], boxes[:, 1], boxes[:, 2], boxes[:, 3]])\n\n    clipped_boxes_y1y2 = tf.stack([clipped_boxes[:, 0], clipped_boxes[:, 2]])\n    clipped_boxes_x1x2 = tf.stack([clipped_boxes[:, 1], clipped_boxes[:, 3]])\n\n    clipped_window_y1y2 = tf.stack([clipped_window[0], clipped_window[2]])\n    clipped_window_x1x2 = tf.stack([clipped_window[1], clipped_window[3]])\n\n    clipped_boxes_y1y2 = tf.maximum(clipped_boxes_y1y2, clipped_window_y1y2)\n    clipped_boxes_x1x2 = tf.maximum(clipped_boxes_x1x2, clipped_window_x1x2)\n\n    clipped_boxes_y1y2 = tf.minimum(clipped_boxes_y1y2, clipped_window_y1", "CodeBleu_score": 10.866448735359274}]}
{"instance_id": "8e0411587a70", "generation_result": [{"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n\n    # Define shared convolutional layers which will be shared by the two convolutional layers for class scores and bounding box predictions\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride, name='rpn_conv_shared')\n\n    # Define the convolutional layer for class scores\n    class_logits = KL.TimeDistributed(KL.Conv2D(anchors_per_location * num_classes, (1, 1), padding='valid', activation='linear', name='rpn_class_logits'), name='rpn_class_logits')\n\n    # Define the convolutional layer for bounding box refinements\n    refine = KL.TimeDistributed(KL.Conv2D(anchors_per_location * (num_classes * 4), (1, 1), padding='valid', activation='linear', name='rpn_bbox_refine'), name='rpn_bbox_refine')\n\n    # Apply the shared convolutional layers to the input feature map\n    shared_layers = shared(feature_map)\n\n    # Apply the convolutional layer for class scores to the shared layers\n    x = class_logits(shared_layers)\n\n    # Reshape the class logits to (batch, height * width * anchors, num_classes)\n    # Each row in the tensor contains the class probabilities for a single anchor\n    class_logits = KL.Reshape((-1, num_classes), name='rpn_class_logits_reshape')(x)\n\n    # Apply the softmax activation to the class logits to obtain class probabilities\n    class_probs = KL.Activation('softmax', name='rpn_class_probs')(class_logits)\n\n    # Apply the convolutional layer for bounding box refinements to the shared layers\n    x = refine(shared_layers)\n\n    # Reshape the refined bounding box values to (batch, height * width * anchors, num_classes * 4)\n    # Each row in the tensor contains the refined bounding box data for a single anchor\n    bbox_deltas = KL.Reshape((-1, num_classes * 4), name='rpn_bbox_pred_reshape')(x)\n\n    return class_logits, class_probs, bbox_deltas\n\n", "CodeBleu_score": 45.524026893805164}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    num_anchors = len(anchors_per_location)\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride, name='rpn_conv_shared')(feature_map)\n\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = KL.Conv2D(2 * num_anchors, (1, 1), activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape to [batch, anchors, 2]\n    rpn_class_logits = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x)\n\n    # Softmax on last dimension of BG/FG.\n    rpn_probs = KL.Lambda(lambda t: tf.nn.softmax(t))(rpn_class_logits)\n\n    # Bounding box refinement. [batch, H, W, anchors per location * depth]\n    # where depth is [x, y, log(w), log(h)]\n    x = KL.Conv2D(num_anchors * 4, (1, 1), activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape to [batch, anchors, 4]\n    rpn_bbox = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x)\n\n    return [rpn_class_logits, rpn_probs, rpn_bbox]\n\n", "CodeBleu_score": 50.459076515123726}, {"code": "def rpn_graph(feature_map, anchors_per_location, anchor_stride)\n\t\n    # Shared convolutional base of the RPN\n    shared = KL.Conv2D(512, (3, 3), padding='same', activation='relu', strides=anchor_stride, name='rpn_conv_shared')(feature_map)\n\n    # Anchor Score. [batch, height, width, anchors per location * 2].\n    x = KL.Conv2D(anchors_per_location * 2, (1, 1), padding='valid', activation='linear', name='rpn_class_raw')(shared)\n\n    # Reshape to [batch, anchors, 2].\n    # [batch, anchors per location, 2] -> [batch, anchors, 2]\n    rpn_class_logits = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 2]))(x)\n\n    # Softmax on last dimension of BG/FG.\n    rpn_probs = KL.Activation('softmax', name='rpn_class_xxx')(rpn_class_logits)\n\n    # Bounding box refinement. [batch, H, W, anchors per location, depth]\n    # where depth is [x, y, log(w), log(h)]\n    x = KL.Conv2D(anchors_per_location * 4, (1, 1), padding='valid', activation='linear', name='rpn_bbox_pred')(shared)\n\n    # Reshape to [batch, anchors, 4]\n    # [batch, anchors per location, 4] -> [batch, anchors, 4]\n    rpn_bbox = KL.Lambda(lambda t: tf.reshape(t, [tf.shape(t)[0], -1, 4]))(x)\n\n    return [rpn_class_logits, rpn_probs, rpn_bbox]\n\n", "CodeBleu_score": 71.90461041126031}]}
{"instance_id": "70777c9261d8", "generation_result": [{"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_loss = K.abs(y_true - y_pred)\n    squared_loss = 0.5 * K.square(y_true - y_pred)\n    linear_loss = K.abs(y_true - y_pred) - 0.5\n    mask = K.cast(K.less(abs_loss, 1.0), K.floatx())\n    loss = K.sum(mask * squared_loss + (1 - mask) * linear_loss)\n    return loss\n\n", "CodeBleu_score": 42.96291068471148}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    abs_diff = K.abs(y_true - y_pred)\n    mask = K.cast(K.less(abs_diff, 1.0), 'float32')\n    loss = (abs_diff - 0.5) * mask + 0.5 * abs_diff * (1 - mask)\n    return loss\n\n", "CodeBleu_score": 30.782490252025745}, {"code": "def smooth_l1_loss(y_true, y_pred)\n\t\n    diff = K.abs(y_true - y_pred)\n    less_than_one = K.cast(K.less(diff, 1.0), \"float32\")\n    loss = (less_than_one * 0.5 * diff ** 2) + (1 - less_than_one) * (diff - 0.5)\n    return loss\n\n", "CodeBleu_score": 58.60419868806381}]}
{"instance_id": "0e747b604087", "generation_result": [{"code": "def build_model(x_train, num_classes)\n\t\n    # Reset the graph\n    tf.reset_default_graph()\n    # Define the input layer with the shape of the training data\n    inputs = tf.placeholder(tf.float32, shape=(None, x_train.shape[1], x_train.shape[2], x_train.shape[3]))\n    # Define the first convolutional layer with 32 filters, 3x3 kernel size, and ReLU activation\n    conv1 = tf.layers.conv2d(inputs, 32, 3, activation=tf.nn.relu)\n    # Define the second convolutional layer with 64 filters, 3x3 kernel size, and ReLU activation\n    conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n    # Define the max-pooling layer with 2x2 pooling size\n    pool = tf.layers.max_pooling2d(conv2, 2, 2)\n    # Flatten the output of the max-pooling layer\n    flat = tf.layers.flatten(pool)\n    # Define the first dense layer with 128 units and ReLU activation\n    dense1 = tf.layers.dense(flat, 128, activation=tf.nn.relu)\n    # Define the second dense layer with the number of classes and softmax activation for classification\n    outputs = tf.layers.dense(dense1, num_classes, activation=tf.nn.softmax)\n    # Compile the model with the Adam optimizer, categorical cross-entropy loss, and accuracy metric\n    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n    model.compile(optimizer=tf.train.AdamOptimizer(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 26.997526096793422}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    x = tf.placeholder(tf.float32, shape=(None, 32, 32, 3), name=\"x\")\n    y = tf.placeholder(tf.float32, shape=(None, num_classes), name=\"y\")\n\n    conv1 = tf.layers.conv2d(\n        inputs=x,\n        filters=32,\n        kernel_size=[5, 5],\n        padding=\"same\",\n        activation=tf.nn.relu)\n    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n\n    conv2 = tf.layers.conv2d(\n        inputs=pool1,\n        filters=64,\n        kernel_size=[5, 5],\n        padding=\"same\",\n        activation=tf.nn.relu)\n    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n\n    pool2_flat = tf.reshape(pool2, [-1, 8 * 8 * 64])\n    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n    logits = tf.layers.dense(inputs=dense, units=num_classes)\n\n    return tf.estimator.Estimator(\n        model_fn=cnn_model_fn,\n        model_dir=\"./models/cnn_model\",\n        params={\"num_classes\": num_classes})\n\n", "CodeBleu_score": 26.666662758570357}, {"code": "def build_model(x_train, num_classes)\n\t\n    tf.reset_default_graph()\n    model = tf.keras.models.Sequential()\n    model.add(tf.keras.layers.Conv2D(16, (3, 3), activation='relu', input_shape=x_train.shape[1:]))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu'))\n    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(tf.keras.layers.Flatten())\n    model.add(tf.keras.layers.Dense(128, activation='relu'))\n    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model\n\n", "CodeBleu_score": 25.288498948624405}]}
{"instance_id": "813e3e2844f4", "generation_result": [{"code": "def extract_bboxes(mask)\n\t\n    boxes = []\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        if not np.sum(m):\n            boxes.append([0, 0, 0, 0])\n            continue\n        y, x = np.where(m)\n        y1, y2 = np.min(y), np.max(y)\n        x1, x2 = np.min(x), np.max(x)\n        boxes.append([x1, y1, x2 - x1 + 1, y2 - y1 + 1])\n    return np.array(boxes).astype(np.int32)\n\n", "CodeBleu_score": 29.4289811710354}, {"code": "def extract_bboxes(mask)\n\t\n\n    boxes = np.zeros((mask.shape[-1], 4), dtype=np.int32)\n\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        # Bounding box.\n        horizontal_indicies = np.where(np.any(m, axis=0))[0]\n        vertical_indicies = np.where(np.any(m, axis=1))[0]\n\n        if horizontal_indicies.shape[0]:\n            x1, x2 = horizontal_indicies[[0, -1]]\n            y1, y2 = vertical_indicies[[0, -1]]\n            # x2 and y2 should not be part of the box. Increment by 1.\n            x2 += 1\n            y2 += 1\n        else:\n            # No mask for this instance. Might happen due to\n            # resizing or cropping. Set bbox to zeros\n            x1, x2, y1, y2 = 0, 0, 0, 0\n        boxes[i] = np.array([y1, x1, y2, x2])\n    return boxes\n\n", "CodeBleu_score": 56.717662120661714}, {"code": "def extract_bboxes(mask)\n\t\n    boxes = np.zeros((mask.shape[-1], 4), dtype='int')\n    for i in range(mask.shape[-1]):\n        m = mask[:, :, i]\n        # determine the horizontal and vertical indices where the mask is present\n        horizontal_indices, vertical_indices = np.where(m)\n        # if there are no mask pixels, set the bounding box to zeros\n        if len(horizontal_indices) == 0:\n            boxes[i] = [0, 0, 0, 0]\n        else:\n            # determine the bounding box coordinates based on the indices\n            x1, x2 = horizontal_indices.min(), horizontal_indices.max() + 1\n            y1, y2 = vertical_indices.min(), vertical_indices.max() + 1\n            # store the bounding box coordinates in the array\n            boxes[i] = [x1, y1, x2, y2]\n    return boxes\n\n", "CodeBleu_score": 34.71222517577267}]}
{"instance_id": "7ad5d430d6ed", "generation_result": [{"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    box_area = box_area\n    boxes_area = boxes_area\n    intersection_area = np.multiply(np.minimum(box[2], boxes[:, 2]), np.minimum(box[3], boxes[:, 3]))\n    union_area = box_area + boxes_area - intersection_area\n    iou = intersection_area / union_area\n    return iou\n\n", "CodeBleu_score": 25.926068180116697}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    box_area = box[2] * box[3]\n    intersection_areas = [box_area if box_area > boxes_area[i] else boxes_area[i] for i, box in enumerate(boxes)]\n    union_areas = [box_area + boxes_area[i] - intersection_areas[i] for i, box in enumerate(boxes)]\n    ious = [intersection_areas[i] / union_areas[i] for i, box in enumerate(boxes)]\n    return ious\n\n", "CodeBleu_score": 17.380883043755055}, {"code": "def compute_iou(box, boxes, box_area, boxes_area)\n\t\n    # Compute the intersection areas between the box and each box in the array\n    intersection_areas = np.minimum(np.expand_dims(box[2], axis=0), boxes[2]) * np.minimum(np.expand_dims(box[3], axis=0), boxes[3])\n    # Compute the union areas using the provided box areas and the intersection areas\n    union_areas = box_area + boxes_area - intersection_areas\n    # Compute the IoU values\n    iou = intersection_areas / union_areas\n    return iou\n\n", "CodeBleu_score": 24.417562965783773}]}
{"instance_id": "15941b852859", "generation_result": [{"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # 1. Tile boxes2 and repeate boxes1. This allows us to compare each\n    # box in boxes1 to all boxes in boxes2.\n    boxes1 = np.tile(np.expand_dims(boxes1, 1), [1, 1, len(boxes2)])\n    boxes2 = np.tile(np.expand_dims(boxes2, 0), [len(boxes1), 1, 1])\n    # 2. Compute intersections\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        box2 = boxes2[:, :, i]\n        overlaps[:, i] = compute_iou(box2, boxes1, box2.area(), boxes1.area())\n    return overlaps\n\n", "CodeBleu_score": 38.57734550700873}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # If no boxes, return empty matrix\n    boxes1 = np.array(boxes1)\n    boxes2 = np.array(boxes2)\n\n    if len(boxes1) == 0 or len(boxes2) == 0:\n        return np.zeros((len(boxes1), len(boxes2)))\n\n    # Calculate box areas\n    box1_area = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    box2_area = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n\n    # Compute overlaps to generate matrix [boxes1 count, boxes2 count]\n    overlaps = np.zeros((len(boxes1), len(boxes2)))\n    for i in range(len(boxes1)):\n        box1_area = (boxes1[i, 2] - boxes1[i, 0]) * (boxes1[i, 3] - boxes1[i, 1])\n        for j in range(len(boxes2)):\n            box2_area = (boxes2[j, 2] - boxes2[j, 0]) * (boxes2[j, 3] - boxes2[j, 1])\n            overlaps[i, j] = compute_iou(boxes1[i], boxes2[j], box1_area, box2_area)\n\n    return overlaps\n\n", "CodeBleu_score": 53.1987229372868}, {"code": "def compute_overlaps(boxes1, boxes2)\n\t\n    # Areas of anchors and GT boxes\n    area1 = (boxes1[:, 2] - boxes1[:, 0]) * (boxes1[:, 3] - boxes1[:, 1])\n    area2 = (boxes2[:, 2] - boxes2[:, 0]) * (boxes2[:, 3] - boxes2[:, 1])\n\n    # Compute overlaps to generate matrix [boxes1 count, boxes2 count]\n    # Each cell contains the IoU value.\n    overlaps = np.zeros((boxes1.shape[0], boxes2.shape[0]))\n    for i in range(overlaps.shape[1]):\n        box = boxes1[i]\n        overlaps[:, i] = compute_iou(box, boxes2, area1[i], area2)\n    return overlaps\n\n", "CodeBleu_score": 56.38769259266322}]}
{"instance_id": "597533722ce3", "generation_result": [{"code": "def load_image(self, image_id):\n\t\n    image_path = self.image_info[image_id]['path']\n    image = skimage.io.imread(image_path)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 63.64741927437648}, {"code": "def load_image(self, image_id):\n\t\n    if image_id not in self.image_info:\n        raise Exception(\"Invalid image ID: \" + image_id)\n    image = self.image_info[image_id]['path']\n    image = skimage.io.imread(image)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 66.11343342159684}, {"code": "def load_image(self, image_id):\n\t\n    image_info = self.image_info[image_id]\n    path = image_info[\"path\"]\n    image = skimage.io.imread(path)\n    if image.shape[-1] == 4:\n        image = image[..., :3]\n    return image\n\n", "CodeBleu_score": 63.9763485914425}]}
{"instance_id": "9b852997ca05", "generation_result": [{"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    assert((titles is None)or (len(images) == len(titles)))\n    n_images = len(images)\n    if titles is None: titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images / float(cols)), n + 1)\n        if cmap is None:\n            cmap = 'gray'\n        if norm is None:\n            norm = 'none'\n        if interpolation is None:\n            interpolation = 'none'\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 36.246915802115964}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    n_images = len(images)\n    if titles is None:\n        titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n    fig = plt.figure()\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(cols, np.ceil(n_images / float(cols)), n + 1)\n        if cmap is None:\n            cmap = 'gray'\n        if norm is None:\n            norm = 'linear'\n        if interpolation is None:\n            interpolation = 'none'\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 37.632387436361356}, {"code": "def display_images(images, titles=None, cols=4, cmap=None, norm=None,\n                   interpolation=None)\n\t\n    n_images = len(images)\n    if titles is None:\n        titles = ['Image (%d)' % i for i in range(1, n_images + 1)]\n    fig = plt.figure()\n    n_rows = (n_images + cols - 1) // cols\n    for n, (image, title) in enumerate(zip(images, titles)):\n        a = fig.add_subplot(n_rows, cols, n + 1)\n        if cmap is None:\n            cmap = 'gray'\n        if norm is None:\n            norm = 'none'\n        if interpolation is None:\n            interpolation = 'none'\n        plt.imshow(image, cmap=cmap, norm=norm, interpolation=interpolation)\n        plt.title(title)\n        plt.axis('off')\n    fig.set_size_inches(np.array(fig.get_size_inches()) * n_images)\n    plt.show()\n\n", "CodeBleu_score": 36.752355780268076}]}
