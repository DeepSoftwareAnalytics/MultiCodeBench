{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait) - 2\n    return wait_time, self._original_connect(*args)\n\n", "CodeBleu_score": 46.097698630603986}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    if self._live.is_set():\n        return self._retry(self._do_call, *args)\n    with self._live.get_lock():\n        if not self._live.is_set():\n            self._live.set()\n            self._reset()\n            self._wake_event.set()\n            self._reset_watchers()\n            self._call(*args)\n    return self._retry(self._do_call, *args)\n\n", "CodeBleu_score": 43.26307598661101}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait = self.loop_wait - 2\n    wait *= 1000\n    return (wait, self._orig_connect(*args))\n\n", "CodeBleu_score": 47.7636102532475}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    if config.retry_timeout != self._client.retry.deadline:\n        self.set_retry_timeout(config.retry_timeout)\n    if config.loop_wait != self._loop_wait:\n        self._loop_wait = config.loop_wait\n        if self._client.handler.name == 'SequentialThreadingHandler':\n            self.set_connect_timeout(self._loop_wait)\n    if config.ttl != self._client.session_timeout:\n        if not self.set_ttl(config.ttl):\n            self._client.stop()\n\n", "CodeBleu_score": 39.20375007805894}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if not config:\n        return\n    if isinstance(config, Config):\n        config = config.config\n    if 'retry_timeout' in config:\n        self.set_retry_timeout(config['retry_timeout'])\n    if 'loop_wait' in config:\n        self.set_loop_wait(config['loop_wait'])\n    if 'ttl' in config:\n        if self.set_ttl(config['ttl']):\n            self.set_connect_timeout(config['loop_wait'])\n\n", "CodeBleu_score": 33.525095768414374}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.config\n    if config.get('retry_timeout') is not None:\n        self.set_retry_timeout(config.get('retry_timeout'))\n    if config.get('loop_wait') is not None:\n        loop_wait = config.get('loop_wait')\n        if loop_wait != self.loop_wait:\n            self.loop_wait = loop_wait\n            if isinstance(self._client, KazooClient) and self._client.handler.name == 'threading':\n                self.set_connect_timeout(loop_wait)\n            if self.set_ttl(config.get('ttl', 30)):\n                self.restart()\n    if config.get('ttl') is not None:\n        self.set_ttl(config.get('ttl'))\n", "CodeBleu_score": 40.77843053462328}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(self)\n    cluster.initialize(path)\n    cluster.configuration = self.get_node(path + self._CONFIG)\n    cluster.history = self.get_node(path + self._HISTORY)\n    cluster.sync = self.get_node(path + self._SYNC)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n", "CodeBleu_score": 12.303905098578198}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    state = self.get_node(path + self._STATE)\n    config = self.get_node(path + self._CONFIG)\n    history = self.get_node(path + self._HISTORY)\n    sync = self.get_node(path + self._SYNC)\n    members = self.load_members(path)\n    leader = self.get_leader(path)\n    status = self.get_status(path, leader)\n    failover = self.get_node(path + self._FAILOVER)\n    failsafe_mode = self.get_node(path + self._FAILSAFE_MODE)\n    return Cluster(\n        state and state[0],\n        config and config[0],\n        history and history[0],\n        sync and sync[0],\n        members,\n        leader,\n        status,\n        failover and failover[0],\n        failsafe_mode and failsafe_mode[0],\n    )\n", "CodeBleu_score": 19.46085891607399}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if self.get_node(path + self._STATUS) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._CONFIG) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._HISTORY) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._SYNC) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._MEMBERS) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._LEADER) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._FAILOVER) is None:\n        raise NoNodeError\n\n    if self.get_node(path + self._FAILSAFE) is None:\n        raise NoNodeError\n\n    config = self.get_node(path + self._CONFIG)\n    history = self.get_node(path + self._HISTORY)\n    sync = self.get_node(path + self._SYNC)\n    members = self.load_members(path)\n    leader = self.get_node(path + self._LEADER)\n    failover = self.get_node(path + self._FAILOVER)\n    failsafe = self.get_node(path + self._FAILSAFE)\n    status = self.get_status(path, leader)\n\n    return Cluster(\n        path,\n        config and config[0],\n        history and history[0],\n        sync and sync[0],\n        members,\n        leader and leader[0],\n        failover and failover[0],\n        failsafe and failsafe[0],\n        status,\n    )\n", "CodeBleu_score": 30.338687399929793}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    while True:\n        try:\n            self.zk.create(self.leader_path, value=self.id, ephemeral=True)\n            return True\n        except KazooException as e:\n            if e.errno == KazooException.CONNECTIONLOSS:\n                continue\n            elif e.errno == KazooException.SESSIONEXPIRED:\n                self.zk.retry(self.attempt_to_acquire_leader)\n            elif e.errno == KazooException.NODEEXISTS:\n                return False\n            else:\n                raise e\n\n", "CodeBleu_score": 35.34423101180344}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, ephemeral=True, sequence=True)\n        return True\n    except NodeExistsError:\n        logger.info(\"Another instance has the lock\")\n        return False\n    except Exception as e:\n        logger.error(e)\n        raise ZooKeeperError(e)\n\n", "CodeBleu_score": 37.60591887245681}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n\n    # We use a retry mechanism here to handle transient issues.\n    for _ in range(self.max_retries):\n        try:\n            self.zk.create(self.leader_path, ephemeral=True)\n            return True\n        except NoNodeError:\n            # The parent node doesn't exist. Create it and retry.\n            self.zk.create(self.zk_root, makepath=True)\n            continue\n        except NodeExistsError:\n            # Another instance has the lock.\n            self.logger.info(\"Another instance has the lock.\")\n            return False\n        except ConnectionLoss:\n            # Connection to ZooKeeper is closed. Retry.\n            self.logger.info(\"Connection to ZooKeeper is closed.\")\n            continue\n        except Exception as e:\n            # Retry on any other exception.\n            self.logger.error(\n                \"Failed to acquire lock due to exception: {}\".format(e)\n            )\n            continue\n    # If we get here, we've retried max_retries times and failed.\n    raise ZooKeeperError(\"Failed to acquire lock.\")\n\n", "CodeBleu_score": 51.21484151549398}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session != self.session:\n        logger.warning(\n            f\"The leader's session ({leader.session}) does not match the current client's session ({self.session}).\"\n        )\n        try:\n            self.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError) as e:\n            logger.warning(f\"Error while deleting leader node: {e}\")\n            return False\n    try:\n        self.create(leader.path, self.client_id.encode(\"utf-8\"))\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.warning(f\"Error while creating leader node: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 35.946385409386274}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n\n    # Check if the current client ID matches the leader's session.\n    if leader.session != self.session_id:\n        # The current client ID does not match the leader's session.\n        # This means that the leader is no longer alive.\n        # Try to delete the existing leader ZNode.\n        try:\n            self.delete(self.leader_path)\n        except NoNodeError:\n            # The leader ZNode does not exist.\n            # This is the expected case.\n            pass\n        except (ConnectionClosedError, RetryFailedError) as e:\n            # The connection to ZooKeeper has been lost.\n            # Ignore this error.\n            logger.warning(\n                \"Failed to delete the leader ZNode due to a connection error: %s\", e\n            )\n        except ZooKeeperError as e:\n            # The connection to ZooKeeper has been lost.\n            # Raise this error.\n            raise e\n        else:\n            # The leader ZNode was successfully deleted.\n            # Try to create a new leader ZNode with the current client's name encoded in UTF-8.\n            try:\n                self.create(\n                    self.leader_path,\n                    self.client_id.encode(\"utf-8\"),\n                    ephemeral=True,\n                    sequence=True,\n                )\n            except (ConnectionClosedError, RetryFailedError) as e:\n                # The connection to ZooKeeper has been lost.\n                # Ignore this error.\n                logger.warning(\n                    \"Failed to create a new leader ZNode due to a connection error: %s\",\n                    e,\n                )\n            except ZooKeeperError as e:\n                # The connection to ZooKeeper has been lost.\n                # Raise this error.\n                raise e\n            else:\n                # The leader ZNode was successfully created.\n                return True\n\n    # The current client ID matches the leader's session.\n    # Nothing to do.\n    return False\n\n", "CodeBleu_score": 48.911021639090826}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        if leader.session_id != self.session_id:\n            self.delete(leader.path)\n            logger.warning(\n                f\"Leader session ID mismatch: {leader.session_id} != {self.session_id}. Deleting the existing leader ZNode {leader.path}.\"\n            )\n    except (NoNodeError, ConnectionClosedError, RetryFailedError) as e:\n        logger.warning(\n            f\"Failed to delete the existing leader ZNode {leader.path} due to {e.__class__.__name__}.\"\n        )\n        return False\n\n    try:\n        self.create(leader.path, value=self.client_id.encode(\"utf-8\"))\n    except (ConnectionClosedError, RetryFailedError) as e:\n        logger.warning(\n            f\"Failed to create a new leader ZNode {leader.path} due to {e.__class__.__name__}.\"\n        )\n        return False\n    return True\n\n", "CodeBleu_score": 39.77362350486851}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None or (time.time() - self._last_poll_time) > self._poll_interval:\n        self._last_poll_time = time.time()\n        try:\n            exhibitors = self._query_exhibitors(self._exhibitors)\n            if exhibitors is None:\n                logging.debug('No exhibitor was available')\n                return False\n            if self._exhibitors != exhibitors:\n                logging.debug('Exhibitors changed from %s to %s', self._exhibitors, exhibitors)\n                self._exhibitors = exhibitors\n                self._update_zookeeper_connection_string()\n                return True\n            logging.debug('Exhibitors remained the same')\n            return False\n        except Exception:\n            logging.exception('Exception while polling for new exhibitors')\n            return False\n    return False\n", "CodeBleu_score": 32.31549484244378}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll is not None and self._last_poll + self._poll_interval > time.time():\n        return False\n    self._last_poll = time.time()\n\n    try:\n        exhibitors = self._query_exhibitors()\n    except Exception:\n        logging.exception('Failed to query exhibitors')\n        return False\n\n    if exhibitors is None:\n        logging.warning('No exhibitors found')\n        return False\n\n    if not isinstance(exhibitors, dict):\n        logging.warning('Invalid exhibitors data')\n        return False\n\n    if 'servers' not in exhibitors or not isinstance(exhibitors['servers'], list):\n        logging.warning('Invalid exhibitors data')\n        return False\n\n    servers = exhibitors['servers']\n    if len(servers) == 0:\n        logging.warning('No exhibitors found')\n        return False\n\n    new_zookeeper_connection_string = ','.join(s['hostname'] + ':' + str(s['port']) for s in servers)\n    if new_zookeeper_connection_string != self._zookeeper_connection_string:\n        logging.info('ZooKeeper connection string changed from %s to %s', self._zookeeper_connection_string, new_zookeeper_connection_string)\n        self._zookeeper_connection_string = new_zookeeper_connection_string\n        return True\n    return False\n", "CodeBleu_score": 40.22906826082468}, {"code": "def poll(self) -> bool\n\t\n    if time.time() - self._last_poll > self._poll_interval:\n        self._last_poll = time.time()\n        try:\n            exhibitors = self._query_exhibitors(self._exhibitors)\n            if exhibitors:\n                logging.debug('Got exhibitor data from %s', exhibitors['server'])\n                if 'port' in exhibitors:\n                    if exhibitors['port'] != self._exhibitor_port:\n                        logging.info('Exhibitor port has changed from %s to %s', self._exhibitor_port, exhibitors['port'])\n                        self._exhibitor_port = exhibitors['port']\n                        self._zookeeper_connection_string = self._create_zookeeper_connection_string()\n                if 'servers' in exhibitors:\n                    if set(exhibitors['servers']) != set(self._exhibitors):\n                        logging.info('Exhibitor list has changed from %s to %s', self._exhibitors, exhibitors['servers'])\n                        self._exhibitors = exhibitors['servers']\n                        self._zookeeper_connection_string = self._create_zookeeper_connection_string()\n                return True\n        except Exception as e:\n            logging.warning('Error polling for exhibitor data: %s', e)\n    return False\n", "CodeBleu_score": 34.50720343412512}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (null == zookeeperListener) {\n\t\tLOGGER.info(\"zookeeperListener is null, return directly\");\n\t\treturn;\n\t}\n\tString group = null;\n\tString dataId = null;\n\ttry {\n\t\tgroup = zookeeperListener.getGroup();\n\t\tdataId = zookeeperListener.getDataId();\n\t\tLOGGER.info(\"unsubscribe from the configuration, group:\" + group + \", dataId:\" + dataId);\n\t\tzookeeperListener.unsubscribe();\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"failed to unsubscribe from the configuration, group:\" + group + \", dataId:\" + dataId, e);\n\t}\n}", "CodeBleu_score": 35.2251409868173}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = config.getProperty(\"group\");\n\tString dataId = config.getProperty(\"dataId\");\n\tlogger.info(\"unsubscribe config, group:{}, dataId:{}\", group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribeDataChanges(group, dataId);\n\t} catch (Exception e) {\n\t\tlogger.error(\"unsubscribe config failed, group:{}, dataId:{}\", group, dataId, e);\n\t}\n}", "CodeBleu_score": 47.254453957470574}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = config.getProperty(GROUP_KEY);\n\tString dataId = config.getProperty(DATAID_KEY);\n\tlogger.info(\"Unsubscribe dataId[\" + dataId + \"] from group[\" + group + \"]\");\n\ttry {\n\t\tzookeeperListener.unsubscribeDataId(group, dataId);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to unsubscribe dataId[\" + dataId + \"] from group[\" + group + \"]\", e);\n\t}\n}", "CodeBleu_score": 49.84968834724916}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tMap<String, String> metadata = new HashMap<>();\n\tif (server instanceof ZookeeperServer) {\n\t\tmetadata = ((ZookeeperServer) server).getPayload().getMetadata();\n\t}\n\treturn metadata;\n}", "CodeBleu_score": 47.83065311169575}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tMap<String, String> metadata = new HashMap<String, String>();\n\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zkServer = (ZookeeperServer) server;\n\t\tmetadata = zkServer.getPayload().getMetadata();\n\t}\n\treturn metadata;\n}", "CodeBleu_score": 55.63591105085878}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn new HashMap<>();\n\t}\n}", "CodeBleu_score": 36.79862863854429}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\treturn subscribeConfig(curatorFramework, group, serviceId, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 7.259896962984144}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getConfigPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener(zookeeperSubscribeCallback);\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tnodeCache.start();\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tzookeeperListener.start();\n\treturn zookeeperListener;\n}", "CodeBleu_score": 52.26624639871807}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = \"/\" + group + \"/\" + serviceId;\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.getListenable().addListener(new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = convertConfig(path);\n\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t}\n\t});\n\tnodeCache.start();\n\tZookeeperListener listener = new ZookeeperListener(nodeCache);\n\tcuratorFramework.getCuratorListenable().addListener(listener);\n\treturn listener;\n}", "CodeBleu_score": 56.80694415146892}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tServerList<ZookeeperInstance> serverList = new ZookeeperServerList(serviceDiscovery);\n\tserverList.initWithNiwsConfig(config);\n\tserverList.setLoadBalancer(new ZoneAwareLoadBalancer<>(serverList, config, null, null));\n\tserverList.setServerListFilter(new PassingServerListFilter());\n\tserverList.setInstanceInfo(new DefaultServerIntrospector(config));\n\treturn serverList;\n}", "CodeBleu_score": 51.90799980707094}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tif (config == null) {\n\t\tthrow new IllegalArgumentException(\"config must not be null\");\n\t}\n\tif (serviceDiscovery == null) {\n\t\tthrow new IllegalArgumentException(\"serviceDiscovery must not be null\");\n\t}\n\tif (config.getClientName() == null) {\n\t\tthrow new IllegalArgumentException(\"clientName must not be null\");\n\t}\n\tServerList<ZookeeperInstance> serverList = new ZookeeperServerList(config, serviceDiscovery);\n\tserverList.initWithNiwsConfig(config);\n\treturn new RibbonServerListDecorator(serverList, config.getClientName());\n}", "CodeBleu_score": 42.730159014478595}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(config, serviceDiscovery);\n}", "CodeBleu_score": 16.854728783987206}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n}\ncatch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.56582238768591}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}, {"code": "public void register(ZookeeperRegistration registration){\n\ttry {\n    RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n    registerListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n    // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 88.80148347285301}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onDeregister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.85471943465048}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\n    RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n    registerListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n    // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 88.84386676325141}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\n    RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n    registerListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n    // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 88.84386676325141}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = config.get(Constants.GROUP);\n\tString dataId = config.get(Constants.DATA_ID);\n\tif (group == null || dataId == null) {\n\t\tlogger.error(\"The group or dataId is null, please check the configuration\");\n\t\treturn null;\n\t}\n\tlogger.info(\"Subscribe config, group: {}, dataId: {}, global: {}\", group, dataId, globalConfig);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, globalConfig, new ConfigListener(config));\n\t} catch (Exception e) {\n\t\tlogger.error(\"Subscribe config failed, group: {}, dataId: {}, global: {}\", group, dataId, globalConfig, e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 40.50148269948925}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\ttry {\n\t\tif (globalConfig) {\n\t\t\tgroup = \"SEATA_GROUP\";\n\t\t\tdataId = \"seata.config.zk.prefix\";\n\t\t} else {\n\t\t\tgroup = \"SEATA_GROUP\";\n\t\t\tdataId = \"seata.config.zk.prefix\";\n\t\t}\n\t\tLOGGER.info(\"subscribe config, group:\" + group + \", dataId:\" + dataId);\n\t\tZookeeperListener zookeeperListener = new ZookeeperListener() {\n\t\t\t@Override\n\t\t\tpublic void handleDataChange(String dataPath, String data) {\n\t\t\t\tLOGGER.info(\"config changed, group:\" + group + \", dataId:\" + dataId + \", data:\" + data);\n\t\t\t\ttry {\n\t\t\t\t\tzkClient.unsubscribeAll();\n\t\t\t\t\tzkClient.subscribeDataChanges(dataPath, this);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOGGER.error(\"config changed, group:\" + group + \", dataId:\" + dataId + \", data:\" + data, e);\n\t\t\t\t}\n\t\t\t}\n\t\t\t@Override\n\t\t\tpublic void handleDataDeleted(String dataPath) {\n\t\t\t\tLOGGER.info(\"config deleted, group:\" + group + \", dataId:\" + dataId);\n\t\t\t\ttry {\n\t\t\t\t\tzkClient.unsubscribeAll();\n\t\t\t\t\tzkClient.subscribeDataChanges(dataPath, this);\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tLOGGER.error(\"config deleted, group:\" + group + \", dataId:\" + dataId, e);\n\t\t\t\t}\n\t\t\t}\n\t\t};\n\t\tzkClient.subscribeDataChanges(dataId, zookeeperListener);\n\t\treturn zookeeperListener;\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"subscribe config, group:\" + group + \", dataId:\" + dataId, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 36.02722302920085}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = null;\n\tString dataId = null;\n\ttry {\n\t\tgroup = config.getProperty(Constants.GROUP_KEY);\n\t\tdataId = config.getProperty(Constants.DATAID_KEY);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error while getting group and dataId from config.properties. Please check if the group and dataId keys are defined in config.properties. \" + e);\n\t\treturn null;\n\t}\n\tlogger.info(\"Subscribing to group: \" + group + \" dataId: \" + dataId);\n\tZookeeperListener listener = new ZookeeperListener(group, dataId, this);\n\ttry {\n\t\tzookeeperOperation.subscribeConfig(group, dataId, globalConfig, listener);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error while subscribing to group: \" + group + \" dataId: \" + dataId + \". \" + e);\n\t\treturn null;\n\t}\n\treturn listener;\n}", "CodeBleu_score": 29.082243409957677}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\n\tif (connectionString == null || connectionString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string cannot be empty\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n\tExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework client = CuratorFrameworkFactory.newClient(connectionString, retryPolicy);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 32.92769076360054}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\n\tif (connectionString == null || connectionString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n\tExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework client = CuratorFrameworkFactory.newClient(connectionString, retryPolicy);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 32.71675116039767}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString zookeeperConnectString = System.getenv(\"ZOOKEEPER_CONNECT_STRING\");\n\tif (zookeeperConnectString == null || zookeeperConnectString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_SLEEP_TIME\"));\n\tExponentialBackoffRetry retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zookeeperConnectString, retryPolicy);\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 37.27487416309755}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n}", "CodeBleu_score": 1.570350114839098}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t", "CodeBleu_score": 1.394537427031336}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t@Bean\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 68.41222666497784}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\treturn CuratorFrameworkFactory.builder()\n    .connectString(zkConnectString)\n    .retryPolicy(retryPolicy)\n    .namespace(zkNamespace)\n    .build();\n}", "CodeBleu_score": 13.063926632313427}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tif (this.curatorFramework != null) {\nthrow new IllegalStateException(\"CuratorFramework already created\");\n}\n\n// Create a CuratorFramework instance\nthis.curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(this.zookeeperQuorum)\n.sessionTimeoutMs(this.sessionTimeoutMs)\n.retryPolicy(new ExponentialBackoffRetry(this.baseSleepTimeMs, this.maxRetries))\n.namespace(this.namespace)\n.build();\n\n// Start the CuratorFramework instance\nthis.curatorFramework.start();\n\nreturn this.curatorFramework;\n}", "CodeBleu_score": 42.0295022974162}, {"code": "public  CuratorFramework createCuratorFramework(){\n\tif (this.curatorFramework != null) {\nreturn this.curatorFramework;\n}\nthis.curatorFramework = CuratorFrameworkFactory.builder()\n.connectString(this.zkConnectString)\n.retryPolicy(this.retryPolicy)\n.namespace(this.zkNamespace)\n.build();\nthis.curatorFramework.start();\nreturn this.curatorFramework;\n}", "CodeBleu_score": 31.744669577137714}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (locksMap.containsKey(path)) {\n\t\tInterProcessMutex lock = locksMap.get(path);\n\t\tif (!lock.isAcquiredInThisProcess()) {\n\t\t\tlock.acquire();\n\t\t}\n\t} else {\n\t\tInterProcessMutex lock = new InterProcessMutex(curator, path);\n\t\ttry {\n\t\t\tlock.acquire();\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(\"Unable to acquire lock for path: \" + path, e);\n\t\t}\n\t\tlocksMap.put(path, lock);\n\t}\n}", "CodeBleu_score": 27.982309091329576}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (locksMap.containsKey(path)) {\n\t\tInterProcessMutex lock = locksMap.get(path);\n\t\ttry {\n\t\t\tlock.acquire();\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(\"Unable to acquire lock for path: \" + path, e);\n\t\t}\n\t} else {\n\t\tInterProcessMutex lock = new InterProcessMutex(curator, path);\n\t\ttry {\n\t\t\tlock.acquire();\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(\"Unable to acquire lock for path: \" + path, e);\n\t\t}\n\t\tlocksMap.put(path, lock);\n\t}\n}", "CodeBleu_score": 33.18748263204785}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tif (locksMap.containsKey(path)) {\n\t\t// Re-acquire the existing lock\n\t\tInterProcessMutex lock = locksMap.get(path);\n\t\tif (!lock.isAcquiredInThisProcess()) {\n\t\t\tlock.acquire();\n\t\t}\n\t} else {\n\t\t// Create a new lock and acquire it\n\t\tInterProcessMutex lock = new InterProcessMutex(client, path);\n\t\tlock.acquire();\n\t\tlocksMap.put(path, lock);\n\t}\n}", "CodeBleu_score": 18.76224157898136}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tif (dtpProperties.getZookeeper().getConfigType().equals(ConfigType.PROPERTIES)) {\n\t\treturn genPropertiesTypeMap(nodePath(dtpProperties), getCuratorFramework(dtpProperties));\n\t} else {\n\t\tString path = ZKPaths.makePath(nodePath(dtpProperties), dtpProperties.getZookeeper().getConfigKey());\n\t\tString value = getVal(path, getCuratorFramework(dtpProperties));\n\t\treturn ConfigHandler.parse(value);\n\t}\n}", "CodeBleu_score": 33.68959500239549}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Zookeeper zookeeper = dtpProperties.getZookeeper();\n\tString nodePath = nodePath(dtpProperties);\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tif (dtpProperties.getZookeeper().getType() == DtpProperties.Zookeeper.Type.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else {\n\t\tString configKey = zookeeper.getConfigKey();\n\t\tString config = getVal(ZKPaths.makePath(nodePath, configKey), curatorFramework);\n\t\treturn ConfigHandler.parse(config);\n\t}\n}", "CodeBleu_score": 43.087964572633794}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tDtpProperties.Config config = dtpProperties.getConfig();\n\tif (config.getType() == DtpProperties.Config.Type.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath(dtpProperties), getCuratorFramework(dtpProperties));\n\t} else if (config.getType() == DtpProperties.Config.Type.JSON) {\n\t\tString path = ZKPaths.makePath(nodePath(dtpProperties), config.getConfigKey());\n\t\tString value = getVal(path, getCuratorFramework(dtpProperties));\n\t\treturn ConfigHandler.getConfigMap(value);\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 34.48125107520136}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t// 1. Retrieve DtpProperties instance from the environment\nDtpProperties dtpProperties = environment.getProperty(\"dtp\", DtpProperties.class);\n// 2. Bind DtpProperties with the environment\nBinder binder = Binder.get(environment);\nbinder.bind(\"dtp\", Bindable.of(DtpProperties.class)).get();\n// 3. Generate a properties map from DtpProperties\nMap<Object, Object> properties = new HashMap<>();\nproperties.put(\"dtp.zookeeper.server-address\", dtpProperties.getZookeeper().getServerAddress());\nproperties.put(\"dtp.zookeeper.namespace\", dtpProperties.getZookeeper().getNamespace());\n// 4. Check if the required property exists in the environment\nif (!checkPropertyExist(environment)) {\n// 5. If the property does not exist, create a Zookeeper property source with the generated properties\ncreateZkPropertySource(environment, properties);\n}\n}", "CodeBleu_score": 62.48272460684912}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = DtpProperties.getInstance();\nBinder binder = Binder.get(environment);\nbinder.bind(DtpProperties.class, dtpProperties);\nMap<Object, Object> properties = dtpProperties.toProperties(environment);\nif (!checkPropertyExist(environment)) {\ncreateZkPropertySource(environment, properties);\n}\n}", "CodeBleu_score": 74.61923328660129}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = application.getBeansOfType(DtpProperties.class).get(DtpProperties.class);\nBinder binder = Binder.get(environment);\nbinder.bind(DtpProperties.class).toInstance(dtpProperties);\nMap<Object, Object> properties = binder.bind(ZK_PROPERTY_SOURCE_NAME, Bindable.of(Map.class)).get();\nif (!checkPropertyExist(environment)) {\n    createZkPropertySource(environment, properties);\n}\n}", "CodeBleu_score": 64.92243535730414}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 4.435738909874791}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tvar clientProvider = new ZookeeperClientProvider(configInfo);\nvar routeFactory = new ZookeeperRouteFactory(clientProvider, configInfo);\nbuilder.RegisterInstance(routeFactory).AsImplementedInterfaces();\nbuilder.RegisterInstance(clientProvider).AsImplementedInterfaces();\nbuilder.RegisterType<ZookeeperServiceRouteManager>().AsImplementedInterfaces().SingleInstance();\nreturn this;\n}", "CodeBleu_score": 33.159138922871264}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nbuilder.Register(provider => {\nvar serializer = new ProtoBufSerializer();\nvar client = provider.Resolve<IZookeeperClientProvider>();\nreturn new ZookeeperServiceRouteManager(client, serializer, configInfo);\n}).As<IServiceRouteManager>().SingleInstance();\nreturn this;\n}", "CodeBleu_score": 38.07306895000157}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 8.618059401316474}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tbuilder.RegisterAdapter(c => new ZookeeperServiceCommandManager(c.Resolve<IServiceProvider>(), configInfo)).InstancePerLifetimeScope();\nreturn new ZookeeperModule();\n}", "CodeBleu_score": 26.129245012802127}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 8.618059401316474}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"The path must be a non-empty string.\", nameof(path));\n\t}\n\tif (provider == null && !Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\"The path must be absolute.\", nameof(path));\n\t}\n\tif (optional && !reloadOnChange) {\n\t\tthrow new ArgumentException(\"The optional parameter cannot be true if reloadOnChange is false.\", nameof(optional));\n\t}\n\tvar source = new ZookeeperConfigurationSource() {\n\t\tPath = path,\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange,\n\t\tProvider = provider\n\t};\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 46.31788355511791}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"The path must be a non-empty string.\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\tvar source = new ZookeeperConfigurationSource() {\n\t\tPath = path,\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\tsource.FileProvider = provider;\n\treturn builder.Add(source);\n}", "CodeBleu_score": 50.724553596987235}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"The path must be a non-empty string.\", nameof(path));\n\t}\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\treturn builder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n}", "CodeBleu_score": 39.135604492486856}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\nawait EnterRoutes();\nforeach (var route in _routes)\n{\nforeach (var address in Address)\n{\nif (route.Address.Equals(address))\n{\nroute.Address = null;\n}\n}\n}\nawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 43.007606879433055}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tvar routes = _routes;\n\tforeach (var route in routes) {\n\t\troute.AddressList.RemoveAll(a => Address.Any(b => a.Equals(b)));\n\t}\n\tawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 41.37413347580798}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tvar routes = _routes.ToList();\n\tforeach (var route in routes) {\n\t\troute.Address.RemoveAll(a => Address.Any(b => b.Equals(a)));\n\t}\n\tawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 41.16533714097962}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = GetRoutePath();\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tvar tasks = zkClients.Select(async zkClient => {\n\t\tvar routesData = await zkClient.GetDataAsync(routePath);\n\t\tvar routesStr = Encoding.UTF8.GetString(routesData);\n\t\tvar routesJson = JObject.Parse(routesStr);\n\t\tvar routeList = routesJson[\"routes\"].ToObject<List<ServiceRoute>>();\n\t\tvar toBeRemovedRoutes = routeList.Except(routes).Where(route => route.Address.Contains(hostAddr));\n\t\tforeach (var route in toBeRemovedRoutes) {\n\t\t\tvar routeNodePath = GetRouteNodePath(route);\n\t\t\tawait zkClient.DeleteAsync(routeNodePath);\n\t\t}\n\t});\n\tawait Task.WhenAll(tasks);\n}", "CodeBleu_score": 20.619472164586433}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\t// Get the current Zookeeper clients\n\tvar zooKeeperClients = await GetZooKeeperClientsAsync();\n\t// For each Zookeeper client\n\tforeach (var zooKeeperClient in zooKeeperClients) {\n\t\t// Get the current routes\n\t\tvar currentRoutes = await GetRoutesAsync(zooKeeperClient);\n\t\t// For each route in the current routes\n\t\tforeach (var currentRoute in currentRoutes) {\n\t\t\t// If the route is not in the new routes\n\t\t\tif (!routes.Any(route => route.RouteId == currentRoute.RouteId)) {\n\t\t\t\t// If the route contains the specified host address\n\t\t\t\tif (currentRoute.Addresses.Any(address => address.Host == hostAddr.Host)) {\n\t\t\t\t\t// Delete the node from Zookeeper\n\t\t\t\t\tawait zooKeeperClient.DeleteAsync(currentRoute.RoutePath);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 25.226731921784705}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = GetRoutePath();\n\tvar routeData = await GetRouteDataAsync(routePath);\n\n\tvar newRoutes = routes.ToList();\n\tvar newRouteData = new List<string>();\n\tforeach (var route in newRoutes) {\n\t\tvar routeStr = route.ToRouteString();\n\t\tnewRouteData.Add(routeStr);\n\t}\n\n\tvar routeDataStr = string.Join(\",\", routeData);\n\tvar newRouteDataStr = string.Join(\",\", newRouteData);\n\n\tif (routeDataStr == newRouteDataStr) {\n\t\treturn;\n\t}\n\n\tvar client = GetZookeeperClient();\n\tvar routeDataNodes = client.GetChildren(routePath);\n\tvar routeDataNodesToRemove = new List<string>();\n\tforeach (var routeDataNode in routeDataNodes) {\n\t\tvar routeDataStr = Encoding.UTF8.GetString(client.GetData(routePath + \"/\" + routeDataNode));\n\t\tvar route = ServiceRoute.FromRouteString(routeDataStr);\n\n\t\tvar routeStr = route.ToRouteString();\n\t\tif (newRouteData.Contains(routeStr)) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tvar routeAddr = route.Address;\n\t\tif (routeAddr.Contains(hostAddr)) {\n\t\t\trouteDataNodesToRemove.Add(routeDataNode);\n\t\t}\n\t}\n\n\tforeach (var routeDataNode in routeDataNodesToRemove) {\n\t\tclient.Delete(routePath + \"/\" + routeDataNode);\n\t}\n}", "CodeBleu_score": 34.26399562794755}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\tServiceRouteDescriptor routeDescriptor = ServiceRouteDescriptor.Deserialize(data);\n\tif (routeDescriptor == null) {\n\t\treturn null;\n\t}\n\tServiceRoute route = ServiceRouteFactory.CreateRoute(routeDescriptor);\n\tif (route == null) {\n\t\treturn null;\n\t}\n\tif (Log.IsDebugEnabled) {\n\t\tLog.DebugFormat(\"GetRoute: {0}\", route);\n\t}\n\treturn route;\n}", "CodeBleu_score": 28.19666776913318}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\tif (Logging.IsDebugEnabled) {\n\t\tLogging.Debug(\"Received route data from {0}.\", this.RemoteEndPoint);\n\t}\n\tServiceRouteDescriptor routeDescriptor = ServiceRouteDescriptor.Deserialize(data);\n\tServiceRouteFactory routeFactory = ServiceRouteFactory.GetFactory(routeDescriptor.ServiceType);\n\tif (routeFactory == null) {\n\t\tthrow new InvalidOperationException(\"No route factory found for service type {0}.\".FormatWith(routeDescriptor.ServiceType));\n\t}\n\tServiceRoute route = routeFactory.CreateRoute(routeDescriptor);\n\treturn route;\n}", "CodeBleu_score": 26.53698596040139}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\n\tif (this.log.IsDebugEnabled) {\n\t\tthis.log.DebugFormat(\"Received route data:\n{0}\", BitConverter.ToString(data));\n\t}\n\n\tServiceRouteDescriptor routeDescriptor = ServiceRouteDescriptor.Deserialize(data);\n\treturn this.serviceRouteFactory.CreateRoute(routeDescriptor);\n}", "CodeBleu_score": 29.683083516631704}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"NodeChange: oldData = {oldData.ToStr()}, newData = {newData.ToStr()}\u3002\");\n\nif (DataEquals(oldData, newData))\nreturn;\n\nvar route = await GetRoute(newData);\nvar oldRoute = await GetRoute(oldData);\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"NodeChange: oldRoute = {oldRoute.ToStr()}, newRoute = {route.ToStr()}\u3002\");\n\nif (oldRoute == null) {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\"NodeChange: \u65b0\u589e\u670d\u52a1\u8282\u70b9\uff0c\u670d\u52a1\u8282\u70b9\u4fe1\u606f\uff1a{route.ToStr()}\u3002\");\n\n_routes.Add(route);\n}\nelse {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation($\"NodeChange: \u66f4\u65b0\u670d\u52a1\u8282\u70b9\uff0c\u670d\u52a1\u8282\u70b9\u4fe1\u606f\uff1a{route.ToStr()}\u3002\");\n\nvar index = _routes.FindIndex(r => r.Equals(oldRoute));\nif (index < 0) {\nif (_logger.IsEnabled(LogLevel.Error))\n_logger.LogError($\"NodeChange: \u65e0\u6cd5\u627e\u5230\u670d\u52a1\u8282\u70b9\uff0c\u670d\u52a1\u8282\u70b9\u4fe1\u606f\uff1a{route.ToStr()}\u3002\");\n\nreturn;\n}\n\n_routes[index] = route;\n}\n\nOnChanged?.Invoke(route, oldRoute);\n}", "CodeBleu_score": 34.633693781575616}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t", "CodeBleu_score": 4.516682952259708}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null && newData == null) return;\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u5237\u65b0\u670d\u52a1\u8def\u7531\uff0c\u65e7\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(oldData)}\uff0c\u65b0\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nServiceRoute oldRoute = null;\nServiceRoute newRoute = null;\n\nif (DataEquals(oldData, newData))\nreturn;\n\n// 1. \u5148\u83b7\u53d6\u65b0\u8def\u7531\u3002\nif (newData != null) {\nvar descriptor = _serializer.Deserialize<byte[], ServiceRouteDescriptor>(newData);\nnewRoute = (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}\n\n// 2. \u518d\u83b7\u53d6\u65e7\u8def\u7531\u3002\nif (oldData != null) {\nvar descriptor = _serializer.Deserialize<byte[], ServiceRouteDescriptor>(oldData);\noldRoute = (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}\n\n// 3. \u5237\u65b0\u8def\u7531\u3002\nawait _lock.WaitAsync();\ntry {\n// 3.1. \u5148\u79fb\u9664\u65e7\u8def\u7531\u3002\nif (oldRoute != null) {\nvar oldRouteDescriptor = oldRoute.Descriptor;\nvar oldRouteDescriptorHash = oldRouteDescriptor.GetHash();\n_routes.RemoveAll(p => p.Descriptor.GetHash() == oldRouteDescriptorHash);\n}\n\n// 3.2. \u518d\u6dfb\u52a0\u65b0\u8def\u7531\u3002\nif (newRoute != null) {\nvar newRouteDescriptor = newRoute.Descriptor;\nvar newRouteDescriptorHash = newRouteDescriptor.GetHash();\n_routes.RemoveAll(p => p.Descriptor.GetHash() == newRouteDescriptorHash);\n_routes.Add(newRoute);\n}\n}\nfinally {\n_lock.Release();\n}\n\n// 4. \u89e6\u53d1\u4e8b\u4ef6\u3002\nOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 44.157026158743406}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar existingSubscribers = await GetSubscribers(subscribers.Select(x => x.Path));\nvar updatedSubscribers = subscribers.Select(x => existingSubscribers.FirstOrDefault(y => y.Path == x.Path) ?? x);\nawait base.SetSubscribersAsync(updatedSubscribers);\n}", "CodeBleu_score": 15.037178938729035}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (subscribers == null)\nthrow new ArgumentNullException(nameof(subscribers));\n\nvar childrens = subscribers.Select(s => s.ServicePath);\nvar existingSubscribers = await GetSubscribers(childrens);\n\nforeach (var subscriber in subscribers)\n{\nvar existingSubscriber = existingSubscribers.FirstOrDefault(s => s.ServicePath == subscriber.ServicePath);\nif (existingSubscriber == null)\n{\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u65b0\u589e\u8ba2\u9605\u8005\uff1a{subscriber.ServicePath}\u3002\");\n\nawait base.SetSubscriberAsync(subscriber);\ncontinue;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u66f4\u65b0\u8ba2\u9605\u8005\uff1a{subscriber.ServicePath}\u3002\");\n\nsubscriber.Addresses = subscriber.Addresses.Union(existingSubscriber.Addresses).ToArray();\nawait base.SetSubscriberAsync(subscriber);\n}\n}", "CodeBleu_score": 49.194109304928865}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t// \u51c6\u5907\u66f4\u65b0\u7684\u8282\u70b9\u5217\u8868\nvar updateNodes = new List<string>();\nforeach (var subscriber in subscribers) {\nvar nodePath = GetNodePath(subscriber.ServiceName);\nupdateNodes.Add(nodePath);\n}\n\n// \u83b7\u53d6\u73b0\u6709\u8282\u70b9\u7684\u5b50\u8282\u70b9\u5217\u8868\nvar oldNodes = await GetChildrens(updateNodes);\n\n// \u904d\u5386\u73b0\u6709\u8282\u70b9\uff0c\u66f4\u65b0\u73b0\u6709\u8282\u70b9\u7684\u5730\u5740\u5217\u8868\nforeach (var oldNode in oldNodes) {\nvar oldNodePath = GetNodePath(oldNode);\nvar oldSubscriber = await GetSubscriber(oldNodePath);\nvar newSubscriber = subscribers.FirstOrDefault(s => s.ServiceName == oldSubscriber.ServiceName);\nif (newSubscriber != null) {\nvar newAddresses = newSubscriber.Addresses.ToArray();\nvar oldAddresses = oldSubscriber.Addresses.ToArray();\nvar addresses = new HashSet<string>(oldAddresses.Concat(newAddresses));\noldSubscriber.Addresses = addresses;\n}\n}\n\n// \u8c03\u7528\u57fa\u7c7b\u65b9\u6cd5\u66f4\u65b0\u8282\u70b9\nawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 37.32651290279255}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tList<ServiceSubscriber> subscribers = new List<ServiceSubscriber>();\n\tforeach (string child in childrens) {\n\t\tstring path = string.Format(\"{0}/{1}\", RootPath, child);\n\t\tLogDebug(string.Format(\"Getting subscriber information for node path {0}\", path));\n\t\ttry {\n\t\t\tvar node = await Client.GetNodeAsync(path);\n\t\t\tvar subscriber = await node.ReadValueAsync(new Value[] { Value.Create(typeof(ServiceSubscriber)) });\n\t\t\tsubscribers.Add(subscriber.GetValue<ServiceSubscriber>(0));\n\t\t}\n\t\tcatch (Exception ex) {\n\t\t\tLogDebug(string.Format(\"Exception while getting subscriber information for node path {0}: {1}\", path, ex.Message));\n\t\t}\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 41.41319032971372}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar rootPath = $\"/{_rootNode}\";\n\tforeach (var child in childrens) {\n\t\tvar path = $\"{rootPath}/{child}\";\n\t\tvar subscriber = await GetSubscriber(path);\n\t\tif (subscriber != null) {\n\t\t\tsubscribers.Add(subscriber);\n\t\t}\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 35.4828952663335}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tList<ServiceSubscriber> subscribers = new List<ServiceSubscriber>();\n\tstring rootPath = ServiceSubscriber.RootPath;\n\tforeach (string child in childrens) {\n\t\tstring fullPath = rootPath + child;\n\t\tServiceSubscriber subscriber = await ServiceSubscriber.GetSubscriber(fullPath);\n\t\tif (subscriber != null) {\n\t\t\tsubscribers.Add(subscriber);\n\t\t}\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 31.183391254187697}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null)\n    return;\n\nvar (zooKeeper, eventReset) = await GetZooKeeper();\nif (zooKeeper == null)\n    return;\n\nvar rootPath = _configInfo.SubscriberPath;\nif (!rootPath.EndsWith(\"/\"))\n    rootPath += \"/\";\n\nvar exists = await zooKeeper.ExistsAsync(rootPath);\nif (exists == null) {\n    _logger.LogWarning($\"\u8282\u70b9{rootPath}\u4e0d\u5b58\u5728\uff0c\u65e0\u6cd5\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n    _subscribers = Array.Empty<ServiceSubscriber>();\n    return;\n}\n\nvar childrens = await zooKeeper.GetChildrenAsync(rootPath);\nif (childrens == null) {\n    _logger.LogWarning($\"\u8282\u70b9{rootPath}\u4e0d\u5b58\u5728\uff0c\u65e0\u6cd5\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n    _subscribers = Array.Empty<ServiceSubscriber>();\n    return;\n}\n\nvar subscribers = await GetSubscribers(childrens);\n_subscribers = subscribers;\n}", "CodeBleu_score": 45.447874883181406}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null)\nreturn;\n\nvar zooKeeper = await GetZooKeeper();\nzooKeeper.Item2.ChildrenWatched += ZooKeeper_ChildrenWatched;\n\nvar (eventWaitHandle, zooKeeper) = zooKeeper;\nawait eventWaitHandle.WaitOne();\n\nif (_subscribers == null)\n_subscribers = await GetSubscribers(zooKeeper.GetChildren(_configInfo.SubscriberPath));\n}", "CodeBleu_score": 39.326232034437034}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers != null)\nreturn;\n\nvar (zooKeeper, eventWaitHandle) = await GetZooKeeper();\nawait eventWaitHandle.WaitOneAsync(_configInfo.SessionTimeout);\n\nif (zooKeeper.State == ZooKeeper.States.Expired)\n{\nawait _zookeeperClientProvider.OnExpired(zooKeeper);\nreturn;\n}\n\nvar rootPath = _configInfo.SubscriberPath;\nif (!rootPath.EndsWith(\"/\"))\nrootPath += \"/\";\n\nvar childrens = await zooKeeper.GetChildrenAsync(rootPath, false);\nif (childrens.Length == 0)\n{\n_logger.LogWarning(\"\u8ba2\u9605\u8005\u8282\u70b9\u4e0d\u5b58\u5728\uff0c\u8bf7\u786e\u8ba4\u662f\u5426\u6b63\u786e\u914d\u7f6e\u3002\");\n_subscribers = Array.Empty<ServiceSubscriber>();\nreturn;\n}\n\n_subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 48.44673237167167}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nvar newCommand = GetServiceCommand(newData);\nvar oldCommand = GetServiceCommand(oldData);\nif (newCommand == null) {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65b0\u6570\u636e\u4e3a\u7a7a\u3002\");\n\nreturn;\n}\nif (oldCommand == null) {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65e7\u6570\u636e\u4e3a\u7a7a\u3002\");\n\n_commands.Add(newCommand);\nreturn;\n}\n\nif (DataEquals(newCommand.Data, oldCommand.Data)) {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65b0\u65e7\u6570\u636e\u76f8\u540c\u3002\");\n\nreturn;\n}\n\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65b0\u65e7\u6570\u636e\u4e0d\u540c\u3002\");\n\nvar index = _commands.FindIndex(x => x.ServiceId == newCommand.ServiceId);\nif (index < 0) {\nif (_logger.IsEnabled(LogLevel.Information))\n_logger.LogInformation(\"\u8282\u70b9\u6570\u636e\u53d8\u66f4\uff0c\u65b0\u6570\u636e\u4e0d\u5b58\u5728\u4e8e\u670d\u52a1\u547d\u4ee4\u5217\u8868\u4e2d\u3002\");\n\n_commands.Add(newCommand);\nreturn;\n}\n\n_commands[index] = newCommand;\n}", "CodeBleu_score": 38.723466802758786}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (oldData == null && newData == null)\nreturn;\n\nvar oldDescriptor = GetServiceCommand(oldData);\nvar newDescriptor = GetServiceCommand(newData);\n\nif (DataEquals(oldData, newData))\nreturn;\n\nif (oldDescriptor == null)\n_serviceCommands.Add(newDescriptor);\nelse\n_serviceCommands[_serviceCommands.IndexOf(oldDescriptor)] = newDescriptor;\n\nOnChanged?.Invoke(newDescriptor, oldDescriptor);\n}", "CodeBleu_score": 26.277803876698165}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u6bd4\u8f83\u670d\u52a1\u547d\u4ee4\uff0c\u914d\u7f6e\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(newData)}\u3002\");\n\nvar oldDescriptor = GetServiceCommand(oldData);\nvar newDescriptor = GetServiceCommand(newData);\nif (oldDescriptor == null && newDescriptor == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u914d\u7f6e\u5185\u5bb9\u672a\u53d1\u751f\u53d8\u5316\u3002\");\nreturn;\n}\n\nif (oldDescriptor == null || newDescriptor == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u914d\u7f6e\u5185\u5bb9\u53d1\u751f\u53d8\u5316\u3002\");\nOnChanged?.Invoke(newDescriptor, oldDescriptor);\nreturn;\n}\n\nif (oldDescriptor.ServiceId != newDescriptor.ServiceId) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u914d\u7f6e\u5185\u5bb9\u53d1\u751f\u53d8\u5316\u3002\");\nOnChanged?.Invoke(newDescriptor, oldDescriptor);\nreturn;\n}\n\nif (!DataEquals(oldDescriptor.Data, newDescriptor.Data)) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u914d\u7f6e\u5185\u5bb9\u53d1\u751f\u53d8\u5316\u3002\");\nOnChanged?.Invoke(newDescriptor, oldDescriptor);\nreturn;\n}\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug(\"\u914d\u7f6e\u5185\u5bb9\u672a\u53d1\u751f\u53d8\u5316\u3002\");\n}", "CodeBleu_score": 30.81234419887884}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t", "CodeBleu_score": 1.9605292502668268}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t/// <summary>\n/// The current and new data are retrieved from the ZooKeeper client.\n/// </summary>\nvar currentData = await _client.GetDataAsync(_path);\nvar newData = await _client.GetDataAsync(_path, newData => {\n/// <summary>\n/// The action is executed with the current and new data.\n/// </summary>\n_action(currentData, newData);\n/// <summary>\n/// The watcher is updated with the new data.\n/// </summary>\n_client.GetDataAsync(_path, _watcher);\n}, _watcher);\n}", "CodeBleu_score": 16.612292259941892}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tvar data = await _client.GetDataAsync(_path, _watcher, _cancelToken);\n\tvar newData = Encoding.UTF8.GetString(data);\n\tvar oldData = Encoding.UTF8.GetString(_data);\n\tif (newData != oldData) {\n\t\t_data = data;\n\t\tawait _action(oldData, newData);\n\t}\n}", "CodeBleu_score": 44.81801329123529}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\treturn builder.UseZookeeperClientProvider(typeof(DefaultZookeeperClientProvider), configInfo);\n}", "CodeBleu_score": 15.33639683830483}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\treturn builder.UseZookeeperClientProvider(_ => configInfo);\n}", "CodeBleu_score": 13.255406954719524}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tvar config = GetConfigInfo(configInfo);\nbuilder.ConfigureServices((context, services) => {\nservices.AddSingleton(config);\nservices.AddSingleton<IAddressSelector, ZookeeperAddressSelector>();\nservices.AddSingleton<IHealthCheckService, ZookeeperHealthCheckService>();\nservices.AddSingleton<ZookeeperClientProvider>();\n});\nreturn builder;\n}", "CodeBleu_score": 48.460300947310685}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tvar client = await _zooKeeperClientFactory.CreateClientAsync();\n\tawait client.ConnectAsync();\n\tawait _logger.LogInformationAsync(\"Connected to ZooKeeper.\");\n\n\tvar tasks = new List<Task>();\n\tforeach (var route in routes) {\n\t\tvar routePath = _routePathBuilder.Build(route);\n\t\tvar task = await EnsureRoutePathExistsAsync(client, routePath);\n\t\ttasks.Add(task);\n\t\tforeach (var routeData in route.RouteData) {\n\t\t\tvar dataPath = _routePathBuilder.BuildDataPath(route, routeData);\n\t\t\ttask = await EnsureDataPathExistsAsync(client, dataPath, routeData);\n\t\t\ttasks.Add(task);\n\t\t}\n\t}\n\tawait Task.WhenAll(tasks);\n\tawait client.CloseAsync();\n\tawait _logger.LogInformationAsync(\"Closed connection to ZooKeeper.\");\n}", "CodeBleu_score": 31.823698765411525}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tvar routePaths = routes.Select(route => route.Route).ToList();\n\tvar client = await this.GetZooKeeperClientAsync();\n\tawait client.EnsureRoutePathsAsync(routePaths);\n\tforeach (var route in routes) {\n\t\tvar routePath = route.Route;\n\t\tvar routeData = this.SerializeRouteData(route);\n\t\tvar routeNode = await client.CreateOrUpdateRouteDataAsync(routePath, routeData);\n\t\tthis.Logger.LogInformation(\"Added route '{0}' with data '{1}' to ZooKeeper.\", routePath, routeData);\n\t\tawait this.InvokeOnRouteAddedAsync(route, routeNode);\n\t}\n}", "CodeBleu_score": 17.324417480807845}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tif (routes == null) {\n\t\treturn;\n\t}\n\tvar routeList = routes.ToList();\n\tif (routeList.Count == 0) {\n\t\treturn;\n\t}\n\tvar routePath = GetRoutePath();\n\tvar zkClientList = await GetZkClientListAsync();\n\tforeach (var zkClient in zkClientList) {\n\t\tvar routeListInZk = await zkClient.GetChildrenAsync(routePath);\n\t\tvar routeListInZkExcept = routeListInZk.Except(routeList.Select(r => r.Name)).ToList();\n\t\tif (routeListInZkExcept.Count == 0) {\n\t\t\tcontinue;\n\t\t}\n\t\tvar routePathExcept = routePath + \"/\" + string.Join(\"/\", routeListInZkExcept);\n\t\tvar children = await zkClient.GetChildrenAsync(routePathExcept);\n\t\tforeach (var child in children) {\n\t\t\tvar nodePath = routePathExcept + \"/\" + child;\n\t\t\tvar nodeData = await zkClient.GetDataAsync(nodePath);\n\t\t\tvar nodeDataStr = Encoding.UTF8.GetString(nodeData);\n\t\t\tvar nodeDataJson = JObject.Parse(nodeDataStr);\n\t\t\tvar nodeAddr = AddressModel.Parse(nodeDataJson[\"Address\"]);\n\t\t\tif (nodeAddr.Host == hostAddr.Host) {\n\t\t\t\tawait zkClient.DeleteAsync(nodePath);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 32.734718477547744}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePaths = routes.Select(x => x.ToRoutePath());\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tforeach (var zkClient in zkClients) {\n\t\tvar currentRoutes = await zkClient.GetChildrenAsync(MqttServiceRoute.Root);\n\t\tvar routesToDelete = currentRoutes.Except(routePaths).Where(x => x.Contains(hostAddr.ToString()));\n\t\tforeach (var routeToDelete in routesToDelete) {\n\t\t\tawait zkClient.DeleteAsync(MqttServiceRoute.Root + \"/\" + routeToDelete);\n\t\t}\n\t}\n}", "CodeBleu_score": 24.181518544436358}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePaths = routes.Select(r => r.ToRoutePath());\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tvar tasks = zkClients.Select(zkClient => zkClient.RemoveExceptAsync(routePaths, hostAddr));\n\tawait Task.WhenAll(tasks);\n}", "CodeBleu_score": 13.984284818894283}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tif (cacheDescriptors == null) {\n\t\tthrow new ArgumentNullException(nameof(cacheDescriptors));\n\t}\n\tLog.LogInformation(\"Updating service caches in Zookeeper\");\n\tvar cachePath = $\"/{_options.ServiceDescriptor.ServiceName}/caches\";\n\tvar clients = await _clientFactory.GetClientsAsync();\n\tforeach (var client in clients) {\n\t\tawait client.CreateRecursiveAsync(cachePath);\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar serializedCacheDescriptor = JsonSerializer.Serialize(cacheDescriptor);\n\t\t\tvar cacheNodePath = $\"/{cachePath}/{cacheDescriptor.CacheName}\";\n\t\t\tvar cacheNodeExists = await client.ExistsAsync(cacheNodePath);\n\t\t\tif (cacheNodeExists) {\n\t\t\t\tvar cacheNodeData = await client.GetDataAsync(cacheNodePath);\n\t\t\t\tif (cacheNodeData.Data == serializedCacheDescriptor) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tawait client.SetDataAsync(cacheNodePath, Encoding.UTF8.GetBytes(serializedCacheDescriptor));\n\t\t\t}\n\t\t\telse {\n\t\t\t\tawait client.CreateAsync(cacheNodePath, Encoding.UTF8.GetBytes(serializedCacheDescriptor));\n\t\t\t}\n\t\t}\n\t}\n\tLog.LogInformation(\"Successfully updated service caches in Zookeeper\");\n}", "CodeBleu_score": 33.87816403287921}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tvar cacheDescriptorsList = cacheDescriptors.ToList();\n\tvar cachePath = GetCachePath();\n\tvar zooKeeperClients = await GetZooKeeperClientsAsync();\n\n\tforeach (var zooKeeperClient in zooKeeperClients) {\n\t\tawait EnsureCachePathExistsAsync(zooKeeperClient, cachePath);\n\t\tforeach (var cacheDescriptor in cacheDescriptorsList) {\n\t\t\tvar serializedCacheDescriptor = SerializeCacheDescriptor(cacheDescriptor);\n\t\t\tvar cacheDescriptorPath = GetCacheDescriptorPath(cachePath, cacheDescriptor.ServiceId);\n\t\t\tvar cacheDescriptorExists = await zooKeeperClient.ExistsAsync(cacheDescriptorPath);\n\t\t\tif (cacheDescriptorExists) {\n\t\t\t\tvar cacheDescriptorData = await zooKeeperClient.GetDataAsync(cacheDescriptorPath);\n\t\t\t\tif (cacheDescriptorData != serializedCacheDescriptor) {\n\t\t\t\t\tawait zooKeeperClient.SetDataAsync(cacheDescriptorPath, serializedCacheDescriptor);\n\t\t\t\t}\n\t\t\t}\n\t\t\telse {\n\t\t\t\tawait zooKeeperClient.CreateAsync(cacheDescriptorPath, serializedCacheDescriptor, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t\t}\n\t\t}\n\t}\n\n\tLogger.LogInformation(\"Successfully added service caches for {ServiceCount} services\", cacheDescriptorsList.Count);\n}", "CodeBleu_score": 28.968326958701073}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\t// Log the operation\n\tvar log = $\"Setting service caches in Zookeeper:\n{string.Join(\"\n\", cacheDescriptors.Select(x => x.ToString()))}\";\n\tthis.Logger?.LogInformation(log);\n\n\t// Construct the cache path\n\tvar path = this.GetCachePath();\n\n\t// Get Zookeeper clients\n\tvar clients = this.GetZooKeeperClients();\n\n\t// Iterate through the cache descriptors\n\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t// Serialize the cache descriptor\n\t\tvar serializedCacheDescriptor = this.SerializeCacheDescriptor(cacheDescriptor);\n\n\t\t// Check if the node exists in Zookeeper\n\t\tvar exists = await clients.ExistsAsync(path + \"/\" + cacheDescriptor.Name);\n\n\t\t// If the node does not exist, create it\n\t\tif (exists is null) {\n\t\t\tawait clients.CreateAsync(path + \"/\" + cacheDescriptor.Name, serializedCacheDescriptor, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PersistentSequential);\n\t\t\tthis.Logger?.LogInformation($\"Created cache {cacheDescriptor.Name} in Zookeeper\");\n\t\t}\n\t\t// Otherwise, update the node's data if necessary\n\t\telse {\n\t\t\tvar data = await clients.GetDataAsync(path + \"/\" + cacheDescriptor.Name);\n\t\t\tif (data.DataString != serializedCacheDescriptor) {\n\t\t\t\tawait clients.SetDataAsync(path + \"/\" + cacheDescriptor.Name, serializedCacheDescriptor);\n\t\t\t\tthis.Logger?.LogInformation($\"Updated cache {cacheDescriptor.Name} in Zookeeper\");\n\t\t\t}\n\t\t}\n\t}\n\n\t// Log the successful addition of the service caches\n\tthis.Logger?.LogInformation(\"Successfully set service caches in Zookeeper\");\n}", "CodeBleu_score": 33.629127356811075}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tif (zooKeeper == null) throw new ArgumentNullException(nameof(zooKeeper));\n\tif (path == null) throw new ArgumentNullException(nameof(path));\n\tif (path.Length == 0) throw new ArgumentException(\"The path cannot be empty.\", nameof(path));\n\n\tvar (manualResetEvent, client) = zooKeeper;\n\tvar pathSegments = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\n\tvar pathBuilder = new StringBuilder();\n\tforeach (var segment in pathSegments) {\n\t\tpathBuilder.Append('/');\n\t\tpathBuilder.Append(segment);\n\t\tvar currentPath = pathBuilder.ToString();\n\n\t\tvar exists = await client.ExistsAsync(currentPath);\n\t\tif (exists) continue;\n\n\t\tawait client.CreateAsync(currentPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\tawait Log.Information(\"Created the Zookeeper node at {Path}.\", currentPath);\n\t}\n\n\tmanualResetEvent.Set();\n}", "CodeBleu_score": 45.26593431109537}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t", "CodeBleu_score": 6.677050525407208}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tawait zooKeeper.Item2.CreateRecursive(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\tConsole.WriteLine(\"Created path: {0}\", path);\n}", "CodeBleu_score": 18.535519362765214}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _config.ZooKeeperAddresses) {\nvar (manualResetEvent, zooKeeper) = CreateZooKeeper(address);\nif (await _healthCheckService.CheckHealthAsync(zooKeeper)) {\nresult.Add((manualResetEvent, zooKeeper));\n}\n}\nreturn result;\n}", "CodeBleu_score": 70.05155028561121}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nvar tasks = new List<Task>();\nforeach (var address in _config.ZooKeeperAddresses) {\nvar (wait, zk) = CreateZooKeeper(address);\ntasks.Add(CheckHealth(address, wait));\nresult.Add((wait, zk));\n}\nawait Task.WhenAll(tasks);\nreturn result;\n}", "CodeBleu_score": 65.16611479676872}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.ZooKeeperAddresses) {\nvar connectionWait = new ManualResetEvent(false);\nvar zk = new ZooKeeper($\"{ipAddress.Ip}:{ipAddress.Port}\", (int)_config.SessionTimeout.TotalMilliseconds, new ReconnectionWatcher(\n() => {\nconnectionWait.Set();\n},\n() => {\nconnectionWait.Close();\n},\nasync () => {\nconnectionWait.Reset();\nif (_zookeeperClients.TryRemove(ipAddress, out (ManualResetEvent, ZooKeeper) value)) {\nawait value.Item2.closeAsync();\nvalue.Item1.Close();\n}\nCreateZooKeeper(ipAddress);\n}\n));\nresult.Add((connectionWait, zk));\n_zookeeperClients.TryAdd(ipAddress, (connectionWait, zk));\n}\nreturn result;\n}", "CodeBleu_score": 58.687421858006836}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\tsynchronized(this) {\n        if (helper == null) {\n            helper = new ZooKeeperHelper(this);\n        }\n        return helper.getZooKeeper();\n    }\n}", "CodeBleu_score": 16.527753373595377}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\treturn getZooKeeper(this.ensembleProvider);\n}", "CodeBleu_score": 3.0284499774521065}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\tsynchronized(this) {\n    if (helper == null) {\n        helper = new ZooKeeperHelper(this);\n    }\n    return helper.getZooKeeper();\n}\n}", "CodeBleu_score": 14.88069543897868}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zooKeeper != null) {\n\t\tthis.zooKeeper.register(new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t}\n\t\t});\n\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\tthis.zooKeeper.close(waitForShutdownTimeoutMs);\n\t\t} else {\n\t\t\tthis.zooKeeper.close();\n\t\t}\n\n\t\tthis.zooKeeper = null;\n\t}\n}", "CodeBleu_score": 22.575781457727555}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk != null) {\n\t\ttry {\n\t\t\tzk.close();\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n\tif (waitForShutdownTimeoutMs > 0) {\n\t\ttry {\n\t\t\tThread.sleep(waitForShutdownTimeoutMs);\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t}\n\t}\n}", "CodeBleu_score": 25.48502329218556}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk != null) {\n\t\ttry {\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tzk.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t} finally {\n\t\t\tzk = null;\n\t\t}\n\t}\n}", "CodeBleu_score": 24.28780302932321}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t//        synchronized (state) {\n            internalBlockUntilConnectedOrTimedOut();\n//        }\n        return isConnected();\n    }", "CodeBleu_score": 6.818891645786464}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tOperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n\ttry {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\ttrace.success();\n\t\treturn true;\n\t} catch (InterruptedException e) {\n\t\ttrace.failure(e);\n\t\tthrow e;\n\t} catch (Exception e) {\n\t\ttrace.failure(e);\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 37.957726892696705}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\ttry {\n    internalBlockUntilConnectedOrTimedOut();\n    return true;\n} catch (InterruptedException e) {\n    return false;\n}\n}", "CodeBleu_score": 10.581057650070342}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t//        synchronized (this) {\n            if (isStarted()) {\n                log.info(\"Closing {}\", this.getClass().getSimpleName());\n                try {\n                    doClose(waitForShutdownTimeoutMs);\n                    log.info(\"Successfully closed {}\", this.getClass().getSimpleName());\n                } catch (IOException e) {\n                    log.error(\"Failed to close {} due to {}\", this.getClass().getSimpleName(), e.getMessage());\n                    if (Thread.currentThread().isInterrupted()) {\n                        log.warn(\"Interrupted while closing {}\", this.getClass().getSimpleName());\n                    }\n                }\n            }\n//        }\n    }", "CodeBleu_score": 46.338656484901}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\t// log the shutdown attempt\n\tlog.info(\"Closing the \" + this.getClass().getSimpleName() + \" service\");\n\t// set the started state to false\n\tthis.started = false;\n\t// attempt to close the state within the given timeout\n\ttry {\n\t\t// attempt to close the state\n\t\tthis.state.close(waitForShutdownTimeoutMs);\n\t} catch (IOException e) {\n\t\t// check for thread interruption\n\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\t// log the error\n\t\t\tlog.error(\"The \" + this.getClass().getSimpleName() + \" service was interrupted while attempting to close the state\", e);\n\t\t} else {\n\t\t\t// log the error\n\t\t\tlog.error(\"An error occurred while attempting to close the \" + this.getClass().getSimpleName() + \" service\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 47.58425859966249}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tif (log.isDebugEnabled()) {\n\t\tlog.debug(\"Closing the \" + getClass().getSimpleName() + \" service\");\n\t}\n\ttry {\n\t\tif (started.compareAndSet(true, false)) {\n\t\t\ttry {\n\t\t\t\tcloseInternal(waitForShutdownTimeoutMs);\n\t\t\t} finally {\n\t\t\t\t// make sure we set the started state to false regardless of any exceptions\n\t\t\t\tstarted.set(false);\n\t\t\t}\n\t\t} else {\n\t\t\tif (log.isDebugEnabled()) {\n\t\t\t\tlog.debug(\"The \" + getClass().getSimpleName() + \" service has already been closed\");\n\t\t\t}\n\t\t}\n\t} catch (IOException e) {\n\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\tlog.warn(\"Interrupted while closing the \" + getClass().getSimpleName() + \" service\", e);\n\t\t} else {\n\t\t\tlog.error(\"Could not close the \" + getClass().getSimpleName() + \" service\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.33108623753099}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t", "CodeBleu_score": 1.4312056341607657}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tif (mConnectionState == ConnectionState.CONNECTED) {\n\t\treturn;\n\t}\n\n\tsynchronized (mConnectionStateLock) {\n\t\tif (mConnectionState == ConnectionState.CONNECTED) {\n\t\t\treturn;\n\t\t}\n\n\t\tif (mConnectionState == ConnectionState.CONNECTING) {\n\t\t\t// Wait for the connection to complete\n\t\t\tmConnectionStateLock.wait();\n\t\t\treturn;\n\t\t}\n\n\t\tif (mConnectionState == ConnectionState.DISCONNECTING) {\n\t\t\t// Wait for the disconnection to complete\n\t\t\tmConnectionStateLock.wait();\n\t\t\treturn;\n\t\t}\n\n\t\tif (mConnectionState == ConnectionState.DISCONNECTED) {\n\t\t\t// Wait for the reconnection to complete\n\t\t\tmConnectionStateLock.wait();\n\t\t\treturn;\n\t\t}\n\t}\n\n\t// The connection state is not valid\n\tthrow new IllegalStateException(\"Invalid connection state: \" + mConnectionState);\n}", "CodeBleu_score": 10.681964002641294}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong startTime = System.currentTimeMillis();\n\tlong waitTime = connectionTimeout;\n\tCountDownLatch latch = new CountDownLatch(1);\n\tConnectionStateWatcher watcher = new ConnectionStateWatcher(latch, connectionState, ConnectionState.CONNECTED);\n\tsynchronized (connectionState) {\n\t\tconnectionState.notifyAll();\n\t}\n\twhile (connectionState.isConnected() == false && waitTime > 0) {\n\t\tsynchronized (connectionState) {\n\t\t\tconnectionState.wait(waitTime);\n\t\t}\n\t\tlong elapsedTime = System.currentTimeMillis() - startTime;\n\t\twaitTime = connectionTimeout - elapsedTime;\n\t\tif (connectionState.isConnected() == false) {\n\t\t\tif (connectionState.isClosed() == true) {\n\t\t\t\tthrow new IllegalStateException(\"Connection is closed.\");\n\t\t\t}\n\t\t\tif (connectionState.isClosing() == true) {\n\t\t\t\tthrow new IllegalStateException(\"Connection is closing.\");\n\t\t\t}\n\t\t\tif (connectionState.isFailed() == true) {\n\t\t\t\tthrow new IllegalStateException(\"Connection is failed.\");\n\t\t\t}\n\t\t}\n\t\tif (connectionState.isConnected() == false) {\n\t\t\twatcher.cancel();\n\t\t\tlatch = new CountDownLatch(1);\n\t\t\twatcher = new ConnectionStateWatcher(latch, connectionState, ConnectionState.CONNECTED);\n\t\t\tsynchronized (connectionState) {\n\t\t\t\tconnectionState.notifyAll();\n\t\t\t}\n\t\t}\n\t}\n\tif (connectionState.isConnected() == false) {\n\t\tthrow new IllegalStateException(\"Connection timed out.\");\n\t}\n}", "CodeBleu_score": 30.661829266787176}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tString newSession = client.getZookeeperClient().getZooKeeper().getSessionId();\n\tif (newSession != sessionId) {\n\t\tlog.warn(\"Session changed from {} to {} during protected mode operation\", sessionId, newSession);\n\t\tif (doProtected()) {\n\t\t\ttry {\n\t\t\t\tclient.getZookeeperClient().getZooKeeper().delete(foundNode, -1);\n\t\t\t} catch (NoNodeException e) {\n\t\t\t\t// ignore\n\t\t\t}\n\t\t}\n\t\tsessionId = newSession;\n\t}\n\treturn foundNode;\n}", "CodeBleu_score": 34.28653442267905}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tif (client.getZookeeperClient().getZooKeeper().getSessionId() != sessionId) {\n        logger.info(\"Session ID has changed from {} to {}.\", sessionId, client.getZookeeperClient().getZooKeeper().getSessionId());\n        sessionId = client.getZookeeperClient().getZooKeeper().getSessionId();\n        if (createMode == CreateMode.EPHEMERAL) {\n            logger.info(\"Deleting old node: \" + foundNode);\n            client.delete().forPath(foundNode);\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 39.23314813781092}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t\tString newSession = client.getZookeeperClient().getZooKeeper().getSessionId();\n\tString oldSession = foundNode.substring(0, foundNode.indexOf(':'));\n\tif (!newSession.equals(oldSession)) {\n\t\tLOGGER.info(\"Session ID changed from \" + oldSession + \" to \" + newSession);\n\t\tclient.getZookeeperClient().getZooKeeper().delete(foundNode, -1);\n\t\treturn null;\n\t}\n\treturn foundNode;\n}", "CodeBleu_score": 32.057632518095865}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tStat stat = null;\n\ttry {\n\t\t// Create a ZooKeeper client\n\t\tZooKeeper zk = ZooKeeperHelper.connect(zooKeeperConnectString, sessionTimeout, connectionTimeout, watcher);\n\n\t\t// Create a ZooKeeper ACL list\n\t\tList<ACL> acl = aclList;\n\n\t\t// Start a ZooKeeper advanced trace\n\t\tTrace zkTrace = ZooKeeperHelper.startAdvancedTrace(zk, path, acl);\n\n\t\t// Perform a synchronous request\n\t\tstat = zk.setACL(path, acl, -1);\n\n\t\t// Commit the trace\n\t\tZooKeeperHelper.commitTrace(zkTrace);\n\t} catch (Exception e) {\n\t\t// Commit the trace\n\t\tZooKeeperHelper.abortTrace(zkTrace);\n\t\tthrow e;\n\t}\n\n\treturn stat;\n}", "CodeBleu_score": 31.851470291829287}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tStat stat = null;\n\ttry {\n\t\tfinal Trace trace = new Trace(Trace.Operation.SET_ACLS, path);\n\t\ttrace.start();\n\t\tstat = zooKeeper.setACL(path, aclList, -1);\n\t\ttrace.stop();\n\t\ttrace.commit();\n\t} catch (final KeeperException e) {\n\t\tthrow new Exception(e.getMessage(), e);\n\t}\n\treturn stat;\n}", "CodeBleu_score": 29.49794748631809}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\t// Start the advanced trace\n\tTrace.start(\"pathInForeground\", TraceLevel.ADVANCED);\n\t// Set the ACL for the path\n\tStat stat = zk.setACL(path, aclList, -1);\n\t// Get the status of the operation\n\tint rc = zk.getReturnCode();\n\t// Commit the trace\n\tTrace.commit();\n\t// Return the status of the operation\n\treturn stat;\n}", "CodeBleu_score": 22.740243454367498}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tif (thisId == null) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null\");\n\t}\n\tif (membershipPath == null) {\n\t\tthrow new IllegalArgumentException(\"membershipPath cannot be null\");\n\t}\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.memberPath = membershipPath + \"/\" + thisId;\n\tthis.memberCache = new CuratorCache(client, memberPath, new GroupMemberCacheListener(), false);\n\tthis.memberNode = new PersistentNode(client, memberPath, payload);\n\tthis.memberNode.start();\n}", "CodeBleu_score": 38.417864488244234}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tif (thisId == null || thisId.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null or empty\");\n\t}\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.memberPath = membershipPath + \"/\" + thisId;\n\tthis.memberCache = new CuratorCache(client, memberPath, new GroupMemberCacheListener(this));\n\tthis.memberNode = new PersistentNode(client, memberPath, payload, CreateMode.EPHEMERAL);\n}", "CodeBleu_score": 39.22147172451581}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tif (thisId == null) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be null\");\n\t}\n\tif (payload == null) {\n\t\tthrow new IllegalArgumentException(\"payload cannot be null\");\n\t}\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = new CuratorCache(client, membershipPath, new GroupMembershipCacheListener(this));\n\tthis.cache.listenable().addListener(new GroupMembershipListener(this));\n\tthis.node = PersistentNode.make(client, membershipPath, thisId, payload, CreateMode.EPHEMERAL);\n\tthis.node.start();\n}", "CodeBleu_score": 39.90343263017295}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t// create a node at the given path asynchronously\nclient.create().forPath(path).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // now set up a watch on the node\n        client.getChildren().watched().forPath(path).whenComplete((children, watcherException) -> {\n            if (watcherException != null) {\n                watcherException.printStackTrace();\n            } else {\n                System.out.println(\"Children are: \" + children);\n            }\n        });\n    }\n});\n}", "CodeBleu_score": 64.15818516393898}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t// create a node at the given path asynchronously\nclient.create().inBackground().forPath(path, \"some data\".getBytes()).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // set up a watch on the node\n        client.getChildren().inBackground(new BackgroundCallback() {\n            @Override\n            public void processResult(CuratorFramework client, CuratorEvent event) throws Exception {\n                System.out.println(event);\n            }\n        }).forPath(path);\n    }\n});\n}", "CodeBleu_score": 59.463983903606334}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n// create the node asynchronously\nasync.create().forPath(path).whenComplete((name, exception) -> {\n    if (exception != null) {\n        // there was a problem\n        exception.printStackTrace();\n    } else {\n        System.out.println(\"Created node name is: \" + name);\n\n        // now set up a watch on the node\n        handleWatchedStage(async.watched().forPath(path));\n    }\n});\n}", "CodeBleu_score": 79.00577399707282}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\n// 1. Execute the transaction\n\nList<OpResult> opResults = client.transaction().forOperations(transaction).commit();\n\n// 2. Check for errors\n\nif (opResults.get(0).getErr() != KeeperException.Code.OK.intValue()) {\n\n// 3. Retrieve the error code\n\nKeeperException.Code code = KeeperException.Code.get(opResults.get(0).getErr());\n\n// 4. Throw an exception with the error code\n\nthrow new KeeperException(code);\n}\n\n// 5. Return the operation results\n\nreturn opResults;\n}", "CodeBleu_score": 39.035093734661565}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> opResults = new ArrayList<OpResult>();\n\n\ttry {\n\t\topResults = transaction.commit();\n\t} catch (KeeperException.BadArgumentsException e) {\n\t\tthrow e;\n\t} catch (KeeperException e) {\n\t\tthrow e;\n\t} catch (Exception e) {\n\t\tthrow new KeeperException.SystemErrorException(\"Unexpected exception: \" + e.getMessage());\n\t}\n\n\tif (opResults.size() > 0) {\n\t\tOpResult opResult = opResults.get(0);\n\t\tif (opResult.getType() == OpCode.error) {\n\t\t\tKeeperException ke = KeeperException.create(opResult.getErr());\n\t\t\tif (ke.code() == Code.NONODE) {\n\t\t\t\tthrow new KeeperException.NoNodeException();\n\t\t\t} else if (ke.code() == Code.BADVERSION) {\n\t\t\t\tthrow new KeeperException.BadVersionException();\n\t\t\t} else if (ke.code() == Code.NONODE) {\n\t\t\t\tthrow new KeeperException.NoNodeException();\n\t\t\t} else if (ke.code() == Code.NODEEXISTS) {\n\t\t\t\tthrow new KeeperException.NodeExistsException();\n\t\t\t} else if (ke.code() == Code.NOTEMPTY) {\n\t\t\t\tthrow new KeeperException.NotEmptyException();\n\t\t\t} else {\n\t\t\t\tthrow ke;\n\t\t\t}\n\t\t}\n\t}\n\n\treturn opResults;\n}", "CodeBleu_score": 42.031060403259836}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t//        if (LOG.isDebugEnabled()) {\n//            LOG.debug(\"doOperation: \" + transaction);\n//        }\n\n        List<OpResult> opResults = Lists.newArrayListWithCapacity(transaction.size());\n\n        for (Op operation : transaction) {\n            OpResult result = operation.getResult();\n            if (result == null) {\n                result = operation.getZooKeeperOperation().execute();\n                operation.setResult(result);\n            }\n            opResults.add(result);\n        }\n\n        OpResult firstOpResult = opResults.get(0);\n        if (firstOpResult.getErrCode() != 0) {\n            // If the first operation result has an error code, the transaction fails.\n            // Retrieve the error code and throw a KeeperException with the appropriate code.\n            int errCode = firstOpResult.getErrCode();\n            String errMsg = firstOpResult.getErrMsg();\n            throw KeeperException.create(Code.get(errCode), errMsg);\n        }\n\n        return opResults;\n    }", "CodeBleu_score": 46.92825151558522}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\n// Get all the service names\nCollection<String> serviceNames = serviceDiscovery.listServices();\n\n// Print the service names and their instances\nfor (String serviceName : serviceNames) {\n\n// Get all the instances for the service\nCollection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n\n// Print the service name and its instances\nSystem.out.println(serviceName + \":\");\nfor (ServiceInstance<InstanceDetails> instance : instances) {\noutputInstance(instance);\n}\n}\n\n// Close the service discovery instance quietly\nserviceDiscovery.close();\n}", "CodeBleu_score": 47.75538666737303}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\tSystem.out.println(\"Listing instances:\");\nList<String> serviceNames = serviceDiscovery.queryForNames();\nfor (String serviceName : serviceNames) {\n    System.out.println(\"\\tService Name: \" + serviceName);\n    List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n    for (ServiceInstance<InstanceDetails> instance : instances) {\n        outputInstance(instance);\n    }\n}\n}", "CodeBleu_score": 47.89863861919016}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t// Get all service names.\n    List<String> serviceNames = serviceDiscovery.queryForNames();\n    System.out.println(\"Service names: \" + serviceNames);\n\n// Get all instances for each service name.\n    for (String serviceName : serviceNames) {\n        System.out.println(\"Instances for service \" + serviceName + \":\");\n        List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n        if (instances.isEmpty()) {\n            System.out.println(\"\\tNo instances found.\");\n        } else {\n            for (ServiceInstance<InstanceDetails> instance : instances) {\n                outputInstance(instance);\n            }\n        }\n    }\n}", "CodeBleu_score": 63.89774601886037}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeIf(n -> n.equals(READY_NODE));\n\tchildren.sort(String::compareTo);\n\treturn children;\n}", "CodeBleu_score": 15.513970203903082}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tfilteredChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 27.810899677116126}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tList<String> filteredChildren = new ArrayList<String>();\n\tfor (String child : children) {\n\t\tif (!child.equals(READY_NODE)) {\n\t\t\tfilteredChildren.add(child);\n\t\t}\n\t}\n\tCollections.sort(filteredChildren);\n\treturn filteredChildren;\n}", "CodeBleu_score": 27.810899677116126}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t//    System.out.println(\"connectToZK: \" + newHost);\n    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, sessionTimeout, this);\n    if (readOnly) {\n        zk.addAuthInfo(\"digest\", (\"readonly:anyone\").getBytes(UTF_8));\n    }\n    while (true) {\n        synchronized (this) {\n            if (state == State.CONNECTED) {\n                break;\n            }\n            wait();\n        }\n    }\n}", "CodeBleu_score": 31.642718074943012}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\t// If there is an existing active ZooKeeper connection, close it.\n    if (zk != null) {\n        zk.close();\n    }\n    // Create a new ZooKeeper instance with the specified host, timeout, and watcher.\n    zk = new ZooKeeper(newHost, sessionTimeout, this);\n    // If the connection is in read-only mode, set the connection to read-only mode.\n    if (readOnlyMode) {\n        zk.setReadOnlyMode();\n    }\n}", "CodeBleu_score": 28.51403354190411}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\tif (zk != null) {\nzk.close();\nzk = null;\n}\n\nif (newHost != null) {\nString[] parts = newHost.split(\":\");\nString host = parts[0];\nint port = Integer.parseInt(parts[1]);\n\nzk = new ZooKeeper(host + \":\" + port, 3000, this);\n\nif (options.get(\"readonly\") != null) {\nzk.setReadOnlyMode();\n}\n\n}\n}", "CodeBleu_score": 46.63101794588167}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nfor (String aclStr : aclString.split(\",\")) {\nif (aclStr.length() > 0) {\nString scheme = \"world\";\nString id = ANYONE_ID_UNSAFE;\nint perms = 0;\nif (aclStr.contains(\":\")) {\nscheme = aclStr.split(\":\")[0];\naclStr = aclStr.split(\":\")[1];\n}\nif (aclStr.contains(\":\")) {\nid = aclStr.split(\":\")[0];\naclStr = aclStr.split(\":\")[1];\n}\nif (aclStr.length() > 0) {\ntry {\nperms = getPermFromString(aclStr);\n} catch (NumberFormatException e) {\noutputStream.write((\"Error parsing ACL, bad perms: \" + aclStr).getBytes());\n}\n}\nacls.add(new ACL(perms)\n.setId(new Id(scheme, id)));\n}\n}\nreturn acls;\n}", "CodeBleu_score": 29.77903936887307}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nif (aclString == null) {\nreturn acls;\n}\nfor (String aclStr : aclString.split(\",\")) {\nString scheme = \"world\";\nString id = \"anyone\";\nint perms = ZooDefs.Perms.ALL;\nif (aclStr.length() > 0) {\nscheme = aclStr.substring(0, aclStr.indexOf(\":\"));\n}\nif (aclStr.length() > scheme.length() + 1) {\nid = aclStr.substring(scheme.length() + 1);\n}\nif (id.startsWith(\":\")) {\nid = id.substring(1);\n}\nif (aclStr.length() > scheme.length() + id.length() + 1) {\nperms = getPermFromString(aclStr.substring(scheme.length() + id.length() + 1));\n}\nacls.add(new ACL(perms, new Id(scheme, id)));\n}\nreturn acls;\n}", "CodeBleu_score": 25.38628022017737}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<ACL>();\nif (aclString == null) {\nreturn acls;\n}\nString[] aclStrings = aclString.split(\",\");\nfor (String aclString : aclStrings) {\nString[] parts = aclString.split(\":\");\nif (parts.length != 3) {\noutputStream.write((\"Invalid ACL syntax: \" + aclString).getBytes());\ncontinue;\n}\ntry {\nACL acl = new ACL(getPermFromString(parts[2]), new Id(parts[1], parts[0]));\nacls.add(acl);\n} catch (IllegalArgumentException e) {\noutputStream.write((\"Invalid ACL syntax: \" + aclString).getBytes());\n}\n}\nreturn acls;\n}", "CodeBleu_score": 26.4337842393696}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\tObjects.requireNonNull(pathList);\nassertZookeeperExists(serverId);\nif (pathList.size() < 20) {\nfor (String path : pathList) {\nzookeeperMap.get(serverId).delete(path);\n}\n} else {\nzookeeperMap.get(serverId).deleteAsync(pathList);\n}\n}", "CodeBleu_score": 93.47297799250008}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tZookeeperParams params = ZookeeperParams.builder().id(id).url(url).build();\n\tCuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n\tZookeeper zookeeper = new Zookeeper(id, url, () -> factory.createAsync(params, Collections.emptyList()), null, Collections.emptyList(), Collections.emptyList());\n\tzookeeper.connect();\n\tZooKeeperMain main = new ZooKeeperMain(zookeeper);\n\tTerminal terminal = new Terminal(id, url, zookeeper, main);\n\twriter.write(\"Connecting to \" + url + \"...\");\n\twriter.flush();\n\tif (!zookeeper.isConnected()) {\n\t\tthrow new Exception(\"Could not connect to \" + url);\n\t}\n\twriter.write(\"Connected to \" + url + \"\n\");\n\twriter.flush();\n\treturn terminal;\n}", "CodeBleu_score": 48.43061064354537}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(Collections.emptyList())\n\t\t\t.maxRetries(10)\n\t\t\t.connectionTimeout(10000)\n\t\t\t.retryIntervalTime(1000)\n\t\t\t.sessionTimeout(10000)\n\t\t\t.build();\n\tvar client = factory.create(params);\n\twriter.write(\"Connecting to Zookeeper at \" + url + \"...\");\n\twriter.flush();\n\tvar main = new ZooKeeperMain(client);\n\twriter.write(\"Success!\");\n\twriter.write(System.lineSeparator());\n\twriter.flush();\n\treturn new Terminal(id, url, client, main);\n}", "CodeBleu_score": 59.23964352655771}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t\tSSHTunnel tunnel = null;\n\tif (serverConfig.getSshTunnelEnabled() && serverConfig.getSshTunnel() != null) {\n\t\tfinal SSHTunnelConfiguration tunnelConfig = serverConfig.getSshTunnel();\n\t\ttunnel = SSHTunnel.builder()\n\t\t\t\t.localhost(tunnelConfig.getLocalhost())\n\t\t\t\t.localPort(tunnelConfig.getLocalPort())\n\t\t\t\t.sshUsername(tunnelConfig.getSshUsername())\n\t\t\t\t.sshPassword(tunnelConfig.getSshPassword())\n\t\t\t\t.sshKeyFilePath(tunnelConfig.getSshKeyFilePath())\n\t\t\t\t.sshHost(tunnelConfig.getSshHost())\n\t\t\t\t.sshPort(tunnelConfig.getSshPort())\n\t\t\t\t.remoteHost(tunnelConfig.getRemoteHost())\n\t\t\t\t.remotePort(tunnelConfig.getRemotePort())\n\t\t\t\t.build();\n\t}\n\tvar factory = new CuratorZookeeperConnectionFactory();\n\tvar params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.aclList(serverConfig.getAclList())\n\t\t\t.maxRetries(serverConfig.getConnectionConfiguration().getMaxRetries())\n\t\t\t.connectionTimeout(serverConfig.getConnectionConfiguration().getConnectionTimeout())\n\t\t\t.retryIntervalTime(serverConfig.getConnectionConfiguration().getRetryIntervalTime())\n\t\t\t.sessionTimeout(serverConfig.getConnectionConfiguration().getSessionTimeout())\n\t\t\t.build();\n\tvar client = factory.create(params, null);\n\twriter.write(\"Connecting to Zookeeper instance at \" + url + \"...\");\n\tif (client.isConnected()) {\n\t\twriter.write(\"Connected!\n\");\n\t} else {\n\t\twriter.write(\"Failed to connect!\n\");\n\t}\n\tvar main = new ZooKeeperMain(client);\n\treturn new Terminal(id, url, client, main);\n}", "CodeBleu_score": 50.7137399998969}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tint retries = 0;\nwhile (!isConnected() && retries < 6) {\n    try {\n        logger.info(\"Attempting to connect to \" + sshClient.getConnectAddress() + \" on port \" + sshClient.getPort());\n        connect();\n        logger.info(\"Connection established to \" + sshClient.getConnectAddress() + \" on port \" + sshClient.getPort());\n        return;\n    } catch (IOException e) {\n        logger.error(\"Error connecting to \" + sshClient.getConnectAddress() + \" on port \" + sshClient.getPort() + \": \" + e.getMessage());\n        close();\n    }\n\n    try {\n        Thread.sleep(1000);\n    } catch (InterruptedException e) {\n        logger.error(\"Interrupted while waiting to connect to \" + sshClient.getConnectAddress() + \" on port \" + sshClient.getPort() + \": \" + e.getMessage());\n        close();\n    }\n\n    retries++;\n}\n\nif (!isConnected()) {\n    close();\n    throw new IllegalStateException(\"Unable to connect to \" + sshClient.getConnectAddress() + \" on port \" + sshClient.getPort() + \" after \" + retries + \" retries\");\n}\n}", "CodeBleu_score": 43.13199399495687}, {"code": "public void blockUntilConnected(){\n\tint attempt = 0;\nwhile (attempt < 6) {\n    try {\n        if (isConnected()) {\n            return;\n        }\n\n        sshClient.connect(host, port);\n        proxySocket = sshClient.getSocketFactory().createSocket(host, port);\n        return;\n    } catch (IOException e) {\n        log.warn(\"Unable to connect to {}:{} (attempt {})\", host, port, attempt, e);\n    }\n\n    try {\n        Thread.sleep(1000);\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(e);\n    }\n\n    attempt++;\n}\n\nthrow new IllegalStateException(\"Unable to connect to \" + host + \":\" + port + \" after \" + attempt + \" attempts\");\n}", "CodeBleu_score": 45.94997850786692}, {"code": "public void blockUntilConnected(){\n\tint retry = 0;\nwhile (!isConnected() && retry < 6) {\n    try {\n        Thread.sleep(1000);\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(e);\n    }\n\n    retry++;\n}\n\nif (!isConnected()) {\n    close();\n    throw new IllegalStateException(\"Could not establish connection after \" + retry + \" attempts\");\n}\n}", "CodeBleu_score": 51.17984922692686}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(e.getMessage(), e);\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 67.88983617070193}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t}\n\tcatch (Exception e) {\n\t\tlogger.error(\"Error while deleting node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(e.getMessage());\n\t}\n}", "CodeBleu_score": 57.47077747999254}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tLOGGER.error(\"Error deleting node(s) from Zookeeper: \" + e.getMessage(), e);\n\t\tthrow new IllegalStateException(\"Error deleting node(s) from Zookeeper: \" + e.getMessage(), e);\n\t}\n}", "CodeBleu_score": 58.07930781439733}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\ttry {\n\t\t// Get the server configuration\n\t\tServerConfiguration serverConfiguration = ServerConfiguration.getInstance();\n\n\t\t// Determine the connection URL\n\t\tString connectionUrl = serverConfiguration.getConnectionUrl(serverId);\n\n\t\t// Start the terminal\n\t\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error starting terminal\", e);\n\t}\n}", "CodeBleu_score": 35.16216979612258}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// Get the server configuration\n\tServer server = serverService.getServer(serverId);\n\t// Get the connection URL\n\tString connectionUrl = getConnectionUrl(server);\n\t// Call the zookeeperDomainService to start the terminal\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 21.3272296419089}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\ttry {\n\t\t// Get the server configuration\n\t\tServer server = serverService.getServer(serverId);\n\t\tif (server == null) {\n\t\t\tstream.write(\"The server could not be found.\");\n\t\t\treturn;\n\t\t}\n\n\t\t// Get the connection URL\n\t\tString connectionUrl = serverService.getConnectionUrl(server);\n\n\t\t// Start the terminal\n\t\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error starting terminal\", e);\n\t\tstream.write(\"Error starting terminal\");\n\t}\n}", "CodeBleu_score": 30.3091300154136}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t", "CodeBleu_score": 7.482584400043339}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tString[] commandArray = {\"/bin/bash\", \"-c\", command};\n\t\tProcess p = Runtime.getRuntime().exec(commandArray);\n\t\tp.waitFor();\n\t\tif (p.exitValue() != 0) {\n\t\t\tSystem.out.println(\"Command failed on server \" + id + \": \" + command);\n\t\t\tSystem.out.println(\"Please retry the command.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error executing command on server \" + id + \": \" + command);\n\t\tSystem.out.println(\"Please retry the command.\");\n\t}\n}", "CodeBleu_score": 41.242310464515796}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tString[] args = command.split(\" \");\n\t\tswitch(args[0]) {\n\t\t\tcase \"create\":\n\t\t\t\tString path = args[1];\n\t\t\t\tbyte[] data = args[2].getBytes();\n\t\t\t\tZooKeeper zk = zookeepers.get(id);\n\t\t\t\tzk.create(path, data, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t\tbreak;\n\t\t\tcase \"delete\":\n\t\t\t\tpath = args[1];\n\t\t\t\tzk = zookeepers.get(id);\n\t\t\t\tzk.delete(path, -1);\n\t\t\t\tbreak;\n\t\t\tcase \"get\":\n\t\t\t\tpath = args[1];\n\t\t\t\tzk = zookeepers.get(id);\n\t\t\t\tzk.getData(path, false, null);\n\t\t\t\tbreak;\n\t\t\tcase \"set\":\n\t\t\t\tpath = args[1];\n\t\t\t\tdata = args[2].getBytes();\n\t\t\t\tzk = zookeepers.get(id);\n\t\t\t\tzk.setData(path, data, -1);\n\t\t\t\tbreak;\n\t\t\tcase \"ls\":\n\t\t\t\tpath = args[1];\n\t\t\t\tzk = zookeepers.get(id);\n\t\t\t\tzk.getChildren(path, false);\n\t\t\t\tbreak;\n\t\t\tdefault:\n\t\t\t\tSystem.err.println(\"Unknown command: \" + command);\n\t\t}\n\t} catch (KeeperException e) {\n\t\tSystem.err.println(\"Error executing command on server \" + id + \": \" + command);\n\t\te.printStackTrace();\n\t} catch (InterruptedException e) {\n\t\tSystem.err.println(\"Interrupted executing command on server \" + id + \": \" + command);\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 35.5323648968256}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tif (new File(ZOOKEEPER_CONFIG_FILE).exists()) {\n\t\t\tprops.load(new FileInputStream(ZOOKEEPER_CONFIG_FILE));\n\t\t\tSystem.out.println(\"Loaded Zookeeper System Properties from \" + ZOOKEEPER_CONFIG_FILE);\n\t\t} else {\n\t\t\tSystem.out.println(\"Unable to load Zookeeper System Properties. \" + ZOOKEEPER_CONFIG_FILE + \" does not exist.\");\n\t\t}\n\t} catch (IOException e) {\n\t\tSystem.out.println(\"Unable to load Zookeeper System Properties. \" + e.getMessage());\n\t}\n\treturn props;\n}", "CodeBleu_score": 33.626950670434255}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties props = new Properties();\n\tString path = System.getProperty(ZOOKEEPER_CONFIG_PATH_PROP_NAME);\n\tif (path == null) {\n\t\tlogger.info(\"No system property found for the Zookeeper configuration file path. Using default path: \" + ZOOKEEPER_CONFIG_PATH_DEFAULT_VALUE);\n\t\tpath = ZOOKEEPER_CONFIG_PATH_DEFAULT_VALUE;\n\t}\n\ttry {\n\t\tInputStream input = new FileInputStream(path);\n\t\tprops.load(input);\n\t\tinput.close();\n\t\tlogger.info(\"Loaded Zookeeper configuration properties from file: \" + path);\n\t} catch (IOException ex) {\n\t\tlogger.error(\"Error occurred while loading Zookeeper configuration properties from file: \" + path + \". Error: \" + ex.getMessage());\n\t\treturn new Properties();\n\t}\n\treturn props;\n}", "CodeBleu_score": 37.942294009155006}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tString filePath = System.getProperty(\"zookeeper.config.file\");\n\tif (filePath == null) {\n\t\tfilePath = System.getProperty(\"user.dir\") + File.separator + \"conf\" + File.separator + \"zookeeper.properties\";\n\t}\n\tFile file = new File(filePath);\n\tif (file.exists()) {\n\t\ttry {\n\t\t\tFileInputStream input = new FileInputStream(file);\n\t\t\tproperties.load(input);\n\t\t\tinput.close();\n\t\t\tSystem.out.println(\"Loaded properties from file \" + filePath + \": \" + properties);\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Error loading properties from file \" + filePath + \": \" + e.getMessage());\n\t\t}\n\t} else {\n\t\tSystem.out.println(\"Unable to load properties from file \" + filePath + \", file does not exist\");\n\t}\n\treturn properties;\n}", "CodeBleu_score": 38.7782832262732}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties props = new Properties();\n\t\tprops.load(new StringReader(content));\n\t\tsaveZookeeperSystemProperties(props);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error loading Zookeeper system properties.\", e);\n\t\tNotifications.create().title(\"Error loading Zookeeper system properties\").text(\"Check the logs for more details.\").showError();\n\t}\n}", "CodeBleu_score": 17.302038670074975}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties props = new Properties();\n\t\tprops.load(new StringReader(content));\n\t\tFileOutputStream out = new FileOutputStream(SYS_PROP_PATH);\n\t\tprops.store(out, \"Saved by Zookeeper\");\n\t\tout.close();\n\t\tNotification.show(\"Saved Zookeeper system properties\", 3000, Notification.Position.TOP_CENTER);\n\t} catch (IOException e) {\n\t\tNotification.show(\"Failed to save Zookeeper system properties\", 3000, Notification.Position.TOP_CENTER);\n\t\tLOGGER.error(\"Failed to save Zookeeper system properties\", e);\n\t}\n}", "CodeBleu_score": 33.0013454013052}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tOutputStream out = null;\n\t\ttry {\n\t\t\tout = new FileOutputStream(SYS_PROP_PATH);\n\t\t\tproperties.store(out, \"Zookeeper System Properties\");\n\t\t} finally {\n\t\t\tif (out != null) {\n\t\t\t\tout.close();\n\t\t\t}\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.error(\"Error loading Zookeeper system properties.\", e);\n\t\tNotifications.Bus.notify(new Notification(\"Zookeeper System Properties\", \"Error loading Zookeeper system properties.\", e.getMessage(), NotificationType.ERROR));\n\t}\n}", "CodeBleu_score": 29.509569277936937}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t\tStringBuilder response = new StringBuilder();\n\ttry {\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString inputLine;\n\t\twhile ((inputLine = in.readLine()) != null) {\n\t\t\tresponse.append(inputLine);\n\t\t}\n\t\tin.close();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Exception while reading from socket\", e);\n\t} finally {\n\t\tcleanup(client);\n\t}\n\treturn response.toString();\n}", "CodeBleu_score": 49.23188670610902}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tStringBuilder sb = new StringBuilder();\n\t\tBufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = br.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tcleanup(br);\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Failed to read response\", e);\n\t}\n}", "CodeBleu_score": 49.764477008665}, {"code": "private String response(Socket client){\n\t\tStringBuilder sb = new StringBuilder();\n\ttry {\n\t\tBufferedReader br = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line = br.readLine();\n\t\twhile (line != null) {\n\t\t\tsb.append(line);\n\t\t\tsb.append(System.getProperty(\"line.separator\"));\n\t\t\tline = br.readLine();\n\t\t}\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Failed to read response\", e);\n\t}\n}", "CodeBleu_score": 48.981800341930935}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\tCuratorFramework curatorFramework = curatorFramework(params);\n\tcuratorFramework.start();\n\ttry {\n\t\tif (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n\t\t\tcuratorFramework.close();\n\t\t\tthrow new ZookeeperConnectionException(\"Connection timed out\");\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tcuratorFramework.close();\n\t\tThread.currentThread().interrupt();\n\t\tthrow new ZookeeperConnectionException(\"Interrupted while waiting for connection\", e);\n\t}\n\treturn new CuratorZookeeperConnection(curatorFramework);\n}", "CodeBleu_score": 58.682343688965425}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tCuratorFramework curatorFramework = curatorFramework(params);\ncuratorFramework.start();\ntry {\nif (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\ncuratorFramework.close();\nthrow new ZookeeperException(\"Failed to connect to zookeeper\");\n}\n} catch (InterruptedException e) {\ncuratorFramework.close();\nthrow new ZookeeperException(\"Interrupted while connecting to zookeeper\", e);\n}\nreturn new CuratorZookeeperConnection(curatorFramework);\n}", "CodeBleu_score": 60.31457570997545}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t\nCuratorFramework curatorFramework = curatorFramework(params);\n\ntry {\n    curatorFramework.start();\n    curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n    return new CuratorZookeeperConnection(curatorFramework);\n} catch (Exception e) {\n    curatorFramework.close();\n    throw new ZookeeperException(\"Failed to create Zookeeper connection\", e);\n}\n}", "CodeBleu_score": 41.78896150971605}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.compareAndSet(false, true)) {\n    logger.info(\"Starting synchronization of Zookeeper nodes\");\n    try {\n        String zkConnectString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n        logger.info(\"Zookeeper connection string is: \" + zkConnectString);\n        treeCache = new CuratorTreeCache(curatorFramework, zkConnectString, listeners);\n        treeCache.getListenable().addListener(treeCacheListener);\n        treeCache.start();\n        logger.info(\"Started TreeCache\");\n    } catch (Exception e) {\n        logger.error(\"Error starting TreeCache\", e);\n        close();\n    }\n} else {\n    logger.info(\"Already synchronizing Zookeeper nodes\");\n}\n}", "CodeBleu_score": 49.238079814381145}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.compareAndSet(false, true)) {\n    log.info(\"Starting synchronization of {} to {}\", id, zookeeperConnectionString);\n    try {\n        curatorFramework = CuratorFrameworkFactory.newClient(zookeeperConnectionString, new ExponentialBackoffRetry(1000, 3));\n        curatorFramework.start();\n        treeCache = new CuratorTreeCache(curatorFramework, zookeeperPath);\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        treeCache.start();\n    } catch (Exception e) {\n        log.error(\"Error starting synchronization of {} to {}\", id, zookeeperConnectionString, e);\n        close();\n    }\n} else {\n    log.info(\"Synchronization of {} to {} is already in progress\", id, zookeeperConnectionString);\n}\n}", "CodeBleu_score": 45.074676367451275}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\tif (isSync.get()) {\n    LOGGER.info(\"Sync already in progress, skipping this attempt\");\n    return;\n}\n\nLOGGER.info(\"Starting sync\");\n\ntry {\n    this.listeners = listeners;\n    curatorFramework = CuratorFrameworkFactory.newClient(ZookeeperUtil.getConnectionString(), new ExponentialBackoffRetry(1000, 3));\n    curatorFramework.start();\n    treeCache = new TreeCache(curatorFramework, ZookeeperUtil.getSyncPath());\n    treeCache.getListenable().addListener(new CuratorTreeCacheListener(this));\n    treeCache.start();\n} catch (Exception e) {\n    LOGGER.error(\"Error starting sync\", e);\n    close();\n}\n\nisSync.set(true);\n}", "CodeBleu_score": 45.08688752106465}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tif (path == null || path.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Path is null or empty\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"Listener is null\");\n\t}\n\tif (zkClient == null) {\n\t\tthrow new Exception(\"Zookeeper client is null\");\n\t}\n\tif (zkClient.getState() != KeeperState.CONNECTED) {\n\t\tthrow new Exception(\"Zookeeper client is not connected\");\n\t}\n\tif (path.startsWith(\"/\")) {\n\t\tpath = path.substring(1);\n\t}\n\tif (path.endsWith(\"/\")) {\n\t\tpath = path.substring(0, path.length() - 1);\n\t}\n\tString cachePath = \"/\" + path;\n\tif (path.contains(\"/\")) {\n\t\tString[] pathParts = path.split(\"/\");\n\t\tfor (String pathPart : pathParts) {\n\t\t\tcachePath = \"/\" + pathPart + cachePath;\n\t\t}\n\t}\n\tif (pathCacheMap.containsKey(cachePath)) {\n\t\tPathChildrenCache pathCache = pathCacheMap.get(cachePath);\n\t\tpathCache.getListenable().removeListener(listener);\n\t\tpathCache.close();\n\t\tpathCacheMap.remove(cachePath);\n\t}\n\tPathChildrenCache pathCache = new PathChildrenCache(zkClient, cachePath, true);\n\tpathCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tpathCache.getListenable().addListener(listener);\n\tpathCacheMap.put(cachePath, pathCache);\n}", "CodeBleu_score": 46.1169568936185}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tif (zkClient == null) {\n\t\tthrow new Exception(\"Zookeeper client not connected\");\n\t}\n\tif (path == null || path.isEmpty()) {\n\t\tthrow new Exception(\"Invalid path\");\n\t}\n\tif (listener == null) {\n\t\tthrow new Exception(\"Invalid listener\");\n\t}\n\ttry {\n\t\tPathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n\t\tcache.getListenable().addListener(listener);\n\t\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\t} catch (Exception e) {\n\t\tthrow new Exception(e);\n\t}\n}", "CodeBleu_score": 58.17196508972246}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tclient.createContainers(path);\n\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.getListenable().addListener(listener);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n}", "CodeBleu_score": 70.2198780174011}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\ttry {\n\t\tcuratorClient.delete().deletingChildrenIfNeeded().forPath(servicePath);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error unregistering service: \" + e.getMessage());\n\t}\n\tcuratorClient.close();\n}", "CodeBleu_score": 33.056052082500884}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\ttry {\n\t\tcuratorClient.start();\n\t\tList<String> children = curatorClient.getChildren().forPath(SERVICE_PATH);\n\t\tfor (String child : children) {\n\t\t\ttry {\n\t\t\t\tcuratorClient.delete().forPath(SERVICE_PATH + \"/\" + child);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.out.println(\"Error deleting \" + child + \": \" + e.getMessage());\n\t\t\t}\n\t\t}\n\t\tcuratorClient.close();\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Error unregistering service: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 29.948082435952312}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\tfor (String path : servicePaths) {\n\t\ttry {\n\t\t\tclient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tSystem.out.println(\"Error unregistering service: \" + e.getMessage());\n\t\t}\n\t}\n\tclient.close();\n}", "CodeBleu_score": 45.636273788441976}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t//    if (client != null) {\n//        client.subscribeStateChanges(listener);\n//    } else {\n//        makeClientReady(client, null).thenAccept(v -> client.subscribeStateChanges(listener));\n//    }\n}", "CodeBleu_score": 3.7549501205011824}, {"code": "public void addListener(IZkStateListener listener){\n\t//    if (this.client == null) {\n//        this.makeClientReady(listener);\n//    } else {\n        this.client.subscribeStateChanges(listener);\n//    }\n}", "CodeBleu_score": 6.337395510245253}, {"code": "public void addListener(IZkStateListener listener){\n\t//    if (client == null) {\n//        client = new ZkClient(this.connectString, this.sessionTimeout, this.connectionTimeout, this.zkSerializer);\n//    }\n//    client.subscribeStateChanges(listener);\n}", "CodeBleu_score": 3.7549501205011824}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis(serverAddr, authority, CuratorZookeeperClient.DEFAULT_CONNECTION_TIMEOUT_MS, CuratorZookeeperClient.DEFAULT_RETRY_POLICY);\n}", "CodeBleu_score": 3.8048943683275964}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tsuper(serverAddr, authority);\n\ttry {\n\t\tthis.client = CuratorFrameworkFactory.newClient(serverAddr, sessionTimeoutMs, connectionTimeoutMs, retryPolicy);\n\t\tthis.client.getConnectionStateListenable().addListener(new StateListener());\n\t\tif (authority != null) {\n\t\t\tthis.client.start();\n\t\t\tthis.client.getZookeeperClient().blockUntilConnectedOrTimedOut();\n\t\t\tthis.client.getZookeeperClient().addAuthInfo(ZooDefs.AUTH_IDS, authority.getBytes());\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Could not connect to server \" + serverAddr, e);\n\t}\n}", "CodeBleu_score": 22.764714565469312}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\tsuper(serverAddr, authority);\n\n// Set up a retry policy\nRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\n// Set up a connection timeout\nint connectionTimeoutMs = 10000;\n\n// Create the CuratorFramework client\nclient = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(connectionTimeoutMs).authorization(\"digest\", authority).build();\n\n// Add a listener for connection state changes\nclient.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n@Override\npublic void stateChanged(CuratorFramework client, ConnectionState state) {\nif (state == ConnectionState.LOST) {\nCuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n} else if (state == ConnectionState.CONNECTED) {\nCuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n} else if (state == ConnectionState.RECONNECTED) {\nCuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n}\n}\n});\n\n// Start the client\ntry {\nclient.start();\n} catch (Exception e) {\nthrow new IllegalStateException(\"Failed to start Curator client\", e);\n}\n}", "CodeBleu_score": 66.62322226813215}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tthis.removeTargetChildListener(path, new TargetChildListener() {\n\t\t@Override\n\t\tpublic void onChildAdded(TargetDataSnapshot dataSnapshot, String previousChildName) {\n\t\t\tlistener.onChildAdded(dataSnapshot);\n\t\t}\n\n\t\t@Override\n\t\tpublic void onChildChanged(TargetDataSnapshot dataSnapshot, String previousChildName) {\n\t\t\tlistener.onChildChanged(dataSnapshot);\n\t\t}\n\n\t\t@Override\n\t\tpublic void onChildRemoved(TargetDataSnapshot dataSnapshot) {\n\t\t\tlistener.onChildRemoved(dataSnapshot);\n\t\t}\n\n\t\t@Override\n\t\tpublic void onChildMoved(TargetDataSnapshot dataSnapshot, String previousChildName) {\n\t\t\tlistener.onChildMoved(dataSnapshot);\n\t\t}\n\t});\n}", "CodeBleu_score": 25.979448500970033}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path cannot be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener cannot be null\");\n\t}\n\tsynchronized (this.childListenerLock) {\n\t\tif (this.childListeners.containsKey(path)) {\n\t\t\tMap<ChildListener, TargetChildListener> listeners = this.childListeners.get(path);\n\t\t\tif (listeners.containsKey(listener)) {\n\t\t\t\tTargetChildListener targetListener = listeners.get(listener);\n\t\t\t\tlisteners.remove(listener);\n\t\t\t\tif (listeners.isEmpty()) {\n\t\t\t\t\tthis.childListeners.remove(path);\n\t\t\t\t}\n\t\t\t\tthis.removeTargetChildListener(path, targetListener);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 53.71738497352388}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (path == null) {\n\t\tthrow new IllegalArgumentException(\"path must not be null\");\n\t}\n\tif (listener == null) {\n\t\tthrow new IllegalArgumentException(\"listener must not be null\");\n\t}\n\tsynchronized (this) {\n\t\tMap<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n\t\tif (listeners != null) {\n\t\t\tTargetChildListener targetListener = listeners.remove(listener);\n\t\t\tif (listeners.isEmpty()) {\n\t\t\t\tthis.listeners.remove(path);\n\t\t\t}\n\t\t\tif (targetListener != null) {\n\t\t\t\tremoveTargetChildListener(path, targetListener);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 70.06077424502647}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tint ret = QCONF_ERR_OTHER;\n\tif (!zh) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\tstring idc;\n\tstring host;\n\tret = qconf_get_idc_host(zh, idc, host);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tqconf_del_idc_host(zh, idc, host);\n\tret = qconf_init(zh, idc.c_str(), host.c_str());\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tret = qconf_init_env(zh);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\tret = qconf_init_zk_watcher(zh);\n\tif (ret != QCONF_OK) {\n\t\treturn ret;\n\t}\n\treturn QCONF_OK;\n}", "CodeBleu_score": 27.658073779800418}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\tif (zh == NULL) {\n\t\tqconf_log(LOG_ERR, \"zh is NULL\");\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\tqconf_log(LOG_DEBUG, \"zh=%p\", zh);\n\n\t/* Retrieve and delete the IDC host information associated with the handle */\n\tchar *idc = NULL;\n\tchar *host = NULL;\n\tint ret = qconf_get_zk_idc_host(zh, &idc, &host);\n\tif (ret != QCONF_OK) {\n\t\tqconf_log(LOG_ERR, \"qconf_get_zk_idc_host failed, ret=%d\", ret);\n\t\treturn ret;\n\t}\n\tqconf_log(LOG_DEBUG, \"idc=%s, host=%s\", idc, host);\n\tqconf_free(idc);\n\tqconf_free(host);\n\n\t/* Close the old handle */\n\tint rc = zookeeper_close(zh);\n\tif (rc != ZOK) {\n\t\tqconf_log(LOG_ERR, \"zookeeper_close failed, rc=%d\", rc);\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t/* Deserialize the IDC and host information and initialize a new ZooKeeper handle with this information */\n\tret = qconf_init_zk_handle(idc, host, &zh);\n\tif (ret != QCONF_OK) {\n\t\tqconf_log(LOG_ERR, \"qconf_init_zk_handle failed, ret=%d\", ret);\n\t\treturn ret;\n\t}\n\n\t/* Initialize the environment for the new handle and reset the table watcher */\n\tret = qconf_init_zk_env(zh);\n\tif (ret != QCONF_OK) {\n\t\tqconf_log(LOG_ERR, \"qconf_init_zk_env failed, ret=%d\", ret);\n\t\treturn ret;\n\t}\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 34.796853515874176}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\t// Update the internal tables with the handle and host information.\n\tmap<string, zhandle_t*>::iterator it = zk_handles.find(idc_host);\n\tif (it != zk_handles.end()) {\n\t\tfprintf(stderr, \"Error: IDC host %s already registered.\n\", idc_host.c_str());\n\t\texit(1);\n\t}\n\tzk_handles[idc_host] = zh;\n\n\t// Check the connection state of the Zookeeper handle.\n\tint state = zoo_state(zh);\n\tif (state != ZOO_CONNECTED_STATE) {\n\t\tfprintf(stderr, \"Error: Zookeeper handle for IDC host %s is not connected.\n\", idc_host.c_str());\n\t\texit(1);\n\t}\n\n\t// Register the current host on the Zookeeper server.\n\tint rc = zoo_create(zh, zk_host_node.c_str(), idc.c_str(), idc.size(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (rc != ZOK) {\n\t\tfprintf(stderr, \"Error: failed to register host %s on Zookeeper server.\n\", idc_host.c_str());\n\t\texit(1);\n\t}\n\n\t// Set a watcher on the notify node.\n\trc = zoo_exists(zh, zk_notify_node.c_str(), 0, zk_notify_watcher, NULL);\n\tif (rc != ZOK) {\n\t\tfprintf(stderr, \"Error: failed to set watcher on notify node %s.\n\", zk_notify_node.c_str());\n\t\texit(1);\n\t}\n}", "CodeBleu_score": 44.1149870134011}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t", "CodeBleu_score": 4.2583564394715525}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t#ifdef DEBUG\n    printf(\"init_env_for_zk: zh=%p, idc_host=%s, idc=%s\n\", zh, idc_host.c_str(), idc.c_str());\n#endif\n    if (idc_host.empty()) {\n        return;\n    }\n    if (idc.empty()) {\n        return;\n    }\n    if (zk_handle_table.find(zh) != zk_handle_table.end()) {\n        return;\n    }\n    zk_handle_table[zh] = idc;\n    zk_host_table[zh] = idc_host;\n    if (zoo_state(zh) == ZOO_CONNECTED_STATE) {\n        string notify_node = \"/zk/notify/\" + idc;\n        zoo_wexists(zh, notify_node.c_str(), 0, zk_notify_watcher, 0);\n    }\n}", "CodeBleu_score": 40.52938451250869}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \":\" + base64.b64encode(hashlib.sha1(password).digest()).decode('utf-8')\n\n", "CodeBleu_score": 26.651560973961928}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \":\" + base64.b64encode(hashlib.sha1(password).digest()).decode(\"utf-8\")\n\n", "CodeBleu_score": 27.037024833198974}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return username + \":\" + base64.b64encode(hashlib.sha1(password).digest()).decode()\n\n", "CodeBleu_score": 23.821663796133226}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.processing_element + \"/lock\"\n    lock_value = self.zk.get(lock_path)[0].decode(\"utf-8\")\n    if lock_value == self.instance_id:\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 38.26248274215958}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        lock_path = self.processing_element.get_lock_path()\n        lock_value = self.processing_element.get_lock_value()\n        return self.zookeeper.sync(lock_path, lock_value)\n\n", "CodeBleu_score": 37.78255464968251}, {"code": "def holds_lock(self)\n\t\n    return self.zk.exists(self.lock_path) and self.zk.get(self.lock_path)[0].decode(\"utf-8\") == self.id\n\n", "CodeBleu_score": 12.112920062599791}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    with self.holds_lock:\n        if self.processing_element is None:\n            return False\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.retry(self.client.delete, lock_path)\n        self.client.retry(self.client.delete, self._path)\n        self.processing_element = None\n        return True\n", "CodeBleu_score": 50.37183477518907}, {"code": "def consume(self)\n\t\n    if not self.holds_lock: return False\n    with self.transaction():\n        lock_id, lock_value = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.delete(lock_path)\n        self.client.delete(self._processing_element_path)\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 45.42214521153065}, {"code": "def consume(self)\n\t\n    with self.holds_lock:\n        if self.processing_element is None:\n            return False\n        lock_id, _ = self.processing_element\n        lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n        self.client.sync(lock_path)\n        value, stat = self.client.retry(self.client.get, lock_path)\n        if value != self.id:\n            return False\n        self.client.retry(self.client.delete, lock_path)\n        self.client.retry(self.client.delete, self._processing_element_path)\n        return True\n\n", "CodeBleu_score": 46.93247533708422}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    client.logger.log(BLATHER, \"Reading from %s\", client.host)\n    if client._stopped.is_set():\n        return\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except socket.timeout:\n        client.logger.debug(\"Read timed out\")\n        return\n    except Exception as exc:\n        client.logger.exception(\"Exception while reading\")\n        client.handler.dispatch_callback(Callback(\"disconnect\", exc))\n        return\n\n    if header.xid == PING_XID:\n        client.logger.debug(\"Received PING\")\n        client._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        client.logger.debug(\"Received AUTH response\")\n        if header.err == 0:\n            client._auth_failed = False\n            client.handler.dispatch_callback(Callback(\"auth\", None))\n        else:\n            client._auth_failed = True\n            client.handler.dispatch_callback(Callback(\"auth\", AuthFailed()))\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 49.60556150918004}, {"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    header, buffer, offset = self._read_header(read_timeout)\n    xid = header.xid\n    if xid == PING_XID:\n        self.logger.log(BLATHER, \"Received ping\")\n        client._outstanding_ping = False\n    elif xid == AUTH_XID:\n        self.logger.debug(\"Received authentication response\")\n        if header.err:\n            exc = EXCEPTIONS[header.err]()\n            self.logger.debug(\"Received error: %s\", exc)\n            client._pending.popleft()[-1].set_exception(exc)\n        else:\n            client._pending.popleft()[-1].set(None)\n    elif xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 51.58945579105567}, {"code": "def _read_socket(self, read_timeout)\n\t\n    client = self.client\n    buffer = b\"\"\n    offset = 0\n\n    # Read the header\n    header, buffer, offset = self._read_header(read_timeout)\n\n    # Determine if its a ping response\n    if header.xid == PING_XID:\n        self.logger.debug(\"Received PING response\")\n        client._outstanding_ping = False\n        return\n\n    # Determine if its an auth response\n    if header.xid == AUTH_XID:\n        self.logger.debug(\"Received AUTH response\")\n        if header.err:\n            client._auth_in_progress = False\n            client._session_id = None\n            client._session_password = <PASSWORD>\n            client._session_password_set = False\n            client._session_timeout = None\n            client._session_timeout_set = False\n            raise EXCEPTIONS[header.err]()\n        else:\n            client._auth_in_progress = False\n            client._session_id = None\n            client._session_password = <PASSWORD>\n            client._session_password_set = False\n            client._session_timeout = None\n            client._session_timeout_set = False\n            client.logger.debug(\"Successfully authenticated\")\n            return\n\n    # Determine if its a close response\n    if header.xid == CLOSE_XID:\n        self.logger.debug(\"Received CLOSE response\")\n        client.close()\n        return\n\n    # Determine if its a watch response\n    if header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n        return\n\n    # Read the response\n    self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 42.868765376929076}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.info('Starting zk_loop')\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.zk.start()\n            self.logger.info('Connected to Zookeeper')\n            self.session_callback(KazooState.CONNECTED)\n            self.connection_stopped.wait()\n            self.session_callback(KazooState.LOST)\n            self.logger.info('Disconnected from Zookeeper')\n        except Exception as e:\n            self.logger.warning('Unable to connect to Zookeeper: %s', e)\n            self.connection_stopped.wait(self.retry_policy.sleep_func(self.retry_policy.max_delay))\n    self.logger.info('Stopping zk_loop')\n\n", "CodeBleu_score": 46.412165601864345}, {"code": "def zk_loop(self)\n\t\n    self.logger.debug('zk_loop started')\n    self.connection_stopped.clear()\n    retry = self.retry\n    while not self.stopped.is_set() and retry.deadline() > time.time():\n        try:\n            self.logger.debug('Connecting to Zookeeper')\n            self.zk.start()\n            self.logger.debug('Connected to Zookeeper')\n            self.connection_stopped.set()\n            self.session_callback(self.session_state)\n            break\n        except Exception:\n            self.logger.warning('Failed to connect to Zookeeper')\n            retry.sleep()\n    self.logger.debug('zk_loop stopped')\n\n", "CodeBleu_score": 49.762124571152555}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting Zookeeper connection loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.logger.info(\"Attempting to connect to Zookeeper\")\n            self.zk.start()\n            self.logger.info(\"Connected to Zookeeper\")\n            self.connection_stopped.set()\n            self.session_callback(self.session_state.CLOSED)\n            self.logger.info(\"Zookeeper connection loop stopped\")\n            break\n        except Exception as e:\n            self.logger.warning(\"Failed to connect to Zookeeper: %s\" % str(e))\n            self.connection_stopped.wait(self.retry_policy.sleep_time)\n    self.stopped.set()\n\n", "CodeBleu_score": 45.99922612221362}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 33.6805163744097}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    # Sort the partitions and members\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n\n    # Find the index of the identifier in the sorted members list\n    index = sorted_members.index(identifier)\n\n    # Return every nth partition starting from the index\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n", "CodeBleu_score": 38.15684315583741}, {"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n\n", "CodeBleu_score": 38.15684315583741}, {"code": "def leave(self)\n\t\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self.participating = False\n\n", "CodeBleu_score": 43.66279553678979}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\t// Check if the server is already running\n\tif (isServerRunning()) {\n\t\treturn new Result(Result.CODE_ERROR, \"The server is already running.\");\n\t}\n\n\ttry {\n\t\t// Start the server\n\t\tserver.start();\n\t\treturn new Result(Result.CODE_SUCCESS, \"The server has been started.\");\n\t} catch (Exception e) {\n\t\treturn new Result(Result.CODE_ERROR, \"An error occurred while starting the server: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 27.29447805276241}, {"code": "public Result start(){\n\t\ttry {\n\t\tif (!isServerRunning()) {\n\t\t\tlogger.info(\"Starting the HDFS over FTP server...\");\n\t\t\tstartServer();\n\t\t\tlogger.info(\"HDFS over FTP server started.\");\n\t\t} else {\n\t\t\tlogger.info(\"HDFS over FTP server already running.\");\n\t\t}\n\t\treturn new Result(Result.SUCCESS);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error while starting the HDFS over FTP server.\", e);\n\t\treturn new Result(Result.ERROR, e);\n\t}\n}", "CodeBleu_score": 30.602883580543317}, {"code": "public Result start(){\n\t\ttry {\n\t\tif (server.getStatus() == State.NOT_RUNNING) {\n\t\t\tserver.start();\n\t\t\treturn new Result(true, \"HDFS over FTP server started successfully\");\n\t\t} else {\n\t\t\treturn new Result(false, \"HDFS over FTP server is already running\");\n\t\t}\n\t} catch (Exception e) {\n\t\treturn new Result(false, e.getMessage());\n\t}\n}", "CodeBleu_score": 29.29372709829927}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\tResult result = new Result();\n\tif (this.server.isRunning()) {\n\t\ttry {\n\t\t\tthis.server.stop();\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"FTP Server stopped.\");\n\t\t} catch (Exception e) {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMessage(e.getMessage());\n\t\t\tLOGGER.error(e.getMessage(), e);\n\t\t}\n\t} else {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(\"FTP Server is not running.\");\n\t}\n\treturn result;\n}", "CodeBleu_score": 30.780634200479835}, {"code": "public Result stop(){\n\t\tif(server != null) {\n\t\ttry {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"FTP server stopped\");\n\t\t}\n\t\tcatch(Exception e) {\n\t\t\tLog.e(TAG, \"Error while stopping FTP server: \" + e.getMessage());\n\t\t\treturn new Result(false, \"Error while stopping FTP server: \" + e.getMessage());\n\t\t}\n\t}\n\telse {\n\t\treturn new Result(false, \"FTP server is not running\");\n\t}\n}", "CodeBleu_score": 37.47495389548166}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"FTP server stopped.\");\n\t\t}\n\t\telse {\n\t\t\treturn new Result(false, \"FTP server is not running.\");\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tlog.error(\"An error occurred while attempting to stop the FTP server.\", e);\n\t\treturn new Result(false, \"An error occurred while attempting to stop the FTP server.\");\n\t}\n}", "CodeBleu_score": 32.3329304195228}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.00644468250869}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\treturn authorize(request, null);\n}", "CodeBleu_score": 3.878984094344266}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 78.00644468250869}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\treturn fileSystem.mkdirs(new Path(fullPath));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 45.29055861759672}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\tSystem.out.println(e.getMessage());\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 44.865619259062115}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tif (fs.mkdirs(fullPath)) {\n\t\t\tSystem.out.println(\"Directory created\");\n\t\t\treturn true;\n\t\t} else {\n\t\t\tSystem.out.println(\"Directory already exists\");\n\t\t\treturn false;\n\t\t}\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 45.59905419303742}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(path.toString()), conf);\n\t\tfs.rename(path, new Path(ftpFile.getParent(), ftpFile.getName()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 63.38762643215758}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tfs.rename(path, new Path(ftpFile.getParent(), ftpFile.getName()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 65.26624983810926}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tPath newPath = new Path(ftpFile.getParent(), ftpFile.getName());\n\t\treturn fs.rename(path, newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 52.67199978314494}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\tArrayList<FtpFile> fileList = new ArrayList<FtpFile>(status.length);\n\t\tfor (FileStatus stat : status) {\n\t\t\tString name = stat.getPath().getName();\n\t\t\tlong size = stat.getLen();\n\t\t\tboolean isDirectory = stat.isDirectory();\n\t\t\tlong lastModified = stat.getModificationTime();\n\t\t\tString fullName = getAbsolutePath() + \"/\" + name;\n\t\t\tfileList.add(new FtpFile(name, fullName, size, isDirectory, lastModified));\n\t\t}\n\t\treturn Collections.unmodifiableList(fileList);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error while listing files in HDFS\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 33.18580580743601}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\t// get the HDFS file system instance\n\t\tFileSystem fs = FileSystem.get(URI.create(path.toString()), conf);\n\n\t\t// list the status of files in the directory\n\t\tFileStatus[] files = fs.listStatus(path);\n\n\t\t// construct virtual file names based on the base directory's virtual path\n\t\tList<FtpFile> ftpFiles = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tString fileName = file.getPath().toString();\n\t\t\tif (fileName.endsWith(\"/\")) {\n\t\t\t\tfileName = fileName.substring(0, fileName.length() - 1);\n\t\t\t}\n\t\t\tString virtualFileName = fileName.substring(path.toString().length());\n\t\t\tif (!virtualFileName.startsWith(\"/\")) {\n\t\t\t\tvirtualFileName = \"/\" + virtualFileName;\n\t\t\t}\n\t\t\tFtpFile ftpFile = new FtpFile(virtualFileName, file.isDirectory());\n\t\t\tftpFiles.add(ftpFile);\n\t\t}\n\n\t\treturn Collections.unmodifiableList(ftpFiles);\n\t} catch (IOException e) {\n\t\t// log the error\n\t\tlogger.error(\"Error while listing files from HDFS\", e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 35.76808316246179}, {"code": "public List<FtpFile> listFiles(){\n\t\ttry {\n\t\tFileStatus[] fileStatuses = fs.listStatus(path);\n\t\tList<FtpFile> files = new ArrayList<FtpFile>(fileStatuses.length);\n\t\tString fullName = getAbsolutePath();\n\t\tfor (FileStatus fileStatus : fileStatuses) {\n\t\t\tString name = fileStatus.getPath().getName();\n\t\t\tif (fileStatus.isFile()) {\n\t\t\t\tfiles.add(new FtpFile(name, fullName, fileStatus.getLen(), fileStatus.getModificationTime()));\n\t\t\t} else {\n\t\t\t\tfiles.add(new FtpFile(name, fullName + \"/\" + name, 0, fileStatus.getModificationTime()));\n\t\t\t}\n\t\t}\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\tlog.error(\"Error while listing files in \" + path, e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 32.65903492501814}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tif (configured) {\n\t\treturn;\n\t}\n\n\tconfigured = true;\n\n\tif (getUserDataFile() == null) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"No user data file specified\");\n\t}\n\n\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data from file \"\n\t\t\t\t\t\t+ getUserDataFile(), e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 26.482879777091117}, {"code": "public void configure(){\n\t\t// set configuration state to true\n\tconfigured = true;\n\n\t// load user data properties\n\tloadUserData();\n\n\t// convert deprecated property names\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 7.826003250116079}, {"code": "public void configure(){\n\t\tif (configured) {\n\t\treturn;\n\t}\n\n\tconfigured = true;\n\n\t// check if the user data file exists\n\tif (!file.exists()) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"User data file does not exist: \" + file.getAbsolutePath());\n\t}\n\n\t// load the properties\n\ttry {\n\t\tuserDataProp.load(new FileInputStream(file));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data file: \" + file.getAbsolutePath(), e);\n\t}\n\n\t// convert any deprecated property names\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 36.86624308791917}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tFile userDir = new File(System.getProperty(\"user.home\") + \"/.ftp\");\n\tif (!userDir.exists()) {\n\t\ttry {\n\t\t\tuserDir.mkdir();\n\t\t} catch (SecurityException e) {\n\t\t\tthrow new FtpException(\"Unable to create user directory: \" + e.getMessage());\n\t\t}\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(new File(userDir, \"user_data\"));\n\t\tObjectOutputStream oos = new ObjectOutputStream(fos);\n\t\toos.writeObject(this.user);\n\t\toos.close();\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Unable to save user data: \" + e.getMessage());\n\t\tthrow new FtpException(\"Unable to save user data: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 38.76724213414935}, {"code": "private void saveUserData() throws FtpException{\n\t\tFile dir = new File(userDir);\n\tif (!dir.exists()) {\n\t\ttry {\n\t\t\tdir.mkdir();\n\t\t} catch (SecurityException e) {\n\t\t\tlogger.error(\"Error creating user data directory: \" + e.getMessage());\n\t\t\tthrow new FtpException(\"Error creating user data directory: \" + e.getMessage());\n\t\t}\n\t}\n\tFile file = new File(userDir + userName + \".txt\");\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(file);\n\t\tfos.write(userData.getBytes());\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error writing user data to file: \" + e.getMessage());\n\t\tthrow new FtpException(\"Error writing user data to file: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 39.89693430654111}, {"code": "private void saveUserData() throws FtpException{\n\t\ttry {\n\t\tFile file = new File(userDir);\n\t\tif (!file.exists()) {\n\t\t\tfile.mkdirs();\n\t\t}\n\t\tFileOutputStream fos = new FileOutputStream(new File(userDir + File.separator + \"user.dat\"));\n\t\tObjectOutputStream oos = new ObjectOutputStream(fos);\n\t\toos.writeObject(user);\n\t\toos.close();\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tSystem.err.println(\"Could not save user data\");\n\t\te.printStackTrace();\n\t\tthrow new FtpException();\n\t}\n}", "CodeBleu_score": 38.31470850978347}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 79.80052682501866}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 79.80052682501866}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n}catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 79.80052682501866}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"Opening file: \" + path + \" with buffer size: \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tLOG.info(\"Qualified path: \" + qualifiedPath);\n\tFSDataInputStream inputStream = fs.open(qualifiedPath, bufferSize);\n\tLOG.info(\"Opened file: \" + path + \" with buffer size: \" + bufferSize);\n\treturn inputStream;\n}", "CodeBleu_score": 27.249656795124764}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"open(path={}, bufferSize={})\", path, bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tFSDataInputStream stream = store.open(qualifiedPath, bufferSize);\n\tLOG.info(\"open(path={}, bufferSize={}) => {}\", path, bufferSize, stream);\n\treturn stream;\n}", "CodeBleu_score": 32.082466331109565}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.info(\"open: \" + qualify(path) + \" bufferSize: \" + bufferSize);\n\tFSDataInputStream stream = fs.open(qualify(path), bufferSize);\n\treturn stream;\n}", "CodeBleu_score": 16.790308323757767}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 94.24097931912301}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 94.24097931912301}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\nLOG.debug(\"rename path: {} => {}\", src, dst);\n\nif (src.isRoot()) {\n    return false;\n}\n\nif (src.equals(dst)) {\n    return true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry != null) {\n    FileStatus dstFileStatus = getFileStatus(dst);\n    String sourceFileName = src.getName();\n    if (!dstFileStatus.isDirectory()) {\n        return false;\n    }\n    adjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 96.13341139347618}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.619069546583695}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 20.756031968442706}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\t// Synchronize the operation.\n\tsynchronized (this) {\n\t\t// Write metadata to the filer client.\n\t\tif (this.metadata != null) {\n\t\t\tthis.metadata.write(this.filerClient);\n\t\t}\n\n\t\t// Update the last flush offset.\n\t\tthis.lastFlushOffset = offset;\n\t}\n}", "CodeBleu_score": 31.774014824141382}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (this.closed) {\n\t\tthrow new IOException(\"The stream is closed.\");\n\t}\n\tif (this.lastFlushOffset >= offset) {\n\t\treturn;\n\t}\n\tthis.lastFlushOffset = offset;\n\tfinal long flushSize = offset - this.lastFlushOffset;\n\tthis.lastFlushOffset = offset;\n\tthis.service.write(this.writtenBytes, this.lastFlushOffset, flushSize);\n\tthis.writtenBytes.position(this.writtenBytes.limit());\n\tthis.writtenBytes.limit(this.writtenBytes.capacity());\n\tthis.service.writeMetadata(this.lastFlushOffset, flushSize);\n}", "CodeBleu_score": 32.311663212565634}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t", "CodeBleu_score": 11.405170056407002}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t//        if (writePosition < 0) {\n//            throw new IllegalArgumentException(\"writePosition must be non-negative\");\n//        }\n//        if (bufferToWrite.remaining() == 0) {\n//            return 0;\n//        }\n//        if (bufferToWrite.isReadOnly()) {\n//            throw new IllegalArgumentException(\"bufferToWrite must be a read/write buffer\");\n//        }\n//        if (lastError != null) {\n//            throw new IOException(\"Last error occurred in a previous operation\", lastError);\n//        }\n\n        final int bufferLength = bufferToWrite.remaining();\n        final long writeOffset = writePosition + lastTotalAppendOffset;\n        final long writeLength = bufferLength;\n\n        if (writeLength > maxWriteLength) {\n            throw new IllegalArgumentException(\"Attempted to write \" + writeLength + \" bytes, which exceeds the maximum write length of \" + maxWriteLength);\n        }\n\n        // Wait until the queue is not overloaded\n        waitForTaskToComplete();\n\n        // Write the buffer to the service\n        final Future<Integer> writeTask = completionService.submit(new WriteTask(bufferToWrite, writeOffset, writeLength));\n        writeOperations.add(new WriteOperation(writeTask, bufferLength));\n\n        return bufferLength;\n    }", "CodeBleu_score": 35.85114240748112}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t//        if (closed) {\n//            throw new IOException(\"Stream closed\");\n//        }\n\n        if (bufferToWrite.remaining() == 0) {\n            return 0;\n        }\n\n        if (writePosition < 0) {\n            throw new IllegalArgumentException(\"position < 0\");\n        }\n\n        if (writePosition > length) {\n            throw new IllegalArgumentException(\"position > length\");\n        }\n\n        // Ensure the buffer is ready for reading\n        bufferToWrite.flip();\n\n        // Calculate the number of bytes to write\n        int numBytesToWrite = bufferToWrite.remaining();\n\n        // Ensure the queue is not overloaded\n        if (writeOperations.size() == MAX_WRITE_QUEUE_SIZE) {\n            shrinkWriteOperationQueue();\n        }\n\n        // Submit the write task to the completion service\n        final WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition);\n        final Future<Integer> writeTask = completionService.submit(writeOperation);\n        writeOperations.add(writeOperation);\n\n        // Record the write operation\n        writeOperations.add(writeOperation);\n\n        // Wait for the task to complete\n        waitForTaskToComplete();\n\n        // Check for errors\n        if (lastError != null) {\n            throw lastError;\n        }\n\n        // Return the number of bytes written\n        return numBytesToWrite;\n    }", "CodeBleu_score": 34.77744482236527}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t//        if (lastError != null) {\n//            throw lastError;\n//        }\n\n        final int length = bufferToWrite.remaining();\n        if (length == 0) {\n            return 0;\n        }\n\n        final long nextWritePosition = writePosition + length;\n        if (nextWritePosition > lastTotalAppendOffset) {\n            lastTotalAppendOffset = nextWritePosition;\n        }\n\n        if (writeOperations.size() >= maxWriteOperations) {\n            shrinkWriteOperationQueue();\n        }\n\n        final WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition);\n        writeOperations.add(writeOperation);\n        completionService.submit(new WriteTask(writeOperation));\n        return length;\n}", "CodeBleu_score": 33.2344646024943}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile(true) {\n\t\ttry {\n\t\t\tif(completionService.take().isDone()) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} catch(InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 15.228206933764483}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\tif (completionService.poll() != null) {\n\t\treturn;\n\t}\n\n\ttry {\n\t\tcompletionService.take();\n\t} catch (InterruptedException e) {\n\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t}\n}", "CodeBleu_score": 25.757572853269938}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (!completionService.isDone()) {\n\t\ttry {\n\t\t\tFuture<Integer> future = completionService.take();\n\t\t\tfuture.get();\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete.\", e);\n\t\t} catch (ExecutionException e) {\n\t\t\tthrow new IOException(\"Error while waiting for task to complete.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 28.217654112658856}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty() && writeOperationQueue.peek().isDone()) {\n\t\tAppendOperation operation = writeOperationQueue.remove();\n\t\tif (operation.exception != null) {\n\t\t\tthrow operation.exception;\n\t\t}\n\t\ttotalAppendOffset += operation.length;\n\t}\n}", "CodeBleu_score": 31.531710790063883}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation writeOperation = writeOperationQueue.peek();\n\t\tif (writeOperation.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\tif (writeOperation.exception != null) {\n\t\t\t\tthrow new IOException(\"Exception in write operation\", writeOperation.exception);\n\t\t\t}\n\t\t\tappendOffset += writeOperation.bytesWritten;\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 27.58787489954363}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\tWriteOperation writeOperation = writeOperationQueue.peek();\n\t\tif (writeOperation.isDone()) {\n\t\t\twriteOperationQueue.remove();\n\t\t\ttry {\n\t\t\t\ttotalAppendOffset += writeOperation.getLength();\n\t\t\t} catch (IOException e) {\n\t\t\t\tthrow new IOException(\"Error while updating total append offset.\", e);\n\t\t\t}\n\t\t} else {\n\t\t\tbreak;\n\t\t}\n\t}\n}", "CodeBleu_score": 30.625413862556698}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"The user argument cannot be null.\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"The user's home directory cannot be null.\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 64.50134578589078}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"The user must not be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"The user's home directory must not be null\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 68.28231411555336}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"User cannot be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User's home directory cannot be null\");\n\t}\n\thomePath = user.getHomeDirectory().getAbsolutePath();\n\tthis.user = user;\n}", "CodeBleu_score": 68.10272475098992}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.equals(\"..\")) {\n\t\tif (currentDirectory.getParent() != null) {\n\t\t\tcurrentDirectory = currentDirectory.getParent();\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\telse if (dir.equals(\".\")) {\n\t\treturn true;\n\t}\n\telse if (dir.startsWith(\"/\")) {\n\t\tPath path = new Path(dir);\n\t\tif (path.isDirectory()) {\n\t\t\tcurrentDirectory = path;\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\telse {\n\t\tPath path = new Path(currentDirectory, dir);\n\t\tif (path.isDirectory()) {\n\t\t\tcurrentDirectory = path;\n\t\t\treturn true;\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 32.28413092188472}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t", "CodeBleu_score": 0.8804759245384238}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\t// If the path is absolute, create a new Path object with the absolute path.\n\tif (dir.charAt(0) == '/') {\n\t\tPath newPath = new Path(dir);\n\n\t\t// If the new path is a directory, update the current path.\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\t// If the new path is not a directory, return false.\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\t// If the path is relative, create a new Path object with the relative path.\n\telse {\n\t\tPath newPath = new Path(currentPath.getPath() + \"/\" + dir);\n\n\t\t// If the new path is a directory, update the current path.\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t}\n\t\t// If the new path is not a directory, return false.\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 25.351647389981068}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(conf);\n\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.conf = conf;\n\tthis.filer = new FilerClient(host, port, grpcPort);\n\tthis.accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\n\tLOG.info(\"Initialized SeaweedFileSystemStore with host={}, port={}, grpcPort={}, accessMode={}, conf={}\", host, port, grpcPort, accessMode, conf);\n}", "CodeBleu_score": 38.7761749907906}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(ACCESS_MODE_KEY, DEFAULT_ACCESS_MODE);\n}", "CodeBleu_score": 19.87576863509564}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\tsuper(host, port, grpcPort, conf);\n}", "CodeBleu_score": 13.300941036719834}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n// Log the path being opened\nlogger.debug(\"Opening file for read: {}\", path);\n\n// Look up the file entry\nFilerProto.Entry entry = lookupEntry(path);\n\n// If the entry is not found, throw a FileNotFoundException\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\n// If the entry is found, return a new SeaweedHadoopInputStream for reading the file, using the filer client, statistics, and file path\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path, entry.getAttributes().get(\"size\"));\n\n}", "CodeBleu_score": 77.64103472904151}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n// Log the path being opened.\nlogger.info(\"Opening file for read: {}\", path);\n\n// Look up the file entry.\nFilerProto.Entry entry = lookupEntry(path);\n\n// If the entry is not found, throw a FileNotFoundException.\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\n// If the entry is found, return a new SeaweedHadoopInputStream for reading the file.\nreturn new SeaweedHadoopInputStream(filerClient, entry, statistics, path);\n\n}", "CodeBleu_score": 73.53136174227302}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n// Log the path being opened.\nif (LOG.isTraceEnabled()) {\n\nLOG.trace(\"Opening file for read: \" + path);\n\n}\n\n// Look up the file entry.\nfinal FilerProto.Entry entry = lookupEntry(path);\n\n// If the entry is not found, throw a FileNotFoundException.\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\n// If the entry is found, return a new SeaweedHadoopInputStream for reading the file.\nreturn new SeaweedHadoopInputStream(filerClient, entry, statistics, path);\n\n}", "CodeBleu_score": 72.74923818035704}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\ttry {\n\t\tthis.hostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.hostName = \"localhost\";\n\t}\n\tthis.numThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tthis.numFiles = conf.getInt(\"mapred.map.tasks.files\", 1);\n\tthis.numThreadsPerFile = this.numThreads / this.numFiles;\n\tthis.pool = Executors.newFixedThreadPool(this.numThreads, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 52.08036715579768}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thost = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thost = \"localhost\";\n\t}\n\tnumThreads = conf.getInt(\"mapred.map.tasks\", 1);\n\tnumFiles = conf.getInt(\"mapred.map.tasks.files\", 1);\n\tnumThreadsPerFile = conf.getInt(\"mapred.map.tasks.files.max\", 1);\n\tthreads = new ArrayList<Thread>(numThreads);\n\tfor (int i = 0; i < numThreads; i++) {\n\t\tthreads.add(new Thread(this));\n\t\tthreads.get(i).setDaemon(true);\n\t}\n}", "CodeBleu_score": 43.554760101845005}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\tthis.localHostname = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\tthis.localHostname = \"localhost\";\n\t}\n\tthis.threadsPerMap = conf.getInt(\"mapred.map.tasks\", 1);\n\tthis.filesPerThread = conf.getInt(\"mapred.map.tasks.files.max\", 1);\n\tthis.threadPool = Executors.newFixedThreadPool(threadsPerMap, new ThreadFactory() {\n\t\tpublic Thread newThread(Runnable r) {\n\t\t\tThread t = new Thread(r);\n\t\t\tt.setDaemon(true);\n\t\t\treturn t;\n\t\t}\n\t});\n}", "CodeBleu_score": 51.99298507865322}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n\t\treturn;\n\t}\n\ttry {\n\t\tUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n\t\temptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n\t\t\tJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n\t\t\tfs.initialize(uri, conf);\n\t\t\treturn fs;\n\t\t});\n\t\tBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n\t} catch (Exception e) {\n\t\tthrow new IOException(\"start trash failed!\",e);\n\t}\n}", "CodeBleu_score": 97.03523785218209}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 96.97284868202057}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 96.97284868202057}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getContext();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tsetContext(context, null);\n\t} else {\n\t\tString[] currentContexts = currentContext.split(\";\");\n\t\tif (currentContexts.length == 1) {\n\t\t\tif (currentContexts[0].equals(context)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tsetContext(currentContext + \";\" + context, null);\n\t\t} else {\n\t\t\tfor (int i = 0; i < currentContexts.length; i++) {\n\t\t\t\tif (currentContexts[i].equals(context)) {\n\t\t\t\t\treturn;\n\t\t\t\t}\n\t\t\t}\n\t\t\tsetContext(currentContext + \";\" + context, null);\n\t\t}\n\t}\n}", "CodeBleu_score": 31.738369234749342}, {"code": "public static void setContext(String context) throws Exception{\n\t\tif (context == null || context.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Context cannot be null or empty\");\n\t}\n\tif (context.length() > MAX_CONTEXT_LENGTH) {\n\t\tthrow new IllegalArgumentException(\"Context cannot be longer than \" + MAX_CONTEXT_LENGTH + \" characters\");\n\t}\n\tif (context.matches(\"[^a-zA-Z0-9_]+\")) {\n\t\tthrow new IllegalArgumentException(\"Context cannot contain any special characters except underscore\");\n\t}\n\tString currentContext = getContext();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tsetContext(context, true);\n\t} else if (!currentContext.contains(context)) {\n\t\tString newContext = currentContext + \"_\" + context;\n\t\tif (newContext.length() > MAX_CONTEXT_LENGTH) {\n\t\t\tthrow new IllegalArgumentException(\"Context cannot be longer than \" + MAX_CONTEXT_LENGTH + \" characters\");\n\t\t}\n\t\tsetContext(newContext, true);\n\t}\n}", "CodeBleu_score": 28.00155821842435}, {"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getContext();\n\tif (currentContext == null || currentContext.isEmpty()) {\n\t\tcurrentContext = context;\n\t} else {\n\t\tString[] contexts = currentContext.split(\";\");\n\t\tif (contexts.length == 1) {\n\t\t\tif (contexts[0].length() > 0) {\n\t\t\t\tcurrentContext = currentContext + \";\" + context;\n\t\t\t} else {\n\t\t\t\tcurrentContext = context;\n\t\t\t}\n\t\t} else {\n\t\t\tboolean found = false;\n\t\t\tfor (int i = 0; i < contexts.length; i++) {\n\t\t\t\tif (contexts[i].equals(context)) {\n\t\t\t\t\tfound = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (!found) {\n\t\t\t\tcurrentContext = currentContext + \";\" + context;\n\t\t\t}\n\t\t}\n\t}\n\tsetContext(currentContext);\n}", "CodeBleu_score": 28.738346401910558}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  int rc = hdfsDelete(fs, uri.c_str(), 0);\n  RETURN_NOT_OK(disconnect(fs));\n  if (rc != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot delete file '\" + uri.to_string() + \"'\"));\n  }\n  return Status::Ok();\n#else\n  return Status_NotImplemented(\"Cannot delete files from HDFS\");\n#endif\n}", "CodeBleu_score": 56.68902737706447}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  int rc = hdfsDelete(fs, uri.c_str(), 0);\n  if (rc != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot delete file '\" + uri.to_string() + \"'\"));\n  }\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_IOError(\"Cannot remove file '\" + uri.to_string() + \"'\"));\n#endif\n}", "CodeBleu_score": 57.234227410097915}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  int rc = hdfsDelete(fs, uri.c_str(), 0);\n  if (rc != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot delete file '\" + uri.to_string() + \"' from HDFS\"));\n  }\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_NotImplemented(\"Cannot delete file '\" + uri.to_string() + \"' from HDFS\"));\n#endif\n}", "CodeBleu_score": 56.06554592102525}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\nif (!ret) {\n  return Status::Ok();\n}\nhdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\nif (file == nullptr) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot open file to sync\"));\n}\nret = libhdfs_->hdfsFlush(fs, file);\nif (ret == -1) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot sync file\"));\n}\nret = libhdfs_->hdfsCloseFile(fs, file);\nif (ret == -1) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot close file after sync\"));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 50.444927669668836}, {"code": "Status HDFS::sync(const URI& uri){\n\thdfsFS fs = nullptr;\nRETURN_NOT_OK(connect(&fs));\nif (!libhdfs_->hdfsExists(fs, uri.to_path().c_str())) {\n  return Status::Ok();\n}\nhdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\nif (file == nullptr) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot open file \" + uri.to_string()));\n}\nint ret = libhdfs_->hdfsFlush(fs, file);\nif (ret != 0) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot flush file \" + uri.to_string()));\n}\nret = libhdfs_->hdfsCloseFile(fs, file);\nif (ret != 0) {\n  return LOG_STATUS(Status_HDFSError(\"Cannot close file \" + uri.to_string()));\n}\nreturn Status::Ok();\n}", "CodeBleu_score": 50.723451260567145}, {"code": "Status HDFS::sync(const URI& uri){\n\t//  LOG_DEBUG(\"Syncing file: \" + uri.to_string());\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (!ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot open file for sync\"));\n  }\n  int ret = libhdfs_->hdfsFlush(fs, file);\n  if (ret != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot flush file for sync\"));\n  }\n  ret = libhdfs_->hdfsCloseFile(fs, file);\n  if (ret != 0) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot close file for sync\"));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 52.470147224086205}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFile file = hdfsOpenFile(fs, uri.c_str(), O_RDONLY, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_IOError(\"Cannot open file\"));\n  }\n  tSize size = hdfsGetPathInfo(fs, uri.c_str(), nullptr)->mSize;\n  hdfsCloseFile(fs, file);\n  *nbytes = static_cast<uint64_t>(size);\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_IOError(\"Cannot open file; libhdfs not found\"));\n#endif\n}", "CodeBleu_score": 46.003365546829656}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFile file = nullptr;\n  RETURN_NOT_OK(open_file(fs, uri, &file));\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_string().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot get file info from HDFS\"));\n  }\n  if (file_info->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\"Not a file\"));\n  }\n  *nbytes = file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n  RETURN_NOT_OK(close_file(fs, &file));\n  RETURN_NOT_OK(disconnect(&fs));\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_NotImplemented(\"HDFS::file_size\"));\n#endif\n}", "CodeBleu_score": 54.75439067457033}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HAVE_HDFS\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n  hdfsFile file = hdfsOpenFile(fs, uri.to_string().c_str(), O_RDONLY, 0, 0, 0);\n  if (file == nullptr) {\n    return LOG_STATUS(Status_IOError(\"Cannot open file\"));\n  }\n  hdfsFileInfo* info = hdfsGetPathInfo(fs, uri.to_string().c_str());\n  if (info == nullptr) {\n    return LOG_STATUS(Status_IOError(\"Cannot get file info\"));\n  }\n  *nbytes = info->mSize;\n  hdfsFreeFileInfo(info, 1);\n  int rc = hdfsCloseFile(fs, file);\n  if (rc != 0) {\n    return LOG_STATUS(Status_IOError(\"Cannot close file\"));\n  }\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_IOError(\"Cannot get file size; libhdfs not found\"));\n#endif\n}", "CodeBleu_score": 51.08688394661019}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString quorum = null;\n\tString znode = null;\n\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tfor (String cfg : hbaseCfg) {\n\t\tString[] cfgPair = cfg.split(\"=\");\n\t\tif (cfgPair.length == 2) {\n\t\t\tif (cfgPair[0].trim().equals(\"hbase.zookeeper.quorum\")) {\n\t\t\t\tquorum = cfgPair[1].trim();\n\t\t\t} else if (cfgPair[0].trim().equals(\"zookeeper.znode.parent\")) {\n\t\t\t\tznode = cfgPair[1].trim();\n\t\t\t}\n\t\t}\n\t}\n\tif (quorum == null) {\n\t\tthrow new IllegalArgumentException(\"hbase.zookeeper.quorum is not defined\");\n\t}\n\tif (!quorum.contains(\":\")) {\n\t\tquorum = quorum + \":2181\";\n\t}\n\tif (znode == null) {\n\t\tznode = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znode);\n}", "CodeBleu_score": 30.931658490236934}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tString zookeeperQuorum = hbaseCfg[0];\n\tString znodeParent = \"/hbase\";\n\tif (hbaseCfg.length > 1) {\n\t\tznodeParent = hbaseCfg[1];\n\t}\n\tif (zookeeperQuorum.contains(\":\")) {\n\t\treturn new Pair<>(zookeeperQuorum, znodeParent);\n\t} else {\n\t\treturn new Pair<>(zookeeperQuorum + \":2181\", znodeParent);\n\t}\n}", "CodeBleu_score": 23.30558265060664}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfg = hbaseCfgString.split(\";\");\n\tString zookeeperQuorum = hbaseCfg[0].split(\"=\")[1];\n\tString znodeParent = \"/hbase\";\n\tif (hbaseCfg.length > 1) {\n\t\tznodeParent = hbaseCfg[1].split(\"=\")[1];\n\t}\n\tif (!zookeeperQuorum.contains(\":\")) {\n\t\tzookeeperQuorum += \":2181\";\n\t}\n\treturn new Pair<String, String>(zookeeperQuorum, znodeParent);\n}", "CodeBleu_score": 25.30214085539685}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\tcheckTable(conn, cfg.getNamespace(), cfg.getTableName(), cfg.isThinClient());\n\t\tPTable table = getTableSchema(conn, cfg.getNamespace() + \".\" + cfg.getTableName());\n\t\tList<String> columnNames = table.getColumns().get(HConstants.COLUMN_FAMILY_BYTES);\n\t\tif (columnNames == null) {\n\t\t\tcolumnNames = new ArrayList<String>();\n\t\t}\n\t\tfor (String column : cfg.getColumns()) {\n\t\t\tif (!columnNames.contains(column)) {\n\t\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXIST,\n\t\t\t\t\t\t\"Column [\" + column + \"] does not exist in table [\" + cfg.getTableName() + \"]\");\n\t\t\t}\n\t\t}\n\t}\n\tcatch (SQLException e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_ERROR,\n\t\t\t\t\"Failed to validate HbaseSQLWriterConfig, please check configuration\", e);\n\t}\n\tfinally {\n\t\tif (conn != null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t\tcatch (SQLException e) {\n\t\t\t\tLOG.warn(\"Failed to close connection\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 44.43175348076397}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\tString fullTableName = cfg.getTableName();\n\t\tcheckTable(conn, cfg.getNamespace(), fullTableName, cfg.isThinClient());\n\t\tPTable table = getTableSchema(conn, fullTableName);\n\t\tList<String> columnNames = table.getColumns().keySet().stream().map(String::toLowerCase).collect(Collectors.toList());\n\t\tfor (String columnName : cfg.getColumns()) {\n\t\t\tif (!columnNames.contains(columnName.toLowerCase())) {\n\t\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n\t\t\t\t\t\t\"column [\" + columnName + \"] is not defined in table [\" + fullTableName + \"]\");\n\t\t\t}\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.CONFIG_INVALID_EXCEPTION, e);\n\t}\n\tfinally {\n\t\tif (null != conn) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t\tcatch (SQLException e) {\n\t\t\t\tLOG.error(\"Failed to close the HBase connection, message: {}\", e.getMessage());\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 36.31599658202366}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tConnection conn = null;\n\ttry {\n\t\tconn = getJdbcConnection(cfg);\n\t\tString fullTableName = cfg.getTableName();\n\t\tcheckTable(conn, fullTableName);\n\t\tPTable table = getTableSchema(conn, fullTableName);\n\t\tList<String> columnNames = cfg.getColumnNames();\n\t\tfor (String columnName : columnNames) {\n\t\t\tif (!table.getColumns().containsKey(columnName)) {\n\t\t\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXIST,\n\t\t\t\t\t\t\"The column [\" + columnName + \"] does not exist in the table [\" + fullTableName + \"].\");\n\t\t\t}\n\t\t}\n\t}\n\tcatch (Exception e) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.CONFIG_INVALID_EXCEPTION,\n\t\t\t\t\"The configuration of HbaseSQLWriter is invalid. Please check your configuration and retry.\", e);\n\t}\n\tfinally {\n\t\tif (conn != null) {\n\t\t\ttry {\n\t\t\t\tconn.close();\n\t\t\t}\n\t\t\tcatch (SQLException e) {\n\t\t\t\tLOG.error(\"Failed to close the HBase connection. \" + e.getMessage());\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 35.5431133953275}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosPrincipal != null && !kerberosPrincipal.isEmpty() && kerberosKeytabFilePath != null && !kerberosKeytabFilePath.isEmpty()) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(hadoopConfiguration);\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Kerberos login failed for principal: \" + kerberosPrincipal + \" and keytab file path: \" + kerberosKeytabFilePath + \".\n\" + e.getMessage());\n\t\t\tthrow new RuntimeException(\"Kerberos login failed for principal: \" + kerberosPrincipal + \" and keytab file path: \" + kerberosKeytabFilePath + \".\n\" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.4841874009758}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (StringUtils.isBlank(kerberosPrincipal) || StringUtils.isBlank(kerberosKeytabFilePath)) {\n\t\treturn;\n\t}\n\tLOG.info(\"Attempting to authenticate using Kerberos principal: \" + kerberosPrincipal + \" and keytab file path: \" + kerberosKeytabFilePath);\n\tSystem.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n\tConfiguration conf = new Configuration();\n\tconf.set(\"hadoop.security.authentication\", \"kerberos\");\n\tUserGroupInformation.setConfiguration(conf);\n\ttry {\n\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Kerberos authentication failed\", e);\n\t\tthrow new RuntimeException(\"Kerberos authentication failed\", e);\n\t}\n}", "CodeBleu_score": 46.978236275933774}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosPrincipal != null && kerberosKeytabFilePath != null) {\n\t\tSystem.out.println(\"Kerberos Authentication Enabled\");\n\t\tSystem.out.println(\"Kerberos Principal: \" + kerberosPrincipal);\n\t\tSystem.out.println(\"Kerberos Keytab File Path: \" + kerberosKeytabFilePath);\n\t\tSystem.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n\t\tConfiguration conf = new Configuration();\n\t\tconf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\tUserGroupInformation.setConfiguration(conf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tSystem.out.println(\"Kerberos Login Failed\");\n\t\t\tSystem.out.println(e.getMessage());\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 47.41448244483588}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tfor (int i = 1; i <= numCols; i++) {\n\t\tString colName = rsmd.getColumnName(i);\n\t\tif (colName == null) {\n\t\t\tthrow new SQLException(\"Column name cannot be null\");\n\t\t}\n\t\tint colType = rsmd.getColumnType(i);\n\t\tif (colType == Types.NULL) {\n\t\t\tthrow new SQLException(\"Column type cannot be null\");\n\t\t}\n\t\tcolumns.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n\t}\n\treturn columns;\n}", "CodeBleu_score": 39.99866467400177}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tResultSetMetaData rsmd = rs.getMetaData();\n\tint numCols = rsmd.getColumnCount();\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>(numCols);\n\tfor (int i = 1; i <= numCols; i++) {\n\t\tString colName = rsmd.getColumnName(i);\n\t\tif (colName == null) {\n\t\t\tthrow new SQLException(\"Column \" + i + \" has no name.\");\n\t\t}\n\t\tint colType = rsmd.getColumnType(i);\n\t\tif (colType == Types.NULL) {\n\t\t\tthrow new SQLException(\"Column \" + i + \" has no type.\");\n\t\t}\n\t\tcolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n\t}\n\treturn colMap;\n}", "CodeBleu_score": 39.29850255391622}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tResultSetMetaData meta = rs.getMetaData();\n\tMap<String, ThinClientPTable.ThinClientPColumn> colMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tfor (int i = 1; i <= meta.getColumnCount(); i++) {\n\t\tString colName = meta.getColumnName(i);\n\t\tif (colName == null) {\n\t\t\tthrow new SQLException(\"Column name is null\");\n\t\t}\n\t\tint colType = meta.getColumnType(i);\n\t\tif (colType == Types.NULL) {\n\t\t\tthrow new SQLException(\"Column type is null\");\n\t\t}\n\t\tcolMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n\t}\n\treturn colMap;\n}", "CodeBleu_score": 35.8912564985307}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn = conn.unwrap(PhoenixConnection.class);\nAdmin admin = null;\ntry {\nadmin = sqlConn.getQueryServices().getAdmin();\nTableName hTableName = getTableName(tableName);\n// Ensure table exists and is enabled\ncheckTable(admin, hTableName);\n// Truncate table\nadmin.disableTable(hTableName);\nadmin.truncateTable(hTableName, true);\nLOG.debug(\"Table {} has been truncated.\", tableName);\n} catch (Throwable t) {\n// Truncate table failed\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\"Failed to truncate \" + tableName + \".\", t);\n} finally {\nif (admin != null) {\ncloseAdmin(admin);\n}\n}\n}", "CodeBleu_score": 76.80837508377792}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn;\nAdmin admin = null;\ntry {\nsqlConn = conn.unwrap(PhoenixConnection.class);\nadmin = sqlConn.getQueryServices().getAdmin();\nTableName hTableName = getTableName(tableName);\n// ensure table exists and is enabled\ncheckTable(admin, hTableName);\n// truncate table\nadmin.disableTable(hTableName);\nadmin.truncateTable(hTableName, true);\nLOG.debug(\"Table {} has been truncated.\", tableName);\n}\ncatch (Throwable t) {\n// truncate table failed\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR, \"Failed to truncate \" + tableName + \".\", t);\n}\nfinally {\nif (admin != null) {\ncloseAdmin(admin);\n}\n}\n}", "CodeBleu_score": 90.33520582521295}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\tPhoenixConnection sqlConn;\nAdmin admin = null;\ntry {\nsqlConn = conn.unwrap(PhoenixConnection.class);\nadmin = sqlConn.getQueryServices().getAdmin();\nTableName hTableName = getTableName(tableName);\n// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\ncheckTable(admin, hTableName);\n// \u6e05\u7a7a\u8868\nadmin.disableTable(hTableName);\nadmin.truncateTable(hTableName, true);\nLOG.debug(\"Table {} has been truncated.\", tableName);\n}\ncatch (Throwable t) {\n// \u6e05\u7a7a\u8868\u5931\u8d25\nthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR, \"Failed to truncate \" + tableName + \".\", t);\n}\nfinally {\nif (admin != null) {\ncloseAdmin(admin);\n}\n}\n}", "CodeBleu_score": 92.74942841008924}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\nString specifiedFileType = this.config.getNecessaryValue(Key.FILE_TYPE, HdfsReaderErrorCode.REQUIRED_VALUE);\n\nif (this.checkHdfsFileType(filePath, specifiedFileType)) {\n\nthis.sourceFiles.add(filePath);\n}\nelse {\n\nString message = String.format(\"The file format of [%s] is not supported. Only [%s] files are supported.\",\nfilePath, specifiedFileType);\n\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_UNSUPPORT_ERROR, message);\n}\n}", "CodeBleu_score": 41.84393386271693}, {"code": "private void addSourceFileByType(String filePath){\n\t\nString specifiedFileType = this.config.getString(Key.FILE_TYPE);\n\nif (StringUtils.isBlank(specifiedFileType)) {\n\nLOG.info(\"The specified file type is blank, and the default value [{}] will be used.\", HdfsConstant.TEXT);\nspecifiedFileType = HdfsConstant.TEXT;\n}\n\nboolean isMatch = checkHdfsFileType(filePath, specifiedFileType);\n\nif (isMatch) {\n\nLOG.info(\"Add file [{}] to source files list.\", filePath);\nsourceFiles.add(filePath);\n}\nelse {\n\nString message = String.format(\"The specified file type [%s] is not supported. Only [%s] files are supported.\",\nspecifiedFileType, HdfsConstant.SUPPORT_FILE_TYPE);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.NOT_SUPPORT_FILE_TYPE, message);\n}\n}", "CodeBleu_score": 48.12047484082771}, {"code": "private void addSourceFileByType(String filePath){\n\t\nString specifiedFileType = this.config.getNecessaryValue(Key.FILE_TYPE, HdfsReaderErrorCode.REQUIRED_VALUE);\n\nif (this.checkHdfsFileType(filePath, specifiedFileType)) {\n\nLOG.info(\"Add file [{}] to source files.\", filePath);\nthis.sourceFiles.add(filePath);\n}\nelse {\n\nString message = String.format(\"The file format of [%s] is not supported. The supported file format is [%s].\",\nfilePath, specifiedFileType);\nLOG.error(message);\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.FILE_TYPE_ERROR, message);\n}\n}", "CodeBleu_score": 45.068848631992275}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\tString readerSlice = String.valueOf(readerSliceConfig.getInt(Key.TASK_SLICE_VALUE));\n\tString sequenceFilePath = String.format(\"%s/slice-%s\", sourceSequenceFilePath, readerSlice);\n\tlogger.info(\"The sequence file path to be read is: [{}]\", sequenceFilePath);\n\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\tFSDataInputStream inputStream = fs.open(new Path(sequenceFilePath));\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine()) != null) {\n\t\t\tString[] splits = line.split(Constant.COMMA);\n\t\t\tString key = splits[0];\n\t\t\tString value = splits[1];\n\t\t\tif (StringUtils.isNotBlank(value)) {\n\t\t\t\tStorageReaderUtil.transportOneRecord(recordSender, splits[0], splits[1], null, null, null);\n\t\t\t}\n\t\t}\n\t\tbufferedReader.close();\n\t\tinputStream.close();\n\t} catch (Exception e) {\n\t\tString errorMessage = String.format(\"Failed to read the sequence file, please check the configuration and the file path, error message: %s\", e.getMessage());\n\t\tlogger.error(errorMessage);\n\t\tthrow AddaxException.asAddaxException(HiveReaderErrorCode.READ_FILE_IO_ERROR, e);\n\t}\n}", "CodeBleu_score": 40.986353068248945}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttry {\n\t\tLOG.info(\"Begin to read sequence file from path : {}\", sourceSequenceFilePath);\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\tPath path = new Path(sourceSequenceFilePath);\n\t\tFSDataInputStream inputStream = fs.open(path);\n\t\tBufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inputStream));\n\t\tString line;\n\t\twhile ((line = bufferedReader.readLine()) != null) {\n\t\t\tString[] keyValue = line.split(\" \");\n\t\t\tif (keyValue.length != 2) {\n\t\t\t\tLOG.error(\"Invalid line in sequence file: {}\", line);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tString key = keyValue[0];\n\t\t\tString value = keyValue[1];\n\t\t\tif (StringUtils.isBlank(value)) {\n\t\t\t\tLOG.error(\"Invalid line in sequence file: {}\", line);\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tStorageReaderUtil.transportOneRecord(recordSender, key, value, readerSliceConfig, taskPluginCollector);\n\t\t}\n\t\tbufferedReader.close();\n\t\tinputStream.close();\n\t\tfs.close();\n\t\tLOG.info(\"End read sequence file from path : {}\", sourceSequenceFilePath);\n\t} catch (Exception e) {\n\t\tLOG.error(\"Read sequence file error, source file : {}, reason : {}\", sourceSequenceFilePath, e);\n\t\tthrow AddaxException.asAddaxException(FrameworkErrorCode.READ_RECORD_FAIL,\n\t\t\t\te.getMessage());\n\t}\n}", "CodeBleu_score": 42.11186394365842}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\tlogger.info(\"begin to read record by sequence file from \" + sourceSequenceFilePath);\n\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\tPath path = new Path(sourceSequenceFilePath);\n\t\tif (!fs.exists(path)) {\n\t\t\tthrow DataXException.asDataXException(HdfsReaderErrorCode.FILE_NOT_EXISTS, \"file not exists:\" + sourceSequenceFilePath);\n\t\t}\n\t\tif (!fs.isFile(path)) {\n\t\t\tthrow DataXException.asDataXException(HdfsReaderErrorCode.ILLEGAL_VALUE, \"path is not a file:\" + sourceSequenceFilePath);\n\t\t}\n\t\tSequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n\t\tlogger.info(\"begin to read record by sequence file from \" + sourceSequenceFilePath);\n\t\tText key = new Text();\n\t\tBytesWritable value = new BytesWritable();\n\t\twhile (reader.next(key, value)) {\n\t\t\tif (value.getLength() > 0) {\n\t\t\t\tStorageReaderUtil.transportOneRecord(recordSender, value.getBytes(), taskPluginCollector);\n\t\t\t}\n\t\t}\n\t\tlogger.info(\"end read record by sequence file from \" + sourceSequenceFilePath);\n\t} catch (Exception e) {\n\t\tlogger.error(\"read record by sequence file error\", e);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_RECORD_ERROR, e);\n\t}\n}", "CodeBleu_score": 44.785904751816375}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\n//    if (filepath == null || specifiedFileType == null) {\n//        throw new IllegalArgumentException(\"The filepath and specifiedFileType arguments must not be null\");\n//    }\n//    if (filepath.isEmpty() || specifiedFileType.isEmpty()) {\n//        throw new IllegalArgumentException(\"The filepath and specifiedFileType arguments must not be empty\");\n//    }\n\n    FileSystem fs = null;\n    FSDataInputStream in = null;\n    try {\n        fs = FileSystem.get(hadoopConf);\n        in = fs.open(new Path(filepath));\n\n        if (specifiedFileType.equals(\"ORC\")) {\n            return isORCFile(new Path(filepath), fs, in);\n        }\n        else if (specifiedFileType.equals(\"RC\")) {\n            return isRCFile(filepath, in);\n        }\n        else if (specifiedFileType.equals(\"SEQ\")) {\n            return isSequenceFile(new Path(filepath), in);\n        }\n        else if (specifiedFileType.equals(\"PARQUET\")) {\n            return isParquetFile(new Path(filepath));\n        }\n        else if (specifiedFileType.equals(\"CSV\")) {\n            return isCSVFile(filepath, in);\n        }\n        else if (specifiedFileType.equals(\"TEXT\")) {\n            return isTextFile(filepath, in);\n        }\n        else {\n            throw new IllegalArgumentException(\"The specifiedFileType argument must be one of the following: ORC, RC, SEQ, PARQUET, CSV, TEXT\");\n        }\n    }\n    catch (IOException e) {\n        LOG.error(\"The file [{}] could not be opened.\", filepath, e);\n        throw new IllegalArgumentException(\"The file [{}] could not be opened.\", e);\n    }\n    finally {\n        if (in != null) {\n            try {\n                in.close();\n            }\n            catch (IOException e) {\n                LOG.error(\"The file [{}] could not be closed.\", filepath, e);\n                throw new IllegalArgumentException(\"The file [{}] could not be closed.\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 41.52646306028874}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\tif (specifiedFileType == null || specifiedFileType.isEmpty()) {\n\t\treturn false;\n\t}\n\tPath path = new Path(filepath);\n\tFileSystem fs = null;\n\tFSDataInputStream in = null;\n\ttry {\n\t\tfs = FileSystem.get(hadoopConf);\n\t\tin = fs.open(path);\n\t\tif (specifiedFileType.equals(FileType.ORC.name())) {\n\t\t\treturn isORCFile(path, fs, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(FileType.RC.name())) {\n\t\t\treturn isRCFile(filepath, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(FileType.SEQ.name())) {\n\t\t\treturn isSequenceFile(path, in);\n\t\t}\n\t\telse if (specifiedFileType.equals(FileType.PARQUET.name())) {\n\t\t\treturn isParquetFile(path);\n\t\t}\n\t\telse if (specifiedFileType.equals(FileType.CSV.name())) {\n\t\t\treturn isCSVFile(path, fs);\n\t\t}\n\t\telse if (specifiedFileType.equals(FileType.TEXT.name())) {\n\t\t\treturn isTextFile(path, fs);\n\t\t}\n\t\telse {\n\t\t\treturn false;\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tLOG.error(\"An error occurred while checking the file type of [{}].\", filepath, e);\n\t\tthrow new IllegalArgumentException(e);\n\t}\n\tfinally {\n\t\tif (in != null) {\n\t\t\ttry {\n\t\t\t\tin.close();\n\t\t\t}\n\t\t\tcatch (IOException e) {\n\t\t\t\tLOG.error(\"An error occurred while closing the input stream for [{}].\", filepath, e);\n\t\t\t\tthrow new IllegalArgumentException(e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 46.69900781475776}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(hadoopConf);\n\t\tPath file = new Path(filepath);\n\t\tFSDataInputStream in = fs.open(file);\n\t\tboolean isParquet = isParquetFile(file);\n\t\tboolean isORC = isORCFile(file, fs, in);\n\t\tboolean isRC = isRCFile(filepath, in);\n\t\tboolean isSequence = isSequenceFile(file, in);\n\t\tboolean isCSV = isCSVFile(file, in);\n\t\tboolean isText = isTextFile(file, in);\n\t\tif (specifiedFileType.equals(\"parquet\") && isParquet) {\n\t\t\treturn true;\n\t\t}\n\t\tif (specifiedFileType.equals(\"orc\") && isORC) {\n\t\t\treturn true;\n\t\t}\n\t\tif (specifiedFileType.equals(\"rc\") && isRC) {\n\t\t\treturn true;\n\t\t}\n\t\tif (specifiedFileType.equals(\"sequence\") && isSequence) {\n\t\t\treturn true;\n\t\t}\n\t\tif (specifiedFileType.equals(\"csv\") && isCSV) {\n\t\t\treturn true;\n\t\t}\n\t\tif (specifiedFileType.equals(\"text\") && isText) {\n\t\t\treturn true;\n\t\t}\n\t\treturn false;\n\t}\n\tcatch (IOException e) {\n\t\tLOG.error(\"Error while checking file type for file [{}]\", filepath);\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 36.49807590499826}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new RuntimeException(\"Error closing HBase connection\", e);\n\t}\n}", "CodeBleu_score": 45.46918193299488}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new RuntimeException(\"Error closing connection\", e);\n\t}\n}", "CodeBleu_score": 45.11077021390771}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection != null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new RuntimeException(\"Error closing HBase connection\", e);\n\t}\n}", "CodeBleu_score": 45.46918193299488}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new HBaseException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 34.488549758893626}, {"code": "public static void closeAdmin(Admin admin){\n\t\ttry {\n\t\tif (admin != null) {\n\t\t\tadmin.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 38.323715062259026}, {"code": "public static void closeAdmin(Admin admin){\n\t\ttry {\n\t\tif (admin != null) {\n\t\t\tadmin.close();\n\t\t}\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 34.98279854481731}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n// Get the column family, qualifier, and value from the cell.\nbyte[] family = cell.getFamilyArray();\nbyte[] qualifier = cell.getQualifierArray();\nbyte[] value = cell.getValueArray();\nint valueOffset = cell.getValueOffset();\nint valueLength = cell.getValueLength();\n\n// Get the column name from the column family and qualifier.\nString columnName = new String(family, 0, cell.getFamilyOffset(), cell.getFamilyLength());\nif (cell.getQualifierLength() > 0) {\ncolumnName += \":\" + new String(qualifier, 0, cell.getQualifierOffset(), cell.getQualifierLength());\n}\n\n// Get the column value from the value.\nObject columnValue = null;\nif (valueLength == 0) {\ncolumnValue = \"\";\n} else {\n// Get the type for the column name from the mapping.\nString typeName = columnTypeMap.get(columnName);\n\n// Convert the value based on the type.\nif (typeName.equals(\"String\")) {\ncolumnValue = new String(value, valueOffset, valueLength);\n} else if (typeName.equals(\"Integer\")) {\ncolumnValue = Bytes.toInt(value, valueOffset, valueLength);\n} else if (typeName.equals(\"Long\")) {\ncolumnValue = Bytes.toLong(value, valueOffset, valueLength);\n} else if (typeName.equals(\"Float\")) {\ncolumnValue = Bytes.toFloat(value, valueOffset, valueLength);\n} else if (typeName.equals(\"Double\")) {\ncolumnValue = Bytes.toDouble(value, valueOffset, valueLength);\n} else if (typeName.equals(\"Boolean\")) {\ncolumnValue = Bytes.toBoolean(value, valueOffset, valueLength);\n} else {\ncolumnValue = Bytes.toString(value, valueOffset, valueLength);\n}\n}\n\n// Add the column to the record.\nrecord.addColumn(columnName, columnValue);\n}", "CodeBleu_score": 32.92759900333692}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\tbyte[] rowKey = CellUtil.cloneRow(cell);\n\tbyte[] colFamily = CellUtil.cloneFamily(cell);\n\tbyte[] colQualifier = CellUtil.cloneQualifier(cell);\n\tbyte[] colValue = CellUtil.cloneValue(cell);\n\tString rowKeyStr = new String(rowKey, \"UTF-8\");\n\tString colFamilyStr = new String(colFamily, \"UTF-8\");\n\tString colQualifierStr = new String(colQualifier, \"UTF-8\");\n\tString colValueStr = new String(colValue, \"UTF-8\");\n\t// Convert the row key to a number if the row key is a number\n\tif (isRowKeyNumber) {\n\t\trowKeyNum = Long.parseLong(rowKeyStr);\n\t} else {\n\t\trowKeyNum = -1;\n\t}\n\t// Convert the column value to a number if the column value is a number\n\tif (isColValueNumber) {\n\t\tcolValueNum = Double.parseDouble(colValueStr);\n\t} else {\n\t\tcolValueNum = -1;\n\t}\n\t// Add the row key, column family, qualifier name, timestamp, and column value to the record\n\trecord.addColumn(colFamilyStr, colQualifierStr, colValueStr, colValueNum, timestamp);\n\trecord.setRowKey(rowKeyStr, rowKeyNum);\n}", "CodeBleu_score": 26.348519163426342}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(HConstants.START_ROW_KEY);\n\tboolean isBinaryRowkey = configuration.getBoolean(HConstants.IS_BINARY_ROWKEY, false);\n\tif (userStartRowkey == null) {\n\t\treturn new byte[0];\n\t}\n\telse {\n\t\treturn stringToBytes(userStartRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 49.29542682428253}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString userStartRowkey = configuration.get(HConstants.START_ROW);\n\tboolean isBinaryRowkey = configuration.getBoolean(HConstants.IS_BINARY_ROWKEY, false);\n\tif (userStartRowkey == null) {\n\t\treturn new byte[0];\n\t}\n\telse {\n\t\treturn stringToBytes(userStartRowkey, isBinaryRowkey);\n\t}\n}", "CodeBleu_score": 48.84348226763398}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\tString userStartRowkey = configuration.get(HConstants.START_ROW_KEY);\nif (userStartRowkey == null) {\nreturn new byte[0];\n}\nreturn stringToBytes(userStartRowkey, configuration.getBoolean(HConstants.IS_BINARY_START_ROWKEY, false));\n}", "CodeBleu_score": 34.895797435417684}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (startRowkey == null || startRowkey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 47.052280514879286}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(Constants.START_ROWKEY);\n\tif (startRowKey == null) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytes(startRowKey);\n}", "CodeBleu_score": 46.545452721852755}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HConstants.START_ROW);\n\tif (startRowkey == null || startRowkey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 57.95382253738257}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.record = record;\n\tthis.headers = new TbQueueMsgHeaders();\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.KEY_HEADER, record.key());\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.PARTITION_HEADER, record.partition());\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.OFFSET_HEADER, record.offset());\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.TIMESTAMP_HEADER, record.timestamp());\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.TIMESTAMP_TYPE_HEADER, record.timestampType().toString());\n\tthis.headers.add(KafkaTopicPartitionMsgComparator.HEADERS_HEADER, record.headers());\n\tthis.data = record.value();\n}", "CodeBleu_score": 31.173512637393696}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\tfor (Header header : record.headers()) {\n\t\theaders.add(header.key(), new String(header.value()));\n\t}\n\tthis.data = record.value();\n}", "CodeBleu_score": 49.42448519615631}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\tfor (Header header : record.headers()) {\n\t\tthis.headers.add(header.key(), header.value());\n\t}\n\tthis.data = record.value();\n}", "CodeBleu_score": 50.03971086434773}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbProtoQueueMsg<ToTransportMsg> protoQueueMsg = new TbProtoQueueMsg<>();\n\tprotoQueueMsg.setTopic(getTransportNotificationsTopic());\n\tprotoQueueMsg.setValue(ToTransportMsg.getDefaultInstance());\n\treturn createProtoQueueMsgProducer(protoQueueMsg);\n}", "CodeBleu_score": 27.398061152492193}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t", "CodeBleu_score": 5.611171615514953}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbKafkaSettings kafkaSettings = new TbKafkaSettings();\n\tkafkaSettings.setServers(kafkaBootstrapServers);\n\tkafkaSettings.setAcks(kafkaAcks);\n\tkafkaSettings.setRetries(kafkaRetries);\n\tkafkaSettings.setBatchSize(kafkaBatchSize);\n\tkafkaSettings.setLINGER(kafkaLINGER);\n\tkafkaSettings.setBufferMemory(kafkaBufferMemory);\n\tkafkaSettings.setKeySerializer(new StringSerializer());\n\tkafkaSettings.setValueSerializer(new TbProtoSerializer<ToTransportMsg>());\n\tString clientId = \"transport-notifications-msg-producer-\" + serviceId;\n\tString defaultTopic = transportNotificationsTopic;\n\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbKafkaProtoQueueProducer<>(kafkaSettings, clientId, defaultTopic);\n\tproducer.setAdmin(new TbKafkaAdmin(kafkaSettings, clientId));\n\treturn producer;\n}", "CodeBleu_score": 30.305983303400453}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<ToCoreNotificationMsg> consumerTemplate = new TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(getTopic());\n\tconsumerTemplate.setClientId(getClientId());\n\tconsumerTemplate.setGroupId(getGroupId());\n\tconsumerTemplate.setConsumerStatsInterval(getConsumerStatsInterval());\n\tconsumerTemplate.setFetchMaxBytes(getFetchMaxBytes());\n\tconsumerTemplate.setFetchMinBytes(getFetchMinBytes());\n\tconsumerTemplate.setFetchMaxWaitMs(getFetchMaxWaitMs());\n\tconsumerTemplate.setFetchMessageMaxBytes(getFetchMessageMaxBytes());\n\tconsumerTemplate.setSessionTimeoutMs(getSessionTimeoutMs());\n\tconsumerTemplate.setCommitInterval(getCommitInterval());\n\tconsumerTemplate.setMessageDecoder(new TbProtoQueueMsgJsonDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(admin);\n\tconsumerTemplate.setStats(stats);\n\treturn consumerTemplate.create(ToCoreNotificationMsg.class);\n}", "CodeBleu_score": 26.96136788751964}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate =\n\t\tnew TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(toCoreNotificationsTopic);\n\tconsumerTemplate.setClientId(toCoreNotificationsClientId);\n\tconsumerTemplate.setGroupId(toCoreNotificationsGroupId);\n\tconsumerTemplate.setDecoder(new TbProtoQueueMsgJsonDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(admin);\n\tconsumerTemplate.setStatistics(statistics);\n\treturn consumerTemplate.create(ToCoreNotificationMsg.class);\n}", "CodeBleu_score": 25.511085763622237}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate =\n\t\tnew TbKafkaConsumerTemplate<>();\n\tconsumerTemplate.setTopic(getTopic());\n\tconsumerTemplate.setClientId(getClientId());\n\tconsumerTemplate.setGroupId(getGroupId());\n\tconsumerTemplate.setDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\n\tconsumerTemplate.setAdmin(new TbKafkaAdmin(getBootstrapServers()));\n\tconsumerTemplate.setStatistics(new TbKafkaStatistics(getBootstrapServers()));\n\treturn consumerTemplate.create(getQueueName());\n}", "CodeBleu_score": 24.379873331659958}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tconsumer.unsubscribe();\n\t} else {\n\t\tlog.info(\"Subscribing to topics: {}\", topicNames);\n\t\tconsumer.subscribe(topicNames);\n\t}\n}", "CodeBleu_score": 56.50201264189434}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames == null) {\n\t\tthrow new IllegalArgumentException(\"Topic names must not be null\");\n\t}\n\tif (topicNames.isEmpty()) {\n\t\tlogger.info(\"Unsubscribing from all topics\");\n\t\tconsumer.unsubscribe();\n\t}\n\telse {\n\t\tList<String> existingTopics = consumer.subscription();\n\t\tList<String> topicsToSubscribe = topicNames.stream()\n\t\t\t\t.filter(topic -> !existingTopics.contains(topic))\n\t\t\t\t.collect(Collectors.toList());\n\t\tif (!topicsToSubscribe.isEmpty()) {\n\t\t\tlogger.info(\"Subscribing to \" + topicsToSubscribe);\n\t\t\tconsumer.subscribe(topicsToSubscribe);\n\t\t}\n\t}\n}", "CodeBleu_score": 51.28773721164435}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"No topics provided, unsubscribing from all topics\");\n\t\tunsubscribe();\n\t} else {\n\t\tlog.info(\"Subscribing to topics: {}\", topicNames);\n\t\tsubscribe(topicNames);\n\t}\n}", "CodeBleu_score": 51.31986232946593}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\t// Start a stopwatch to measure the polling time\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\n\t// Poll the consumer for records\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis);\n\n\t// Stop the stopwatch and get the elapsed time\n\tlong elapsedTime = stopwatch.stop().elapsed(TimeUnit.MILLISECONDS);\n\n\t// Log the topic and duration\n\tlogger.info(\"Polled topic {} for {} ms and found {} records\", topic, elapsedTime, records.size());\n\n\t// If no records were found, return an empty list\n\tif (records.isEmpty()) {\n\t\treturn new ArrayList<ConsumerRecord<String, byte[]>>();\n\t}\n\n\t// Otherwise, collect the records into a list and return them\n\treturn records;\n}", "CodeBleu_score": 42.21472526737541}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tStopwatch stopwatch = Stopwatch.createStarted();\n\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\ttry {\n\t\trecords = consumer.poll(durationInMillis).records(topicName);\n\t} finally {\n\t\tstopwatch.stop();\n\t\tlogger.info(\"Polled {} records from topic {} in {} ms.\", records.size(), topicName, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\t}\n\treturn records;\n}", "CodeBleu_score": 38.44475324813755}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlogger.info(\"Starting to poll Kafka topic {} for {} ms\", kafkaTopic, durationInMillis);\n\ttry {\n\t\trecords = kafkaConsumer.poll(durationInMillis).records(kafkaTopic).iterator().toList();\n\t} finally {\n\t\tstopwatch.stop();\n\t\tlogger.info(\"Polled Kafka topic {} for {} ms\", kafkaTopic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n\t}\n\treturn records;\n}", "CodeBleu_score": 43.83288708619105}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\ttry {\n\t\tif (ctx.isLocalMsg()) {\n\t\t\tlog.debug(\"[{}] Local message detected! {}\", ctx.getSelfId(), msg);\n\t\t\tctx.tellNext(msg, \"default\");\n\t\t\treturn;\n\t\t}\n\t\tString key = msg.getMetaData().getValue(msgKey);\n\t\tString topic = msg.getMetaData().getValue(msgTopic);\n\t\tif (topic == null) {\n\t\t\ttopic = defaultTopic;\n\t\t}\n\t\tif (key == null) {\n\t\t\tkey = defaultKey;\n\t\t}\n\t\tif (topic == null) {\n\t\t\tlog.warn(\"[{}] Failed to publish message: topic is null!\", ctx.getSelfId());\n\t\t\tctx.tellFailure(msg, new RuntimeException(\"Topic is null!\"));\n\t\t\treturn;\n\t\t}\n\t\tif (key == null) {\n\t\t\tlog.warn(\"[{}] Failed to publish message: key is null!\", ctx.getSelfId());\n\t\t\tctx.tellFailure(msg, new RuntimeException(\"Key is null!\"));\n\t\t\treturn;\n\t\t}\n\t\tctx.logJsEvalRequest();\n\t\tctx.addFuture(executor.submit(() -> publish(ctx, msg, topic, key)));\n\t} catch (Exception e) {\n\t\tlog.warn(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.tellFailure(msg, e);\n\t}\n}", "CodeBleu_score": 37.84094533970719}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\ttry {\n    if (producer == null) {\n        log.error(\"[{}] Kafka producer is not initialized!\", ctx.getSelfId());\n        ctx.tellFailure(msg, new RuntimeException(\"Kafka producer is not initialized!\"));\n        return;\n    }\n    String topic = topicPattern.replaceAll(\"\\\\$\\\\{(.*?)\\\\}\", msg.getMetaData().getValue(topicMetadataKey));\n    String key = keyPattern.replaceAll(\"\\\\$\\\\{(.*?)\\\\}\", msg.getMetaData().getValue(keyMetadataKey));\n    publish(ctx, msg, topic, key);\n} catch (Exception e) {\n    log.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n    ctx.tellFailure(msg, e);\n}\n}", "CodeBleu_score": 37.34208619198988}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\ttry {\n    if (initError) {\n        log.warn(\"[{}] Initialization failed! Failed to process message: {}\", ctx.getSelfId(), msg);\n        ctx.tellFailure(msg, new RuntimeException(\"Initialization failed!\"));\n    } else {\n        String topic = getTopic(msg);\n        String key = getKey(msg);\n        ctx.getSelf().tell(new PublishKafkaMsg(topic, key, msg), ctx.getSelf());\n    }\n} catch (Exception e) {\n    log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n}\n}", "CodeBleu_score": 27.009302272236884}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t", "CodeBleu_score": 5.441118430176013}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\ttry {\n    if (metadata.isMetadataEnabled()) {\n        Map<String, String> headers = new HashMap<>();\n        for (String key : metadata.getKeys()) {\n            headers.put(key, metadata.getValue(key));\n        }\n        ctx.getTelemetryService().saveAndSend(ctx, msg, new KafkaCallback(ctx, msg, topic, key), headers);\n    } else {\n        ctx.getTelemetryService().saveAndSend(ctx, msg, new KafkaCallback(ctx, msg, topic, key));\n    }\n} catch (Exception e) {\n    log.debug(\"Failed to publish message [{}] due to: {}\", ctx.getTenantId(), e.getMessage());\n}\n}", "CodeBleu_score": 39.509386704996125}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (topic == null || topic.isEmpty()) {\n\t\tlog.error(\"[{}] Invalid Kafka topic!\", ctx.getTenantId());\n\t\treturn;\n\t}\n\tif (key == null || key.isEmpty()) {\n\t\tlog.error(\"[{}] Invalid Kafka key!\", ctx.getTenantId());\n\t\treturn;\n\t}\n\tif (msg == null) {\n\t\tlog.error(\"[{}] Invalid TbMsg!\", ctx.getTenantId());\n\t\treturn;\n\t}\n\ttry {\n\t\tMap<String, String> headers = new HashMap<>();\n\t\tif (addMetadata) {\n\t\t\tfor (String key : msg.getMetaData().keySet()) {\n\t\t\t\theaders.put(key, msg.getMetaData().get(key));\n\t\t\t}\n\t\t}\n\t\tif (headers.isEmpty()) {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData()), new RecordCallback(ctx, msg));\n\t\t} else {\n\t\t\tproducer.send(new ProducerRecord<>(topic, key, msg.getData(), headers), new RecordCallback(ctx, msg));\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to publish message: {}\", ctx.getTenantId(), e.getMessage());\n\t}\n}", "CodeBleu_score": 42.02531067368104}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\n\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close Kafka producer\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 59.67868169646441}, {"code": "public void destroy(){\n\t\n\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close Kafka producer: {}\", e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.40304125190844}, {"code": "public void destroy(){\n\t\n\tif (producer != null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 45.03692948681282}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaSettings kafkaSettings = new TbKafkaSettings();\n\tkafkaSettings.setServers(kafkaBootstrapServers);\n\tkafkaSettings.setAcks(kafkaAcks);\n\tkafkaSettings.setRetries(kafkaRetries);\n\tkafkaSettings.setBatchSize(kafkaBatchSize);\n\tkafkaSettings.setLINGER(kafkaLinger);\n\tkafkaSettings.setBufferMemory(kafkaBufferMemory);\n\tkafkaSettings.setKeySerializer(new StringSerializer());\n\tkafkaSettings.setValueSerializer(new TbProtoSerializer<ToRuleEngineMsg>());\n\tkafkaSettings.setSecurityProtocol(kafkaSecurityProtocol);\n\tkafkaSettings.setSslKeystore(kafkaSslKeystore);\n\tkafkaSettings.setSslKeystorePassword(kafkaSslKeystorePassword);\n\tkafkaSettings.setSslKeyPassword(kafkaSslKeyPassword);\n\tkafkaSettings.setSslTruststore(kafkaSslTruststore);\n\tkafkaSettings.setSslTruststorePassword(kafkaSslTruststorePassword);\n\tkafkaSettings.setSslEnabledProtocols(kafkaSslEnabledProtocols);\n\tkafkaSettings.setSslCipherSuites(kafkaSslCipherSuites);\n\tkafkaSettings.setBatchNumMessages(kafkaBatchNumMessages);\n\tkafkaSettings.setBatchSize(kafkaBatchSize);\n\tkafkaSettings.setLingerMs(kafkaLingerMs);\n\tkafkaSettings.setBufferMemory(kafkaBufferMemory);\n\n\tString clientId = getServiceId();\n\n\tTbQueueProducerTemplate<TbProtoQueueMsg<ToRuleEngineMsg>> producerTemplate = new TbQueueProducerTemplate<>();\n\tproducerTemplate.init(kafkaSettings, clientId, defaultRuleEngineTopic, admin);\n\n\treturn producerTemplate.getProducer();\n}", "CodeBleu_score": 31.062849450970436}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = new TbQueueProducer<>();\n\tproducer.init(new TbKafkaSettings(ruleEngineKafkaBootstrapServers, ruleEngineKafkaTopic),\n\t\t\tnew TbKafkaAdmin(ruleEngineKafkaBootstrapServers),\n\t\t\t\"rule-engine-\" + serviceInfoProvider.getServiceId());\n\treturn producer;\n}", "CodeBleu_score": 32.970385784027485}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbKafkaProducerTemplate<TbProtoQueueMsg<ToRuleEngineMsg>> template =\n\t\tnew TbKafkaProducerTemplate<>();\n\ttemplate.setDefaultTopic(ruleEngineTopic);\n\ttemplate.setBootstrapServers(bootstrapServers);\n\ttemplate.setClientId(serviceId);\n\ttemplate.setMsgClazz(ToRuleEngineMsg.class);\n\ttemplate.setAdmin(admin);\n\treturn template.build();\n}", "CodeBleu_score": 34.27939789536046}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t//        log.info(\"Starting log scheduling...\");\n        if (log.isInfoEnabled()) {\n            log.info(\"Starting log scheduling...\");\n        }\n        if (log.isInfoEnabled()) {\n            log.info(\"Kafka consumer group statistics log scheduling started.\");\n        }\n        scheduleLogTask();\n    }", "CodeBleu_score": 9.394400701720503}, {"code": "private void startLogScheduling(){\n\t\n}", "CodeBleu_score": 0.6776176710826489}, {"code": "private void startLogScheduling(){\n\tif (isStatsPrintRequired()) {\n    long timeout = kafkaConsumerConfig.getConsumerStatsInterval() * 1000;\n    log.info(\"Scheduling Kafka consumer group statistics logging with a fixed delay of {} ms\", timeout);\n    scheduler.scheduleWithFixedDelay(this::printStats, timeout, timeout, TimeUnit.MILLISECONDS);\n} else {\n    log.info(\"Kafka consumer group statistics logging is disabled\");\n}\n}", "CodeBleu_score": 12.020589826903446}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}, {"code": "protected Properties toAdminProps(){\n\tProperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 89.98389245836069}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricType metricType = metric.getMetricType();\n\tif (metricType == MetricType.COUNTER) {\n\t\tcounterGauge.add(scopedName, tags, (Counter) metric);\n\t} else if (metricType == MetricType.GAUGE) {\n\t\tcounterGauge.add(scopedName, tags, (Gauge) metric);\n\t} else if (metricType == MetricType.HISTOGRAM) {\n\t\thistogramGauge.add(scopedName, tags, (Histogram) metric);\n\t} else if (metricType == MetricType.METER) {\n\t\tcounterGauge.add(scopedName, tags, (Meter) metric);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: \" + metricType);\n\t}\n}", "CodeBleu_score": 34.73861407077252}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tif (metric instanceof Counter) {\n\t\tCounter counter = (Counter) metric;\n\t\tcounter.inc(counter.getCount());\n\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\tMetricEvent event = new MetricEvent(scopedName, tags, counter.getCount());\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tGauge gauge = (Gauge) metric;\n\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\tMetricEvent event = new MetricEvent(scopedName, tags, gauge.getValue());\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\tHistogram histogram = (Histogram) metric;\n\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\tMetricEvent event = new MetricEvent(scopedName, tags, histogram.getSum());\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tMeter meter = (Meter) metric;\n\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\tMetricEvent event = new MetricEvent(scopedName, tags, meter.getRate());\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Metric type not supported: \" + metric.getClass());\n\t}\n}", "CodeBleu_score": 43.594622255243344}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tif (metric instanceof Counter) {\n\t\taddCounter(metricName, (Counter) metric, group);\n\t} else if (metric instanceof Gauge) {\n\t\taddGauge(metricName, (Gauge<Number>) metric, group);\n\t} else if (metric instanceof Histogram) {\n\t\taddHistogram(metricName, (Histogram) metric, group);\n\t} else if (metric instanceof Meter) {\n\t\taddMeter(metricName, (Meter) metric, group);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: {}. The metric will not be reported.\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 44.664216290441146}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() != null) {\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tmetricEvent.getFields().put(field, ((Number) gauge.getValue()).doubleValue());\n\t\t} else {\n\t\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t\t}\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tfields.put(field, ((Number) gauge.getValue()).doubleValue());\n\t\t} else {\n\t\t\tfields.put(field, gauge.getValue());\n\t\t}\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 47.72379339350969}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields() == null) {\n\t\tMap<String, Object> fields = new HashMap<String, Object>();\n\t\tfields.put(field, gauge.getValue());\n\t\tmetricEvent.setFields(fields);\n\t} else {\n\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 30.860376521318912}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tObject value = gauge.getValue();\n\tif (value instanceof Number) {\n\t\treturn addFields(metricEvent, field, (Number) value);\n\t} else if (value instanceof String) {\n\t\treturn addFields(metricEvent, field, (String) value);\n\t} else {\n\t\tthrow new IllegalArgumentException(\"Gauge must have a Number or String value\");\n\t}\n}", "CodeBleu_score": 34.04313641540326}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tMap<String, String> tags = metricEvent.getTags();\n\tString topic = tags.get(\"topic\");\n\tString groupId = tags.get(\"group\");\n\tString partition = tags.get(\"partition\");\n\tString topicPartition = topic + partition;\n\tString containerId = tags.get(\"container_id\");\n\n\t// If the Kafka lag metrics have already been added to this MetricEvent, return it.\n\tif (kafkaLagTimes.containsKey(topicPartition) && kafkaLagTimes.get(topicPartition).containsKey(containerId)) {\n\t\treturn metricEvent;\n\t}\n\n\t// Extract the current offset and committed offset from the gauge object.\n\tString[] gaugeValue = gauge.getValue().toString().split(\",\");\n\tlong currentOffset = Long.parseLong(gaugeValue[0]);\n\tlong committedOffset = Long.parseLong(gaugeValue[1]);\n\n\t// If the current offset is less than the committed offset, the consumer is falling behind.\n\tlong lag = currentOffset - committedOffset;\n\tif (lag < 0) {\n\t\tlag = 0;\n\t}\n\n\t// If the lag is 0, the consumer is caught up.\n\tif (lag == 0) {\n\t\tlag = 1;\n\t}\n\n\t// Update the Kafka lag metrics map with the current timestamp.\n\tif (kafkaLagTimes.containsKey(topicPartition)) {\n\t\tkafkaLagTimes.get(topicPartition).put(containerId, timestamp);\n\t} else {\n\t\tMap<String, Long> containerTimes = new HashMap<>();\n\t\tcontainerTimes.put(containerId, timestamp);\n\t\tkafkaLagTimes.put(topicPartition, containerTimes);\n\t}\n\n\t// Update the MetricEvent's fields.\n\tmetricEvent.setValue(lag);\n\tmetricEvent.setTimestamp(timestamp);\n\tmetricEvent.setTimestampMs(timestamp);\n\tmetricEvent.setTimestampSeconds(timestamp / 1000);\n\treturn metricEvent;\n}", "CodeBleu_score": 42.77941243890726}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t", "CodeBleu_score": 2.8929956351891004}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\n//        env.getConfig().setGlobalJobParameters(parameterTool);\n        Properties props = buildKafkaProps();\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n            props.setProperty(\"auto.offset.reset\", \"earliest\");\n            FlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n            kafkaConsumer.setStartFromSpecificOffsets(partitionOffset);\n            return env.addSource(kafkaConsumer);\n        } else {\n            FlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n            return env.addSource(kafkaConsumer);\n        }\n    }", "CodeBleu_score": 56.31579783199337}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t//        StreamExecutionEnvironment env = getRuntimeContext().getStreamExecutionEnvironment();\n        Properties properties = buildKafkaProps(env.getConfig());\n        DataStreamSource<MetricEvent> source = null;\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> partitionOffsets = buildOffsetByTime(properties, env.getConfig(), time);\n            source = env.addSource(new FlinkKafkaConsumer<>(topic, new JsonSchema(), properties, partitionOffsets));\n        } else {\n            source = env.addSource(new FlinkKafkaConsumer<>(topic, new JsonSchema(), properties));\n        }\n        return source;\n    }", "CodeBleu_score": 49.29132737499216}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\nProperties props = buildKafkaProps();\nMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, env.getStreamGraph().getJobParameters(), time);\nFlinkKafkaConsumer<MetricEvent> kafkaConsumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), props);\nkafkaConsumer.setStartFromSpecificOffsets(partitionOffset);\nDataStreamSource<MetricEvent> kafkaSource = env.addSource(kafkaConsumer);\nreturn kafkaSource;\n}", "CodeBleu_score": 53.27613225327017}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\t// Set the consumer group ID using the provided time\n\tString groupId = String.valueOf(time);\n\tprops.setProperty(\"group.id\", groupId);\n\n\t// Create a KafkaConsumer with the properties\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n\t// Retrieve partition information for the specified topic\n\tMap<TopicPartition, PartitionInfo> partitionInfoMap = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\n\t// Create a map associating each partition with the timestamp\n\tMap<KafkaTopicPartition, Long> topicPartitionOffsets = new HashMap<>();\n\tfor (Map.Entry<TopicPartition, PartitionInfo> entry : partitionInfoMap.entrySet()) {\n\t\tTopicPartition topicPartition = entry.getKey();\n\t\tPartitionInfo partitionInfo = entry.getValue();\n\t\tlong partitionOffset = partitionInfo.getOffsets().high() - time;\n\t\tif (partitionOffset < 0) {\n\t\t\tpartitionOffset = 0;\n\t\t}\n\t\ttopicPartitionOffsets.put(KafkaTopicPartition.of(topicPartition), partitionOffset);\n\t}\n\n\t// Close the consumer and return the map of partition offsets\n\tconsumer.close();\n\treturn topicPartitionOffsets;\n}", "CodeBleu_score": 44.06185779709902}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\t// set the consumer group ID using the provided time\n\tprops.setProperty(\"group.id\", \"flink-kafka-consumer-\" + time);\n\n\t// create a KafkaConsumer with the properties\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n\t// retrieve partition information for the specified topic\n\tMap<TopicPartition, PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\n\t// create a map associating each partition with the timestamp\n\tMap<KafkaTopicPartition, Long> partitionToOffsets = new HashMap<>();\n\tfor (TopicPartition topicPartition : partitionInfos.keySet()) {\n\t\tpartitionToOffsets.put(new KafkaTopicPartition(topicPartition.topic(), topicPartition.partition()), time);\n\t}\n\n\t// fetch the offsets for the given times\n\tconsumer.assign(partitionToOffsets.keySet());\n\tconsumer.seekToBeginning(partitionToOffsets.keySet());\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(partitionToOffsets);\n\n\t// build a map of KafkaTopicPartition to offsets\n\tMap<KafkaTopicPartition, Long> result = new HashMap<>();\n\tfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n\t\tresult.put(new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry.getValue().offset());\n\t}\n\n\t// close the consumer and return the map of partition offsets\n\tconsumer.close();\n\treturn result;\n}", "CodeBleu_score": 53.50482976682578}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString topic = parameterTool.getRequired(\"topic\")\n\tMap<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>()\n\tprops.setProperty(\"group.id\", \"flink-kafka-consumer\")\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props)\n\tconsumer.assign(consumer.partitionsFor(topic).stream().map(p -> new TopicPartition(topic, p.partition())).collect(Collectors.toList()))\n\tMap<TopicPartition, OffsetAndTimestamp> partitionTimestamps = consumer.offsetsForTimes(partitionOffsets.entrySet().stream().collect(Collectors.toMap(Map.Entry::getKey, e -> new OffsetAndTimestamp(e.getValue()))))\n\tfor (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : partitionTimestamps.entrySet()) {\n\t\tpartitionOffsets.put(new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry.getValue().offset())\n\t}\n\tconsumer.close()\n\treturn partitionOffsets\n}", "CodeBleu_score": 42.36189137722115}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"acks\", \"all\");\n\tprops.put(\"retries\", 0);\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\tMetricEvent me = new MetricEvent();\n\tme.setTimestamp(System.currentTimeMillis());\n\tme.setName(\"test_metric\");\n\tme.setFields(new HashMap<String, Object>() {{\n\t\tput(\"test_field\", \"test_value\");\n\t}});\n\tme.setTags(new HashMap<String, String>() {{\n\t\tput(\"test_tag\", \"test_value\");\n\t}});\n\tProducerRecord<String, String> data = new ProducerRecord<String, String>(\"test_topic\", me.getName(), me.toJson());\n\tproducer.send(data);\n\tSystem.out.println(me.toJson());\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 54.167743306476225}, {"code": "public static void writeToKafka() throws InterruptedException{\n\tProperties props = new Properties();\nprops.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nprops.put(ProducerConfig.CLIENT_ID_CONFIG, \"simple-producer\");\nprops.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\nprops.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class);\n\nProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\nMetricEvent event = new MetricEvent();\nevent.setTimestamp(System.currentTimeMillis());\nevent.setName(\"KafkaMetricEvent\");\nevent.setFields(new HashMap<String, Object>() {{\nput(\"field1\", 1234);\nput(\"field2\", 2345);\nput(\"field3\", 3456);\n}});\nevent.setTags(new HashMap<String, String>() {{\nput(\"tag1\", \"value1\");\nput(\"tag2\", \"value2\");\n}});\n\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"sample-metrics\", event.serialize());\n\nproducer.send(record);\nSystem.out.println(\"Sent data: \" + record.toString());\nproducer.flush();\nproducer.close();\n}", "CodeBleu_score": 45.19386486862681}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t// Setup the Kafka producer properties.\nProperties properties = new Properties();\nproperties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, \"localhost:9092\");\nproperties.put(ProducerConfig.CLIENT_ID_CONFIG, \"KafkaExampleProducer\");\nproperties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\nproperties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());\n\n// Create a Kafka producer.\nKafkaProducer<String, String> producer = new KafkaProducer<String, String>(properties);\n\n// Create a MetricEvent.\nMetricEvent metricEvent = new MetricEvent();\nmetricEvent.setTimestamp(System.currentTimeMillis());\nmetricEvent.setName(\"KafkaExampleMetricEvent\");\nmetricEvent.setFields(new HashMap<String, Object>() {{\n    put(\"count\", 1);\n    put(\"status\", \"ok\");\n}});\nmetricEvent.setTags(new HashMap<String, String>() {{\n    put(\"host\", \"localhost\");\n    put(\"region\", \"us-west-1\");\n}});\n\n// Serialize the MetricEvent.\nString metricEventJson = new ObjectMapper().writeValueAsString(metricEvent);\n\n// Create a ProducerRecord.\nProducerRecord<String, String> record = new ProducerRecord<String, String>(\"metrics\", \"metricEventJson\");\n\n// Send the record to the Kafka topic.\nproducer.send(record);\n\n// Flush the producer to ensure all data is sent.\nproducer.flush();\n\n// Print the sent data.\nSystem.out.println(metricEventJson);\n}", "CodeBleu_score": 46.111992958219986}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\ttry {\nif (event.getLevel().isMoreSpecificThan(this.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\nString jsonEvent = subAppend(event);\nif (jsonEvent != null) {\nproducer.send(new ProducerRecord<String, String>(topic, jsonEvent));\n}\n}\n} catch (Exception e) {\nlog.warn(\"Error processing log event\", e);\n}\n}", "CodeBleu_score": 49.682179892871964}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\tif (event.getLevel().isMoreSpecificThan(level) && !event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Error sending log event to Kafka topic: \" + topic, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 43.049257965301614}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t\ttry {\n\t\tif (event.getLevel().toString().equals(\"INFO\")) {\n\t\t\tif (!event.getLoggerName().contains(\"xxx\")) {\n\t\t\t\tString logEvent = subAppend(event);\n\t\t\t\tproducer.send(new ProducerRecord(topic, logEvent));\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.warn(\"Exception occurred while processing the event: \" + event, e);\n\t}\n}", "CodeBleu_score": 44.229522716205324}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidTopicSuffixMethods := []string{\"\", \"hash\", \"random\"}\n\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn errors.New(\"unknown topic suffix method: \" + method)\n}", "CodeBleu_score": 71.1820643105999}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 92.41207029386057}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\n\t\t\"none\",\n\t\t\"hash\",\n\t\t\"random\",\n\t}\n\n\tfor _, v := range validMethods {\n\t\tif v == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 72.9375696562115}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tvar routingKey string\n\tvar err error\n\n\tif k.RoutingTag != \"\" {\n\t\troutingKey, err = metric.GetTag(k.RoutingTag)\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"RoutingTag %s not found in metric %s\", k.RoutingTag, metric.Name())\n\t\t}\n\t} else {\n\t\troutingKey = k.RoutingKey\n\t}\n\n\tif routingKey == \"random\" {\n\t\troutingKey = uuid.New().String()\n\t}\n\n\treturn routingKey, nil\n}", "CodeBleu_score": 49.680481490749806}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\t// Get the routing tag, if one is specified\n\troutingTag := k.RoutingTag\n\tif routingTag != \"\" {\n\t\t// Check if the routing tag is present in the metric's tags\n\t\tif _, ok := metric.Tags()[routingTag]; !ok {\n\t\t\t// If the tag is not present, return an error\n\t\t\treturn \"\", fmt.Errorf(\"Routing tag %s not present in metric tags\", routingTag)\n\t\t}\n\t\t// If the tag is present, return its value as the routing key\n\t\treturn metric.Tags()[routingTag], nil\n\t}\n\t// Get the routing key\n\troutingKey := k.RoutingKey\n\t// If the routing key is set to \"random\", generate a new UUID\n\tif routingKey == \"random\" {\n\t\treturn uuid.New().String(), nil\n\t}\n\t// Otherwise, return the routing key as the key\n\treturn routingKey, nil\n}", "CodeBleu_score": 46.54984176801007}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.New().String(), nil\n\t}\n\tif k.RoutingTag != \"\" {\n\t\tif tag, ok := metric.Tags()[k.RoutingTag]; ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 52.394027295181836}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tif len(k.TopicRegexps) == 0 {\n\t\treturn errors.New(\"TopicRegexps is empty\")\n\t}\n\n\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error compiling topic regexp %d: %s\", i, err)\n\t\t}\n\t\tregexps[i] = re\n\t}\n\n\tk.regexps = regexps\n\treturn nil\n}", "CodeBleu_score": 43.52445095343966}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tvar err error\n\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tk.regexps[i], err = regexp.Compile(re)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", re, err)\n\t\t}\n\t}\n\treturn nil\n}", "CodeBleu_score": 57.81267684953728}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not compile regular expression %s: %s\", re, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 61.13527942581951}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mutex.Lock()\n\tdefer h.mutex.Unlock()\n\n\tm := h.undelivered[track.DeliveryTag]\n\tif m == nil {\n\t\treturn\n\t}\n\n\tif m.delivered {\n\t\treturn\n\t}\n\n\tm.delivered = true\n\tm.deliveredAt = time.Now()\n\n\th.session.MarkMessage(telegraf.ConsumerGroupMessage{\n\t\tConsumer: h.name,\n\t\tMessage:  m,\n\t})\n\n\tdelete(h.undelivered, track.DeliveryTag)\n\th.sem.Release()\n}", "CodeBleu_score": 47.04704362680403}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.handlerLock.Lock()\n\tdefer h.handlerLock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryTag]\n\tif ok {\n\t\tmsg.Delivered = true\n\t\tmsg.DeliveredAt = time.Now()\n\t\tmsg.DeliveryInfo = track\n\t\tmsg.Topic = h.consumer.Topic()\n\t\tmsg.Partition = h.consumer.Partition()\n\t\tmsg.Offset = track.Offset\n\t\tmsg.PartitionKey = h.consumer.Key()\n\n\t\th.session.MarkMessage(msg, \"\")\n\t\th.session.Commit()\n\t\tdelete(h.undelivered, track.DeliveryTag)\n\t\th.semaphore.Done()\n\t}\n}", "CodeBleu_score": 48.286779785582944}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.handlerLock.Lock()\n\tdefer h.handlerLock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryTag]\n\tif ok {\n\t\tmsg.Delivered = true\n\t\tmsg.DeliveryTime = time.Now()\n\t\th.session.MarkMessage(msg, \"\")\n\t\tdelete(h.undelivered, track.DeliveryTag)\n\t\th.semaphore.Done()\n\t}\n}", "CodeBleu_score": 52.37092417751397}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tfor msg := range claim.Messages() {\n\t\tctx, cancel := context.WithCancel(context.Background())\n\t\tdefer cancel()\n\n\t\t// Create a new context with the session context.\n\t\tctx = context.WithValue(ctx, sessionContextKey, session)\n\n\t\t// Call the handler function.\n\t\tif err := h.handler(ctx, msg); err != nil {\n\t\t\tlog.Printf(\"error handling message: %v\", err)\n\t\t}\n\n\t\t// Mark the message as processed.\n\t\tsession.MarkMessage(msg, \"\")\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 45.83777930712121}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tfor msg := range claim.Messages() {\n\t\t// NOTE: A successful message processing MUST call session.MarkMessage(msg, \"\")\n\t\t// for each message, otherwise the consumer will block forever.\n\t\t//\n\t\t// NOTE: A failed message processing MUST call session.MarkMessage(msg, err.Error())\n\t\t// for each message, otherwise the consumer will block forever.\n\n\t\t// TODO: handle message\n\t\terr := h.handleMessage(msg)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tsession.MarkMessage(msg, \"\")\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 34.23120249851834}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t", "CodeBleu_score": 3.1071579261949545}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id != null && !logkafka_id.isEmpty, EmptyLogkafkaId)\ncheckCondition(logkafka_id != \".\" && logkafka_id != \"..\", IllegalCharacterInLogkafkaId)\ncheckCondition(logkafka_id.length <= 64, LogkafkaIdTooLong)\ncheckCondition(logkafka_id.matches(\"[a-zA-Z0-9_-]+\"), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 33.12186588093575}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id != null, IllegalNullLogkafkaId)\n\tcheckCondition(logkafka_id.length > 0, IllegalEmptyLogkafkaId)\n\tcheckCondition(logkafka_id != \".\", IllegalDotLogkafkaId)\n\tcheckCondition(logkafka_id != \"..\", IllegalDotDotLogkafkaId)\n\tcheckCondition(logkafka_id.length <= MAX_LOGKAFKA_ID_LENGTH, IllegalLogkafkaIdLength)\n\tcheckCondition(logkafka_id.matches(VALID_LOGKAFKA_ID_REGEX), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 49.124105036538744}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id.length > 0, IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be empty.\"))\n\tcheckCondition(!logkafka_id.equals(\".\"), IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be \\\".\\\".\"))\n\tcheckCondition(!logkafka_id.equals(\"..\"), IllegalCharacterInLogkafkaId(\"Logkafka ID cannot be \\\"..\\\".\"))\n\tcheckCondition(logkafka_id.length <= 64, IllegalCharacterInLogkafkaId(\"Logkafka ID cannot exceed 64 characters.\"))\n\tcheckCondition(logkafka_id.matches(\"\"\"^[a-zA-Z0-9][a-zA-Z0-9\\-_]*[a-zA-Z0-9]$\"\"\"), IllegalCharacterInLogkafkaId(\"Logkafka ID can only contain alphanumeric characters, hyphens and underscores.\"))\n}", "CodeBleu_score": 36.972268961596306}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t//    logger.debug(s\"Sending message $msg to Kafka manager actor\")\n    val f = kafkaManagerActor ? msg\n    f.map {\n      case Success(output) =>\n//        logger.debug(s\"Message $msg sent to Kafka manager actor\")\n        try {\n          \\/-(fn(output))\n        } catch {\n          case e: Exception =>\n            logger.error(s\"Error processing response from Kafka manager actor: $e\")\n            error(e)\n        }\n      case Failure(error) =>\n//        logger.error(s\"Error sending message $msg to Kafka manager actor: $error\")\n        error(error)\n    }\n  }", "CodeBleu_score": 30.910850960204577}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n-    val result: Future[Output] = kafkaManagerActor ? msg\n+    val result: Future[Output] = kafkaManagerActor ? msg.withReplyTo(sender())\n     result.map {\n       case Success(value) =>\n         try {\n@@ -149,7 +150,7 @@ private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n   }\n   result.recover {\n     case e: Exception =>\n-      log.error(s\"Error while processing message [${msg}]\", e)\n+      log.error(s\"Error while processing message [${msg}] to actor [${kafkaManagerActor.path}]\", e)\n       InternalServerError(e.getMessage)\n   }\n }\n@@ -174,7 +175,7 @@ private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n   }", "CodeBleu_score": 38.14764996355312}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\tval kafkaManagerActor = getKafkaManagerActor\nval response = kafkaManagerActor.ask(msg)\nresponse.map {\ncase ActorErrorResponse(err) => ApiError.fromActorError(err)\ncase ActorResponse(data) => fn(data.asInstanceOf[Output])\n}\n}", "CodeBleu_score": 26.123177948408394}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t\n/**\n * The sendAndReceive function sends a message to the Kafka Manager actor and processes the response.\nIt takes an input message and a function to handle the output.\nIt sends the message to the Kafka Manager actor and applies the provided function to the response if it matches the expected output type.\nIf an ActorErrorResponse is received, it returns an ApiError.\nIf a throwable occurs, it recovers by returning an ApiError from the throwable.\n */\n    val response = kafkaManagerActor ? msg\n\n    response.map {\n      case ActorErrorResponse(error) =>\n        logger.error(s\"Actor Error Response: $error\")\n        ApiError.fromActorErrorResponse(error)\n\n      case output: Output =>\n        logger.debug(s\"Actor Response: $output\")\n        fn(output)\n\n      case unexpectedResponse =>\n        logger.error(s\"Unexpected Response: $unexpectedResponse\")\n        ApiError.fromUnexpectedActorResponse(unexpectedResponse)\n    }.flatten\n  }", "CodeBleu_score": 35.500492622437804}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t//    val log = context.system.log\n    val askTimeout = Timeout(settings.askTimeout)\n    (kafkaManagerActor ? msg)(askTimeout).mapTo[Output].flatMap {\n      case ActorErrorResponse(error) => Future.successful(ApiError.fromActorError(error))\n      case other => fn(other)\n    }.recover {\n      case error: Throwable => ApiError.fromThrowable(error)\n    }\n  }", "CodeBleu_score": 33.60434994097837}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\nval request = ClusterCommandRequest(clusterName, PreferredReplicaElectionCommand(topics))\n\nval result = sendClusterCommand(request)\n\nresult.map {\n    case (cluster, result) => result match {\n        case Success(ClusterCommandResponse(Some(PreferredReplicaElectionResponse(t)))) => \\/-(cluster)\n        case Success(ClusterCommandResponse(None)) => -\\/(ApiError(s\"Preferred leader election failed for cluster $clusterName\"))\n        case Failure(error) => -\\/(ApiError(s\"Preferred leader election failed for cluster $clusterName: $error\"))\n    }\n}\n  }", "CodeBleu_score": 19.06658806334501}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\nval request = KMClusterCommandRequest(\n  clusterName,\n  Some(KMReassignPartitions(topics, Some(KMReassignPartitionsStrategyPreferred))))\n\nval response = Await.result(\n  kafkaManager.ask(request),\n  timeout.duration)\n\nresponse match {\n  case KMError(_, message) =>\n    Future.failed(new IllegalStateException(s\"Failed to run preferred leader election for topics $topics in cluster $clusterName: $message\"))\n  case KMClusterCommandSuccess(_, clusterContext) =>\n    Future.successful(clusterContext)\n}\n\n}", "CodeBleu_score": 21.434806166301943}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t(for {\n    topics <- getTopicList(clusterName)\n    result <- topics.toRight(ApiError(s\"Error retrieving topic list for cluster $clusterName\"))\n    result <- runPreferredLeaderElection(clusterName, result.map(_.name))\n  } yield result).merge\n}", "CodeBleu_score": 19.268372847974486}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t(for {\n    topicList <- getTopicList(clusterName)\n    result <- topicList.toRight(ApiError(s\"Failed to retrieve topic list for cluster $clusterName\"))\n    result <- runPreferredLeaderElection(clusterName, result.map(_.topic).toSet)\n  } yield result).leftMap(ApiError.apply)\n}", "CodeBleu_score": 20.89602948021042}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t", "CodeBleu_score": 3.006318370370258}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\nval assignmentsList = assignments.map { case (topic, partitionAssignments) =>\n  val partitionAssignmentsList = partitionAssignments.map { case (partition, replicas) =>\n    val replicasList = replicas.map(new java.lang.Integer(_))\n    new KafkaManager.PartitionAssignment(topic, partition, replicasList)\n  }\n  new KafkaManager.TopicAssignment(topic, partitionAssignmentsList.asJava)\n}\n\nval assignmentsListJava = assignmentsList.asJava\n\ntryWithKafkaManagerActor(\n  KMClusterCommandRequest(clusterName, KafkaManager.KMReassignPartitionsCommand(assignmentsListJava))) {\n  case KafkaManager.KMReassignPartitionsResponse(error, success) =>\n    val errorList = error.asScala.toList\n    val successList = success.asScala.toList\n    val errors = errorList.map(ApiError.from)\n    if (errors.nonEmpty) -\\/(errors) else \\/-(successList)\n}\n}", "CodeBleu_score": 31.393579016725383}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\timplicit val ec = apiExecutionContext\nsystem.actorSelection(kafkaManagerActor).ask(KMClusterCommandRequest(clusterName,\n                                                                     KafkaManagerCommand.ManualPartitionAssignments(\n                                                                       assignments))).map {\n  case err: ActorErrorResponse => \n    error(s\"Failed on input : $clusterName\")\n    -\\/(ApiError.from(err))\n  case o: CMManualPartitionAssignments =>\n    Try {\n      o\n    } match {\n      case Failure(t) => \n        error(s\"Failed on input : $clusterName\")\n        -\\/(ApiError.fromThrowable(t))\n      case Success(foutput) => \\/-(foutput)\n    }\n}.recover { case t: Throwable =>\n  error(s\"Failed on input : $clusterName\", t)\n  -\\/(ApiError.fromThrowable(t))\n}\n}", "CodeBleu_score": 30.591541870008648}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster to get the available nodes within a specified timeout.\n\tfinal DescribeClusterResult describeResult = admin.describeCluster();\n\tfinal Collection<Node> nodes = describeResult.nodes().get();\n\tif (nodes.size() < 1) {\n\t\tthrow new ConnectException(\"No nodes found in the cluster.\");\n\t}\n\t// Select the first node's ID and request its configuration.\n\tfinal DescribeConfigsResult configResult = admin.describeConfigs(Collections.singletonMap(nodes.iterator().next().idString(), Collections.singleton(KafkaConfig.BrokerIdProp())));\n\tfinal Config configs = configResult.all().get().get(nodes.iterator().next().idString());\n\tif (configs.values().size() < 1) {\n\t\tthrow new ConnectException(\"No configuration found for the node.\");\n\t}\n\t// Return the broker's configuration.\n\treturn configs.values().iterator().next();\n}", "CodeBleu_score": 50.25282650714424}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tConfig config = new Config();\n\ttry {\n\t\t// Describe cluster to get the available nodes within a specified timeout\n\t\tDescribeClusterResult describeClusterResult = admin.describeCluster();\n\t\tList<Node> nodes = describeClusterResult.nodes().get();\n\t\tif (nodes.size() == 0) {\n\t\t\tthrow new ConnectException(\"No nodes found in cluster.\");\n\t\t}\n\n\t\t// Select the first node's ID and request its configuration\n\t\tString nodeId = nodes.get(0).idString();\n\t\tDescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(nodeId));\n\t\tConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodeId);\n\t\tConfigResourceResponse configResourceResponse = describeConfigsResult.all().get().get(configResource);\n\t\tif (configResourceResponse == null) {\n\t\t\tthrow new ConnectException(\"No configuration found for node \" + nodeId);\n\t\t}\n\n\t\t// Return the broker's configuration\n\t\tconfig = configResourceResponse.config();\n\t} catch (Exception e) {\n\t\tthrow new ConnectException(\"Failed to retrieve configuration for Kafka broker.\", e);\n\t}\n\treturn config;\n}", "CodeBleu_score": 49.804647482589544}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\t// Describe the cluster to get the available nodes within a specified timeout\n\tDescribeClusterResult describeClusterResult = admin.describeCluster(DescribeClusterOptions.builder().operationTimeout(Duration.ofSeconds(10)).build());\n\tList<Node> nodes = describeClusterResult.nodes().get();\n\n\t// If no nodes are available, throw an exception\n\tif (nodes.isEmpty()) {\n\t\tthrow new Exception(\"No nodes found!\");\n\t}\n\n\t// Select the first node's ID and request its configuration\n\tConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodes.get(0).idString());\n\tConfig config = admin.describeConfigs(Collections.singletonList(configResource), DescribeConfigsOptions.builder().includeSynonyms(false).build()).all().get().get(configResource);\n\n\t// If no configurations are received, throw an exception\n\tif (config.entries().isEmpty()) {\n\t\tthrow new Exception(\"No configuration found!\");\n\t}\n\n\t// Return the broker's configuration\n\treturn config;\n}", "CodeBleu_score": 51.92195367009778}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\tvalidator.configure(configs);\n\t\t}\n\n\t\t@Override\n\t\tpublic boolean isInvalid(TopicPartition topicPartition, long offset, Schema schema) {\n\t\t\tif (schema == null) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t\tif (schema.schemaType() == SchemaType.AVRO) {\n\t\t\t\treturn validator.isInvalid(topicPartition, offset, schema);\n\t\t\t} else {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic void close() {\n\t\t\tvalidator.close();\n\t\t}\n\t};\n}", "CodeBleu_score": 30.765684156544282}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn new Validator() {\n\t\t@Override\n\t\tpublic void configure(Map<String, ?> configs) {\n\t\t\tvalidator.configure(configs);\n\t\t}\n\n\t\t@Override\n\t\tpublic void validate(String topic, byte[] value, Schema schema) {\n\t\t\tif (schema.schemaType() == SchemaType.AVRO) {\n\t\t\t\tfinal SchemaCompatibilityResult compatibility = SchemaCompatibility.checkReaderWriterCompatibility(schema, new KafkaAvroDeserializer().configure(Collections.emptyMap(), false).deserialize(topic, value).getSchema());\n\t\t\t\tif (compatibility.isCompatible()) {\n\t\t\t\t\tvalidator.validate(topic, value, schema);\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tvalidator.validate(topic, value, schema);\n\t\t\t}\n\t\t}\n\n\t\t@Override\n\t\tpublic boolean isConfigured() {\n\t\t\treturn validator.isConfigured();\n\t\t}\n\t};\n}", "CodeBleu_score": 36.414160204985215}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (config, history) -> {\n\t\tif (history instanceof KafkaSchemaHistory) {\n\t\t\treturn validator.validate(config, history);\n\t\t}\n\t\treturn 0;\n\t};\n}", "CodeBleu_score": 18.906240253274984}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t", "CodeBleu_score": 4.348203638397692}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t\tif (version == null) {\n\t\tversion = parseVersion(config.get(ConfigName.CONNECTOR_CLASS).toString());\n\t}\n\tif (version.onOrAfter(Version.parse(\"2.3.0\"))) {\n\t\treturn config.get(ConfigName.TOPIC_CREATION_ENABLE) != null && (Boolean) config.get(ConfigName.TOPIC_CREATION_ENABLE);\n\t}\n\treturn true;\n}", "CodeBleu_score": 33.333967239097724}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t", "CodeBleu_score": 4.348203638397692}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\t// Check for mandatory configuration options and throw an exception if any are missing.\n\tcheckMandatoryConfigOptions(config);\n\t// Create a shared Kafka admin client with the admin properties.\n\tSharedTopicAdmin sharedAdmin = new SharedTopicAdmin(config);\n\t// Create a KafkaOffsetBackingStore with the shared admin, client ID, and an offset store converter.\n\treturn new KafkaOffsetBackingStore(sharedAdmin, config.get(CLIENT_ID_CONFIG), converterForOffsetStore());\n}", "CodeBleu_score": 13.234916440111697}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t\tif (node.isObject()) {\n\t\tnode = node.get(PAYLOAD_FIELD);\n\t}\n\tif (config.keyFields().isEmpty()) {\n\t\treturn reader.readValue(node);\n\t}\n\telse if (config.keyFields().size() == 1) {\n\t\tString fieldName = config.keyFields().get(0);\n\t\tif (node.has(fieldName)) {\n\t\t\treturn reader.readValue(node.get(fieldName));\n\t\t}\n\t\telse {\n\t\t\tthrow new IOException(\"Unable to find key field '\" + fieldName + \"' in JSON: \" + node);\n\t\t}\n\t}\n\telse {\n\t\treturn reader.readValue(node);\n\t}\n}", "CodeBleu_score": 41.67277730235156}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t\tif (node.isObject()) {\n\t\tnode = node.get(PAYLOAD_FIELD);\n\t}\n\n\tif (config.keyIsSimple()) {\n\t\treturn reader.readValue(node);\n\t}\n\telse {\n\t\treturn reader.readValue(node);\n\t}\n}", "CodeBleu_score": 24.834621287301083}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tJsonNode payload = node.get(PAYLOAD_FIELD);\n\n// Schema + payload format\nif (payload != null) {\nnode = payload;\n}\n// Debezium envelope\nif (config.asEnvelope()) {\nreturn reader.readValue(node);\n}\n// Extracted format\nelse {\nList<String> fieldNames = config.keyFieldNames();\nif (fieldNames.size() == 1) {\nString fieldName = fieldNames.get(0);\nif (node.has(fieldName)) {\nreturn reader.readValue(node.get(fieldName));\n}\nelse {\nthrow new IllegalArgumentException(\nString.format(\"Field '%s' does not exist in JSON object: %s\", fieldName, node));\n}\n}\nelse {\nreturn reader.readValue(node);\n}\n}\n}", "CodeBleu_score": 45.862520286647595}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t//        String topicName = topicNameFor(id);\n//        return sanitizeTopicName(topicName, prefix, delimiter);\n        return topicNameFor(id);\n    }", "CodeBleu_score": 6.537266915357696}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t//        String topicName = topicNameFor(id);\n//        if (topicName.equals(topicNameFor(id, prefix, delimiter))) {\n//            return topicName;\n//        }\n//        String sanitizedTopicName = topicName;\n//        for (int i = 0; i < sanitizedTopicName.length(); i++) {\n//            char c = sanitizedTopicName.charAt(i);\n//            if (!isValidTopicNameCharacter(c)) {\n//                sanitizedTopicName = sanitizedTopicName.replace(c, replacementCharacter);\n//                logger.warn(\"Invalid character '\" + c + \"' found in topic name '\" + topicName + \"'. Replacing with '\" + replacementCharacter + \"'.\");\n//            }\n//        }\n//        return sanitizedTopicName;\n}", "CodeBleu_score": 3.644927833422239}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tif (id == null) {\nthrow new IllegalArgumentException(\"id cannot be null\");\n}\nif (prefix == null) {\nthrow new IllegalArgumentException(\"prefix cannot be null\");\n}\nif (delimiter == null) {\nthrow new IllegalArgumentException(\"delimiter cannot be null\");\n}\nString topicName = topicNameNamer.topicNameFor(id, prefix, delimiter);\nString sanitizedTopicName = sanitizeTopicName(topicName);\nif (!topicName.equals(sanitizedTopicName)) {\nlog.warn(\"Sanitized topic name {} to {}\", topicName, sanitizedTopicName);\n}\nreturn sanitizedTopicName;\n}", "CodeBleu_score": 26.89088079735213}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tthis.connectorType = connectorType;\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.producerThrowable = null;\n\tthis.retries = replacedErrorHandler == null ? connectorConfig.getRetries() : replacedErrorHandler.retries;\n}", "CodeBleu_score": 45.896945736744215}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tthis.connectorType = connectorType;\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.producerThrowable = new AtomicReference<>();\n\tthis.retries = replacedErrorHandler != null ? replacedErrorHandler.retries : connectorConfig.getMaxRetries();\n}", "CodeBleu_score": 51.84258905718765}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tthis.connectorType = connectorType;\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.producerThrowable = new AtomicReference<>();\n\tthis.retries = replacedErrorHandler == null ? Integer.MAX_VALUE : replacedErrorHandler.retries;\n}", "CodeBleu_score": 49.48693547143597}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 84.09949999606884}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 84.09949999606884}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 84.09949999606884}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\n\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader != null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 95.78268445597212}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader != null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 97.57940834905897}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\nif (oldSchema.type().isPrimitive()) {\n    return oldSchema;\n}\n\n// Get fields from original schema\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n    if (isContainedIn(field.name(), nestedFields)) {\n\n        newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n    }\n    else {\n        newSchemabuilder.field(field.name(), field.schema());\n    }\n}\n\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\n\n    Header currentHeader = headerToProcess.get(headers.get(i));\n    Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n    LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n    if (currentFieldName.isPresent() && currentHeader != null) {\n        newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n    }\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 97.57940834905897}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.schema().field(SNAPSHOT_KEY) == null) {\n\t\treturn null;\n\t}\n\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 29.879273517904398}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\tif (snapshotString != null) {\n\t\tsnapshotString = snapshotString.toUpperCase();\n\t\treturn SnapshotRecord.valueOf(snapshotString);\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.256793731322475}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.schema().field(SNAPSHOT_KEY) == null) {\n\t\treturn null;\n\t}\n\n\tString snapshotString = source.getString(SNAPSHOT_KEY);\n\tif (snapshotString == null) {\n\t\treturn null;\n\t}\n\n\treturn SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 29.879273517904398}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\tString[] subparts = parts[0].split(\"-\");\n\tif (subparts.length > 1) {\n\t\tparts[0] = subparts[0];\n\t}\n\treturn Optional.of(Float.parseFloat(parts[0]));\n}", "CodeBleu_score": 53.723713197215275}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOfRange(parts, 0, 2);\n\t}\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(parts[0].split(\"-\")[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 64.12024983449575}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length == 0) {\n\t\treturn Optional.empty();\n\t}\n\n\tfloat major = Float.parseFloat(parts[0]);\n\tif (parts.length == 1) {\n\t\treturn Optional.of(major);\n\t}\n\n\tString[] minorParts = parts[1].split(\"-\");\n\tif (minorParts.length == 0) {\n\t\treturn Optional.empty();\n\t}\n\n\tfloat minor = Float.parseFloat(minorParts[0]);\n\tif (minorParts.length == 1) {\n\t\treturn Optional.of(major + minor);\n\t}\n\n\treturn Optional.empty();\n}", "CodeBleu_score": 47.114689184024634}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n.operationName(\"createConnector\")\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 92.94612271212847}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n    .cluster(clusterName)\n    .connect(connectName)\n    .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n    .operationName(\"createConnector\")\n    .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n        .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.61649513843518}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n    .cluster(clusterName)\n    .connect(connectName)\n    .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n    .operationName(\"createConnector\")\n    .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n        .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.61649513843518}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 96.09403183430064}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nAccessContext context = AccessContext.builder()\n    .cluster(clusterName)\n    .connect(connectName)\n    .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n    .operationName(\"deleteConnector\")\n    .operationParams(Map.of(CONNECTOR_NAME, connectName))\n    .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n        .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 94.60572070602856}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\nvar context = AccessContext.builder()\n    .cluster(clusterName)\n    .connect(connectName)\n    .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n    .operationName(\"deleteConnector\")\n    .operationParams(Map.of(CONNECTOR_NAME, connectName))\n    .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n        .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.87341580605556}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nConnectAction[] connectActions;\nif (RESTART_ACTIONS.contains(action)) {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n} else {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n}\n\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(connectActions)\n.operationName(\"updateConnectorState\")\n.operationParams(Map.of(CONNECTOR_NAME, connectorName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService\n.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.74142540022329}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n// 1. Build access context\n\n// 1.1. Define connect actions based on action\n\n// 1.2. Create context with cluster, connect, actions, operation name, and parameters\n\n// 2. Validate access\n\n// 3. Update connector state\n\n// 3.1. Update connector state using kafkaConnectService\n\n// 4. Return response entity\n\n// 4.1. Return ok response entity\n\n// 5. Audit\n\n// 5.1. Create audit context with cluster, connect, actions, operation name, and parameters\n\n// 5.2. Audit for each signal\n\n}", "CodeBleu_score": 6.700678162085702}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\nvar context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(getConnectActions(action))\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\nreturn validateAccess(context).then(\n        kafkaConnectService\n            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 56.83209927554774}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(new Initializer())\n\t\t.run(args);\n}", "CodeBleu_score": 36.6014432321738}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new ApplicationContextInitializer<ConfigurableApplicationContext>() {\n\t\t\t\t@Override\n\t\t\t\tpublic void initialize(ConfigurableApplicationContext applicationContext) {\n\t\t\t\t\tapplicationContext.addBeanFactoryPostProcessor(new KafkaUiPropertySourcePostProcessor());\n\t\t\t\t}\n\t\t\t})\n\t\t\t.run(args);\n}", "CodeBleu_score": 57.8642415469692}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t.initializers(new ApplicationPropertiesInitializer())\n\t\t.run(args);\n}", "CodeBleu_score": 39.454112365935885}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\treturn search == null ? t -> true : t -> getStringsForSearch(t).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 39.45552485883953}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t\n//    return (final FullConnectorInfoDTO connector) -> search == null || getStringsForSearch(connector).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n    return (final FullConnectorInfoDTO connector) -> search == null || getStringsForSearch(connector).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n  }", "CodeBleu_score": 41.775005172847976}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\nreturn c -> true;\n}\nfinal String searchTerm = search.toLowerCase();\nreturn c -> getStringsForSearch(c).anyMatch(s -> s.toLowerCase().contains(searchTerm));\n}", "CodeBleu_score": 61.39753862199569}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n/**\n * If the properties map is null, return an empty map.\n */\n    if (propertiesMap == null) {\n      return new HashMap<>();\n    }\n\n/**\n * Initialize the flattened map with the properties map.\n */\n    Map<String, Object> flattenedProperties = new HashMap<>(propertiesMap);\n\n/**\n * For each entry in the properties map, construct a new key by combining the prefix and the current key.\n */\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n\n/**\n * If the value is another map, recursively flatten it with the new key as the prefix.\n */\n      if (value instanceof Map) {\n        flattenedProperties.putAll(flattenClusterProperties(prefix == null ? key : prefix + \".\" + key,\n                                                            (Map<String, Object>) value));\n      }\n    }\n\n    return flattenedProperties;\n  }", "CodeBleu_score": 44.9319974538773}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n\n    Map<String, Object> flattenedProperties = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedProperties;\n    }\n\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix == null ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattenedProperties.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattenedProperties.put(newKey, value);\n      }\n    }\n    return flattenedProperties;\n  }", "CodeBleu_score": 53.149803650330874}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t\n//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n\n    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newPrefix = (prefix == null) ? key : prefix + \".\" + key;\n        if (value instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(newPrefix, (Map<String, Object>) value));\n        } else {\n          flattenedMap.put(newPrefix, value);\n        }\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 50.743929566770454}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t// If ACL view is not enabled, ACL editing is not allowed.\n    if (!aclViewEnabled(adminClient)) {\n        return Mono.empty();\n    }\n\n// If the user does not have permissions for altering ACLs, ACL editing is not allowed.\n    if (!clusterDescription.getAclDescriptions().stream().allMatch(acl -> acl.operation().equals(AclOperation.ALTER))) {\n        return Mono.empty();\n    }\n\n// Otherwise, ACL editing is allowed.\n    return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 31.378439108209065}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn adminClient.describeCluster().map(clusterDescription -> {\n  if (!clusterDescription.isAclAuthEnabled()) {\n    return Mono.empty();\n  }\n  if (!clusterDescription.isAclViewEnabled()) {\n    return Mono.empty();\n  }\n  Set<AclOperation> authorizedOperations = clusterDescription.getAuthorizedOperations();\n  if (!authorizedOperations.containsAll(AclOperation.ALTER, AclOperation.DESCRIBE, AclOperation.READ, AclOperation.WRITE)) {\n    return Mono.empty();\n  }\n  return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n}).flatMap(Function.identity());\n}", "CodeBleu_score": 32.4310826468594}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\treturn Mono.just(clusterDescription)\n  .map(ClusterDescription::getAuthorizedOperations)\n  .map(authorizedOperations -> authorizedOperations.containsAll(Arrays.asList(AclOperation.ALTER, AclOperation.DESCRIBE)))\n  .filter(isAllowed -> isAllowed)\n  .map(isAllowed -> clusterDescription.getFeatures().contains(ClusterFeature.KAFKA_ACL_VIEW))\n  .filter(isAllowed -> isAllowed)\n  .map(isAllowed -> ClusterFeature.KAFKA_ACL_EDIT)\n  .switchIfEmpty(Mono.empty());\n}", "CodeBleu_score": 29.136179989822637}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\tif (prevRange.isEmpty()) {\n\t\t// First poll\n\t\tnextRange = seekOperations.getSeekToOffsets();\n\t} else {\n\t\t// Subsequent poll\n\t\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n\t\t\tTopicPartition tp = entry.getKey();\n\t\t\tFromToOffset prevOffsetRange = entry.getValue();\n\t\t\tlong prevEndOffset = prevOffsetRange.getTo();\n\t\t\tlong numMessagesToPoll = Math.min(maxNumMessagesPerPoll, prevEndOffset - prevOffsetRange.getFrom() + 1);\n\t\t\tlong startOffset = Math.max(prevOffsetRange.getFrom() + numMessagesToPoll, 0);\n\t\t\tnextRange.put(tp, new FromToOffset(startOffset, prevEndOffset));\n\t\t}\n\t}\n\treturn nextRange;\n}", "CodeBleu_score": 31.017411932389578}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t", "CodeBleu_score": 3.709413387662834}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\n\tif (prevRange == null || prevRange.isEmpty()) {\n\t\t// if the previous range is empty, we need to initialize the map with the seek operations\n\t\tfor (Map.Entry<TopicPartition, Long> entry : seekOperations.getSeekTo().entrySet()) {\n\t\t\tnextRange.put(entry.getKey(), new FromToOffset(entry.getValue(), null));\n\t\t}\n\t} else {\n\t\t// if the previous range is not empty, we need to update the offsets\n\t\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n\t\t\tlong startOffset = entry.getValue().getFrom();\n\t\t\tlong endOffset = entry.getValue().getTo();\n\t\t\tlong numMessages = endOffset - startOffset + 1;\n\n\t\t\t// if the previous range is empty, we need to initialize the map with the seek operations\n\t\t\tif (numMessages <= 0) {\n\t\t\t\tnextRange.put(entry.getKey(), new FromToOffset(seekOperations.getSeekTo().get(entry.getKey()), null));\n\t\t\t} else {\n\t\t\t\tlong newStartOffset = startOffset + numMessages;\n\t\t\t\tnextRange.put(entry.getKey(), new FromToOffset(newStartOffset, null));\n\t\t\t}\n\t\t}\n\t}\n\n\t// calculate the number of messages to poll per partition\n\tint numMessagesPerPartition = (int) Math.ceil((double) pollTimeout / pollInterval);\n\n\t// for each topic partition, we need to determine the start offset and adjust it based on the number of messages to poll\n\tfor (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\n\t\tlong startOffset = entry.getValue().getFrom();\n\t\tlong endOffset = entry.getValue().getTo();\n\t\tlong numMessages = endOffset - startOffset + 1;\n\n\t\t// if the number of messages is less than the number of messages per partition, we need to poll all the messages\n\t\tif (numMessages < numMessagesPerPartition) {\n\t\t\tentry.getValue().setTo(null);\n\t\t} else {\n\t\t\tentry.getValue().setTo(startOffset + numMessagesPerPartition - 1);\n\t\t}\n\t}\n\n\treturn nextRange;\n}", "CodeBleu_score": 30.304846232672528}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\nif (configuration.containsKey(CK_ZOOKEEPER) && configuration.containsKey(CK_BOOTSTRAP)) {\nthrow new IllegalArgumentException(\"Cannot specify both \" + CK_ZOOKEEPER + \" and \" + CK_BOOTSTRAP);\n}\ndoLaunchLegacy(input);\n} else {\ndoLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read every second\nfinal ScheduledFuture<?> future = executor.scheduleWithFixedDelay(new Runnable() {\n@Override\npublic void run() {\nlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n}\n}, 1, 1, TimeUnit.SECONDS);\n\n// wait for the server to be running\nwhile (true) {\nfinal boolean running = server.isRunning();\nif (running) {\nbreak;\n}\ntry {\nThread.sleep(1000);\n} catch (InterruptedException e) {\nLOG.warn(\"Interrupted while waiting for server to start.\", e);\nThread.currentThread().interrupt();\n}\n}\n\n// register for lifecycle events\nserver.registerLifecycleListener(this);\n}", "CodeBleu_score": 45.09513026302777}, {"code": "public void doLaunch(final MessageInput input){\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\n    if (configuration.containsKey(CK_ZOOKEEPER)) {\n        if (configuration.containsKey(CK_BOOTSTRAP)) {\n            throw new IllegalArgumentException(\n                    \"Both \" + CK_ZOOKEEPER + \" and \" + CK_BOOTSTRAP + \" are configured, but only one can be used at a time.\");\n        }\n    } else if (!configuration.containsKey(CK_BOOTSTRAP)) {\n        throw new IllegalArgumentException(\n                \"Neither \" + CK_ZOOKEEPER + \" nor \" + CK_BOOTSTRAP + \" are configured, but one of them is required.\");\n    }\n    doLaunchLegacy(input);\n} else {\n    doLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read\nscheduler.scheduleAtFixedRate(new Runnable() {\n    @Override\n    public void run() {\n        lastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n    }\n}, 1, 1, TimeUnit.SECONDS);\n\n// wait for the server to be running\nif (!serverRunningLatch.await(configuration.getInt(CK_STARTUP_TIMEOUT_MS), TimeUnit.MILLISECONDS)) {\n    throw new IllegalStateException(\"Kafka server did not start within \" + configuration.getInt(CK_STARTUP_TIMEOUT_MS)\n            + \" ms, please check the server log for details.\");\n}\n\n// register for lifecycle events\nLifecycle.addLifecycleListener(this);\n\n// wait for the server to be stopped\ntry {\n    stopLatch.await();\n} catch (InterruptedException e) {\n    LOG.warn(\"Interrupted while waiting for Kafka server to stop.\");\n}\n\n// unregister for lifecycle events\nLifecycle.removeLifecycleListener(this);\n\n// shut down the consumer connection\nif (cc != null) {\n    cc.shutdown();\n}\n\n// shut down the executor\nexecutor.shutdown();\n\n// shut down the scheduler\nscheduler.shutdown();\n}", "CodeBleu_score": 39.383612477857554}, {"code": "public void doLaunch(final MessageInput input){\n\tif (configuration.getBoolean(CK_LEGACY_MODE)) {\n    if (configuration.getString(CK_ZOOKEEPER) == null) {\n        throw new IllegalArgumentException(\"Legacy mode requires zookeeper to be configured.\");\n    }\n    doLaunchLegacy(input);\n} else {\n    if (configuration.getString(CK_BOOTSTRAP) == null) {\n        throw new IllegalArgumentException(\"Consumer mode requires bootstrap servers to be configured.\");\n    }\n    doLaunchConsumer(input);\n}\n\n// schedule a task to update the last second bytes read\nfinal ScheduledFuture<?> future = executor.scheduleAtFixedRate(new Runnable() {\n    @Override\n    public void run() {\n        lastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n    }\n}, 1, 1, TimeUnit.SECONDS);\n\n// wait for the server to be running\nwaitForServerRunning();\n\n// register for lifecycle events\nregisterLifecycleEvents();\n}", "CodeBleu_score": 46.37223015080707}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\tString customProperties = getCustomProperties();\n\t\tif (customProperties != null) {\n\t\t\tProperties customProps = new Properties();\n\t\t\tcustomProps.load(new StringReader(customProperties));\n\t\t\tprops.putAll(customProps);\n\t\t}\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error loading custom properties\", e);\n\t}\n}", "CodeBleu_score": 44.12792621542405}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString customProperties = null;\n\ttry {\n\t\tcustomProperties = readCustomProperties();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error reading custom properties file: \" + e.getMessage());\n\t\treturn;\n\t}\n\tProperties customProps = new Properties();\n\ttry {\n\t\tcustomProps.load(new StringReader(customProperties));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error loading custom properties: \" + e.getMessage());\n\t\treturn;\n\t}\n\tfor (String key : customProps.stringPropertyNames()) {\n\t\tprops.setProperty(key, customProps.getProperty(key));\n\t}\n}", "CodeBleu_score": 37.6916599426045}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\t// Load the custom properties from the configuration string\n\t\tProperties customProps = new Properties();\n\t\tcustomProps.load(new StringReader(customProperties));\n\n\t\t// Merge the custom properties into the existing properties\n\t\tprops.putAll(customProps);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to load custom properties\", e);\n\t}\n}", "CodeBleu_score": 38.96188476083289}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null) {\n\t\treturn;\n\t}\n\n\tfinal List<Journal.Entry> journalEntries = new ArrayList<Journal.Entry>(entries.size());\n\tlong totalBytes = 0;\n\n\tfor (final RawMessageEvent entry : entries) {\n\t\tif (entry == null) {\n\t\t\tcontinue;\n\t\t}\n\n\t\tfinal Journal.Entry journalEntry = new Journal.Entry(entry.getTopic(), entry.getPartition(), entry.getOffset(), entry.getEvent());\n\t\tjournalEntries.add(journalEntry);\n\t\ttotalBytes += journalEntry.getEvent().getBody().length;\n\t}\n\n\ttry {\n\t\twriteToJournal(journalEntries);\n\t} catch (final InterruptedException e) {\n\t\tthrow new MessageQueueException(\"Interrupted while waiting to write to journal\", e);\n\t}\n\n\tmetrics.updateWrittenMessages(journalEntries.size());\n\tmetrics.updateWrittenBytes(totalBytes);\n}", "CodeBleu_score": 38.212783344927594}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries == null || entries.isEmpty()) {\n\t\treturn;\n\t}\n\n\tList<Journal.Entry> journalEntries = new ArrayList<>();\n\tlong totalBytes = 0;\n\tfor (RawMessageEvent event : entries) {\n\t\tif (event != null) {\n\t\t\tJournal.Entry entry = new Journal.Entry(event.getPartition(), event.getOffset(), event.getMessage());\n\t\t\tjournalEntries.add(entry);\n\t\t\ttotalBytes += event.getMessage().length;\n\t\t}\n\t}\n\n\tif (journalEntries.isEmpty()) {\n\t\treturn;\n\t}\n\n\t// Try to write the entries to the journal, and if it fails, retry using an exponential back-off strategy.\n\tlong backoffMs = 1;\n\twhile (true) {\n\t\ttry {\n\t\t\twriteToJournal(journalEntries);\n\t\t\tbreak;\n\t\t} catch (MessageQueueException e) {\n\t\t\tLOG.warn(\"Failed to write to journal, will retry in {} ms.\", backoffMs, e);\n\t\t\ttry {\n\t\t\t\tThread.sleep(backoffMs);\n\t\t\t} catch (InterruptedException ie) {\n\t\t\t\tLOG.warn(\"Interrupted while sleeping, will retry immediately.\", ie);\n\t\t\t}\n\n\t\t\tbackoffMs = Math.min(backoffMs * 2, 1000);\n\t\t}\n\t}\n\n\t// Update metrics.\n\tmetrics.updateWrittenMessages(journalEntries.size());\n\tmetrics.updateWrittenBytes(totalBytes);\n}", "CodeBleu_score": 35.424563619814045}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tList<Journal.Entry> journalEntries = new ArrayList<Journal.Entry>(entries.size());\n\tlong totalBytes = 0;\n\tfor (RawMessageEvent event : entries) {\n\t\tif (event == null) {\n\t\t\tcontinue;\n\t\t}\n\t\tbyte[] message = event.getMessage();\n\t\tif (message == null) {\n\t\t\tcontinue;\n\t\t}\n\t\ttotalBytes += message.length;\n\t\tjournalEntries.add(new Journal.Entry(event.getOffset(), message));\n\t}\n\tif (journalEntries.isEmpty()) {\n\t\treturn;\n\t}\n\twriteToJournal(journalEntries);\n\tmetrics.addMessagesWritten(journalEntries.size());\n\tmetrics.addBytesWritten(totalBytes);\n}", "CodeBleu_score": 24.958041481136334}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages == null || messages.isEmpty()) {\n\t\treturn;\n\t}\n\n\t// Identify the maximum valid message queue ID from the list of messages\n\tlong maxValidMessageQueueId = -1;\n\tfor (Message message : messages) {\n\t\tif (message.getMessageQueueId() > maxValidMessageQueueId && message.getStoreSize() > 0) {\n\t\t\tmaxValidMessageQueueId = message.getMessageQueueId();\n\t\t}\n\t}\n\n\t// If the maximum valid message queue ID is smaller than 0, it means that no valid message is found\n\tif (maxValidMessageQueueId < 0) {\n\t\treturn;\n\t}\n\n\t// Acknowledge the maximum valid message queue ID\n\ttry {\n\t\tthis.messageStore.ackMessage(maxValidMessageQueueId, this.getMessageQueue().getQueueId());\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to acknowledge the maximum valid message queue ID: \" + maxValidMessageQueueId, e);\n\t\treturn;\n\t}\n\n\t// Update the metrics\n\tthis.getBrokerController().getBrokerStatsManager().getSingleMessageTopicStats(this.getTopic()).getMsgCountAck().incrementAndGet();\n}", "CodeBleu_score": 19.78016302661451}, {"code": "public void acknowledge(List<Message> messages){\n\t\tlong maxValidMessageQueueId = 0L;\n\tfor (Message message : messages) {\n\t\tif (message.getQueueId() > maxValidMessageQueueId) {\n\t\t\tmaxValidMessageQueueId = message.getQueueId();\n\t\t}\n\t}\n\tif (maxValidMessageQueueId > 0) {\n\t\tacknowledge(maxValidMessageQueueId);\n\t}\n\tmetrics.markMessagesAcknowledged(messages.size());\n}", "CodeBleu_score": 22.122245735008235}, {"code": "public void acknowledge(List<Message> messages){\n\t\t// Get the maximum valid message queue ID from the list of messages\n\tlong maxMessageQueueId = 0;\n\tfor (Message message : messages) {\n\t\tif (message.getMessageQueueId() > maxMessageQueueId && message.getMessageQueueId() <= this.maxMessageQueueId) {\n\t\t\tmaxMessageQueueId = message.getMessageQueueId();\n\t\t}\n\t}\n\n\t// If the maximum valid message queue ID is greater than 0, then acknowledge it\n\tif (maxMessageQueueId > 0) {\n\t\tthis.ack(maxMessageQueueId);\n\t}\n\n\t// Update the metrics\n\tthis.metrics.ackedMessages(messages.size());\n}", "CodeBleu_score": 20.23185542698244}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t//            final String prefix = LocalKafkaJournal.class.getName();\n//            for (final Map.Entry<String, Metric> entry : this.metrics.entrySet()) {\n//                if (entry.getKey().startsWith(prefix)) {\n//                    final String legacyName = entry.getKey().substring(prefix.length());\n//                    try {\n//                        this.metricRegistry.register(legacyName, entry.getValue());\n//                    } catch (final IllegalArgumentException e) {\n//                        log.warn(\"Unable to register legacy metric {} under {}: {}\", entry.getKey(), legacyName, e.getMessage());\n//                    }\n//                }\n//            }\n}", "CodeBleu_score": 1.0472453922148197}, {"code": "private void registerLegacyMetrics(){\n\tfor (final MetricName metricName : this.metricRegistry.getNames()) {\nif (metricName.getName().startsWith(LocalKafkaJournal.class.getName())) {\ntry {\nthis.metricRegistry.register(LegacyMetricNameConverter.convert(metricName), this.metricRegistry.getMetrics().get(metricName));\n} catch (final Exception e) {\nLOGGER.warn(\"Unable to register legacy metric {}. This metric will not be available in the legacy metrics map.\", metricName, e);\n}\n}\n}\n}", "CodeBleu_score": 26.85386815634223}, {"code": "private void registerLegacyMetrics(){\n\tfor (final Map.Entry<String, Gauge> entry : this.metricRegistry.getGauges().entrySet()) {\nif (entry.getKey().startsWith(LocalKafkaJournal.class.getName() + \".\")) {\nfinal String legacyName = entry.getKey().substring(LocalKafkaJournal.class.getName().length() + 1);\ntry {\nthis.metricRegistry.register(legacyName, entry.getValue());\n} catch (final IllegalArgumentException e) {\nLOGGER.warn(\"Failed to register legacy metric {} under name {}.\", entry.getKey(), legacyName, e);\n}\n}\n}\n}", "CodeBleu_score": 43.641067233365405}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException iae) {\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 30.008947764975}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer hdrTimer = null;\n\ttry {\n\t\thdrTimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\thdrTimer = metricRegistry.timer(metricRegistry.getNames().get(metricRegistry.getNames().indexOf(metricName)));\n\t}\n\treturn hdrTimer;\n}", "CodeBleu_score": 35.02134420530828}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer hdrTimer = null;\n\ttry {\n\t\thdrTimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\thdrTimer = metricRegistry.getTimers().get(metricRegistry.getNames().get(metricName));\n\t}\n\treturn hdrTimer;\n}", "CodeBleu_score": 33.3476949528431}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n    metricRegistry.register(name, new Gauge<Integer>() {\n        @Override\n        public Integer getValue() {\n            long committedOffset = getCommittedOffset();\n            if (committedOffset == KafkaLog.INVALID_COMMITTED_OFFSET) {\n                return (int) (getLogEndOffset() - getLogStartOffset());\n            }\n            return (int) (getLogEndOffset() - committedOffset);\n        }\n    });\n} catch (IllegalArgumentException e) {\n    // ignore\n}\n}", "CodeBleu_score": 46.23737776126256}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(name, new Gauge<Long>() {\n                @Override\n                public Long getValue() {\n                    final long committedOffset = getCommittedOffset();\n                    if (committedOffset == DEFAULT_COMMITTED_OFFSET) {\n                        return Math.max(0, getLogEndOffset() - getLogStartOffset());\n                    } else {\n                        return Math.max(0, getLogEndOffset() - committedOffset);\n                    }\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            log.debug(\"Ignoring exception registering uncommitted gauge {}: {}\", name, e.getMessage());\n        }\n    }", "CodeBleu_score": 49.23437701559658}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n    metricRegistry.register(name, new Gauge<Long>() {\n        @Override\n        public Long getValue() {\n            try {\n                long committedOffset = getCommittedOffset();\n                if (committedOffset == -1) {\n                    return getLogEndOffset() - getLogStartOffset();\n                } else {\n                    return getLogEndOffset() - committedOffset;\n                }\n            } catch (Exception e) {\n                return 0L;\n            }\n        }\n    });\n} catch (IllegalArgumentException e) {\n    // ignore\n}\n}", "CodeBleu_score": 55.57818636228229}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tlogger.debug(\"No messages to flush\");\n\t\treturn -1;\n\t}\n\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages);\n\tlogger.debug(\"Writing {} bytes to Kafka log\", messageSet.sizeInBytes());\n\tlong startOffset = kafkaLog.append(messageSet);\n\tlogger.debug(\"Wrote {} messages to Kafka log starting at offset {}\", messages.size(), startOffset);\n\tmetrics.markMessages(messages.size());\n\tmetrics.markBytes(payloadSize);\n\treturn startOffset;\n}", "CodeBleu_score": 39.9539313526684}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tlogger.debug(\"No messages to flush\");\n\t\treturn -1;\n\t}\n\n\tlogger.debug(\"Flushing {} messages\", messages.size());\n\n\t// Create a message set from the list of messages\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, payloadSize, messages);\n\tlogger.debug(\"Created message set with {} bytes\", messageSet.sizeInBytes());\n\n\t// Append the message set to the Kafka log\n\tlong lastOffset = kafkaLog.append(messageSet);\n\tlogger.debug(\"Wrote message set to Kafka log at offset {}\", lastOffset);\n\n\t// Mark the number of messages written\n\tnumMessagesWritten += messages.size();\n\tlogger.debug(\"Marked {} messages as written\", numMessagesWritten);\n\n\treturn lastOffset;\n}", "CodeBleu_score": 41.33061699951014}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t\tif (messages.isEmpty()) {\n\t\tlogger.debug(\"No messages to write to Kafka\");\n\t\treturn lastOffset;\n\t}\n\n\tByteBufferMessageSet messageSet = new ByteBufferMessageSet(compressionCodec, messages);\n\tlong appendOffset = kafkaLog.append(messageSet);\n\tlogger.debug(\"Wrote {} messages to Kafka log at offset {}\", messageSet.sizeInBytes(), appendOffset);\n\tnumMessagesWritten += messageSet.sizeInBytes();\n\tlastOffset = appendOffset;\n\treturn appendOffset;\n}", "CodeBleu_score": 35.478661520348155}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u4f4fclientMap\uff0c\u4fdd\u8bc1\u7ebf\u7a0b\u5b89\u5168\n    synchronized (clientMap) {\n        List<AdminClient> adminClientList = clientMap.remove(clusterPhyId);\n        if (adminClientList == null) {\n            return;\n        }\n\n        boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n        if (allSuccess) {\n            LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n        }\n    }\n}", "CodeBleu_score": 49.19606124212536}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u4f4f\u5ba2\u6237\u7aef\u96c6\u5408\n    synchronized (this.clientMap) {\n        // \u4ece\u5ba2\u6237\u7aef\u96c6\u5408\u4e2d\u83b7\u53d6\u96c6\u7fa4\u7684\u5ba2\u6237\u7aef\u5217\u8868\n        List<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n\n        // \u5982\u679c\u5ba2\u6237\u7aef\u5217\u8868\u4e3a\u7a7a\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n        if (adminClientList == null) {\n            return;\n        }\n\n        // \u5173\u95ed\u5ba2\u6237\u7aef\u5217\u8868\n        boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n\n        // \u5982\u679c\u5173\u95ed\u5931\u8d25\uff0c\u5219\u4ece\u5ba2\u6237\u7aef\u5217\u8868\u4e2d\u79fb\u9664\n        if (!allSuccess) {\n            this.clientMap.remove(clusterPhyId);\n        }\n    }\n}", "CodeBleu_score": 30.23044274370547}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9a\u5ba2\u6237\u7aefmap\uff0c\u4ee5\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\nsynchronized (kafkaAdminClientMap) {\n    List<AdminClient> adminClientList = kafkaAdminClientMap.get(clusterPhyId);\n    if (adminClientList == null) {\n        return;\n    }\n\n    boolean allSuccess = closeAdminClientList(clusterPhyId, adminClientList);\n\n    if (allSuccess) {\n        LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n    } else {\n        LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n    }\n\n    kafkaAdminClientMap.remove(clusterPhyId);\n}\n}", "CodeBleu_score": 49.4277952935556}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close admin client for cluster {}.\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 63.48490215962643}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(Duration.ofSeconds(30));\n\t\t} catch (Exception e) {\n\t\t\tsuccess = false;\n\t\t\tlogger.error(\"Error closing Kafka AdminClient for cluster ID \" + clusterPhyId, e);\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 62.86710425073792}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true\n\tif (adminClientList == null) {\n\t\treturn true\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS)\n\t\t} catch (Exception e) {\n\t\t\tLOGGER.error(\"Error while closing AdminClient for cluster ID: \" + clusterPhyId, e)\n\t\t\tsuccess = false\n\t\t}\n\t}\n\treturn success\n}", "CodeBleu_score": 52.47849767729609}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (app != null)  {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0)  {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry  {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e)  {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.31292453614584}, {"code": "public void stop() {\n\t\tif (app != null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.73382833539546}, {"code": "public void stop() {\n\t\tif (app != null)  {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0)  {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry  {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e)  {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 94.31292453614584}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableTLS(true);\n\trunner.setKeystore(KEYSTORE_PATH, KEYSTORE_PASS);\n\trunner.setTruststore(TRUSTSTORE_PATH, TRUSTSTORE_PASS);\n\trunner.run();\n\treturn runner;\n}", "CodeBleu_score": 41.5269089961228}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerConfig serverConfig = new EurekaServerConfig(config);\n\tEurekaServerRunner eurekaServer = new EurekaServerRunner(serverConfig);\n\teurekaServer.enableSelfSignedHttps(serverConfig.getKeystore(), serverConfig.getKeystorePassword(), serverConfig.getTruststore(), serverConfig.getTruststorePassword());\n\teurekaServer.start();\n\treturn eurekaServer;\n}", "CodeBleu_score": 35.66685602517254}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t", "CodeBleu_score": 3.2210673266230256}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(server, config, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 59.169574299053885}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate and private key\n\tKeyAndCert ca = new KeyAndCert(CA_NAME, CA_PASSWORD);\n\tca.createKeyPair();\n\tca.createCert(ca.subject(), ca.subject());\n\tca.signCert(ca.subject());\n\n\t// Create a server certificate and private key\n\tKeyAndCert server = new KeyAndCert(SERVER_NAME, SERVER_PASSWORD);\n\tserver.createKeyPair();\n\tserver.createCert(ca.subject(), server.subject());\n\tserver.signCert(ca.subject());\n\n\t// Create a client certificate and private key\n\tKeyAndCert client = new KeyAndCert(CLIENT_NAME, CLIENT_PASSWORD);\n\tclient.createKeyPair();\n\tclient.createCert(ca.subject(), client.subject());\n\tclient.signCert(ca.subject());\n\n\t// Create a second CA certificate and private key\n\tKeyAndCert ca2 = new KeyAndCert(CA2_NAME, CA2_PASSWORD);\n\tca2.createKeyPair();\n\tca2.createCert(ca2.subject(), ca2.subject());\n\tca2.signCert(ca2.subject());\n\n\t// Create a second client certificate and private key\n\tKeyAndCert client2 = new KeyAndCert(CLIENT2_NAME, CLIENT2_PASSWORD);\n\tclient2.createKeyPair();\n\tclient2.createCert(ca2.subject(), client2.subject());\n\tclient2.signCert(ca2.subject());\n\n\t// Save the certificates and private keys\n\tsaveCert(ca);\n\tsaveCert(ca2);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 27.445874270606236}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate\n\tKeyAndCert ca = KeyTool.createCA(\"CA\");\n\t// Create a server certificate\n\tKeyAndCert server = KeyTool.createSignedCert(\"Server\", ca, \"127.0.0.1\");\n\t// Create a client certificate\n\tKeyAndCert client = KeyTool.createSignedCert(\"Client\", ca, \"127.0.0.1\");\n\t// Save the certificates\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveCert(client);\n\t// Create a second CA certificate\n\tKeyAndCert ca2 = KeyTool.createCA(\"CA2\");\n\t// Create a second client certificate\n\tKeyAndCert client2 = KeyTool.createSignedCert(\"Client2\", ca2, \"127.0.0.1\");\n\t// Save the certificates\n\tsaveCert(ca2);\n\tsaveCert(client2);\n\t// Create a key and certificate for the CA\n\tKeyAndCert ca3 = KeyTool.createCA(\"CA3\");\n\t// Save the certificate\n\tsaveCert(ca3);\n\t// Create a key and certificate for the client\n\tKeyAndCert client3 = KeyTool.createSignedCert(\"Client3\", ca3, \"127.0.0.1\");\n\t// Save the certificate\n\tsaveCert(client3);\n\t// Create a key and certificate for the server\n\tKeyAndCert server3 = KeyTool.createSignedCert(\"Server3\", ca3, \"127.0.0.1\");\n\t// Save the certificate\n\tsaveCert(server3);\n}", "CodeBleu_score": 37.855331414862185}, {"code": "static void createCertificates() throws Exception{\n\t\t// Create a CA certificate and key\n\tKeyAndCert ca = new KeyAndCert(\"ca\", \"ca\", \"ca\");\n\tca.createKeyPair();\n\tca.createSelfSignedCertificate();\n\n\t// Create a server certificate and key signed by the CA\n\tKeyAndCert server = new KeyAndCert(\"server\", \"server\", \"server\");\n\tserver.createKeyPair();\n\tserver.createSignedCertificate(ca);\n\n\t// Create a client certificate and key signed by the CA\n\tKeyAndCert client = new KeyAndCert(\"client\", \"client\", \"client\");\n\tclient.createKeyPair();\n\tclient.createSignedCertificate(ca);\n\n\t// Create a second CA certificate and key\n\tKeyAndCert ca2 = new KeyAndCert(\"ca2\", \"ca2\", \"ca2\");\n\tca2.createKeyPair();\n\tca2.createSelfSignedCertificate();\n\n\t// Create a client certificate and key signed by the second CA\n\tKeyAndCert client2 = new KeyAndCert(\"client2\", \"client2\", \"client2\");\n\tclient2.createKeyPair();\n\tclient2.createSignedCertificate(ca2);\n\n\t// Save the certificates and keys\n\tsaveCert(ca);\n\tsaveCert(ca2);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(client2);\n}", "CodeBleu_score": 29.30368510916293}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = seconds * 1000;\n\twhile (System.currentTimeMillis() - startTime < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tThread.sleep(100);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 44.4661839484604}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong start = System.currentTimeMillis();\n\tlong limit = start + seconds * 1000;\n\twhile (System.currentTimeMillis() < limit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tThread.yield();\n\t}\n\tthrow new RuntimeException(\"Assertion did not pass in \" + seconds + \" seconds\");\n}", "CodeBleu_score": 54.923203623831874}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = seconds * 1000L;\n\tlong currentTime = System.currentTimeMillis();\n\twhile (currentTime - startTime < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t\tcurrentTime = System.currentTimeMillis();\n\t}\n\tthrow new RuntimeException(\"Timed out after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 45.55907803178425}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\tbuilder.addExtension(Extension.subjectKeyIdentifier, false, createSubjectKeyId(keyPair.getPublic()));\n\tbuilder.addExtension(Extension.basicConstraints, false, new BasicConstraints(false));\n\tbuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 69.91505907291793}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate signCert = signCert(certBuilder(keyPair.getPublic(), ca, ca), keyPair.getPrivate());\n\n\treturn signCert;\n}", "CodeBleu_score": 33.226746787428354}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\tbuilder.addExtension(Extension.subjectKeyIdentifier, false, createSubjectKeyId(keyPair.getPublic()));\n\tbuilder.addExtension(Extension.authorityKeyIdentifier, false, createAuthorityKeyId(keyPair.getPublic()));\n\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 66.30083335422228}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField registrationClientField = EurekaTransport.class.getDeclaredField(\"registrationClient\");\n\t\t\tregistrationClientField.setAccessible(true);\n\t\t\tRegistrationClient registrationClient = (RegistrationClient) registrationClientField.get(eurekaTransport);\n\t\t\teurekaHttpClient = registrationClient.getEurekaHttpClient();\n\t\t} catch (IllegalAccessException e) {\n\t\t\tLOG.error(\"Error accessing EurekaHttpClient\", e);\n\t\t} catch (NoSuchFieldException e) {\n\t\t\tLOG.error(\"Error accessing EurekaHttpClient\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 50.78238093163419}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient != null) {\n\t\treturn eurekaHttpClient;\n\t}\n\ttry {\n\t\tField registrationClientField = EurekaTransport.class.getDeclaredField(\"registrationClient\");\n\t\tregistrationClientField.setAccessible(true);\n\t\tregistrationClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n\t\teurekaHttpClient = registrationClient;\n\t\treturn eurekaHttpClient;\n\t} catch (IllegalAccessException e) {\n\t\tlogger.error(\"Unable to access EurekaTransport.registrationClient field.\", e);\n\t} catch (NoSuchFieldException e) {\n\t\tlogger.error(\"Unable to access EurekaTransport.registrationClient field.\", e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 46.2314504939425}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) ReflectionUtils.getField(eurekaTransport, \"registrationClient\").get();\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlog.error(\"Cannot access registrationClient field of eurekaTransport\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 36.34843533197445}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications().getRegisteredApplications();\n\tif (applications != null) {\n\t\tfor (Application application : applications) {\n\t\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\t\tString name = instance.getAppName().toLowerCase();\n\t\t\t\tif (!services.contains(name)) {\n\t\t\t\t\tservices.add(name);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 44.34348559358946}, {"code": "public List<String> getServices(){\n\t\tList<String> services = new ArrayList<>();\n\tList<Application> applications = this.eurekaClient.getApplications().getRegisteredApplications();\n\tif (applications == null) {\n\t\treturn services;\n\t}\n\tfor (Application application : applications) {\n\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\tString name = instance.getAppName().toLowerCase();\n\t\t\tif (!services.contains(name)) {\n\t\t\t\tservices.add(name);\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 50.92123804312783}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tfor (InstanceInfo instance : application.getInstances()) {\n\t\t\tString vipAddress = instance.getVIPAddress();\n\t\t\tif (StringUtils.hasText(vipAddress)) {\n\t\t\t\tservices.add(vipAddress.toLowerCase());\n\t\t\t}\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 51.33459082352029}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor contributor = entry.getValue();\n\t\tif (contributor instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) contributor;\n\t\t\tfor (HealthIndicator indicator : discoveryCompositeHealthContributor.getIndicators()) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(entry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 43.131291934743054}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tMap<String, HealthContributor> tempHealthContributors = [:]\n\tfor (entry in healthContributors) {\n\t\tif (entry.value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tfor (indicator in entry.value.indicators) {\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\ttempHealthContributors[indicator.name] = indicator\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\ttempHealthContributors[entry.key] = entry.value\n\t\t}\n\t}\n\thealthContributors.clear()\n\thealthContributors.putAll(tempHealthContributors)\n}", "CodeBleu_score": 28.821554258393146}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor compositeContributor = (DiscoveryCompositeHealthContributor) value;\n\t\t\tMap<String, HealthContributor> indicators = compositeContributor.getContributorMap();\n\t\t\tfor (Map.Entry<String, HealthContributor> indicatorEntry : indicators.entrySet()) {\n\t\t\t\tHealthContributor indicator = indicatorEntry.getValue();\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(indicatorEntry.getKey(), indicator);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 40.420919788942136}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\t// Use the Discovery Client to find an instance of \"provider-application\"\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.size() == 0) {\n\t\tthrow new RuntimeException(\"No instances found for provider-application\");\n\t}\n\t// Use the first instance's URI to send a POST request to its \"/echo\" endpoint\n\tString url = instances.get(0).getUri() + \"/echo\";\n\tString response = restTemplate.postForObject(url, \"Hello, world!\", String.class);\n\treturn response;\n}", "CodeBleu_score": 54.30934172959895}, {"code": "public String hello(){\n\t\t// Create a Discovery Client and use it to find an instance of \"provider-application\"\n\tDiscoveryClient discoveryClient = new DiscoveryClient(\"http://localhost:8761/eureka\");\n\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\n\t// If no instances are found, throw a RuntimeException\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances found for 'provider-application'\");\n\t}\n\n\t// Send a POST request to the first instance's \"/echo\" endpoint\n\tString url = \"http://\" + instances.get(0).getHost() + \":\" + instances.get(0).getPort() + \"/echo\";\n\tResponseEntity<String> response = new RestTemplate().postForEntity(url, \"Hello World!\", String.class);\n\n\t// Return the response\n\treturn response.getBody();\n}", "CodeBleu_score": 48.24236891314884}, {"code": "public String hello(){\n\t\tString providerApplicationName = \"provider-application\";\n\tString echoUrl = null;\n\tString response = null;\n\n\ttry {\n\t\tList<ServiceInstance> serviceInstances = discoveryClient.getInstances(providerApplicationName);\n\t\tif (serviceInstances.size() > 0) {\n\t\t\tServiceInstance serviceInstance = serviceInstances.get(0);\n\t\t\techoUrl = String.format(\"http://%s:%s/echo\", serviceInstance.getHost(), serviceInstance.getPort());\n\t\t\tRestTemplate restTemplate = new RestTemplate();\n\t\t\tresponse = restTemplate.postForObject(echoUrl, \"Hello from the consumer\", String.class);\n\t\t} else {\n\t\t\tthrow new RuntimeException(String.format(\"No instances found for %s\", providerApplicationName));\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\n\treturn response;\n}", "CodeBleu_score": 53.39567791239832}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\tList<ServiceInstance> instances = loadBalancerClient.choose(\"provider-application\").get();\n\tif (instances != null && instances.size() > 0) {\n\t\tURI uri = UriComponentsBuilder.fromHttpUrl(instances.get(0).getUri().toString() + \"/echo\").build().toUri();\n\t\treturn restTemplate.postForObject(uri, \"Hello World\", String.class);\n\t}\n\tthrow new RuntimeException(\"No service instance found\");\n}", "CodeBleu_score": 55.110818722386554}, {"code": "public String world(){\n\t\tString response = null;\n\ttry {\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\t\tif (serviceInstance == null) {\n\t\t\tthrow new RuntimeException(\"No service instance found for 'provider-application'\");\n\t\t}\n\t\tString uri = String.format(\"http://%s:%s/echo\", serviceInstance.getHost(), serviceInstance.getPort());\n\t\tRestTemplate restTemplate = new RestTemplate();\n\t\tresponse = restTemplate.postForObject(uri, \"Hello World\", String.class);\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn response;\n}", "CodeBleu_score": 57.41231268442364}, {"code": "public String world(){\n\t\tServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n\tif (instance == null) {\n\t\tthrow new RuntimeException(\"No provider application instance found\");\n\t}\n\tString url = String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort());\n\treturn restTemplate.postForObject(url, \"Hello\", String.class);\n}", "CodeBleu_score": 50.0644667481323}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlog.info(\"Registered \" + ip + \":\" + port + \" for service \" + serviceName);\n\t\treturn true;\n\t}\n\telse {\n\t\tHashSet<Server> newSet = new HashSet<Server>();\n\t\tnewSet.add(new Server(ip, port));\n\t\tserverMap.put(serviceName, newSet);\n\t\tlog.info(\"Registered \" + ip + \":\" + port + \" for service \" + serviceName);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 48.12265430883499}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// Synchronize on the serverMap\n\tsynchronized (serverMap) {\n\t\t// If the service is not already registered\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\t// Create a new HashSet for the service\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t}\n\t\t// Add the new server to the service set\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\t// Log the registration\n\t\tlogger.info(\"Registered \" + serviceName + \" at \" + ip + \":\" + port);\n\t\t// Return true\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 46.066931807480906}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlog.info(\"Registered service \" + serviceName + \" with IP \" + ip + \" and port \" + port);\n\t\treturn true;\n\t}\n\telse {\n\t\tserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlog.info(\"Registered service \" + serviceName + \" with IP \" + ip + \" and port \" + port);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 44.80158937259851}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tserverMap.get(serviceName).remove(new Server(ip, port));\n\t\tlog.info(\"Deregistered \" + serviceName + \" \" + ip + \":\" + port);\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 33.17259279438149}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tServer server = serverMap.get(serviceName);\n\t\tif (server.getIp().equals(ip) && server.getPort().equals(port)) {\n\t\t\tlog.info(\"Deregistering server: \" + serviceName + \", \" + ip + \", \" + port);\n\t\t\tserverMap.get(serviceName).setRegistered(false);\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.64414609026937}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tif (serverMap.containsKey(serviceName)) {\n\t\tSet<Server> serverSet = serverMap.get(serviceName);\n\t\tIterator<Server> serverIterator = serverSet.iterator();\n\t\twhile (serverIterator.hasNext()) {\n\t\t\tServer server = serverIterator.next();\n\t\t\tif (server.getIp().equals(ip) && server.getPort().equals(port)) {\n\t\t\t\tlogger.info(\"Deregistering server: \" + server);\n\t\t\t\tserverIterator.remove();\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\treturn false;\n}", "CodeBleu_score": 43.09314440736475}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t//        AnnotationAttributes attributes = AnnotationAttributes.fromMap(metadata.getAnnotationAttributes(RibbonClients.class.getName(), true));\n//        if (attributes != null) {\n//            Map<String, Object> defaultConfig = attributes.getAnnotation(\"defaultConfiguration\", Map.class);\n//            if (defaultConfig != null) {\n//                String name = metadata.getClassName() + \".\" + defaultConfig.get(\"name\");\n//                registerClientConfiguration(registry, name, defaultConfig);\n//            }\n//            for (Map<String, Object> config : attributes.getAnnotationArray(\"value\")) {\n//                String name = metadata.getClassName() + \".\" + config.get(\"name\");\n//                registerClientConfiguration(registry, name, config);\n//            }\n//        }\n}", "CodeBleu_score": 4.661468346856617}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nString[] value = (String[]) attributes.get(\"value\");\nif (value.length > 0) {\nfor (String name : value) {\nregisterClientConfiguration(registry, name, null);\n}\n}\nString[] basePackages = (String[]) attributes.get(\"basePackages\");\nif (basePackages.length > 0) {\nregisterBasePackages(registry, basePackages);\n}\nString[] basePackageClasses = (String[]) attributes.get(\"basePackageClasses\");\nif (basePackageClasses.length > 0) {\nregisterBasePackageClasses(registry, basePackageClasses);\n}\n}", "CodeBleu_score": 40.34446128912362}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes != null) {\n\t\tString[] value = (String[]) attributes.get(\"value\");\n\t\tif (value != null) {\n\t\t\tfor (String s : value) {\n\t\t\t\tregisterClientConfiguration(registry, s, null);\n\t\t\t}\n\t\t}\n\t\tRibbonClientSpecification[] clients = (RibbonClientSpecification[]) attributes.get(\"clients\");\n\t\tif (clients != null) {\n\t\t\tfor (RibbonClientSpecification client : clients) {\n\t\t\t\tregisterClientConfiguration(registry, client.getName(), client.getConfiguration());\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 42.746817604894524}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// Get the load balancer for this service ID\n\tLoadBalancer loadBalancer = loadBalancers.get(serviceId);\n\tif (loadBalancer == null) {\n\t\treturn null;\n\t}\n\n\t// Get the server instance\n\tServer server = loadBalancer.chooseServer(request);\n\tif (server == null) {\n\t\treturn null;\n\t}\n\n\t// Return the service instance\n\treturn new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 57.896564652260906}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn choose(serviceId, request, null);\n}", "CodeBleu_score": 12.420362692234196}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString originalURI = original.toString();\n\tString originalPath = originalURI.substring(originalURI.indexOf(\"/\", 8));\n\tString reconstructedURI = \"http://\" + server.getHost() + \":\" + server.getPort() + originalPath;\n\tif (original.getQuery() != null) {\n\t\treconstructedURI += \"?\" + original.getQuery();\n\t}\n\ttry {\n\t\treturn new URI(reconstructedURI);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(\"Invalid URI syntax: \" + reconstructedURI, e);\n\t}\n}", "CodeBleu_score": 35.515943956041454}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tif (server == null)  {\n\t\tthrow new IllegalArgumentException(\"server cannot be null\");\n\t}\n\tif (original == null)  {\n\t\tthrow new IllegalArgumentException(\"original cannot be null\");\n\t}\n\n\tString scheme = original.getScheme();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString path = original.getRawPath();\n\tString query = original.getRawQuery();\n\tString fragment = original.getRawFragment();\n\n\ttry {\n\t\treturn new URI(scheme, null, host, port, path, query, fragment);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 41.61767355789831}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString uri = original.toString();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString scheme = original.getScheme();\n\tString path = original.getRawPath();\n\tString query = original.getRawQuery();\n\tString fragment = original.getRawFragment();\n\tif (query != null && !query.isEmpty()) {\n\t\turi = uri.replace(\"?\" + query, \"\");\n\t}\n\tif (fragment != null && !fragment.isEmpty()) {\n\t\turi = uri.replace(\"#\" + fragment, \"\");\n\t}\n\ttry {\n\t\turi = new URI(scheme, null, host, port, path, query, fragment).toString();\n\t}\n\tcatch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn URI.create(uri);\n}", "CodeBleu_score": 40.23742167538895}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\tString serviceName = \"tutu\";\n\tString serverAddress = \"http://discovery.tutum.co\";\n\n\t// Construct the URL\n\tString url = serverAddress + \"/list\";\n\turl += \"?service=\" + serviceName;\n\n\t// Send the request\n\tHttpResponse response = HttpRequest.get(url).header(\"Accept\", \"application/json\").send();\n\n\t// Parse the response\n\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\tif (response.isSuccessful()) {\n\t\ttry {\n\t\t\tJSONObject json = new JSONObject(response.body());\n\t\t\tJSONArray jsonArray = json.getJSONArray(\"Results\");\n\t\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\t\tJSONObject server = jsonArray.getJSONObject(i);\n\t\t\t\tString address = server.getString(\"Address\");\n\t\t\t\tint port = server.getInt(\"Port\");\n\t\t\t\tservers.add(new TutuServer(address, port));\n\t\t\t}\n\t\t} catch (JSONException e) {\n\t\t\te.printStackTrace();\n\t\t}\n\t}\n\treturn servers;\n}", "CodeBleu_score": 33.58810467900895}, {"code": "private List<TutuServer> getServer(){\n\t\tString url = \"http://\"+serverAddress+\"/list?serviceName=\"+serviceName;\n\tSystem.out.println(\"Server address: \"+url);\n\tList<TutuServer> servers = new ArrayList<TutuServer>();\n\ttry {\n\t\tURL obj = new URL(url);\n\t\tHttpURLConnection con = (HttpURLConnection) obj.openConnection();\n\t\tcon.setRequestMethod(\"GET\");\n\t\tint responseCode = con.getResponseCode();\n\t\tif (responseCode == 200) {\n\t\t\tBufferedReader in = new BufferedReader(new InputStreamReader(con.getInputStream()));\n\t\t\tString inputLine;\n\t\t\tStringBuffer response = new StringBuffer();\n\t\t\twhile ((inputLine = in.readLine()) != null) {\n\t\t\t\tresponse.append(inputLine);\n\t\t\t}\n\t\t\tin.close();\n\t\t\tString json = response.toString();\n\t\t\tSystem.out.println(\"Received JSON: \"+json);\n\t\t\tJSONObject jsonObject = new JSONObject(json);\n\t\t\tJSONArray jsonArray = jsonObject.getJSONArray(\"servers\");\n\t\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\t\tJSONObject jsonObj = jsonArray.getJSONObject(i);\n\t\t\t\tString ip = jsonObj.getString(\"ip\");\n\t\t\t\tint port = jsonObj.getInt(\"port\");\n\t\t\t\tTutuServer server = new TutuServer(ip, port);\n\t\t\t\tservers.add(server);\n\t\t\t}\n\t\t} else {\n\t\t\tSystem.out.println(\"GET request failed with error code \"+responseCode);\n\t\t}\n\t} catch (MalformedURLException e) {\n\t\te.printStackTrace();\n\t} catch (ProtocolException e) {\n\t\te.printStackTrace();\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t} catch (JSONException e) {\n\t\te.printStackTrace();\n\t}\n\treturn servers;\n}", "CodeBleu_score": 30.861163355381432}, {"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> serverList = new ArrayList<TutuServer>();\n\ttry {\n\t\tURL url = new URL(discoveryServiceAddress + \"/list?serviceName=\" + serviceName);\n\t\tHttpURLConnection connection = (HttpURLConnection) url.openConnection();\n\t\tconnection.setRequestMethod(\"GET\");\n\t\tconnection.setDoOutput(true);\n\t\tconnection.setDoInput(true);\n\t\tconnection.connect();\n\t\tInputStreamReader reader = new InputStreamReader(connection.getInputStream());\n\t\tBufferedReader in = new BufferedReader(reader);\n\t\tString inputLine;\n\t\tStringBuffer response = new StringBuffer();\n\t\twhile ((inputLine = in.readLine()) != null) {\n\t\t\tresponse.append(inputLine);\n\t\t}\n\t\tin.close();\n\t\treader.close();\n\t\tString responseString = response.toString();\n\t\tJSONArray jsonArray = new JSONArray(responseString);\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\t\t\tString ipAddress = jsonObject.getString(\"ipAddress\");\n\t\t\tint port = jsonObject.getInt(\"port\");\n\t\t\tTutuServer server = new TutuServer(ipAddress, port);\n\t\t\tserverList.add(server);\n\t\t}\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn serverList;\n}", "CodeBleu_score": 31.36518177623483}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tif (path == null) {\n\t\treturn null;\n\t}\n\tfor (Route route : routes) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = pathMatcher.extractPathWithinPattern(route.getPath(), path);\n\t\t\tif (route.getPath().endsWith(\"/\")) {\n\t\t\t\ttargetPath = targetPath + \"/\";\n\t\t\t}\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 35.087763248426576}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (Route route : routes) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = path.replaceFirst(route.getPath(), \"\");\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 28.677955213630256}, {"code": "public Route getMatchingRoute(String path){\n\t\tif (pathMatcher == null) {\n\t\tpathMatcher = new AntPathMatcher();\n\t}\n\tfor (Route route : routes) {\n\t\tif (pathMatcher.match(route.getPath(), path)) {\n\t\t\tString targetPath = pathMatcher.extractPathWithinPattern(route.getPath(), path);\n\t\t\treturn new Route(targetPath, route.getServiceId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.234802393440525}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tMap<String, Object> attributes = importingClassMetadata.getAnnotationAttributes(EnableFeignClients.class.getName());\n\tregisterBeanDefinitions(importingClassMetadata, registry, attributes);\n}", "CodeBleu_score": 11.82762053633798}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
