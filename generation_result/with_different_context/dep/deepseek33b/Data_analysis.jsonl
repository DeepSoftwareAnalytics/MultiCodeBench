{"instance_id": "58936b2a621b", "generation_result": [{"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n", "CodeBleu_score": 83.87646776544821}, {"code": "def set_model_params(model: LogisticRegression, params: NDArrays) -> LogisticRegression\n\t\n    model.coef_ = params[0]\n    if model.fit_intercept:\n        model.intercept_ = params[1]\n    return model\n\n\n\n\n", "CodeBleu_score": 83.87646776544821}]}
{"instance_id": "83b142d9d251", "generation_result": [{"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n\n    # Split the data and labels into training and testing sets\n    x_train, x_test, y_train, y_test = train_test_split(\n        data, label, test_size=support_ratio, random_state=42, stratify=label\n    )\n\n    # Return the training and testing sets\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 68.12968840831522}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n\n    return x_train, x_test, y_train, y_test\n\n", "CodeBleu_score": 65.30740775035834}, {"code": "def support_query_split(\n    data,\n    label,\n    support_ratio: float,\n) -> Tuple[List, List, List, List]\n\t\n    x_train, x_test, y_train, y_test = train_test_split(\n        data,\n        label,\n        test_size=1 - support_ratio,\n        random_state=42,\n        stratify=label,\n    )\n    return x_train, x_test, y_train, y_test\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 65.30740775035834}]}
{"instance_id": "5fd02b540f61", "generation_result": [{"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    # Generate dataset\n    X, y = make_regression(n_samples=1000, n_features=3, random_state=42)\n\n    # Split dataset into training and testing sets\n    X, X_test, y, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n    return X, y, X_test, y_test\n\n", "CodeBleu_score": 52.08914289469184}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=100, n_features=3, random_state=1)\n    X_test, y_test = make_regression(\n        n_samples=100, n_features=3, random_state=1\n    )\n    return X, y, X_test, y_test\n\n", "CodeBleu_score": 44.29887636028768}, {"code": "def load_data() -> (\n    Tuple[List[np.ndarray], List[np.ndarray], List[np.ndarray], List[np.ndarray]]\n)\n\t\n    X, y = make_regression(n_samples=100, n_features=3, random_state=42)\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42\n    )\n    return X_train, y_train, X_test, y_test\n\n", "CodeBleu_score": 38.988730693271556}]}
{"instance_id": "ad958cb31a57", "generation_result": [{"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(ndarrays[0], ndarrays[1], ndarrays[2], ndarrays[3], ndarrays[4])\n\n", "CodeBleu_score": 28.988763610480394}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n", "CodeBleu_score": 79.03672928896962}, {"code": "def ndarrays_to_gmmparam(ndarrays: NDArray) -> GMMParameters\n\t\n    return GMMParameters(\n        label=ndarrays[0],\n        means=ndarrays[1],\n        weights=ndarrays[2],\n        covariances=ndarrays[3],\n        num_samples=ndarrays[4],\n    )\n\n\n\n\n", "CodeBleu_score": 79.03672928896962}]}
{"instance_id": "061d5a5b9d56", "generation_result": [{"code": "def datafiles_fusion(data_paths):\n\t\n    # Load the first data file\n    X, Y = load_svmlight_file(data_paths[0])\n\n    # Convert the features to a dense array\n    X = X.toarray()\n\n    # Iterate over the remaining data files\n    for path in data_paths[1:]:\n        # Load the data file\n        X_new, Y_new = load_svmlight_file(path)\n\n        # Check if the number of features matches the first file\n        if X_new.shape[1] != X.shape[1]:\n            raise ValueError(\n                \"Number of features in file {} does not match the first file\".format(path))\n\n        # Concatenate the new features and labels to the existing arrays\n        X = np.concatenate((X, X_new.toarray()), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n\n    return X, Y\n\n", "CodeBleu_score": 36.03050855775024}, {"code": "def datafiles_fusion(data_paths):\n\t\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n    for path in data_paths[1:]:\n        X_new, Y_new = load_svmlight_file(path)\n        X_new = X_new.toarray()\n        assert X.shape[1] == X_new.shape[1]\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n    return X, Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.73434046030095}, {"code": "def datafiles_fusion(data_paths):\n\t\n    # Load the first data file\n    X, Y = load_svmlight_file(data_paths[0])\n    X = X.toarray()\n\n    # Load the remaining data files and concatenate the features and labels\n    for data_path in data_paths[1:]:\n        X_new, Y_new = load_svmlight_file(data_path)\n        X_new = X_new.toarray()\n\n        # Ensure the number of features matches the first file\n        if X_new.shape[1] != X.shape[1]:\n            raise ValueError(\"Number of features in {} does not match the first file.\".format(data_path))\n\n        # Concatenate the new features and labels to the existing arrays\n        X = np.concatenate((X, X_new), axis=0)\n        Y = np.concatenate((Y, Y_new), axis=0)\n\n    return X, Y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.9824260496776}]}
{"instance_id": "977d3bd5d5a3", "generation_result": [{"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n\n", "CodeBleu_score": 54.6058043693212}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average=\"micro\")\n    precision = precision_score(y_test, y_pred, average=\"micro\")\n    f1 = f1_score(y_test, y_pred, average=\"micro\")\n    return accuracy, recall, precision, f1\n\n\n\n\n", "CodeBleu_score": 61.39499773490273}, {"code": "def eval_learning(y_test, y_pred)\n\t\n    from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n    accuracy = accuracy_score(y_test, y_pred)\n    recall = recall_score(y_test, y_pred, average='micro')\n    precision = precision_score(y_test, y_pred, average='micro')\n    f1 = f1_score(y_test, y_pred, average='micro')\n    return accuracy, recall, precision, f1\n\n", "CodeBleu_score": 54.6058043693212}]}
{"instance_id": "f4c838f1f092", "generation_result": [{"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()\n\n", "CodeBleu_score": 72.89324029568995}, {"code": "def train(model, train_loader, num_epochs=1)\n\t\n    criterion = nn.BCELoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n    model.train()\n    for epoch in range(num_epochs):\n        for X_batch, y_batch in train_loader:\n            optimizer.zero_grad()\n            outputs = model(X_batch)\n            loss = criterion(outputs, y_batch)\n            loss.backward()\n            optimizer.step()", "CodeBleu_score": 72.89324029568995}]}
{"instance_id": "35068c779c02", "generation_result": [{"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    if cfg.dataset.type != \"LIBSVM\":\n        raise RuntimeError(\"Dataset type must be LIBSVM\")\n\n    dataset_path = cfg.dataset.path\n    dataset_name = cfg.dataset.name\n\n    # Load data\n    data, labels = load_svmlight_file(dataset_path)\n    data = data.todense().astype(np.float32)\n    labels = labels.astype(np.float32)\n\n    # Print unique labels and their counts\n    unique_labels, counts = np.unique(labels, return_counts=True)\n    print(f\"Unique labels: {unique_labels}\")\n    print(f\"Label counts: {counts}\")\n    print(f\"Shape of features: {data.shape}\")\n\n    # Remap labels for MUSHROOMS dataset\n    if dataset_name == \"MUSHROOMS\":\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(\"Dataset name must be MUSHROOMS\")\n\n    return TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 46.485780609403506}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\"\n    path = cfg.dataset.path\n    name = cfg.dataset.name\n\n    data, labels = load_svmlight_file(f\"{path}/{name}\")\n    data = data.todense().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(np.unique(labels, return_counts=True))\n    print(data.shape)\n\n    if name == \"MUSHROOMS\":\n        labels = labels.copy()\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(\"Dataset name not supported\")\n\n    return TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n", "CodeBleu_score": 31.871618509390732}, {"code": "def _load_libsvm_dataset(cfg: DictConfig) -> Dataset\n\t\n    assert cfg.dataset.type == \"LIBSVM\"\n    path = cfg.dataset.path\n    name = cfg.dataset.name\n\n    data, labels = load_svmlight_file(os.path.join(path, name))\n    data = data.todense().astype(np.float32)\n    labels = labels.astype(np.int32)\n    print(\"unique labels:\", np.unique(labels, return_counts=True))\n    print(\"data shape:\", data.shape)\n\n    if name == \"MUSHROOMS\":\n        labels[labels == 1] = 0\n        labels[labels != 0] = 1\n    else:\n        raise RuntimeError(f\"Unknown dataset {name}\")\n\n    return TensorDataset(torch.from_numpy(data), torch.from_numpy(labels))\n\n", "CodeBleu_score": 31.327743380477713}]}
{"instance_id": "d602a96e571e", "generation_result": [{"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}, {"code": "def _fit_transform_one(transformer, X, y, weight, **fit_params)\n\t\n    if hasattr(transformer, \"fit_transform\"):\n        res = transformer.fit_transform(X, y, **fit_params)\n    else:\n        res = transformer.fit(X, y, **fit_params).transform(X)\n    if weight is None:\n        return res, transformer\n    return res * weight, transformer\n\n", "CodeBleu_score": 88.84159847409744}]}
{"instance_id": "fcf88a773fd8", "generation_result": [{"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', dtype=None)\n\n    if issparse(X) and not isspmatrix_csc(X):\n        X = X.tocsc()\n\n    n_features = X.shape[1]\n\n    if selected == \"all\":\n        return transform(X)\n    elif len(selected) == 0:\n        return X\n    elif not all(isinstance(f, (int, np.integer)) for f in selected):\n        raise ValueError(\"When passing selected features as a list of strings\"\n                         \" via the 'categorical_features' keyword argument,\"\n                         \" all elements must be integers.\")\n    elif max(selected) >= n_features or min(selected) < 0:\n        raise ValueError(\"Selected features must be a subset of the features\"\n                         \" in X, which has {} features.\".format(n_features))\n\n    ind_sorted = sorted(selected)\n    selected_mask = np.zeros(n_features, dtype=bool)\n    selected_mask[ind_sorted] = True\n    non_selected_mask = ~selected_mask\n\n    X_sel = transform(X[:, ind_sorted])\n    X_not_sel = X[:, non_selected_mask]\n\n    if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n        return sparse.hstack((X_sel, X_not_sel), format='csr')\n    else:\n        return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 47.800893969625825}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse='csc', dtype=None)\n\n    if isinstance(selected, six.string_types) and selected == \"all\":\n        return transform(X)\n\n    if len(selected) == 0:\n        return X\n\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n\n    if n_selected == 0:\n        # No features selected.\n        return X\n    elif n_selected == n_features:\n        # All features selected.\n        return transform(X)\n    else:\n        X_sel = transform(X[:, ind[sel]])\n        X_not_sel = X[:, ind[not_sel]]\n\n        if sp.issparse(X_sel) or sp.issparse(X_not_sel):\n            return sp.hstack((X_sel, X_not_sel), format='csr')\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 77.6324930640567}, {"code": "def _transform_selected(X, transform, selected=\"all\", copy=True)\n\t\n    X = check_array(X, accept_sparse=\"csc\", force_all_finite=False)\n    if selected == \"all\":\n        return transform(X)\n    elif len(selected) == 0:\n        return X\n    n_features = X.shape[1]\n    ind = np.arange(n_features)\n    sel = np.zeros(n_features, dtype=bool)\n    sel[np.asarray(selected)] = True\n    not_sel = np.logical_not(sel)\n    n_selected = np.sum(sel)\n\n    if n_selected == 0:\n        # No features selected.\n        return X\n    elif n_selected == n_features:\n        # All features selected.\n        return transform(X)\n    else:\n        X_sel = transform(X[:, ind[sel]])\n        X_not_sel = X[:, ind[not_sel]]\n\n        if sparse.issparse(X_sel) or sparse.issparse(X_not_sel):\n            return sparse.hstack((X_sel, X_not_sel), format=\"csr\")\n        else:\n            return np.hstack((X_sel, X_not_sel))\n\n", "CodeBleu_score": 75.28373109742003}]}
{"instance_id": "c9dfb00047d1", "generation_result": [{"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, dtype=None)\n    n_samples, n_features = X.shape\n\n    X_int, X_mask = _transform_selected(X, self._all_features_indices,\n                                        self._encode)\n\n    n_categories = [len(cats) for cats in self.categories_]\n    indices = _transform_selected(X_int, self._all_features_indices,\n                                  lambda X, cats: _encode_python(X, uniques=cats))\n    indptr = np.asarray([0] + list(np.cumsum(n_categories)))\n\n    data = (np.ones(n_samples) if self.sparse else np.ones(len(indices)))\n\n    return _infer_feature_names_tags(self, X,\n                                     names=self._get_feature_names_out(\n                                         input_features=self.input_features_),\n                                     dtype=X.dtype)(\n                                         csr_matrix((data, indices, indptr),\n                                                    shape=(n_samples, len(indptr) - 1),\n                                                    dtype=self.dtype))\n\n", "CodeBleu_score": 28.40748547533918}, {"code": "def _transform_new(self, X)\n\t\n    X_temp = check_array(X, dtype=None)\n    if not hasattr(X, 'dtype') and np.issubdtype(X_temp.dtype, np.str_):\n        X = check_array(X, dtype=np.object)\n    else:\n        X = X_temp\n\n    _, n_features = X.shape\n    X_int = np.zeros_like(X, dtype=np.int)\n    X_mask = np.ones_like(X, dtype=np.bool)\n\n    for i in range(n_features):\n        Xi = X[:, i]\n        valid_mask = np.in1d(Xi, self.categories_[i])\n\n        if not np.all(valid_mask):\n            if self.handle_unknown == 'error':\n                diff = np.unique(X[~valid_mask, i])\n                msg = (\"Found unknown categories {0} in column {1}\"\n                       \" during transform\".format(diff, i))\n                raise ValueError(msg)\n            else:\n                # Set the problematic rows to an acceptable value and\n                # continue `The rows are marked `X_mask` and will be\n                # removed later.\n                X_mask[:, i] = valid_mask\n                Xi = Xi.copy()\n                Xi[~valid_mask] = self.categories_[i][0]\n        X_int[:, i] = self._label_encoders_[i].transform(Xi)\n\n    n_values = [cats.shape[0] for cats in self.categories_]\n    n_values = np.array([0] + n_values)\n    indices = np.cumsum(n_values)\n\n    column_indices = (X_int + indices[:-1]).ravel()\n    row_indices = np.repeat(np.arange(X.shape[0], dtype=np.int32), X.shape[1])\n    data = np.ones(X.shape[0] * X.shape[1], dtype=np.int32)\n\n    out =", "CodeBleu_score": 49.42298479210766}, {"code": "def _transform_new(self, X)\n\t\n    X = check_array(X, dtype=None)\n    n_samples, n_features = X.shape\n\n    X_int, X_mask = _transform_selected(X, self._transformers,\n                                       dtype=np.int64)\n    X_mask = X_mask.ravel()\n\n    n_values = [cats.shape[0] for cats in self.categories_]\n    n_values = np.array([0] + n_values)\n    indices = np.cumsum(n_values)\n\n    column_indices = (X_int + indices[:-1]).ravel()[X_mask]\n    row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n                           n_features)[X_mask]\n    data = np.ones(n_samples * n_features)[X_mask]\n\n    out = sparse.csr_matrix((data, (row_indices, column_indices)),\n                            shape=(n_samples, indices[-1]),\n                            dtype=self.dtype).astype(self.dtype)\n    if not self.sparse:\n        out = out.toarray()\n    return out\n\n", "CodeBleu_score": 37.66299115948312}]}
{"instance_id": "fcde391a8972", "generation_result": [{"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.lower, self.upper)\n    return uniform(self.lower, self.upper)\n\n", "CodeBleu_score": 23.343095470548864}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return scipy.stats.loguniform(self.lower, self.upper)\n    else:\n        return scipy.stats.uniform(self.lower, self.upper)\n\n\n\n", "CodeBleu_score": 23.814079087046558}, {"code": "def convert_to_sklearn(self)\n\t\n    if self.log:\n        return loguniform(self.low, self.high)\n    else:\n        return uniform(self.low, self.high)\n\n\n\n", "CodeBleu_score": 19.856461573598768}]}
{"instance_id": "5d5413adcca6", "generation_result": [{"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers:\n        self._render_header(state, \"Partial Dependence Plots\")\n    fig, ax = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.pd_kwargs}\n    if self.two_way:\n        data = state.X.copy()\n        data = data.loc[data[features[0]].notnull() & data[features[1]].notnull()]\n    else:\n        data = state.X\n    PartialDependenceDisplay.from_estimator(state.model, data, features, ax=ax, **kwargs)\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 52.86159556968612}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers is not None:\n        display_header(self.headers, 3)\n\n    fig, axes = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.predefined_kw}\n    if self.two_way:\n        state.data = state.data.dropna(subset=self.features)\n    display = PartialDependenceDisplay.from_estimator(\n        state.model,\n        state.data,\n        features,\n        ax=axes,\n        **kwargs,\n    )\n    plt.tight_layout()\n    plt.show()", "CodeBleu_score": 48.33955150858495}, {"code": "def _render(self, state: AnalysisState) -> None\n\t\n    additional_kwargs, fig_args, features = self._get_args()\n    if self.headers is not None:\n        self._render_header(state, self.headers)\n    fig, axes = plt.subplots(**fig_args)\n    kwargs = {**additional_kwargs, **self.kwargs}\n    if self.two_way:\n        X = state.X.copy()\n        X = X[X[features[0]].notnull() & X[features[1]].notnull()]\n        kwargs[\"X\"] = X\n    PartialDependenceDisplay.from_estimator(state.model, state.X, features, ax=axes, **kwargs)\n    plt.tight_layout()\n    plt.show()\n\n", "CodeBleu_score": 45.7192365091271}]}
{"instance_id": "db8aac29180b", "generation_result": [{"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}, {"code": "def _preprocess(self, X, **kwargs)\n\t\n    X = super()._preprocess(X, **kwargs)\n    if self._feature_generator is None:\n        self._feature_generator = LabelEncoderFeatureGenerator(verbosity=0)\n        self._feature_generator.fit(X=X)\n    if self._feature_generator.features_in:\n        X = X.copy()\n        X[self._feature_generator.features_in] = self._feature_generator.transform(X=X)\n    X = X.fillna(0).to_numpy(dtype=np.float32)\n    return X\n\n", "CodeBleu_score": 79.5391784405486}]}
{"instance_id": "d4eb45e6d013", "generation_result": [{"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # Retrieve model parameters\n    num_classes = kwargs.get('num_classes', None)\n    if num_classes is None:\n        num_classes = self._get_num_classes(y=kwargs.get('y', None))\n    num_rows = X.shape[0]\n    num_cols = X.shape[1]\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    num_estimators = self._get_num_estimators(num_classes=num_classes)\n    if num_estimators < 40 or self.params_to_try is not None:\n        num_estimators = 40\n    # Estimate bytes used per estimator\n    bytes_per_estimator = (num_rows * num_cols * 8 * 2.5) + ((num_rows * num_cols) * 2) + (50 * num_cols * 8) + (num_rows * num_trees_per_estimator * 12)\n    bytes_per_estimator *= 1.25\n    # Calculate expected minimum memory usage\n    expected_memory_usage = num_estimators * bytes_per_estimator\n    return expected_memory_usage\n\n", "CodeBleu_score": 43.91579441219}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    # Get model parameters\n    params = self.get_params()\n    # Determine the final number of estimators\n    if self.n_jobs == -1:\n        num_jobs = cpu_count()\n    else:\n        num_jobs = self.n_jobs\n    if self.min_samples_leaf is None:\n        self.min_samples_leaf = 1\n    if self.max_samples is None:\n        self.max_samples = 1.0\n    if self.max_samples < 1.0:\n        self.max_samples = int(self.max_samples * X.shape[0])\n    if self.max_samples > X.shape[0]:\n        self.max_samples = X.shape[0]\n    if self.max_samples < 1.0:\n        self.max_samples = 1\n    if self.n_estimators is None:\n        if self.search_spaces is None:\n            self.n_estimators = 40\n        else:\n            self.n_estimators = 1\n    # Get the number of trees per estimator\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    # Estimate the bytes used per estimator\n    bytes_per_estimator = (\n        X.shape[0] * X.shape[1] * 8\n        + self.max_samples * X.shape[1] * 8\n        + (self.max_samples * X.shape[1] * 8) * num_trees_per_estimator\n    )\n    # Adjust for the number of jobs\n    bytes_per_estimator *= num_jobs\n    # Adjust for the number of estimators\n    if self.n_estimators is None:\n        if self.search_spaces is None:\n            min_estimators = 40\n        else:\n            min_estimators = 1\n    else:\n        min_estimators = self.n_estimators\n    if min_estimators < 40:\n        min_estimators = 40\n    # Calculate the expected minimum memory usage", "CodeBleu_score": 34.81557995080808}, {"code": "def _estimate_memory_usage(self, X, **kwargs)\n\t\n    if self.memory_allocation is None:\n        return None\n\n    if self.problem_type in [MULTICLASS, SOFTCLASS]:\n        if self.num_classes is None:\n            num_classes = len(np.unique(y))\n        else:\n            num_classes = self.num_classes\n        if num_classes < 10:\n            self.params[\"num_classes\"] = num_classes\n    else:\n        self.params[\"num_classes\"] = 1\n\n    if self.search_spaces is not None:\n        num_estimators = 40\n    else:\n        num_estimators = self.params.get(\"n_estimators\", 100)\n        num_estimators = max(num_estimators, 40)\n\n    num_trees_per_estimator = self._get_num_trees_per_estimator()\n    bytes_per_estimator = self._estimate_bytes_per_estimator(X, num_trees_per_estimator)\n\n    expected_minimum_memory_usage = bytes_per_estimator * num_estimators\n    return expected_minimum_memory_usage\n\n", "CodeBleu_score": 43.97343407873459}]}
{"instance_id": "6923cb007f4c", "generation_result": [{"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    import numpy as np\n    import pandas as pd\n    from collections import Counter\n    # Create a Counter object from the n-gram frequency data\n    ngram_counter = Counter(ngram_freq)\n\n    # Identify the top n most common n-grams according to the specified vocabulary size\n    top_ngrams = [ngram for ngram, count in ngram_counter.most_common(vocab_size)]\n\n    # Sort the names of the top n n-grams\n    top_ngrams = sorted(top_ngrams)\n\n    # Create a new vocabulary dictionary mapping each n-gram to a unique index\n    new_vocab = {ngram: i for i, ngram in enumerate(top_ngrams)}\n\n    # Update the vectorizer's vocabulary with the new, downsized vocabulary\n    vectorizer.vocabulary_ = new_vocab\n\n    return vectorizer\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.031543284774735}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n\n    # Create a Counter object from the n-gram frequency data\n    ngram_counter = Counter(ngram_freq)\n\n    # Identify the top n most common n-grams according to the specified vocabulary size\n    top_ngrams = ngram_counter.most_common(vocab_size)\n\n    # Sort the names of these top n n-grams\n    sorted_ngrams = sorted(top_ngrams, key=lambda x: x[0])\n\n    # Create a new vocabulary dictionary, mapping each n-gram to a unique index\n    new_vocab = {ngram: i for i, (ngram, _) in enumerate(sorted_ngrams)}\n\n    # Update the vectorizer's vocabulary with this new, downsized vocabulary\n    vectorizer.vocabulary_ = new_vocab\n\n\n\n\n\n", "CodeBleu_score": 34.37547860020737}, {"code": "def downscale_vectorizer(vectorizer, ngram_freq, vocab_size)\n\t\n    from collections import Counter\n    # Create a Counter object from the n-gram frequency data\n    ngram_counter = Counter(ngram_freq)\n    # Identify the top n most common n-grams\n    top_ngrams = ngram_counter.most_common(vocab_size)\n    # Sort the names of the top n n-grams\n    sorted_ngrams = sorted(top_ngrams, key=lambda x: x[0])\n    # Create a new vocabulary dictionary mapping each n-gram to a unique index\n    new_vocab = {ngram: idx for idx, (ngram, _) in enumerate(sorted_ngrams)}\n    # Update the vectorizer's vocabulary with the new, downsized vocabulary\n    vectorizer.vocabulary_ = new_vocab\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.962231954956025}]}
{"instance_id": "0e837b2d8088", "generation_result": [{"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = {}\n    skewness_threshold = self.params['skewness_threshold']\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            feature_types[feature] = 'skewed'\n        else:\n            feature_types[feature] = 'continuous'\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.142594841491025}, {"code": " def _select_continuous(self, df, features)\n\t\n    feature_types = {}\n    skewness_threshold = self.parameters.get(\"skewness_threshold\", 0.9)\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            if \"skewed\" not in feature_types:\n                feature_types[\"skewed\"] = []\n            feature_types[\"skewed\"].append(feature)\n        else:\n            if \"continuous\" not in feature_types:\n                feature_types[\"continuous\"] = []\n            feature_types[\"continuous\"].append(feature)\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.05591405216656}, {"code": " def _select_continuous(self, df, features)\n\t\n\n    feature_types = {}\n    skewness_threshold = self.params[\"skewness_threshold\"]\n    for feature in features:\n        skewness = df[feature].skew()\n        if abs(skewness) > skewness_threshold:\n            if \"skewed\" not in feature_types:\n                feature_types[\"skewed\"] = []\n            feature_types[\"skewed\"].append(feature)\n        else:\n            if \"continuous\" not in feature_types:\n                feature_types[\"continuous\"] = []\n            feature_types[\"continuous\"].append(feature)\n    return feature_types\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 44.23967812296319}]}
{"instance_id": "bb569c10f975", "generation_result": [{"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        weights = dist.copy()\n        inf_mask = np.isinf(weights)\n        inf_row = np.any(inf_mask, axis=1)\n        weights[inf_row] = inf_mask[inf_row]\n        return weights\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\"weights not recognized: should be 'uniform', \"\n                         \"'distance', or a callable function\")\n\n\n\n\n", "CodeBleu_score": 63.440453794001975}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    if weights == \"distance\":\n        weights = np.ma.masked_array(dist, mask=np.isinf(dist))\n        weights = 1.0 / weights\n        _fix_null_denominator(weights)\n        return weights\n    if callable(weights):\n        return weights(dist)\n    raise ValueError(\n        \"weights not recognized: should be 'uniform', \"\n        \"'distance', or a callable function\"\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.30888043768129}, {"code": "def _get_weights(dist, weights):\n\t\n    if weights is None or weights == \"uniform\":\n        return None\n    elif weights == \"distance\":\n        weights = np.ma.masked_array(1.0 / dist, mask=np.isinf(dist))\n        _fix_null_denominator(weights)\n        return weights\n    elif callable(weights):\n        return weights(dist)\n    else:\n        raise ValueError(\n            \"weights not recognized: should be 'uniform', \"\n            \"'distance', or a callable function\"\n        )\n\n\n\n", "CodeBleu_score": 52.37051591054791}]}
{"instance_id": "12aaa9c78402", "generation_result": [{"code": "def predict_loo(self)\n\t\n\n    distances, indices = self.kneighbors(self._X)\n    weights = self._get_weights(distances)\n\n    if self._y.ndim == 1:\n        self._y = self._y.reshape(-1, 1)\n\n    if self.weights == 'uniform':\n        predictions = np.mean(self._y[indices], axis=1)\n    else:\n        predictions = np.sum(self._y[indices] * weights, axis=1) / np.sum(weights, axis=1)\n\n    if self._y.ndim == 1:\n        predictions = predictions.flatten()\n\n    return predictions\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.830420190470115}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors(self._X)\n    weights = self._get_weights(distances)\n    if self._y.ndim == 1:\n        self._y = self._y.reshape(-1, 1)\n    predictions = np.zeros_like(self._y)\n    for i in range(self._X.shape[0]):\n        neighbors = indices[i, :]\n        if self.weights == \"uniform\":\n            predictions[i] = np.mean(self._y[neighbors], axis=0)\n        else:\n            predictions[i] = np.sum(\n                self._y[neighbors] * weights[i, :], axis=0\n            ) / np.sum(weights[i, :])\n    if self._y.ndim == 1:\n        predictions = predictions.flatten()\n    return predictions\n\n\n", "CodeBleu_score": 35.90108232005472}, {"code": "def predict_loo(self)\n\t\n    distances, indices = self.kneighbors(self._X)\n    weights = self._get_weights(distances)\n    if self._y.ndim == 1:\n        self._y = self._y.reshape(-1, 1)\n    predictions = np.zeros((self._X.shape[0], self._y.shape[1]))\n    for i in range(self._X.shape[0]):\n        if self.weights == 'uniform':\n            predictions[i] = np.mean(self._y[indices[i]], axis=0)\n        else:\n            predictions[i] = np.sum(self._y[indices[i]] * weights[i], axis=0) / np.sum(weights[i])\n    if self._y.shape[1] == 1:\n        predictions = predictions.flatten()\n    return predictions\n\n", "CodeBleu_score": 35.82127934046869}]}
{"instance_id": "b316687d9e9b", "generation_result": [{"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        data = input_data[i]\n        ir = IsotonicRegression(out_of_bounds=\"clip\", increasing=True)\n        y_ = ir.fit_transform(quantile_list, data)\n        transformed_data.append(y_)\n    transformed_data = np.stack(transformed_data)\n    return transformed_data\n\n", "CodeBleu_score": 37.58009056420802}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        y = input_data[i]\n        ir = IsotonicRegression(y_min=0.0, y_max=1.0, increasing=True)\n        y_ = ir.fit_transform(quantile_list, y)\n        transformed_data.append(y_)\n    transformed_data = np.stack(transformed_data)\n    return transformed_data\n\n\n\n", "CodeBleu_score": 37.66416980618981}, {"code": "def isotonic(input_data, quantile_list)\n\t\n    quantile_list = np.array(quantile_list).reshape(-1)\n    batch_size = input_data.shape[0]\n    transformed_data = []\n    for i in range(batch_size):\n        data = input_data[i]\n        ir = IsotonicRegression(out_of_bounds=\"clip\")\n        y_ = ir.fit_transform(quantile_list, data)\n        transformed_data.append(y_)\n    transformed_data = np.stack(transformed_data, axis=0)\n    return transformed_data\n\n", "CodeBleu_score": 37.97476575431288}]}
{"instance_id": "17566e088b4e", "generation_result": [{"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_text = vectorizer.transform(text_data)\n    return vectorizer, vectorized_text\n\n\n", "CodeBleu_score": 45.22807051565422}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    return vectorizer, vectorizer.transform(text_data)\n\n\n", "CodeBleu_score": 40.6826747095547}, {"code": "def _train_vectorizer(text_data: list, vectorizer)\n\t\n    vectorizer.fit(text_data)\n    vectorizer.stop_words_ = None\n    vectorized_text = vectorizer.transform(text_data)\n    return vectorizer, vectorized_text\n\n\n\n", "CodeBleu_score": 45.22807051565422}]}
{"instance_id": "be23c0afc2d6", "generation_result": [{"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Drop rows with missing entries\n    df = df[df.ne(\"--\").all(axis=1)]\n\n    # Drop columns with unique values less than or equal to 1\n    df = df.loc[:, df.nunique() > 1]\n\n    # Drop columns with \"id\" in their name\n    df = df.loc[:, ~df.columns.str.contains(\"id\")]\n\n    # Drop shortcut columns\n    df = df.drop([\"days_to_death\", \"year_of_death\"], axis=1)\n\n    # Split the data into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n    return train_df, test_df\n\n\n\n", "CodeBleu_score": 23.380329826898}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    df = df.dropna(subset=[\"date_of_death\"])\n    df = df.dropna(subset=[\"date_of_birth\"])\n    df = df.dropna(subset=[\"cause_of_death\"])\n    df = df.dropna(subset=[\"age_at_death\"])\n    df = df.dropna(subset=[\"sex\"])\n    df = df.dropna(subset=[\"place_of_death\"])\n    df = df.dropna(subset=[\"marital_status\"])\n    df = df.dropna(subset=[\"year_of_death\"])\n    df = df.dropna(subset=[\"month_of_death\"])\n    df = df.dropna(subset=[\"day_of_death\"])\n    df = df.dropna(subset=[\"age_recode_12\"])\n    df = df.dropna(subset=[\"race_recode_3\"])\n    df = df.dropna(subset=[\"race_recode_5\"])\n    df = df.dropna(subset=[\"icd_recode\"])\n    df = df.dropna(subset=[\"icd_code\"])\n    df = df.dropna(subset=[\"cause_recode_39\"])\n    df = df.dropna(subset=[\"cause_recode_113\"])\n    df = df.dropna(subset=[\"number_of_entries\"])\n    df = df.dropna(subset=[\"last_visit_days\"])\n    df = df.dropna(subset=[\"last_visit_months\"])\n    df = df.dropna(subset=[\"last_visit_years\"])\n    df = df.dropna(subset=[\"last_visit_weeks\"])\n    df = df.dropna(subset=[\"last_visit_status\"])\n    df = df.dropna(subset=[\"last_visit_days_after_death\"])\n    df = df.dropna(subset=[\"last_visit_months_after_death\"])\n    df = df.dropna(subset=[\"", "CodeBleu_score": 15.180282768973024}, {"code": "def preprocess(df, test_size, shuffle)\n\t\n    # Remove rows with missing entries marked by '--'\n    df = df[~df.eq('--').any(axis=1)]\n\n    # Drop columns with unique values less than or equal to 1 or containing 'id' in their name\n    df = df.drop(columns=[col for col in df.columns if df[col].nunique() <= 1 or 'id' in col.lower()])\n\n    # Drop shortcut columns like 'days_to_death' and 'year_of_death'\n    df = df.drop(columns=[col for col in df.columns if 'days_to_death' in col.lower() or 'year_of_death' in col.lower()])\n\n    # Split the dataframe into training and testing sets\n    train_df, test_df = train_test_split(df, test_size=test_size, shuffle=shuffle)\n\n    return train_df, test_df\n\n\n\n", "CodeBleu_score": 31.28072013824336}]}
{"instance_id": "6a82997a8c59", "generation_result": [{"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, make_sparse=sparse)\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n    classifier = classifier(random_state=1, **default)\n    classifier.iterative_fit(X_train, Y_train, n_iter=2, refit=True)\n    for iter in [4, 8, 16, 32, 64]:\n        classifier.iterative_fit(X_train, Y_train, n_iter=iter, refit=False)\n    pred = classifier.predict(X_test)\n    return pred, Y_test, classifier\n\n", "CodeBleu_score": 25.13041295521924}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, make_sparse=sparse)\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n\n    classifier = classifier(\n        random_state=np.random.RandomState(1),\n        **{\n            hp_name: default[hp_name]\n            for hp_name in default\n            if default[hp_name] is not None\n        },\n    )\n\n    # make sure the hyperparameters are working so we can later\n    # test the iterative fitting\n    for i in range(2):\n        classifier.iterative_fit(X_train, Y_train, n_iter=1, refit=True)\n\n    while not classifier.configuration_fully_fitted():\n        classifier.iterative_fit(X_train, Y_train, n_iter=2 ** (i + 1), refit=False)\n        i += 1\n\n    prediction = classifier.predict(X_test)\n    return prediction, Y_test, classifier\n\n", "CodeBleu_score": 36.51707900044432}, {"code": "def _test_classifier_iterative_fit(classifier, dataset=\"iris\", sparse=False)\n\t\n    X_train, Y_train, X_test, Y_test = get_dataset(dataset, make_sparse=sparse)\n    cs = classifier.get_hyperparameter_search_space()\n    default = cs.get_default_configuration()\n    classifier = classifier(configuration=default, random_state=1)\n\n    # Adjust parameter if the iris dataset is used for a\n    # binary classification problem\n    if dataset == \"iris\" and len(np.unique(Y_train)) == 2:\n        default[\"max_depth\"] = 1\n        classifier.set_hyperparameters(default)\n\n    # Make sure the hyperparameters are correctly\n    # set\n    params = classifier.get_hyperparameters()\n    for p in default:\n        assert p in params\n        assert params[p] == default[p]\n\n    # Test fit()\n    train_losses = []\n    iterations = []\n    start_time = time.time()\n    iterations_ = 1\n    for iter_ in range(10):\n        classifier.fit(X_train, Y_train, iterations=iterations_)\n        iterations.append(iterations_)\n        iterations_ *= 2\n        train_losses.append(sklearn.metrics.log_loss(Y_train, classifier.predict_proba(X_train)))\n        if time.time() - start_time > 10:\n            break\n\n    assert classifier.get_max_iter() > 0\n    assert len(train_losses) > 1\n\n    # Test refit\n    classifier.fit(X_train, Y_train, refit=False)\n    train_losses_2 = sklearn.metrics.log_loss(Y_train, classifier.predict_proba(X_train))\n    assert train_losses[-1] != train_losses_2\n\n    classifier.fit(X_train, Y_train, refit=True)\n    train_losses_3 = sklearn.metrics.log_loss(Y_train, classifier.predict_proba(X_train))\n    assert train_losses[-1] == train_loss", "CodeBleu_score": 34.389608971119365}]}
{"instance_id": "d0d8450c4c17", "generation_result": [{"code": "def _load_models(self)\n\t\n    if self.ensemble_ is not None:\n        self.ensemble_.load_models(backend=self._backend, seed=self._seed)\n\n    if self.ensemble_ is None and self.evaluator_output_ is not None:\n        if (\n            self.evaluator_output_.get(\"ensemble_size\") > 0\n            and self.resampling_strategy_ != \"holdout\"\n        ):\n            self.ensemble_ = self._load_best_individual_model()\n\n    if self.ensemble_ is None:\n        self.models_ = []\n        self.cross_validated_models_ = None\n        return\n\n    self.model_identifiers_ = self.ensemble_.get_selected_model_identifiers()\n    self.models_ = self._backend.load_models_by_identifiers(\n        self.model_identifiers_, self.model_directory\n    )\n\n    if self.resampling_strategy_ in [\"cv\", \"partial_cv\"]:\n        self.cross_validated_models_ = self._backend.load_models_by_identifiers(\n            self.model_identifiers_, self.model_directory, cv=True\n        )\n    else:\n        self.cross_validated_models_ = None\n\n", "CodeBleu_score": 45.963345287984765}, {"code": "def _load_models(self)\n\t\n    if self.ensemble_ is not None:\n        self.ensemble_ = self.backend.load_ensemble(self.ensemble_, self.seed)\n\n    if (\n        self.ensemble_ is None\n        and self.evaluator_output_ is not None\n        and self.evaluator_output_.has_ensemble()\n        and self.resampling_strategy_ is not None\n    ):\n        self.ensemble_ = self._load_best_individual_model()\n\n    if self.ensemble_ is not None:\n        self.model_identifiers_ = self.ensemble_.get_identifiers_with_weights()\n        self.models_ = self.backend.load_models(\n            self.model_identifiers_, self.seed, self.task\n        )\n\n        if self.resampling_strategy_ in [\n            ResamplingStrategyEnum.cv,\n            ResamplingStrategyEnum.partial_cv,\n        ]:\n            self.cross_validated_models_ = self.backend.load_cross_validated_models(\n                self.model_identifiers_, self.seed, self.task\n            )\n        else:\n            self.cross_validated_models_ = None\n    else:\n        self.model_identifiers_ = []\n        self.models_ = []\n        self.cross_validated_models_ = None\n\n", "CodeBleu_score": 49.18745321162613}, {"code": "def _load_models(self)\n\t\n    # Load the ensemble if it is defined\n    if self.ensemble_ is not None:\n        self.ensemble_ = self.backend.load_ensemble(self.ensemble_, self.seed)\n\n    # If the ensemble is not loaded and certain evaluator output conditions and resampling strategies are met, load the best individual model instead\n    if self.ensemble_ is None and self.evaluator_output_ is not None:\n        if self.evaluator_output_.get(\"resampling_strategy\") == \"holdout\":\n            if self.evaluator_output_.get(\"evaluation_result\") is not None:\n                self.ensemble_ = self.backend.load_best_individual_model(self.seed)\n\n    # If the ensemble is successfully loaded, retrieve model identifiers and load the corresponding models using the backend\n    if self.ensemble_ is not None:\n        model_identifiers = self.ensemble_.get_selected_model_identifiers()\n        self.models_ = self.backend.load_models_by_identifiers(model_identifiers)\n\n    # For specific resampling strategies, load cross-validated models; otherwise, set the cross-validated models to None\n    if self.evaluator_output_ is not None:\n        if self.evaluator_output_.get(\"resampling_strategy\") == \"cv\":\n            self.cross_validated_models_ = self.backend.load_cross_validated_models(\n                self.ensemble_, self.seed\n            )\n        else:\n            self.cross_validated_models_ = None\n\n    # If no ensemble is loaded, initialize empty lists for models and cross-validated models\n    if self.ensemble_ is None:\n        self.models_ = []\n        self.cross_validated_models_ = None", "CodeBleu_score": 51.84798425307693}]}
{"instance_id": "ef71b1cddb50", "generation_result": [{"code": "def load_task(task_id)\n\t\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n\n    dataset = task.get_dataset()\n    _, categorical_indicator = dataset.get_data(\n        target=dataset.default_target_attribute\n    )\n\n    label_to_index = {label: index for index, label in enumerate(set(y))}\n    y_train = np.array([label_to_index[label] for label in y_train])\n    y_test = np.array([label_to_index[label] for label in y_test])\n\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 42.80591902255586}, {"code": "def load_task(task_id)\n\t\n\n    # Load task\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n\n    # Get train-test split indices\n    train_indices, test_indices = task.get_train_test_split_indices()\n\n    # Create training and testing sets\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n\n    # Fetch dataset\n    dataset = openml.datasets.get_dataset(task.dataset_id)\n\n    # Determine categorical or numerical nature of each feature\n    categorical_indicator = [\n        dataset.get_feat_type(i) == \"nominal\" for i in range(X.shape[1])\n    ]\n\n    # Map unique label values to integer indices\n    label_mapping = {label: i for i, label in enumerate(np.unique(y))}\n    y_train = np.array([label_mapping[label] for label in y_train])\n    y_test = np.array([label_mapping[label] for label in y_test])\n\n    return X_train, y_train, X_test, y_test, categorical_indicator\n\n", "CodeBleu_score": 47.77323452861439}, {"code": "def load_task(task_id)\n\t\n    import openml\n    import numpy as np\n    task = openml.tasks.get_task(task_id)\n    X, y = task.get_X_and_y()\n    train_indices, test_indices = task.get_train_test_split_indices()\n    X_train = X[train_indices]\n    y_train = y[train_indices]\n    X_test = X[test_indices]\n    y_test = y[test_indices]\n    dataset = task.get_dataset()\n    _, categorical = dataset.get_features_by_type()\n    is_categorical = [feat.name in categorical for feat in dataset.features.values()]\n    map_dict = {val: i for i, val in enumerate(np.unique(y_train))}\n    y_train = np.array([map_dict[val] for val in y_train])\n    y_test = np.array([map_dict[val] for val in y_test])\n    return X_train, y_train, X_test, y_test, is_categorical\n\n\n", "CodeBleu_score": 62.57603025501688}]}
{"instance_id": "90bd6edbcc9e", "generation_result": [{"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if isinstance(y, SUPPORTED_SPARSE_TYPES):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 55.660117565945924}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if issparse(y):\n        if y.ndim == 1:\n            return y.toarray().flatten()\n        else:\n            return y.toarray()\n    elif isinstance(y, pd.DataFrame):\n        return y.values\n    elif isinstance(y, pd.Series):\n        return y.values\n    elif isinstance(y, list):\n        return np.array(y)\n    else:\n        return y\n\n", "CodeBleu_score": 38.46293970908617}, {"code": "def convert_if_sparse(\n    y: SUPPORTED_TARGET_TYPES,\n) -> Union[np.ndarray, List, pd.DataFrame, pd.Series]\n\t\n    if issparse(y):\n        y = y.toarray()\n        if y.ndim == 1:\n            y = y.flatten()\n    return y\n\n", "CodeBleu_score": 51.91134492159348}]}
{"instance_id": "5728e3d4f914", "generation_result": [{"code": "def _calculate_weights(self) -> None\n\t\n    # Count the occurrences of each ensemble member index\n    counts = Counter(self.ensemble_members)\n    # Initialize weights array with zeros\n    self.weights_ = np.zeros(len(self.input_models_))\n    # Calculate weights based on occurrences\n    for i, count in counts.items():\n        weight = count / len(self.ensemble_members)\n        self.weights_[i] = weight\n    # Normalize weights if their sum is less than 1\n    if np.sum(self.weights_) < 1:\n        self.weights_ /= np.sum(self.weights_)\n\n", "CodeBleu_score": 26.196809534916927}, {"code": "def _calculate_weights(self) -> None\n\t\n    weights = np.zeros(len(self.models_))\n    for ensemble_member in self.ensemble_members_:\n        weights[ensemble_member] += 1\n    weights = weights / len(self.ensemble_members_)\n    if np.sum(weights) < 1:\n        weights = weights / np.sum(weights)\n    self.weights_ = weights", "CodeBleu_score": 41.86891593144912}, {"code": "def _calculate_weights(self) -> None\n\t\n    weights = np.zeros(len(self.models_))\n    for i in range(len(self.models_)):\n        weights[i] = np.count_nonzero(self.ensemble_members_ == i) / len(self.ensemble_members_)\n    if np.sum(weights) < 1:\n        weights = weights / np.sum(weights)\n    self.weights_ = weights\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.2013186234403}]}
{"instance_id": "4f9c4799fd8f", "generation_result": [{"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_proba = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_proba, axis=1), 1)\n    assert np.all((0 <= y_proba) & (y_proba <= 1))\n    return y_proba\n\n", "CodeBleu_score": 31.539810435392635}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_pred_proba = super(AutoSklearnClassifier, self).predict_proba(\n        X, batch_size=batch_size, n_jobs=n_jobs\n    )\n    if self.automl_._common.target_type != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_pred_proba, axis=1), 1)\n    assert np.all(y_pred_proba <= 1.0)\n    assert np.all(y_pred_proba >= 0.0)\n    return y_pred_proba\n\n", "CodeBleu_score": 29.209299370991527}, {"code": "def predict_proba(self, X, batch_size=None, n_jobs=1)\n\t\n    y_pred_proba = super().predict_proba(X, batch_size=batch_size, n_jobs=n_jobs)\n    if self.target_type_ != \"multilabel-indicator\":\n        assert np.allclose(np.sum(y_pred_proba, axis=1), 1.0)\n    assert np.all((0.0 <= y_pred_proba) & (y_pred_proba <= 1.0))\n    return y_pred_proba\n\n", "CodeBleu_score": 31.37449494786478}]}
{"instance_id": "a9a13150aebe", "generation_result": [{"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return Ybin.dot(np.arange(Ybin.shape[1]))\n\n\n\n", "CodeBleu_score": 27.13397993791789}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return np.dot(Ybin, range(Ybin.shape[1]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.043052488809614}, {"code": "def convert_to_num(Ybin: np.ndarray) -> np.ndarray:\n\t\n    if Ybin.ndim == 1:\n        return Ybin\n    else:\n        return Ybin.dot(np.arange(Ybin.shape[1]))\n\n", "CodeBleu_score": 27.13397993791789}]}
{"instance_id": "e97d38e62f81", "generation_result": [{"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params\n\n", "CodeBleu_score": 98.02795049070139}, {"code": "def fit_transformer(self, X, y, fit_params=None)\n\t\n    if fit_params is None:\n        fit_params = {}\n\n    if self.config[\"balancing:strategy\"] == \"weighting\":\n        balancing = Balancing(strategy=\"weighting\")\n        _init_params, _fit_params = balancing.get_weights(\n            y,\n            self.config[\"classifier:__choice__\"],\n            self.config[\"feature_preprocessor:__choice__\"],\n            {},\n            {},\n        )\n        _init_params.update(self.init_params)\n        self.set_hyperparameters(\n            feat_type=self.feat_type,\n            configuration=self.config,\n            init_params=_init_params,\n        )\n\n        if _fit_params is not None:\n            fit_params.update(_fit_params)\n\n    X, fit_params = super().fit_transformer(X, y, fit_params=fit_params)\n\n    return X, fit_params", "CodeBleu_score": 98.02795049070139}]}
{"instance_id": "b1aaad80a9c4", "generation_result": [{"code": "def test_glm_identity_link_func()\n\t\n    from pyspark.sql import SparkSession\n    spark = SparkSession.builder.appName(\"test_glm_identity_link_func\").getOrCreate()\n    from pysparkling.ml import GLM\n    from pysparkling.ml.util import assemble_expr\n    import numpy as np\n    import pandas as pd\n    import statsmodels.api as sm\n    import statsmodels.formula.api as smf\n    from pyspark.ml.linalg import Vectors\n    from pyspark.sql.types import DoubleType, StructField, StructType\n    from pyspark.ml.feature import VectorAssembler\n    from pyspark.ml import Pipeline\n    from pyspark.sql.functions import col\n    # Create a small dataset\n    data = [(1.0, 2.0),\n            (2.0, 3.0),\n            (3.0, 4.0),\n            (4.0, 5.0),\n            (5.0, 6.0)]\n    df = spark.createDataFrame(data, [\"x\", \"y\"])\n    # Convert the dataset to a Pandas DataFrame\n    pdf = df.toPandas()\n    # Fit the GLM model using Statsmodels\n    sm_model = smf.glm(\"y ~ x\", data=pdf, family=sm.families.Tweedie(var_power=1.0, link=sm.genmod.families.links.identity)).fit()\n    # Convert the fitted model to an expression representation using the assembler\n    assembler = VectorAssembler(inputCols=[\"x\"], outputCol=\"features\")\n    glm = GLM(family=\"tweedie\", link=\"identity\", featuresCol=\"features\", labelCol=\"y\", maxIter=10, regParam=0.0, variancePower=1.0)\n    pipeline = Pipeline(stages=[assembler, glm])\n    model = pipeline.fit(df)\n    assembler_expr = assemble_expr(model)\n    # Compare the assembled expression to an expected expression\n    assert as", "CodeBleu_score": 36.897412940211446}, {"code": "def test_glm_identity_link_func()\n\t\n    from pyspark.sql import SparkSession\n    spark = SparkSession.builder.getOrCreate()\n    from pysparkling.ml import GLM\n    from pysparkling.ml import VectorAssembler\n    from pyspark.ml.linalg import Vectors\n    from pyspark.sql.types import *\n    import numpy as np\n\n    # Create a dataset\n    data = [\n        (1.0, Vectors.dense(1.0), 1.0),\n        (2.0, Vectors.dense(2.0), 2.0),\n        (3.0, Vectors.dense(3.0), 3.0),\n        (4.0, Vectors.dense(4.0), 4.0),\n        (5.0, Vectors.dense(5.0), 5.0)\n    ]\n    df = spark.createDataFrame(data, [\"label\", \"features\", \"weight\"])\n\n    # Define the GLM model\n    glm = GLM(family=\"tweedie\", link=\"power\", linkPower=1.0)\n\n    # Fit the model\n    model = glm.fit(df)\n\n    # Assemble the model\n    assembler = VectorAssembler(inputCols=[\"features\"], outputCol=\"assembled_features\")\n    assembled_df = assembler.transform(df)\n    assembled_df = assembled_df.select(\"label\", \"assembled_features\", \"weight\")\n\n    # Convert the fitted model into an expression representation\n    expression = model.assemble()\n\n    # Assert that the assembled expression matches the expected expression\n    expected_expression = \"1.0 + features[0] * 1.0\"\n    assert expression == expected_expression\n\n\n\n", "CodeBleu_score": 36.9960617392503}, {"code": "def test_glm_identity_link_func()\n\t\n    pass\n\n", "CodeBleu_score": 0.33783783783783783}]}
{"instance_id": "bcab63e592d0", "generation_result": [{"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    # If the aggregation is provided as a tuple, extract the name and function\n    if isinstance(agg, tuple):\n        name, func = agg\n    else:\n        # Determine the name from the string or function name\n        name = agg.__name__ if hasattr(agg, \"__name__\") else str(agg)\n        func = agg\n\n    # Construct the new column name based on the original column name and the aggregation name\n    new_col_name = f\"{col.name}_{name}\"\n\n    # Apply the aggregation to the grouped DataFrame\n    result = self.groupby(col.name)[col.name].agg(func)\n\n    # Reset the index to include the new column name\n    result = result.reset_index(name=new_col_name)\n\n    return result\n\n", "CodeBleu_score": 55.2341577820615}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n\n    if isinstance(agg, tuple):\n        name, func = agg\n    else:\n        name = agg if isinstance(agg, str) else agg.__name__\n        func = agg\n\n    new_col = f\"{col}__{name}\"\n\n    return self.groupby(col, group_keys=False)[new_col].apply(func)", "CodeBleu_score": 62.59047899441785}, {"code": "def _compute_aggregation(\n        self, col: Variable, agg: Union[str, Callable, Tuple[str, Union[str, Callable]]]\n    ) -> pd.Series\n\t\n    if isinstance(agg, tuple):\n        agg_name, agg_func = agg\n    else:\n        agg_name = agg if isinstance(agg, str) else agg.__name__\n        agg_func = agg\n\n    new_col_name = f\"{col}__{agg_name}\"\n    return self.groupby(col, as_index=False)[col].agg(agg_func).rename(\n        columns={col: new_col_name}\n    )\n\n\n\n", "CodeBleu_score": 56.81545114588178}]}
{"instance_id": "114d623dae7b", "generation_result": [{"code": "def _corrfunc(self, x, y, **kws)\n\t\n    kws.pop(\"color\", None)\n    color = kws.get(\"color\")\n    ax = plt.gca()\n    if color is None:\n        hue_axis = self._hue_axes.get(ax, {})\n        nhues = len(hue_axis)\n        hue_idx = hue_axis.get(color, nhues - 1)\n        anot_kws = dict(\n            ha=\"center\",\n            va=\"center\",\n            multialignment=\"center\",\n            fontsize=12 / (nhues + 1),\n        )\n        anot_kws.update(kws.get(\"annot_kws\", {}))\n        fmt_str = anot_kws.pop(\"fmt\", \"2.2f\")\n        r, p = stats.pearsonr(x, y)\n        r_text = f\"r={r:{fmt_str}}\"\n        xo = np.mean(ax.get_xlim())\n        yo = np.mean(ax.get_ylim())\n        yo += np.diff(ax.get_ylim())[0] * 0.12 * (hue_idx + 1)\n        ax.text(xo, yo, r_text, **anot_kws)\n    else:\n        ax.set_title(f\"r={r:.2f}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.017586346644}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import seaborn as sns\n    import pandas as pd\n    from scipy.stats import pearsonr\n\n    # Get the axis object\n    if \"ax\" in kws:\n        ax = kws[\"ax\"]\n    elif \"axes\" in kws:\n        ax = kws[\"axes\"]\n    else:\n        ax = plt.gca()\n\n    # Get the hue group\n    if \"hue\" in kws:\n        hue = kws[\"hue\"]\n    else:\n        hue = None\n\n    # Get the data\n    if hue is None:\n        x = x.dropna()\n        y = y.dropna()\n    else:\n        df = pd.concat([x, y, hue], axis=1)\n        df = df.dropna()\n        x = df[x.name]\n        y = df[y.name]\n\n    # Calculate the correlation coefficient\n    r, p = pearsonr(x, y)\n\n    # Adjust the font size based on the number of hue groups\n    if hue is None:\n        fontsize = 12\n    else:\n        fontsize = 12 / (len(hue.unique()) + 1)\n\n    # Annotate the axis with the correlation coefficient\n    if \"label\" in kws:\n        label = kws[\"label\"]\n    else:\n        label = None\n\n    # Get the position of the annotation\n    if \"loc\" in kws:\n        loc = kws[\"loc\"]\n    else:\n        loc = \"best\"\n\n    # Get the position of the annotation\n    if \"fontweight\" in kws:\n        fontweight = kws[\"fontweight\"]\n    else:\n        fontweight = \"bold\"\n\n    # Get the position of the annotation\n    if \"fontsize\" in kws:\n        fontsize = kws[\"fontsize\"]\n    else:\n        fontsize = 12\n\n    # Get the position of the annotation\n    if \"ha\" in kws:\n        ha = kws[\"ha\"]", "CodeBleu_score": 34.462166801218004}, {"code": "def _corrfunc(self, x, y, **kws)\n\t\n    import seaborn as sns\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Get the axis\n    if sns.__version__[:3] >= \"0.11\":\n        ax = kws.pop(\"ax\", None)\n    else:\n        ax = kws.pop(\"axes\", None)\n\n    # Get the hue groups\n    hue_groups = x.dropna().unique()\n\n    # Compute the correlation coefficient\n    r = np.corrcoef(x.dropna(), y.dropna())[0, 1]\n\n    # Adjust the font size based on the number of hue groups and the correlation value\n    fontsize = max(10, 100 / len(hue_groups)) * (20 / np.abs(r))\n\n    # Get the axis\n    if ax is None:\n        ax = plt.gca()\n\n    # Annotate the axis with the correlation coefficient\n    if sns.__version__[:3] >= \"0.11\":\n        ax.annotate(\n            f\"r = {r:.2f}\",\n            xy=(0.5, 0.5),\n            xycoords=\"axes fraction\",\n            ha=\"center\",\n            va=\"center\",\n            fontsize=fontsize,\n        )\n    else:\n        ax.annotate(\n            f\"r = {r:.2f}\",\n            xy=(0.5, 0.5),\n            xycoords=\"axes fraction\",\n            ha=\"center\",\n            va=\"center\",\n            fontsize=fontsize,\n            **kws,\n        )\n\n", "CodeBleu_score": 31.747948626351096}]}
{"instance_id": "4c1ade308953", "generation_result": [{"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        rounddigit = 0\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        from decimal import Decimal, ROUND_HALF_UP\n        return float(Decimal(str(src)).quantize(Decimal(f'1.{\"0\" * rounddigit}'), rounding=ROUND_HALF_UP))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError(\"Invalid method. Choose from 'decimal', 'sig', or 'format'.\")\n\n", "CodeBleu_score": 50.98248623379674}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if rounddigit is None:\n        return src\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        import decimal\n        return float(decimal.Decimal(src).quantize(decimal.Decimal('1.' + '0' * rounddigit), rounding=decimal.ROUND_HALF_UP))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError(f'Invalid method: {method}')\n\n", "CodeBleu_score": 57.119849567077395}, {"code": "def _round_digits(src: float, rounddigit: int = None, method='decimal')\n\t\n    if method == 'decimal':\n        return round(src, rounddigit)\n    elif method == 'sig':\n        from decimal import Decimal, ROUND_HALF_UP\n        return float(Decimal(str(src)).quantize(Decimal(f'0.{\"0\" * (rounddigit - 1)}1'), rounding=ROUND_HALF_UP))\n    elif method == 'format':\n        return float(f'{src:.{rounddigit}g}')\n    else:\n        raise ValueError('Invalid method')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.33370425215121}]}
{"instance_id": "a9923e678320", "generation_result": [{"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 83.09941583544582}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 83.09941583544582}, {"code": "def _round_dict_digits(cls, srcdict: Dict[str, float], rounddigit: int = None, method='decimal')\n\t\n    dstdict = {}\n    for k, v in srcdict.items():\n        if rounddigit is not None and isinstance(v, float):\n            dstdict[k] = cls._round_digits(v, rounddigit=rounddigit, method=method)\n        else:\n            dstdict[k] = v\n    return dstdict\n\n", "CodeBleu_score": 83.09941583544582}]}
{"instance_id": "b6106e079dc0", "generation_result": [{"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    df = pd.DataFrame(np.column_stack([x, y]), columns=[x_name, y_name])\n    if hue_data is not None:\n        df[hue_name] = hue_data\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=df, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if \"title\" not in legend_kws:\n            legend_kws[\"title\"] = hue_name\n        ax.legend(**legend_kws)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.073765000491456}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    import seaborn as sns\n    import pandas as pd\n    import matplotlib.pyplot as plt\n    if hue_data is not None:\n        df = pd.DataFrame({x_name: x, y_name: y, hue_name: hue_data})\n    else:\n        df = pd.DataFrame({x_name: x, y_name: y})\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=df, ax=ax, **scatter_kws)\n    if ax.get_legend() is not None:\n        if legend_kws.get('title') is None:\n            legend_kws['title'] = hue_name\n        ax.legend(**legend_kws)\n    return ax\n\n", "CodeBleu_score": 46.562937279860755}, {"code": "def _scatterplot_ndarray(cls, x, x_name, y, y_name, hue_data, hue_name, ax, scatter_kws, legend_kws)\n\t\n    import pandas as pd\n    import seaborn as sns\n    df = pd.DataFrame({x_name: x, y_name: y})\n    if hue_data is not None:\n        df[hue_name] = hue_data\n    sns.scatterplot(x=x_name, y=y_name, hue=hue_name, data=df, ax=ax, **scatter_kws)\n    if legend_kws is not None:\n        if \"title\" not in legend_kws:\n            legend_kws[\"title\"] = hue_name\n        ax.legend(**legend_kws)\n\n\n", "CodeBleu_score": 42.60594589985703}]}
{"instance_id": "257e0aa5dd4d", "generation_result": [{"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}, {"code": "def fit(self, **fit_args) -> \"TimeSeriesModel\"\n\t\n    as_df = self.node.item\n    end = self._get_transformed_data(as_series=True)\n    if self.node.exogenous:\n        ex = as_df[self.node.exogenous]\n    else:\n        ex = None\n    with warnings.catch_warnings():\n        warnings.filterwarnings(\"ignore\", category=UserWarning)\n        warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n        self.model = self.model.fit(y=end, X=ex, **fit_args)\n    return self\n\n", "CodeBleu_score": 81.66611757152214}]}
{"instance_id": "6446de2223e8", "generation_result": [{"code": "def create_model(self, **kwargs)\n\t\n    model_type = self.model_type\n    if model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = ExponentialSmoothing(transformed_data, **kwargs)\n    elif model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logging.error(\"pmdarima is not installed. Please install it and try again.\")\n            sys.exit(1)\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = AutoARIMA(**kwargs)\n        model.fit(transformed_data)\n    elif model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exog = self._get_transformed_data(as_series=True)\n        if exog is not None:\n            model = SARIMAX(transformed_data, exog=exog, **kwargs)\n        else:\n            model = SARIMAX(transformed_data, **kwargs)\n    else:\n        raise Exception(\"Model type not recognized\")\n    return model\n\n", "CodeBleu_score": 42.67561260900335}, {"code": "def create_model(self, **kwargs)\n\t\n    if self.model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = ExponentialSmoothing(\n            transformed_data,\n            trend=self.trend,\n            damped=self.damped,\n            seasonal=self.seasonal,\n            seasonal_periods=self.seasonal_periods,\n        )\n    elif self.model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\"pmdarima is not installed. Please install it.\")\n            sys.exit(1)\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = AutoARIMA(**kwargs)\n        model.fit(transformed_data)\n    elif self.model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exog = None\n        if self.exogenous_variables:\n            exog = self._get_transformed_data(as_series=True)\n        model = SARIMAX(\n            transformed_data,\n            exog=exog,\n            order=self.order,\n            seasonal_order=self.seasonal_order,\n            trend=self.trend,\n            enforce_stationarity=self.enforce_stationarity,\n            enforce_invertibility=self.enforce_invertibility,\n        )\n    else:\n        raise Exception(\n            f\"Model type {self.model_type} is not recognized. Please use one of 'holt_winters', 'auto_arima', or 'sarimax'.\"\n        )\n    return model\n\n", "CodeBleu_score": 44.0270912459346}, {"code": "def create_model(self, **kwargs)\n\t\n    model_type = self.model_type\n    if model_type == \"holt_winters\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = ExponentialSmoothing(\n            transformed_data,\n            trend=self.trend,\n            seasonal=self.seasonal,\n            seasonal_periods=self.seasonal_periods,\n            **kwargs,\n        )\n    elif model_type == \"auto_arima\":\n        try:\n            from pmdarima import AutoARIMA\n        except ImportError:\n            logger.error(\"pmdarima is not installed. Please install pmdarima.\")\n            sys.exit(1)\n        transformed_data = self._get_transformed_data(as_series=True)\n        model = AutoARIMA(**kwargs)\n    elif model_type == \"sarimax\":\n        transformed_data = self._get_transformed_data(as_series=True)\n        exog_data = self._get_exogenous_data()\n        if exog_data is not None:\n            model = SARIMAX(\n                transformed_data,\n                exog=exog_data,\n                trend=self.trend,\n                seasonal=self.seasonal,\n                seasonal_periods=self.seasonal_periods,\n                **kwargs,\n            )\n        else:\n            model = SARIMAX(\n                transformed_data,\n                trend=self.trend,\n                seasonal=self.seasonal,\n                seasonal_periods=self.seasonal_periods,\n                **kwargs,\n            )\n    else:\n        raise Exception(f\"Unrecognized model type: {model_type}\")\n    return model\n\n", "CodeBleu_score": 45.32310547345786}]}
{"instance_id": "b2f67820e27f", "generation_result": [{"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    if (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    return array\n\n", "CodeBleu_score": 81.55341328072576}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    elif (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    else:\n        return array\n\n", "CodeBleu_score": 79.63601240001748}, {"code": "def _to_chx(array)\n\t\n    if isinstance(array, numpy.ndarray):\n        return _from_numpy(array)\n    elif (cupy is not None) and isinstance(array, cupy.ndarray):\n        return _from_cupy(array)\n    else:\n        return array\n\n", "CodeBleu_score": 79.63601240001748}]}
{"instance_id": "b96f7d9bcc95", "generation_result": [{"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if not isinstance(ys, list):\n        ys = [ys]\n    if not isinstance(indices_or_sections, list):\n        indices_or_sections = [indices_or_sections]\n    if len(ys) != len(indices_or_sections):\n        raise ValueError(\"Number of split segments does not match the number of split indices or sections.\")\n    if len(ys) == 0:\n        return ys\n    if len(ys[0].shape) != len(x.shape):\n        # Calculate expected shapes for split segments\n        split_sizes = [len(y) for y in ys]\n        split_shapes = [np.array(x.shape) for _ in range(len(ys))]\n        for i, (start, end) in enumerate(zip([0] + split_sizes, split_sizes + [x.shape[axis]])):\n            split_shapes[i][axis] = end - start\n        # Reshape segments to expected shapes\n        for i, (y, shape) in enumerate(zip(ys, split_shapes)):\n            if y.shape != shape:\n                ys[i] = y.reshape(shape)\n    return ys\n\n", "CodeBleu_score": 38.01303191422002}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 0:\n        return ys\n    if len(ys) == 1:\n        return ys\n    if len(ys[0].shape) != len(x.shape):\n        split_sizes = np.array([y.shape[axis] for y in ys])\n        split_sizes = np.cumsum(split_sizes)[:-1]\n        split_sizes = np.insert(split_sizes, 0, 0)\n        split_sizes = np.append(split_sizes, x.shape[axis])\n        split_sizes = np.diff(split_sizes)\n        ys = [np.reshape(y, (split_sizes[i],) + y.shape[1:]) for i, y in enumerate(ys)]\n    return ys\n\n", "CodeBleu_score": 39.279740160772946}, {"code": "def _fix_numpy_split(ys, x, indices_or_sections, axis)\n\t\n    if len(ys) == 0:\n        return ys\n    if len(ys[0].shape) == len(x.shape):\n        return ys\n    if isinstance(indices_or_sections, int):\n        num_segments = indices_or_sections\n    else:\n        num_segments = len(indices_or_sections) + 1\n    split_sizes = np.array(np.array_split(np.zeros(x.shape[axis]), num_segments, axis=axis)).sum(axis=(axis + 1, axis + 2))\n    split_sizes[split_sizes == 0] = 1\n    ys = [y.reshape(split_sizes) if len(y.shape) != len(x.shape) else y for y in ys]\n    return ys\n\n", "CodeBleu_score": 37.23826717674229}]}
{"instance_id": "cf39fb123842", "generation_result": [{"code": "def to_device_batch(batch):\n\t\n    if device is None:\n        return batch\n    elif device < 0:\n        return [chainer.dataset.to_device(device, x) for x in batch]\n    xp = cuda.cupy.get_array_module(*batch)\n    concat = xp.concatenate(batch, axis=0)\n    sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n    concat_dev = cuda.to_gpu(concat)\n    batch_dev = cuda.cupy.split(concat_dev, sections)\n    return batch_dev\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 81.94906339993622}, {"code": "def to_device_batch(batch):\n\t\n    device = batch[0].device\n    if device is None:\n        return batch\n    elif device < 0:\n        return chainer.dataset.to_device(device, batch)\n    xp = cuda.get_array_module(*batch)\n    concat_batch = xp.concatenate(batch, axis=0)\n    sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n    concat_dev = concat_batch.device\n    with cuda.get_device_from_array(concat_batch):\n        return cuda.cupy.split(concat_batch, sections)\n\n", "CodeBleu_score": 61.97449022736411}, {"code": "def to_device_batch(batch):\n\t\n    device = None\n    if device is None:\n        return batch\n    elif device < 0:\n        return chainer.dataset.to_device(device, batch)\n    xp = cuda.get_array_module(*batch)\n    concat = xp.concatenate(batch, axis=0)\n    sections = np.cumsum([len(x) for x in batch[:-1]], dtype=np.int32)\n    concat_dev = cuda.to_gpu(concat)\n    batch_dev = cuda.cupy.split(concat_dev, sections)\n    return batch_dev", "CodeBleu_score": 68.41773483005895}]}
{"instance_id": "845c744d897c", "generation_result": [{"code": "def make_image(trainer)\n\t\n    import torch\n    import numpy as np\n    import os\n    from PIL import Image\n    import torchvision.transforms as transforms\n\n    # Set random seed for reproducibility\n    torch.manual_seed(0)\n\n    # Determine the number of images to generate\n    num_images = 64\n\n    # Create a latent variable z\n    z = torch.randn(num_images, trainer.latent_dim, device=trainer.device)\n\n    # Generate images using a generator model with the training mode turned off\n    with torch.no_grad():\n        fake_images = trainer.generator(z).detach().cpu()\n\n    # Move the generated images to the CPU\n    fake_images = fake_images.cpu()\n\n    # Scale the generated images to a [0, 255] range\n    fake_images = (fake_images + 1) / 2 * 255\n\n    # Convert the generated images to uint8 type\n    fake_images = fake_images.type(torch.uint8)\n\n    # Reshape and transpose the generated images to form a grid of images\n    fake_images = fake_images.view(num_images, 1, 28, 28)\n    fake_images = fake_images.transpose(1, 2).transpose(2, 3)\n\n    # Create a directory for saving the preview image if it doesn't exist\n    os.makedirs(\"preview\", exist_ok=True)\n\n    # Save the generated image as a PNG file\n    image_path = f\"preview/image_{trainer.iterations}.png\"\n    transforms.ToPILImage()(fake_images).save(image_path)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.120635650400505}, {"code": "def make_image(trainer)\n\t\n    import torch\n    import os\n    from torchvision.utils import save_image\n    import numpy as np\n\n    # Set random seed\n    torch.manual_seed(0)\n\n    # Determine the number of images to generate\n    num_images = 100\n\n    # Create a latent variable z\n    z = torch.randn(num_images, trainer.latent_dim).to(trainer.device)\n\n    # Generate images using the generator model\n    with torch.no_grad():\n        generated_images = trainer.generator(z)\n\n    # Move the generated images to the CPU\n    generated_images = generated_images.detach().cpu()\n\n    # Scale the generated images to [0, 255] range\n    generated_images = (generated_images + 1) / 2 * 255\n\n    # Convert the generated images to uint8 type\n    generated_images = generated_images.type(torch.uint8)\n\n    # Reshape and transpose the generated images to form a grid\n    generated_images = generated_images.view(num_images, 28, 28)\n    generated_images = generated_images.transpose(1, 2)\n\n    # Create a directory for saving the preview image if it doesn't exist\n    if not os.path.exists(\"preview_images\"):\n        os.makedirs(\"preview_images\")\n\n    # Save the generated image as a PNG file\n    save_image(generated_images, f\"preview_images/generated_image_{trainer.current_iteration}.png\", nrow=10)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.57215135460015}, {"code": "def make_image(trainer)\n\t\n    import os\n    import torch\n    import torchvision\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Set random seed\n    torch.manual_seed(42)\n\n    # Determine number of images to generate\n    n_images = 100\n\n    # Create latent variable z\n    z = torch.randn(n_images, trainer.generator.latent_dim, device=trainer.device)\n\n    # Generate images using generator model\n    with torch.no_grad():\n        generated_images = trainer.generator(z)\n\n    # Move generated images to CPU and scale to [0, 255] range\n    generated_images = generated_images.cpu().detach().numpy()\n    generated_images = np.clip(generated_images * 255, 0, 255).astype(np.uint8)\n\n    # Reshape and transpose to form a grid of images\n    grid_size = int(np.sqrt(n_images))\n    generated_images = generated_images.reshape(grid_size, grid_size, 28, 28)\n    generated_images = np.transpose(generated_images, (0, 2, 1, 3))\n    generated_images = generated_images.reshape(grid_size * 28, grid_size * 28)\n\n    # Create directory for saving preview image if it doesn't exist\n    os.makedirs(\"preview_images\", exist_ok=True)\n\n    # Save generated image as PNG file\n    plt.imsave(f\"preview_images/generated_images_{trainer.current_iteration}.png\", generated_images, cmap=\"gray\")\n\n\n\n\n\n\n", "CodeBleu_score": 32.616244557320144}]}
{"instance_id": "fc2162d43aee", "generation_result": [{"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    _typechars = \"?bhilqpBHILQPefdFD\"\n    return _typechars.index(from_dtype.char) <= _typechars.index(to_dtype.char)\n\n", "CodeBleu_score": 47.370231997805654}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    _typechars = \"?bBhHiIlLqQpPefdFD\"\n    return _typechars.index(from_dtype.char) <= _typechars.index(to_dtype.char)\n\n", "CodeBleu_score": 47.370231997805654}, {"code": "def _cuda_can_cast(from_dtype: npt.DTypeLike, to_dtype: npt.DTypeLike) -> bool\n\t\n    from_dtype = np.dtype(from_dtype)\n    to_dtype = np.dtype(to_dtype)\n    _typechars = \"?bBhHiIlLqQpPefdFD\"\n    from_pos = _typechars.find(from_dtype.char)\n    to_pos = _typechars.find(to_dtype.char)\n    return from_pos <= to_pos\n\n", "CodeBleu_score": 45.90887587936079}]}
{"instance_id": "5b8e2d5e6e12", "generation_result": [{"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    import matplotlib.patches as patches\n    import matplotlib.pyplot as plt\n\n    if isinstance(g, Visualizer):\n        ax = g.ax\n    elif g is None:\n        ax = plt.gca()\n    else:\n        ax = g\n\n    if len(labels) != len(colors):\n        raise ValueError(\"Length of labels and colors must match.\")\n\n    legend_handles = [\n        patches.Patch(color=color, label=label)\n        for label, color in zip(labels, colors)\n    ]\n\n    return ax.legend(handles=legend_handles, **legend_kwargs)\n\n", "CodeBleu_score": 63.85174306162843}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    import matplotlib.patches as patches\n    if g is None:\n        ax = plt.gca()\n    elif isinstance(g, Visualizer):\n        ax = g.ax\n    elif isinstance(g, plt.Axes):\n        ax = g\n    else:\n        raise ValueError(\"g must be a Visualizer, None, or a matplotlib Axes object\")\n    if len(labels) != len(colors):\n        raise ValueError(\"labels and colors must have the same length\")\n    handles = [patches.Patch(color=colors[i], label=labels[i]) for i in range(len(labels))]\n    return ax.legend(handles=handles, **legend_kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 54.146567618385966}, {"code": "def manual_legend(g, labels, colors, **legend_kwargs)\n\t\n    if isinstance(g, Visualizer):\n        ax = g.ax\n    elif g is None:\n        ax = plt.gca()\n    elif isinstance(g, Axes):\n        ax = g\n    else:\n        raise ValueError(\"g must be a Visualizer, None, or an Axes object\")\n\n    if len(labels) != len(colors):\n        raise ValueError(\"labels and colors must have the same length\")\n\n    handles = [patches.Patch(color=c, label=l) for l, c in zip(labels, colors)]\n    return ax.legend(handles=handles, **legend_kwargs)\n\n\n\n", "CodeBleu_score": 54.78045329684631}]}
{"instance_id": "494e7f719eb6", "generation_result": [{"code": "def pcoords_time(X, y, fast=True)\n\t\n    from time import time\n    from yellowbrick.features.pcoords import ParallelCoordinates\n    from matplotlib import pyplot as plt\n\n    start = time()\n    visualizer = ParallelCoordinates(fast=fast)\n    visualizer.fit_transform(X, y)\n    plt.close(\"all\")\n    return time() - start\n\n", "CodeBleu_score": 35.485610151946496}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    import time\n    import matplotlib.pyplot as plt\n    from yellowbrick.features.pcoords import ParallelCoordinates\n    _, ax = plt.subplots()\n    visualizer = ParallelCoordinates(fast=fast, ax=ax)\n    start = time.time()\n    visualizer.fit_transform(X, y)\n    elapsed = time.time() - start\n    plt.close()\n    return elapsed\n\n\n\n", "CodeBleu_score": 69.90617731016953}, {"code": "def pcoords_time(X, y, fast=True)\n\t\n    import time\n    import matplotlib.pyplot as plt\n    from yellowbrick.features import ParallelCoordinates\n    _, ax = plt.subplots()\n    visualizer = ParallelCoordinates(fast=fast, ax=ax)\n    start_time = time.time()\n    visualizer.fit_transform(X, y)\n    end_time = time.time()\n    plt.close()\n    return end_time - start_time\n\n\n\n", "CodeBleu_score": 60.43627626262813}]}
{"instance_id": "db4143bc029f", "generation_result": [{"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the alpha transparency value from the object's attributes or defaults to 0.25\n    alpha = kwargs.get('alpha', self.alpha)\n\n    # For each instance, extract the feature vector and corresponding label, determine the color based on the label, and plot the feature vector against a predefined increment sequence on the axis\n    for i, (xi, yi) in enumerate(zip(X, y)):\n        color = self.get_colors(yi)\n        self.ax.plot(xi, self.increments, color=color, alpha=alpha)\n\n    # Return the axis object with the plotted instances\n    return self.ax\n\n", "CodeBleu_score": 34.27456338946434}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n    # Get the alpha transparency value from the object's attributes or defaults to 0.25\n    alpha = kwargs.pop('alpha', self.alpha)\n\n    # For each instance, extract the feature vector and corresponding label,\n    # determine the color based on the label, and plot the feature vector\n    # against a predefined increment sequence on the axis\n    for i, (x, yi) in enumerate(zip(X, y)):\n        color = self.get_colors(yi)\n        self.ax.plot(np.arange(len(x)), x, color=color, alpha=alpha, label=yi, **kwargs)\n\n    # Return the axis object with the plotted instances\n    return self.ax\n\n", "CodeBleu_score": 40.80540740977212}, {"code": "def draw_instances(self, X, y, **kwargs):\n\t\n\n    # Get the alpha transparency value from the object's attributes or defaults to 0.25\n    alpha = kwargs.get(\"alpha\", self.alpha)\n\n    # For each instance, extract the feature vector and corresponding label, determine the color based on the label, and plot the feature vector against a predefined increment sequence on the axis\n    for i, (xi, yi) in enumerate(zip(X, y)):\n        color = self.get_colors(yi)\n        self.ax.plot(xi, self.increment_sequence, c=color, alpha=alpha, **kwargs)\n\n    # Return the axis object with the plotted instances\n    return self.ax\n\n", "CodeBleu_score": 38.703306493300126}]}
{"instance_id": "676433312ffe", "generation_result": [{"code": "def draw_classes(self, X, y, **kwargs):\n\t\n    # Set the alpha transparency value from the object's attributes or defaults to 0.5\n    alpha = kwargs.get(\"alpha\", self.alpha)\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.c_[X, np.ones(X.shape[0])]\n\n    # Append None to the increments list to create breaks between instances\n    increments = self.increments_ + [None]\n\n    # Identify unique class labels in y\n    classes = np.unique(y)\n\n    # Iterate over each class\n    for yi in classes:\n        # Determine the color for the class\n        color = self.get_colors(yi)\n\n        # Select the instances of X belonging to the class\n        instances = X[y == yi]\n\n        # Plot the instances as a single line plot with the specified color and alpha transparency\n        self.ax.plot(\n            np.vstack(\n                [\n                    np.repeat(increments, instances.shape[1]),\n                    np.vstack([instances.T] * len(increments)).T,\n                ]\n            ),\n            color=color,\n            alpha=alpha,\n        )\n\n    return self.ax\n\n", "CodeBleu_score": 42.35364208814239}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n\n    # Set the alpha transparency value from the object's attributes or defaults to 0.5\n    alpha = kwargs.pop(\"alpha\", self.alpha)\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.c_[X, np.ones(X.shape[0])]\n\n    # Append None to the increments list to create breaks between instances\n    increments = [None] + self.increments\n\n    # Identify unique class labels in y\n    classes = np.unique(y)\n\n    # Iterate over each unique class\n    for label in classes:\n        # Determine the color for the class\n        color = self.get_colors(label)\n\n        # Select the instances of X belonging to the class\n        instances = X[y == label, :]\n\n        # Plot the instances of the class as a single line plot\n        self.ax.plot(\n            np.vstack((increments, instances.T)).T, color=color, alpha=alpha, **kwargs\n        )\n\n    return self.ax\n\n", "CodeBleu_score": 36.46406932459738}, {"code": "def draw_classes(self, X, y, **kwargs):\n\t\n\n    # Set the alpha transparency value from the object's attributes or defaults to 0.5\n    alpha = kwargs.get(\"alpha\", self.alpha)\n\n    # Add a column of ones to X to separate the instances visually\n    X = np.c_[X, np.ones(X.shape[0])]\n\n    # Append None to the increments list to create breaks between instances\n    increments = [None] + self.increments\n\n    # Identify unique class labels in y\n    classes = np.unique(y)\n\n    # Iterate over unique class labels\n    for index, label in enumerate(classes):\n        # Determine the color for the current class label\n        color = self.get_colors(label)\n\n        # Select the instances of X belonging to the current class label\n        instances = X[y == label, :]\n\n        # Plot the instances as a single line plot with the specified color and alpha transparency\n        self.ax.plot(\n            instances.flatten(),\n            color=color,\n            alpha=alpha,\n            label=str(label),\n        )\n\n    # Return the axis object with the plotted classes\n    return self.ax\n\n", "CodeBleu_score": 37.43968753929963}]}
{"instance_id": "9d297b12a673", "generation_result": [{"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    # Set up the side-by-side axes grid\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n    # Perform RadViz analysis on occupancy data\n    X, y = load_occupancy()\n    viz = RadViz(ax=axes[0], features=[\"temperature\", \"relative humidity\", \"light\", \"C02\", \"humidity\"])\n    viz.fit(X, y)\n    viz.finalize()\n\n    # Perform Rank2D analysis on concrete data\n    X, y = load_concrete()\n    viz = Rank2D(ax=axes[1], features=[\"cement\", \"slag\", \"ash\", \"water\", \"splast\", \"coarse\", \"fine\", \"age\"])\n    viz.fit(X, y)\n    viz.transform(X)\n    viz.finalize()\n\n    # Save the resulting figure to a specified file path\n    fig.savefig(fname)\n\n", "CodeBleu_score": 38.85122681838118}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n    X, y = load_occupancy(split=False)\n    oz = RadViz(ax=ax[0], features=X.columns, classes=[\"unoccupied\", \"occupied\"])\n    oz.fit(X, y)\n    oz.finalize()\n\n    X, y = load_concrete(split=False)\n    oz = Rank2D(ax=ax[1], features=X.columns, classes=[\"low\", \"high\"])\n    oz.fit(X, y)\n    oz.transform(X)\n    oz.finalize()\n\n    fig.savefig(fname)\n\n", "CodeBleu_score": 50.03208002343633}, {"code": "def feature_analysis(fname=\"feature_analysis.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n\n    # RadViz analysis\n    radviz = RadViz(ax=axes[0], features=[\"temperature\", \"relative humidity\", \"light\", \"C02\", \"humidity\"])\n    radviz.fit(X_train, y_train)\n    radviz.transform(X_train)\n    radviz.finalize()\n\n    # Rank2D analysis\n    rank2d = Rank2D(ax=axes[1], features=[\"cement\", \"slag\", \"ash\", \"water\", \"splast\", \"coarse\", \"fine\", \"age\"])\n    rank2d.fit(X_train, y_train)\n    rank2d.transform(X_train)\n    rank2d.finalize()\n\n    fig.savefig(fname)\n\n", "CodeBleu_score": 35.93434011650752}]}
{"instance_id": "fd1b4b9cd7ef", "generation_result": [{"code": "def regression(fname=\"regression.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-6, 6, 13)\n\n    X, y, X_train, X_test, y_train, y_test = load_concrete(split=True)\n\n    ax[0].plot(alphas, -cross_val_score(LassoCV(alphas=alphas), X, y, cv=3))\n    ax[0].set_xscale(\"log\")\n    ax[0].set_ylim(ymin=-2, ymax=0)\n    ax[0].set_xlabel(\"alpha\")\n    ax[0].set_ylabel(\"neg_mean_absolute_error\")\n    ax[0].set_title(\"LassoCV\")\n\n    ax[1].plot(alphas, cross_val_score(RidgeCV(alphas=alphas), X, y, cv=3))\n    ax[1].set_xscale(\"log\")\n    ax[1].set_ylim(ymin=0.5, ymax=0.9)\n    ax[1].set_xlabel(\"alpha\")\n    ax[1].set_ylabel(\"r2\")\n    ax[1].set_title(\"RidgeCV\")\n\n    fig.tight_layout()\n    path = os.path.join(FIGURES, fname)\n    fig.savefig(path)\n    return path\n\n", "CodeBleu_score": 39.06413518871952}, {"code": "def regression(fname=\"regression.png\")\n\t\n    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-6, 6, 13)\n\n    X, y, X_train, X_test, y_train, y_test = load_concrete(split=True)\n\n    # YOUR CODE HERE\n    # LassoCV\n    lasso = LassoCV(alphas=alphas, cv=5).fit(X_train, y_train)\n    lasso_pred = lasso.predict(X_test)\n    lasso_mse = mean_squared_error(y_test, lasso_pred)\n    axes[0].plot(alphas, np.sqrt(lasso.mse_path_), label=\"LassoCV\")\n    axes[0].set_xscale(\"log\")\n    axes[0].set_xlabel(\"alpha\")\n    axes[0].set_ylabel(\"rmse\")\n    axes[0].set_title(f\"LassoCV (mse={lasso_mse:.2f})\")\n    axes[0].legend()\n\n    # RidgeCV\n    ridge = RidgeCV(alphas=alphas, cv=5).fit(X_train, y_train)\n    ridge_pred = ridge.predict(X_test)\n    ridge_mse = mean_squared_error(y_test, ridge_pred)\n    axes[1].plot(alphas, np.sqrt(ridge.cv_values_), label=\"RidgeCV\")\n    axes[1].set_xscale(\"log\")\n    axes[1].set_xlabel(\"alpha\")\n    axes[1].set_ylabel(\"rmse\")\n    axes[1].set_title(f\"RidgeCV (mse={ridge_mse:.2f})\")\n    axes[1].legend()\n\n    fig.tight_layout()\n    fig.savefig(os.path.join(IMG_DIR, fname))\n    return os.path.join(IMG_", "CodeBleu_score": 39.29099936652587}, {"code": "def regression(fname=\"regression.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(18, 6))\n    alphas = np.logspace(-10, 10, 21)\n\n    X, y, _, _ = load_concrete()\n    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n\n    lasso = LassoCV(alphas=alphas, cv=5, random_state=42)\n    lasso.fit(X_train, y_train)\n    lasso_scores = lasso.score(X_test, y_test)\n\n    ridge = RidgeCV(alphas=alphas, cv=5)\n    ridge.fit(X_train, y_train)\n    ridge_scores = ridge.score(X_test, y_test)\n\n    ax[0].plot(alphas, lasso_scores, label=\"LassoCV\")\n    ax[0].plot(alphas, ridge_scores, label=\"RidgeCV\")\n    ax[0].legend()\n    ax[0].set_xscale(\"log\")\n    ax[0].set_xlabel(\"alpha\")\n    ax[0].set_ylabel(\"score\")\n    ax[0].set_title(\"Prediction Error\")\n\n    ax[1].plot(alphas, lasso.coef_, label=\"LassoCV\")\n    ax[1].plot(alphas, ridge.coef_, label=\"RidgeCV\")\n    ax[1].legend()\n    ax[1].set_xscale(\"log\")\n    ax[1].set_xlabel(\"alpha\")\n    ax[1].set_ylabel(\"coef\")\n    ax[1].set_title(\"Residuals\")\n\n    fig.tight_layout()\n    path = os.path.join(IMG, fname)\n    fig.savefig(path)\n    return path\n\n", "CodeBleu_score": 43.42097836892398}]}
{"instance_id": "627126918f88", "generation_result": [{"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\n    # Left plot\n    X, y, X_train, X_test, y_train, y_test = load_spam(split=True)\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n    visualize.classification_report(model, X_test, y_test, ax=ax[0])\n\n    # Right plot\n    X, y = load_spam(split=False)\n    model = LogisticRegression()\n    model.fit(X, y)\n    visualize.discrimination_threshold(model, X, y, ax=ax[1])\n\n    fig.tight_layout()\n    fig.savefig(fname)\n\n", "CodeBleu_score": 35.31025118969428}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(16, 6))\n\n    # Left plot\n    ax[0].set_title(\"Multinomial Naive Bayes\")\n    X_train, X_test, y_train, y_test = load_spam(split=True)\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n    visualize.classification_report(model, X_test, y_test, ax=ax[0])\n\n    # Right plot\n    ax[1].set_title(\"Logistic Regression\")\n    X, y = load_spam()\n    model = LogisticRegression()\n    visualize.discrimination_threshold(X, y, model, ax=ax[1])\n\n    fig.tight_layout()\n    fig.savefig(fname)\n\n", "CodeBleu_score": 34.13633273949359}, {"code": "def classification(fname=\"classification.png\")\n\t\n    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n\n    # Left Axis\n    X_train, X_test, y_train, y_test = load_spam(split=True)\n    model = MultinomialNB()\n    model.fit(X_train, y_train)\n    visualize.classification_report(model, X_test, y_test, ax=ax[0])\n\n    # Right Axis\n    X, y = load_spam()\n    model = LogisticRegression()\n    model.fit(X, y)\n    visualize.discrimination_threshold(model, X, y, ax=ax[1])\n\n    fig.tight_layout()\n    fig.savefig(fname)\n\n", "CodeBleu_score": 33.3027775253844}]}
{"instance_id": "318d3a674694", "generation_result": [{"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib as mpl\n        if mpl.__version__ >= '1.5.0':\n            return [c['color'] for c in mpl.rcParams['axes.prop_cycle']]\n        else:\n            return mpl.rcParams['axes.color_cycle']\n    except KeyError:\n        return mpl.rcParams['axes.color_cycle']\n\n\n\n", "CodeBleu_score": 41.90858711919119}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib\n        if matplotlib.__version__ >= '1.5.0':\n            return [c['color'] for c in matplotlib.rcParams['axes.prop_cycle']]\n        else:\n            return matplotlib.rcParams['axes.color_cycle']\n    except KeyError:\n        return matplotlib.rcParams['axes.color_cycle']\n\n", "CodeBleu_score": 40.230622546163055}, {"code": "def get_color_cycle()\n\t\n    try:\n        import matplotlib\n        if matplotlib.__version__ >= '1.5.0':\n            from matplotlib import rcParams\n            return rcParams['axes.prop_cycle'].by_key()['color']\n        else:\n            from matplotlib import rcParams\n            return rcParams['axes.color_cycle']\n    except KeyError:\n        from matplotlib import rcParams\n        return rcParams['axes.color_cycle']\n\n", "CodeBleu_score": 30.60182899863087}]}
{"instance_id": "f3fac557334c", "generation_result": [{"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.normalized_x, self.normalized_y)\n    plt.plot(self.distance_curve, 'r')\n    plt.xlabel('Points')\n    plt.ylabel('Distance')\n    plt.xticks(np.arange(0, max(self.normalized_x), 0.1))\n    plt.yticks(np.arange(0, max(self.normalized_y), 0.1))\n    plt.vlines(self.knee, plt.ylim()[0], plt.ylim()[1], linestyles='dashed')\n    plt.show()", "CodeBleu_score": 48.53428685623194}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.normalized_x, self.normalized_y)\n    plt.plot(self.distance_curve, color='red')\n    plt.xlabel('Normalized X')\n    plt.ylabel('Normalized Y')\n    plt.title('Normalized Curve with Knee Point')\n    plt.xticks(np.arange(min(self.normalized_x), max(self.normalized_x)+0.1, 0.1))\n    plt.yticks(np.arange(min(self.normalized_y), max(self.normalized_y)+0.1, 0.1))\n    if self.knee_point is not None:\n        plt.axvline(x=self.knee_point, color='red', linestyle='--')\n    plt.show()\n\n\n\n", "CodeBleu_score": 44.37975504066971}, {"code": "def plot_knee_normalized(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x_normalized, self.y_normalized)\n    plt.plot(self.x_normalized, self.distance, 'r')\n    plt.xlabel('Normalized X')\n    plt.ylabel('Normalized Y')\n    plt.xticks(np.arange(min(self.x_normalized), max(self.x_normalized)+0.1, 0.1))\n    plt.yticks(np.arange(min(self.y_normalized), max(self.y_normalized)+0.1, 0.1))\n    if self.knee_point:\n        plt.axvline(x=self.knee_point, color='r', linestyle='--')\n    plt.show()\n\n\n\n\n\n", "CodeBleu_score": 49.12551420630671}]}
{"instance_id": "b2d48aae4fce", "generation_result": [{"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y)\n    if self.knee_point is not None:\n        plt.axvline(self.knee_point, ymin=0, ymax=1, color='r', linestyle='--')\n    plt.show()", "CodeBleu_score": 48.755384268707594}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    fig, ax = plt.subplots(figsize=(8, 8))\n    ax.plot(self.x, self.y)\n    if self.knee_point is not None:\n        ax.vlines(self.knee_point, ymin=min(self.y), ymax=max(self.y), color='red', linestyle='--')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 38.616641149522486}, {"code": "def plot_knee(\n        self,\n    )\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n    plt.figure(figsize=(8, 8))\n    plt.plot(self.x, self.y, 'b-')\n    if self.knee_point is not None:\n        plt.axvline(x=self.knee_point, color='r', linestyle='--')\n    plt.xlabel('x')\n    plt.ylabel('y')\n    plt.title('Knee Point')\n    plt.show()\n\n\n\n", "CodeBleu_score": 49.1164448433527}]}
{"instance_id": "4450ba2384c9", "generation_result": [{"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, len(data) - 1));\n\n", "CodeBleu_score": 81.79703624972666}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, data.shape[0] - 1));\n\n", "CodeBleu_score": 89.31129533842159}, {"code": "def plot_pca_interactive(data, n_components=6)\n\t\n    from sklearn.decomposition import PCA\n    from ipywidgets import interact\n\n    pca = PCA(n_components=n_components)\n    Xproj = pca.fit_transform(data)\n\n    def show_decomp(i=0):\n        plot_image_components(data[i], Xproj[i],\n                              pca.mean_, pca.components_)\n\n    interact(show_decomp, i=(0, len(data) - 1));\n", "CodeBleu_score": 81.79703624972666}]}
{"instance_id": "b09a163f3ff1", "generation_result": [{"code": "def plot_iris_knn()\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from sklearn import datasets, neighbors\n\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n\n    # Extract the first two features and the target labels\n    X = iris.data[:, :2]\n    y = iris.target\n\n    # Create a kNN classifier with 5 neighbors\n    knn = neighbors.KNeighborsClassifier(n_neighbors=5)\n\n    # Train the kNN classifier on the Iris dataset\n    knn.fit(X, y)\n\n    # Define the mesh grid over the feature space\n    h = 0.02  # step size in the mesh\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Reshape the predictions and display as a color plot\n    Z = Z.reshape(xx.shape)\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n    # Plot the training points on top of the decision boundary plot\n    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n    plt.show()\n\n", "CodeBleu_score": 63.56096202379915}, {"code": "def plot_iris_knn()\n\t\n    from sklearn.datasets import load_iris\n    from sklearn.neighbors import KNeighborsClassifier\n    import matplotlib.pyplot as plt\n\n    # Load the Iris dataset\n    iris = load_iris()\n\n    # Extract the first two features and target labels\n    X = iris.data[:, :2]\n    y = iris.target\n\n    # Create a kNN classifier with 5 neighbors\n    knn = KNeighborsClassifier(n_neighbors=5)\n\n    # Train the kNN classifier on the Iris dataset\n    knn.fit(X, y)\n\n    # Define a mesh grid over the feature space\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n\n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    # Plot the decision boundaries\n    plt.contourf(xx, yy, Z, alpha=0.4)\n    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 60.92426523667059}, {"code": "def plot_iris_knn()\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from sklearn import datasets, neighbors\n\n    # Load the Iris dataset\n    iris = datasets.load_iris()\n\n    # Extract the first two features and target labels\n    X = iris.data[:, :2]\n    y = iris.target\n\n    # Define the number of neighbors\n    n_neighbors = 5\n\n    # Create an instance of the kNN classifier\n    knn = neighbors.KNeighborsClassifier(n_neighbors)\n\n    # Fit the model to the data\n    knn.fit(X, y)\n\n    # Create a mesh grid over the feature space\n    h = 0.02  # Step size in the mesh\n    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\n    # Predict the class for each point in the mesh grid\n    Z = knn.predict(np.c_[xx.ravel(), yy.ravel()])\n\n    # Reshape the predictions to match the mesh grid\n    Z = Z.reshape(xx.shape)\n\n    # Plot the decision boundary\n    plt.figure()\n    plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n\n    # Plot the training points\n    plt.scatter(X[:, 0], X[:, 1], c=y, edgecolors='k', cmap=plt.cm.Paired)\n    plt.xlabel('Sepal length')\n    plt.ylabel('Sepal width')\n    plt.xlim(xx.min(), xx.max())\n    plt.ylim(yy.min(), yy.max())\n   ", "CodeBleu_score": 60.82330965636934}]}
{"instance_id": "8eaee3207c09", "generation_result": [{"code": "def plot_sgd_separator()\n\t\n    # we'll use 50 synthetic data points \n    # this produces a two_moons dataset with 100 points per class\n    # XX is the input while yy returns each point's class\n    XX, yy = datasets.make_moons(n_samples=100, random_state=123)\n    \n    # convert the class labels from integers to hats and dots\n    yy_hat = label_binarize(yy, classes=[0, 1])\n    n_class = 2\n\n    # SGD is sensitive to feature scaling, so we scale all columns to [0, 1]\n    XX = MinMaxScaler().fit_transform(XX)\n\n    # fit an SGD classifier\n    clf = SGDClassifier(loss='log', alpha=0.01, n_iter=200, fit_intercept=True)\n    clf.fit(XX, yy)\n\n    # get the separating hyperplane w[0] x1 + w[1] x2 + intercept = 0\n    # transform to slope-intercept form: x2 = (-w[0]/w[1])x1 - (intercept/w[1])\n    w = clf.coef_[0]\n    a = -w[0] / w[1]\n    xx = np.linspace(-5, 5)\n    yy = a * xx - (clf.intercept_[0]) / w[1]\n\n    # plot the line, the points, and the nearest vectors to the plane\n    plt.figure(figsize=(10,6))\n    plt.plot(xx, yy, 'k-')\n    plt.scatter(clf.support_vectors_[:, 0], clf.support_vectors_[:, 1], s=80,\n                facecolors='none', zorder=10, edgecolors='k')\n    plt.scatter(XX[:, 0], XX[:, 1], c=yy_hat, zorder=10, cmap=plt.cm.Paired,\n                edgecolors=", "CodeBleu_score": 34.23027852425708}, {"code": "def plot_sgd_separator()\n\t\n    # we'll use 50 data points\n    # we can tweak the parameters to try to get better results\n    X, y = make_blobs(n_samples=50, centers=2, random_state=0, cluster_std=0.60)\n    # fit the model\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, y)\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = [\"dashed\", \"solid\", \"dashed\"]\n    colors = 'k'\n    plt.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired, edgecolor=\"black\", s=20)\n    plt.axis(\"tight\")\n    plt.show()\n\n\n\n", "CodeBleu_score": 58.90749188255593}, {"code": "def plot_sgd_separator()\n\t\n    # we'll use 50 synthetic data points \n    # this creates a set of two-dimensional data\n    X, y = make_blobs(n_samples=50, centers=2,\n                      random_state=0, cluster_std=0.60)\n\n    # fit the model, don't regularize for illustration purposes\n    clf = SGDClassifier(loss=\"hinge\", alpha=0.01, max_iter=200, fit_intercept=True)\n    clf.fit(X, y)\n\n    # plot the line, the points, and the nearest vectors to the plane\n    xx = np.linspace(-1, 5, 10)\n    yy = np.linspace(-1, 5, 10)\n\n    X1, X2 = np.meshgrid(xx, yy)\n    Z = np.empty(X1.shape)\n    for (i, j), val in np.ndenumerate(X1):\n        x1 = val\n        x2 = X2[i, j]\n        p = clf.decision_function([[x1, x2]])\n        Z[i, j] = p[0]\n    levels = [-1.0, 0.0, 1.0]\n    linestyles = ['dashed', 'solid', 'dashed']\n    colors = 'k'\n\n    ax = plt.axes()\n    ax.contour(X1, X2, Z, levels, colors=colors, linestyles=linestyles)\n\n    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Paired,\n               edgecolor='black', s=20)\n\n    ax.axis('tight')\n\n", "CodeBleu_score": 65.47433403158}]}
{"instance_id": "8b54f999b4c0", "generation_result": [{"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}, {"code": "def dump_svmlight_file(self, file)\n\t\n    data = np.array(self.data)\n    X = data[:, 0:2]\n    y = data[:, 2]\n    dump_svmlight_file(X, y, file)\n\n", "CodeBleu_score": 54.50515311965599}]}
{"instance_id": "2419013adc6e", "generation_result": [{"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}, {"code": "def fit(self)\n\t\n    print(\"fit the model\")\n    train = np.array(self.model.data)\n    X = train[:, 0:2]\n    y = train[:, 2]\n\n    C = float(self.complexity.get())\n    gamma = float(self.gamma.get())\n    coef0 = float(self.coef0.get())\n    degree = int(self.degree.get())\n    kernel_map = {0: \"linear\", 1: \"rbf\", 2: \"poly\"}\n    if len(np.unique(y)) == 1:\n        clf = svm.OneClassSVM(kernel=kernel_map[self.kernel.get()],\n                              gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X)\n    else:\n        clf = svm.SVC(kernel=kernel_map[self.kernel.get()], C=C,\n                      gamma=gamma, coef0=coef0, degree=degree)\n        clf.fit(X, y)\n    if hasattr(clf, 'score'):\n        print(\"Accuracy:\", clf.score(X, y) * 100)\n    X1, X2, Z = self.decision_surface(clf)\n    self.model.clf = clf\n    self.model.set_surface((X1, X2, Z))\n    self.model.surface_type = self.surface_type.get()\n    self.fitted = True\n    self.model.changed(\"surface\")\n\n", "CodeBleu_score": 98.88171687993604}]}
{"instance_id": "e887fd2a8513", "generation_result": [{"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import sys\n    import traceback\n    import importlib\n    importlib.invalidate_caches()\n    importlib.reload(sys.modules[\"tpot\"])\n    importlib.reload(sys.modules[\"tpot.builtins\"])\n    importlib.reload(sys.modules[\"tpot.config\"])\n    importlib.reload(sys.modules[\"tpot.export_utils\"])\n    importlib.reload(sys.modules[\"tpot.gp_functions\"])\n    importlib.reload(sys.modules[\"tpot.optimizer\"])\n    importlib.reload(sys.modules[\"tpot.pipeline\"])\n    importlib.reload(sys.modules[\"tpot.pipeline_optmimizer\"])\n    importlib.reload(sys.modules[\"tpot.tpot\"])\n    importlib.reload(sys.modules[\"tpot.util\"])\n    importlib.reload(sys.modules[\"tpot.config\"])\n    importlib.reload(sys.modules[\"tpot.builtins\"])\n    importlib.reload(sys.modules[\"tpot.export_utils\"])\n    importlib.reload(sys.modules[\"tpot.gp_functions\"])\n    importlib.reload(sys.modules[\"tpot.optimizer\"])\n    importlib.reload(sys.modules[\"tpot.pipeline\"])\n    importlib.reload(sys.modules[\"tpot.pipeline_optmimizer\"])\n    importlib.reload(sys.modules[\"tpot.tpot\"])\n    importlib.reload(sys.modules[\"tpot.util\"])\n    importlib.reload(sys.modules[\"tpot.config\"])\n    importlib.reload(sys.modules[\"tpot.builtins\"])\n    importlib.reload(sys.modules[\"tpot.export_utils\"])\n    importlib.reload(sys.modules[\"tpot.gp_functions\"])\n    importlib.reload(sys.modules[\"tpot.optimizer\"])\n    importlib.reload(sys.modules[\"tpot.pipeline\"])\n    importlib", "CodeBleu_score": 11.133211255522312}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import sys\n    import importlib\n    import traceback\n\n    sourcecode = sourcecode.replace('", "CodeBleu_score": 2.241736815662634}, {"code": "def source_decode(sourcecode, verbose=0)\n\t\n    import importlib\n    import sys\n    import traceback\n\n    sourcecode = sourcecode.split(\".\")\n    sourcecode_module = \".\".join(sourcecode[:-1])\n    sourcecode_object = sourcecode[-1]\n    if sourcecode_module.startswith(\"tpot\"):\n        sourcecode_module = sourcecode_module.replace(\"tpot\", \"TPOT\")\n        sourcecode_object = sourcecode_object.replace(\"tpot\", \"TPOT\")\n    if verbose > 2:\n        print(f\"Importing {sourcecode_module}\")\n    try:\n        sourcecode_module = importlib.import_module(sourcecode_module)\n        sourcecode_object = getattr(sourcecode_module, sourcecode_object)\n    except ImportError as e:\n        if verbose > 2:\n            raise ImportError(\n                f\"Error importing {sourcecode_module}:", "CodeBleu_score": 38.45363182789865}]}
{"instance_id": "5d6f629c3363", "generation_result": [{"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if \"sample_weight\" in inspect.signature(step.fit).parameters:\n                    key = f\"{step_name}_sample_weight\"\n                    sample_weight_dict[key] = sample_weight\n    if len(sample_weight_dict) > 0:\n        return sample_weight_dict\n    else:\n        return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.756761094015445}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for step_name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if \"sample_weight\" in inspect.signature(step.fit).parameters:\n                    key = f\"{step_name}_sample_weight\"\n                    sample_weight_dict[key] = sample_weight\n    return sample_weight_dict if sample_weight_dict else None\n", "CodeBleu_score": 42.122499278900946}, {"code": "def set_sample_weight(pipeline_steps, sample_weight=None)\n\t\n    sample_weight_dict = {}\n    if sample_weight is not None:\n        for name, step in pipeline_steps:\n            if hasattr(step, \"fit\"):\n                if \"sample_weight\" in inspect.signature(step.fit).parameters:\n                    sample_weight_dict[name + \"__sample_weight\"] = sample_weight\n    if sample_weight_dict:\n        return sample_weight_dict\n    else:\n        return None\n\n", "CodeBleu_score": 52.23237906018301}]}
{"instance_id": "cae17d519818", "generation_result": [{"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n    # Check if an optimized pipeline exists\n    if not self._best_pipeline:\n        raise RuntimeError(\n            \"No optimized pipeline found. Please call fit() before calling summary().\"\n        )\n\n    # Compile and fit the best pipeline\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._best_pipeline.compile(features, target)\n        self._best_pipeline.fit(features, target)\n\n    # Print the best pipeline string, adding extra spacing if verbosity is 2 or higher\n    if self.verbosity >= 1:\n        if self.verbosity >= 2:\n            self._pbar.write(\"\", file=self.log_file_)\n        self._pbar.write(\n            \"Optimization Completed. Best pipeline score: {:.3f}\".format(\n                self._best_pipeline.score(features, target)\n            ),\n            file=self.log_file_,\n        )\n        self._pbar.write(\n            \"Best pipeline: \" + self._best_pipeline.pretty, file=self.log_file_\n        )\n\n    # Compile and fit the entire Pareto front of pipelines\n    self._pareto_front_models = []\n    for individual in self._pareto_front:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            pipeline = self._toolbox.individual_to_pipeline(individual)\n            pipeline.compile(features, target)\n            pipeline.fit(features, target)\n            self._pareto_front_models.append(pipeline)\n\n", "CodeBleu_score": 39.33070338498028}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n\n    # Check if an optimized pipeline exists\n    if not self._best_pipeline:\n        raise RuntimeError(\"No optimized pipeline has been found yet. Please call fit() first.\")\n\n    # Compile and fit the best pipeline\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._best_pipeline.compile(features, target)\n        self._best_pipeline.fit(features, target)\n\n    # Print the best pipeline string\n    if self.verbosity >= 1:\n        if self.verbosity == 2:\n            self._pbar.write(\"\", file=self.log_file_)\n        self._pbar.write(\n            \"Final optimized pipeline: {}\".format(self._best_pipeline), file=self.log_file_\n        )\n\n    # Compile and fit the entire Pareto front of pipelines\n    self._pareto_front_models = []\n    for pipeline in self._pareto_front.items:\n        with warnings.catch_warnings():\n            warnings.simplefilter(\"ignore\")\n            pipeline.compile(features, target)\n            pipeline.fit(features, target)\n        self._pareto_front_models.append(pipeline)\n\n", "CodeBleu_score": 34.32049187133271}, {"code": "def _summary_of_best_pipeline(self, features, target):\n\t\n\n    if not self._fitted_pipeline:\n        raise RuntimeError(\n            \"You must fit TPOT before calling \"\n            \"summary(). Try running tpot.fit(X, y)\"\n        )\n\n    # Compile and fit the best pipeline\n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\")\n        self._fitted_pipeline.compile(features, target)\n        self._fitted_pipeline.fit(features, target)\n\n    if self.verbosity >= 1:\n        best_pipeline_str = self._fitted_pipeline.pretty_print()\n        if self.verbosity >= 2:\n            best_pipeline_str = \"\n", "CodeBleu_score": 23.24945742577251}]}
{"instance_id": "638683d78167", "generation_result": [{"code": "def score(self, testing_features, testing_target)\n\t\n    if not self.fitted_pipeline_:\n        raise ValueError(\"Cannot score pipeline prior to fitting.\")\n\n    # Check if the testing features and target are valid\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n\n    # Get the scorer from the SCORERS dictionary or use the provided callable scorer\n    if self.scoring == \"auto\":\n        scorer = SCORERS[\"accuracy\"]\n    else:\n        scorer = SCORERS.get(self.scoring)\n        if scorer is None:\n            scorer = self.scoring\n\n    # Calculate and return the score\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n", "CodeBleu_score": 37.75454334439294}, {"code": "def score(self, testing_features, testing_target)\n\t\n    # Check if the pipeline has been optimized\n    if not self.fitted_pipeline_:\n        raise ValueError(\"Cannot score pipeline because it has not been optimized.\")\n\n    # Validate the testing features and target\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n\n    # If the scorer is a string, retrieve the scorer from the predefined SCORERS dictionary\n    if isinstance(self.scoring_function, str):\n        if self.scoring_function not in SCORERS:\n            raise ValueError(\n                \"Scoring function {} not found in SCORERS.\".format(self.scoring_function)\n            )\n        scorer = SCORERS[self.scoring_function]\n    # Otherwise, use the provided callable scorer\n    else:\n        scorer = self.scoring_function\n\n    # Calculate and return the score\n    return scorer(self.fitted_pipeline_, testing_features, testing_target)\n\n", "CodeBleu_score": 44.80815678163681}, {"code": "def score(self, testing_features, testing_target)\n\t\n    if self.fitted_pipeline is None:\n        raise ValueError(\n            \"You must fit the pipeline before you can score it. Please call `fit` first.\"\n        )\n\n    if self.scoring_function is None:\n        raise ValueError(\n            \"You must provide a scoring function. Please use the `set_scorer` method.\"\n        )\n\n    testing_features, testing_target = self._check_dataset(\n        testing_features, testing_target\n    )\n\n    if self.scoring_function in SCORERS.keys():\n        scorer = SCORERS[self.scoring_function]\n    else:\n        scorer = self.scoring_function\n\n    score = scorer(self.fitted_pipeline, testing_features, testing_target)\n\n    return score", "CodeBleu_score": 48.475520894359924}]}
{"instance_id": "a04382560333", "generation_result": [{"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\n            \"Imputing missing values in feature set using scikit-learn SimpleImputer...\",\n            file=self.log_file_,\n        )\n    if not isinstance(self._imputer, type(None)):\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n", "CodeBleu_score": 56.44516022902161}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values in feature set...\", file=self.log_file_)\n    if not self._imputer:\n        self._imputer = SimpleImputer(strategy=\"median\")\n        self._imputer.fit(features)\n    return self._imputer.transform(features)\n\n", "CodeBleu_score": 74.80812439164619}, {"code": " def _impute_values(self, features)\n\t\n    if self.verbosity > 1:\n        print(\"Imputing missing values in feature set...\", file=self.log_file_)\n    if not hasattr(self, \"imputer\"):\n        self.imputer = SimpleImputer(strategy=\"median\")\n        self.imputer.fit(features)\n    return self.imputer.transform(features)\n\n", "CodeBleu_score": 65.09872029598752}]}
{"instance_id": "0043d411c332", "generation_result": [{"code": "def _compile_to_sklearn(self, expr)\n\t\n    from sklearn.pipeline import Pipeline\n    from sklearn.compose import ColumnTransformer\n    from sklearn.preprocessing import OneHotEncoder\n    from sklearn.preprocessing import StandardScaler\n    from sklearn.preprocessing import MinMaxScaler\n    from sklearn.preprocessing import MaxAbsScaler\n    from sklearn.preprocessing import RobustScaler\n    from sklearn.preprocessing import PowerTransformer\n    from sklearn.preprocessing import QuantileTransformer\n    from sklearn.preprocessing import Normalizer\n    from sklearn.preprocessing import PolynomialFeatures\n    from sklearn.preprocessing import FunctionTransformer\n    from sklearn.feature_selection import SelectKBest\n    from sklearn.feature_selection import SelectFromModel\n    from sklearn.feature_selection import RFE\n    from sklearn.feature_selection import RFECV\n    from sklearn.feature_selection import VarianceThreshold\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_selection import SelectFwe\n    from sklearn.feature_selection import SelectPercentile\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_selection import SelectFwe\n    from sklearn.feature_selection import SelectPercentile\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_selection import SelectFwe\n    from sklearn.feature_selection import SelectPercentile\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_selection import SelectFwe\n    from sklearn.feature_selection import SelectPercentile\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_selection import SelectFwe\n    from sklearn.feature_selection import SelectPercentile\n    from sklearn.feature_selection import SelectFpr\n    from sklearn.feature_selection import SelectFdr\n    from sklearn.feature_", "CodeBleu_score": 12.00366276191773}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n    code = expr.compile(self.operators)\n    env = {\"np\": np, \"pd\": pd}\n    exec(code, env)\n    pipeline = env[\"pipeline\"]\n    pipeline.memory = self.memory\n    if self.random_state is not None:\n        for _, step in pipeline.steps:\n            if hasattr(step, \"random_state\"):\n                step.random_state = self.random_state\n    return pipeline\n\n", "CodeBleu_score": 38.443770017388076}, {"code": "def _compile_to_sklearn(self, expr)\n\t\n\n    code = self._generate_pipeline_code(expr)\n    scope = {\n        \"StandardScaler\": StandardScaler,\n        \"MinMaxScaler\": MinMaxScaler,\n        \"MaxAbsScaler\": MaxAbsScaler,\n        \"Binarizer\": Binarizer,\n        \"QuantileTransformer\": QuantileTransformer,\n        \"Normalizer\": Normalizer,\n        \"PowerTransformer\": PowerTransformer,\n        \"SimpleImputer\": SimpleImputer,\n        \"MissingIndicator\": MissingIndicator,\n        \"PolynomialFeatures\": PolynomialFeatures,\n        \"SparseInteractions\": SparseInteractions,\n        \"RobustScaler\": RobustScaler,\n        \"PCA\": PCA,\n        \"TruncatedSVD\": TruncatedSVD,\n        \"Nystroem\": Nystroem,\n        \"RBFSampler\": RBFSampler,\n        \"FastICA\": FastICA,\n        \"GaussianRandomProjection\": GaussianRandomProjection,\n        \"SparseRandomProjection\": SparseRandomProjection,\n        \"FeatureAgglomeration\": FeatureAgglomeration,\n        \"SelectKBest\": SelectKBest,\n        \"SelectPercentile\": SelectPercentile,\n        \"VarianceThreshold\": VarianceThreshold,\n        \"GenericUnivariateSelect\": GenericUnivariateSelect,\n        \"RFE\": RFE,\n        \"RFECV\": RFECV,\n        \"SelectFromModel\": SelectFromModel,\n        \"StackingClassifier\": StackingClassifier,\n        \"StackingRegressor\": StackingRegressor,\n        \"VotingClassifier\": VotingClassifier,\n        \"VotingRegressor\": VotingRegressor,\n        \"BaggingClassifier\": BaggingClassifier,\n        \"BaggingRegressor\": BaggingRegressor,\n        \"ExtraTreesClassifier\": ExtraTreesClassifier,\n        \"ExtraTreesRegressor\": ExtraTreesRegressor,\n        \"RandomForestClassifier\": RandomForestClassifier,\n        \"RandomForestRegressor\": RandomForestRegressor,\n", "CodeBleu_score": 23.344849391118306}]}
{"instance_id": "ca0ce462aa76", "generation_result": [{"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create sets of primitive nodes for each individual\n    primitive_sets = [set(individual.primitives) for individual in population]\n\n    # Convert individuals to strings\n    individual_strings = [str(individual) for individual in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = []\n    for i, primitive_set in enumerate(primitive_sets):\n        for j, other_primitive_set in enumerate(primitive_sets[i+1:], i+1):\n            if primitive_set.intersection(other_primitive_set) and individual_strings[i] != individual_strings[j]:\n                eligible_pairs.append((i, j))\n                eligible_pairs.append((j, i))\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n\n    # Return the corresponding individuals from the population\n    return population[i], population[j]\n\n\n\n", "CodeBleu_score": 28.110274610805096}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    # Create a set of primitive nodes for each individual\n    primitive_sets = [set(individual.get_primitive_nodes()) for individual in population]\n\n    # Convert each individual to a string representation\n    individual_strings = [str(individual) for individual in population]\n\n    # Identify pairs of individuals that share at least one primitive and are not identical\n    eligible_pairs = [(i, j) for i in range(len(population)) for j in range(i + 1, len(population)) if len(primitive_sets[i].intersection(primitive_sets[j])) > 0 and individual_strings[i] != individual_strings[j]]\n\n    # Consider eligible pairs in both possible orders\n    eligible_pairs.extend([(j, i) for i, j in eligible_pairs])\n\n    # If no eligible pairs are found, return None for both individuals\n    if not eligible_pairs:\n        return None, None\n\n    # Randomly select one of the eligible pairs\n    i, j = random.choice(eligible_pairs)\n\n    # Return the corresponding individuals from the population\n    return population[i], population[j]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.76915742389831}, {"code": "def pick_two_individuals_eligible_for_crossover(population)\n\t\n    individuals = [individual for individual in population]\n    individuals_as_strings = [str(individual) for individual in individuals]\n    individuals_as_strings_set = set(individuals_as_strings)\n    individuals_as_strings_set_as_list = list(individuals_as_strings_set)\n    individuals_as_strings_set_as_list_of_sets = [set(individual.split()) for individual in individuals_as_strings_set_as_list]\n    individuals_as_strings_set_as_list_of_sets_as_list = list(individuals_as_strings_set_as_list_of_sets)\n    individuals_as_strings_set_as_list_of_sets_as_list_of_lists = [list(individual) for individual in individuals_as_strings_set_as_list_of_sets_as_list]\n    individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets = [set(individual) for individual in individuals_as_strings_set_as_list_of_sets_as_list_of_lists]\n    individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets_as_list = list(individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets)\n    individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets_as_list_of_lists = [list(individual) for individual in individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets_as_list]\n    individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets_as_list_of_lists_of_sets = [set(individual) for individual in individuals_as_strings_set_as_list_of_sets_as_list_of_lists_of_sets_as_list_of_lists]\n   ", "CodeBleu_score": 9.800324939938147}]}
{"instance_id": "4b03c843f506", "generation_result": [{"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n\n    if num_steps > 1:\n        code = \"make_pipeline(", "CodeBleu_score": 12.700606198537153}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n    num_steps = len(steps)\n\n    if num_steps > 1:\n        formatted_steps = \",", "CodeBleu_score": 12.326043327563212}, {"code": "def generate_export_pipeline_code(pipeline_tree, operators)\n\t\n    steps = _process_operator(pipeline_tree, operators)\n\n    if len(steps) > 1:\n        return \"make_pipeline(", "CodeBleu_score": 9.368681534819483}]}
{"instance_id": "e9aec2ee39a4", "generation_result": [{"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}, {"code": "def _process_operator(operator, operators, depth=0)\n\t\n    steps = []\n    op_name = operator[0]\n\n    if op_name == \"CombineDFs\":\n        steps.append(_combine_dfs(operator[1], operator[2], operators))\n    else:\n        input_name, args = operator[1], operator[2:]\n        tpot_op = get_by_name(op_name, operators)\n\n        if input_name != \"input_matrix\":\n            steps.extend(_process_operator(input_name, operators, depth + 1))\n\n        # If the step is an estimator and is not the last step then we must\n        # add its guess as synthetic feature(s)\n        # classification prediction for both regression and classification\n        # classification probabilities for classification if available\n        if tpot_op.root and depth > 0:\n            steps.append(\n                \"StackingEstimator(estimator={})\".format(tpot_op.export(*args))\n            )\n        else:\n            steps.append(tpot_op.export(*args))\n    return steps\n\n", "CodeBleu_score": 85.26779567740981}]}
{"instance_id": "0513bf969510", "generation_result": [{"code": "def transform(self, X)\n\t\n    # Select categorical features based on a threshold\n    categorical_features = X.select_dtypes(include=['object']).columns\n    if len(categorical_features) == 0:\n        raise ValueError(\"No categorical features found in the input data.\")\n    else:\n        # Apply one-hot encoding to categorical features\n        X_transformed = pd.get_dummies(X[categorical_features], drop_first=True)\n        return X_transformed", "CodeBleu_score": 27.522850026944052}, {"code": "def transform(self, X)\n\t\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError(\"Input data must be a pandas DataFrame.\")\n    self.categorical_features = [\n        col for col in X.columns if X[col].dtype == \"object\"\n    ]\n    if len(self.categorical_features) == 0:\n        raise ValueError(\"No categorical features found in input data.\")\n    self.one_hot_encoder = OneHotEncoder(\n        sparse=False, handle_unknown=\"ignore\"\n    )\n    self.one_hot_encoder.fit(X[self.categorical_features])\n    X_transformed = self.one_hot_encoder.transform(\n        X[self.categorical_features]\n    )\n    X_transformed = pd.DataFrame(\n        X_transformed, columns=self.one_hot_encoder.get_feature_names_out()\n    )\n    return X_transformed", "CodeBleu_score": 28.793513967199345}, {"code": "def transform(self, X)\n\t\n    # Check if X is a pandas DataFrame\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError(\"X must be a pandas DataFrame\")\n\n    # Check if X has only categorical features\n    if not all(X.dtypes == \"category\"):\n        raise ValueError(\"X must have only categorical features\")\n\n    # Check if X has at least one categorical feature\n    if len(X.select_dtypes(include=[\"category\"]).columns) == 0:\n        raise ValueError(\"X must have at least one categorical feature\")\n\n    # Check if threshold is a float between 0 and 1\n    if not isinstance(self.threshold, float) or not 0 <= self.threshold <= 1:\n        raise ValueError(\"threshold must be a float between 0 and 1\")\n\n    # Select categorical features based on threshold\n    selected_features = []\n    for feature in X.columns:\n        if X[feature].value_counts(normalize=True).max() < self.threshold:\n            selected_features.append(feature)\n\n    # Check if any categorical features were selected\n    if len(selected_features) == 0:\n        raise ValueError(\"No categorical features were selected\")\n\n    # Apply one-hot encoding to selected categorical features\n    X_transformed = pd.get_dummies(X[selected_features], prefix=selected_features)\n\n    return X_transformed\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.86899134827845}]}
{"instance_id": "5b1bcf42ca9e", "generation_result": [{"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    # Compute the sensitivity and specificity for each class\n    classes = np.unique(y_true)\n    class_accuracies = []\n    for c in classes:\n        # Compute the sensitivity and specificity\n        tp = np.sum((y_true == c) & (y_pred == c))\n        fn = np.sum((y_true == c) & (y_pred != c))\n        tn = np.sum((y_true != c) & (y_pred != c))\n        fp = np.sum((y_true != c) & (y_pred == c))\n        sensitivity = tp / (tp + fn)\n        if tn + fp == 0:\n            specificity = 1\n        else:\n            specificity = tn / (tn + fp)\n        # Compute the class accuracy\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n\n    # Compute the balanced accuracy\n    balanced_accuracy = np.mean(class_accuracies)\n    return balanced_accuracy\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 24.801950700935514}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    classes = np.unique(y_true)\n    class_accuracies = []\n    for c in classes:\n        tp = np.sum((y_true == c) & (y_pred == c))\n        tn = np.sum((y_true != c) & (y_pred != c))\n        fp = np.sum((y_true != c) & (y_pred == c))\n        fn = np.sum((y_true == c) & (y_pred != c))\n        sensitivity = tp / (tp + fn)\n        specificity = tn / (tn + fp) if (tn + fp) > 0 else 1\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n    return np.mean(class_accuracies)\n\n\n\n", "CodeBleu_score": 22.19465743885857}, {"code": "def balanced_accuracy(y_true, y_pred)\n\t\n    classes = np.unique(y_true)\n    class_accuracies = []\n    for c in classes:\n        true_positives = np.sum((y_true == c) & (y_pred == c))\n        true_negatives = np.sum((y_true != c) & (y_pred != c))\n        false_positives = np.sum((y_true != c) & (y_pred == c))\n        false_negatives = np.sum((y_true == c) & (y_pred != c))\n        sensitivity = true_positives / (true_positives + false_negatives)\n        specificity = true_negatives / (true_negatives + false_positives)\n        if len(classes) == 1:\n            specificity = 1\n        class_accuracy = (sensitivity + specificity) / 2\n        class_accuracies.append(class_accuracy)\n    return np.mean(class_accuracies)\n\n\n", "CodeBleu_score": 25.071615045792107}]}
{"instance_id": "19a9ad39de0a", "generation_result": [{"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    if not hasattr(X, \"tocoo\"):\n        raise TypeError(\"Input type is not supported.\")\n    n_samples, n_features = X.shape\n    X_coo = X.tocoo()\n    row_nnz = np.bincount(X_coo.row, minlength=n_samples)\n    col_nnz = np.bincount(X_coo.col, minlength=n_features)\n    nnz_X = np.hstack((row_nnz.reshape(-1, 1), col_nnz.reshape(-1, 1)))\n    return np.hstack((nnz_X, X_coo.data.reshape(-1, 1)))\n\n\n\n\n", "CodeBleu_score": 30.33098210168159}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    n_samples, n_features = X.shape\n\n    # build new array of shape(n_samples, n_features + 2)\n    non_zero = np.diff(X.indptr)\n    data = np.empty((n_samples, n_features + 2), dtype=X.dtype)\n    data[:, 0] = non_zero\n    data[:, 1] = n_features - non_zero\n    data[:, 2:] = X.toarray()\n\n    return data", "CodeBleu_score": 19.02335321671302}, {"code": "def transform(self, X, y=None)\n\t\n    X = check_array(X, accept_sparse='csr')\n    n_samples, n_features = X.shape\n\n    # Count the number of non-zero elements per row\n    nnz = X.getnnz(axis=1)\n    # Count the number of zero elements per row\n    zeros = n_features - nnz\n\n    # Create a new array with the additional columns\n    X_new = np.column_stack((nnz, zeros, X))\n\n    return X_new", "CodeBleu_score": 10.945759476915768}]}
{"instance_id": "5e8db0b5d447", "generation_result": [{"code": "def _init_pretest(self, features, target)\n\t\n    # Calculate the number of unique target classes\n    self.n_classes_ = len(np.unique(target))\n\n    # Ensure the training size is at least this number\n    if self.n_classes_ > len(features):\n        raise ValueError(\"Number of unique target classes is greater than the number of training examples.\")\n\n    # Split the features and target into pretest_X and pretest_y with a specified random state\n    self.pretest_X_, self.pretest_y_ = train_test_split(features, target, train_size=self.n_classes_, random_state=self.random_state)\n\n    # If all target classes are not included in pretest_y, adjust pretest_y to include at least one example from each class by indexing unique target values\n    if len(np.unique(self.pretest_y_)) != self.n_classes_:\n        unique_target_values = np.unique(target)\n        for value in unique_target_values:\n            if value not in self.pretest_y_:\n                index = np.where(target == value)[0][0]\n                self.pretest_X_ = np.vstack((self.pretest_X_, features[index]))\n                self.pretest_y_ = np.hstack((self.pretest_y_, target[index]))\n\n    # Print the number of unique target classes and the number of examples in pretest_X and pretest_y\n    print(f\"Number of unique target classes: {self.n_classes_}\")\n    print(f\"Number of examples in pretest_X: {len(self.pretest_X_)}\")\n    print(f\"Number of examples in pretest_y: {len(self.pretest_y_)}\")\n\n\n\n\n\n\n", "CodeBleu_score": 32.00804474658801}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.pretest_size = len(np.unique(target))\n    if self.pretest_size > self.train_size:\n        self.train_size = self.pretest_size\n    pretest_X, pretest_y = train_test_split(\n        features, target, train_size=self.pretest_size, random_state=self.random_state\n    )\n    if len(np.unique(pretest_y)) != len(np.unique(target)):\n        unique_target_values = np.unique(target)\n        pretest_y = np.array([unique_target_values[i] for i in range(len(unique_target_values))])\n    return pretest_X, pretest_y\n\n", "CodeBleu_score": 31.808391244361}, {"code": "def _init_pretest(self, features, target)\n\t\n    self.pretest_size = len(set(target))\n    self.pretest_X, self.pretest_y = train_test_split(features, target, train_size=self.pretest_size, random_state=self.random_state)\n    if len(set(self.pretest_y)) != len(set(target)):\n        for i in set(target):\n            self.pretest_X = np.vstack((self.pretest_X, features[target == i][0]))\n            self.pretest_y = np.hstack((self.pretest_y, i))\n\n\n\n\n", "CodeBleu_score": 23.474217451752644}]}
{"instance_id": "5e3d48667396", "generation_result": [{"code": "def _to_numpy_type(dtype)\n\t\n    if dtype == tf.float32:\n        return np.float32\n    elif dtype == tf.float64:\n        return np.float64\n    elif dtype == tf.int32:\n        return np.int32\n    elif dtype == tf.int64:\n        return np.int64\n    elif dtype == tf.bool:\n        return np.bool\n    elif dtype == tf.string:\n        return np.str\n    else:\n        return dtype\n\n", "CodeBleu_score": 39.94008966836287}, {"code": "def _to_numpy_type(dtype)\n\t\n    if isinstance(dtype, tf.dtypes.DType):\n        return dtype.as_numpy_dtype\n    else:\n        return dtype\n\n", "CodeBleu_score": 31.29023423875224}, {"code": "def _to_numpy_type(dtype)\n\t\n    import tensorflow as tf\n    if isinstance(dtype, tf.dtypes.DType):\n        return dtype.as_numpy_dtype\n    else:\n        return dtype\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.4938687241961}]}
{"instance_id": "8f1120fdd463", "generation_result": [{"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        if batch_size is not None:\n            ds = ds.batch(batch_size)\n        return np.concatenate([_to_numpy(x) for x in ds], axis=0)\n    except TypeError:\n        return np.array([_to_numpy(x) for x in ds])\n", "CodeBleu_score": 15.361614954710861}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        ds = ds.batch(batch_size)\n        ds_numpy = [batch for batch in ds]\n    except:\n        ds_numpy = []\n        for batch in ds:\n            ds_numpy.append(batch)\n    ds_numpy = np.concatenate([_to_numpy(e) for e in ds_numpy], axis=0)\n    return ds_numpy\n\n", "CodeBleu_score": 18.876844848155386}, {"code": "def _dataset_as_numpy(ds, batch_size=None)\n\t\n    try:\n        ds = ds.batch(batch_size)\n    except TypeError:\n        ds = ds.batch(batch_size, drop_remainder=True)\n    ds_numpy = [batch for batch in ds.as_numpy_iterator()]\n    return ds_numpy\n\n", "CodeBleu_score": 16.089780759652488}]}
{"instance_id": "282271955871", "generation_result": [{"code": "def get_prng(seed)\n\t\n    if not isinstance(seed, int):\n        raise TypeError(\"seed must be an integer\")\n\n    # Split the seed into two 32-bit unsigned integers\n    key1 = seed >> 32\n    key2 = seed & 0xFFFFFFFF\n\n    # Concatenate the two 32-bit unsigned integers to form the PRNG key\n    key = jax.random.PRNGKey(key1)\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1)[0]\n    key = jax.random.split(key, 1", "CodeBleu_score": 23.624186133634847}, {"code": "def get_prng(seed)\n\t\n    assert isinstance(seed, int)\n    return jax.random.PRNGKey(seed)\n\n", "CodeBleu_score": 3.0540679100654424}, {"code": "def get_prng(seed)\n\t\n    if not isinstance(seed, int):\n        raise TypeError(f\"The seed must be an integer, but got {type(seed)}.\")\n    seed = int(seed)\n    key1, key2 = jax.random.split(jax.random.PRNGKey(seed))\n    return jax.random.PRNGKey(\n        jnp.uint32(key1[0]), jnp.uint32(key1[1]), jnp.uint32(key2[0]), jnp.uint32(key2[1])\n    )\n\n", "CodeBleu_score": 25.766072173306316}]}
{"instance_id": "42234dccce9a", "generation_result": [{"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        s = s.dt.tz_convert(dtype.tz)\n    elif isinstance(s.dtype, datetime64):\n        s = s.dt.tz_localize(dtype.tz)\n    elif isinstance(s.dtype, np.number):\n        s = pd.to_datetime(s, unit=\"ms\", utc=True).dt.tz_localize(dtype.tz)\n    else:\n        s = pd.to_datetime(s, utc=True).dt.tz_localize(dtype.tz)\n    return s\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 61.05464011101024}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(dtype, pd.DatetimeTZDtype):\n        return s.dt.tz_convert(dtype.tz)\n    if isinstance(pandas_type, pd.DatetimeTZDtype):\n        return s.dt.tz_localize(pandas_type.tz)\n    if s.dtype.kind in \"mM\":\n        return pd.to_datetime(s, utc=True).dt.tz_localize(dtype.tz)\n    return pd.to_datetime(s).dt.tz_localize(dtype.tz)\n\n\n\n", "CodeBleu_score": 56.53589410806028}, {"code": "def convert_Timestamp(cls, s, dtype, pandas_type)\n\t\n    if isinstance(s.dtype, pd.DatetimeTZDtype):\n        s = s.dt.tz_convert(s.dt.tz)\n    elif isinstance(s.dtype, datetime64):\n        s = s.dt.tz_localize(\"UTC\")\n    elif isinstance(s.dtype, np.number):\n        s = pd.to_datetime(s, utc=True)\n    else:\n        s = pd.to_datetime(s, utc=True)\n    return s.dt.tz_localize(\"UTC\")\n\n\n\n", "CodeBleu_score": 52.6746849432024}]}
{"instance_id": "9cee7388879b", "generation_result": [{"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is not None:\n        arg = arg.dt.tz_convert(\"UTC\")\n    if lower_bound.dtype.tz is not None:\n        lower_bound = lower_bound.dt.tz_convert(\"UTC\")\n    if upper_bound.dtype.tz is not None:\n        upper_bound = upper_bound.dt.tz_convert(\"UTC\")\n    return arg.map_partitions(\n        lambda x: (lower_bound <= x) & (x <= upper_bound),\n        meta=pd.Series(dtype=\"boolean\"),\n    )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 30.033979884207973}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtypes[0] == \"datetime64[ns]\":\n        arg = arg.dt.tz_localize(\"UTC\")\n    if lower_bound.dtypes[0] == \"datetime64[ns]\":\n        lower_bound = lower_bound.dt.tz_localize(\"UTC\")\n    if upper_bound.dtypes[0] == \"datetime64[ns]\":\n        upper_bound = upper_bound.dt.tz_localize(\"UTC\")\n    lower_bound = lower_bound.iloc[0]\n    upper_bound = upper_bound.iloc[0]\n    indexer = (arg >= lower_bound) & (arg <= upper_bound)\n    indexer = indexer.compute()\n    return cls(pd.DataFrame(indexer, columns=[\"__index__\"]))\n\n", "CodeBleu_score": 30.22982997364707}, {"code": "def visit(cls, op: ops.BetweenTime, arg, lower_bound, upper_bound)\n\t\n    if arg.dtype.tz is not None:\n        arg = arg.dt.tz_convert(\"UTC\")\n\n    indexer = (arg >= lower_bound) & (arg <= upper_bound)\n    return indexer.to_dask_array()\n\n", "CodeBleu_score": 21.961883283110865}]}
{"instance_id": "0ab1cc8ccf71", "generation_result": [{"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    elif isinstance(value, dd.Scalar):\n        return dd.from_array(value.value, 1).to_series()\n    elif isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    elif isinstance(value, tuple):\n        return dd.from_array(value, 1).to_series()\n    elif isinstance(value, list):\n        return dd.from_array(value, 1).to_series()\n    elif isinstance(value, dict):\n        return dd.from_array(value, 1).to_series()\n    else:\n        return dd.from_array(value, 1).to_series()\n\n", "CodeBleu_score": 31.814062721333386}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, dd.Series):\n        return value\n    elif isinstance(value, dd.Scalar):\n        return dd.from_array(value.to_array(), npartitions=1)\n    elif isinstance(value, pd.Series):\n        return dd.from_pandas(value, npartitions=1)\n    elif isinstance(value, tuple):\n        return dd.from_pandas(pd.Series(value), npartitions=1)\n    elif isinstance(value, list):\n        return dd.from_pandas(pd.Series(value), npartitions=1)\n    elif isinstance(value, dict):\n        return dd.from_pandas(pd.Series(value), npartitions=1)\n    else:\n        return dd.from_pandas(pd.Series([value]), npartitions=1)\n\n", "CodeBleu_score": 38.79050514033979}, {"code": "def asseries(cls, value, like=None)\n\t\n    if isinstance(value, (pd.Series, pd.DataFrame)):\n        return dd.from_pandas(value, npartitions=1)\n    elif isinstance(value, (dd.Series, dd.DataFrame)):\n        return value\n    elif isinstance(value, dask.array.Array):\n        return dd.from_dask_array(value)\n    elif isinstance(value, dask.dataframe.core.Series):\n        return dd.from_dask_array(value.values)\n    elif isinstance(value, (int, float, str, bool)):\n        return dd.from_array([value], npartitions=1)\n    elif isinstance(value, (tuple, list)):\n        return dd.from_array(value, npartitions=1)\n    elif isinstance(value, dict):\n        return dd.from_array([value], npartitions=1)\n    elif isinstance(value, dask.array.core.Scalar):\n        return dd.from_array([value.value], npartitions=1)\n    elif like is not None:\n        if isinstance(like, (pd.Series, pd.DataFrame)):\n            return dd.from_pandas(like, npartitions=1)\n        elif isinstance(like, (dd.Series, dd.DataFrame)):\n            return like\n        elif isinstance(like, dask.array.Array):\n            return dd.from_dask_array(like)\n        elif isinstance(like, dask.dataframe.core.Series):\n            return dd.from_dask_array(like.values)\n        elif isinstance(like, (int, float, str, bool)):\n            return dd.from_array([like], npartitions=1)\n        elif isinstance(like, (tuple, list)):\n            return dd.from_array(like, npartitions=1)\n        elif isinstance(like, dict):\n            return dd.from_array([like], npartitions=1)\n        elif isinstance(like, dask.array.core", "CodeBleu_score": 37.7382688219514}]}
{"instance_id": "926220a06a0c", "generation_result": [{"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k}.\"\n                f\" Got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 88.24580567012508}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k},\"\n                f\" got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)", "CodeBleu_score": 89.83741871525928}, {"code": "def do_connect(\n        self,\n        dictionary: MutableMapping[str, dd.DataFrame] | None = None,\n    ) -> None\n\t\n    if dictionary is None:\n        dictionary = {}\n\n    for k, v in dictionary.items():\n        if not isinstance(v, (dd.DataFrame, pd.DataFrame)):\n            raise TypeError(\n                f\"Expected an instance of 'dask.dataframe.DataFrame' for {k}.\"\n                f\" got an instance of '{type(v).__name__}' instead.\"\n            )\n    super().do_connect(dictionary)\n\n", "CodeBleu_score": 89.7194918665626}]}
{"instance_id": "95afc38c9125", "generation_result": [{"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    try:\n        from sklearn.base import BaseEstimator\n        from sklearn.utils import all_estimators\n    except ImportError:\n        raise ImportError(\"Unable to import sklearn.base.BaseEstimator and sklearn.utils.all_estimators. \"\n                          \"Please make sure you have scikit-learn installed.\")\n    try:\n        from importlib import import_module\n    except ImportError:\n        raise ImportError(\"Unable to import importlib.import_module. \"\n                          \"Please make sure you have importlib installed.\")\n\n    def get_module_members(module_name):\n        module = import_module(module_name)\n        classes = {name: cls for name, cls in module.__dict__.items() if isinstance(cls, type)}\n        return classes\n\n    classes = get_module_members(library_name)\n    if estimator_name not in classes:\n        raise ValueError(f\"Estimator {estimator_name} could not be found in module {library_name}\")\n\n    matching_estimators = [cls for name, cls in classes.items() if name.lower() == estimator_name.lower()]\n    if len(matching_estimators) > 1:\n        logger.debug(f\"Multiple classes found for estimator {estimator_name}: {matching_estimators}\")\n        logger.warning(f\"Multiple classes found for estimator {estimator_name}. Using the first one: {matching_estimators[0]}\")\n\n    selected_estimator_class = matching_estimators[0]\n\n    if not issubclass(selected_estimator_class, BaseEstimator):\n        logger.info(f\"Estimator {estimator_name} is not a subclass of sklearn's BaseEstimator.\")\n\n    return selected_estimator_class\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.176331138195614}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    import logging\n\n    from sklearn.base import BaseEstimator\n\n    from . import _get_module_members\n\n    logger = logging.getLogger(__name__)\n\n    classes = _get_module_members(library_name)\n\n    if estimator_name not in classes:\n        raise ValueError(\n            f\"Estimator {estimator_name} could not be found in module {library_name}.\"\n        )\n\n    classes = {k.lower(): v for k, v in classes.items()}\n    selected_estimator = classes[estimator_name.lower()]\n\n    if len(classes) > 1:\n        logger.debug(\n            f\"Multiple estimators with name {estimator_name} found in module {library_name}. \"\n            f\"Using {selected_estimator}.\"\n        )\n        logger.warning(\n            f\"Multiple estimators with name {estimator_name} found in module {library_name}. \"\n            f\"Using {selected_estimator}. \"\n        )\n\n    if not issubclass(selected_estimator, BaseEstimator):\n        logger.info(\n            f\"The class {selected_estimator} is not a subclass of sklearn's BaseEstimator. \"\n            f\"It is recommended to use a class that inherits from BaseEstimator to ensure compatibility with sklearn.\"\n        )\n\n    return selected_estimator\n\n", "CodeBleu_score": 44.38147187712871}, {"code": "def get_estimator(library_name: str, estimator_name: str)\n\t\n    from autogluon.common.utils import get_module_members\n    from autogluon.common.utils import log_warning_message\n    from autogluon.common.utils import log_debug_message\n    from autogluon.common.utils import log_info_message\n    from autogluon.common.utils import log_print\n    from autogluon.common.utils import warning_filter\n    from sklearn.base import BaseEstimator\n    if library_name == 'sklearn':\n        classes = get_module_members('sklearn.ensemble')\n    elif library_name == 'mxnet':\n        classes = get_module_members('mxnet.gluon.contrib.estimator')\n    else:\n        raise ValueError(f'Unsupported library: {library_name}')\n    selected_estimator = None\n    for (name, cls) in classes.items():\n        if (name == estimator_name):\n            if (selected_estimator is not None):\n                log_warning_message(f'Multiple classes found for estimator {estimator_name}: {selected_estimator}, {cls}. Using {selected_estimator}')\n            else:\n                selected_estimator = cls\n    if (selected_estimator is None):\n        raise ValueError(f'Estimator {estimator_name} could not be found in module {library_name}')\n    if (not issubclass(selected_estimator, BaseEstimator)):\n        log_info_message(f'Selected estimator {selected_estimator} is not a subclass of sklearn.BaseEstimator')\n    return selected_estimator", "CodeBleu_score": 33.28347726445553}]}
{"instance_id": "9562a9cc043b", "generation_result": [{"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    import json\n    import os\n\n    # Load the mapping from a JSON file\n    mapping_path = os.path.join(os.path.dirname(__file__), 'mapping.json')\n    with open(mapping_path, 'r') as f:\n        mapping = json.load(f)\n\n    # Check if the estimator name ends with any of the postfixes in the mapping\n    for postfix, task in mapping.items():\n        if estimator_name.endswith(postfix):\n            return task\n\n    # If no match is found, return \"unknown\"\n    return \"unknown\"\n\n\n", "CodeBleu_score": 45.04026091175509}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    import json\n    with open(\"estimator_to_task_mapping.json\", \"r\") as f:\n        estimator_to_task_mapping = json.load(f)\n    for task, estimators in estimator_to_task_mapping.items():\n        for estimator in estimators:\n            if estimator_name.endswith(estimator):\n                return task\n    return \"unknown\"\n\n", "CodeBleu_score": 41.06607232915369}, {"code": "def estimator_to_task(estimator_name: str) -> str\n\t\n    import json\n    import os\n\n    # Get the directory of the current script\n    script_dir = os.path.dirname(os.path.abspath(__file__))\n\n    # Construct the path to the JSON file relative to the current script\n    json_file_path = os.path.join(script_dir, \"estimator_task_mapping.json\")\n\n    # Open the JSON file\n    with open(json_file_path, \"r\") as json_file:\n        # Load the JSON data into a dictionary\n        mapping = json.load(json_file)\n\n    # Iterate over the keys in the mapping dictionary\n    for key in mapping:\n        # Check if the estimator name ends with the current key\n        if estimator_name.endswith(key):\n            # If a match is found, return the corresponding task\n            return mapping[key]\n\n    # If no match is found, return \"unknown\"\n    return \"unknown\"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.8710165298245}]}
{"instance_id": "2f50195d043a", "generation_result": [{"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data = {}\n    for filename in get_filenames_by_prefix(data_cache, data_name):\n        if filename.endswith(\".json\"):\n            continue\n        component, ext = filename.split(\".\")\n        data[component] = load_data_file(os.path.join(data_cache, filename), ext)\n    return data\n\n", "CodeBleu_score": 37.25482840131109}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    assert os.path.isdir(data_cache)\n    data_filenames = get_filenames_by_prefix(data_cache, data_name)\n    data_dict = dict()\n    for filename in data_filenames:\n        if filename.endswith(\".json\"):\n            continue\n        component, extension = filename.replace(data_name, \"\").split(\".\")\n        data_dict[component] = load_data_file(os.path.join(data_cache, filename), extension)\n    return data_dict\n\n", "CodeBleu_score": 49.98850277071173}, {"code": "def load_data_from_cache(data_cache: str, data_name: str) -> Dict\n\t\n    data_cache = Path(data_cache)\n    data_name = Path(data_name)\n    data = {}\n    for filepath in data_cache.iterdir():\n        if filepath.suffix == \".json\":\n            continue\n        component, extension = filepath.stem.split(\".\")\n        data[component] = load_data_file(filepath, extension)\n    return data\n\n", "CodeBleu_score": 31.43817306355498}]}
{"instance_id": "e0281206029e", "generation_result": [{"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n\n    if os.path.isfile(filename):\n        print(f\"{filename} already exists.\")\n        return\n\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(f\"Failed to download from {url}. Status code: {response.status_code}\")\n\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written_size = 0\n\n        with open(filename, \"wb\") as file:\n            for data in response.iter_content(block_size):\n                written_size += len(data)\n                file.write(data)\n\n        if total_size > 0 and written_size != total_size:\n            raise AssertionError(\"Error downloading file. Total size mismatch.\")\n", "CodeBleu_score": 67.51546194433703}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n    if os.path.isfile(filename):\n        print(f\"{filename} already exists.\")\n        return\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code == 200:\n            total_size = int(response.headers.get(\"Content-Length\", 0))\n            block_size = 1024\n            written = 0\n            with open(filename, \"wb\") as f:\n                for data in response.iter_content(block_size):\n                    written = written + len(data)\n                    f.write(data)\n            if total_size != 0 and written != total_size:\n                raise AssertionError(\n                    \"Error, something went wrong while downloading the file. The file might be corrupted.\")\n        else:\n            raise AssertionError(\n                f\"Error, something went wrong while downloading the file. The status code is {response.status_code}.\")\n\n", "CodeBleu_score": 59.261962711154894}, {"code": "def retrieve(url: str, filename: str) -> None\n\t\n    import os\n    import requests\n\n    if os.path.isfile(filename):\n        print(f\"{filename} already exists\")\n        return\n\n    if url.startswith(\"http\"):\n        response = requests.get(url, stream=True)\n        if response.status_code != 200:\n            raise AssertionError(f\"Failed to download {url}: {response.status_code}\")\n        total_size = int(response.headers.get(\"content-length\", 0))\n        block_size = 1024\n        written = 0\n        with open(filename, \"wb\") as f:\n            for data in response.iter_content(block_size):\n                written += len(data)\n                f.write(data)\n        if total_size != 0 and written != total_size:\n            raise AssertionError(\"ERROR, something went wrong\")\n\n", "CodeBleu_score": 67.64729794947402}]}
{"instance_id": "a69a71cc2fe8", "generation_result": [{"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    (x, y) = fetch_covtype(return_X_y=True)\n    y = y - 1\n    if dataset_params.get(\"binary\", False):\n        y[y != 0] = 1\n    (x_train, x_test, y_train, y_test) = train_test_split(\n        x, y, test_size=0.2, random_state=42\n    )\n    train_data = {\n        \"x\": x_train,\n        \"y\": y_train,\n    }\n    test_data = {\n        \"x\": x_test,\n        \"y\": y_test,\n    }\n    description = {\n        \"name\": \"covtype\",\n        \"n_classes\": 2,\n        \"default_split\": {\n            \"train_size\": 0.8,\n            \"stratify\": True,\n        },\n    }\n    return (train_data, test_data, description)\n\n", "CodeBleu_score": 37.613260485081945}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    (X_train, y_train), (X_test, y_test) = covtype.load_data()\n    y_train = y_train - 1\n    y_test = y_test - 1\n    if dataset_params[\"convert_binary\"]:\n        y_train = (y_train > 0).astype(int)\n        y_test = (y_test > 0).astype(int)\n    dataset = {\n        \"X_train\": X_train,\n        \"y_train\": y_train,\n        \"X_test\": X_test,\n        \"y_test\": y_test,\n    }\n    description = {\n        \"name\": data_name,\n        \"n_classes\": len(np.unique(y_train)),\n        \"length\": len(X_train) + len(X_test),\n        \"split_name\": \"train_test\",\n        \"train_length\": len(X_train),\n        \"test_length\": len(X_test),\n    }\n    return dataset, description\n\n", "CodeBleu_score": 39.36700805761117}, {"code": "def load_covtype(\n    data_name: str, data_cache: str, raw_data_cache: str, dataset_params: Dict\n) -> Tuple[Dict, Dict]\n\t\n    data = {}\n    with open(os.path.join(raw_data_cache, data_name + \".data\"), \"r\") as f:\n        lines = f.readlines()\n    lines = [line.strip().split(\",\") for line in lines]\n    data[\"features\"] = np.array([[float(x) for x in line[:-1]] for line in lines])\n    data[\"labels\"] = np.array([int(line[-1]) for line in lines])\n    data[\"labels\"] -= 1\n    if dataset_params[\"convert_to_binary\"]:\n        data[\"labels\"] = (data[\"labels\"] == 2).astype(int)\n    data[\"num_classes\"] = len(np.unique(data[\"labels\"]))\n    description = {\n        \"num_classes\": data[\"num_classes\"],\n        \"default_split\": {\"train\": 0.8, \"val\": 0.1, \"test\": 0.1},\n    }\n    return data, description\n\n", "CodeBleu_score": 34.4560157121184}]}
{"instance_id": "129cbd2529ef", "generation_result": [{"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    # iteration with inner recursion\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}, {"code": "def flatten_list(input_list: List, ensure_type_homogeneity: bool = False) -> List\n\t\n    output_list = list()\n    # iteration with inner recursion\n    for value in input_list:\n        if isinstance(value, list):\n            inner_flat_list = flatten_list(value)\n            for inner_value in inner_flat_list:\n                output_list.append(inner_value)\n        else:\n            output_list.append(value)\n    if ensure_type_homogeneity:\n        ensure_list_types_homogeneity(output_list)\n    return output_list\n\n", "CodeBleu_score": 81.48787186632478}]}
{"instance_id": "2d38c2c60b59", "generation_result": [{"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n\n    def _logit(x: np.ndarray, eps=None, complex_mode=\"jax\"):\n        if complex_mode == \"jax\":\n            return jnp.logit(x, eps)\n        if complex_mode == \"split\":\n            return jnp.logit(x.real, eps) + 1j * jnp.logit(x.imag, eps)\n        if complex_mode == \"magnitude\":\n            return jnp.logit(jnp.abs(x), eps)\n\n    return handle_complex(\n        x,\n        _logit,\n        eps=eps,\n        complex_mode=complex_mode,\n        out=out,\n    )\n\n", "CodeBleu_score": 28.73275507393683}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    return np.logit(x, eps=eps, out=out)", "CodeBleu_score": 17.1742890076788}, {"code": "def logit(\n    x: np.ndarray,\n    /,\n    *,\n    eps: Optional[float] = None,\n    complex_mode: Literal[\"split\", \"magnitude\", \"jax\"] = \"jax\",\n    out: Optional[np.ndarray] = None,\n)\n\t\n    return np.logit(x, eps=eps, out=out)", "CodeBleu_score": 17.1742890076788}]}
{"instance_id": "205e296f8621", "generation_result": [{"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(x < -lambd, x, np.where(x > lambd, x, 0)).astype(x.dtype)\n\n", "CodeBleu_score": 38.022240999588696}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    return np.where(np.abs(x) > lambd, x, 0)\n\n", "CodeBleu_score": 24.094178490219818}, {"code": "def hardshrink(\n    x: np.ndarray, /, *, lambd: float = 0.5, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.copy(x)\n    np.less(x, -lambd, out=out, where=np.less(x, -lambd))\n    np.greater(x, lambd, out=out, where=np.greater(x, lambd))\n    return out", "CodeBleu_score": 41.03030047497693}]}
{"instance_id": "5b133f6ebe2d", "generation_result": [{"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    window = []\n    for n in range(window_length):\n        window.append(round(math.sin((math.pi / 2) * (math.sin(math.pi * (n / (window_length - 1)))) ** 2), 8))\n    return np.array(window, dtype=dtype, out=out)\n\n", "CodeBleu_score": 36.24231086254726}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    window_length = int(window_length)\n    window = []\n    for i in range(window_length):\n        window.append(\n            round(\n                np.sin(\n                    (np.pi / 2) * (np.sin(np.pi * (i) / (window_length))) ** 2\n                ),\n                8,\n            )\n        )\n    return np.array(window, dtype=dtype, out=out)\n\n", "CodeBleu_score": 34.141871234138215}, {"code": "def vorbis_window(\n    window_length: np.ndarray,\n    *,\n    dtype: np.dtype = np.float32,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n\n    window_length = int(window_length)\n    if window_length <= 0:\n        raise ValueError(\"Window length must be greater than 0\")\n    if out is not None:\n        if out.shape != (window_length,):\n            raise ValueError(\"Output array shape must be (window_length,)\")\n        if out.dtype != dtype:\n            raise ValueError(\"Output array dtype must be {}\".format(dtype))\n\n    window = []\n    for i in range(window_length):\n        window.append(\n            round(\n                np.sin(\n                    (np.pi / 2) * (np.sin(np.pi * (i / (window_length - 1)) ** 2)) ** 2\n                ),\n                8,\n            )\n        )\n\n    window = np.array(window, dtype=dtype)\n    if out is not None:\n        out[:] = window\n        return out\n    else:\n        return window\n\n", "CodeBleu_score": 39.083964512522364}]}
{"instance_id": "473296f771a9", "generation_result": [{"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result", "CodeBleu_score": 94.57815771555306}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result\n\n", "CodeBleu_score": 94.57815771555306}, {"code": "def polyval(coeffs: np.ndarray, x: np.ndarray) -> np.ndarray\n\t\n    with ivy.PreciseMode(True):\n        promoted_type = ivy.promote_types(ivy.dtype(coeffs[0]), ivy.dtype(x[0]))\n    result = np.polyval(coeffs, x)\n    result = np.asarray(result, np.dtype(promoted_type))\n    return result\n\n", "CodeBleu_score": 94.57815771555306}]}
{"instance_id": "b8455221cb2a", "generation_result": [{"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret\n\n", "CodeBleu_score": 78.35765070891931}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret\n\n", "CodeBleu_score": 78.35765070891931}, {"code": "def amax(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Sequence[int]]] = None,\n    keepdims: bool = False,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    ret = np.amax(a=x, axis=axis, out=out, keepdims=keepdims)\n    return np.asarray(ret) if np.isscalar(ret) else ret", "CodeBleu_score": 78.35765070891931}]}
{"instance_id": "f72489f434a3", "generation_result": [{"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if not isinstance(x1, np.ndarray):\n        x1 = np.asarray(x1)\n    if not isinstance(x2, np.ndarray):\n        x2 = np.asarray(x2)\n    promoted_type = promote_types_of_inputs(x1.dtype, x2.dtype)\n    if promoted_type == np.float16:\n        x1, x2 = np.float16(x1), np.float16(x2)\n    elif promoted_type == np.float32:\n        x1, x2 = np.float32(x1), np.float32(x2)\n    elif promoted_type == np.float64:\n        x1, x2 = np.float64(x1), np.float64(x2)\n    else:\n        x1, x2 = np.float_(x1), np.float_(x2)\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 45.182711013369826}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = ivy.promote_types_of_inputs(x1, x2)\n    if not ivy.is_float_dtype(x1):\n        x1 = ivy.astype(x1, ivy.default_float_dtype(as_native=True))\n        x2 = ivy.astype(x2, ivy.default_float_dtype(as_native=True))\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 69.96355147702037}, {"code": "def copysign(\n    x1: npt.ArrayLike,\n    x2: npt.ArrayLike,\n    /,\n    *,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    x1, x2 = promote_types_of_inputs(x1, x2)\n    if not isinstance(x1.dtype, np.float_):\n        x1, x2 = np.asarray(x1, dtype=np.float_), np.asarray(x2, dtype=np.float_)\n    return np.copysign(x1, x2, out=out)\n\n", "CodeBleu_score": 55.41038593684415}]}
{"instance_id": "55c0d77e4dc2", "generation_result": [{"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.asarray(np.count_nonzero(a, axis=axis, keepdims=keepdims), dtype=dtype)\n\n", "CodeBleu_score": 47.799692847147426}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.count_nonzero(a, axis=axis, keepdims=keepdims, dtype=dtype, out=out)\n\n", "CodeBleu_score": 46.196732391005405}, {"code": "def count_nonzero(\n    a: np.ndarray,\n    /,\n    *,\n    axis: Optional[Union[int, Tuple[int, ...]]] = None,\n    keepdims: bool = False,\n    dtype: Optional[np.dtype] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if axis is None:\n        np_axis = None\n    else:\n        np_axis = tuple(axis) if isinstance(axis, list) else axis\n    return np.asarray(np.count_nonzero(a, axis=np_axis, keepdims=keepdims), dtype=dtype)\n\n", "CodeBleu_score": 56.26404034427301}]}
{"instance_id": "784bf7d24fc2", "generation_result": [{"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}, {"code": "def gradient(\n    x: np.ndarray,\n    /,\n    *,\n    spacing: Union[int, list, tuple] = 1,\n    axis: Optional[Union[int, list, tuple]] = None,\n    edge_order: int = 1,\n) -> Union[np.ndarray, List[np.ndarray]]\n\t\n    if type(spacing) in (int, float):\n        return np.gradient(x, spacing, axis=axis, edge_order=edge_order)\n    return np.gradient(x, *spacing, axis=axis, edge_order=edge_order)\n\n", "CodeBleu_score": 96.56449344642135}]}
{"instance_id": "efa0a51af6bc", "generation_result": [{"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.any(x == 0):\n        return ivy.zeros_like(y)\n    return ivy.multiply(x, ivy.log(y), out=out)", "CodeBleu_score": 58.37357842616699}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    x, y = promote_types_of_inputs(x, y)\n    if ivy.any(x == 0):\n        return ivy.zeros_like(y)\n    return ivy.multiply(x, ivy.log(y), out=out)", "CodeBleu_score": 58.37357842616699}, {"code": "def xlogy(\n    x: np.ndarray, y: np.ndarray, /, *, out: Optional[np.ndarray] = None\n) -> np.ndarray\n\t\n    if out is None:\n        out = np.full(x.shape, np.nan)\n    x, y = promote_types_of_inputs(x, y)\n    if np.all(x == 0):\n        return np.array(0.0, dtype=x.dtype)\n    else:\n        return np.multiply(x, np.log(y), out=out)\n\n", "CodeBleu_score": 57.98782849590458}]}
{"instance_id": "ac1645284260", "generation_result": [{"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _depth_max_pooling_helper(\n        x.shape, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        perm = [0, dims + 1] + list(range(1, dims + 1))\n        x = jnp.transpose(x, perm)\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 58.89082077094264}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _determine_depth_max_pooling_helper(\n        kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = _transpose(x, [0, dims + 1, *range(1, dims + 1)])\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 49.092720105608784}, {"code": "def _determine_depth_max_pooling(x, kernel, strides, dims, data_format=\"channel_last\")\n\t\n    kernel, strides, depth_pooling = _get_depth_max_pooling_helper(\n        x.shape, kernel, strides, dims, data_format\n    )\n    if depth_pooling:\n        x = np.transpose(x, (0, 4, 1, 2, 3))\n    return x, kernel, strides, depth_pooling\n\n", "CodeBleu_score": 43.88063019294521}]}
{"instance_id": "18ff0a4f7550", "generation_result": [{"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif data_format != \"NWC\":\n            raise ValueError(\"Invalid data_format.\")\n        mask = np.random.binomial(1, 1 - prob, x.shape)\n        res = x * mask * np.reciprocal(1 - prob, out=out, where=mask)\n        if data_format == \"NCW\":\n            res = np.transpose(res, (0, 2, 1))\n        return res\n    return x", "CodeBleu_score": 49.81528110182866}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = np.transpose(x, (0, 2, 1))\n        elif not data_format == \"NWC\":\n            raise NotImplementedError(\n                \"Only 'NCW' and 'NWC' data formats are supported for 1D dropout.\"\n            )\n        mask = np.random.binomial(1, 1 - prob, size=x.shape)\n        scaled_x = np.where(mask, x * (1.0 / (1 - prob)), np.zeros_like(x))\n        if data_format == \"NCW\":\n            scaled_x = np.transpose(scaled_x, (0, 2, 1))\n        return scaled_x\n    else:\n        return x\n\n", "CodeBleu_score": 50.381366196135026}, {"code": "def dropout1d(\n    x: np.ndarray,\n    prob: float,\n    /,\n    *,\n    training: bool = True,\n    data_format: str = \"NWC\",\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if training:\n        if data_format == \"NCW\":\n            x = x.transpose((0, 2, 1))\n        if x.ndim == 2:\n            mask = np.random.binomial(1, 1 - prob, x.shape[1])\n            x *= mask.reshape((1, x.shape[1]))\n        else:\n            mask = np.random.binomial(1, 1 - prob, x.shape[2])\n            x *= mask.reshape((1, 1, x.shape[2]))\n        if data_format == \"NCW\":\n            x = x.transpose((0, 2, 1))\n    return x\n\n", "CodeBleu_score": 48.68610918525602}]}
{"instance_id": "0ce45eb7cbd9", "generation_result": [{"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return ivy.top_k(x, k, axis=axis, largest=largest, sorted=sorted, out=out)\n\n", "CodeBleu_score": 16.543112076012438}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return np.top_k(x, k, axis, largest, sorted, out)\n\n", "CodeBleu_score": 15.910160905600055}, {"code": "def top_k(\n    x: np.ndarray,\n    k: int,\n    /,\n    *,\n    axis: int = -1,\n    largest: bool = True,\n    sorted: bool = True,\n    out: Optional[Tuple[np.ndarray, np.ndarray]] = None,\n) -> Tuple[np.ndarray, np.ndarray]\n\t\n    return np.top_k(x, k, axis=axis, largest=largest, sorted=sorted, out=out)\n\n", "CodeBleu_score": 16.705540897022033}]}
{"instance_id": "1424f9541998", "generation_result": [{"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    return np.divide(\n        x,\n        np.expand_dims(\n            np.sum(\n                np.abs(x),\n                axis=axis,\n                keepdims=True,\n            ),\n            axis=axis,\n        ),\n        out=out,\n    )", "CodeBleu_score": 30.586491551574195}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    if out is not None:\n        np.copyto(out, x)\n        x = out\n    if axis is None:\n        denorm = np.sum(np.abs(x.ravel()))\n    else:\n        denorm = np.sum(np.abs(x), axis=axis, keepdims=True)\n    denorm = np.maximum(denorm, 10 ** (-7))\n    return x / denorm", "CodeBleu_score": 58.592736789700695}, {"code": "def l1_normalize(\n    x: np.ndarray,\n    /,\n    *,\n    axis: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    denorm = (\n        np.linalg.norm(x, 1, axis, keepdims=True)\n        if axis is not None\n        else np.linalg.norm(x.flatten(), 1)\n    )\n    denorm = np.maximum(denorm, 1e-12)\n    return np.divide(x, denorm, out=out)\n\n", "CodeBleu_score": 35.917775298914854}]}
{"instance_id": "4c3a386a1f05", "generation_result": [{"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}, {"code": "def beta(\n    alpha: Union[float, np.ndarray],\n    beta: Union[float, np.ndarray],\n    /,\n    *,\n    shape: Optional[Union[ivy.NativeShape, Sequence[int]]] = None,\n    device: Optional[str] = None,\n    dtype: Optional[np.dtype] = None,\n    seed: Optional[int] = None,\n    out: Optional[np.ndarray] = None,\n) -> np.ndarray\n\t\n    shape = _check_bounds_and_get_shape(alpha, beta, shape).shape\n    if seed is not None:\n        np.random.seed(seed)\n    return np.asarray(np.random.beta(alpha, beta, shape), dtype=dtype)\n\n", "CodeBleu_score": 90.33571882792663}]}
{"instance_id": "271200a8b261", "generation_result": [{"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse[np.argsort(inverse)]\n\n", "CodeBleu_score": 58.995904881049256}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.array(x)\n    sorted_indices = np.argsort(x)\n    inverse = np.zeros_like(sorted_indices)\n    inverse[sorted_indices] = np.arange(len(x))\n    return inverse\n\n", "CodeBleu_score": 56.60266130052361}, {"code": "def invert_permutation(\n    x: Union[np.ndarray, list, tuple],\n    /,\n) -> np.ndarray\n\t\n    x = np.array(x)\n    indices = np.argsort(x)\n    inverse = np.zeros_like(indices)\n    inverse[indices] = np.arange(len(x))\n    inverse = np.argsort(inverse)\n    return inverse\n\n", "CodeBleu_score": 51.0586429468909}]}
{"instance_id": "040d73b37229", "generation_result": [{"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    plt.style.use(\"seaborn-darkgrid\")\n\n    # Create figure with subplots\n    fig, axs = plt.subplots(3, 2, figsize=(10, 10))\n\n    # Plot\n    plot_monthly_vomit(axs[0, 0], data)\n    plot_days_between_vomit(axs[0, 1], data)\n    plot_daycare_days(axs[1, 0], data)\n    plot_doctor_visit_monthly(axs[1, 1], data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export\n    fig.savefig(\n        \"C:/Users/jonat/OneDrive/Documents/GitHub/personal-projects/data-analysis/data-analysis-medical/data/plots/medical_charts.png\",\n        dpi=300,\n    )\n\n", "CodeBleu_score": 26.679771123630502}, {"code": "def plot_medical_charts() -> None\n\t\n\n    # Set plotting style\n    plt.style.use(\"seaborn-whitegrid\")\n\n    # Create figure and subplots\n    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n\n    # Plot total vomit per month\n    plot_monthly_vomit(ax1, data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(ax2, data)\n\n    # Plot days in daycare\n    plot_daycare_days(ax3, data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(ax4, data)\n\n    # Adjust layout\n    plt.tight_layout()\n\n    # Export figure\n    plt.savefig(\"../plots/medical_charts.png\")\n\n", "CodeBleu_score": 22.828144700806103}, {"code": "def plot_medical_charts() -> None\n\t\n    # Set style\n    plt.style.use(\"seaborn-darkgrid\")\n\n    # Create figure and subplots\n    fig, axs = plt.subplots(\n        2,\n        2,\n        figsize=(16, 10),\n        gridspec_kw={\"hspace\": 0.4, \"wspace\": 0.2},\n    )\n\n    # Plot total vomit per month\n    plot_monthly_vomit(axs[0, 0], data)\n\n    # Plot days between vomit\n    plot_days_between_vomit(axs[0, 1], data)\n\n    # Plot days in daycare\n    plot_daycare_days(axs[1, 0], data)\n\n    # Plot doctor visits\n    plot_doctor_visit_monthly(axs[1, 1], data)\n\n    # Adjust layout\n    fig.tight_layout()\n\n    # Export figure\n    fig.savefig(\n        \"./output/medical_charts.png\",\n        bbox_inches=\"tight\",\n        dpi=300,\n    )", "CodeBleu_score": 26.824507136520115}]}
{"instance_id": "7061f4d0c3fc", "generation_result": [{"code": "def plot_feeding_24h_viz() -> None\n\t\n    # Import and extract feeding data\n    feeding_data = parse_raw_data(\n        pd.read_csv(\n            \"../data/raw/baby_feeding_data.csv\",\n            parse_dates=[\"Date\"],\n            date_parser=lambda x: pd.to_datetime(x, format=\"%d/%m/%Y\"),\n        ),\n        key=[\"Date\"],\n    )\n\n    # Set up plot with dark grid style\n    plt.style.use(\"dark_background\")\n    fig, ax = plt.subplots(figsize=(10, 6))\n\n    # Compute offset from birthday based on the last solid feeding date\n    solid_feeding_dates = feeding_data[feeding_data[\"Type\"] == \"Solid\"][\"Date\"]\n    offset = (solid_feeding_dates.iloc[-1] - solid_feeding_dates.iloc[-2]).days\n\n    # Create scatter plot of feeding times\n    ax.scatter(\n        feeding_data[feeding_data[\"Type\"] == \"Bottle\"][\"timestamp_hour\"],\n        feeding_data[feeding_data[\"Type\"] == \"Bottle\"][\"day_number\"],\n        c=\"red\",\n        label=\"Bottle\",\n    )\n    ax.scatter(\n        feeding_data[feeding_data[\"Type\"] == \"Solid\"][\"timestamp_hour\"],\n        feeding_data[feeding_data[\"Type\"] == \"Solid\"][\"day_number\"] + offset,\n        c=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend to distinguish between bottle and solid feedings\n    ax.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date(feeding_data, first_year_only=True)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    ax.set_xlim(0, 24)\n    ax.set_xticks(np.arange(0, 25, 2))\n    ax.set_xticklabels(\n        [f\"{", "CodeBleu_score": 28.22407470083938}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n\n    # Import and extract feeding data\n    feeding_data = parse_raw_data(\n        pd.read_csv(\n            \"./data/feeding_data.csv\",\n            parse_dates=[\"Date\"],\n        ),\n        key=[\"Date\"],\n    )\n\n    # Set up plot with dark grid style\n    plt.style.use(\"dark_background\")\n\n    # Compute offset from birthday based on last solid feeding date\n    offset = (feeding_data[\"Date\"].iloc[-1] - pd.to_datetime(\"2022-07-01\")).days\n\n    # Create scatter plot of feeding times\n    plt.scatter(\n        feeding_data[\"timestamp_hour\"],\n        feeding_data[\"day_number\"] - offset,\n        c=feeding_data[\"Bottle/Solid\"],\n        cmap=\"bwr_r\",\n        label=\"Bottle/Solid\",\n    )\n\n    # Add legend to distinguish between bottle and solid feedings\n    plt.legend()\n\n    # Calculate end date for plot\n    end_date = get_end_date(feeding_data, first_year_only=True)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    plt.xticks(np.arange(0, 24, 1))\n    plt.xlabel(\"Time\")\n    plt.yticks(np.arange(0, end_date, 1))\n    plt.ylabel(\"Day\")\n    plt.title(\"Feeding Data\")\n\n    # Export figure\n    export_figure(\"feeding_24h_viz\")\n\n", "CodeBleu_score": 23.747871064915046}, {"code": "def plot_feeding_24h_viz() -> None\n\t\n\n    # Import and extract feeding data\n    data = parse_raw_data(pd.read_csv(filepath_or_buffer=\"data/feeding_data.csv\"), key=[\"Date\", \"Time\"])\n\n    # Set up plot with dark grid style\n    plt.style.use(\"dark_background\")\n    fig, ax = plt.subplots()\n\n    # Compute offset from birthday based on the last solid feeding date\n    offset = get_end_date(data, first_year_only=True)\n\n    # Create scatter plot of feeding times\n    ax.scatter(\n        data[data[\"Solid/Bottle\"] == \"Bottle\"][\"timestamp_hour\"],\n        data[data[\"Solid/Bottle\"] == \"Bottle\"][\"day_number\"] - offset,\n        color=\"red\",\n        label=\"Bottle\",\n    )\n    ax.scatter(\n        data[data[\"Solid/Bottle\"] == \"Solid\"][\"timestamp_hour\"],\n        data[data[\"Solid/Bottle\"] == \"Solid\"][\"day_number\"] - offset,\n        color=\"blue\",\n        label=\"Solid\",\n    )\n\n    # Add legend to distinguish between the two\n    ax.legend(loc=\"upper left\")\n\n    # Calculate end date for plot\n    end_date = get_end_date(data, first_year_only=False)\n\n    # Format plot to display feeding data over a week in a 24-hour format\n    ax.set_xlim([0, 24])\n    ax.set_xticks(np.arange(0, 25, 2))\n    ax.set_ylim([-1, end_date])\n    ax.set_yticks(np.arange(0, end_date, 7))\n    ax.set_ylabel(\"Days Since Birth\")\n    ax.set_xlabel(\"Time of Day (Hours)\")\n    ax.set_title(\"24-Hour Feeding Data\")\n\n    # Export figure\n    export_figure(fig, \"feeding_24h_", "CodeBleu_score": 27.76907793508052}]}
{"instance_id": "6c1ffa63d122", "generation_result": [{"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n    ax.set_title(f'{task.name} Counts')\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n    ax.set_ylim(0, max(target_counts) * 1.1)\n    for i, count in enumerate(target_counts):\n        ax.text(i, count + 1, str(count), ha='center')\n    sns.despine()\n\n", "CodeBleu_score": 39.04016736031231}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=counts, ax=ax, **kwargs)\n    ax.set_title(f'{task.name} counts')\n    ax.set_xlabel('Target')\n    ax.set_ylabel('Count')\n\n    return ax\n\n", "CodeBleu_score": 40.9998969990114}, {"code": "def plot(self, ax, task: ClassificationTask = ClassificationTask.Result, **kwargs):\n\t\n    target_counts, target_names = self._get_target_counts(task)\n    sns.barplot(x=target_names, y=target_counts, ax=ax, **kwargs)\n\n", "CodeBleu_score": 45.80788839017864}]}
{"instance_id": "2f81a906bad5", "generation_result": [{"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_agg import FigureCanvasAgg\n\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = FigureCanvasAgg(fig)\n            canvas.draw()\n            buf = canvas.buffer_rgba()\n            image = np.asarray(buf)\n            image = image.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n            images.append(image)\n            plt.close(fig)\n        return np.stack(images)\n\n    canvas = FigureCanvasAgg(figure)\n    canvas.draw()\n    buf = canvas.buffer_rgba()\n    image = np.asarray(buf)\n    image = image.reshape(figure.canvas.get_width_height()[::-1] + (3,))\n    plt.close(figure)\n    return image\n\n\n\n", "CodeBleu_score": 36.39541918572801}, {"code": "def render_to_rgb(figure)\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    if isinstance(figure, list):\n        images = []\n        for fig in figure:\n            canvas = plt_backend_agg.FigureCanvasAgg(fig)\n            canvas.draw()\n            buf = np.array(canvas.buffer_rgba())\n            image = buf.reshape(fig.canvas.get_width_height()[::-1] + (3,))\n            images.append(image)\n            plt.close(fig)\n        return np.stack(images)\n    else:\n        canvas = plt_backend_agg.FigureCanvasAgg(figure)\n        canvas.draw()\n        buf = np.array(canvas.buffer_rgba())\n        image = buf.reshape(figure.canvas.get_width_height()[::-1] + (3,))\n        plt.close(figure)\n        return image\n\n\n\n", "CodeBleu_score": 39.87970549840001}, {"code": "def render_to_rgb(figure)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n\n    def render_to_rgb_single(figure):\n        canvas = FigureCanvas(figure)\n        canvas.draw()\n        image = np.frombuffer(canvas.tostring_rgb(), dtype='uint8')\n        image = image.reshape(figure.canvas.get_width_height()[::-1] + (3,))\n        return image\n\n    if isinstance(figure, list):\n        return np.stack([render_to_rgb_single(fig) for fig in figure])\n    else:\n        return render_to_rgb_single(figure)", "CodeBleu_score": 39.3350462315842}]}
{"instance_id": "c3037b01569c", "generation_result": [{"code": "def beholder_pytorch()\n\t\n    import torch\n    import random\n    import time\n    from beholder import Beholder\n\n    logdir = \"./logs\"\n    beholder = Beholder(logdir)\n\n    for i in range(1000):\n        tensors_1 = [torch.randn(3, 224, 224), torch.randn(3, 224, 224)]\n        tensors_2 = [torch.randn(3, 224, 224), torch.randn(3, 224, 224)]\n        names_1 = [\"tensor_1\", \"tensor_2\"]\n        names_2 = [\"tensor_1\", \"tensor_2\"]\n        frame = random.randint(0, 100)\n        beholder.update(tensors_1, names_1, frame, \"group_1\")\n        beholder.update(tensors_2, names_2, frame, \"group_2\")\n        time.sleep(0.1)\n        print(f\"Iteration {i}\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.104954233760978}, {"code": "def beholder_pytorch()\n\t\n    import torch\n    from beholder import Beholder\n    import random\n    import time\n\n    beholder = Beholder(log_dir=\"logs\")\n\n    for i in range(1000):\n        # Generate random tensors\n        tensor1 = torch.randn(3, 32, 32)\n        tensor2 = torch.randn(3, 32, 32)\n        tensor3 = torch.randn(3, 32, 32)\n        tensor4 = torch.randn(3, 32, 32)\n        tensor5 = torch.randn(3, 32, 32)\n\n        # Generate random names for the tensors\n        names = [f\"tensor{i}\" for i in range(5)]\n\n        # Update the Beholder visualization\n        beholder.update(\n            tensors=[tensor1, tensor2, tensor3, tensor4, tensor5],\n            names=names,\n            frame=random.randint(0, 100),\n        )\n\n        # Sleep briefly\n        time.sleep(0.1)\n\n        print(f\"Iteration {i}\")\n\n\n\n", "CodeBleu_score": 29.48265148193964}, {"code": "def beholder_pytorch()\n\t\n    import torch\n    from beholder import Beholder\n    import time\n    import random\n\n    beholder = Beholder(log_dir=\"logs/beholder/pytorch\")\n\n    for i in range(1000):\n        tensor_list1 = [\n            torch.randn(3, 256, 256),\n            torch.randn(3, 256, 256),\n            torch.randn(3, 256, 256),\n        ]\n        tensor_list2 = [\n            torch.randn(3, 256, 256),\n            torch.randn(3, 256, 256),\n            torch.randn(3, 256, 256),\n        ]\n        names_list1 = [\n            \"tensor1\",\n            \"tensor2\",\n            \"tensor3\",\n        ]\n        names_list2 = [\n            \"tensor4\",\n            \"tensor5\",\n            \"tensor6\",\n        ]\n        beholder.update(\n            tensor_list1,\n            tensor_list2,\n            names_list1,\n            names_list2,\n            frame=random.randint(0, 1000),\n        )\n        time.sleep(0.1)\n        print(i)\n\n\n", "CodeBleu_score": 24.886226611363234}]}
{"instance_id": "cd57b5de8a88", "generation_result": [{"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    tensor_data = tf.reshape(tensor_data, [-1])\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds + 1)]\n    TP, FP, TN, FN, precision, recall = tf.split(tensor_data, 6)\n    TP = tf.cast(TP, dtype=tf.int32).numpy().tolist()\n    FP = tf.cast(FP, dtype=tf.int32).numpy().tolist()\n    TN = tf.cast(TN, dtype=tf.int32).numpy().tolist()\n    FN = tf.cast(FN, dtype=tf.int32).numpy().tolist()\n    precision = precision.numpy().tolist()\n    recall = recall.numpy().tolist()\n    pr_data = {\"thresholds\": thresholds, \"TP\": TP, \"FP\": FP, \"TN\": TN, \"FN\": FN, \"precision\": precision, \"recall\": recall}\n    self.log_asset_data(pr_data, tag, step)", "CodeBleu_score": 28.071928899763073}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    if summary.tensor.tensor_shape.dim[0].size == 1:\n        tensor_data = [tensor_data]\n    tensor_data = np.array(tensor_data).reshape(\n        (num_thresholds, 5)\n    )\n    thresholds = [float(i) / num_thresholds for i in range(num_thresholds)]\n    (\n        true_positives,\n        false_positives,\n        true_negatives,\n        false_negatives,\n        precision,\n        recall,\n    ) = tensor_data.T\n    pr_data = {\n        \"tag\": tag,\n        \"thresholds\": thresholds,\n        \"true_positives\": list(true_positives),\n        \"false_positives\": list(false_positives),\n        \"true_negatives\": list(true_negatives),\n        \"false_negatives\": list(false_negatives),\n        \"precision\": list(precision),\n        \"recall\": list(recall),\n    }\n    self.log_asset_data(pr_data, tag, step)\n\n", "CodeBleu_score": 36.870677640237055}, {"code": "def log_pr_data(self, tag, summary, num_thresholds, step=None)\n\t\n    tensor_data = summary.tensor.float_val\n    if summary.tensor.dim:\n        tensor_data = np.reshape(tensor_data, [x.size for x in summary.tensor.dim])\n    else:\n        tensor_data = np.array(tensor_data)\n    thresholds = [i / num_thresholds for i in range(num_thresholds + 1)]\n    tp = []\n    fp = []\n    tn = []\n    fn = []\n    precision = []\n    recall = []\n    for threshold in thresholds:\n        tp.append(tensor_data[0][0][0][0][threshold])\n        fp.append(tensor_data[0][0][1][0][threshold])\n        tn.append(tensor_data[0][1][0][0][threshold])\n        fn.append(tensor_data[0][1][1][0][threshold])\n        precision.append(tensor_data[1][0][0][0][threshold])\n        recall.append(tensor_data[1][0][1][0][threshold])\n    pr_data = {\n        \"true_positives\": tp,\n        \"false_positives\": fp,\n        \"true_negatives\": tn,\n        \"false_negatives\": fn,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"thresholds\": thresholds,\n    }\n    self.log_asset_data(pr_data, tag, step=step)", "CodeBleu_score": 33.0716213577914}]}
{"instance_id": "7c4ea9beecc9", "generation_result": [{"code": "def load_mnist(images, labels, num)\n\t\n    import gzip\n    import numpy as np\n\n    data = []\n    target = []\n    with gzip.open(images, 'rb') as f:\n        f.read(16)\n        for i in range(num):\n            data.append(np.frombuffer(f.read(784), dtype=np.uint8).reshape(28, 28))\n    with gzip.open(labels, 'rb') as f:\n        f.read(8)\n        for i in range(num):\n            target.append(np.frombuffer(f.read(1), dtype=np.uint8))\n    return np.array(data), np.array(target)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.932791539374364}, {"code": "def load_mnist(images, labels, num)\n\t\n    import gzip\n    import numpy as np\n\n    data = []\n    target = []\n    with gzip.open(images, 'rb') as f:\n        f.read(16)\n        for i in range(num):\n            data.append(np.frombuffer(f.read(28 * 28), dtype=np.uint8).reshape(28, 28))\n    with gzip.open(labels, 'rb') as f:\n        f.read(8)\n        for i in range(num):\n            target.append(np.frombuffer(f.read(1), dtype=np.uint8))\n    return np.array(data), np.array(target)\n\n\n\n", "CodeBleu_score": 38.03292536131938}, {"code": "def load_mnist(images, labels, num)\n\t\n    import gzip\n    import numpy as np\n\n    data = np.empty((num, 784), dtype=np.uint8)\n    target = np.empty((num,), dtype=np.uint8)\n\n    with gzip.open(images, 'rb') as f_images, gzip.open(labels, 'rb') as f_labels:\n        f_images.read(16)\n        f_labels.read(8)\n        for i in range(num):\n            target[i] = ord(f_labels.read(1))\n            for j in range(784):\n                data[i, j] = ord(f_images.read(1))\n\n    return data, target\n\n", "CodeBleu_score": 59.992605611097495}]}
{"instance_id": "bf4f1c828b25", "generation_result": [{"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.cardinality = {}\n    self.min_max = {}\n    self.unique_values = {}\n    self.dataset_length = len(ldf)\n\n    for attribute in ldf.columns:\n        unique_vals = list(ldf.unique_values[attribute])\n        self.unique_values[attribute] = unique_vals\n        self.cardinality[attribute] = len(unique_vals)\n        if pd.api.types.is_numeric_dtype(ldf.data_type[attribute]):\n            self.min_max[attribute] = (min(unique_vals), max(unique_vals))\n\n    if not pd.api.types.is_integer_dtype(ldf.data_type[ldf.index.name]):\n        unique_index_vals = list(ldf.unique_values[ldf.index.name])\n        self.unique_values[ldf.index.name] = unique_index_vals\n        self.cardinality[ldf.index.name] = len(unique_index_vals)\n        if pd.api.types.is_numeric_dtype(ldf.data_type[ldf.index.name]):\n            self.min_max[ldf.index.name] = (\n                min(unique_index_vals),\n                max(unique_index_vals),\n            )", "CodeBleu_score": 38.656153343870805}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.unique_values = {}\n    self.min_max = {}\n    self.cardinality = {}\n    self.data_length = len(ldf)\n    for attribute in ldf.columns:\n        self.unique_values[attribute] = list(ldf.unique_values[attribute])\n        self.cardinality[attribute] = len(ldf.unique_values[attribute])\n        if ldf.data_type[attribute] == \"quantitative\":\n            self.min_max[attribute] = (ldf.min_max[attribute])\n    if not ldf.index.is_integer():\n        self.unique_values[ldf.index.name] = list(ldf.unique_values[ldf.index.name])\n        self.cardinality[ldf.index.name] = len(ldf.unique_values[ldf.index.name])\n\n", "CodeBleu_score": 30.825264021488696}, {"code": "def compute_stats(self, ldf: LuxDataFrame)\n\t\n    self.cardinality = {}\n    self.min_max = {}\n    self.unique_values = {}\n    self.dataset_length = len(ldf)\n    for attr in ldf.columns:\n        self.unique_values[attr] = list(ldf.unique_values[attr])\n        self.cardinality[attr] = len(ldf.unique_values[attr])\n        if ldf.data_type[attr] == \"quantitative\":\n            self.min_max[attr] = (ldf.min_max[attr][0], ldf.min_max[attr][1])\n    if not ldf.data_type[ldf.index.name] == \"integer\":\n        self.unique_values[ldf.index.name] = list(ldf.unique_values[ldf.index.name])\n        self.cardinality[ldf.index.name] = len(ldf.unique_values[ldf.index.name])\n\n", "CodeBleu_score": 28.046874051666475}]}
{"instance_id": "3e6fc3d2f47c", "generation_result": [{"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    query = f\"SELECT * FROM {tbl.table_name} LIMIT {preview_size}\"\n    return tbl.conn.execute(query).fetch_df()\n\n", "CodeBleu_score": 16.745347875196114}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    import pandas as pd\n    from lux.utils.utils import execute_sql_query\n    from lux.utils.sql_utils import get_sql_template\n\n    sql_template = get_sql_template(\"preview\")\n    query = sql_template.format(tbl.table_name, preview_size)\n    df = execute_sql_query(query, tbl.sql_context)\n    return df\n\n", "CodeBleu_score": 37.59959849269799}, {"code": "def execute_preview(tbl: LuxSQLTable, preview_size=5)\n\t\n    from lux.utils import get_import_error\n    from lux.utils.sql_utils import execute_sql_query\n    from lux.utils.utils import get_agg_types\n    import pandas as pd\n    import numpy as np\n    import lux\n\n    preview_query = f\"SELECT * FROM {tbl.table_name} LIMIT {preview_size}\"\n    df = execute_sql_query(preview_query)\n    if df.empty:\n        return df\n    df = df.replace(r\"^\\s*$\", np.nan, regex=True)\n    # df = df.replace(np.nan, \"\")\n    df = df.applymap(lambda x: \"\" if pd.isnull(x) else x)\n    return df\n\n", "CodeBleu_score": 38.56921069537258}]}
{"instance_id": "b3dee87be4b8", "generation_result": [{"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    config = lux.config\n    if config.sampling.SAMPLE_FLAG:\n        tbl_len = len(tbl)\n        limit = config.sampling.SAMPLE_FRAC * tbl_len\n        if config.sampling.SAMPLE_CAP:\n            limit = min(limit, config.sampling.SAMPLE_CAP)\n        limit = int(limit)\n        if config.sampling.SAMPLE_START:\n            offset = config.sampling.SAMPLE_START\n            if offset < 0:\n                offset += tbl_len\n            offset = max(0, offset)\n            if offset > tbl_len:\n                offset = tbl_len\n            limit += offset\n            query = f\"SELECT * FROM {tbl.tableName} LIMIT {limit} OFFSET {offset}\"\n        else:\n            query = f\"SELECT * FROM {tbl.tableName} LIMIT {limit}\"\n        tbl._sampled = psql.execute_SQL_query(query)\n\n", "CodeBleu_score": 29.17312953711559}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    SAMPLE_FLAG = lux.config.sampling.SAMPLE_FLAG\n    SAMPLE_START = lux.config.sampling.SAMPLE_START\n    SAMPLE_CAP = lux.config.sampling.SAMPLE_CAP\n    SAMPLE_FRAC = lux.config.sampling.SAMPLE_FRAC\n    if SAMPLE_FLAG:\n        table_len = len(tbl.df)\n        if SAMPLE_CAP:\n            limit = SAMPLE_CAP\n        elif SAMPLE_START:\n            limit = SAMPLE_START\n        else:\n            limit = SAMPLE_FRAC * table_len\n        limit = int(limit)\n        if limit < table_len:\n            sampled_df = pd.read_sql_query(\n                f\"SELECT * FROM {tbl.table_name} LIMIT {limit}\", lux.config.SQLconnection\n            )\n            tbl._sampled = sampled_df\n            tbl._sampled_init = True", "CodeBleu_score": 27.534218791738112}, {"code": "def execute_sampling(tbl: LuxSQLTable)\n\t\n    # TODO: use sample_cap to determine if we need to sample at all\n    sample_flag = lux.config.sampling.SAMPLE_FLAG\n    sample_start = lux.config.sampling.SAMPLE_START\n    sample_cap = lux.config.sampling.SAMPLE_CAP\n    sample_frac = lux.config.sampling.SAMPLE_FRAC\n    if sample_flag:\n        if len(tbl.unique_values) < sample_cap:\n            sampled_df = tbl.data_obj.head(sample_cap)\n        else:\n            sampled_df = tbl.data_obj.head(sample_start)\n        if len(tbl.unique_values) > sample_cap:\n            limit = sample_frac * len(tbl.unique_values)\n            query = f\"SELECT * FROM {tbl.table_name} LIMIT {limit}\"\n            sampled_df = tbl.data_obj.execute_SQL(query)\n        tbl._sampled = sampled_df\n\n", "CodeBleu_score": 26.332193284843306}]}
{"instance_id": "485253b1088a", "generation_result": [{"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    # Override default text settings with provided parameters\n    text_params = override_params(\n        default_dict=params[\"text\"],\n        new_dict=params[\"text\"]\n    )\n\n    # Extract text, x, and y values\n    text = text_params[\"text\"]\n    x = text_params[\"x\"]\n    y = text_params[\"y\"]\n\n    # Retrieve background's bounds\n    bounds = background.bounds\n\n    # Interpolate x and y values to fit within background's bounds\n    x = interpolate_value(x, bounds[0], bounds[2])\n    y = interpolate_value(y, bounds[1], bounds[3])\n\n    # Use plt.text to draw text at calculated position with remaining parameters\n    plt.text(\n        x=x,\n        y=y,\n        **text_params\n    )\n\n", "CodeBleu_score": 16.630679101978952}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    # Override default text settings with provided parameters\n    text_params = override_params(\n        default_dict={\n            \"text\": \"\",\n            \"x\": 0.5,\n            \"y\": 0.5,\n            \"fontsize\": 12,\n            \"horizontalalignment\": \"center\",\n            \"verticalalignment\": \"center\",\n            \"color\": \"black\",\n            \"bbox\": None,\n            \"alpha\": None,\n            \"zorder\": 1000,\n        },\n        new_dict=params,\n    )\n\n    # Extract text, x, and y values\n    text = text_params[\"text\"]\n    x = text_params[\"x\"]\n    y = text_params[\"y\"]\n\n    # Get background bounds\n    x_min, y_min, x_max, y_max = background.bounds\n\n    # Interpolate x and y values to fit within background bounds\n    x = (x - x_min) / (x_max - x_min)\n    y = (y - y_min) / (y_max - y_min)\n\n    # Draw text at calculated position with remaining parameters\n    plt.text(\n        x=x,\n        y=y,\n        s=text,\n        fontsize=text_params[\"fontsize\"],\n        horizontalalignment=text_params[\"horizontalalignment\"],\n        verticalalignment=text_params[\"verticalalignment\"],\n        color=text_params[\"color\"],\n        bbox=text_params[\"bbox\"],\n        alpha=text_params[\"alpha\"],\n        zorder=text_params[\"zorder\"],\n    )\n\n", "CodeBleu_score": 22.137003294319495}, {"code": "def draw_text(\n    params: Dict[str, dict],\n    background: BaseGeometry\n) -> None\n\t\n\n    text_params = override_params(\n        default_dict={\n            \"fontsize\": 12,\n            \"ha\": \"center\",\n            \"va\": \"center\",\n            \"bbox\": {\n                \"boxstyle\": \"round\",\n                \"facecolor\": \"white\",\n                \"alpha\": 0.5,\n                \"pad\": 0.5,\n            },\n        },\n        new_dict=params,\n    )\n\n    text = text_params[\"text\"]\n    x = text_params[\"x\"]\n    y = text_params[\"y\"]\n\n    del text_params[\"text\"]\n    del text_params[\"x\"]\n    del text_params[\"y\"]\n\n    x_min, y_min, x_max, y_max = background.bounds\n\n    x = (x - x_min) / (x_max - x_min)\n    y = (y - y_min) / (y_max - y_min)\n\n    plt.text(x, y, text, **text_params)\n\n", "CodeBleu_score": 25.229416877396876}]}
{"instance_id": "5f70a88b6b72", "generation_result": [{"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n\n    # Calculate the average number of days between consecutive dates\n    days_between = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]\n    avg_days_between = sum(days_between) / len(days_between)\n\n    # Check if the data is intraday\n    if avg_days_between < 0.33:\n        # Check if the data spans multiple days\n        if (dates[-1] - dates[0]).days > 0:\n            return '%b %d, %H:%M'\n        else:\n            return '%H:%M'\n    else:\n        # Check if the data spans multiple years\n        if (dates[-1] - dates[0]).days > 365:\n            return '%Y-%b-%d'\n        else:\n            return '%b %d'\n\n\n\n", "CodeBleu_score": 40.54199035386371}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    import datetime\n    import numpy as np\n    if datetime_format is not None:\n        return datetime_format\n    else:\n        # Calculate the average number of days between consecutive dates\n        diffs = [(date - dates[i-1]).days for i, date in enumerate(dates) if i > 0]\n        avg_days = np.mean(diffs)\n        if avg_days < 0.33:\n            # Intraday data\n            if len(set(dates)) > 1:\n                return '%b %d, %H:%M'\n            else:\n                return '%H:%M'\n        else:\n            # Daily or less frequent data\n            if len(set(dates)) > 1:\n                return '%Y-%b-%d'\n            else:\n                return '%b %d'\n\n\n", "CodeBleu_score": 39.701168610933436}, {"code": "def _determine_format_string( dates, datetime_format=None )\n\t\n    if datetime_format is not None:\n        return datetime_format\n    # Calculate the average number of days between consecutive dates\n    delta_days = [(dates[i+1] - dates[i]).days for i in range(len(dates)-1)]\n    avg_delta_days = sum(delta_days) / len(delta_days)\n\n    # Determine the format string based on the average number of days\n    if avg_delta_days < 0.33:\n        # Intraday data\n        if dates[-1].date() != dates[0].date():\n            # Data spans multiple days\n            return '%b %d, %H:%M'\n        else:\n            # Data spans only one day\n            return '%H:%M'\n    else:\n        # Daily or less frequent data\n        if dates[-1].year != dates[0].year:\n            # Data spans multiple years\n            return '%Y-%b-%d'\n        else:\n            # Data spans only one year\n            return '%b %d'\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.021048690605525}]}
{"instance_id": "f9589bf4666d", "generation_result": [{"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        c = [v/255 for v in c]\n    if isinstance(c, str):\n        c = mpl.colors.to_rgba(c)\n    if isinstance(c, tuple):\n        if len(c) == 3:\n            c = (*c, 1.0)\n        if alpha is not None:\n            c = (*c[0:3], alpha)\n    return c\n\n", "CodeBleu_score": 31.26045990551216}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 3:\n            c = np.array(c)/255.0\n        elif len(c) == 4:\n            c = np.array(c[0:3])/255.0\n            if alpha is None:\n                alpha = c[3]\n        else:\n            raise ValueError(f\"c is a {len(c)}-tuple, but must be a 3- or 4-tuple\")\n    c = mpl.colors.to_rgba(c, alpha=alpha)\n    return c\n\n", "CodeBleu_score": 30.449202920200857}, {"code": "def _mpf_to_rgba(c, alpha=None)\n\t\n    if _is_uint8_rgb_or_rgba(c):\n        if len(c) == 4:\n            return tuple(c)\n        else:\n            return c[0]/255, c[1]/255, c[2]/255, alpha\n    else:\n        return colors.to_rgba(c, alpha)\n\n", "CodeBleu_score": 25.608176204037292}]}
{"instance_id": "4202e378ab0b", "generation_result": [{"code": "def subplots(self,*args,**kwargs)\n\t\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n", "CodeBleu_score": 91.92960540361257}, {"code": "def subplots(self,*args,**kwargs)\n\t\n\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n", "CodeBleu_score": 91.92960540361257}, {"code": "def subplots(self,*args,**kwargs)\n\t\n\n    if 'style' in kwargs or not hasattr(self,'mpfstyle'):\n        style = _check_for_and_apply_style(kwargs)\n        self.mpfstyle = style\n    else:\n        style = _check_for_and_apply_style(dict(style=self.mpfstyle))\n\n    axlist = mplfigure.Figure.subplots(self,*args,**kwargs)\n\n    if isinstance(axlist,mpl_axes.Axes):\n        axlist.mpfstyle = style\n    elif isinstance(axlist,np.ndarray):\n        for ax in axlist.flatten():\n            ax.mpfstyle = style\n    else:\n       raise TypeError('Unexpected type ('+str(type(axlist))+') '+\n                       'returned from \"matplotlib.figure.Figure.subplots()\"')\n    return axlist\n\n", "CodeBleu_score": 91.92960540361257}]}
{"instance_id": "3e2b6dfe4753", "generation_result": [{"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if \"figsize\" not in config:\n        ratio = config[\"figratio\"]\n        if ratio < 1:\n            ratio = 1 / ratio\n        if ratio > 1.5:\n            ratio = 1.5\n        fig.set_size_inches(config[\"figwidth\"] / ratio, config[\"figwidth\"])\n    else:\n        fig.set_size_inches(*config[\"figsize\"])\n\n", "CodeBleu_score": 22.144173555954126}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if not fig:\n        return\n    if not config.get(\"figure_size\"):\n        ratio = config[\"figure_ratio\"]\n        if ratio < 1:\n            ratio = 1 / ratio\n        if ratio > 2:\n            ratio = 2 / ratio\n        fig.set_size_inches(10 * ratio, 10)\n    else:\n        fig.set_size_inches(*config[\"figure_size\"])\n\n\n\n\n", "CodeBleu_score": 17.96955336608463}, {"code": "def _adjust_figsize(fig,config)\n\t\n    if fig is None:\n        return\n    if 'figsize' not in config:\n        ratio = config['figratio']\n        figsize = _get_figsize(ratio)\n    else:\n        figsize = config['figsize']\n    fig.set_size_inches(figsize)\n\n", "CodeBleu_score": 22.248644925988216}]}
{"instance_id": "986e5804b941", "generation_result": [{"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}, {"code": "def _plot_mav(ax,config,xdates,prices,apmav=None,apwidth=None)\n\t rolling mean of the prices, applies any shifts, and plots the result on the axis using the specified line width and color cycle from the config.", "CodeBleu_score": 2.950604062810505}]}
{"instance_id": "5308e20f3c90", "generation_result": [{"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    assert len(inputs) == 1\n    assert len(outputs) == 1\n    input_shape = inputs[0].shape\n    kernel_height = opnode.kernel_height\n    kernel_width = opnode.kernel_width\n    num_input_channels = input_shape[1]\n    num_output_channels = opnode.num_output_channels\n    output_height = outputs[0].shape[2]\n    output_width = outputs[0].shape[3]\n    total_num_output_elements = num_output_channels * output_height * output_width\n    if opnode.bias is not None:\n        total_num_output_elements += num_output_channels\n    return total_num_output_elements * num_input_channels * kernel_height * kernel_width\n\n", "CodeBleu_score": 28.83487898621031}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    assert len(inputs) == 1\n    assert len(outputs) == 1\n    _, _, kh, kw = opnode.kernel.shape\n    _, _, ih, iw = inputs[0].shape\n    _, _, oh, ow = outputs[0].shape\n    n_input = inputs[0].shape[1]\n    n_output = outputs[0].shape[1]\n    flops = n_output * n_input * kh * kw * oh * ow\n    if opnode.bias is not None:\n        flops += n_output * oh * ow\n    return flops\n\n", "CodeBleu_score": 28.51680918334744}, {"code": "def flops_conv(opnode: ConvolutionForward, inputs, outputs)\n\t\n    _, _, kernel_h, kernel_w = inputs[0].shape\n    in_channels = inputs[0].shape[1]\n    total_num_elements = prod(outputs[0].shape)\n    bias_flops = 1 if len(inputs) == 3 else 0\n    return total_num_elements * (kernel_h * kernel_w * in_channels + bias_flops)\n\n", "CodeBleu_score": 18.179929319636106}]}
{"instance_id": "70811d3cf578", "generation_result": [{"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    import numpy as np\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    from .ir import _dtype_to_ir_type\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)\n\n", "CodeBleu_score": 28.360135574587254}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    import numpy as np\n    from megengine.core import _dtype_to_ir_type\n    mge_dtype = np.dtype(mge_dtype)\n    assert mge_dtype.type in _dtype_to_ir_type, \"unsupported dtype: {}", "CodeBleu_score": 38.404519009027936}, {"code": "def mge_dtype_to_ir_type(mge_dtype)\n\t\n    mge_dtype = np.dtype(mge_dtype)\n    assert isinstance(mge_dtype, np.dtype)\n    return _dtype_to_ir_type[mge_dtype](mge_dtype)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 21.40981359960167}]}
{"instance_id": "a108c9ba2c22", "generation_result": [{"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype), copy=False)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.int8)\n    elif x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    elements_attr = DenseElementsAttr(x.flatten(), type=ir_type)\n    return [ConstantOp(elements_attr).result]\n\n", "CodeBleu_score": 43.071626226951174}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.copy()\n    if x.dtype == np.bool:\n        x = x.astype(np.uint8)\n    if x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    x = np.ascontiguousarray(x)\n    elements_attr = DenseElementsAttr.get(x, ir_type)\n    return [ir.ConstantOp(elements_attr).result]\n\n", "CodeBleu_score": 38.9296352511045}, {"code": "def _numpy_array_constant(x: np.ndarray, canonicalize_types) -> Sequence[ir.Value]\n\t\n    if canonicalize_types:\n        x = x.astype(canonicalize_dtype(x.dtype))\n    ir_type = mge_dtype_to_ir_type(x.dtype)\n    if x.dtype == np.bool_:\n        x = x.astype(np.uint8)\n    if x.dtype == np.bfloat16:\n        x = x.astype(np.float32)\n    x = np.ascontiguousarray(x)\n    elements_attr = DenseElementsAttr.get(x.shape, x.dtype, x)\n    return ConstantOp(elements_attr, ir_type).result\n\n", "CodeBleu_score": 40.607574434704304}]}
{"instance_id": "3345fe4d008b", "generation_result": [{"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if not val.size:\n        return _numpy_array_constant(val, canonicalize_types)\n    zero_stride_axes = []\n    non_zero_stride_axes = []\n    for i, stride in enumerate(val.strides):\n        if stride == 0:\n            zero_stride_axes.append(i)\n        else:\n            non_zero_stride_axes.append(i)\n    if zero_stride_axes:\n        val = np.squeeze(val, axis=zero_stride_axes)\n        if canonicalize_types:\n            val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n        return (hlo.BroadcastInDimOp(\n            _ndarray_constant_handler(val, canonicalize_types=False)[0],\n            dense_int_elements(non_zero_stride_axes),\n            shape=val.shape,\n        ).result,)\n    else:\n        return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 37.25929075734644}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if not val.size:\n        return _numpy_array_constant(val, canonicalize_types)\n    zero_stride_axes = [i for i, s in enumerate(val.strides) if s == 0]\n    non_zero_stride_axes = [i for i, s in enumerate(val.strides) if s != 0]\n    if len(zero_stride_axes) == 0:\n        return _numpy_array_constant(val, canonicalize_types)\n    val = val.transpose(non_zero_stride_axes + zero_stride_axes)\n    val = val[tuple(0 for _ in range(len(non_zero_stride_axes)))]\n    if canonicalize_types:\n        val = np.asarray(val, dtype.canonicalize_dtype(val.dtype))\n    shape = val.shape\n    val = np.broadcast_to(val, val.shape + (1,) * len(zero_stride_axes))\n    val = val.transpose(\n        list(range(len(non_zero_stride_axes), len(non_zero_stride_axes) + len(zero_stride_axes)))\n        + non_zero_stride_axes\n    )\n    val = val.reshape(shape)\n    return broadcast_to(val, shape)\n\n", "CodeBleu_score": 41.68278888233198}, {"code": "def _ndarray_constant_handler(\n    val: np.ndarray, canonicalize_types\n) -> Sequence[ir.Value]\n\t\n    if val.size == 0:\n        return ()\n    if val.strides:\n        zero_stride_axes, non_zero_stride_axes = [], []\n        for i, stride in enumerate(val.strides):\n            if stride == 0:\n                zero_stride_axes.append(i)\n            else:\n                non_zero_stride_axes.append(i)\n        if zero_stride_axes:\n            val = np.expand_dims(val, zero_stride_axes)\n            val = np.broadcast_to(val, val.shape[:1] + val.shape[2:])\n            val = np.squeeze(val, zero_stride_axes)\n            return broadcast_in_dim(val, non_zero_stride_axes, canonicalize_types)\n    return _numpy_array_constant(val, canonicalize_types)\n\n", "CodeBleu_score": 28.331764672012095}]}
{"instance_id": "91b298678351", "generation_result": [{"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    packed_bits = ir.BitArrayAttr.get_packed(xs, little_endian=True)\n    if len(xs) == 1:\n        if xs[0]:\n            packed_bits = ir.BitArrayAttr.get_packed([1], little_endian=True)\n        else:\n            packed_bits = ir.BitArrayAttr.get_packed([0], little_endian=True)\n    return ir.DenseElementsAttr.get(packed_bits, \"i1\", shape=[len(xs)])\n\n", "CodeBleu_score": 37.83273796123945}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    if len(xs) == 1:\n        xs = [xs[0]]\n    packed = pack_bits(xs)\n    if len(xs) > 1:\n        packed = pack_bits(xs)\n    else:\n        packed = [xs[0]]\n    return ir.DenseElementsAttr.get(packed, \"0_1_si1\")\n\n", "CodeBleu_score": 34.278558967881764}, {"code": "def dense_bool_elements(xs: Sequence[bool]) -> ir.DenseElementsAttr\n\t\n    bits = pack_bits(xs, 1)\n    if len(xs) == 1:\n        bits = bits if xs[0] else 0\n    return ir.DenseElementsAttr.get(\n        type=ir.IntegerType.get_signless(1),\n        shape=(len(xs),),\n        contents=bits,\n    )\n\n", "CodeBleu_score": 36.709481184402456}]}
{"instance_id": "06ebabf1e0ff", "generation_result": [{"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n    if input_var.bound_data is not None:\n        ctx.module.set_input(0, input_var.bound_data)\n        ctx.module.set_output(0, output_var.bound_data)\n    else:\n        assert output_var.bound_data is not None\n        ctx.module.set_output(0, output_var.bound_data)\n    assert input_var.shape == output_var.shape\n    if output_var.bound_data is not None:\n        created_data = output_var.bound_data.numpy().astype(output_var.dtype)\n    elif input_var.bound_data is not None:\n        created_data = input_var.bound_data.numpy().astype(input_var.dtype)\n    else:\n        raise AssertionError(\"Only tensor creation from constants is supported\")\n    return HLOTensor(created_data, dtype=output_var.dtype)\n\n", "CodeBleu_score": 48.44743254162427}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n    if input_var.bound_data is not None:\n        ctx.module.set_input(input_var.name, input_var.bound_data)\n        ctx.module.set_output(output_var.name, output_var.bound_data)\n        assert input_var.shape == output_var.shape\n        output_var.bound_data = np.array(output_var.bound_data, dtype=output_var.dtype)\n        return HLOTensor(output_var.bound_data)\n    elif output_var.bound_data is not None:\n        ctx.module.set_input(input_var.name, output_var.bound_data)\n        ctx.module.set_output(output_var.name, output_var.bound_data)\n        assert input_var.shape == output_var.shape\n        input_var.bound_data = np.array(output_var.bound_data, dtype=input_var.dtype)\n        return HLOTensor(input_var.bound_data)\n    else:\n        assert False, \"Only tensor creation from constants is supported\"\n\n", "CodeBleu_score": 49.333596672344456}, {"code": "def create_tensor_lower(ctx, *args: Union[HLOTensor, Sequence[HLOTensor]])\n\t\n    assert len(args) == 1\n    assert len(ctx.vars_in) == 1\n    assert len(ctx.vars_out) == 1\n    input_var = ctx.vars_in[0]\n    output_var = ctx.vars_out[0]\n    if input_var.bound_data is not None:\n        ctx.module.set_input(input_var.name, input_var.bound_data)\n        ctx.module.set_output(output_var.name, output_var.bound_data)\n        assert input_var.shape == output_var.shape\n        if output_var.bound_data is not None:\n            output_var.bound_data = output_var.bound_data.astype(\n                output_var.dtype)\n        else:\n            input_var.bound_data = input_var.bound_data.astype(\n                input_var.dtype)\n    else:\n        raise AssertionError(\n            \"Only tensor creation from constants is supported\")\n    return HLOTensor(output_var.name, output_var.shape, output_var.dtype, output_var.bound_data)\n\n", "CodeBleu_score": 47.352992149862686}]}
{"instance_id": "6cd750fa0c8d", "generation_result": [{"code": "def _device_put_scalar(x, device)\n\t\n    pass\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 2.9166666666723406}, {"code": "def _device_put_scalar(x, device)\n\t\n    return _device_put(np.array(x), device)\n\n", "CodeBleu_score": 4.379012625003654}, {"code": "def _device_put_scalar(x, device)\n\t\n    pass\n\n\n\n", "CodeBleu_score": 2.9166666666723406}]}
{"instance_id": "140de7c2b6a8", "generation_result": [{"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list)) and isinstance(rhs_shape, (tuple, list)), \"Shape must be tuple or list\"\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int), \"Shape must be list of int\"\n    if len(rhs_shape) > 0:\n        assert isinstance(rhs_shape[0], int), \"Shape must be list of int\"\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for i in range(len(lhs_shape)):\n        if lhs_shape[i] != rhs_shape[i]:\n            return False\n    return True\n\n", "CodeBleu_score": 50.64773891242691}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list)) and isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0 and len(rhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int) and isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for lhs_dim, rhs_dim in zip(lhs_shape, rhs_shape):\n        if lhs_dim != rhs_dim:\n            return False\n    return True\n\n", "CodeBleu_score": 50.31334258249408}, {"code": "def _shape_equal(lhs_shape, rhs_shape)\n\t\n    if isinstance(lhs_shape, np.ndarray):\n        lhs_shape = list(lhs_shape)\n    if isinstance(rhs_shape, np.ndarray):\n        rhs_shape = list(rhs_shape)\n    assert isinstance(lhs_shape, (tuple, list))\n    assert isinstance(rhs_shape, (tuple, list))\n    if len(lhs_shape) == 0 and len(rhs_shape) == 0:\n        return True\n    if len(lhs_shape) > 0 and len(rhs_shape) > 0:\n        assert isinstance(lhs_shape[0], int)\n        assert isinstance(rhs_shape[0], int)\n    if len(lhs_shape) != len(rhs_shape):\n        return False\n    for i in range(len(lhs_shape)):\n        if lhs_shape[i] != rhs_shape[i]:\n            return False\n    return True\n\n", "CodeBleu_score": 48.30255687407281}]}
{"instance_id": "55d0c71a259b", "generation_result": [{"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n    training_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_metadata = pd.read_csv(\n        test_set_metadata_filename,\n        dtype={**meta_dtypes, \"target\": None},\n    )\n    return training_set, test_set, training_metadata, test_metadata\n\n", "CodeBleu_score": 30.142402921772156}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n    training_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    meta_dtypes_copy = meta_dtypes.copy()\n    del meta_dtypes_copy[\"target\"]\n    test_metadata = pd.read_csv(test_set_metadata_filename, dtype=meta_dtypes_copy)\n    return training_set, test_set, training_metadata, test_metadata\n\n", "CodeBleu_score": 29.553950447019123}, {"code": "def read(\n    training_set_filename,\n    test_set_filename,\n    training_set_metadata_filename,\n    test_set_metadata_filename,\n    dtypes,\n    meta_dtypes,\n)\n\t\n    training_set = pd.read_csv(training_set_filename, dtype=dtypes)\n    test_set = pd.read_csv(test_set_filename, dtype=dtypes)\n    training_metadata = pd.read_csv(training_set_metadata_filename, dtype=meta_dtypes)\n    test_metadata = pd.read_csv(\n        test_set_metadata_filename, dtype={**meta_dtypes, \"target\": None}\n    )\n    meta_dtypes[\"target\"] = dtypes[\"target\"]\n    return training_set, test_set, training_metadata, test_metadata\n\n", "CodeBleu_score": 31.659425529068702}]}
{"instance_id": "9e5e02cd73e0", "generation_result": [{"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcParams, axes as axesmod\n    from matplotlib.pyplot import subplots\n    from numpy import linspace\n\n    with rcParams(axes_style=\"white\"):\n        fig, ax = subplots(1, 1, figsize=(8, 2))\n        ax.set_axis_off()\n        ax.set_xlim([0, 1])\n        ax.set_ylim([0, 1])\n        ax.pcolormesh(linspace(0, 1, 256).reshape(1, -1), cmap=cmap)\n\n\n\n\n", "CodeBleu_score": 28.236200517864553}, {"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcmod\n    with rcmod.axes_style(\"white\"):\n        fig, ax = plt.subplots(1, 1, figsize=(8, 2), constrained_layout=True)\n    ax.set_axis_off()\n    X = np.linspace(0, 1, 256)[None, :]\n    ax.imshow(X.T, aspect=\"auto\", cmap=cmap)\n    ax.set_xlim(-0.5, 255.5)\n    ax.set_ylim(-0.5, 0.5)\n    ax.set_yticks([])\n    ax.set_title(cmap.__name__, rotation=0, loc=\"left\", pad=10)\n\n", "CodeBleu_score": 43.0018510774158}, {"code": "def _show_cmap(cmap)\n\t\n    from matplotlib import rcParams\n    from matplotlib.pyplot import figure, show, axes, pcolormesh\n    from numpy import linspace, meshgrid\n    from matplotlib import rcmod\n    rcmod.axes_style(use='white')\n    fig = figure(figsize=(8, 4))\n    ax = axes([0.01, 0.01, 0.98, 0.98], frameon=False)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    x = linspace(0, 1, 100)\n    X, Y = meshgrid(x, x)\n    pcolormesh(X, Y, linspace(0, 1, 100).reshape(100, 1), cmap=cmap)\n    show()\n\n\n\n", "CodeBleu_score": 36.96681394792806}]}
{"instance_id": "ad0781b5cc38", "generation_result": [{"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return xdata, ydata\n    elif obj.axes.transData != obj.get_transform():\n        points = obj.get_transform().transform(list(zip(xdata, ydata)))\n        return points[:, 0], points[:, 1]\n    else:\n        return xdata, ydata\n\n\n\n", "CodeBleu_score": 40.08817416188132}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.get_axes() is not None:\n        if obj.get_transform() != obj.get_axes().transData:\n            points = obj.get_transform().transform(xdata)\n            return points[:, 0], points[:, 1]\n        else:\n            return xdata, ydata\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 38.603178581460085}, {"code": "def transform_to_data_coordinates(obj, xdata, ydata)\n\t\n    if obj.axes is None:\n        return xdata, ydata\n    elif obj.get_transform() != obj.axes.transData:\n        points = obj.get_transform().transform(list(zip(xdata, ydata)))\n        return points[:, 0], points[:, 1]\n    else:\n        return xdata, ydata\n\n", "CodeBleu_score": 46.15628803877465}]}
{"instance_id": "bf776cadef8d", "generation_result": [{"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n\n", "CodeBleu_score": 6.737749546279492}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n\n", "CodeBleu_score": 6.737749546279492}, {"code": "def kdeplot(self, data=None, data2=None, *args, **kwargs)\n\t\n\n    data = self._maybe_target_series(data, key='data')\n\n    if data2 is not None:\n        if not pd.api.types.is_list_like(data2):\n            data2 = self._df[data2]\n    return self._module.kdeplot(data, data2=data2, *args, **kwargs)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 78.95861998202267}]}
{"instance_id": "fb44964174d9", "generation_result": [{"code": "def plot_most_used_words(df)\n\t\n    # Correct the word \"programa\" to \"programar\"\n    df['tokens'] = df['tokens'].apply(lambda x: ['programar' if w == 'programa' else w for w in x])\n\n    # Filter the dataframe to include only alphabetic tokens that are longer than one character and are not stop words\n    df_filtered = df[df['tokens'].apply(lambda x: all(w.isalpha() and len(w) > 1 and w not in stop_words for w in x))]\n\n    # Count the occurrences of the words\n    word_counts = Counter(chain.from_iterable(df_filtered['tokens']))\n\n    # Select the top 20 most frequent words\n    top_words = word_counts.most_common(20)\n\n    # Create a bar plot showing the frequency of the top 20 words\n    plt.figure(figsize=(10, 6))\n    plt.bar(range(len(top_words)), [count for _, count in top_words], align='center')\n    plt.xticks(range(len(top_words)), [word for word, _ in top_words], rotation=90)\n    plt.xlabel('Word')\n    plt.ylabel('Frequency')\n    plt.title('Most Frequent Words')\n    plt.savefig('most_frequent_words.png')\n\n\n\n\n", "CodeBleu_score": 25.045368275505258}, {"code": "def plot_most_used_words(df)\n\t\n    df['token'] = df['token'].apply(lambda x: 'programar' if x == 'programa' else x)\n    df = df[df['token'].apply(lambda x: x.isalpha())]\n    df = df[df['token'].apply(lambda x: len(x) > 1)]\n    df = df[~df['token'].isin(stopwords)]\n    words = df['token'].value_counts()[:20]\n    plt.figure(figsize=(10, 6))\n    plt.bar(words.index, words.values)\n    plt.xticks(rotation=45)\n    plt.title('Palabras m\u00e1s frecuentes')\n    plt.xlabel('Palabra')\n    plt.ylabel('Frecuencia')\n    plt.savefig('palabras_mas_frecuentes.png', bbox_inches='tight')\n    plt.show()\n\n\n\n\n", "CodeBleu_score": 26.307953806451202}, {"code": "def plot_most_used_words(df)\n\t\n    # Correct the word \"programa\" to \"programar\"\n    df['token'] = df['token'].replace('programa', 'programar')\n\n    # Filter the dataframe to include only alphabetic tokens that are longer than one character and are not stop words\n    df = df[(df['token'].str.isalpha()) & (df['token'].str.len() > 1) & (~df['token'].isin(stopwords.words('spanish')))]\n\n    # Count the occurrences of the filtered words\n    word_counts = df['token'].value_counts()\n\n    # Select the top 20 most frequent words\n    top_words = word_counts.head(20)\n\n    # Create a bar plot showing the frequency of the top 20 words\n    plt.figure(figsize=(10, 5))\n    plt.bar(top_words.index, top_words.values)\n    plt.xticks(rotation=90)\n    plt.xlabel('Word')\n    plt.ylabel('Frequency')\n    plt.title('Most Frequent Words')\n    plt.tight_layout()\n    plt.savefig('most_used_words.png')\n    plt.show()\n\n\n\n", "CodeBleu_score": 36.146970098746934}]}
{"instance_id": "13414a7eb4e3", "generation_result": [{"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n    from bottleneck import move_nanmean\n\n    a = da.from_array(a, chunks=(1000, 1000))\n    a = a.astype(float)\n\n    depth = {\n        1: (0,),\n        2: (0, 0),\n    }[a.ndim]\n\n    boundary = {\n        np.dtype(\"float64\"): np.nan,\n        np.dtype(\"int64\"): None,\n    }[a.dtype]\n\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    y = ag.map_blocks(\n        moving_func,\n        window,\n        min_count=min_count,\n        axis=axis,\n        dtype=float,\n    )\n\n    return da.overlap.trim_internal(y, depth)\n\n", "CodeBleu_score": 44.55590092271683}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n\n    a = da.promote_dtypes(a, a.dtype)\n\n    depth = {\n        \"backward\": window - 1,\n        \"forward\": window - 1,\n        \"centered\": window // 2,\n    }[moving_func.__name__]\n\n    boundary = {\n        \"backward\": a[..., 0],\n        \"forward\": a[..., -1],\n        \"centered\": da.concatenate(\n            [\n                a[..., :depth],\n                a[..., -(window - depth) :],\n            ]\n        ),\n    }[moving_func.__name__]\n\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n    out = da.map_blocks(\n        moving_func, ag, window, min_count=min_count, axis=axis, dtype=a.dtype\n    )\n    out = da.overlap.trim_internal(out, depth)\n\n    return out\n\n", "CodeBleu_score": 47.37727030449568}, {"code": "def dask_rolling_wrapper(moving_func, a, window, min_count=None, axis=-1)\n\t\n    import dask.array as da\n    import numpy as np\n\n    a = da.from_array(a, chunks=a.shape)\n    depth = {-1: window, 1: window}\n    boundary = {-1: \"nearest\", 1: \"nearest\"}\n    ag = da.overlap.overlap(a, depth=depth, boundary=boundary)\n\n    if min_count is None:\n        min_count = 1\n\n    if axis == -1:\n        res = da.map_blocks(\n            moving_func, ag, window, min_count=min_count, axis=1, dtype=a.dtype\n        )\n    else:\n        res = da.map_blocks(\n            moving_func, ag, window, min_count=min_count, axis=0, dtype=a.dtype\n        )\n\n    res = da.overlap.trim_internal(res, depth)\n    return res\n\n", "CodeBleu_score": 43.51067942019954}]}
{"instance_id": "68ce25d325d4", "generation_result": [{"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import numpy as np\n    import dask.array as da\n    from dask.array.linalg import inv, svd, solve\n    from dask.array.linalg import qr\n    from dask.array.linalg import eig\n    from dask.array.linalg import eigh\n    from dask.array.linalg import eigvals\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigvalsh\n   ", "CodeBleu_score": 8.372299939346393}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import numpy as np\n    import dask.array as da\n    from dask.array.linalg import inv\n    from dask.array.linalg import solve\n    from dask.array.linalg import qr\n    from dask.array.linalg import svd\n    from dask.array.linalg import eig\n    from dask.array.linalg import eigh\n    from dask.array.linalg import eigvals\n    from dask.array.linalg import eigvalsh\n    from dask.array.linalg import eigsh\n    from dask.array.linalg import eigsh_lanczos\n    from dask.array.linalg import eigsh_lobpcg\n    from dask.array.linalg import eigsh_arpack\n    from dask.array.linalg import eigsh_arpack_stochastic\n    from dask.array.linalg import eigsh_scipy\n    from dask.array.linalg import eigsh_scipy_sym\n    from dask.array.linalg import eigsh_scipy_arpack\n    from dask.array.linalg import eigsh_scipy_arpack_stochastic\n    from dask.array.linalg import eigsh_scipy_lobpcg\n    from dask.array.linalg import eigsh_scipy_lobpcg_arpack\n    from dask.array.linalg import eigsh_scipy_lobpcg_arpack_stochastic\n    from dask.array.linalg import eigsh_scipy_lobpcg_arpack_stochastic_sym\n    from dask.array.linalg import eigsh_scipy_lobpcg_arpack_stochastic_sym_\n    from dask.array.linalg import eigsh_scipy_lobpcg_arpack_stochastic_sym_\n    from dask.array.linalg import eigsh_scipy_lobpc", "CodeBleu_score": 7.809943417893877}, {"code": "def least_squares(lhs, rhs, rcond=None, skipna=False)\n\t\n    import dask.array as da\n    import numpy as np\n\n    lhs = da.from_array(lhs, chunks=(lhs.shape[0], -1))\n    rhs = da.from_array(rhs, chunks=(rhs.shape[0], -1))\n\n    if skipna:\n        if rhs.ndim == 1:\n            rhs = rhs.reshape(-1, 1)\n        rhs = da.apply_along_axis(np.polynomial.polynomial.polyfit, 0, lhs, rhs, deg=1)\n        coeffs = rhs[:-1]\n        residuals = rhs[-1]\n    else:\n        coeffs, residuals, _, _ = da.linalg.lstsq(lhs, rhs)\n\n    return coeffs, residuals\n\n\n\n", "CodeBleu_score": 39.6129525326753}]}
{"instance_id": "c0c2c53b76e0", "generation_result": [{"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]", "CodeBleu_score": 92.04127144323292}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n", "CodeBleu_score": 22.332506203473944}, {"code": "def from_array(\n        self, data: Any, chunks: T_Chunks | _NormalizedChunks, **kwargs: Any\n    ) -> DaskArray | Any\n\t\n    import dask.array as da\n\n    if isinstance(data, ImplicitToExplicitIndexingAdapter):\n        # lazily loaded backend array classes should use NumPy array operations.\n        kwargs[\"meta\"] = np.ndarray\n\n    return da.from_array(\n        data,\n        chunks,\n        **kwargs,\n    )  # type: ignore[no-untyped-call]\n\n", "CodeBleu_score": 92.04127144323292}]}
{"instance_id": "6559019d09a0", "generation_result": [{"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n\n", "CodeBleu_score": 21.982758620689655}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n    if is_duck_dask_array(self._data):\n        a: tuple[PostPersistCallable[Any], tuple[Any, ...]]\n        a = self._data.__dask_postpersist__()  # type: ignore[no-untyped-call]\n        array_func, array_args = a\n\n        return self._dask_finalize, (array_func,) + array_args\n    else:\n        raise AttributeError(\"Method requires self.data to be a dask array.\")\n\n\n\n", "CodeBleu_score": 93.9150977472243}, {"code": "def __dask_postpersist__(\n        self,\n    ) -> tuple[\n        Callable[\n            [Graph, PostPersistCallable[Any], Any, Any],\n            Self,\n        ],\n        tuple[Any, ...],\n    ]\n\t\n\n", "CodeBleu_score": 21.982758620689655}]}
{"instance_id": "4a2801bb3851", "generation_result": [{"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 57.520993331871395}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 57.520993331871395}, {"code": "def _dask_or_eager_func(\n    name,\n    eager_module=np,\n    dask_module=\"dask.array\",\n)\n\t\n\n    def f(*args, **kwargs):\n        if any(is_duck_dask_array(arg) for arg in args):\n            if isinstance(dask_module, str):\n                dask_module = import_module(dask_module)\n            func = getattr(dask_module, name)\n        else:\n            func = getattr(eager_module, name)\n        return func(*args, **kwargs)\n\n    return f\n\n", "CodeBleu_score": 57.520993331871395}]}
{"instance_id": "eef8d746d01e", "generation_result": [{"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n\n    if arr1.shape != arr2.shape:\n        return False\n\n    if dask is not None and (is_duck_array(arr1) or is_duck_array(arr2)):\n        try:\n            return dask.utils.tokenize(arr1) == dask.utils.tokenize(arr2)\n        except NotImplementedError:\n            return None\n\n    return None\n\n", "CodeBleu_score": 75.82406458215745}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if has_dask and (is_duck_array(arr1) or is_duck_array(arr2)):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 67.37970240720792}, {"code": "def lazy_array_equiv(arr1, arr2)\n\t\n    if arr1 is arr2:\n        return True\n    arr1 = asarray(arr1)\n    arr2 = asarray(arr2)\n    if arr1.shape != arr2.shape:\n        return False\n    if dask is not None and is_duck_array(arr1) and is_duck_array(arr2):\n        return tokenize(arr1) == tokenize(arr2)\n    return None\n\n", "CodeBleu_score": 71.07516632067632}]}
{"instance_id": "15e830ff5fcb", "generation_result": [{"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    import numpy as np\n    import dask.array as da\n    from numpy.random import default_rng\n    rng = default_rng(seed)\n    if chunks:\n        x = rng.standard_normal(shape, chunks=chunks)\n        if frac_nan:\n            x[rng.random(shape) < frac_nan] = np.nan\n        return x\n    else:\n        x = rng.standard_normal(shape)\n        if frac_nan:\n            x[rng.random(shape) < frac_nan] = np.nan\n        return x\n\n\n\n\n", "CodeBleu_score": 44.92860039541935}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    import numpy as np\n    import dask.array as da\n    import random\n    random.seed(seed)\n    if frac_nan is not None:\n        if chunks is not None:\n            arr = da.random.normal(size=shape, chunks=chunks)\n        else:\n            arr = np.random.normal(size=shape)\n        arr = arr.rechunk(chunks)\n        n_nans = int(arr.size * frac_nan)\n        nan_indices = random.sample(range(arr.size), n_nans)\n        arr = arr.flatten()\n        arr[nan_indices] = np.nan\n        arr = arr.reshape(shape)\n    else:\n        if chunks is not None:\n            arr = da.random.normal(size=shape, chunks=chunks)\n        else:\n            arr = np.random.normal(size=shape)\n    return arr\n\n\n\n", "CodeBleu_score": 45.09718062824444}, {"code": "def randn(shape, frac_nan=None, chunks=None, seed=0)\n\t\n    import numpy as np\n    import dask.array as da\n    np.random.seed(seed)\n    if chunks is not None:\n        arr = da.random.randn(shape[0], shape[1], chunks=chunks)\n    else:\n        arr = np.random.randn(*shape)\n    if frac_nan is not None:\n        arr = arr.rechunk(chunks)\n        n_nan = int(np.prod(shape) * frac_nan)\n        idx = np.random.choice(np.arange(np.prod(shape)), size=n_nan, replace=False)\n        arr = arr.flatten()\n        arr[idx] = np.nan\n        arr = arr.reshape(shape)\n    return arr\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.583306269177804}]}
{"instance_id": "5b57abbbe38b", "generation_result": [{"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n\n\n", "CodeBleu_score": 81.06081450739325}, {"code": "def analyst_price_target(self) -> pd.DataFrame\n\t\n    if self._analyst_price_target is None:\n        raise YFNotImplementedError(\"analyst_price_target\")\n    return self._analyst_price_target\n\n", "CodeBleu_score": 81.06081450739325}]}
{"instance_id": "592e414671e9", "generation_result": [{"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.fundamentals_keys.keys():\n        raise ValueError(\n            f\"Invalid name: {name}. Allowed financial statements: {', '.join(const.fundamentals_keys.keys())}\"\n        )\n\n    if timescale not in const.periods.keys():\n        raise ValueError(\n            f\"Invalid timescale: {timescale}. Allowed periods: {', '.join(const.periods.keys())}\"\n        )\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        self.logger.error(\n            f\"Error while creating financials table for {name} and {timescale}: {e}\"\n        )\n        return pd.DataFrame()\n\n", "CodeBleu_score": 36.8246997638376}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.financials_allowed:\n        raise ValueError(\n            f\"{name} is not a valid financial statement. Allowed financial statements are: {const.financials_allowed}\"\n        )\n    if timescale not in const.periods_allowed:\n        raise ValueError(\n            f\"{timescale} is not a valid timescale. Allowed timescales are: {const.periods_allowed}\"\n        )\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        logging.error(f\"Error creating financials table: {e}\")\n        return pd.DataFrame()\n\n", "CodeBleu_score": 36.0440582022838}, {"code": "def _fetch_time_series(self, name, timescale, proxy=None)\n\t\n    if name not in const.fundamentals_keys:\n        raise ValueError(\n            \"Invalid financial statement name: {}\".format(name)\n        )\n\n    if timescale not in const.periods:\n        raise ValueError(\"Invalid timescale: {}\".format(timescale))\n\n    try:\n        return self._create_financials_table(name, timescale, proxy)\n    except Exception as e:\n        self._logger.error(\n            \"Error fetching time series for {} and timescale {}: {}\".format(\n                name, timescale, e\n            )\n        )\n        return pd.DataFrame()", "CodeBleu_score": 33.75385242016381}]}
{"instance_id": "af01d9bae091", "generation_result": [{"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership_list = data['fundOwnership']['ownershipList']\n    for owner in ownership_list:\n        owner['maxAge'] = float(owner['maxAge'])\n\n    self._mutualfund = pd.DataFrame(ownership_list)\n\n    if not self._mutualfund.empty:\n        self._mutualfund['reportDate'] = pd.to_datetime(self._mutualfund['reportDate'])\n        self._mutualfund = self._mutualfund.rename(\n            columns={\n                'reportDate': 'date',\n                'orgName': 'fund_house',\n                'investType': 'fund_type',\n                'maxAge': 'investment_horizon',\n                'pctHoldings': 'holdings',\n                'value': 'value',\n                'valueChange': 'value_change',\n                'valueChangePct': 'value_change_pct'\n            })\n\n", "CodeBleu_score": 30.89711913450428}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    ownership = data[\"ownershipList\"]\n    for owner in ownership:\n        owner[\"rawValue\"] = owner.pop(\"rawValue\")\n        owner.pop(\"maxAge\")\n    df = pd.DataFrame(ownership)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"])\n        df = df.rename(\n            columns={\n                \"value\": \"fundValue\",\n                \"name\": \"fundName\",\n                \"shareClassId\": \"fundId\",\n                \"shareClassName\": \"fundClass\",\n            }\n        )\n    self._mutualfund = df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.823215319345316}, {"code": "def _parse_fund_ownership(self, data)\n\t\n    data = data[\"fundOwnership\"]\n    data = [i for i in data if i[\"ownership\"] != \"-\"]\n    for i in data:\n        i[\"ownership\"] = float(i[\"ownership\"].strip(\"%\")) / 100\n        i[\"value\"] = float(i[\"value\"].replace(\",\", \"\"))\n        i.pop(\"maxAge\")\n    df = pd.DataFrame(data)\n    if not df.empty:\n        df[\"reportDate\"] = pd.to_datetime(df[\"reportDate\"])\n        df = df.rename(\n            columns={\n                \"entityId\": \"id\",\n                \"entityProperName\": \"name\",\n                \"value\": \"value\",\n                \"ownership\": \"ownership\",\n            }\n        )\n    self._mutualfund = df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.36928897907181}]}
{"instance_id": "2b5c6f1253db", "generation_result": [{"code": "def currency(self)\n\t\n    if hasattr(self, \"currency\"):\n        return self.currency\n    meta = self.history_metadata(as_dict=True)\n    self.currency = meta[\"currency\"]\n    return self.currency\n\n", "CodeBleu_score": 43.68027709521313}, {"code": "def currency(self)\n\t\n    if self.currency is None:\n        metadata = self.history_metadata(as_dict=True)\n        self.currency = metadata['currency']\n    return self.currency\n\n\n\n", "CodeBleu_score": 41.602035005865936}, {"code": "def currency(self)\n\t\n    if self.currency:\n        return self.currency\n    metadata = self.history_metadata(self.ticker)\n    self.currency = metadata[\"currency\"]\n    return self.currency", "CodeBleu_score": 46.23688666343476}]}
{"instance_id": "16b80be60e3b", "generation_result": [{"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(_RECOMMENDATIONS_URL_, [\"recommendationTrend\"])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = pd.DataFrame(self._recommendations[\"quoteSummary\"][\"result\"][0][\"recommendationTrend\"][\"trend\"])\n            except KeyError:\n                raise YFDataException(\"Could not parse data for recommendations\")\n    return self._recommendations\n\n", "CodeBleu_score": 49.60303291347772}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._fetch(_RECOMMENDATIONS_PROXY_, ['recommendationTrend'])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = self._recommendations['recommendationTrend']['trend']\n            except (KeyError, TypeError):\n                raise YFDataException(\"Could not parse data\")\n    return self._recommendations\n\n", "CodeBleu_score": 42.94438523448554}, {"code": "def recommendations(self) -> pd.DataFrame\n\t\n    if self._recommendations is None:\n        self._recommendations = self._fetch(self._proxy, ['recommendationTrend'])\n        if self._recommendations is None:\n            self._recommendations = pd.DataFrame()\n        else:\n            try:\n                self._recommendations = self._recommendations['quoteSummary']['result'][0]['recommendationTrend']['trend']\n            except KeyError:\n                raise YFDataException('Error parsing data.')\n    return self._recommendations\n\n", "CodeBleu_score": 48.21868187899657}]}
{"instance_id": "abaf8c2a3ecc", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    import time\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    if not hasattr(clf, 'n_clusters'):\n        raise ValueError(\n            \"The classifier does not have the 'n_clusters' attribute.\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    sse = []\n    if show_cluster_time:\n        cluster_time = []\n\n    for k in cluster_ranges:\n        clf.n_clusters = k\n        t0 = time.time()\n        clf.fit(X)\n        duration = time.time() - t0\n        sse.append(clf.score(X))\n        if show_cluster_time:\n            cluster_time.append(duration)\n\n    sse = np.array(sse)\n    cluster_ranges = np.array(cluster_ranges)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, sse, 'o-', color='b')\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, cluster_time, 'o-', color='r')\n        ax2.set_ylabel('Clustering Time (s)', fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 50.953888357505896}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The passed clf does not have the 'n_clusters' attribute, \"\n                        \"which is required for generating an elbow plot.\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, min(11, len(X)))\n\n    sse = []\n    for k in cluster_ranges:\n        clf.n_clusters = k\n        sse.append(clf.score(X, sample_weight=None))\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    # Plot SSE\n    ax.plot(cluster_ranges, sse, label='SSE')\n    ax.set_xticks(cluster_ranges)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of Squared Errors (SSE)', fontsize=text_fontsize)\n    ax.tick_params(labelsize=text_fontsize)\n\n    # Plot time to cluster on secondary axis\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, [0] + list(np.diff(sse)), label='Time to Cluster',\n                 color='r', linestyle='--')\n        ax2.set_ylabel('Time to Cluster', fontsize=text_fontsize, color='r')\n        ax2.tick_params(labelsize=text_fontsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.legend(fontsize=text_fontsize)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 52.211727116457126}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None, n_jobs=1,\n                     show_cluster_time=True, ax=None, figsize=None,\n                     title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from time import time\n    from sklearn.metrics import silhouette_score\n    import matplotlib.pyplot as plt\n    import numpy as np\n    from sklearn.cluster import KMeans\n\n    if not hasattr(clf, 'n_clusters'):\n        raise ValueError(\n            \"The classifier does not have `n_clusters` attribute\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(2, 11)\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    start_time = time()\n    sse = []\n    for k in cluster_ranges:\n        clf = clf.set_params(n_clusters=k)\n        clf.fit(X)\n        sse.append(clf.inertia_)\n    end_time = time()\n    durations = end_time - start_time\n    ax.plot(cluster_ranges, sse)\n    ax.set_xticks(cluster_ranges)\n    ax.set_xticklabels(cluster_ranges)\n    ax.set_xlabel('Number of clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Sum of squared error', fontsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    if show_cluster_time:\n        ax2 = ax.twinx()\n        ax2.plot(cluster_ranges, durations, 'ro-')\n        ax2.set_ylabel('seconds', fontsize=text_fontsize)\n    return ax\n\n", "CodeBleu_score": 52.812821399519585}]}
{"instance_id": "8a90815c4ee1", "generation_result": [{"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    from time import time\n    t0 = time()\n    clf = clone(clf)\n    clf.set_params(n_clusters=n_clusters)\n    clf.fit(X)\n    t1 = time()\n    return clf.score(X), t1 - t0\n\n", "CodeBleu_score": 45.29275836699612}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    start_time = time()\n    cloned_clf = clone(clf)\n    cloned_clf.set_params(n_clusters=n_clusters)\n    cloned_clf.fit(X)\n    end_time = time()\n    return cloned_clf, end_time - start_time\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.836956682164626}, {"code": "def _clone_and_score_clusterer(clf, X, n_clusters)\n\t\n    from time import time\n    start = time()\n    clf_clone = clf.clone()\n    clf_clone.n_clusters = n_clusters\n    clf_clone.fit(X)\n    end = time()\n    return clf_clone.score(X), end - start\n\n", "CodeBleu_score": 42.31544047947035}]}
{"instance_id": "da40bd5dd81a", "generation_result": [{"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, \"fit\"):\n        raise TypeError(f\"{clf} is not a valid clusterer instance.\")\n\n    if not hasattr(clf, \"fit_predict\"):\n        raise TypeError(f\"{clf} is not a valid clusterer instance.\")\n\n    additional_methods = {\n        \"plot_silhouette\": _plot_silhouette,\n        \"plot_elbow_curve\": _plot_elbow_curve,\n    }\n\n    for method_name, method in additional_methods.items():\n        if hasattr(clf, method_name):\n            warnings.warn(\n                f\"{clf} already has a method called {method_name}, it will be overridden.\"\n            )\n        setattr(clf, method_name, method.__get__(clf))\n\n    return clf\n\n", "CodeBleu_score": 34.39258782892038}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, \"fit\") or not hasattr(clf, \"fit_predict\"):\n        raise TypeError(\n            f\"{clf} is not a valid clusterer instance. It must have 'fit' and 'fit_predict' methods.\"\n        )\n\n    def plot_silhouette(self, X, ax=None, figsize=(10, 6), title=None, **kwargs):\n        \"\"\"\n        The function `plot_silhouette` is a method of the class `clusterer`. It takes in two arguments: `self` and `X`. The method is used to plot the silhouette diagram of the clustering algorithm.\n\n        The method first imports the necessary libraries, including `matplotlib.pyplot`, `numpy`, `pandas`, `seaborn`, and `sklearn.metrics`. It then sets the style of the plot using `seaborn.set_style` and sets the context of the plot using `seaborn.set_context`.\n\n        Next, the method checks if the input `X` is a `pandas.DataFrame`. If it is, the method converts it to a `numpy.ndarray` using the `values` attribute.\n\n        The method then calls the `fit_predict` method of the `clusterer` object to obtain the cluster labels for the input data.\n\n        The method then calculates the silhouette scores for each data point using the `silhouette_samples` function from `sklearn.metrics`. It also calculates the average silhouette score using the `silhouette_score` function.\n\n        The method then creates a new `pandas.DataFrame` called `silhouette_df` with two columns: `cluster` and `silhouette_score`. The `cluster` column contains the cluster labels for each data point, and the `silhouette_score` column contains the silhouette scores for each data point.\n\n        The method then creates a new `pandas.DataFrame` called `silhouette_avg_df` with two columns: `cluster` and `silhouette_score`. The `cluster` column contains the cluster labels", "CodeBleu_score": 27.3092374687059}, {"code": "def clustering_factory(clf)\n\t\n    if not hasattr(clf, \"fit\"):\n        raise TypeError(\"The clustering object should have a 'fit' method.\")\n    if not hasattr(clf, \"fit_predict\"):\n        raise TypeError(\"The clustering object should have a 'fit_predict' method.\")\n\n    def plot_silhouette(self, X, **kwargs):\n        \"\"\"The function plot_silhouette takes a clustering object self and a dataset X as arguments.", "CodeBleu_score": 13.499754579763929}]}
{"instance_id": "b8d8ba3c0b1b", "generation_result": [{"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    from sklearn.model_selection import learning_curve\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if train_sizes is not None:\n        train_sizes = train_sizes\n    else:\n        train_sizes = np.linspace(0.1, 1.0, 5)\n\n    N_train, val_train, val_test = learning_curve(\n        clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    ax.set_xlabel(\"Training examples\", fontsize=text_fontsize)\n    ax.set_ylabel(\"Score\", fontsize=text_fontsize)\n    ax.grid()\n\n    train_scores_mean = np.mean(val_train, axis=1)\n    train_scores_std = np.std(val_train, axis=1)\n    test_scores_mean = np.mean(val_test, axis=1)\n    test_scores_std = np.std(val_test, axis=1)\n\n    ax.plot(N_train, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(N_train, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", fontsize=text_fontsize)\n\n    ax.fill_between(N_train, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(N_train, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_", "CodeBleu_score": 73.86106170895884}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    from sklearn.model_selection import learning_curve\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if train_sizes is not None:\n        train_sizes, train_scores, test_scores = learning_curve(\n            clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes, scoring=scoring)\n    else:\n        train_sizes, train_scores, test_scores = learning_curve(\n            clf, X, y, cv=cv, n_jobs=n_jobs, scoring=scoring)\n\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n\n    # Plot learning curve\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1,\n                    color=\"g\")\n    ax.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n            label=\"Training score\")\n    ax.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n            label=\"Cross-validation score\")\n    ax.legend(loc=\"best\", font", "CodeBleu_score": 75.06671842542407}, {"code": "def plot_learning_curve(clf, X, y, title='Learning Curve', cv=None,\n                        train_sizes=None, n_jobs=1, scoring=None,\n                        ax=None, figsize=None, title_fontsize=\"large\",\n                        text_fontsize=\"medium\")\n\t\n    from sklearn.model_selection import learning_curve\n    import matplotlib.pyplot as plt\n\n    if ax is None:\n        fig, ax = plt.subplots(1, 1, figsize=figsize)\n\n    ax.set_title(title, fontsize=title_fontsize)\n    if train_sizes is not None:\n        train_sizes, train_scores, test_scores = learning_curve(\n            clf, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes,\n            scoring=scoring)\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n    else:\n        train_sizes, train_scores, test_scores = learning_curve(\n            clf, X, y, cv=cv, n_jobs=n_jobs, scoring=scoring)\n        train_scores_mean = np.mean(train_scores, axis=1)\n        train_scores_std = np.std(train_scores, axis=1)\n        test_scores_mean = np.mean(test_scores, axis=1)\n        test_scores_std = np.std(test_scores, axis=1)\n\n    ax.grid()\n    ax.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                    train_scores_mean + train_scores_std, alpha=0.1,\n                    color=\"r\")\n    ax.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                    test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n    ax.plot(train_sizes, train_", "CodeBleu_score": 70.04101264829616}]}
{"instance_id": "e6e76eb35945", "generation_result": [{"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have a \"\n                        \"'n_clusters' attribute. \"\n                        \"'%s' doesn't appear to have \"\n                        \"one.\" % (clf))\n\n    clfs = [clone(clf) for _ in cluster_ranges]\n\n    for i, c in enumerate(cluster_ranges):\n        clfs[i].n_clusters = c\n\n    labels = np.asarray([c.fit(X).score(X) for c in clfs])\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, np.abs(labels), linestyle='--', marker='o',\n            color='b')\n\n    ax.grid(True)\n\n    ax.set_xlabel('Number of clusters')\n    ax.set_xticks(cluster_ranges)\n    ax.set_xticklabels(cluster_ranges)\n    ax.set_ylabel('Score', color='b')\n    ax.set_title(title, fontsize=title_fontsize)\n\n    # setting the fontsize for the ticks of the x-axis and y-axis\n    ax.xaxis.set_tick_params(labelsize=text_fontsize)\n    ax.yaxis.set_tick_params(labelsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 53.23779423932628}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have a `n_clusters` attribute\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    inertia_scores = []\n    for k in cluster_ranges:\n        clf.n_clusters = k\n        clf.fit(X)\n        inertia_scores.append(clf.inertia_)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, inertia_scores, 'o-', color='g')\n    ax.grid(True)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Inertia', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.set_title(\"Elbow Plot \" + title, fontsize=title_fontsize)\n    return ax", "CodeBleu_score": 51.5293786598674}, {"code": "def plot_elbow_curve(clf, X, title='Elbow Plot', cluster_ranges=None,\n                     ax=None, figsize=None, title_fontsize=\"large\",\n                     text_fontsize=\"medium\")\n\t\n    if not hasattr(clf, 'n_clusters'):\n        raise TypeError(\"The classifier passed should have a `n_clusters` attribute\")\n\n    if cluster_ranges is None:\n        cluster_ranges = range(1, 11, 2)\n\n    inertia_scores = []\n    for k in cluster_ranges:\n        clf.n_clusters = k\n        clf.fit(X)\n        inertia_scores.append(clf.inertia_)\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    ax.plot(cluster_ranges, inertia_scores, 'o-', color='g')\n    ax.grid(True)\n    ax.set_xlabel('Number of Clusters', fontsize=text_fontsize)\n    ax.set_ylabel('Inertia', fontsize=text_fontsize)\n    ax.set_xticks(cluster_ranges)\n    ax.tick_params(labelsize=text_fontsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    return ax\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 51.79822987580973}]}
{"instance_id": "6f4530c8a20f", "generation_result": [{"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from sklearn.decomposition import PCA\n    import matplotlib.pyplot as plt\n\n    X = PCA(n_components=2).fit_transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    targets = len(set(y))\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.set_xlabel('Principal Component 1', fontsize=text_fontsize)\n    ax.set_ylabel('Principal Component 2', fontsize=text_fontsize)\n    for i, target_name in zip(range(targets), clf.classes_):\n        ax.scatter(X[y == i, 0], X[y == i, 1], s=80,\n                    facecolors='none', edgecolors='black', label=target_name)\n    ax.legend(loc=\"best\", shadow=False, scatterpoints=1)\n    ax.axis([-4, 4, -3, 3])\n    return ax\n\n", "CodeBleu_score": 47.32823105774203}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from sklearn.decomposition import PCA\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n\n    pca = PCA(n_components=2)\n    X_pca = pca.fit_transform(X)\n\n    n_classes = len(np.unique(y))\n    colors = plt.cm.get_cmap(cmap, n_classes)(np.linspace(0, 1, n_classes))\n\n    for i, class_name in enumerate(np.unique(y)):\n        ax.scatter(X_pca[y == class_name, 0], X_pca[y == class_name, 1],\n                   color=colors[i], label=class_name)\n\n    ax.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0] * 100:.2f}%)')\n    ax.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1] * 100:.2f}%)')\n    ax.set_title(title, fontsize=title_fontsize)\n    ax.legend(loc='best', fontsize=text_fontsize)\n\n    return ax\n\n", "CodeBleu_score": 51.23552489588372}, {"code": "def plot_pca_2d_projection(clf, X, y, title='PCA 2-D Projection', ax=None,\n                           figsize=None, cmap='Spectral',\n                           title_fontsize=\"large\", text_fontsize=\"medium\")\n\t\n    from sklearn.decomposition import PCA\n    import matplotlib.pyplot as plt\n\n    X = PCA(n_components=2).fit_transform(X)\n    if ax is None:\n        fig, ax = plt.subplots(figsize=figsize)\n    ax.set_title(title, fontsize=title_fontsize)\n    targets = list(set(y))\n    colors = ['b', 'r', 'g', 'c', 'm', 'y', 'k']\n    for color, i, target_name in zip(colors, targets, target_names):\n        ax.scatter(X[y == i, 0], X[y == i, 1],\n                   color=color, label=target_name, alpha=0.5)\n    ax.set_xlabel('PC1', fontsize=text_fontsize)\n    ax.set_ylabel('PC2', fontsize=text_fontsize)\n    ax.legend(loc='best', shadow=False, scatterpoints=1)\n    ax.tick_params(direction='in', length=6, width=2, colors='k',\n                   grid_color='k', grid_alpha=0.5)\n    return ax\n\n", "CodeBleu_score": 50.52480210770586}]}
{"instance_id": "e7c2775d024c", "generation_result": [{"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    X = np.arange(16)\n    Y1 = np.random.uniform(0.5, 1.0, len(X))\n    Y2 = np.random.uniform(0.5, 1.0, len(X))\n\n    ax.bar(X, +Y1, facecolor='#cccccc', edgecolor='white')\n    ax.bar(X, -Y2, facecolor='#999999', edgecolor='white')\n\n    ax.bar(X, +Y1, facecolor='#ffaaaa', edgecolor='white', clip_path=clip1)\n    ax.bar(X, -Y2, facecolor='#ff7777', edgecolor='white', clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\n    ax.text(0.0, 1.0, \"Bar plot\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", size=16, color=\"black\")\n    ax.text(0.0, 0.92, \"ax.bar()\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", size=12, color=\"#0000aa\",\n            family=\"monospace\")\n\n", "CodeBleu_score": 41.71028073103021}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n\n    # data\n    X = np.arange(1, 17)\n    Y1 = np.random.uniform(0.5, 1.0, len(X))\n    Y2 = np.random.uniform(0.5, 1.0, len(X))\n\n    # gray bars\n    ax.bar(X, +Y1, facecolor='#cccccc', edgecolor='white', width=1,\n           align='center', linewidth=0)\n    ax.bar(X, -Y2, facecolor='#999999', edgecolor='white', width=1,\n           align='center', linewidth=0)\n\n    # red bars\n    ax.bar(X, +Y1, facecolor='#ff0000', edgecolor='white', width=1,\n           align='center', linewidth=0, clip_path=clip1)\n    ax.bar(X, -Y2, facecolor='#ff0000', edgecolor='white', width=1,\n           align='center', linewidth=0, clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.05, 0.95, \"Bar plot\", color='black', fontsize=20,\n            horizontalalignment='left', verticalalignment='top',\n            transform=ax.transAxes)\n    ax.text(0.95, 0.95, \"ax.bar()\", color='blue', fontsize=20,\n            horizontalalignment='right', verticalalignment='top',\n            fontfamily='monospace', transform=ax.transAxes)\n\n", "CodeBleu_score": 40.54214444046893}, {"code": "def barplot(ax)\n\t\n    clip1, clip2 = clip_path(ax)\n    X = np.arange(16)\n    Y1 = np.random.uniform(0.5, 1, len(X))\n    Y2 = np.random.uniform(0.5, 1, len(X))\n\n    ax.bar(X, +Y1, 1, facecolor='#cccccc', edgecolor='white', clip_path=clip1)\n    ax.bar(X, -Y2, 1, facecolor='#999999', edgecolor='white', clip_path=clip1)\n    ax.bar(X, +Y1, 1, facecolor='#ffaaaa', edgecolor='white', clip_path=clip2)\n    ax.bar(X, -Y2, 1, facecolor='#ff7777', edgecolor='white', clip_path=clip2)\n\n    ax.set_xlim(-1, 16)\n\n    ax.text(0.05, 1.05, \"Bar plot\", transform=ax.transAxes,\n            ha=\"left\", va=\"bottom\", color=\"0.3\")\n    ax.text(0.95, 1.05, \"ax.bar()\", transform=ax.transAxes,\n            ha=\"right\", va=\"bottom\", color=\"b\",\n            family=\"monospace\", fontsize=\"medium\")\n\n", "CodeBleu_score": 52.12463279983714}]}
{"instance_id": "0ec1d146a32b", "generation_result": [{"code": "def split(n_segment)\n\t\n    width = (1.0 - 0.00) / n_segment\n    padding = width * 0.1\n    X0 = np.zeros(n_segment)\n    X1 = np.zeros(n_segment)\n    for i in range(n_segment):\n        X0[i] = 0.0 + i * width + i * padding\n        X1[i] = X0[i] + width\n    return X0, X1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 25.900924063268416}, {"code": "def split(n_segment)\n\t\n    width = 100\n    padding = 2\n    segment_width = (width - padding * (n_segment - 1)) / n_segment\n    segment_width = [segment_width] * n_segment\n    X0 = [0]\n    X1 = []\n    for i in range(n_segment - 1):\n        X0.append(X0[i] + segment_width[i] + padding)\n        X1.append(X0[i + 1] + segment_width[i + 1])\n    return X0, X1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 29.958444014616738}, {"code": "def split(n_segment)\n\t\n    width = n_segment\n    padding = width / 10\n    X0 = np.zeros(width)\n    X1 = np.zeros(width)\n    for i in range(width):\n        X0[i] = i * padding + i * width\n        X1[i] = X0[i] + width\n    return X0, X1\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.225124086106252}]}
{"instance_id": "604a3e93ac0d", "generation_result": [{"code": "def pixelated_text(dpi=100)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import matplotlib.font_manager as fm\n\n    # Set the font properties\n    font = fm.FontProperties(family='monospace', style='normal', size=75)\n\n    # Create a figure and a canvas\n    fig, ax = plt.subplots(figsize=(1, 1))\n\n    # Place the character 'a' at the center of the figure\n    ax.text(0.5, 0.5, 'a', fontproperties=font, ha='center', va='center')\n\n    # Remove the axis\n    ax.axis('off')\n\n    # Draw the canvas\n    fig.canvas.draw()\n\n    # Get the RGBA buffer from the canvas\n    rgba_buf = fig.canvas.buffer_rgba()\n\n    # Convert the RGBA buffer to a NumPy array\n    arr = np.asarray(rgba_buf)\n\n    # Reshape the array to the dimensions specified by dpi\n    arr = arr.reshape((dpi, dpi, 4))\n\n    # Roll the array along the last axis to adjust the color channels\n    arr = np.roll(arr, 1, axis=-1)\n\n    # Return the resulting image array\n    return arr\n\n\n\n", "CodeBleu_score": 43.76385116035}, {"code": "def pixelated_text(dpi=100)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvas\n    from matplotlib.figure import Figure\n    import matplotlib as mpl\n\n    # Create a figure and a canvas\n    fig = Figure(figsize=(1, 1), dpi=dpi)\n    canvas = FigureCanvas(fig)\n\n    # Place the character 'a' at the center of the figure\n    ax = fig.add_axes([0, 0, 1, 1])\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n\n    # Remove the axis\n    ax.set_axis_off()\n\n    # Draw the canvas\n    canvas.draw()\n\n    # Convert the canvas to an image array\n    image_array = np.array(canvas.renderer._renderer)\n\n    # Reshape the array to the dimensions specified by dpi\n    image_array = image_array.reshape((dpi, dpi, 4))\n\n    # Adjust the color channels by rolling the array along the last axis\n    image_array = np.roll(image_array, 1, axis=-1)\n\n    return image_array\n\n\n\n\n", "CodeBleu_score": 49.82159938582755}, {"code": "def pixelated_text(dpi=100)\n\t\n    import matplotlib.pyplot as plt\n    import numpy as np\n\n    # Set the DPI (dots per inch)\n    dpi = 100\n\n    # Create a figure and a canvas\n    fig, ax = plt.subplots(figsize=(1, 1), dpi=dpi)\n\n    # Place the character 'a' at the center of the figure\n    ax.text(0.5, 0.5, 'a', fontsize=75, ha='center', va='center')\n\n    # Remove the axis\n    ax.axis('off')\n\n    # Draw the canvas\n    fig.canvas.draw()\n\n    # Get the RGBA values of the image\n    rgba = np.array(fig.canvas.renderer._renderer)\n\n    # Reshape the array to the dimensions specified by dpi\n    rgba = rgba.reshape((dpi, dpi, 4))\n\n    # Adjust the color channels by rolling the array along the last axis\n    rgba = np.roll(rgba, 1, axis=-1)\n\n    # Return the resulting image array\n    return rgba\n\n\n\n", "CodeBleu_score": 46.67830446056618}]}
{"instance_id": "2a7fc7d560ea", "generation_result": [{"code": "def curve()\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n    import random\n\n    # Define the number of components\n    n_components = random.randint(3, 6)\n\n    # Define the range of centers\n    center_range = (0, 10)\n\n    # Define the range of widths\n    width_range = (0.1, 1.0)\n\n    # Define the range of scales\n    scale_range = (0.1, 1.0)\n\n    # Initialize the curve array\n    curve = np.zeros(100)\n\n    # Iterate over the number of components\n    for i in range(n_components):\n        # Generate random center, width, and scale\n        center = random.uniform(*center_range)\n        width = random.uniform(*width_range)\n        scale = random.uniform(*scale_range)\n\n        # Generate the Gaussian-like component\n        component = scale * np.exp(-((np.arange(100) - center) / width) ** 2)\n\n        # Add the component to the curve\n        curve += component\n\n    # Normalize the curve\n    curve /= np.sum(curve)\n\n    # Plot the curve\n    plt.plot(curve)\n    plt.show()\n\n    return curve\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 28.742738993579188}, {"code": "def curve()\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Initialize an array of zeros\n    curve = np.zeros(1000)\n\n    # Randomly determine the number of components\n    num_components = np.random.randint(1, 5)\n\n    # Randomly determine the centers, widths, and scales of the components\n    centers = np.random.uniform(0, 1000, num_components)\n    widths = np.random.uniform(10, 50, num_components)\n    scales = np.random.uniform(1, 10, num_components)\n\n    # Normalize the widths and scales to sum to specific values\n    widths = widths / np.sum(widths) * 50\n    scales = scales / np.sum(scales) * 10\n\n    # Add the scaled Gaussian components to the curve\n    for i in range(num_components):\n        curve += scales[i] * np.exp(-(np.arange(1000) - centers[i])**2 / (2 * widths[i]**2))\n\n    # Return the resulting composite curve\n    return curve\n\n\n\n", "CodeBleu_score": 36.6406118843795}, {"code": "def curve()\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Define the number of components\n    n_components = np.random.randint(1, 5)\n\n    # Define the centers of the components\n    centers = np.random.uniform(-1, 1, n_components)\n\n    # Define the widths of the components\n    widths = np.random.uniform(0.1, 0.5, n_components)\n\n    # Normalize the widths to sum to a specific value\n    widths = widths / np.sum(widths) * 0.5\n\n    # Define the scales of the components\n    scales = np.random.uniform(0.1, 0.5, n_components)\n\n    # Normalize the scales to sum to a specific value\n    scales = scales / np.sum(scales) * 0.5\n\n    # Generate the curve\n    x = np.linspace(-1, 1, 100)\n    y = np.zeros_like(x)\n    for i in range(n_components):\n        y += scales[i] * np.exp(-((x - centers[i]) / widths[i])**2)\n\n    # Plot the curve\n    plt.plot(x, y)\n    plt.show()\n\n    return y\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 43.901371588823366}]}
{"instance_id": "be694335ebfc", "generation_result": [{"code": "def difference(derivative, accuracy=1)\n\t\n    derivative += 1\n    radius = (accuracy + 1) / 2\n    points = np.linspace(-radius, radius, derivative)\n    coefficients = np.linalg.inv(np.vander(points))[derivative - 1] * factorial(derivative - 1)\n    return coefficients, points\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 57.950717681570566}, {"code": "def difference(derivative, accuracy=1)\n\t\n    derivative += 1\n    radius = accuracy / derivative\n    points = np.linspace(-radius, radius, derivative)\n    inverse = np.linalg.inv(np.vander(points))\n    return inverse[derivative - 1] / math.factorial(derivative - 1), points\n\n\n\n", "CodeBleu_score": 52.69448358770222}, {"code": "def difference(derivative, accuracy=1)\n\t\n\n    derivative += 1\n    radius = accuracy / derivative\n\n    points = np.linspace(-radius, radius, derivative)\n    coefficients = np.linalg.inv(np.vander(points))[derivative - 1]\n\n    return coefficients / np.math.factorial(derivative - 1), points\n\n\n\n", "CodeBleu_score": 53.40974914065488}]}
{"instance_id": "fa3fb47f33fa", "generation_result": [{"code": "def interpolate(X, Y, T)\n\t\n    import numpy as np\n    import matplotlib.pyplot as plt\n\n    # Calculate the distances between consecutive points\n    distances = np.sqrt(np.diff(X)**2 + np.diff(Y)**2)\n\n    # Calculate the cumulative distances\n    cumulative_distances = np.cumsum(distances)\n\n    # Calculate the total distance\n    total_distance = cumulative_distances[-1]\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interpolated = np.interp(T, cumulative_distances, X)\n    Y_interpolated = np.interp(T, cumulative_distances, Y)\n\n    # Return the interpolated X and Y coordinates along with the total distance\n    return X_interpolated, Y_interpolated, total_distance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.93965834818718}, {"code": "def interpolate(X, Y, T)\n\t\n    import numpy as np\n\n    # Calculate the distances between consecutive points\n    distances = np.sqrt(np.diff(X) ** 2 + np.diff(Y) ** 2)\n\n    # Calculate the cumulative distances\n    cumulative_distances = np.concatenate([[0], np.cumsum(distances)])\n\n    # Interpolate the X and Y coordinates at the positions specified by T\n    X_interpolated = np.interp(T, cumulative_distances, X)\n    Y_interpolated = np.interp(T, cumulative_distances, Y)\n\n    # Calculate the total distance covered by the original coordinates\n    total_distance = np.sum(distances)\n\n    return X_interpolated, Y_interpolated, total_distance\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.627256674669436}, {"code": "def interpolate(X, Y, T)\n\t\n    # Compute distances between consecutive points\n    dx = np.diff(X)\n    dy = np.diff(Y)\n    ds = np.sqrt(dx**2 + dy**2)\n\n    # Compute cumulative distances\n    s = np.concatenate(([0], np.cumsum(ds)))\n\n    # Interpolate X and Y coordinates at target positions\n    X_interp = np.interp(T, s, X)\n    Y_interp = np.interp(T, s, Y)\n\n    # Compute total distance covered by original coordinates\n    total_distance = np.sum(ds)\n\n    return X_interp, Y_interp, total_distance\n\n", "CodeBleu_score": 27.161658372399344}]}
{"instance_id": "870a2dad3c66", "generation_result": [{"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 74.06148760271176}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None] * 1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n\n", "CodeBleu_score": 74.06148760271176}, {"code": "def mandelbrot_set(xmin, xmax, ymin, ymax, xn, yn, maxiter, horizon=2.0)\n\t\n    X = np.linspace(xmin, xmax, xn, dtype=np.float32)\n    Y = np.linspace(ymin, ymax, yn, dtype=np.float32)\n    C = X + Y[:, None]*1j\n    N = np.zeros(C.shape, dtype=int)\n    Z = np.zeros(C.shape, np.complex64)\n    for n in range(maxiter):\n        I = np.less(abs(Z), horizon)\n        N[I] = n\n        Z[I] = Z[I]**2 + C[I]\n    N[N == maxiter-1] = 0\n    return Z, N\n\n\n\n\n", "CodeBleu_score": 71.73444197840678}]}
{"instance_id": "e1a908945acf", "generation_result": [{"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = max(int(sigma), 3) * 2 + 1\n    A = np.array(A, dtype=float)\n    A_smooth = np.empty_like(A)\n    for i in range(A.shape[0]):\n        A_smooth[i, :] = smooth1d(A[i, :], window_len)\n    for i in range(A.shape[1]):\n        A_smooth[:, i] = smooth1d(A_smooth[:, i], window_len)\n    return A_smooth\n\n", "CodeBleu_score": 40.89805787663002}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = max(int(sigma), 3) * 2 + 1\n    A = np.apply_along_axis(smooth1d, 0, A, window_len)\n    A = np.apply_along_axis(smooth1d, 0, A.T, window_len).T\n    return A\n\n", "CodeBleu_score": 27.4995125832817}, {"code": "def smooth2d(A, sigma=3)\n\t\n    window_len = int(sigma) * 4 + 1\n    window_len = min(window_len, len(A))\n    if window_len < 3:\n        return A\n    s = np.r_[A[window_len - 1 : 0 : -1], A, A[-1:-window_len:-1]]\n    w = np.hanning(window_len)\n    y = np.convolve(w / w.sum(), s, mode=\"same\")\n    y = y[window_len - 1 : -window_len + 1]\n    y = np.transpose(y)\n    y = np.convolve(w / w.sum(), y, mode=\"same\")\n    y = y[window_len - 1 : -window_len + 1]\n    y = np.transpose(y)\n    return y\n\n", "CodeBleu_score": 32.079248940951324}]}
{"instance_id": "94563c54b483", "generation_result": [{"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.ox, self.oy\n    px, py = 72 / dpi, 72 / dpi\n    ox, oy = round(ox * px), round(oy * py)\n    return np.roll(np.roll(padded_src, ox, axis=1), oy, axis=0)", "CodeBleu_score": 30.979794442749508}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.offsets\n    px = 1 / dpi * 72\n    return np.roll(np.roll(padded_src, int(ox / px), axis=1), int(oy / px), axis=0)\n\n\n\n\n\n\n", "CodeBleu_score": 30.251537504420828}, {"code": "def process_image(self, padded_src, dpi)\n\t\n    ox, oy = self.get_offsets()\n    px = 1 / dpi * 72\n    py = 1 / dpi * 72\n    ox = int(ox / px)\n    oy = int(oy / py)\n    return np.roll(np.roll(padded_src, ox, axis=1), oy, axis=0)\n\n", "CodeBleu_score": 32.50213379577003}]}
{"instance_id": "d71d232872fe", "generation_result": [{"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape,) * 2 if isinstance(shape, int) else shape\n    width = width * 2 if isinstance(width, (int, float)) else width\n    center = center * 2 if isinstance(center, (int, float)) else center\n    shape = np.array(shape)\n    width = np.array(width)\n    center = np.array(center)\n    x, y = np.meshgrid(np.linspace(0, shape[0] - 1, shape[0]), np.linspace(0, shape[1] - 1, shape[1]))\n    x = x - center[0]\n    y = y - center[1]\n    x = x / width[0]\n    y = y / width[1]\n    x = x ** 2\n    y = y ** 2\n    x = np.exp(-0.5 * x)\n    y = np.exp(-0.5 * y)\n    return x * y\n\n", "CodeBleu_score": 23.93692431403924}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = (shape,) * 2 if isinstance(shape, int) else shape\n    width = (width,) * 2 if isinstance(width, (int, float)) else width\n    center = (center,) * 2 if isinstance(center, (int, float)) else center\n    x, y = np.meshgrid(np.linspace(-1, 1, shape[0]), np.linspace(-1, 1, shape[1]))\n    d = np.sqrt(x * x + y * y)\n    g = np.exp(-(d - center[0]) ** 2 / (2 * width[0] ** 2) - (d - center[1]) ** 2 / (2 * width[1] ** 2))\n    return g / np.max(g)\n\n\n\n", "CodeBleu_score": 26.514868719635405}, {"code": "def gaussian(shape=(25, 25), width=0.5, center=0.0)\n\t\n    shape = _check_shape(shape)\n    width = _check_width(width)\n    center = _check_center(center, shape)\n    gauss = np.zeros(shape)\n    for i in range(shape[0]):\n        for j in range(shape[1]):\n            gauss[i, j] = np.exp(-0.5 * (((i - center[0]) / width[0]) ** 2 + ((j - center[1]) / width[1]) ** 2))\n    return gauss\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 17.347049386827493}]}
{"instance_id": "7bbd08c987bc", "generation_result": [{"code": "def stimulus(position, size, intensity)\n\t\n    # Convert polar coordinates to Cartesian coordinates\n    x = position[0] * np.cos(position[1])\n    y = position[0] * np.sin(position[1])\n\n    # Normalize the coordinates\n    x_norm = (x - np.mean(x)) / np.std(x)\n    y_norm = (y - np.mean(y)) / np.std(y)\n\n    # Create a mesh grid representing the spatial domain\n    x_range = np.linspace(-1, 1, size[0])\n    y_range = np.linspace(-1, 1, size[1])\n    x_mesh, y_mesh = np.meshgrid(x_range, y_range)\n\n    # Normalize and center the mesh grid\n    x_mesh_norm = (x_mesh - np.mean(x_mesh)) / np.std(x_mesh)\n    y_mesh_norm = (y_mesh - np.mean(y_mesh)) / np.std(y_mesh)\n\n    # Compute the squared Euclidean distance from each point in the mesh grid to the stimulus center\n    R = (x_mesh_norm - x_norm)**2 + (y_mesh_norm - y_norm)**2\n\n    # Compute the stimulus using an exponential decay function\n    stimulus = intensity * np.exp(-R / (2 * size[0] * size[1]))\n\n    return stimulus\n\n", "CodeBleu_score": 29.483786705963954}, {"code": "def stimulus(position, size, intensity)\n\t\n    import numpy as np\n    import math\n    x, y = position\n    R = np.sqrt((x - size) ** 2 + (y - size) ** 2)\n    R = R / size\n    R = np.exp(-R)\n    R = R * intensity\n    return R\n\n", "CodeBleu_score": 22.14527545671338}, {"code": "def stimulus(position, size, intensity)\n\t\n    import numpy as np\n    # Convert polar coordinates to Cartesian coordinates\n    x = position[0] + size[0]/2 * np.cos(position[1])\n    y = position[0] + size[0]/2 * np.sin(position[1])\n    # Normalize the coordinates\n    x = (x - np.mean(x)) / np.std(x)\n    y = (y - np.mean(y)) / np.std(y)\n    # Create a mesh grid representing the spatial domain\n    X, Y = np.meshgrid(x, y)\n    # Compute the squared Euclidean distance from each point in the grid to the stimulus center\n    R = np.sqrt(X**2 + Y**2)\n    # Return an exponential decay function of the distances, scaled by the size parameter\n    return intensity * np.exp(-R**2 / (2 * size**2))\n\n", "CodeBleu_score": 16.90345221300465}]}
{"instance_id": "2b5806238d5d", "generation_result": [{"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel(\"x\")\n    ax.set_ylabel(\"y\")\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        transform=ax.transAxes,\n        fontsize=24,\n        fontweight=\"bold\",\n        color=\"white\",\n    )\n    ax.set_title(\"Title\", fontfamily=\"serif\", fontweight=\"bold\")\n\n", "CodeBleu_score": 43.18852608164324}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([0, 1])\n    ax.set_yticks([0, 1])\n    ax.set_xlabel(\"x\", fontsize=12)\n    ax.set_ylabel(\"y\", fontsize=12)\n    ax.text(\n        0.5,\n        0.5,\n        text,\n        horizontalalignment=\"center\",\n        verticalalignment=\"center\",\n        fontdict={\"family\": \"serif\", \"weight\": \"bold\", \"size\": 20},\n    )\n    ax.set_title(\"Title\", fontdict={\"family\": \"serif\", \"weight\": \"bold\"})\n\n", "CodeBleu_score": 31.580264782386795}, {"code": "def plot(ax, text)\n\t\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.set_xlabel('x')\n    ax.set_ylabel('y')\n    ax.text(0.5, 0.5, text, horizontalalignment='center', verticalalignment='center', fontdict={'family': 'serif', 'weight': 'bold', 'size': 20})\n    ax.set_title('Title', fontdict={'family': 'serif', 'weight': 'bold'})\n\n", "CodeBleu_score": 40.364983528942446}]}
{"instance_id": "0b42aac61e21", "generation_result": [{"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(Xt, **kwargs)", "CodeBleu_score": 74.95631865887393}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, name, transform in self._iter(with_final=False):\n        Xt = transform.transform(Xt)\n    return self.steps[-1][1].predict_cumulative_hazard_function(Xt, **kwargs)\n\n", "CodeBleu_score": 68.13651900340287}, {"code": "def predict_cumulative_hazard_function(self, X, **kwargs)\n\t\n    for name, transform in self.steps[:-1]:\n        X = transform.transform(X)\n    return self.steps[-1][-1].predict_cumulative_hazard_function(X, **kwargs)", "CodeBleu_score": 44.91596863924203}]}
{"instance_id": "c8439e4918ad", "generation_result": [{"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for _, step in self.steps[:-1]:\n        Xt = step.transform(Xt)\n    return self.steps[-1][-1].predict_survival_function(Xt, **kwargs)\n\n\n\n\n", "CodeBleu_score": 54.492951889458126}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self.steps[:-1]:\n        Xt = transform.transform(Xt)\n    return self.steps[-1][1].predict_survival_function(Xt, **kwargs)\n\n\n\n", "CodeBleu_score": 51.73340234170482}, {"code": "def predict_survival_function(self, X, **kwargs)\n\t\n    Xt = X\n    for name, transform in self.steps[:-1]:\n        Xt = transform.transform(Xt)\n    return self.steps[-1][1].predict_survival_function(Xt, **kwargs)\n\n\n\n", "CodeBleu_score": 51.73340234170482}]}
{"instance_id": "216662ca7db4", "generation_result": [{"code": "def _check_success(self, results)\n\t\n    if results.solver.termination_condition == TerminationCondition.optimal:\n        self.logger.info('Successful termination of the optimization algorithm.')\n    elif results.solver.termination_condition == TerminationCondition.maxIterations:\n        self.logger.warning('Convergence termination of the optimization algorithm.')\n    elif results.solver.termination_condition in (TerminationCondition.primalInfeasible, TerminationCondition.dualInfeasible, TerminationCondition.primalAndDualInfeasible):\n        raise RuntimeError('The optimization algorithm failed due to infeasibility.')\n    else:\n        raise RuntimeError('The optimization algorithm failed due to unhandled termination condition.')", "CodeBleu_score": 29.276510570029668}, {"code": "def _check_success(self, results)\n\t\n    if results.success:\n        return\n    elif results.status == 10:\n        raise RuntimeError(\"Optimization terminated due to unboundedness.\")\n    elif results.status == 11:\n        raise RuntimeError(\"Optimization terminated due to local infeasibility.\")\n    elif results.status == 12:\n        raise RuntimeError(\"Optimization terminated due to model numerically unstable.\")\n    elif results.status == 13:\n        raise RuntimeError(\"Optimization terminated due to primal infeasibility.\")\n    elif results.status == 14:\n        raise RuntimeError(\"Optimization terminated due to dual infeasibility.\")\n    elif results.status == 15:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 16:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 17:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 18:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 19:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 20:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 21:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 22:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 23:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 24:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 25:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 26:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 27:\n        raise RuntimeError(\"Optimization terminated due to user interruption.\")\n    elif results.status == 28:\n", "CodeBleu_score": 20.581629617640623}, {"code": "def _check_success(self, results)\n\t\n    if (results.solver.status == SolverStatus.ok) and (results.solver.termination_condition == TerminationCondition.optimal):\n        pass\n    elif (results.solver.termination_condition in (TerminationCondition.maxIterations, TerminationCondition.minStepLength)):\n        self.warning('Failed to converge: %s' % str(results.solver.termination_condition))\n    elif (results.solver.status != SolverStatus.ok):\n        raise RuntimeError('Solver (%s) reported non-optimal exit flags: %s' % (results.solver.name, results.solver.status))\n    elif (results.solver.termination_condition != TerminationCondition.optimal):\n        raise RuntimeError('Solver (%s) reported termination condition: %s' % (results.solver.name, results.solver.termination_condition))", "CodeBleu_score": 30.884922850609158}]}
{"instance_id": "1fe2e379fca0", "generation_result": [{"code": "def _decompose(self, P)\n\t\n    import numpy as np\n    import scipy.linalg as la\n\n    # Compute eigenvalues and eigenvectors\n    eigvals, eigvecs = la.eigh(P)\n\n    # Identify the largest eigenvalue\n    max_eigval = np.max(eigvals)\n\n    # Compute a condition number based on the largest eigenvalue\n    condition_number = max_eigval * np.prod(P.shape) / np.finfo(float).eps\n\n    # Filter out eigenvalues below the positive cutoff\n    positive_cutoff = np.max(eigvals) * np.finfo(float).eps / np.max(eigvals)\n    eigvals = eigvals[eigvals > positive_cutoff]\n\n    # Normalize the eigenvalues\n    eigvals /= max_eigval\n\n    # Return the transposed decomposed matrix and the largest eigenvalue\n    return eigvecs.T, max_eigval", "CodeBleu_score": 28.085337162177865}, {"code": "def _decompose(self, P)\n\t\n    # Calculate eigenvalues and eigenvectors\n    eigvals, eigvecs = linalg.eigh(P)\n\n    # Identify largest eigenvalue\n    max_eigval = eigvals.max()\n\n    # Calculate condition number\n    condition_number = max_eigval / (np.shape(P)[0] * np.finfo(float).eps)\n\n    # Filter out eigenvalues below cutoff\n    eigvals = eigvals[eigvals > -self.cutoff]\n\n    # Normalize eigenvalues\n    eigvals = eigvals / max_eigval\n\n    return eigvecs.T, eigvals, max_eigval", "CodeBleu_score": 15.423086074178094}, {"code": "def _decompose(self, P)\n\t\n    D, V = linalg.eigh(P)\n    D = D[-1::-1]\n    V = fliplr(V[:, -1::-1])\n    V = V.T\n    eVal0 = D[0]\n    condition = max(abs(D)) / (min(abs(D)) + eps)\n    if condition > 1e14:\n        print(\"Bad condition number\")\n        return 0, 0\n    D = D[abs(D) > eVal0 * eps]\n    V = V[:, abs(D) > eVal0 * eps]\n    D = D / max(abs(D))\n    return V, D[0]\n\n", "CodeBleu_score": 15.807154622587985}]}
{"instance_id": "20c3f5d05d79", "generation_result": [{"code": "def _update_coef(self, coef, D)\n\t\n    coef_ = coef\n    coef_[np.abs(coef_) < 1e-15] = 0\n    coef_[np.abs(coef_) > 1e-15] = coef_[np.abs(coef_) > 1e-15] / D[np.abs(coef_) > 1e-15]\n    self.coef_ = coef_", "CodeBleu_score": 17.982420472417683}, {"code": "def _update_coef(self, coef, D)\n\t\n    self.coef_ = (coef != 0) * (coef / np.maximum(D, 1e-15))\n\n", "CodeBleu_score": 16.251144988961624}, {"code": "def _update_coef(self, coef, D)\n\t\n    coef[coef < self.threshold] = 0\n    coef *= D\n    self.coef_ = coef\n\n", "CodeBleu_score": 21.157845347215687}]}
{"instance_id": "37c347d00d35", "generation_result": [{"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    event_type = y_true[:, 0]\n    event_time = y_true[:, 1]\n    risk_set_size = self.risk_set_size\n    n_samples = y_true.shape[0]\n    gradient = np.zeros((n_samples, risk_set_size))\n    for i in range(n_samples):\n        if event_type[i] == 1:\n            gradient[i, :] = np.exp(raw_prediction[i, :])\n            gradient[i, :] /= np.sum(gradient[i, :])\n            gradient[i, :] -= 1\n    if sample_weight is not None:\n        gradient *= sample_weight[:, np.newaxis]\n    return gradient\n\n\n\n", "CodeBleu_score": 42.185569738711656}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    event_type, event_time = y_true[:, 0], y_true[:, 1]\n    hazard_ratio = np.exp(raw_prediction)\n    hazard_ratio_cumsum = np.cumsum(hazard_ratio)\n    hazard_ratio_sum = np.sum(hazard_ratio)\n    if sample_weight is None:\n        return -(event_type - hazard_ratio_cumsum / hazard_ratio_sum) * hazard_ratio\n    else:\n        return -(event_type - hazard_ratio_cumsum / hazard_ratio_sum) * hazard_ratio * sample_weight\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 31.605558010391682}, {"code": "def gradient(self, y_true, raw_prediction, sample_weight=None, **kwargs)\n\t\n    if sample_weight is None:\n        sample_weight = 1\n    event_type, event_time = y_true[:, 0], y_true[:, 1]\n    event_type = event_type.astype(np.int32)\n    gradient = self.compute_gradient(event_type, event_time, raw_prediction)\n    return gradient * sample_weight", "CodeBleu_score": 40.41811045836175}]}
{"instance_id": "6be432d27e52", "generation_result": [{"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if not np.isfinite(X).all():\n            raise ValueError(\"Input contains NaN, infinity or a value too large for %r.\" % estimator_name)\n        return None\n    if np.isnan(X).any():\n        return np.isnan(X).any(axis=0)\n    return None\n\n\n", "CodeBleu_score": 21.620824278799628}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if not self._support_missing_values(X):\n        if not np.isfinite(X).all():\n            raise ValueError(\n                \"Input contains NaN, infinity or a value too large for \"\n                \"dtype('float64').\"\n            )\n        return None\n    if self.missing_values == \"NaN\":\n        mask = np.isnan(X)\n    else:\n        mask = X == self.missing_values\n    if np.any(mask):\n        if estimator_name is None:\n            estimator_name = type(self).__name__\n        raise ValueError(\n            f\"Input contains NaN, infinity or a value too large for \"\n            f\"{estimator_name}.", "CodeBleu_score": 35.058807627120146}, {"code": "def _compute_missing_values_in_feature_mask(self, X, estimator_name=None)\n\t\n    if self._support_missing_values(X):\n        return None\n    elif not np.isfinite(X).all():\n        raise ValueError(\n            \"Input contains NaN, infinity or a value too large for %r.\"\n            % X.dtype\n        )\n    elif np.isnan(X).any():\n        return np.isnan(X).any(axis=0)\n    else:\n        return None\n\n    \n\n", "CodeBleu_score": 20.92813721263584}]}
{"instance_id": "dc5bda895a07", "generation_result": [{"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    check_is_fitted(self, \"tree_\")\n    X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n    pred = self.tree_.predict(X)\n    if return_array:\n        return pred[..., 1]\n    else:\n        x = np.unique(pred[..., 0])\n        return _array_to_step_function(x, pred[..., 1])\n\n", "CodeBleu_score": 67.17404275335457}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    if self.low_memory:\n        check_is_fitted(self, \"tree_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        pred = self.tree_.predict(X)\n        if return_array:\n            return pred[..., 1]\n        return _array_to_step_function(self.unique_times_, pred[..., 1])\n\n    chf = self.predict_cumulative_hazard_function(X, check_input, return_array=True)\n    return self._predict_survival_function(chf, return_array=return_array)\n\n", "CodeBleu_score": 67.1127362210631}, {"code": "def predict_survival_function(self, X, check_input=True, return_array=False)\n\t\n    if self.low_memory:\n        check_is_fitted(self, \"tree_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        pred = self.tree_.predict(X)\n        array = pred[..., 1]\n    else:\n        check_is_fitted(self, \"durations_\")\n        X = self._validate_X_predict(X, check_input, accept_sparse=\"csr\")\n        array = self._predict_survival_function(X)\n\n    if return_array:\n        return array\n    else:\n        return self._array_to_step_function(self.unique_times_, array)\n\n", "CodeBleu_score": 71.31323261660702}]}
{"instance_id": "84ae915b5933", "generation_result": [{"code": "def _pre_fit(self, X, y)\n\t\n    (X, y) = check_X_y(X, y, dtype=np.float64)\n    if X.shape[0] < self.min_samples:\n        raise ValueError('X must contain at least %d samples.' % self.min_samples)\n    (event, time) = y[:, 0], y[:, 1]\n    X = self._center(X)\n    if self.normalize:\n        X = self._normalize(X)\n    idx = np.argsort(time, kind='mergesort')[::-1]\n    X, event, time = (X[idx], event[idx], time[idx])\n    X = np.asfortranarray(X)\n    return (X, event, time, self.mean_, self.scale_)\n\n", "CodeBleu_score": 29.52731234022219}, {"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y, dtype=[np.float64, np.float64])\n    n_samples, n_features = X.shape\n    if self.min_samples is not None and n_samples < self.min_samples:\n        raise ValueError(\n            \"The number of samples is too small to fit a model. \"\n            f\"Got {n_samples} samples but expected at least {self.min_samples}.\"\n        )\n    if self.normalize:\n        X = X / np.sqrt(np.sum(X**2, axis=0))\n    X_mean = X.mean(axis=0)\n    X -= X_mean\n    X, y = check_arrays(X, y, dtype=[np.float64, np.float64])\n    event, time = y[:, 0], y[:, 1]\n    order = np.argsort(-time, kind=\"mergesort\")\n    X, event, time = X[order], event[order], time[order]\n    X = np.asfortranarray(X)\n    return X, event, time, X_mean, np.ones(X.shape[1], dtype=X.dtype)\n\n", "CodeBleu_score": 28.420876267880736}, {"code": "def _pre_fit(self, X, y)\n\t\n    X, y = check_X_y(X, y, accept_sparse=True)\n    if len(X) < self.min_samples:\n        raise ValueError(\n            \"The minimum number of samples required is %d.\" % self.min_samples\n        )\n    if self.normalize:\n        X = normalize(X, norm=\"max\", axis=0)\n    X = np.asfortranarray(X, dtype=np.float64)\n    event, time = check_y_survival(y)\n    X_mean = np.mean(X, axis=0)\n    X_std = np.std(X, axis=0)\n    if self.center:\n        X = X - X_mean\n    if self.scale:\n        X = X / X_std\n    order = np.argsort(-time, kind=\"mergesort\")\n    X = X[order]\n    event = event[order]\n    time = time[order]\n    return X, event, time, X_mean, X_std\n\n", "CodeBleu_score": 40.397663272073444}]}
{"instance_id": "c70bb013f85f", "generation_result": [{"code": "def _check_alphas(self)\n\t\n    if self._alphas is None:\n        if not isinstance(self.nalphas, int) or self.nalphas <= 0:\n            raise ValueError(\n                \"Number of alphas must be a positive integer; got (nalphas=%r)\"\n                % self.nalphas\n            )\n        alphas = np.logspace(\n            -self.alphas_log_min, self.alphas_log_max, self.nalphas\n        )\n        self._alphas = alphas\n        self._alphas_new = True\n    else:\n        alphas = np.asarray(self._alphas)\n        if alphas.ndim != 1:\n            raise ValueError(\"Alphas must be a 1D array, got %r\" % alphas)\n        if not np.all(np.isfinite(alphas)) or not np.all(alphas >= 0.0):\n            raise ValueError(\n                \"Alphas must be non-negative and finite, got %r\" % alphas\n            )\n        self._alphas_new = False\n    return alphas, self._alphas_new\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.42705487698608}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if not isinstance(self.n_alphas, int) or self.n_alphas <= 0:\n            raise ValueError(\"n_alphas must be a positive integer\")\n        alphas = np.linspace(0, 1, self.n_alphas)\n        new_path = True\n    else:\n        alphas = np.asarray(self.alphas)\n        if alphas.ndim != 1:\n            raise ValueError(\"alphas must be a 1D array\")\n        if not np.all(np.isfinite(alphas)) or not np.all(alphas >= 0):\n            raise ValueError(\"alphas must be finite and non-negative\")\n        new_path = False\n    return alphas, new_path\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 47.45269754642633}, {"code": "def _check_alphas(self)\n\t\n    if self.alphas is None:\n        if not isinstance(self.n_alphas, int) or self.n_alphas <= 0:\n            raise ValueError(\"n_alphas must be a positive integer.\")\n        alphas = np.linspace(0, 1, self.n_alphas)\n        new_path = True\n    else:\n        alphas = np.array(self.alphas)\n        if alphas.ndim != 1:\n            raise ValueError(\"alphas must be a 1D array.\")\n        if not np.all(np.isfinite(alphas)):\n            raise ValueError(\"alphas must be finite.\")\n        if not np.all(alphas >= 0):\n            raise ValueError(\"alphas must be non-negative.\")\n        new_path = False\n    return alphas, new_path\n\n\n", "CodeBleu_score": 44.1155096646712}]}
{"instance_id": "7b54a0554ba4", "generation_result": [{"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    order = np.argsort(time, kind=\"mergesort\")\n    time, n_events, n_at_risk, _ = _compute_counts(event, time, order)\n    # omega = n_events / n_at_risk\n    # estimate = np.cumsum(omega)\n    with np.errstate(invalid=\"ignore\", divide=\"ignore\"):\n        ratio = np.divide(n_events, n_at_risk)\n        ratio[n_at_risk == 0] = 0\n\n    return time, np.cumsum(ratio)\n\n", "CodeBleu_score": 40.24939407820759}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    order = np.argsort(time, kind=\"mergesort\")\n\n    uniq_times, n_events, n_at_risk, _ = _compute_counts(event, time, order)\n    # estimate the cumulative hazard function\n    # divides by n_at_risk because the rate is proportional to\n    # n_events / n_at_risk\n    divisor = np.diff(n_at_risk).astype(float, copy=False)\n    hazard = np.r_[0, np.cumsum(n_events / divisor)]\n\n    return uniq_times, hazard\n\n", "CodeBleu_score": 41.393807518598464}, {"code": "def nelson_aalen_estimator(event, time)\n\t\n    event, time = check_y_survival(event, time)\n    order = np.argsort(time, kind=\"mergesort\")\n\n    uniq_times, n_events, n_at_risk, _ = _compute_counts(event, time, order)\n\n    # estimate cumulative hazard\n    cum_n_events = np.cumsum(n_events)\n    cum_n_censored = np.cumsum(n_at_risk - n_events)\n    cum_hazard = _divide_row_vectorize(cum_n_events, cum_n_censored)\n\n    return uniq_times, cum_hazard\n\n", "CodeBleu_score": 36.002219189229706}]}
{"instance_id": "35af806300cc", "generation_result": [{"code": "def ipc_weights(event, time)\n\t\n\n    event, time = check_y_survival(event, time)\n    n_samples = event.shape[0]\n\n    if np.all(event):\n        # if all events have occurred, return ones\n        return np.ones(n_samples)\n\n    # compute the Kaplan-Meier estimator for the event and time data in reverse\n    unique_times, prob_survival = kaplan_meier_estimator(~event, time, reverse=True)\n\n    # find the index positions of event times within the unique time values\n    event_pos = np.searchsorted(unique_times, time[event])\n\n    # retrieve the corresponding survival probabilities\n    ipc_values = prob_survival[event_pos]\n\n    # ensure all retrieved probabilities are positive\n    if np.any(ipc_values <= 0):\n        raise ValueError(\"Encountered non-positive probability in IPC calculation\")\n\n    # create weights array and assign inverse probabilities to events\n    weights = np.ones(n_samples)\n    weights[event] = 1.0 / ipc_values\n\n    return weights\n\n", "CodeBleu_score": 43.08258244564581}, {"code": "def ipc_weights(event, time)\n\t\n    if np.all(event):\n        return np.ones_like(event)\n\n    uniq_times, prob_survival = kaplan_meier_estimator(event, time, reverse=True)\n    # find index positions of event times within the unique time values\n    # account for precision issues due to how isclose is implemented in python\n    # https://docs.python.org/3/library/math.html#math.isclose\n    event_idx = np.searchsorted(uniq_times, time, side=\"left\")\n    event_idx[event_idx >= uniq_times.shape[0]] -= 1\n    # retrieve the corresponding survival probabilities\n    weights = 1.0 - prob_survival[event_idx]\n    # ensure all retrieved probabilities are positive\n    weights[weights < 0] = 0\n    return weights\n\n", "CodeBleu_score": 41.998795724560225}, {"code": "def ipc_weights(event, time)\n\t\n    # check if all events have occurred\n    if np.all(event):\n        return np.ones_like(event)\n\n    # calculate Kaplan-Meier estimator in reverse\n    _, prob_survival = kaplan_meier_estimator(event, time, reverse=True)\n\n    # find index positions of event times within unique time values\n    idx = np.searchsorted(prob_survival[:, 0], time[event == 1])\n\n    # retrieve survival probabilities at event times\n    probs = prob_survival[:, 1][idx]\n\n    # ensure all retrieved probabilities are positive\n    probs[probs <= 0] = np.min(probs[probs > 0])\n\n    # create weights array\n    weights = np.ones_like(event)\n    weights[event == 1] = 1 / probs\n\n    return weights\n\n", "CodeBleu_score": 46.48828586163299}]}
{"instance_id": "72b19985ea11", "generation_result": [{"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n\n    if isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n\n    if isinstance(dfs, list):\n        for i, df in enumerate(dfs):\n            if isinstance(df, pd.DataFrame):\n                dfs[i] = PandasConnector(df)\n            elif isinstance(df, modin.pandas.DataFrame):\n                dfs[i] = ModinConnector(df)\n            elif isinstance(df, pl.DataFrame):\n                dfs[i] = PolarsConnector(df)\n            elif not isinstance(df, BaseConnector):\n                raise ValueError(\n                    f\"Invalid data type: {type(df)}. Expected pandas.DataFrame, modin.pandas.DataFrame, or polars.DataFrame\"\n                )\n    else:\n        raise ValueError(\n            f\"Invalid data type: {type(dfs)}. Expected pandas.DataFrame, modin.pandas.DataFrame, or polars.DataFrame\"\n        )\n\n    return dfs\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 33.604182128008404}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n    elif isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n    elif isinstance(dfs, list):\n        pass\n    else:\n        raise ValueError(\"Invalid input type.\")\n\n    connectors = []\n    for df in dfs:\n        if isinstance(df, pd.DataFrame):\n            connectors.append(PandasConnector(df))\n        elif isinstance(df, modin.pandas.DataFrame):\n            connectors.append(ModinConnector(df))\n        elif isinstance(df, pl.DataFrame):\n            connectors.append(PolarsConnector(df))\n        elif isinstance(df, BaseConnector):\n            connectors.append(df)\n        else:\n            raise ValueError(\"Invalid input type.\")\n\n    return connectors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 39.20953505184027}, {"code": "def get_dfs(\n        self,\n        dfs: Union[\n            pd.DataFrame, BaseConnector, List[Union[pd.DataFrame, BaseConnector]]\n        ],\n    )\n\t\n\n    if isinstance(dfs, pd.DataFrame):\n        dfs = [dfs]\n\n    if isinstance(dfs, BaseConnector):\n        dfs = [dfs]\n\n    if isinstance(dfs, list):\n        for i, df in enumerate(dfs):\n            if isinstance(df, pd.DataFrame):\n                dfs[i] = PandasConnector(df)\n\n            elif isinstance(df, modin.pandas.DataFrame):\n                dfs[i] = ModinConnector(df)\n\n            elif isinstance(df, pl.DataFrame):\n                dfs[i] = PolarsConnector(df)\n\n            elif not isinstance(df, BaseConnector):\n                raise ValueError(\n                    f\"Invalid data type for dfs: {type(df)}. Expected pandas, modin, or polars dataframes or custom connectors.\"\n                )\n\n    else:\n        raise ValueError(\n            f\"Invalid data type for dfs: {type(dfs)}. Expected a single dataframe, a list of dataframes, or a list of custom connectors.\"\n        )\n\n    return dfs", "CodeBleu_score": 34.42163000621862}]}
{"instance_id": "cf22fb696e90", "generation_result": [{"code": "def execute(self) -> pd.DataFrame\n\t\n    if self._cached(include_additional_filters=False):\n        return pd.read_csv(self._cached(include_additional_filters=False))\n    elif self._cached(include_additional_filters=True):\n        return pd.read_csv(self._cached(include_additional_filters=True))\n    elif isinstance(self._instance, pd.DataFrame):\n        return self._instance\n    else:\n        self._instance = self._fetch_data()\n        return self._instance\n\n", "CodeBleu_score": 63.86040755980316}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    cached_data = self._cached(include_additional_filters=False)\n    if cached_data is not None:\n        return pd.read_csv(cached_data)\n\n    cached_data = self._cached(include_additional_filters=True)\n    if cached_data is not None:\n        return pd.read_csv(cached_data)\n\n    if isinstance(self._instance, pd.DataFrame):\n        return self._instance\n\n    self._instance = self._fetch_data()\n    self._cache_data()\n    return self._instance\n\n", "CodeBleu_score": 58.007823298474605}, {"code": "def execute(self) -> pd.DataFrame\n\t\n    cached_data = self._cached(include_additional_filters=False)\n    if cached_data is not None:\n        return pd.read_csv(cached_data)\n\n    cached_data = self._cached(include_additional_filters=True)\n    if cached_data is not None:\n        return pd.read_csv(cached_data)\n\n    if isinstance(self.data, pd.DataFrame):\n        return self.data\n\n    data = self._fetch_data()\n    self.data = data\n    return data\n\n", "CodeBleu_score": 49.37809246688068}]}
{"instance_id": "21df5ecea95f", "generation_result": [{"code": "def column_hash(self)\n\t\n    if not isinstance(self._instance, pd.DataFrame):\n        self._instance = self.execute()\n    column_string = \"|\".join(self._instance.columns)\n    formula_string = self._build_formula()\n    combined_string = column_string + formula_string\n    return hashlib.sha256(combined_string.encode(\"utf-8\")).hexdigest()\n\n", "CodeBleu_score": 73.48074873907947}, {"code": "def column_hash(self)\n\t\n    if isinstance(self._instance, pd.DataFrame):\n        pass\n    else:\n        self._instance = self.execute()\n    column_names_string = \"|\".join(self._instance.columns)\n    formula_string = self._build_formula()\n    combined_string = f\"{column_names_string}|{formula_string}\"\n    return sha256(combined_string.encode()).hexdigest()\n\n", "CodeBleu_score": 50.895875541009005}, {"code": "def column_hash(self)\n\t\n    if isinstance(self._instance, pd.DataFrame):\n        columns_string = \"|\".join(self._instance.columns)\n        formula_string = self._build_formula()\n        combined_string = columns_string + formula_string\n        return hashlib.sha256(combined_string.encode(\"utf-8\")).hexdigest()\n    else:\n        self._instance = self.execute()\n        return self.column_hash()\n\n", "CodeBleu_score": 51.230663199584555}]}
{"instance_id": "27ee5f415000", "generation_result": [{"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, str):\n        if df.endswith(\".csv\"):\n            df = pd.read_csv(df)\n        elif df.endswith(\".xlsx\"):\n            df = pd.read_excel(df)\n        elif df.endswith(\".parquet\"):\n            df = pd.read_parquet(df)\n        else:\n            raise ValueError(\"Unsupported file type\")\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    else:\n        raise ValueError(\"Unsupported input type\")\n    return df\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.91249086071308}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, pd.DataFrame):\n        pass\n    elif isinstance(df, str):\n        if df.endswith(\".csv\"):\n            df = pd.read_csv(df)\n        elif df.endswith(\".xlsx\"):\n            df = pd.read_excel(df)\n        else:\n            raise ValueError(\"Unsupported file type\")\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame(df)\n    else:\n        raise ValueError(\"Unsupported data type\")\n    return df\n\n", "CodeBleu_score": 50.55381458986217}, {"code": "def _load_df(self, df: Union[pd.DataFrame, pd.Series, str, list, dict])\n\t\n    if isinstance(df, pd.Series):\n        df = df.to_frame()\n    elif isinstance(df, str):\n        df = pd.read_csv(df)\n    elif isinstance(df, list):\n        df = pd.DataFrame(df)\n    elif isinstance(df, dict):\n        df = pd.DataFrame.from_dict(df)\n    elif isinstance(df, pd.DataFrame):\n        pass\n    else:\n        raise ValueError(\"Unsupported data type\")\n    return df\n\n\n\n", "CodeBleu_score": 45.08255917549808}]}
{"instance_id": "38f48a358606", "generation_result": [{"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 77.45090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 77.45090533983699}, {"code": "def sample(self, n: int = 3) -> pd.DataFrame\n\t\n    sampled_df = pd.DataFrame()\n    if len(self.df) <= n:\n        sampled_df = self.df.sample(frac=1)\n    else:\n        for col in self.df.columns:\n            col_sample = self._sample_column(col, n)\n            sampled_df[col] = col_sample\n\n    # anonymize the sampled dataframe head\n    sampled_df = Anonymizer.anonymize_dataframe_head(sampled_df)\n\n    return sampled_df\n\n", "CodeBleu_score": 77.45090533983699}]}
{"instance_id": "8bddad2e31ca", "generation_result": [{"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    csv_content = df.to_csv(index=False)\n    return f\"<DataFrame name='{name}' description='{description}' dimensions='{df.shape}'>", "CodeBleu_score": 25.040446962935757}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    name = extras.get(\"name\", \"\")\n    description = extras.get(\"description\", \"\")\n    csv_content = df.to_csv()\n    csv_tag = f\"<csv name='{name}' description='{description}'>", "CodeBleu_score": 21.916957476359464}, {"code": "def convert_df_to_csv(self, df: pd.DataFrame, extras: dict) -> str\n\t\n    # Construct the opening tag with name and description attributes\n    tag = f\"<{df.name} name=\\\"{df.name}\\\" description=\\\"{df.description}\\\">", "CodeBleu_score": 16.46102160700074}]}
{"instance_id": "5380bb60fd39", "generation_result": [{"code": "def convert_df_sql_connector_to_str\n\t\n    if 'description' in df.attrs:\n        description = df.attrs['description']\n        html = f'<table name=\"{df.name}\" description=\"{description}\">", "CodeBleu_score": 19.87494875710168}, {"code": "def convert_df_sql_connector_to_str\n\t\n    # Get the table name and description from the DataFrame metadata\n    table_name = df.metadata.get('table_name', '')\n    table_description = df.metadata.get('table_description', '')\n\n    # Construct the opening table tag with the table name and optional description\n    html = f'<table name=\"{table_name}\">'\n    if table_description:\n        html += f'<p>{table_description}</p>'\n\n    # Add the CSV representation of the DataFrame's head\n    html += df.head().to_csv(index=False)\n\n    # Close the table tag\n    html += '</table>'\n\n    return html\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 40.11552762687436}, {"code": "def convert_df_sql_connector_to_str\n\t\n    if \"description\" in df.attrs:\n        description = df.attrs[\"description\"]\n        table_str = f\"<table name='{df.name}' description='{description}'>", "CodeBleu_score": 19.836538731668522}]}
{"instance_id": "0afd995716c5", "generation_result": [{"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    json_dict = self.convert_df_to_json(df, extras)\n    yaml_str = yaml.dump(json_dict)\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        yaml_str = f\"<table>{yaml_str}</table>\"\n    return yaml_str\n\n", "CodeBleu_score": 64.93851077084727}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t", "CodeBleu_score": 11.79006085192698}, {"code": "def convert_df_to_yml(self, df: pd.DataFrame, extras: dict) -> str:\n\t\n    df_json = self.convert_df_to_json(df, extras)\n    df_yml = yaml.dump(df_json)\n\n    if \"is_direct_sql\" in extras and extras[\"is_direct_sql\"]:\n        df_yml = f\"<table>{df_yml}</table>\"\n\n    return df_yml", "CodeBleu_score": 62.721821425580785}]}
{"instance_id": "e2b90ebd4e5d", "generation_result": [{"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"\":\n        return True\n    elif expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    elif expected_type == \"string\":\n        return isinstance(self.value, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    elif expected_type == \"plot\":\n        return isinstance(self.value, str) or isinstance(self.value, dict)\n    else:\n        return False\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 55.95523499959072}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if not expected_type:\n        return True\n    if expected_type == \"number\":\n        return isinstance(self.value, (int, float))\n    if expected_type == \"string\":\n        return isinstance(self.value, str)\n    if expected_type == \"dataframe\":\n        return isinstance(self.value, (pd.DataFrame, pd.Series))\n    if expected_type == \"plot\":\n        return isinstance(self.value, str) or isinstance(self.value, dict)\n    return False\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 53.68392814911154}, {"code": "def validate_value(self, expected_type: str) -> bool\n\t\n    if expected_type == \"number\":\n        return isinstance(self.value, int) or isinstance(self.value, float)\n    elif expected_type == \"string\":\n        return isinstance(self.value, str)\n    elif expected_type == \"dataframe\":\n        return isinstance(self.value, pd.DataFrame) or isinstance(self.value, pd.Series)\n    elif expected_type == \"plot\":\n        return isinstance(self.value, str) and re.match(r\"^\\w+\\.png$\", self.value) or isinstance(self.value, dict)\n    else:\n        return True\n\n\n\n", "CodeBleu_score": 48.862729595529444}]}
{"instance_id": "d95828fdcbcb", "generation_result": [{"code": " def _distance(self, X, X2=None)\n\t\n    if self.distance_params is None:\n        self.distance_params = {}\n    if isinstance(self.distance, str):\n        return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n    else:\n        if X2 is None:\n            if len(signature(self.distance).parameters) == 1:\n                return self.distance(X)\n            else:\n                return self.distance(X, X)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 26.558818797057306}, {"code": " def _distance(self, X, X2=None)\n\t\n    if X2 is None:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, **self.distance_params)\n    else:\n        if isinstance(self.distance, str):\n            return pairwise_distance(X, X2, metric=self.distance, **self.distance_params)\n        else:\n            return self.distance(X, X2, **self.distance_params)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 20.165725207265577}, {"code": " def _distance(self, X, X2=None)\n\t\n    if self.distance_params is None:\n        self.distance_params = {}\n    if isinstance(self.distance, str):\n        dist = pairwise_distance(self.distance, X, X2, **self.distance_params)\n    else:\n        if X2 is None:\n            signature = inspect.signature(self.distance)\n            if len(signature.parameters) == 1:\n                dist = self.distance(X, **self.distance_params)\n            else:\n                dist = self.distance(X, X, **self.distance_params)\n        else:\n            dist = self.distance(X, X2, **self.distance_params)\n    return dist\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.45948628338242}]}
{"instance_id": "497d73b298ee", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if not isinstance(X, pd.DataFrame):\n        raise ValueError(\n            \"Input data must be a pandas DataFrame. Found type: \" + str(type(X))\n        )\n\n    if self.equal_length:\n        if isinstance(X, pd.DataFrame):\n            X = X.to_numpy()\n        elif isinstance(X, np.ndarray):\n            X = X\n        else:\n            raise ValueError(\n                \"Input data must be a pandas DataFrame or numpy array. Found type: \"\n                + str(type(X))\n            )\n    else:\n        X = X.reset_index(drop=True)\n        X = X.pivot(index=\"index\", columns=\"dim_0\", values=\"value\")\n        X = X.fillna(0)\n        X = X.to_numpy()\n        lengths = X.shape[0]\n        X = np.concatenate((np.array([lengths]), X), axis=0)\n\n    return X", "CodeBleu_score": 38.18717755420741}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if isinstance(X, np.ndarray):\n        if X.ndim == 2:\n            return X\n        elif X.ndim == 1:\n            return X.reshape(-1, 1)\n        else:\n            raise ValueError(\n                \"If input data X is a numpy array, its dimension must be either 1 or 2.\"\n            )\n    elif isinstance(X, pd.DataFrame):\n        if X.shape[1] == 1:\n            return X.to_numpy().reshape(-1, 1)\n        else:\n            return X.to_numpy()\n    elif isinstance(X, pd.Series):\n        return X.to_frame().to_numpy()\n    elif isinstance(X, (list, tuple)):\n        if isinstance(X[0], (list, tuple, np.ndarray)):\n            if not all(isinstance(x, (list, tuple, np.ndarray)) for x in X):\n                raise ValueError(\n                    \"If input data X is a list of lists, tuples, or numpy arrays, all elements must be of the same type.\"\n                )\n            if not all(len(X[0]) == len(x) for x in X):\n                raise ValueError(\n                    \"If input data X is a list of lists or tuples, all elements must have the same length.\"\n                )\n            return np.array(X)\n        elif isinstance(X[0], (int, float)):\n            return np.array(X).reshape(-1, 1)\n        else:\n            raise ValueError(\n                \"If input data X is a list, its elements must be either lists, tuples, numpy arrays, or integers or floats.\"\n            )\n    else:\n        raise TypeError(\n            \"Input data X must be either a numpy array, pandas DataFrame, pandas Series, or a list of lists, tuples, or numpy arrays.\"\n        )\n\n\n", "CodeBleu_score": 17.17091127081941}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if isinstance(X, pd.DataFrame):\n        X = X.copy()\n        X.index = range(X.shape[0])\n        X = X.pivot(index=None, columns=X.columns[0], values=X.columns[1])\n        X = X.fillna(0)\n        X = X.to_numpy()\n        lengths = [X.shape[1]] * X.shape[0]\n        X = np.concatenate([np.array(lengths)[:, None], X], axis=1)\n    else:\n        if not isinstance(X, np.ndarray):\n            X = np.array(X)\n        if X.ndim == 2:\n            lengths = [X.shape[1]] * X.shape[0]\n            X = np.concatenate([np.array(lengths)[:, None], X], axis=1)\n        else:\n            X = X.flatten()\n    return X\n\n\n\n", "CodeBleu_score": 39.50633220471188}]}
{"instance_id": "8798260a6f12", "generation_result": [{"code": "def is_sklearn_estimator(obj)\n\t\n    if not isinstance(obj, type):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n", "CodeBleu_score": 22.216868586077418}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isinstance(obj, type):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)\n\n\n\n", "CodeBleu_score": 22.216868586077418}, {"code": "def is_sklearn_estimator(obj)\n\t\n    if not isinstance(obj, type):\n        return False\n    return issubclass(obj, SklearnBaseEstimator) and not issubclass(obj, BaseObject)", "CodeBleu_score": 22.216868586077418}]}
{"instance_id": "2ab2596d8520", "generation_result": [{"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        pipeline = TransformerPipeline(self.transformers + [other])\n        return SklearnRegressorPipeline(self.regressor, pipeline)\n    return NotImplemented\n\n\n\n\n\n\n", "CodeBleu_score": 31.955365925998574}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        other_pipeline = TransformerPipeline([other])\n        expanded_pipeline = other_pipeline * self.transformer_pipeline\n        return SklearnRegressorPipeline(self.regressor, expanded_pipeline)\n    else:\n        return NotImplemented\n\n\n\n\n", "CodeBleu_score": 38.560292867354995}, {"code": "def __rmul__(self, other)\n\t\n    if isinstance(other, BaseTransformer):\n        return TransformerPipeline(other, self)\n    return NotImplemented", "CodeBleu_score": 13.952327625158528}]}
{"instance_id": "5c1c6d14ca93", "generation_result": [{"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = list(map(str, df.columns))\n    if all(isinstance(col, str) for col in df.columns):\n        return df\n    else:\n        df.columns = list(map(str, df.columns))\n        return df", "CodeBleu_score": 49.58575891443899}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = list(map(str, df.columns))\n    if all(isinstance(col, str) for col in df.columns):\n        return df\n    else:\n        df.columns = list(map(str, df.columns))\n        return df\n\n", "CodeBleu_score": 49.58575891443899}, {"code": "def prep_skl_df(df, copy_df=False)\n\t\n    if copy_df:\n        df = df.copy()\n    df.columns = list(df.columns)\n    cols = df.columns\n    for col in cols:\n        if type(col) != str:\n            try:\n                df[str(col)] = df[col]\n            except Exception:\n                print(f'Could not convert {col} to string.')\n            df = df.drop(columns=[col])\n    return df\n\n", "CodeBleu_score": 46.58004990707848}]}
{"instance_id": "d5e567c20361", "generation_result": [{"code": "def predict(self, X)\n\t\n    rng = check_random_state(self.random_state)\n    probas = self.predict_proba(X)\n    n_samples, n_classes = probas.shape\n    max_idx = np.argmax(probas, axis=1)\n    rand_idx = rng.randint(0, n_classes, size=n_samples)\n    rand_idx = np.where(probas[np.arange(n_samples), max_idx] > self.threshold, max_idx, rand_idx)\n    return self.classes_[rand_idx]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.185250872889846}, {"code": "def predict(self, X)\n\t\n    rng = check_random_state(self.random_state)\n    probas = self.predict_proba(X)\n    n_samples = X.shape[0]\n    n_classes = self.n_classes_\n    y_pred = np.zeros(n_samples)\n    for i in range(n_samples):\n        max_index = np.argwhere(probas[i] == np.amax(probas[i])).flatten()\n        y_pred[i] = rng.choice(max_index)\n    return self.classes_[y_pred.astype(int)]\n\n\n", "CodeBleu_score": 41.391935266762246}, {"code": "def predict(self, X)\n\t\n    rng = check_random_state(self.random_state)\n    probas = self.predict_proba(X)\n    n_samples, n_classes = probas.shape\n    max_index = np.argmax(probas, axis=1)\n    index = rng.choice(np.arange(n_classes), size=n_samples, replace=True, p=probas)\n    return np.array([self.classes_[i] for i in index])\n\n\n", "CodeBleu_score": 32.1425184677857}]}
{"instance_id": "210b60dffd55", "generation_result": [{"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_transformed = []\n    for i, group in enumerate(groups):\n        X_transformed.append(pcas[i].transform(X[:, group]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n    X_transformed = np.nan_to_num(X_transformed)\n    y_proba = clf.predict_proba(X_transformed)\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba = self._adjust_proba(y_proba)\n    return y_proba\n\n", "CodeBleu_score": 34.79046260139146}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    # transform the data\n    X_transformed = []\n    for group in groups:\n        X_transformed.append(pcas[group].transform(X[:, group]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n\n    # replace missing values with 0\n    X_transformed[np.isnan(X_transformed)] = 0\n\n    # compute class probabilities\n    y_proba = clf.predict_proba(X_transformed)\n\n    # adjust probabilities to match expected class structure\n    if y_proba.shape[1] != self.n_classes_:\n        y_proba = np.concatenate(\n            (y_proba, np.zeros((y_proba.shape[0], 1))), axis=1\n        )\n\n    return y_proba\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 35.50716762263084}, {"code": "def _predict_proba_for_estimator(self, X, clf, pcas, groups)\n\t\n    X_transformed = []\n    for i in range(len(groups)):\n        X_transformed.append(pcas[i].transform(X[:, groups[i]]))\n    X_transformed = np.concatenate(X_transformed, axis=1)\n    X_transformed = np.nan_to_num(X_transformed)\n    y_probas = clf.predict_proba(X_transformed)\n    if y_probas.shape[1] != self.n_classes_:\n        y_probas = self._adjust_probas(y_probas)\n    return y_probas\n\n\n", "CodeBleu_score": 30.838862187486765}]}
{"instance_id": "9436ee0860bb", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # treat case of single class seen in fit\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n    return dists\n\n", "CodeBleu_score": 88.56183340968327}, {"code": "def predict_proba(self, X)\n\t", "CodeBleu_score": 0.7380952380952381}, {"code": "def predict_proba(self, X)\n\t\n\n    # Check if the model is fitted\n    if not self._is_fitted:\n        raise NotFittedError(\n            f\"This instance of {self.__class__.__name__} has not \"\n            f\"been fitted yet; please call `fit` first.\"\n        )\n\n    # Handle the case of a single class\n    if self.n_classes_ == 1:\n        return np.repeat([[1]], X.shape[0], axis=0)\n\n    # Reshape the input if it is a 3D numpy array with a single feature\n    if isinstance(X, np.ndarray) and len(X.shape) == 3 and X.shape[1] == 1:\n        X = np.reshape(X, (X.shape[0], -1))\n    # Raise an error for invalid input types or shapes\n    elif not isinstance(X, np.ndarray) or len(X.shape) > 2:\n        raise ValueError(\n            \"ContinuousIntervalTree is not a time series classifier. \"\n            \"A valid sklearn input such as a 2d numpy array is required.\"\n            \"Sparse input formats are currently not supported.\"\n        )\n\n    # Validate the input data, allowing NaN values\n    X = self._validate_data(X=X, reset=False, force_all_finite=\"allow-nan\")\n\n    # Calculate the probability distributions\n    dists = np.zeros((X.shape[0], self.n_classes_))\n    for i in range(X.shape[0]):\n        dists[i] = self._root.predict_proba(X[i], self.n_classes_)\n\n    return dists", "CodeBleu_score": 88.56183340968327}]}
{"instance_id": "d7cb1cb66840", "generation_result": [{"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    if self.transformers_.scitype == \"Primitives\":\n        return convert(X, from_type=\"nested_univ\", to_type=\"numpy2D\")\n    elif self.transformers_.scitype == \"Series\":\n        return convert(X, from_type=\"nested_univ\", to_type=\"numpyflat\")\n    else:\n        raise TypeError(\n            f\"unexpected output type {self.transformers_.scitype} from transformers\"\n        )\n\n", "CodeBleu_score": 28.521272823946315}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ == \"Primitives\":\n        Xt = convert(X, from_type=\"nested_univ\", to_type=\"numpyflat\")\n        return convert(Xt, from_type=\"numpyflat\", to_type=\"numpy3D\")\n    elif self.transformers_ == \"Series\":\n        Xt = convert(X, from_type=\"nested_univ\", to_type=\"numpyflat\")\n        return convert(Xt, from_type=\"numpyflat\", to_type=\"numpy2D\")\n    else:\n        raise TypeError(\n            \"unexpected output type from transformers, should be Series or Panel\"\n        )\n\n", "CodeBleu_score": 44.13580782945872}, {"code": "def _convert_X_to_sklearn(self, X)\n\t\n    if self.transformers_ is None:\n        return X\n    else:\n        Xt = self.transformers_.fit_transform(X)\n        scitype = scitype_to_inst(Xt)\n        if scitype == \"Primitives\":\n            Xt = convert(Xt, \"numpyflat\", \"numpy3D\")\n            return Xt\n        elif scitype == \"Series\":\n            Xt = convert(Xt, \"numpyflat\", \"numpy2D\")\n            return Xt\n        else:\n            raise TypeError(\"Unexpected output type\")\n\n\n\n", "CodeBleu_score": 42.0114171721313}]}
{"instance_id": "497cb75f2b4d", "generation_result": [{"code": "def set_random_state(estimator, random_state=0)\n\t\n    from sklearn.utils import check_random_state\n    random_state = check_random_state(random_state)\n    params = {}\n    for key in estimator.get_params(deep=True):\n        if \"random_state\" in key:\n            params[key] = random_state.randint(0, 2**32 - 1)\n    if params:\n        estimator.set_params(**params)\n    return estimator\n\n\n\n", "CodeBleu_score": 48.97270077387696}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    if random_state is None:\n        return estimator\n    if isinstance(random_state, int):\n        random_state = np.random.RandomState(random_state)\n    params = {}\n    for param in estimator.get_params(deep=False):\n        if param.endswith('random_state'):\n            params[param] = random_state.randint(0, 2**32 - 1)\n    if len(params) > 0:\n        estimator.set_params(**params)\n    return estimator\n\n\n\n", "CodeBleu_score": 37.46980585258119}, {"code": "def set_random_state(estimator, random_state=0)\n\t\n    random_state = check_random_state(random_state)\n    new_params = {}\n    for param in estimator.get_params(deep=False):\n        if param.endswith(\"random_state\") or param.endswith(\"seed\"):\n            new_params[param] = random_state.randint(0, 2**32 - 1)\n    if new_params:\n        estimator.set_params(**new_params)\n\n", "CodeBleu_score": 35.58263622718201}]}
{"instance_id": "59ffd1d596a1", "generation_result": [{"code": "def _transform(X, intervals)\n\t\n    # Get the number of instances and intervals\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n\n    # Initialize an empty array to store the transformed features\n    transformed = np.zeros((n_instances, n_intervals * 3))\n\n    # Loop through each interval and compute the features\n    for i, interval in enumerate(intervals):\n        # Slice the input matrix\n        X_slice = X[:, interval[0] : interval[1]]\n\n        # Compute the mean, standard deviation, and slope of the slice\n        mean = np.mean(X_slice, axis=1)\n        std = np.std(X_slice, axis=1)\n        slope = _slope(X_slice, axis=1)\n\n        # Store the features in the transformed array\n        transformed[:, i * 3] = mean\n        transformed[:, i * 3 + 1] = std\n        transformed[:, i * 3 + 2] = slope\n\n    # Return the transposed transformed array\n    return transformed.T\n\n", "CodeBleu_score": 41.00392284944172}, {"code": "def _transform(X, intervals)\n\t\n    # Get the number of instances and intervals\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n\n    # Initialize an empty array to store the transformed features\n    transformed = np.zeros(n_instances * n_intervals * 3)\n\n    # Loop through each interval\n    for i, interval in enumerate(intervals):\n        # Slice the input matrix for the current interval\n        X_slice = X[:, interval[0] : interval[1]]\n\n        # Compute the mean, standard deviation, and slope of the slice\n        mean = np.mean(X_slice, axis=1)\n        std = np.std(X_slice, axis=1)\n        slope = _slope(X_slice.T, axis=0)\n\n        # Store the computed features in the transformed array\n        transformed[n_instances * i : n_instances * (i + 1)] = mean\n        transformed[\n            n_instances * (n_intervals + i) : n_instances * (n_intervals + i + 1)\n        ] = std\n        transformed[\n            n_instances * (2 * n_intervals + i) : n_instances * (2 * n_intervals + i + 1)\n        ] = slope\n\n    # Return the transposed transformed array\n    return transformed.reshape((n_instances, n_intervals * 3)).T\n\n", "CodeBleu_score": 34.548051080916885}, {"code": "def _transform(X, intervals)\n\t\n    # Get the number of instances and intervals\n    n_instances, _ = X.shape\n    n_intervals = len(intervals)\n\n    # Initialize the transformed array\n    transformed = np.zeros((n_instances, 3 * n_intervals))\n\n    # Loop over the intervals\n    for i, interval in enumerate(intervals):\n        # Slice the input matrix\n        X_slice = X[:, interval[0] : interval[1]]\n\n        # Compute the mean, standard deviation, and slope\n        mean = np.mean(X_slice, axis=1)\n        std = np.std(X_slice, axis=1)\n        slope = _slope(X_slice, axis=1)\n\n        # Store the values in the transformed array\n        transformed[:, 3 * i] = mean\n        transformed[:, 3 * i + 1] = std\n        transformed[:, 3 * i + 2] = slope\n\n    # Return the transposed transformed array\n    return transformed.T\n\n", "CodeBleu_score": 44.00253241608242}]}
{"instance_id": "5a01594eebfb", "generation_result": [{"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    # Initialize annotation and operation parameters if they are not provided\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    self.new_plot(ax_op_before, *args, **kwargs).configure(**configuration).plot(\n        plot, **plot_params)\n\n    # Configure and annotate the plot based on provided configuration and annotation functions\n    self.configure(**configuration).annotate(**annotate_params)\n\n    # Apply post-plot axis operations\n    _apply_ax_operations(self.ax, ax_op_after)\n\n    # Return the output of the plotting process\n    return self.ax, self.annotations\n\n", "CodeBleu_score": 47.24925157486519}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    if annotate_params is None:\n        annotate_params = {}\n    if annotation_params is None:\n        annotation_params = {}\n    _apply_ax_operations(self.ax, ax_op_before)\n    self.new_plot(self.ax, plot=plot, plot_params=plot_params, *args, **kwargs)\n    self.configure(**configuration)\n    getattr(self, annotation_func)(**annotation_params)\n    _apply_ax_operations(self.ax, ax_op_after)\n    return self.ax, self.annotations\n\n", "CodeBleu_score": 54.729062918556146}, {"code": "def plot_and_annotate_facets(\n            self, plot: str, plot_params: dict, configuration: dict,\n            annotation_func: str, *args, annotation_params: dict = None,\n            ax_op_before: List[Union[str, Optional[list],\n                                     Optional[dict]]] = None,\n            ax_op_after: List[Union[str, Optional[list],\n                                    Optional[dict]]] = None,\n            annotate_params: dict = None, **kwargs)\n\t\n    # Initialize annotation and operation parameters if they are not provided\n    if annotation_params is None:\n        annotation_params = {}\n    if annotate_params is None:\n        annotate_params = {}\n    if ax_op_before is None:\n        ax_op_before = []\n    if ax_op_after is None:\n        ax_op_after = []\n\n    # Create the plot with given parameters and apply pre-plot axis operations\n    ax = self.new_plot(\n        *args, plot=plot, plot_params=plot_params, **kwargs).ax\n    _apply_ax_operations(ax, ax_op_before)\n\n    # Configure the plot and annotate it based on provided configuration and annotation functions\n    self.configure(**configuration).annotate(**annotate_params)\n    if annotation_func is not None:\n        getattr(self, annotation_func)(**annotation_params)\n\n    # Apply post-plot axis operations\n    _apply_ax_operations(ax, ax_op_after)\n\n    # Return the output of the plotting process\n    return self.get_output()\n\n", "CodeBleu_score": 58.21781208253305}]}
{"instance_id": "b5b17d312c74", "generation_result": [{"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, '_program'):\n        raise ValueError('The model has not been fitted yet.')\n    X = check_array(X)\n    if X.shape[1] != self.n_features_in_:\n        raise ValueError(f'The input data has {X.shape[1]} features, but the model was trained on data with {self.n_features_in_} features.')\n    scores = self._program.execute(X)\n    probabilities = np.exp(scores) / np.sum(np.exp(scores), axis=1, keepdims=True)\n    return probabilities\n\n\n", "CodeBleu_score": 44.69425045898593}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise ValueError(\"Model not fitted\")\n    X = check_array(X, accept_sparse=\"csr\")\n    if X.shape[1] != self.n_features_in_:\n        raise ValueError(\n            f\"X has {X.shape[1]} features per sample; expecting {self.n_features_in_}\"\n        )\n    scores = self._program(X)\n    scores = np.exp(scores)\n    scores /= scores.sum(axis=1, keepdims=True)\n    return np.column_stack((1 - scores, scores))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 41.356654218501795}, {"code": "def predict_proba(self, X)\n\t\n    if not hasattr(self, \"_program\"):\n        raise ValueError(\"The model has not been fitted yet.\")\n    X = check_array(X)\n    if X.shape[1] != self.n_features_in_:\n        raise ValueError(\n            f\"Expected {self.n_features_in_} features, got {X.shape[1]}.\"\n        )\n    scores = self._program(X)\n    scores = scores.reshape(-1, 1)\n    scores = np.hstack([-scores, scores])\n    scores = softmax(scores, axis=1)\n    return scores", "CodeBleu_score": 42.885904834985446}]}
{"instance_id": "83f71c959df7", "generation_result": [{"code": "def point_mutation(self, random_state)\n\t\n    mutated_program = copy.deepcopy(self)\n    nodes_to_modify = [i for i in range(len(mutated_program)) if random_state.uniform() < self.mutation_probability]\n    for node_index in nodes_to_modify:\n        if isinstance(mutated_program[node_index], Function):\n            valid_replacement_functions = [f for f in self.function_set if f.arity == mutated_program[node_index].arity]\n            mutated_program[node_index] = random_state.choice(valid_replacement_functions)\n        else:\n            if random_state.uniform() < 0.5:\n                mutated_program[node_index] = random_state.uniform(self.constant_range[0], self.constant_range[1])\n            else:\n                mutated_program[node_index] = random_state.randint(0, self.num_features - 1)\n    return mutated_program, nodes_to_modify\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.12093231703427}, {"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    mutated_program = self.copy()\n\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    nodes_to_modify = [\n        i for i, node in enumerate(mutated_program) if random_state.uniform() < self.point_mutation_prob\n    ]\n\n    # For each node to be modified, perform the mutation\n    for node_index in nodes_to_modify:\n        node = mutated_program[node_index]\n\n        # If the node is a function, find a valid replacement function with the same arity\n        if node.arity > 0:\n            valid_replacement_functions = [\n                f for f in self.functions if f.arity == node.arity and f.name != node.name\n            ]\n            replacement_function = random_state.choice(valid_replacement_functions)\n            mutated_program[node_index] = replacement_function\n\n        # If the node is a terminal, replace it with either a constant or a variable\n        else:\n            if random_state.uniform() < 0.5:\n                replacement_value = random_state.uniform(self.constant_range[0], self.constant_range[1])\n                mutated_program[node_index] = replacement_value\n            else:\n                replacement_value = random_state.randint(0, self.num_features - 1)\n                mutated_program[node_index] = replacement_value\n\n    # Return the mutated program and the list of modified node indices\n    return mutated_program, nodes_to_modify\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 27.539513249862864}, {"code": "def point_mutation(self, random_state)\n\t\n    # Create a copy of the program\n    mutated_program = self.copy()\n\n    # Identify nodes to modify based on a uniform random distribution and a probability threshold\n    nodes_to_modify = [\n        node for node in mutated_program.nodes if random_state.uniform() < self.mutation_probability\n    ]\n\n    # For each node to be mutated\n    for node in nodes_to_modify:\n        # If it is a function\n        if node.arity > 0:\n            # Find a valid replacement function with the same arity\n            replacement_function = random_state.choice(\n                [f for f in self.function_set if f.arity == node.arity]\n            )\n            # Update the node\n            node.update_function(replacement_function)\n        # If the node is a terminal\n        else:\n            # Replace it with either a constant or a variable, ensuring valid replacement according to the defined constant range and number of features\n            if random_state.uniform() < 0.5:\n                replacement_terminal = random_state.uniform(\n                    self.constant_range[0], self.constant_range[1]\n                )\n            else:\n                replacement_terminal = random_state.randint(0, self.num_features)\n            node.update_terminal(replacement_terminal)\n\n    # Return the mutated program and the list of modified node indices\n    return mutated_program, nodes_to_modify\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 23.25206108248966}]}
{"instance_id": "f1853251e671", "generation_result": [{"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    offset = int(offset) if offset and offset != 0 else 0\n\n    # Validate Arguments\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    offset = int(offset) if offset and offset != 0 else 0\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n\n    # Calculate Result\n    if mamode == \"sma\":\n        ma = close.rolling(length).mean()\n    else:\n        ma = close.rolling(length).mean()\n\n    result = (close / ma) - 1\n    result.name = f\"BIAS_{length}_{mamode}\"\n    result.category = \"momentum\"\n\n    # Offset\n    if offset != 0:\n        result = result.shift(offset)\n\n    # Handle fills\n    if \"fillna\" in kwargs:\n        result.fillna(kwargs[\"fillna\"], inplace=True)\n    if \"fill_method\" in kwargs:\n        result.fillna(method=kwargs[\"fill_method\"], inplace=True)\n\n    # Name and Categorize it\n    result.name = f\"BIAS_{length}_{mamode}\"\n    result.category = \"momentum\"\n\n    return result\n\n", "CodeBleu_score": 49.72819318049939}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n    return pd.Series(\n        tulipy.bias(\n            close.values,\n            length=length,\n            mamode=mamode,\n            offset=offset,\n        ),\n        name=\"BIAS\",\n        index=close.index,\n    )\n\n", "CodeBleu_score": 6.332972456992993}, {"code": "def bias(close, length=None, mamode=None, offset=None, **kwargs)\n\t\n\n    # Validate Arguments\n    close = verify_series(close)\n    length = int(length) if length and length > 0 else 26\n    mamode = mamode.lower() if mamode and isinstance(mamode, str) else \"sma\"\n    offset = int(offset) if offset and offset != 0 else 0\n\n    # Calculate Result\n    if close is not None:\n        if mamode == \"sma\":\n            ma = close.rolling(length).mean()\n        elif mamode == \"ema\":\n            ma = close.ewm(span=length, adjust=False).mean()\n        elif mamode == \"wma\":\n            weights = np.arange(1, length + 1)\n            ma = close.rolling(length).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True)\n        elif mamode == \"hma\":\n            weights = np.arange(1, length + 1)\n            ma = close.rolling(length).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True)\n        elif mamode == \"zlsma\":\n            ma = close.rolling(length).apply(lambda x: np.dot(x, np.arange(1, length + 1)) / np.arange(1, length + 1).sum(), raw=True)\n        else:\n            raise ValueError(\"Invalid mamode argument. Choose from 'sma', 'ema', 'wma', 'hma', or 'zlsma'.\")\n\n        bias = (close / ma) - 1\n        bias.name = f\"BIAS_{length}_{mamode}\"\n        bias.category = \"momentum\"\n\n    return bias\n\n", "CodeBleu_score": 41.532772273790066}]}
{"instance_id": "77825be37c24", "generation_result": [{"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        if broker == 'hb':\n            url = 'https://api.huobi.pro/market/history/kline?period=' + ktype + '&size=' + size + '&symbol=' + code + 'usdt'\n            js = http_get_request(url)\n            data = js['data']\n            columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n            df = pd.DataFrame(data, columns=columns)\n            df['date'] = df['date'].map(lambda x: int2time(x))\n            df['date'] = pd.to_datetime(df['date'])\n            return df\n        elif broker == 'okx':\n            url = 'https://www.okx.com/api/v5/market/history-candles?instId=' + code + '-USDT&bar=' + ktype + '&limit=' + size\n            js = http_get_request(url)\n            data = js['data']\n            columns = ['date', 'open', 'high', 'low', 'close', 'volume']\n            df = pd.DataFrame(data, columns=columns)\n            df['date'] = df['date'].map(lambda x: int2time(x))\n            df['date'] = pd.to_datetime(df['date'])\n            return df\n        elif broker == 'binance':\n            url = 'https://api.binance.com/api/v3/klines?symbol=' + code + 'USDT&interval=' + ktype + '&limit=' + size\n            js = http_get_request(url)\n            data = js\n            columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'close_time', 'quote_asset_volume', 'number_of_trades', 'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore']\n            df = pd.DataFrame(data, columns=columns)\n            df['date'] = df['date'].map(lambda x: int2time(x))\n           ", "CodeBleu_score": 33.09039277662923}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        if broker == 'hb':\n            url = 'https://api.huobi.pro/market/history/kline?period=' + ktype + '&size=' + size + '&symbol=' + code.upper() + 'usdt'\n        elif broker == 'okx':\n            url = 'https://www.okx.com/api/v5/market/history-candles?instId=' + code.upper() + '-USDT&bar=' + ktype + '&limit=' + size\n        elif broker == 'binance':\n            url = 'https://api.binance.com/api/v3/klines?symbol=' + code.upper() + 'USDT&interval=' + ktype + '&limit=' + size\n        elif broker == 'bitmex':\n            url = 'https://www.bitmex.com/api/v1/trade/bucketed?binSize=' + ktype + '&partial=false&symbol=XBTUSD&count=' + size + '&reverse=false'\n        elif broker == 'kraken':\n            url = 'https://api.kraken.com/0/public/OHLC?pair=XBTUSD&interval=' + str(int(ktype) * 60) + '&since=' + str(int(time.time()) - int(ktype) * 60 * int(size))\n        elif broker == 'bitfinex':\n            url = 'https://api-pub.bitfinex.com/v2/candles/trade:' + ktype + ':t' + code.upper() + 'USD/hist?limit=' + size\n        elif broker == 'bitflyer':\n            url = 'https://api.bitflyer.com/v1/getcharts?product_code=BTC_USD&candle_type=' + ktype + '&count=' + size\n        elif broker == 'bitstamp':\n            url = 'https://www.bitstamp.net/api/v2/ohlc/btcusd/?limit=' + size + '&", "CodeBleu_score": 24.442927027851336}, {"code": "def coins_bar(broker='hb', code='btc', ktype='D', size='2000')\n\t\n    try:\n        if broker == 'hb':\n            url = 'https://api.huobi.pro/market/history/kline?period={}&size={}&symbol={}usdt'.format(ktype, size, code)\n            js = json.loads(requests.get(url).text)\n            df = pd.DataFrame(js['data'])\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'amount', 'count', 'BCH', 'BSV', 'BTC', 'DASH', 'ETC', 'EOS', 'ETH', 'LTC', 'XRP', 'USDT']\n            df['date'] = df['date'].apply(lambda x: int2time(x))\n            df['date'] = pd.to_datetime(df['date'])\n            return df\n        elif broker == 'binance':\n            url = 'https://api.binance.com/api/v1/klines?symbol={}USDT&interval={}&limit={}'.format(code.upper(), ktype, size)\n            js = json.loads(requests.get(url).text)\n            df = pd.DataFrame(js)\n            df.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'date2', 'volume2', 'count', 'BCH', 'BSV', 'BTC', 'DASH', 'ETC', 'EOS', 'ETH', 'LTC', 'XRP', 'USDT']\n            df['date'] = df['date'].apply(lambda x: int2time(x/1000))\n            df['date'] = pd.to_datetime(df['date'])\n            return df\n        elif broker == 'okex':\n            url = 'https://www.okex.com/api/v1/kline.do?symbol={}_usdt&type={}&size={}'.format(code, ktype, size)\n            js = json.loads(requests.get(url).text)\n            df = pd.DataFrame(js)\n            df.columns = ['date', 'open',", "CodeBleu_score": 39.812462656026796}]}
{"instance_id": "c6552851da8a", "generation_result": [{"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        js = _get_data(broker, code, size)\n        if broker == 'hb':\n            asks = js['tick']['asks']\n            bids = js['tick']['bids']\n            ts = int2time(js['ts'] / 1000)\n        elif broker == 'ok':\n            asks = js['data']['asks']\n            bids = js['data']['bids']\n            ts = js['data']['timestamp']\n        else:\n            return\n        df_ask = pd.DataFrame(asks, columns=['price', 'amount'])\n        df_bid = pd.DataFrame(bids, columns=['price', 'amount'])\n        df_ask['ts'] = ts\n        df_bid['ts'] = ts\n        return pd.Panel({'ask': df_ask, 'bid': df_bid})\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 39.84801608369574}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        js = _get_data(broker, code, size)\n        if broker == 'hb':\n            asks = [item['asks'][0] for item in js['data']['tick']['asks']]\n            asks = pd.DataFrame(asks, columns=['price', 'volume'])\n            bids = [item['bids'][0] for item in js['data']['tick']['bids']]\n            bids = pd.DataFrame(bids, columns=['price', 'volume'])\n            ts = pd.to_datetime(js['data']['ts'], unit='ms')\n        else:\n            asks = [item['data'][0]['asks'][0] for item in js['data']]\n            asks = pd.DataFrame(asks, columns=['price', 'volume'])\n            bids = [item['data'][0]['bids'][0] for item in js['data']]\n            bids = pd.DataFrame(bids, columns=['price', 'volume'])\n            ts = pd.to_datetime(js['ts'], unit='ms')\n        asks['ts'] = ts\n        bids['ts'] = ts\n        return pd.Panel({'asks': asks, 'bids': bids})\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 42.094095243627635}, {"code": "def coins_snapshot(broker='hb', code='btc', size='5')\n\t\n    try:\n        js = _get_data(broker, code, size)\n        if broker == 'hb':\n            asks = [item['ask'] for item in js['data']['asks']]\n            bids = [item['bid'] for item in js['data']['bids']]\n            timestamp = int2time(js['data']['timestamp'])\n        else:\n            asks = [item['data'][0] for item in js['data']['asks']]\n            bids = [item['data'][0] for item in js['data']['bids']]\n            timestamp = int2time(js['data']['timestamp'])\n        df_ask = pd.DataFrame(asks, columns=['price', 'quantity'])\n        df_bid = pd.DataFrame(bids, columns=['price', 'quantity'])\n        df_ask['timestamp'] = timestamp\n        df_bid['timestamp'] = timestamp\n        data = {'ask': df_ask, 'bid': df_bid}\n        df = pd.Panel(data)\n        return df\n    except Exception:\n        print(traceback.print_exc())\n\n", "CodeBleu_score": 45.207871263775864}]}
{"instance_id": "8b5fee723398", "generation_result": [{"code": "def coins_trade(broker='hb', code='btc')\n\t\n    data = get_data(broker, code)\n    if data is not None:\n        if broker == 'hb':\n            data = data[['id', 'ts', 'data']]\n            data.columns = ['tid', 'datetime', 'amount']\n            data['datetime'] = data['datetime'].apply(int2time)\n            data['price'] = data['amount']\n            data['type'] = 'sell'\n        elif broker == 'ok' or broker == 'chbtc':\n            data = data[['tid', 'date', 'price', 'amount']]\n            data.columns = ['tid', 'datetime', 'price', 'amount']\n            data['datetime'] = data['datetime'].apply(int2time)\n            data['type'] = 'sell'\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n    return data\n\n", "CodeBleu_score": 39.07295485349564}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    data = get_data(broker, code)\n    if data is not None:\n        if broker == 'hb':\n            data = data[['data', 'ts', 'amount', 'type']]\n            data.columns = ['tid', 'datetime', 'amount', 'type']\n            data['datetime'] = data['datetime'].apply(int2time)\n        elif broker in ['ok', 'chbtc']:\n            data = data[['tid', 'date', 'price', 'amount', 'type']]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = data['datetime'].apply(int2time)\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n        return data\n\n", "CodeBleu_score": 38.56441991933328}, {"code": "def coins_trade(broker='hb', code='btc')\n\t\n    data = get_data(broker=broker, code=code)\n    if data is not None:\n        if broker == 'hb':\n            data = data[['id', 'ts', 'price', 'amount', 'direction']]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = data['datetime'].apply(int2time)\n        elif broker in ['ok', 'chbtc']:\n            data = data[['tid', 'date', 'price', 'amount', 'type']]\n            data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n            data['datetime'] = data['datetime'].apply(int2time)\n        data.columns = ['tid', 'datetime', 'price', 'amount', 'type']\n    return data\n\n", "CodeBleu_score": 40.58622726091713}]}
{"instance_id": "25e0a134c45b", "generation_result": [{"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    import requests\n    import json\n    import pandas as pd\n\n    try:\n        response = requests.get(url)\n        response.encoding = 'utf-8'\n        data = response.text.split('=')[-1]\n        data = json.loads(data)\n\n        if fund_type == 'open':\n            fund_df = pd.DataFrame(data['Data']['LSJZList'])\n            fund_df.columns = ['fund_date', 'value']\n            fund_df['value'] = fund_df['value'].str.replace(',', '')\n            fund_df['value'] = fund_df['value'].astype(float)\n            fund_df['value'] = fund_df['value'] / 100 + 1\n            fund_df = fund_df.set_index('fund_date')\n            fund_df = fund_df.reindex(index=pd.date_range(fund_df.index.min(), fund_df.index.max()))\n            fund_df = fund_df.fillna(method='ffill')\n            fund_df = fund_df.reset_index()\n            fund_df.columns = ['date', 'value']\n            fund_df['date'] = pd.to_datetime(fund_df['date'])\n            fund_df = fund_df.set_index('date')\n            fund_df = fund_df.reset_index()\n            fund_df.columns = ['date', 'value']\n            fund_df['value'] = fund_df['value'].astype(float)\n            fund_df['value'] = fund_df['value'].fillna(0)\n            return fund_df\n\n        elif fund_type == 'close':\n            fund_df = pd.DataFrame(data['Data']['LSJZList'])\n            fund_df.columns = ['fund_date', 'value']\n            fund_df['value'] = fund_df['value'].str.replace(',', '')\n            fund_df['value'] = fund_df['value'].astype(float)\n            fund_df['value'] = fund_df['value'] / 100 + 1\n            fund_", "CodeBleu_score": 37.272686661456746}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    print(f'Requesting {url}')\n    try:\n        response = requests.get(url)\n        response.encoding = 'utf-8'\n        text = response.text\n        text = text.replace('jsonpgz(', '')\n        text = text.replace(');', '')\n        text = text.replace('datatable', 'data')\n        text = text.replace('pages', 'page')\n        text = text.replace('records', 'record')\n        text = text.replace('curpage', 'page')\n        text = text.replace('total', 'record')\n        text = text.replace('null', '\"null\"')\n        text = text.replace('false', '\"false\"')\n        text = text.replace('true', '\"true\"')\n        text = text.replace('columns', 'column')\n        text = text.replace('rows', 'row')\n        text = text.replace('meta', 'column')\n        text = text.replace('cells', 'cell')\n        text = text.replace('data', 'datas')\n        text = text.replace('column', 'columns')\n        text = text.replace('row', 'rows')\n        text = text.replace('cell', 'cells')\n        text = text.replace('datas', 'data')\n        text = text.replace('columns', 'column')\n        text = text.replace('rows', 'row')\n        text = text.replace('cells', 'cell')\n        text = text.replace('data', 'datas')\n        text = text.replace('column', 'columns')\n        text = text.replace('row', 'rows')\n        text = text.replace('cell', 'cells')\n        text = text.replace('data', 'datas')\n        text = text.replace('column', 'columns')\n        text = text.replace('row', 'rows')\n        text = text.replace('cell', 'cells')\n        text = text.replace('data', 'datas')\n        text = text.replace('column', 'columns')\n        text = text.replace('row', 'rows')\n        text = text.replace('cell', 'cells')\n        text = text.replace('", "CodeBleu_score": 25.704424898243428}, {"code": "def _parse_fund_data(url, fund_type='open')\n\t\n    import requests\n    import json\n    import pandas as pd\n\n    headers = {\n        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n    response = requests.get(url, headers=headers)\n    response.encoding = 'utf-8'\n    text = response.text\n    if fund_type == 'open':\n        text = text.split('jsonpgz(')[1].split(');')[0]\n    elif fund_type == 'close':\n        text = text.split('jsonpgz(')[1].split(');')[0]\n    text = text.replace('datas', 'data')\n    text = text.replace('diff', 'data')\n    text = text.replace('", "CodeBleu_score": 26.321359418216517}]}
{"instance_id": "401d18e122d8", "generation_result": [{"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        func = get_cffex_daily\n    elif market == 'CZCE':\n        func = get_czce_daily\n    elif market == 'SHFE':\n        func = get_shfe_daily\n    elif market == 'DCE':\n        func = get_dce_daily\n    elif market == 'INE':\n        func = get_ine_daily\n    else:\n        raise ValueError('Invalid market')\n    start = pd.to_datetime(start) if start else pd.to_datetime('today')\n    end = pd.to_datetime(end) if end else pd.to_datetime('today')\n    df_list = []\n    for date in pd.date_range(start, end):\n        date_str = date.strftime('%Y%m%d')\n        data = func(date_str)\n        if not data.empty:\n            df_list.append(data)\n    if df_list:\n        return pd.concat(df_list)\n    else:\n        return pd.DataFrame()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 45.95205903479437}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    import datetime\n    import pandas as pd\n    import numpy as np\n    import warnings\n    warnings.filterwarnings('ignore')\n    # Determine the appropriate function to call based on the market parameter\n    if market == 'CFFEX':\n        func = get_cffex_daily\n    elif market == 'CZCE':\n        func = get_czce_daily\n    elif market == 'DCE':\n        func = get_dce_daily\n    elif market == 'INE':\n        func = get_ine_daily\n    elif market == 'SHFE':\n        func = get_shfe_daily\n    else:\n        raise ValueError(\"Invalid market parameter\")\n    # Convert the start and end dates to the correct format\n    if start is None:\n        start = datetime.datetime.now().strftime('%Y-%m-%d')\n    if end is None:\n        end = datetime.datetime.now().strftime('%Y-%m-%d')\n    start = pd.to_datetime(start).strftime('%Y-%m-%d')\n    end = pd.to_datetime(end).strftime('%Y-%m-%d')\n    # Initialize an empty list to hold data frames\n    df_list = []\n    # Iterate over each date in the range\n    for date in pd.date_range(start, end):\n        # Retrieve daily data using the appropriate function\n        df = func(date.strftime('%Y-%m-%d'))\n        # Append the data frame to the list if data is found\n        if df is not None:\n            df_list.append(df)\n    # Concatenate and return the list of data frames if any data was collected\n    if df_list:\n        return pd.concat(df_list)\n    else:\n        return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 49.46297393102922}, {"code": "def get_future_daily(start = None, end = None, market = 'CFFEX')\n\t\n    if market == 'CFFEX':\n        func = get_cffex_daily\n    elif market == 'CZCE':\n        func = get_czce_daily\n    elif market == 'DCE':\n        func = get_dce_daily\n    elif market == 'INE':\n        func = get_ine_daily\n    elif market == 'SHFE':\n        func = get_shfe_daily\n    else:\n        raise ValueError(\"Invalid market specified. Supported markets are 'CFFEX', 'CZCE', 'DCE', 'INE', and 'SHFE'.\")\n    \n    start = pd.to_datetime(start) if start else pd.Timestamp.today()\n    end = pd.to_datetime(end) if end else pd.Timestamp.today()\n    start = start.strftime('%Y%m%d')\n    end = end.strftime('%Y%m%d')\n    \n    df_list = []\n    for date in pd.date_range(start, end, freq='D'):\n        date = date.strftime('%Y%m%d')\n        data = func(date)\n        if not data.empty:\n            df_list.append(data)\n    if df_list:\n        return pd.concat(df_list)\n    else:\n        return pd.DataFrame()\n\n\n\n", "CodeBleu_score": 46.672319010309124}]}
{"instance_id": "697779825988", "generation_result": [{"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    import requests\n    import pandas as pd\n    import time\n    url = 'https://www.endata.com.cn/API/GetData/cinemaBoxOffice/realtimeBoxOffice'\n    for i in range(retry_count):\n        try:\n            response = requests.get(url)\n            if response.status_code == 200:\n                data = response.json()\n                if data['data2']:\n                    df = pd.DataFrame(data['data2'])\n                    df.drop(columns=['MovieImg', 'mId'], inplace=True)\n                    df['timestamp'] = pd.Timestamp.now()\n                    return df\n        except Exception as e:\n            print(f\"Attempt {i+1} failed: {e}\")\n            time.sleep(pause)\n    return None\n\n", "CodeBleu_score": 36.11742482886169}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    import requests\n    import pandas as pd\n    import time\n\n    url = 'https://www.endata.com.cn/API/GetData/bdc7f975-681f-4a22-9c58-b89740076919'\n\n    for i in range(retry_count):\n        try:\n            response = requests.get(url)\n            response.raise_for_status()  # Raise an exception for HTTP errors\n            data = response.json()\n            if data:\n                df = pd.DataFrame(data['Data']['Data2'])\n                df = df.drop(['MovieImg', 'mId'], axis=1)\n                df['timestamp'] = pd.Timestamp.now()\n                return df\n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n            time.sleep(pause)\n\n    return None\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 37.44698343179451}, {"code": "def realtime_boxoffice(retry_count=3,pause=0.001)\n\t\n    for _ in range(retry_count):\n        try:\n            url = 'https://www.endata.com.cn/API/GetData/cinemaBoxOffice/getCinemaBoxOffice'\n            res = requests.get(url)\n            res.raise_for_status()\n            data = json.loads(res.text)\n            df = pd.DataFrame(data['data2'])\n            df.drop(['MovieImg','mId'],axis=1,inplace=True)\n            df['timestamp'] = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n            return df\n        except:\n            time.sleep(pause)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 32.61012431363016}]}
