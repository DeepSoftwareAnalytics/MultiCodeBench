{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait = max(2, self.loop_wait - 2) * 1000\n    return wait, self._connect(*args)\n\n", "CodeBleu_score": 48.65798850155595}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    try:\n        loop_wait = self.loop_wait\n        if loop_wait is None:\n            loop_wait = self.default_loop_wait\n        wait_time = max(2, loop_wait - 2) * 1000\n        return (wait_time, self._kazoo_client.connect(*args))\n    except Exception as e:\n        self._kazoo_client.close()\n        raise e\n\n", "CodeBleu_score": 44.12232174973215}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    try:\n        return_value = self._orig_connect(*args)\n        wait = (self.loop_wait - 2) * 1000\n    except KazooRetry:\n        wait = (self.loop_wait - 2) * 1000\n        raise\n    return wait, return_value", "CodeBleu_score": 52.18998837841789}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n\n    self.set_retry_timeout(config['retry_timeout'])\n    loop_wait = config['loop_wait']\n    if loop_wait != self._loop_wait:\n        self._loop_wait = loop_wait\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(loop_wait)\n    if self.set_ttl(config['ttl']):\n        self._client.close()\n\n\n", "CodeBleu_score": 53.443019913103186}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self.set_retry_timeout(config.get('retry_timeout', 10))\n    loop_wait = config.get('loop_wait', 10)\n    if loop_wait != self._client.loop_wait:\n        self._client.loop_wait = loop_wait\n        if isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(loop_wait)\n    if self.set_ttl(config.get('ttl', 30)):\n        self._client.close()\n\n", "CodeBleu_score": 48.62237798112058}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_loop_wait(config['loop_wait'])\n    if self.set_ttl(config['ttl']):\n        if self._loop_wait != config['loop_wait'] and isinstance(self._client.handler, PatroniSequentialThreadingHandler):\n            self._client.handler.connect_timeout = self._connect_timeout\n        self._client.close()\n\n", "CodeBleu_score": 44.07026255669978}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n\n    if self.get_node(path + self._INITIALIZED):\n        cluster.initialized = True\n\n    if self.get_node(path + self._CONFIG):\n        cluster.config = self.get_node(path + self._CONFIG)[0]\n\n    if self.get_node(path + self._TIMELINE_HISTORY):\n        cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)[0]\n\n    if self.get_node(path + self._SYNC_STATE):\n        cluster.sync_state = self.get_node(path + self._SYNC_STATE)[0]\n\n    cluster.members = self.load_members(path)\n\n    if self.get_node(path + self._LEADER):\n        cluster.leader = Leader.from_node(self.get_node(path + self._LEADER)[0])\n\n    cluster.status = self.get_status(path, cluster.leader)\n\n    if self.get_node(path + self._FAILOVER_STATE):\n        cluster.failover_state = self.get_node(path + self._FAILOVER_STATE)[0]\n\n    if self.get_node(path + self._FAILSAFE):\n        cluster.failsafe = self.get_node(path + self._FAILSAFE)[0]\n\n    return cluster\n\n", "CodeBleu_score": 21.402123971031934}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster()\n    cluster.initialize = self.get_node(path + self._INITIALIZE)\n    cluster.configuration = self.get_node(path + self._CONFIGURATION)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.synchronization = self.get_node(path + self._SYNCHRONIZATION)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n\n", "CodeBleu_score": 13.224204965382974}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    init_state = self.get_node(path + self._INIT_STATE)\n    if not init_state:\n        raise Exception('No init state')\n    init_state = InitState.from_node(init_state[0])\n\n    config = self.get_node(path + self._CONFIG)\n    if not config:\n        raise Exception('No config')\n    config = Config.from_node(config[0])\n\n    timeline_history = self.load_timeline_history(path + self._TIMELINE_HISTORY)\n    if not timeline_history:\n        raise Exception('No timeline history')\n\n    sync_state = self.get_node(path + self._SYNC_STATE)\n    if not sync_state:\n        raise Exception('No sync state')\n    sync_state = SyncState.from_node(sync_state[0])\n\n    members = self.load_members(path)\n    if not members:\n        raise Exception('No members')\n\n    leader = self.get_node(path + self._LEADER)\n    if not leader:\n        raise Exception('No leader')\n    leader = Leader.from_node(leader[0])\n\n    status = self.get_status(path, leader)\n\n    failover_state = self.get_node(path + self._FAILOVER_STATE)\n    if not failover_state:\n        raise Exception('No failover state')\n    failover_state = FailoverState.from_node(failover_state[0])\n\n    failsafe_config = self.get_node(path + self._FAILSAFE_CONFIG)\n    if not failsafe_config:\n        raise Exception('No failsafe config')\n    failsafe_config = FailsafeConfig.from_node(failsafe_config[0])\n\n    return Cluster(\n        init_state,\n        config,\n        timeline_history,\n        sync_state,\n        members,\n        leader,\n        status,\n        failover_state,\n        failsafe_config,\n    )\n\n", "CodeBleu_score": 34.813639814125416}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(\n            self.leader_path,\n            b\"\",\n            ephemeral=True,\n            acl=self.acl,\n        )\n        return True\n    except kazoo.exceptions.KazooException:\n        if self.zk.client_state == KazooState.CONNECTED:\n            for retry in range(self.retry_count):\n                try:\n                    self.zk.create(\n                        self.leader_path,\n                        b\"\",\n                        ephemeral=True,\n                        acl=self.acl,\n                    )\n                    return True\n                except kazoo.exceptions.NodeExistsError:\n                    break\n                except kazoo.exceptions.KazooException:\n                    pass\n        else:\n            raise ZooKeeperError(\"Connection to ZooKeeper is closed\")\n\n    if self.zk.client_state == KazooState.CONNECTED:\n        self.logger.info(\"Another instance has the lock\")\n    else:\n        self.logger.error(\"Connection to ZooKeeper is closed\")\n\n    return False", "CodeBleu_score": 30.235045326606613}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, ephemeral=True)\n        return True\n    except kazoo.exceptions.KazooException as e:\n        if isinstance(e, kazoo.exceptions.ConnectionClosedError):\n            raise ZooKeeperError(\n                \"ZooKeeper connection closed while attempting to acquire leader lock\"\n            ) from e\n        else:\n            if not self._retry_attempt_to_acquire_leader():\n                self.logger.error(\n                    f\"Failed to acquire leader lock after {self.max_retries} retries\"\n                )\n                return False\n            else:\n                return True\n    except kazoo.exceptions.NodeExistsError:\n        self.logger.info(\"Another instance has the leader lock\")\n    except Exception as e:\n        self.logger.error(f\"Unexpected error while attempting to acquire leader lock: {e}\")\n        raise e\n\n\n\n", "CodeBleu_score": 52.42546733438985}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, ephemeral=True)\n        return True\n    except kazoo.exceptions.ConnectionClosedError:\n        raise ZooKeeperError(\"Connection to ZooKeeper closed\")\n    except kazoo.exceptions.KazooException as e:\n        if self.retry_policy.should_retry():\n            time.sleep(self.retry_policy.next_delay_seconds())\n            return self.attempt_to_acquire_leader()\n        else:\n            raise ZooKeeperError(\"Failed to acquire leader lock\") from e\n    except kazoo.exceptions.NodeExistsError:\n        self.logger.info(\"Another instance has the leader lock\")\n        return False\n\n\n\n", "CodeBleu_score": 42.20156269700194}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id != leader.session:\n        self.logger.warning(\n            \"Client ID mismatch, deleting existing leader %s\", leader.name\n        )\n        try:\n            self.zk.delete(leader.znode)\n        except NoNodeError:\n            pass\n        except (ConnectionClosedError, RetryFailedError):\n            raise ZooKeeperError()\n    try:\n        self.zk.create(\n            self.leader_path, self.client_id.encode(\"utf-8\"), ephemeral=True\n        )\n    except (NodeExistsError, ConnectionClosedError, RetryFailedError):\n        self.logger.warning(\"Failed to create leader ZNode\")\n        return False\n    return True\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 36.47147277182709}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        if self.client_id != leader.session:\n            self.logger.warning(\n                \"Client ID mismatch: %s vs %s\",\n                self.client_id,\n                leader.session,\n            )\n            self.delete_leader_znode()\n            return False\n        return True\n    except NoNodeError:\n        return False\n    except ConnectionClosedError:\n        raise ZooKeeperError() from None\n    except RetryFailedError:\n        raise ZooKeeperError() from None\n\n    try:\n        self.create_leader_znode(self.client_name.encode(\"utf-8\"))\n    except (NoNodeError, NodeExistsError):\n        self.logger.exception(\"Failed to create leader ZNode\")\n        return False\n    return True", "CodeBleu_score": 34.50682274194726}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        if self.client_id != leader.session:\n            logger.warning(\n                \"Session ID mismatch, deleting old leader %s\",\n                leader.name,\n            )\n            self.delete(leader.name)\n            return self._update_leader(leader)\n    except NoNodeError:\n        pass\n    except ConnectionClosedError:\n        raise ZooKeeperError(\n            \"Connection closed while updating leader\"\n        )\n    except RetryFailedError:\n        raise ZooKeeperError(\n            \"Retry failed while updating leader\"\n        )\n    try:\n        self.create(\n            leader.name,\n            self.client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            sequence=False,\n        )\n        return True\n    except NoNodeError:\n        logger.error(\n            \"Failed to update leader %s, no node found\",\n            leader.name,\n        )\n        return False\n    except NodeExistsError:\n        logger.error(\n            \"Failed to update leader %s, node already exists\",\n            leader.name,\n        )\n        return False\n    except ConnectionClosedError:\n        logger.error(\n            \"Failed to update leader %s, connection closed\",\n            leader.name,\n        )\n        return False\n    except RetryFailedError:\n        logger.error(\n            \"Failed to update leader %s, retry failed\",\n            leader.name,\n        )\n        return False\n\n\n\n\n", "CodeBleu_score": 39.55187371022186}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if not self._should_poll():\n        return False\n    logging.debug('Polling exhibitors')\n    exhibitors = self._get_exhibitors()\n    if not exhibitors:\n        logging.debug('No exhibitors found')\n        return False\n    logging.debug('Found exhibitors: %s', exhibitors)\n    data = self._query_exhibitors(exhibitors)\n    if not data:\n        logging.debug('No data found')\n        return False\n    logging.debug('Found data: %s', data)\n    if not self._is_valid(data):\n        logging.debug('Data is not valid')\n        return False\n    connection_string = self._get_connection_string(data)\n    if self._connection_string != connection_string:\n        logging.info('Connection string changed: %s -> %s', self._connection_string, connection_string)\n        self._connection_string = connection_string\n        self._state = self.STATE_CONNECTED\n        return True\n    return False\n\n", "CodeBleu_score": 33.48941115350273}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None or time.time() - self._last_poll_time > self._poll_interval:\n        logging.debug('Polling exhibitors')\n        self._last_poll_time = time.time()\n        data = self._query_exhibitors(self._exhibitors)\n        if data is not None:\n            server_port = '{}:{}'.format(data['hostname'], data['port'])\n            if server_port != self._zk_server_port:\n                logging.info('ZooKeeper connection string changed from %s to %s', self._zk_server_port, server_port)\n                self._zk_server_port = server_port\n                self._update_state()\n                return True\n    return False", "CodeBleu_score": 37.68582361066149}, {"code": "def poll(self) -> bool\n\t\n    if time.time() < self._next_poll:\n        return False\n    self._next_poll = time.time() + self._poll_interval\n    exhibitors = self._query_exhibitors(self._exhibitors)\n    if exhibitors is None:\n        return False\n    servers = exhibitors.get('servers')\n    if servers is None:\n        return False\n    zk_connection_string = ','.join('%s:%s' % (host, port) for host, port in servers)\n    if zk_connection_string != self._zk_connection_string:\n        logging.info('ZooKeeper connection string has changed: %s', zk_connection_string)\n        self._zk_connection_string = zk_connection_string\n        self._zk_client.set_servers(zk_connection_string)\n        return True\n    return False\n", "CodeBleu_score": 40.98670515926373}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n        if self._ensemble_provider.poll():\n            self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n        return super(Exhibitor, self)._load_cluster(path, loader)", "CodeBleu_score": 95.37052616514315}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t  if (zookeeperListener != null) {\n    String group = zookeeperListener.getGroup();\n    String dataId = zookeeperListener.getDataId();\n    logger.info(\"start unsubscribe from zookeeper config: group: {}, dataId: {}\", group, dataId);\n    try {\n      zookeeperListener.unSubscribe();\n    }\n catch (    Exception e) {\n      logger.error(\"unsubscribe from zookeeper config failed, group: {}, dataId: {}\", group, dataId, e);\n    }\n  }\n}", "CodeBleu_score": 36.49096644878497}, {"code": "public void destroy(){\n\t  if (zookeeperListener == null) {\n    return;\n  }\n  String group = zookeeperListener.getGroup();\n  String dataId = zookeeperListener.getDataId();\n  logger.info(\"unsubscribe zookeeper config, dataId:{}, group:{}\", dataId, group);\n  try {\n    zookeeperListener.unSubscribe();\n  }\n catch (  Exception e) {\n    logger.error(\"unsubscribe zookeeper config failed, dataId:{}, group:{}\", dataId, group, e);\n  }\n}", "CodeBleu_score": 48.315399675186676}, {"code": "public void destroy(){\n\t  if (zookeeperListener != null) {\n    String group = zookeeperListener.getGroup();\n    String dataId = zookeeperListener.getDataId();\n    logger.info(\"Start to unsubscribe zookeeper config. group={}, dataId={}\", group, dataId);\n    try {\n      zookeeperListener.unsubscribe();\n    }\n catch (  Exception e) {\n      logger.error(\"Failed to unsubscribe zookeeper config. group={}, dataId={}\", group, dataId, e);\n    }\n  }\n}", "CodeBleu_score": 36.97547677006357}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getPayload().getMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 67.15336074372748}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 57.513534660890954}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 57.513534660890954}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t        String path = \"/\" + group + \"/\" + serviceId + \"/config\";\n        NodeCache nodeCache = new NodeCache(curatorFramework, path);\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getData());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        nodeCache.start();\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        addListener(zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 68.98214497233248}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t        String path = getPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path);\n        nodeCache.start();\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getData());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        listeners.add(zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 75.30295527867624}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t        String path = getPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                String config = convertConfig(nodeCache.getCurrentData().getData());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        nodeCache.start();\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        listeners.add(zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 73.61112148290398}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t  ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n  serverList.initWithNiwsConfig(config);\n  serverList.setLoadBalanceListenerExecutor(this.loadBalanceListenerExecutor);\n  return serverList;\n}", "CodeBleu_score": 65.48124138188153}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t  ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n  serverList.initWithNiwsConfig(config);\n  serverList.setLoadBalancerListenerExecutor(config.getLoadBalancerListenerExecutor());\n  return serverList;\n}", "CodeBleu_score": 68.0878599184392}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery, config.getClientName());\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor);\n    return serverList;\n}", "CodeBleu_score": 66.88217057501512}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.7694205192842}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.7694205192842}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.7694205192842}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t  String group = globalConfig ? \"DEFAULT_GROUP\" : this.group;\n  String dataId = globalConfig ? \"global\" : this.dataId;\n  logger.info(\"Subscribe to the configuration: group: {}, dataId: {}\", group, dataId);\n  try {\n    return zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperListener() {\n      @Override\n      public void receiveConfigInfo(String configInfo) {\n        logger.info(\"Received the config info: {}\", configInfo);\n        processConfig(configInfo);\n      }\n    });\n  } catch (Exception e) {\n    logger.error(\"Subscribe to the configuration failed\", e);\n    return null;\n  }\n}", "CodeBleu_score": 46.485770851920904}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? ConfigConsts.NACOS_GROUP : getGroup();\n    String dataId = globalConfig ? ConfigConsts.NACOS_DATA_ID : getDataId();\n    try {\n        LOGGER.info(\"[subscribeConfig] subscribe start. dataId: {}, group: {}\", dataId, group);\n        return (ZookeeperListener) zookeeperOperation.subscribe(group, dataId, new ConfigChangeListener() {\n            @Override\n            public void receiveConfigInfo(String configInfo) {\n                LOGGER.info(\"[receiveConfigInfo] configInfo: {}\", configInfo);\n                setConfigInfo(configInfo);\n            }\n        });\n    } catch (Exception e) {\n        LOGGER.error(\"[subscribeConfig] subscribe failed. dataId: {}, group: {}\", dataId, group, e);\n        return null;\n    }\n}", "CodeBleu_score": 45.21618165919532}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? \"SEATA_GROUP\" : getGroup();\n    String dataId = globalConfig ? \"client.yml\" : getDataId();\n    LOGGER.info(\"start to subscribe config: {} - {}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribeConfig(group, dataId, new ConfigChangeListener() {\n            @Override\n            public void receiveConfigInfo(String configInfo) {\n                LOGGER.info(\"receive config info {}\", configInfo);\n                setConfigInfo(configInfo);\n            }\n        });\n    } catch (Exception e) {\n        LOGGER.error(\"subscribe config failed\", e);\n        return null;\n    }\n}", "CodeBleu_score": 48.44565581472633}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    String zkConnectionString = System.getenv(\"ZOOKEEPER_CONNECTION_STRING\");\n    if (zkConnectionString == null || zkConnectionString.isEmpty()) {\n        throw new DiscoveryException(\"ZOOKEEPER_CONNECTION_STRING environment variable is not set\");\n    }\n    int retryCount = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_COUNT\"));\n    int sleepTime = Integer.parseInt(System.getenv(\"ZOOKEEPER_RETRY_SLEEP_TIME\"));\n    CuratorFramework client = CuratorFrameworkFactory.newClient(zkConnectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n    client.start();\n    return client;\n}", "CodeBleu_score": 32.640492571952}, {"code": "public CuratorFramework curatorFramework(){\n\t    String zkConnectionString = System.getenv(\"ZK_CONNECTION_STRING\");\n    if (zkConnectionString == null || zkConnectionString.isEmpty()) {\n        throw new DiscoveryException(\"ZK_CONNECTION_STRING not set in environment\");\n    }\n    int retryCount = Integer.parseInt(System.getenv(\"ZK_RETRY_COUNT\"));\n    int sleepTime = Integer.parseInt(System.getenv(\"ZK_SLEEP_TIME\"));\n    CuratorFramework client = CuratorFrameworkFactory.newClient(zkConnectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n    client.start();\n    return client;\n}", "CodeBleu_score": 31.083778675827073}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectionString = environment.getProperty(\"zookeeper.connection.string\");\n    if (connectionString == null || connectionString.isEmpty()) {\n        throw new DiscoveryException(\"zookeeper.connection.string is empty\");\n    }\n    int retryCount = environment.getProperty(\"zookeeper.retry.count\", Integer.class, 5);\n    int sleepTime = environment.getProperty(\"zookeeper.sleep.time\", Integer.class, 1000);\n    CuratorFramework client = CuratorFrameworkFactory.newClient(connectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n    client.start();\n    return client;\n}", "CodeBleu_score": 36.95394548537739}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t", "CodeBleu_score": 1.394537427031336}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n    @Bean\n    @ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(ZookeeperDiscoveryClient zookeeperDiscoveryClient,\n            ZookeeperDiscoveryProperties zookeeperDiscoveryProperties,\n            GatewayRouteDefinitionLocator gatewayRouteDefinitionLocator) {\n        return new GatewayStrategyRouteZookeeperProcessor(zookeeperDiscoveryClient, zookeeperDiscoveryProperties,\n                gatewayRouteDefinitionLocator);\n    }\n\n}", "CodeBleu_score": 28.76756912079633}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t", "CodeBleu_score": 1.394537427031336}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t    // Create a CuratorFramework instance using the provided ZooKeeper client properties.\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zookeeperClientProperties.getHosts(), zookeeperClientProperties.getSessionTimeout(), zookeeperClientProperties.getConnectionTimeout(), zookeeperClientProperties.getNamespace());\n    // Set the retry policy for the CuratorFramework instance.\n    curatorFramework.setRetryPolicy(retryPolicy);\n    // Start the CuratorFramework instance.\n    curatorFramework.start();\n    // Return the initialized CuratorFramework instance.\n    return curatorFramework;\n}", "CodeBleu_score": 41.83047323975836}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFramework client = CuratorFrameworkFactory.newClient(zookeeperClientProperties.getHosts(), zookeeperClientProperties.getSessionTimeout(), zookeeperClientProperties.getConnectionTimeout(), zookeeperClientProperties.getRetryPolicy());\n    client.start();\n    return client;\n  }", "CodeBleu_score": 31.514380688369826}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(zookeeperHosts).sessionTimeoutMs(sessionTimeout).retryPolicy(retryPolicy).namespace(namespace).build();\n    curatorFramework.start();\n    return curatorFramework;\n  }", "CodeBleu_score": 39.22177948331621}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client, path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n    }\n}", "CodeBleu_score": 27.111144965329576}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client, path);\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n    }\n}", "CodeBleu_score": 27.087129728323788}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    if (locksMap.containsKey(path)) {\n        locksMap.get(path).acquire();\n    } else {\n        InterProcessMutex lock = new InterProcessMutex(client, path);\n        try {\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 27.419036638517476}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t        final CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        final String nodePath = nodePath(dtpProperties);\n        if (ConfigTypeEnum.PROPERTIES.getType().equals(dtpProperties.getConfigType())) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        } else {\n            final String configKey = dtpProperties.getConfigKey();\n            final String path = ZKPaths.makePath(nodePath, configKey);\n            String value = getVal(path, curatorFramework);\n            return ConfigHandler.parseConfig(value, dtpProperties.getConfigType());\n        }\n    }", "CodeBleu_score": 45.45971531182096}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t        final CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        final String nodePath = nodePath(dtpProperties);\n        if (dtpProperties.getConfigType() == ConfigTypeEnum.PROPERTIES) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        } else {\n            final String path = ZKPaths.makePath(nodePath, dtpProperties.getConfigKey());\n            final String value = getVal(path, curatorFramework);\n            return ConfigHandler.parseMap(value);\n        }\n    }", "CodeBleu_score": 42.069273408318764}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t        final CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n        final String nodePath = nodePath(dtpProperties);\n        if (dtpProperties.getConfigType() == ConfigTypeEnum.PROPERTIES) {\n            return genPropertiesTypeMap(nodePath, curatorFramework);\n        }\n        final String configKey = dtpProperties.getConfigKey();\n        final String path = ZKPaths.makePath(nodePath, configKey);\n        String value = getVal(path, curatorFramework);\n        Map<Object, Object> properties = ConfigHandler.parseMap(value);\n        return properties;\n    }", "CodeBleu_score": 46.44313445793698}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t        DtpProperties dtpProperties = DtpProperties.bind(environment);\n        Map<Object, Object> properties = dtpProperties.generateProperties();\n        if (!checkPropertyExist(environment)) {\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 68.61254222914872}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t        DtpProperties dtpProperties = getDtpProperties(application);\n        Binder binder = Binder.get(environment);\n        binder.bind(DtpProperties.PREFIX, Bindable.ofInstance(dtpProperties));\n        Map<Object, Object> properties = generateProperties(dtpProperties);\n        if (!checkPropertyExist(environment)) {\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 65.27086255905724}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t        DtpProperties dtpProperties = new DtpProperties();\n        Binder.get(environment).bind(DtpProperties.PROP_PREFIX, Binder.get(environment).bindOrCreate(DtpProperties.class.getName(), dtpProperties));\n        Map<Object, Object> properties = dtpProperties.toMap();\n        if (!checkPropertyExist(environment)) {\n            createZkPropertySource(environment, properties);\n        }\n    }", "CodeBleu_score": 66.82346554900995}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 4.435738909874791}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider =>\n    {\n        var logger = provider.Resolve<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.Resolve<ISerializer<ServiceRoute>>();\n        var routeFactory = provider.Resolve<IServiceRouteFactory>();\n        var zookeeperClientProvider = provider.Resolve<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(logger, serializer, routeFactory, zookeeperClientProvider, configInfo);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 41.03544148681626}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    configInfo = GetConfigInfo(configInfo);\n    builder.RegisterType<ZooKeeperClientProvider>().As<IZookeeperClientProvider>().WithParameter(TypedParameter.From(configInfo)).SingleInstance();\n    builder.Register(provider => {\n        var clientProvider = provider.Resolve<IZookeeperClientProvider>();\n        var logger = provider.Resolve<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.Resolve<ISerializer<ServiceRoute>>();\n        var factory = new ZooKeeperServiceRouteFactory(logger, serializer);\n        return new ZooKeeperServiceRouteManager(configInfo, clientProvider, factory, logger);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 34.90238938805159}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (configInfo == null)\n                throw new ArgumentNullException(nameof(configInfo));\n            if (string.IsNullOrEmpty(configInfo.ConnectionString))\n                throw new ArgumentNullException(nameof(configInfo.ConnectionString));\n            if (string.IsNullOrEmpty(configInfo.CommandPath))\n                throw new ArgumentNullException(nameof(configInfo.CommandPath));\n            configInfo = GetConfigInfo(configInfo);\n            builder.RegisterAdapter<IServiceCommandManager, ZookeeperServiceCommandManager>(ServiceLifetime.Singleton).Configure((p, o) => {\n                o.ConnectionString = configInfo.ConnectionString;\n                o.SessionTimeout = configInfo.SessionTimeout;\n                o.CommandPath = configInfo.CommandPath;\n                o.SubscriberPath = configInfo.SubscriberPath;\n                o.RoutePath = configInfo.RoutePath;\n                o.CachePath = configInfo.CachePath;\n                o.MqttRoutePath = configInfo.MqttRoutePath;\n                o.ChRoot = configInfo.ChRoot;\n                o.ReloadOnChange = configInfo.ReloadOnChange;\n                o.EnableChildrenMonitor = configInfo.EnableChildrenMonitor;\n            });\n            return this;\n        }", "CodeBleu_score": 34.097901025831476}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (configInfo == null) {\n                configInfo = new ConfigInfo();\n            }\n            var config = GetConfigInfo(configInfo);\n            builder.RegisterAdapter<IServiceCommandManager, ZookeeperServiceCommandManager>(Lifetime.Singleton).Configure(config);\n            return this;\n        }", "CodeBleu_score": 25.193988484764716}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (configInfo == null)\n                throw new ArgumentNullException(nameof(configInfo));\n            if (configInfo.ConnectionString == null)\n                throw new ArgumentNullException(nameof(configInfo.ConnectionString));\n            if (configInfo.SessionTimeout == null)\n                throw new ArgumentNullException(nameof(configInfo.SessionTimeout));\n            if (configInfo.SessionTimeout.TotalMilliseconds <= 0)\n                throw new ArgumentException(nameof(configInfo.SessionTimeout));\n            if (configInfo.RoutePath == null)\n                throw new ArgumentNullException(nameof(configInfo.RoutePath));\n            if (configInfo.SubscriberPath == null)\n                throw new ArgumentNullException(nameof(configInfo.SubscriberPath));\n            if (configInfo.CommandPath == null)\n                throw new ArgumentNullException(nameof(configInfo.CommandPath));\n            if (configInfo.CachePath == null)\n                throw new ArgumentNullException(nameof(configInfo.CachePath));\n            if (configInfo.MqttRoutePath == null)\n                throw new ArgumentNullException(nameof(configInfo.MqttRoutePath));\n            if (configInfo.ChRoot == null)\n                throw new ArgumentNullException(nameof(configInfo.ChRoot));\n            builder.Register(sp =>\n            {\n                var config = GetConfigInfo(configInfo);\n                var serviceProvider = sp.GetService<IServiceProvider>();\n                var logger = sp.GetService<ILogger<ZookeeperServiceCommandManager>>();\n                return new ZookeeperServiceCommandManager(\n                    serviceProvider,\n                    config,\n                    logger\n                    );\n            }).As<IServiceCommandManager>().SingleInstance();\n            return this;\n        }", "CodeBleu_score": 41.24312633121697}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 52.481094452895825}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n    return builder.AddZookeeperFile(s => {\n        s.FileProvider = provider;\n        s.Path = path;\n        s.Optional = optional;\n        s.ReloadOnChange = reloadOnChange;\n        s.ResolveFileProvider();\n    });\n}", "CodeBleu_score": 34.87822010364299}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentNullException(nameof(path));\n    }\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n        path = Path.GetFileName(path);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 76.58322118521733}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Addresses = route.Addresses.Where(x => !Address.Contains(x)).ToList();\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 68.87380360524476}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        foreach (var address in Address) {\n            route.Addresses.Remove(address);\n        }\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 57.8036696587193}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes)\n    {\n        route.Addresses = route.Addresses.Except(Address).ToList();\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 74.190163445901}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = GetRoutePath();\n    var clients = _zookeeperClientManager.GetAll();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(routePath);\n        var exceptRoutes = routes.Select(r => r.ToJson()).ToList();\n        foreach (var child in children) {\n            var route = JsonConvert.DeserializeObject<ServiceRoute>(child);\n            if (!exceptRoutes.Contains(route.ToJson()) && route.Address.Contains(hostAddr.Ip) && route.Address.Contains(hostAddr.Port.ToString())) {\n                await client.DeleteRecursiveAsync(routePath + \"/\" + child);\n            }\n        }\n    }\n}", "CodeBleu_score": 33.553741667595524}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = ZKPaths.Base + \"/\" + ZKPaths.Routes;\n    var clients = _zkClient.GetClients();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(routePath);\n        var toDelete = children.Where(c => !routes.Any(r => r.Address.Equals(c))).ToList();\n        foreach (var route in toDelete) {\n            var addr = AddressModel.Parse(route);\n            if (addr.Equals(hostAddr)) {\n                await client.DeleteRecursiveAsync(routePath + \"/\" + route);\n            }\n        }\n    }\n}", "CodeBleu_score": 27.2002506675156}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var newRoutes = routes.ToList();\n    var routePath = ZookeeperPath.CreateProviderPath(hostAddr.Name);\n    var zkClients = GetZookeeperClients();\n\n    foreach (var zkClient in zkClients) {\n        var children = await zkClient.GetChildrenAsync(routePath);\n        var childrenToDelete = children.Except(newRoutes.Select(r => r.Address.ToString()));\n\n        foreach (var child in childrenToDelete) {\n            var childPath = ZookeeperPath.Combine(routePath, child);\n            var data = await zkClient.GetDataAsync(childPath);\n            var address = JsonSerializer.Deserialize<AddressModel>(data);\n\n            if (address.Host == hostAddr.Host && address.Port == hostAddr.Port) {\n                await zkClient.DeleteRecursiveAsync(childPath);\n            }\n        }\n    }\n}", "CodeBleu_score": 32.55202179903633}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    if (Logger.IsEnabled(LogLevel.Debug)) {\n        Logger.LogDebug($\"Route data: {Encoding.UTF8.GetString(data)}\");\n    }\n\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(Encoding.UTF8.GetString(data));\n\n    return _serviceRouteFactory.Create(descriptor);\n}", "CodeBleu_score": 36.74549556901787}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug(\"Route data: {data}\", Encoding.UTF8.GetString(data));\n    }\n\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(data, _jsonSerializerOptions);\n    return _serviceRouteFactory.Create(descriptor);\n}", "CodeBleu_score": 36.830575135956835}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Route data: {Encoding.UTF8.GetString(data)}\");\n    }\n\n    var descriptor = JsonSerializer.Deserialize<ServiceRouteDescriptor>(data, _jsonSerializerOptions);\n    return _serviceRouteFactory.Create(descriptor);\n}", "CodeBleu_score": 37.52869332566658}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData))\n        return;\n\n    var newRoute = await GetRoute(newData);\n    var oldRoute = _routes.FirstOrDefault(x => x.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\n    lock (_routes) {\n        if (oldRoute != null)\n            _routes.Remove(oldRoute);\n\n        _routes.Add(newRoute);\n    }\n\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 45.18109778379808}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData))\n        return;\n\n    var newRoute = await GetRoute(newData);\n    if (newRoute == null)\n        return;\n\n    var oldRoute = _routes.FirstOrDefault(r => r.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n    if (oldRoute == null)\n        return;\n\n    lock (_routes) {\n        _routes[_routes.IndexOf(oldRoute)] = newRoute;\n    }\n\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 43.723446968701715}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData))\n        return;\n\n    var newRoute = await GetRoute(newData);\n    if (newRoute == null)\n        return;\n\n    var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\n    lock (_lock) {\n        if (oldRoute != null)\n            _routes.Remove(oldRoute);\n        _routes.Add(newRoute);\n    }\n\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 47.33254651831265}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var childrens = await _client.GetChildrenAsync(_configInfo.SubscriberPath);\n    var oldSubscribers = await GetSubscribers(childrens);\n    foreach (var subscriber in subscribers) {\n        var oldSubscriber = oldSubscribers.FirstOrDefault(x => x.ServiceName == subscriber.ServiceName && x.ServiceId == subscriber.ServiceId);\n        if (oldSubscriber != null) {\n            subscriber.AddressList = subscriber.AddressList.Union(oldSubscriber.AddressList).Distinct().ToArray();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 56.95196676497621}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var rootPath = _configInfo.SubscriberPath;\n    if (!rootPath.EndsWith(\"/\"))\n        rootPath += \"/\";\n\n    var childrens = await _client.GetChildrenAsync(rootPath);\n    var subscriberList = await GetSubscribers(childrens);\n\n    var subscriberDict = new Dictionary<string, ServiceSubscriber>();\n    foreach (var subscriber in subscriberList)\n        subscriberDict.Add(subscriber.Name, subscriber);\n\n    foreach (var subscriber in subscribers) {\n        if (subscriberDict.TryGetValue(subscriber.Name, out var existingSubscriber)) {\n            var mergedAddresses = existingSubscriber.Address.Union(subscriber.Address).Distinct().ToArray();\n            subscriber.Address = mergedAddresses;\n        }\n    }\n\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 42.400163494943946}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetSubscribers(new[] { _configInfo.SubscriberPath });\n    foreach (var subscriber in subscribers) {\n        var serviceSubscriber = serviceSubscribers.FirstOrDefault(i => i.ServiceName == subscriber.ServiceName);\n        if (serviceSubscriber != null) {\n            var addresses = serviceSubscriber.Address.ToList();\n            foreach (var address in subscriber.Address) {\n                if (!addresses.Contains(address)) {\n                    addresses.Add(address);\n                }\n            }\n            subscriber.Address = addresses.ToArray();\n        }\n    }\n    await base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 51.20437713803398}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var rootPath = string.Format(\"{0}{1}\", _path, ServiceSubscriber.Root);\n    var subscribers = new List<ServiceSubscriber>();\n\n    foreach (var child in childrens) {\n        var fullPath = string.Format(\"{0}{1}\", rootPath, child);\n        var subscriber = await _client.GetAsync<ServiceSubscriber>(fullPath);\n        subscribers.Add(subscriber);\n    }\n\n    return subscribers.ToArray();\n}", "CodeBleu_score": 37.47273080319723}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = Path.Combine(_options.RootPath, _options.SubscribersPath);\n\n    _logger.LogDebug($\"Retrieving subscribers for {childrens.Count()} childrens.\");\n    foreach (var children in childrens) {\n        var fullPath = Path.Combine(rootPath, children);\n        var subscriber = await _client.GetDataAsync<ServiceSubscriber>(fullPath);\n        if (subscriber != null) {\n            subscribers.Add(subscriber);\n        }\n    }\n\n    return subscribers.ToArray();\n}", "CodeBleu_score": 44.58051574468493}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = Path.Combine(this.rootPath, \"subscribers\");\n    foreach (var children in childrens) {\n        var path = Path.Combine(rootPath, children);\n        var subscriber = await this.GetSubscriber(path);\n        subscribers.Add(subscriber);\n    }\n    return subscribers.ToArray();\n}", "CodeBleu_score": 37.91231275448262}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) return;\n    var (mre, zooKeeper) = await GetZooKeeper();\n    mre.WaitOne();\n    var rootPath = _configInfo.SubscriberPath;\n    if (!await zooKeeper.ExistsAsync(rootPath)) {\n        _logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u4e0d\u5b58\u5728\u3002\");\n        _subscribers = new ServiceSubscriber[0];\n        return;\n    }\n\n    var childrens = await zooKeeper.GetChildrenAsync(rootPath);\n    _subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 45.32210265848376}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) return;\n\n    var (zooKeeperEvent, zooKeeper) = await GetZooKeeper();\n    await zooKeeperEvent.WaitOneAsync();\n\n    var childrens = await zooKeeper.GetChildrenAsync(_configInfo.SubscriberPath);\n    if (childrens == null) {\n        _logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{_configInfo.SubscriberPath}\u4e0d\u5b58\u5728\u3002\");\n        _subscribers = new ServiceSubscriber[0];\n        return;\n    }\n\n    _subscribers = await GetSubscribers(childrens);\n}", "CodeBleu_score": 50.21884439961153}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) return;\n    var (event, zooKeeper) = await GetZooKeeper();\n    await event.WaitOneAsync();\n    if (event.IsSet) {\n        var rootPath = _configInfo.SubscriberPath;\n        if (!rootPath.EndsWith(\"/\")) {\n            rootPath += \"/\";\n        }\n        var exists = await zooKeeper.ExistsAsync(rootPath);\n        if (exists != null) {\n            var childrens = await zooKeeper.GetChildrenAsync(rootPath);\n            _subscribers = await GetSubscribers(childrens);\n        } else {\n            _logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u4e0d\u5b58\u5728\u3002\");\n            _subscribers = Array.Empty<ServiceSubscriber>();\n        }\n    }\n}", "CodeBleu_score": 49.19497373618823}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData == null || newData == null)\n        return;\n\n    var oldCommand = GetServiceCommand(oldData);\n    var newCommand = GetServiceCommand(newData);\n\n    if (oldCommand == null || newCommand == null)\n        return;\n\n    if (oldCommand.ServiceId != newCommand.ServiceId)\n        return;\n\n    if (DataEquals(oldCommand.Data, newCommand.Data))\n        return;\n\n    var serviceCommand = newCommand;\n    var serviceCommands = _serviceCommands.GetOrAdd(serviceCommand.ServiceId, new List<ServiceCommandDescriptor>());\n    var oldServiceCommand = serviceCommands.FirstOrDefault(i => i.Id == serviceCommand.Id);\n    if (oldServiceCommand != null)\n        serviceCommands.Remove(oldServiceCommand);\n    serviceCommands.Add(serviceCommand);\n\n    OnChanged?.Invoke(serviceCommand, oldServiceCommand);\n}", "CodeBleu_score": 39.27954337750839}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) {\n        return;\n    }\n    var newCommand = GetServiceCommand(newData);\n    var oldCommand = GetServiceCommand(oldData);\n    if (newCommand == null || oldCommand == null) {\n        return;\n    }\n    var serviceId = newCommand.ServiceId;\n    var serviceCommands = ServiceCommands;\n    var oldCommandIndex = serviceCommands.FindIndex(c => c.ServiceId == serviceId);\n    if (oldCommandIndex >= 0) {\n        serviceCommands[oldCommandIndex] = newCommand;\n    } else {\n        serviceCommands.Add(newCommand);\n    }\n    OnChanged?.Invoke(newCommand, oldCommand);\n}", "CodeBleu_score": 39.0227646820054}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (_logger.IsEnabled(LogLevel.Debug))\n        _logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d1\u751f\u53d8\u5316\uff0c\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u547d\u4ee4\u3002\");\n    var oldCommand = GetServiceCommand(oldData);\n    var newCommand = GetServiceCommand(newData);\n    if (oldCommand == null || newCommand == null || !DataEquals(oldCommand.Data, newCommand.Data)) {\n        _logger.LogDebug($\"\u8282\u70b9\u6570\u636e\u53d1\u751f\u53d8\u5316\uff0c\u51c6\u5907\u66f4\u65b0\u670d\u52a1\u547d\u4ee4\u3002\");\n        var oldCommands = _serviceCommands.Where(x => x.ServiceId == newCommand.ServiceId).ToList();\n        foreach (var oldCommand1 in oldCommands) {\n            _serviceCommands.Remove(oldCommand1);\n        }\n        _serviceCommands.Add(newCommand);\n        OnChanged(newCommand, oldCommand);\n    }\n}", "CodeBleu_score": 40.255287706397986}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.Type == EventType.NodeDataChanged) {\n        var data = await _client.GetDataAsync(watchedEvent.Path);\n        _action(data.Data, _currentData);\n        _currentData = data.Data;\n        await _client.SetWatcher(watchedEvent.Path, this);\n    }\n}", "CodeBleu_score": 45.224313238392575}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.Type == EventType.NodeDataChanged) {\n        var data = await _client.GetDataAsync(watchedEvent.Path);\n        _action(data.Data, _currentData);\n        _currentData = data.Data;\n        await _client.AddWatch(watchedEvent.Path, this);\n    }\n}", "CodeBleu_score": 44.95503256492764}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.Type == EventType.NodeDataChanged) {\n        try {\n            string newData = await _client.GetDataAsync(watchedEvent.Path);\n            _action(newData, _currentData);\n            _currentData = newData;\n            await _client.ExistsAsync(watchedEvent.Path, true);\n        } catch (KeeperException.NoNodeException) {\n            // Node has been deleted\n            _watcher.Stop();\n        }\n    }\n}", "CodeBleu_score": 49.65531032612276}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    var config = GetConfigInfo(configInfo);\n    builder.Services.AddSingleton<IZookeeperClientProvider>(sp => {\n        var healthCheckService = sp.GetService<IHealthCheckService>();\n        var addressSelector = sp.GetService<IAddressSelector>();\n        var logger = sp.GetService<ILogger<DefaultZookeeperClientProvider>>();\n        return new DefaultZookeeperClientProvider(config, healthCheckService, addressSelector, logger);\n    });\n    return builder;\n}", "CodeBleu_score": 46.68118143404497}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    var config = GetConfigInfo(configInfo);\n    builder.Services.AddSingleton<IZookeeperClientProvider>(sp => new DefaultZookeeperClientProvider(config, sp.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>(), sp.GetRequiredService<IHealthCheckService>(), sp.GetRequiredService<IAddressSelector>(), sp.GetRequiredService<ILogger<ZookeeperSubscriber>>(), sp.GetRequiredService<ILogger<ZookeeperCommand>>(), sp.GetRequiredService<ILogger<ZookeeperCache>>(), sp.GetRequiredService<ILogger<ZookeeperMqttRoute>>()));\n    return builder;\n}", "CodeBleu_score": 51.5147439330691}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    configInfo = GetConfigInfo(configInfo);\n    builder.Services.AddSingleton<IZookeeperClientProvider>(sp =>\n    {\n        var healthCheckService = sp.GetRequiredService<IHealthCheckService>();\n        var addressSelector = sp.GetRequiredService<IAddressSelector>();\n        var logger = sp.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>();\n        return new DefaultZookeeperClientProvider(configInfo, healthCheckService, addressSelector, logger);\n    });\n    return builder;\n}", "CodeBleu_score": 42.85390571364248}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var clients = await _zookeeperClientFactory.GetAllClientsAsync();\n    foreach (var client in clients) {\n        var routePath = ZooKeeperPath.Join(client.BasePath, \"routes\", \"mqtt\");\n        await client.CreateIfNotExistsAsync(routePath);\n        foreach (var route in routes) {\n            var routeData = new MqttServiceRouteData {\n                Route = route,\n                ServiceDescriptor = _serviceDescriptor\n            };\n            var routeDataBytes = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(routeData));\n            var routeNodePath = ZooKeeperPath.Join(routePath, route.RouteId);\n            if (await client.ExistsAsync(routeNodePath)) {\n                await client.SetDataAsync(routeNodePath, routeDataBytes);\n                _logger.LogInformation(\"Updated data of route node: '{routeNodePath}'.\", routeNodePath);\n            }\n            else {\n                await client.CreateAsync(routeNodePath, routeDataBytes, CreateMode.Persistent);\n                _logger.LogInformation(\"Created route node: '{routeNodePath}'.\", routeNodePath);\n            }\n        }\n    }\n    _logger.LogInformation(\"Routes successfully added.\");\n}", "CodeBleu_score": 38.87713496884704}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var zkClients = await _zookeeperClient.GetClientsAsync();\n    foreach (var zkClient in zkClients) {\n        var rootPath = GetRootPath(zkClient);\n        var rootPathExists = await zkClient.ExistsAsync(rootPath);\n        if (!rootPathExists) {\n            await zkClient.CreateRecursiveAsync(rootPath);\n        }\n        foreach (var route in routes) {\n            var routePath = GetRoutePath(route);\n            var routePathExists = await zkClient.ExistsAsync(routePath);\n            if (!routePathExists) {\n                await zkClient.CreateRecursiveAsync(routePath);\n            }\n            var routeData = JsonConvert.SerializeObject(route);\n            if (routePathExists) {\n                await zkClient.SetDataAsync(routePath, routeData);\n                _logger.LogInformation($\"Updated route {routePath} with data {routeData}\");\n            } else {\n                await zkClient.CreateAsync(routePath, routeData);\n                _logger.LogInformation($\"Created route {routePath} with data {routeData}\");\n            }\n        }\n    }\n    _logger.LogInformation(\"Routes added successfully\");\n}", "CodeBleu_score": 36.70816692112846}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var clients = await GetZooKeeperClientsAsync();\n    foreach (var client in clients) {\n        var routePath = Path.Combine(Paths.Routes, client.Id);\n        var routePathExists = await client.ExistsAsync(routePath);\n        if (!routePathExists) {\n            await client.CreateAsync(routePath, null, false, true);\n        }\n        foreach (var route in routes) {\n            var routeData = JsonConvert.SerializeObject(route);\n            var routeNodePath = Path.Combine(routePath, route.Id);\n            var routeNodeExists = await client.ExistsAsync(routeNodePath);\n            if (routeNodeExists) {\n                await client.SetDataAsync(routeNodePath, routeData);\n                _logger.LogInformation(\"Updated route {routeId} in ZooKeeper\", route.Id);\n            } else {\n                await client.CreateAsync(routeNodePath, routeData, false, true);\n                _logger.LogInformation(\"Added route {routeId} to ZooKeeper\", route.Id);\n            }\n        }\n    }\n    _logger.LogInformation(\"Added routes to ZooKeeper\");\n}", "CodeBleu_score": 36.26339943046324}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = GetRoutePath();\n    var clients = GetClients();\n    foreach (var client in clients) {\n        var existingRoutes = await client.GetChildrenAsync(routePath);\n        var routesToDelete = existingRoutes.Except(routes.Select(r => r.ToString())).ToList();\n        foreach (var route in routesToDelete) {\n            var routeAddr = MqttServiceRoute.Parse(route);\n            if (routeAddr.Address.Equals(hostAddr)) {\n                await client.DeleteAsync($\"{routePath}/{route}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 29.56078191753562}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = ZookeeperPath.CreateMqttServiceRoutePath(hostAddr.Ip, hostAddr.Port);\n    var clients = await _zookeeperClient.GetClientsAsync();\n\n    foreach (var client in clients) {\n        var existingRoutes = await _zookeeperClient.GetChildrenAsync(client, routePath);\n        var routesToDelete = existingRoutes.Except(routes.Select(r => r.ToString()));\n\n        foreach (var route in routesToDelete) {\n            var routeAddr = MqttServiceRoute.Parse(route);\n\n            if (routeAddr.Ip == hostAddr.Ip && routeAddr.Port == hostAddr.Port) {\n                var routeToDeletePath = ZookeeperPath.CreateMqttServiceRoutePath(routeAddr.Ip, routeAddr.Port);\n                await _zookeeperClient.DeleteNodeAsync(client, routeToDeletePath);\n            }\n        }\n    }\n}", "CodeBleu_score": 36.35213275844509}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = ZookeeperPath.GetServiceRoutePath(hostAddr.Host, hostAddr.Port);\n    var zkClients = await _zookeeperManager.GetClientsAsync();\n    foreach (var zkClient in zkClients) {\n        var children = await zkClient.GetChildrenAsync(routePath);\n        var childrenToRemove = children.Except(routes.Select(r => r.ToString())).ToList();\n        foreach (var child in childrenToRemove) {\n            if (child.Contains(hostAddr.Host)) {\n                await zkClient.DeleteRecursiveAsync($\"{routePath}/{child}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 28.842120060965946}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    Logger.LogInformation(\"Adding service caches.\");\n    var cachePath = GetCachePath();\n    var clients = GetClients();\n    foreach (var client in clients) {\n        await client.CreateIfNotExistsAsync(cachePath, CreateMode.Persistent);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var serializedDescriptor = JsonSerializer.Serialize(cacheDescriptor);\n            var nodePath = GetNodePath(cacheDescriptor.Name);\n            var nodeExists = await client.ExistsAsync(nodePath);\n            if (nodeExists == null) {\n                await client.CreateIfNotExistsAsync(nodePath, serializedDescriptor, CreateMode.Persistent);\n            } else {\n                await client.SetDataAsync(nodePath, serializedDescriptor);\n            }\n        }\n    }\n    Logger.LogInformation(\"Successfully added service caches.\");\n}", "CodeBleu_score": 36.67614127803506}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    Logger.LogInformation(\"Setting service caches...\");\n\n    var cachePath = Path.Combine(Path.Combine(ZookeeperRootPath, ServiceName), \"Caches\");\n    var zookeeperClients = ZookeeperClients;\n\n    foreach (var zookeeperClient in zookeeperClients) {\n        await zookeeperClient.EnsurePathExistsAsync(cachePath);\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cacheDescriptorData = JsonSerializer.SerializeToUtf8Bytes(cacheDescriptor);\n            var cacheDescriptorPath = Path.Combine(cachePath, cacheDescriptor.Key);\n            var cacheDescriptorExists = await zookeeperClient.ExistsAsync(cacheDescriptorPath);\n\n            if (!cacheDescriptorExists) {\n                await zookeeperClient.CreateAsync(cacheDescriptorPath, cacheDescriptorData, CreateMode.Persistent);\n            }\n            else {\n                var currentCacheDescriptorData = await zookeeperClient.GetDataAsync(cacheDescriptorPath);\n\n                if (!currentCacheDescriptorData.SequenceEqual(cacheDescriptorData)) {\n                    await zookeeperClient.SetDataAsync(cacheDescriptorPath, cacheDescriptorData);\n                }\n            }\n        }\n    }\n\n    Logger.LogInformation(\"Successfully added service caches.\");\n}", "CodeBleu_score": 36.544673339970366}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Adding service caches\");\n    var cachePath = _servicePath + \"/caches\";\n    var zooKeeperClients = _zookeeperClientProvider.GetZooKeeperClients();\n    foreach (var zooKeeperClient in zooKeeperClients) {\n        await zooKeeperClient.EnsurePathAsync(cachePath).ConfigureAwait(false);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var data = _serializer.Serialize(cacheDescriptor);\n            var nodePath = cachePath + \"/\" + cacheDescriptor.Name;\n            var nodeExists = await zooKeeperClient.ExistsAsync(nodePath).ConfigureAwait(false);\n            if (!nodeExists) {\n                await zooKeeperClient.CreateAsync(nodePath, data, CreateMode.Persistent).ConfigureAwait(false);\n            } else {\n                await zooKeeperClient.SetDataAsync(nodePath, data).ConfigureAwait(false);\n            }\n        }\n    }\n    _logger.LogInformation(\"Successfully added service caches\");\n}", "CodeBleu_score": 36.87181311998323}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, zooKeeperClient) = zooKeeper;\n    await manualResetEvent.WaitOneAsync();\n\n    if (await zooKeeperClient.ExistsAsync(path, watcher: null) is not null) {\n        return;\n    }\n\n    var directories = path.Split('/');\n    var currentPath = string.Empty;\n    foreach (var directory in directories) {\n        currentPath += $\"/{directory}\";\n        if (await zooKeeperClient.ExistsAsync(currentPath, watcher: null) is null) {\n            await zooKeeperClient.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n            _logger.LogInformation(\"Created Zookeeper node: {Path}\", currentPath);\n        }\n    }\n}", "CodeBleu_score": 44.83790604109558}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, zooKeeperClient) = zooKeeper;\n\n    // Wait for the manual reset event to be set before proceeding\n    manualResetEvent.WaitOne();\n\n    // Check if the path already exists\n    var exists = await zooKeeperClient.ExistsAsync(path);\n\n    if (!exists) {\n        // Log the creation process\n        _logger.LogInformation($\"Creating Zookeeper node path: {path}\");\n\n        // Iteratively create each subdirectory in the path\n        var subPaths = path.Split('/').Where(x => !string.IsNullOrEmpty(x));\n        var currentPath = \"\";\n\n        foreach (var subPath in subPaths) {\n            currentPath += $\"/{subPath}\";\n\n            if (!await zooKeeperClient.ExistsAsync(currentPath)) {\n                await zooKeeperClient.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n            }\n        }\n    }\n}", "CodeBleu_score": 38.7688915258525}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, client) = zooKeeper;\n    await Task.Run(() => manualResetEvent.WaitOne());\n    if (!await client.ExistsAsync(path)) {\n        var subdirectories = path.Split('/').Where(subdirectory => !string.IsNullOrEmpty(subdirectory));\n        var currentPath = string.Empty;\n        foreach (var subdirectory in subdirectories) {\n            currentPath += $\"/{subdirectory}\";\n            if (!await client.ExistsAsync(currentPath)) {\n                await client.CreateAsync(currentPath, null, ZooKeeperAcl.Read | ZooKeeperAcl.Write, CreateMode.Persistent);\n                _logger.LogInformation(\"Created Zookeeper node: {Path}\", currentPath);\n            }\n        }\n    }\n}", "CodeBleu_score": 40.33297276929226}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _config.Addresses) {\n        if (await _healthCheckService.CheckHealthAsync(address)) {\n            result.Add(CreateZooKeeper(address));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 78.00125276885505}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var ipAddress in _config.IpAddresses) {\n        if (await _healthCheckService.CheckHealthAsync(ipAddress)) {\n            result.Add(CreateZooKeeper(ipAddress));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 76.95290888589075}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var ipAddress in _config.Addresses) {\n        var (connectionWait, zooKeeper) = CreateZooKeeper(ipAddress);\n        await connectionWait.WaitOneAsync();\n        if (await _healthCheckService.CheckHealthAsync(zooKeeper)) {\n            result.Add((connectionWait, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 72.23981804600857}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t        synchronized (this) {\n            if (zk == null) {\n                String connectionString = getConnectionString();\n                if (connectionString == null) {\n                    throw new IllegalStateException(\"connection string is null\");\n                }\n                zk = new ZooKeeper(connectionString, sessionTimeout, this);\n                this.data = new byte[0];\n            }\n            return zk;\n        }\n    }", "CodeBleu_score": 38.296725648340626}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t        synchronized (this) {\n            if (zk == null) {\n                zk = new ZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, this);\n            }\n            return zk;\n        }\n    }", "CodeBleu_score": 35.56943346829231}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t        synchronized (this) {\n            if (zk == null) {\n                zk = new ZooKeeper(connectionString, sessionTimeout, this);\n            }\n            return zk;\n        }\n    }", "CodeBleu_score": 25.52542245629732}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  if (zk != null) {\n    try {\n      zk.register(new Watcher() {\n\n        @Override\n        public void process(WatchedEvent event) {\n        }\n      });\n    }\n    catch (KeeperException e) {\n      LOG.warn(\"Failed to register dummy watcher\",e);\n    }\n    zk.close(waitForShutdownTimeoutMs);\n    zk = null;\n  }\n}", "CodeBleu_score": 26.82792622800452}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  ZooKeeper zk = zkHelper.getZk();\n  if (zk != null) {\n    zk.register(null);\n    zk.close();\n  }\n  if (waitForShutdownTimeoutMs > 0) {\n    zkHelper.waitForShutdown(waitForShutdownTimeoutMs);\n  }\n}", "CodeBleu_score": 18.691238115308163}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t  if (zk != null) {\n    try {\n      zk.register(new Watcher() {\n\n        public void process(WatchedEvent event) {\n          // do nothing\n        }\n      });\n    }\n    catch (Exception e) {\n      // ignore\n    }\n    if (waitForShutdownTimeoutMs > 0) {\n      zk.close(waitForShutdownTimeoutMs);\n    }\n    else {\n      zk.close();\n    }\n  }\n}", "CodeBleu_score": 26.282714597126944}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    long startTime = System.currentTimeMillis();\n    LOG.info(\"Starting operation: blockUntilConnectedOrTimedOut\");\n    boolean connected = internalBlockUntilConnectedOrTimedOut();\n    LOG.info(\"Finished operation: blockUntilConnectedOrTimedOut. Time taken: {} ms\", System.currentTimeMillis() - startTime);\n    return connected;\n}", "CodeBleu_score": 39.15483551963865}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    OperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n    try {\n        internalBlockUntilConnectedOrTimedOut();\n        trace.setResult(true);\n        return true;\n    } catch (InterruptedException e) {\n        trace.setResult(false);\n        throw e;\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 38.80126383170304}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    OperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\");\n    try {\n        internalBlockUntilConnectedOrTimedOut();\n        return isConnected();\n    } finally {\n        trace.end();\n    }\n}", "CodeBleu_score": 30.897055927100816}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (!started) {\n        return;\n    }\n    logger.info(\"Shutting down {}\", getName());\n    started = false;\n    try {\n        if (!closeWithTimeout(waitForShutdownTimeoutMs)) {\n            logger.warn(\"{} did not shut down within {}ms\", getName(), waitForShutdownTimeoutMs);\n        }\n    } catch (IOException e) {\n        if (Thread.currentThread().isInterrupted()) {\n            logger.warn(\"Interrupted while shutting down {}\", getName());\n        } else {\n            logger.error(\"Error while shutting down {}\", getName(), e);\n        }\n    }\n}", "CodeBleu_score": 46.57516696275278}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t        if (started) {\n            LOG.info(\"Shutting down {}\", this);\n            started = false;\n            try {\n                close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n            } catch (IOException e) {\n                if (Thread.interrupted()) {\n                    LOG.warn(\"Interrupted while shutting down {}\", this, e);\n                } else {\n                    LOG.error(\"Error while shutting down {}\", this, e);\n                }\n            }\n        }\n    }", "CodeBleu_score": 38.33689667856132}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (started) {\n        log.info(\"Shutting down service {}\", this.getClass().getSimpleName());\n        started = false;\n        try {\n            close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n        } catch (IOException e) {\n            if (Thread.currentThread().isInterrupted()) {\n                log.warn(\"Interrupted while shutting down service {}\", this.getClass().getSimpleName());\n            } else {\n                log.error(\"Error while shutting down service {}\", this.getClass().getSimpleName(), e);\n            }\n        }\n    }\n}", "CodeBleu_score": 43.98940150003737}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t  long start = System.currentTimeMillis();\n  long remaining = connectionTimeout;\n  CountDownLatch connectedLatch = new CountDownLatch(1);\n  while (remaining > 0 && !isConnected()) {\n    try {\n      Watcher watcher = new Watcher() {\n        @Override public void process(        WatchedEvent event) {\n          if (event.getState() == KeeperState.SyncConnected) {\n            connectedLatch.countDown();\n          }\n        }\n      };\n      addWatch(watcher, false);\n      try {\n        connectedLatch.await(remaining, TimeUnit.MILLISECONDS);\n      }\n catch (      InterruptedException e) {\n        throw e;\n      }\n finally {\n        removeWatcher(watcher);\n      }\n      remaining = connectionTimeout - (System.currentTimeMillis() - start);\n    }\n catch (    KeeperException e) {\n      if (e.code() == KeeperException.Code.SESSIONEXPIRED || e.code() == KeeperException.Code.SESSIONMOVED) {\n        continue;\n      }\n      throw e;\n    }\n  }\n  if (remaining <= 0) {\n    throw new ConnectionLossException(\"Connection timed out: \" + connectionTimeout + \"ms elapsed without success\");\n  }\n}", "CodeBleu_score": 41.102259157894494}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t  int remaining = this.connectionTimeoutMs;\n  while (this.connectionState.get() == ConnectionState.CONNECTING) {\n    CountDownLatch latch=new CountDownLatch(1);\n    Watcher watcher=new Watcher() {\n      @Override public void process(      WatchedEvent event) {\n        latch.countDown();\n      }\n    }\n;\n    this.watcher.addWatch(watcher,this.connectionState);\n    try {\n      latch.await(remaining,TimeUnit.MILLISECONDS);\n    }\n catch (    InterruptedException e) {\n      throw e;\n    }\n finally {\n      this.watcher.removeWatch(watcher);\n    }\n    remaining=remaining - this.connectionTimeoutMs + latch.getCount();\n  }\n}", "CodeBleu_score": 36.98578468901233}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t", "CodeBleu_score": 1.4312056341607657}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t        if (doProtected()) {\n            if (createMode == CreateMode.EPHEMERAL) {\n                if (!client.getSessionId().equals(protectedId)) {\n                    LOGGER.info(\"Session ID changed, deleting old node: \" + foundNode);\n                    client.delete().forPath(foundNode);\n                    protectedId = client.getSessionId();\n                }\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 32.82677180230915}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t        if (createMode == CreateMode.EPHEMERAL_SEQUENTIAL || createMode == CreateMode.EPHEMERAL) {\n            if (client.getZookeeperClient().getSessionId() != sessionId) {\n                LOGGER.warn(\"Session changed during protected mode operation. Deleting old node: \" + foundNode);\n                client.delete().inBackground().forPath(foundNode);\n                sessionId = client.getZookeeperClient().getSessionId();\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 38.2486560061155}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t        if (createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n            // we need to check if the session has changed since we created the node\n            if (protectedId != null && !protectedId.equals(client.getZookeeperClient().getSessionId())) {\n                LOG.info(\"Session has changed since we created the node - deleting old node\");\n                client.delete().forPath(foundNode);\n                protectedId = client.getZookeeperClient().getSessionId();\n            }\n        }\n        return foundNode;\n    }", "CodeBleu_score": 35.87031184703735}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t  final Stat stat = new Stat();\n  final String traceName = \"pathInForeground\";\n  final Tracer tracer = new Tracer(traceName, this.getZkClient(), path);\n  tracer.recordRequest(aclList);\n  boolean done = false;\n  int retryCount = 0;\n  while (!done) {\n    try {\n      tracer.recordRequest(aclList);\n      stat.setVersion(-1);\n      stat.setAversion(-1);\n      stat.setCversion(-1);\n      stat.setCtime(-1);\n      stat.setMtime(-1);\n      stat.setMzxid(-1);\n      stat.setPzxid(-1);\n      stat.setEphemeralOwner(-1);\n      stat.setDataLength(-1);\n      stat.setNumChildren(-1);\n      stat.setCtime(System.currentTimeMillis());\n      this.zkClient.setACL(path, aclList, -1);\n      tracer.recordResponse(stat);\n      done = true;\n    }\n    catch (    KeeperException e) {\n      if (e instanceof KeeperException.NoNodeException) {\n        tracer.recordException(e);\n        done = true;\n      }\n      else {\n        if (e instanceof KeeperException.SessionExpiredException) {\n          tracer.recordException(e);\n          retryCount++;\n          if (retryCount > this.maxRetries) {\n            throw e;\n          }\n          else {\n            this.sessionExpired();\n          }\n        }\n        else {\n          tracer.recordException(e);\n          throw e;\n        }\n      }\n    }\n  }\n  tracer.commit();\n  return stat;\n}", "CodeBleu_score": 29.036808129345747}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t", "CodeBleu_score": 7.8987931873300745}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkArgument(thisId.length() > 0, \"thisId cannot be empty\");\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.cache = new CuratorCache(client, membershipPath, false);\n    this.cache.start();\n    this.member = new PersistentNode(client, membershipPath + \"/\" + thisId, payload, CreateMode.EPHEMERAL);\n    this.member.start();\n}", "CodeBleu_score": 44.86683570989016}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkArgument(thisId.length() > 0);\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n    this.membershipCache = new CuratorCache(client, membershipPath, false);\n    this.membershipCache.start();\n    this.member = client.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n}", "CodeBleu_score": 48.42450055985539}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n    validateId(thisId);\n    this.cache = new CuratorCache(client, membershipPath);\n    this.cache.start();\n    this.member = new PersistentNode(client, membershipPath + \"/\" + thisId, CreateMode.EPHEMERAL, payload);\n}", "CodeBleu_score": 48.29841184098215}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework async =\n            AsyncCuratorFramework.wrap(client); // normally you'd wrap early in your app and reuse the instance\n\n    // create a node at the given path with the given payload asynchronously\n    async.create().forPath(path, \"\".getBytes()).whenComplete((name, exception) -> {\n        if (exception != null) {\n            // there was a problem\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Created node name is: \" + name);\n            // now setup a watch on the node\n            setupWatch(async, path);\n        }\n    });\n}", "CodeBleu_score": 72.33845925545295}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n    async.create().forPath(path).whenComplete((name, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Created node name is: \" + name);\n            // Set up a watch on the node\n            async.checkExists().watched().forPath(path).whenComplete((event, exception2) -> {\n                if (exception2 != null) {\n                    exception2.printStackTrace();\n                } else {\n                    System.out.println(\"Watch set up for node: \" + path);\n                }\n            });\n        }\n    });\n}", "CodeBleu_score": 78.38497981254656}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\n    async.create().forPath(path, new byte[0]).whenComplete((name, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Created node name is: \" + name);\n            // set up a watch on the node\n            async.checkExists().watched().forPath(path).whenComplete((watchedEvent, watchedException) -> {\n                if (watchedException != null) {\n                    watchedException.printStackTrace();\n                } else {\n                    System.out.println(\"Watched event type is: \" + watchedEvent.getType());\n                }\n            });\n        }\n    });\n}", "CodeBleu_score": 73.29316985199115}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = new ArrayList<OpResult>();\n    try {\n        results = client.transaction().forOperations(transaction.getOperations()).commit();\n        if (results.size() > 0) {\n            OpResult firstResult = results.get(0);\n            if (firstResult.getType() == OpResult.OpResultType.ERROR) {\n                int errorCode = firstResult.getErr();\n                throw KeeperException.create(errorCode);\n            }\n        }\n    } catch (KeeperException e) {\n        if (e.code() == KeeperException.Code.SESSIONEXPIRED) {\n            throw new SessionExpiredException(e.getMessage(), e);\n        }\n        throw e;\n    }\n    return results;\n}", "CodeBleu_score": 53.8951866676445}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t        List<OpResult> results = transaction.execute(client);\n\n        if (results.size() > 0) {\n            OpResult first = results.get(0);\n            if (first.getType() == OpResult.Type.ERROR) {\n                KeeperException.Code code = first.getErr();\n                if (code == KeeperException.Code.OK) {\n                    code = KeeperException.Code.SYSTEMERROR;\n                }\n                throw new KeeperException(code);\n            }\n        }\n\n        return results;\n    }", "CodeBleu_score": 48.86664340990462}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = new ArrayList<OpResult>();\n\n    // Execute the multi-operation transaction\n    List<Op> ops = transaction.getOperations();\n    List<OpResult> opResults = client.transaction().forOperations(ops).execute();\n    results.addAll(opResults);\n\n    // Check if the first result indicates an error\n    OpResult firstResult = opResults.get(0);\n    if (firstResult.getType() == OpResult.Type.ERROR) {\n        // Retrieve the error code and throw a KeeperException with the appropriate code\n        KeeperException.Code code = firstResult.getErr();\n        throw new KeeperException(code);\n    }\n\n    return results;\n}", "CodeBleu_score": 49.92750412985808}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        for (String name : serviceDiscovery.queryForNames()) {\n            System.out.println(name);\n            for (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(name)) {\n                outputInstance(instance);\n            }\n        }\n    } catch (NoNodeException e) {\n        System.err.println(\"No nodes found\");\n    } finally {\n        serviceDiscovery.close();\n    }\n}", "CodeBleu_score": 44.89901965277755}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t        try {\n            serviceDiscovery.start();\n            List<String> services = serviceDiscovery.queryForNames();\n            for (String service : services) {\n                System.out.println(\"Instances of '\" + service + \"':\");\n                List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\n                for (ServiceInstance<InstanceDetails> instance : instances) {\n                    outputInstance(instance);\n                }\n            }\n        } catch (NoNodeException e) {\n            System.err.println(\"No node found. Check if the zookeeper server is running.\");\n        } finally {\n            serviceDiscovery.close();\n        }\n    }", "CodeBleu_score": 63.2555007291195}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t        System.out.println(\"Services:\");\n        for (String serviceName : serviceDiscovery.queryForNames()) {\n            System.out.println(serviceName + \":\");\n            try {\n                for (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(serviceName)) {\n                    outputInstance(instance);\n                }\n            } catch (NoNodeException e) {\n                System.err.println(\"\\tNo nodes found for \" + serviceName);\n            }\n        }\n        serviceDiscovery.close();\n    }", "CodeBleu_score": 49.30370065235855}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  return children.stream().filter(name -> !READY_NODE.equals(name)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.06319638326888}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  return children.stream().filter(name -> !READY_NODE.equals(name)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.06319638326888}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream().filter(name -> !READY_NODE.equals(name)).sorted().collect(Collectors.toList());\n}", "CodeBleu_score": 15.193362495204255}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t            if (zk != null) {\n                try {\n                    zk.close();\n                } catch (InterruptedException e) {\n                    throw e;\n                }\n            }\n            try {\n                zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n                connectedSignal.await();\n            } catch (IOException e) {\n                if (zk != null) {\n                    try {\n                        zk.close();\n                    } catch (InterruptedException e1) {\n                        e1.printStackTrace();\n                    }\n                }\n                throw e;\n            }\n        }", "CodeBleu_score": 27.943020626796688}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t", "CodeBleu_score": 4.002539703279978}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t            close();\n            String[] hostAndPort = newHost.split(\":\");\n            String host = hostAndPort[0];\n            String port = hostAndPort[1];\n            try {\n                zk = new ZooKeeper(host + \":\" + port, Integer.parseInt(getOption(\"timeout\")), this);\n            } catch (NumberFormatException e) {\n                System.out.println(\"Invalid port, using 2181\");\n                zk = new ZooKeeper(host + \":\" + 2181, Integer.parseInt(getOption(\"timeout\")), this);\n            }\n            countDownLatch.await();\n        }", "CodeBleu_score": 37.73839944106313}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t        List<ACL> acls = new ArrayList<ACL>();\n        String[] segments = aclString.split(\",\");\n        for (String segment : segments) {\n            String[] parts = segment.split(\":\");\n            if (parts.length != 3) {\n                outputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\n                continue;\n            }\n            String scheme = parts[0];\n            String id = parts[1];\n            int perm = getPermFromString(parts[2]);\n            ACL acl = new ACL(perm, new Id(scheme, id));\n            acls.add(acl);\n        }\n        return acls;\n    }", "CodeBleu_score": 31.10335973068905}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t        List<ACL> aclList = new ArrayList<ACL>();\n        String[] segments = aclString.split(\",\");\n        for (String segment : segments) {\n            String[] parts = segment.split(\":\");\n            if (parts.length != 3) {\n                outputStream.write((\"Invalid ACL format: \" + segment).getBytes());\n                continue;\n            }\n            String scheme = parts[0];\n            String id = parts[1];\n            String permString = parts[2];\n            int perm = getPermFromString(permString);\n            ACL acl = new ACL(perm, new Id(scheme, id));\n            aclList.add(acl);\n        }\n        return aclList;\n    }", "CodeBleu_score": 31.810616234955834}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t        List<ACL> acls = new ArrayList<ACL>();\n        String[] segments = aclString.split(\",\");\n        for (String segment : segments) {\n            String[] parts = segment.split(\":\");\n            if (parts.length != 3) {\n                outputStream.write((\"Invalid ACL format: \" + segment).getBytes());\n                continue;\n            }\n            String scheme = parts[0];\n            String id = parts[1];\n            int perm = getPermFromString(parts[2]);\n            ACL acl = new ACL(perm, new Id(scheme, id));\n            acls.add(acl);\n        }\n        return acls;\n    }", "CodeBleu_score": 31.20267575261272}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    Objects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeperMap.get(serverId).delete(path);\n        }\n    } else {\n        zookeeperMap.get(serverId).deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 99.80465478981657}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t        Objects.requireNonNull(pathList);\n        assertZookeeperExists(serverId);\n        if (pathList.size() < 20) {\n            for (String path : pathList) {\n                zookeeperMap.get(serverId).delete(path);\n            }\n        } else {\n            zookeeperMap.get(serverId).deleteAsync(pathList);\n        }\n    }", "CodeBleu_score": 96.80308378969973}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    Objects.requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeperMap.get(serverId).delete(path);\n        }\n    } else {\n        zookeeperMap.get(serverId).deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 99.80465478981657}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t        writer.write(\"Connecting to Zookeeper...\");\n        var connection = CuratorZookeeperConnectionFactory.create(url);\n        writer.write(\"Connected to Zookeeper\");\n        var main = new ZooKeeperMain(connection);\n        return new Terminal(id, url, connection, main);\n    }", "CodeBleu_score": 27.67045964772136}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t        writer.write(\"Connecting to \" + url + \"...\");\n        var factory = new CuratorZookeeperConnectionFactory();\n        var params = ZookeeperParams.builder()\n                .id(id)\n                .url(url)\n                .aclList(Collections.emptyList())\n                .maxRetries(10)\n                .connectionTimeout(10000)\n                .retryIntervalTime(1000)\n                .sessionTimeout(10000)\n                .build();\n        var connection = factory.create(params, Collections.emptyList());\n        writer.write(\"Successfully connected to \" + url + \"\n\");\n        var zkMain = new ZooKeeperMain(connection, writer);\n        return new Terminal(id, url, connection, zkMain);\n    }", "CodeBleu_score": 66.45726384995136}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t        writer.write(\"Connecting to \" + url + \"... \");\n        var connection = new CuratorZookeeperConnectionFactory().create(\n                ZookeeperParams.builder()\n                        .id(id)\n                        .url(url)\n                        .build());\n        writer.write(\"success\n\");\n        var zkMain = new ZooKeeperMain(connection.getClient());\n        return new Terminal(id, url, connection, zkMain);\n    }", "CodeBleu_score": 52.53965851711637}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t        int attempt = 0;\n        while (!isConnected()) {\n            try {\n                attempt++;\n                if (attempt > 6) {\n                    close();\n                    throw new IllegalStateException(\"Failed to establish SSH tunnel connection\");\n                }\n                log.info(\"Attempting to connect to SSH tunnel... (Attempt {})\", attempt);\n                sshClient.connect();\n            } catch (IOException e) {\n                close();\n                throw new IllegalStateException(e);\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        }\n    }", "CodeBleu_score": 40.91616428498973}, {"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (retries > 0) {\n        try {\n            sshClient.connect();\n            if (sshClient.isConnected()) {\n                break;\n            }\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n        retries--;\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n    if (!isConnected()) {\n        close();\n        throw new IllegalStateException(\"SSH connection failed\");\n    }\n}", "CodeBleu_score": 50.17074934725745}, {"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (!isConnected()) {\n        try {\n            sshClient.connect();\n        } catch (IOException e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n\n        if (retries-- == 0) {\n            close();\n            throw new IllegalStateException(\"Failed to establish SSH tunnel connection\");\n        }\n\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(e);\n        }\n    }\n}", "CodeBleu_score": 46.507377232164224}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"deleteNode error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 84.85775485894237}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"Delete node error, serverId:{}, pathList:{}\", serverId, pathList);\n        throw new IllegalStateException(\"Delete node error, serverId:\" + serverId + \", pathList:\" + pathList, e);\n    }\n}", "CodeBleu_score": 62.42335565630468}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"deleteNode error\", e);\n        throw new IllegalStateException(\"deleteNode error\");\n    }\n}", "CodeBleu_score": 69.76429249238117}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        treeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 92.63209854582692}, {"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        treeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 92.63209854582692}, {"code": "public void disconnect(String id){\n\t        Platform.runLater(() -> {\n            ServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n            zookeeperDomainService.disconnect(serverConfiguration.getId());\n            treeItemCache.remove(id);\n        });\n    }", "CodeBleu_score": 90.48842970608284}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfig serverConfig = serverConfigService.getServerConfig(serverId);\n    String connectionUrl = getConnectionUrl(serverConfig);\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 23.964506929479807}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    // Retrieve the server configuration based on the server ID\n    ServerConfiguration serverConfiguration = serverConfigurationService.getServerConfiguration(serverId);\n    // Determine the connection URL based on whether SSH tunneling is enabled\n    String connectionUrl = serverConfiguration.isSshTunnelEnabled() ? serverConfiguration.getSshTunnelUrl() : serverConfiguration.getServerUrl();\n    // Start the terminal with the specified server ID and connection URL\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 39.70902456245317}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = Server.findById(serverId)\n    if (server == null) {\n        throw new IllegalArgumentException(\"Invalid server ID: \" + serverId)\n    }\n    ServerConfig serverConfig = server.getServerConfig()\n    String connectionUrl = serverConfig.getSshTunnelEnabled() ? serverConfig.getSshTunnelUrl() : serverConfig.getConnectionUrl()\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream)\n}", "CodeBleu_score": 41.983961952338824}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t    try {\n        ZooKeeper zk = new ZooKeeper(id, 3000, null);\n        zk.execute(command);\n    } catch (Exception e) {\n        logger.error(\"Failed to execute command on server \" + id + \": \" + e.getMessage());\n        System.out.println(\"Failed to execute command on server \" + id + \". Please try again.\");\n    }\n}", "CodeBleu_score": 43.553708137450684}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        ZooKeeper zk = zkMap.get(id);\n        zk.execute(command);\n    } catch (Exception e) {\n        LOGGER.error(\"Failed to execute command on server with ID: {}\", id, e);\n        JOptionPane.showMessageDialog(null, \"Failed to execute command on server with ID: \" + id + \". Please try again.\", \"Error\", JOptionPane.ERROR_MESSAGE);\n    }\n}", "CodeBleu_score": 42.18082174176311}, {"code": "public void executeCommand(String id, String command){\n\t  try {\n    // Execute the command on the Zookeeper server identified by the ID\n    // ...\n\n    // Log the successful execution of the command\n    logger.info(\"Command '{}' executed successfully on server with ID '{}'\", command, id);\n  } catch (Exception e) {\n    // Log the error that occurred during command execution\n    logger.error(\"Failed to execute command '{}' on server with ID '{}'\", command, id, e);\n\n    // Display an error message indicating that the command execution failed and should be retried\n    showErrorMessage(\"Failed to execute command. Please try again.\");\n  }\n}", "CodeBleu_score": 44.89548971522598}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t    String filePath = System.getProperty(\"zookeeper.system.properties.file\", \"zookeeper.properties\");\n    File file = new File(filePath);\n    if (file.exists()) {\n        try (InputStream inputStream = new FileInputStream(file)) {\n            Properties properties = new Properties();\n            properties.load(inputStream);\n            log.info(\"Loaded zookeeper system properties from file {}\", filePath);\n            return properties;\n        } catch (IOException e) {\n            log.error(\"Error loading zookeeper system properties from file {}\", filePath, e);\n        }\n    } else {\n        log.info(\"Zookeeper system properties file {} does not exist\", filePath);\n    }\n    return new Properties();\n}", "CodeBleu_score": 49.3511449241959}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    String filePath = \"zookeeper.properties\";\n    try {\n        File file = new File(filePath);\n        if (file.exists()) {\n            try (FileInputStream inputStream = new FileInputStream(filePath)) {\n                properties.load(inputStream);\n                logger.info(\"Loaded Zookeeper properties from file: \" + filePath);\n                return properties;\n            }\n        } else {\n            logger.info(\"Zookeeper properties file does not exist: \" + filePath);\n            return properties;\n        }\n    } catch (IOException e) {\n        logger.error(\"Error loading Zookeeper properties from file: \" + filePath, e);\n        return properties;\n    }\n}", "CodeBleu_score": 42.68519748255517}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    String filePath = System.getProperty(\"zookeeper.system.properties.file\");\n    if (filePath != null) {\n        File file = new File(filePath);\n        if (file.exists()) {\n            try {\n                properties.load(new FileInputStream(file));\n                log.info(\"Loaded zookeeper system properties from \" + filePath);\n            } catch (IOException e) {\n                log.error(\"Error loading zookeeper system properties from \" + filePath, e);\n            }\n        } else {\n            log.error(\"Zookeeper system properties file does not exist: \" + filePath);\n        }\n    }\n    return properties;\n}", "CodeBleu_score": 43.5643491639453}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        logger.error(\"Error loading zookeeper system properties from content\", e);\n        Notifications.create().title(\"Error\").text(\"Error loading zookeeper system properties from content\").showError();\n        return;\n    }\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper System Properties\");\n    } catch (IOException e) {\n        logger.error(\"Error saving zookeeper system properties to file\", e);\n        Notifications.create().title(\"Error\").text(\"Error saving zookeeper system properties to file\").showError();\n    }\n}", "CodeBleu_score": 39.58818045358166}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        LOG.error(\"Error loading Zookeeper system properties\", e);\n        NotificationUtil.showError(\"Error loading Zookeeper system properties\", \"Error loading Zookeeper system properties\", e);\n        return;\n    }\n    try {\n        props.store(new FileWriter(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        LOG.error(\"Error saving Zookeeper system properties\", e);\n        NotificationUtil.showError(\"Error saving Zookeeper system properties\", \"Error saving Zookeeper system properties\", e);\n    }\n}", "CodeBleu_score": 32.78654847133864}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t  try {\n    Properties properties=new Properties();\n    properties.load(new StringReader(content));\n    properties.store(new FileOutputStream(SYS_PROP_PATH),null);\n  }\n catch (  IOException e) {\n    logger.error(\"Failed to save Zookeeper system properties\",e);\n    Notification.show(\"Failed to save Zookeeper system properties\",Notification.Type.ERROR_MESSAGE);\n  }\n}", "CodeBleu_score": 19.339698300685093}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t        try {\n            BufferedReader in = new BufferedReader(\n                    new InputStreamReader(client.getInputStream(), StandardCharsets.UTF_8));\n            StringBuilder response = new StringBuilder();\n            String line;\n            while ((line = in.readLine()) != null) {\n                response.append(line);\n                response.append(\"\n\");\n            }\n            cleanup(in);\n            return response.toString();\n        } catch (IOException ex) {\n            throw new IllegalStateException(\"Can't read response\", ex);\n        }\n    }", "CodeBleu_score": 46.41418002257067}, {"code": "private String response(Socket client){\n\t        try {\n            BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n            StringBuilder response = new StringBuilder();\n            String line;\n            while ((line = in.readLine()) != null) {\n                response.append(line);\n            }\n            cleanup(client);\n            return response.toString();\n        } catch (IOException e) {\n            throw new IllegalStateException(e);\n        }\n    }", "CodeBleu_score": 57.1598093608625}, {"code": "private String response(Socket client){\n\t        StringBuilder result = new StringBuilder();\n        try {\n            BufferedReader reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n            String line;\n            while ((line = reader.readLine()) != null) {\n                result.append(line).append(\"\n\");\n            }\n            cleanup(reader);\n        } catch (IOException e) {\n            throw new IllegalStateException(e);\n        }\n        cleanup(client);\n        return result.toString();\n    }", "CodeBleu_score": 58.970831244853336}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t        final CuratorFramework curatorFramework = curatorFramework(params);\n        curatorFramework.start();\n        try {\n            if (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n                throw new RuntimeException(\"Failed to connect to Zookeeper\");\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new RuntimeException(\"Interrupted while waiting for Zookeeper connection\", e);\n        }\n        return new CuratorZookeeperConnection(curatorFramework, params);\n    }", "CodeBleu_score": 61.459679028181455}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t        CuratorFramework client = curatorFramework(params);\n        client.start();\n\n        try {\n            if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n                throw new IllegalStateException(\"Connection not established\");\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw new IllegalStateException(e);\n        }\n\n        return new CuratorZookeeperConnection(client, params);\n    }", "CodeBleu_score": 67.78699457375038}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t        final CuratorFramework curatorFramework = curatorFramework(params);\n        curatorFramework.start();\n        try {\n            if (!curatorFramework.blockUntilConnected(5, TimeUnit.SECONDS)) {\n                throw new RuntimeException(\"Failed to connect to Zookeeper\");\n            }\n        } catch (InterruptedException e) {\n            curatorFramework.close();\n            throw new RuntimeException(\"Interrupted while waiting for Zookeeper connection\", e);\n        }\n        return new CuratorZookeeperConnection(curatorFramework, params);\n    }", "CodeBleu_score": 68.11582724749488}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getConnectionString();\n    if (!isSync.compareAndSet(false, true)) {\n        log.info(\"Synchronization is already in progress.\");\n        return;\n    }\n\n    log.info(\"Starting synchronization process for Zookeeper nodes.\");\n    treeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n        @Override\n        public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\n            ZookeeperNode node = new ZookeeperNode(event.getData().getPath(), event.getData().getData());\n            switch (event.getType()) {\n                case NODE_ADDED:\n                    listeners.forEach(listener -> listener.onNodeAdded(node));\n                    break;\n                case NODE_UPDATED:\n                    listeners.forEach(listener -> listener.onNodeUpdated(node));\n                    break;\n                case NODE_REMOVED:\n                    listeners.forEach(listener -> listener.onNodeRemoved(node));\n                    break;\n                default:\n                    break;\n            }\n        }\n    });\n\n    try {\n        treeCache.start();\n    } catch (Exception e) {\n        log.error(\"Error occurred during synchronization process for Zookeeper nodes: {}\", e.getMessage());\n        treeCache.close();\n    }\n}", "CodeBleu_score": 38.135882620881176}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    if (!isSync.get()) {\n        log.info(\"Start syncing zookeeper nodes...\");\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n            @Override\n            public void childEvent(CuratorFramework curatorFramework, TreeCacheEvent treeCacheEvent) throws Exception {\n                listeners.forEach(listener -> {\n                    try {\n                        listener.onEvent(treeCacheEvent);\n                    } catch (Exception e) {\n                        log.error(\"Failed to process event\", e);\n                    }\n                });\n            }\n        });\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            log.error(\"Failed to start tree cache\", e);\n            treeCache.close();\n        }\n    } else {\n        log.info(\"Zookeeper nodes are already syncing...\");\n    }\n}", "CodeBleu_score": 42.26123081506969}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String zookeeperConnectionString = zookeeperConfig.getZookeeperConnectionString();\n    if (isSync.compareAndSet(false, true)) {\n        log.info(\"Starting Zookeeper synchronization for connection string: {}\", zookeeperConnectionString);\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener() {\n            @Override\n            public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\n                if (event.getType() == TreeCacheEvent.Type.NODE_UPDATED) {\n                    ZookeeperNode node = ZookeeperNode.from(event.getData().getData());\n                    listeners.forEach(listener -> listener.onNodeUpdated(node));\n                }\n            }\n        });\n        try {\n            treeCache.start();\n        } catch (Exception e) {\n            log.error(\"Error starting Zookeeper synchronization for connection string: {}\", zookeeperConnectionString, e);\n            treeCache.close();\n        }\n    } else {\n        log.info(\"Zookeeper synchronization already in progress for connection string: {}\", zookeeperConnectionString);\n    }\n}", "CodeBleu_score": 43.855295671665075}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n    // BUILD_INITIAL_CACHE \u4ee3\u8868\u4f7f\u7528\u540c\u6b65\u7684\u65b9\u5f0f\u8fdb\u884c\u7f13\u5b58\u521d\u59cb\u5316\u3002\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 99.75314840003469}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 73.84492591071368}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 92.65728873983663}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t  logger.info(\"Unregistering service from Zookeeper\");\n  try {\n    for (String path : paths) {\n      client.delete().forPath(path);\n    }\n  }\n catch (  Exception e) {\n    logger.error(\"Error unregistering service from Zookeeper: \" + e.getMessage());\n  }\n finally {\n    client.close();\n  }\n}", "CodeBleu_score": 55.04590388769719}, {"code": "public void unregisterService(){\n\t    log.info(\"Unregistering service\");\n    try {\n        for (String path : paths) {\n            log.info(\"Deleting path: {}\", path);\n            curatorClient.delete().forPath(path);\n        }\n    } catch (Exception e) {\n        log.error(\"Error unregistering service: {}\", e.getMessage());\n    } finally {\n        curatorClient.close();\n    }\n}", "CodeBleu_score": 49.73191709617634}, {"code": "public void unregisterService(){\n\t    logger.info(\"Unregistering services...\");\n    try {\n        for (String path : paths) {\n            try {\n                client.delete().forPath(path);\n            } catch (Exception e) {\n                logger.error(\"Error deleting path: \" + path, e);\n            }\n        }\n    } finally {\n        client.close();\n    }\n}", "CodeBleu_score": 55.27067565071706}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t        CompletableFuture.runAsync(() -> makeClientReady(client, null), executorService)\n                .thenRunAsync(() -> {\n                    if (client != null) {\n                        client.subscribeStateChanges(listener);\n                    }\n                }, executorService);\n    }", "CodeBleu_score": 36.5723179129042}, {"code": "public void addListener(IZkStateListener listener){\n\t        CompletableFuture.runAsync(() -> {\n            makeClientReady(client, null);\n            this.client.subscribeStateChanges(listener);\n        });\n    }", "CodeBleu_score": 20.74122987260792}, {"code": "public void addListener(IZkStateListener listener){\n\t        CompletableFuture.runAsync(() -> {\n            makeClientReady(client, null);\n            if (client != null) {\n                client.subscribeStateChanges(listener);\n            }\n        });\n    }", "CodeBleu_score": 37.87260777513177}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.connectionTimeoutMs = 30 * 1000;\n    this.curatorFramework = CuratorFrameworkFactory.newClient(this.serverAddr, this.retryPolicy);\n    this.curatorFramework.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState state) {\n            if (state == ConnectionState.LOST) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n            } else if (state == ConnectionState.CONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n            } else if (state == ConnectionState.RECONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n            }\n        }\n    });\n    if (this.authority != null) {\n        this.curatorFramework = this.curatorFramework.authorization(\"digest\", this.authority.getBytes()).build();\n    }\n    try {\n        this.curatorFramework.start();\n    } catch (Exception e) {\n        throw new IllegalStateException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 68.68282305161111}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t        this.serverAddr = serverAddr;\n        this.authority = authority;\n        this.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n        this.connectionTimeout = 30 * 1000;\n        this.client = CuratorFrameworkFactory.builder().connectString(serverAddr).retryPolicy(retryPolicy).connectionTimeoutMs(connectionTimeout).build();\n        this.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n            @Override\n            public void stateChanged(CuratorFramework client, ConnectionState state) {\n                if (state == ConnectionState.LOST) {\n                    CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n                } else if (state == ConnectionState.CONNECTED) {\n                    CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n                } else if (state == ConnectionState.RECONNECTED) {\n                    CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n                }\n            }\n        });\n        if (authority != null) {\n            this.client = this.client.authorization(\"digest\", authority.getBytes()).build();\n        }\n        this.client.start();\n        try {\n            this.client.blockUntilConnected(30, TimeUnit.SECONDS);\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(e.getMessage(), e);\n        }\n    }", "CodeBleu_score": 71.0298954887387}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    this.connectionTimeoutMs = 30 * 1000;\n    this.client = CuratorFrameworkFactory.newClient(this.serverAddr, this.retryPolicy);\n    if (this.authority != null) {\n        this.client = this.client.authorization(\"digest\", this.authority.getBytes()).build();\n    }\n    this.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState state) {\n            if (state == ConnectionState.LOST) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n            } else if (state == ConnectionState.CONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n            } else if (state == ConnectionState.RECONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n            }\n        }\n    });\n    this.client.start();\n    try {\n        this.client.blockUntilConnected(this.connectionTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 69.37765608943225}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    removeTargetChildListener(path, listener);\n}", "CodeBleu_score": 14.271502618973619}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> listeners = this.listeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            this.removeTargetChildListener(path, targetListener);\n        }\n    }\n}", "CodeBleu_score": 76.61972157743642}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    removeTargetChildListener(path, listener);\n    removeTargetChildListener(path, listener);\n}", "CodeBleu_score": 18.361550878645655}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (zh == NULL) {\n        return QCONF_ERR_OTHER;\n    }\n\n    char *idc = NULL;\n    char *host = NULL;\n    int ret = lock_ht_find(g_idc_host_ht, g_idc_host_ht_mu, zh, idc);\n    if (ret != QCONF_OK) {\n        return ret;\n    }\n    ret = lock_ht_find(g_idc_host_ht, g_idc_host_ht_mu, zh, host);\n    if (ret != QCONF_OK) {\n        return ret;\n    }\n    lock_ht_delete(g_idc_host_ht, g_idc_host_ht_mu, zh);\n    lock_ht_delete(g_idc_host_ht, g_idc_host_ht_mu, zh);\n\n    zookeeper_close(zh);\n    zh = zookeeper_init(host, watcher_global, 10000, 0, (void *)idc, 0);\n    if (zh == NULL) {\n        return QCONF_ERR_OTHER;\n    }\n\n    ret = init_zk_env(zh);\n    if (ret != QCONF_OK) {\n        return ret;\n    }\n\n    ret = reset_table_watcher();\n    if (ret != QCONF_OK) {\n        return ret;\n    }\n\n    return QCONF_OK;\n}", "CodeBleu_score": 41.97946951407278}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // Update internal tables with the handle and host information\n    lock_ht_update(zk_handle_ht, zk_handle_mu, zh, idc_host);\n    lock_ht_update(zk_host_ht, zk_host_mu, idc_host, zh);\n\n    // Check the connection state of the Zookeeper handle\n    int state = zoo_state(zh);\n    if (state != ZOO_CONNECTED_STATE) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    int ret = zoo_create(zh, ZK_REGISTER_PATH, idc_host.c_str(), idc_host.size(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n    if (ret != ZOK) {\n        return;\n    }\n\n    // Set a watcher on the notify node\n    ret = zoo_wexists(zh, ZK_NOTIFY_PATH, notify_watcher, NULL, NULL);\n    if (ret != ZOK) {\n        // Add the IDC to a gray list if the operation fails\n        lock_ht_update(zk_gray_list_ht, zk_gray_list_mu, idc, 1);\n        LOG_ERROR(\"zoo_wexists failed, ret=%d, idc=%s\", ret, idc.c_str());\n        return;\n    }\n}", "CodeBleu_score": 54.13374042168404}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // Update internal tables with the handle and host information\n    zk_handle_to_host[zh] = idc_host;\n    zk_host_to_handle[idc_host] = zh;\n\n    // Check the connection state of the Zookeeper handle\n    if (!zk_is_connected(zh)) {\n        return;\n    }\n\n    // Register the current host on the Zookeeper server\n    int ret = zoo_create(zh, ZK_REGISTER_PATH, idc_host.c_str(), idc_host.size(),\n                         &ZOO_OPEN_ACL_UNSAFE, ZOO_EPHEMERAL, NULL, 0);\n    if (ret != ZOK) {\n        // Log an error if the operation fails\n        LOG(ERROR) << \"Failed to register host on Zookeeper server: \" << zerror(ret);\n        return;\n    }\n\n    // Set a watcher on the notify node\n    ret = zoo_wexists(zh, ZK_NOTIFY_PATH, watcher_func, NULL, NULL);\n    if (ret != ZOK) {\n        // Add the IDC to a gray list if the operation fails\n        gray_list.insert(idc);\n        LOG(ERROR) << \"Failed to set watcher on notify node: \" << zerror(ret);\n    }\n}", "CodeBleu_score": 44.85515101818367}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    zk_handle_to_idc_host_ht[zh] = idc_host;\n    zk_handle_to_idc_ht[zh] = idc;\n    int ret = zoo_state(zh);\n    if (ret != ZOO_CONNECTED_STATE) {\n        return;\n    }\n    ret = zoo_create(zh, notify_node.c_str(), \"\", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n    if (ret != ZOK && ret != ZNODEEXISTS) {\n        LOG_ERROR(\"zoo_create failed, ret: %d, errno: %d, idc: %s, idc_host: %s\", ret, errno, idc.c_str(), idc_host.c_str());\n        return;\n    }\n    ret = zoo_wexists(zh, notify_node.c_str(), watch_notify, NULL, NULL);\n    if (ret != ZOK) {\n        LOG_ERROR(\"zoo_wexists failed, ret: %d, errno: %d, idc: %s, idc_host: %s\", ret, errno, idc.c_str(), idc_host.c_str());\n        return;\n    }\n    if (ret == ZOK) {\n        gray_list_add(idc);\n    }\n}", "CodeBleu_score": 48.98856665852123}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    import hashlib\n    import base64\n    # Combine the username and password\n    credential = username + \":\" + password\n    # Hash the credential using SHA-1\n    hashed_credential = hashlib.sha1(credential.encode()).digest()\n    # Encode the hashed credential in base64\n    encoded_credential = base64.b64encode(hashed_credential).decode()\n    # Return the credential in the format \"username:base64_hash\"\n    return username + \":\" + encoded_credential\n\n\n", "CodeBleu_score": 50.19425014545275}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    import hashlib\n    import base64\n\n    # Combine the username and password\n    credential = username + \":\" + password\n\n    # Hash the credential using SHA-1\n    hashed_credential = hashlib.sha1(credential.encode()).digest()\n\n    # Encode the hash in base64\n    encoded_credential = base64.b64encode(hashed_credential).decode()\n\n    # Return the credential in the format \"username:base64_hash\"\n    return username + \":\" + encoded_credential\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.19425014545275}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    import hashlib\n    import base64\n    # Combine the username and password\n    combined = username + \":\" + password\n    # Hash the combined string using SHA-1\n    hashed = hashlib.sha1(combined.encode()).digest()\n    # Encode the hash in base64\n    encoded = base64.b64encode(hashed).decode()\n    # Return the credential in the format \"username:base64_hash\"\n    return username + \":\" + encoded\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 50.275695356854044}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = \"/\".join([self.processing_element.lock_path, self.name])\n    with self.processing_element.zk_client.Lock(lock_path):\n        lock_value = self.processing_element.zk_client.get(lock_path)[0]\n        return lock_value == self.instance_id\n\n\n\n", "CodeBleu_score": 44.02086382052317}, {"code": "def holds_lock(self)\n\t\n    if (self.zk_client is None):\n        return False\n    lock_path = self.get_lock_path()\n    try:\n        (lock_value, _) = self.zk_client.get(lock_path)\n    except Exception:\n        return False\n    return (lock_value == self.instance_id)", "CodeBleu_score": 32.36329452772302}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element.get_lock_path(self.id)\n    with self.processing_element.lock:\n        lock_value = self.processing_element.zk.get(lock_path)[0].decode(\"utf-8\")\n        return lock_value == self.id\n\n\n", "CodeBleu_score": 49.68835595336557}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock():\n        with self.client.transaction() as transaction:\n            transaction.delete(self._lock_path)\n            transaction.delete(self.path)\n            self.processing_element = None\n        return True\n    return False", "CodeBleu_score": 39.18048749636133}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, _ = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=lock_id)\n    with self.client.transaction() as transaction:\n        transaction.check(lock_path, self.id)\n        transaction.delete(lock_path)\n        transaction.delete(entry_path)\n    self.processing_element = None\n    return True", "CodeBleu_score": 61.11099579419994}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock:\n        with self.client.transaction() as transaction:\n            transaction.delete(self.lock_path)\n            transaction.delete(self.path)\n        self.processing_element = None\n        return True\n    return False", "CodeBleu_score": 37.21303546756065}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except socket.timeout:\n        return\n    except Exception as exc:\n        self.logger.exception(\"Exception raised during read_header\")\n        self.client._stopped.set()\n        return\n\n    self.logger.log(BLATHER, \"Read header: %s\", header)\n\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Received ping\")\n        self.client._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        self._read_auth(header, buffer, offset)\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 50.75556388646477}, {"code": "def _read_socket(self, read_timeout)\n\t\n    header, buffer, offset = self._read_header(read_timeout)\n    if header.xid == PING_XID:\n        self.logger.debug(\"Received ping\")\n        self.clear_outstanding_ping()\n    elif header.xid == AUTH_XID:\n        self.logger.debug(\"Received auth response\")\n        if header.err:\n            self.auth_exception = EXCEPTIONS[header.err]()\n        else:\n            self.auth_exception = None\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self.logger.debug(\"Received response: %r\", header)\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 45.38316479617378}, {"code": "def _read_socket(self, read_timeout)\n\t\n    header, buffer, offset = self._read_header(read_timeout)\n    if header.xid == PING_XID:\n        self.logger.debug(\"Received ping\")\n        self._outstanding_ping = False\n    elif header.xid == AUTH_XID:\n        self._handle_auth_response(header, buffer, offset)\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n    else:\n        self.logger.debug(\"Received header: %r\", header)\n        self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 40.151632729722934}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    try:\n        self.retry(self.connect)\n    except:\n        self.logger.warning(\"Failed to connect to ZK\")\n        return\n    self.logger.info(\"Connected to ZK\")\n    self.connection_stopped.wait()\n    self.logger.info(\"Stopping ZK loop\")\n    self.trigger_session_callback(zk.WatchedEvent(type=zk.WatchedEvent.SESSION_STATE_CHANGED, state=zk.WatchedEvent.SESSION_CLOSED_STATE))\n\n\n\n", "CodeBleu_score": 36.87484353512495}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.log.info(\"Attempting to connect to ZK\")\n            self.zk.start()\n            self.zk.add_listener(self.session_callback)\n            self.connection_stopped.wait()\n            self.log.info(\"ZK connection stopped\")\n        except Exception:\n            self.log.warning(\"ZK connection failed\", exc_info=True)\n            self.connection_stopped.wait(1)\n        self.zk.stop()\n        self.zk.close()\n        self.session_callback(state=KazooState.LOST)\n    self.log.info(\"Stopping ZK loop\")\n\n\n\n\n", "CodeBleu_score": 46.59643150031887}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.log.debug(\"Connecting to ZK\")\n            self.zk.start()\n            self.log.debug(\"Connected to ZK\")\n            break\n        except (NoNodeError, NodeExistsError):\n            self.log.warning(\"ZK connection failed, retrying...\")\n            self.zk.stop()\n            self.zk.close()\n            self.zk = KazooClient(hosts=self.zk_hosts, connection_retry=self.zk_retry_policy)\n            if not self.stopped.wait(timeout=1):\n                continue\n            else:\n                self.log.info(\"Stopping ZK loop\")\n                self.connection_stopped.set()\n                self.session_callback(state=KeeperState.CLOSED)\n                return\n        except Exception as e:\n            self.log.warning(\"ZK connection failed, retrying...\")\n            self.zk.stop()\n            self.zk.close()\n            self.zk = KazooClient(hosts=self.zk_hosts, connection_retry=self.zk_retry_policy)\n            if not self.stopped.wait(timeout=1):\n                continue\n            else:\n                self.log.info(\"Stopping ZK loop\")\n                self.connection_stopped.set()\n                self.session_callback(state=KeeperState.CLOSED)\n                return\n    self.log.info(\"ZK loop started\")\n    self.connection_stopped.set()\n    self.session_callback(state=KeeperState.CONNECTED)\n    self.zk.add_listener(self.session_callback)\n    self.zk.stop_loop()\n    self.log.info(\"Stopping ZK loop\")\n    self.connection_stopped.set()\n    self.session_callback(state=KeeperState.CLOSED)\n\n\n\n", "CodeBleu_score": 38.88146387328}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_partitions = sorted(partitions)\n    sorted_members = sorted(members)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::self.num_workers]\n\n\n", "CodeBleu_score": 29.129874821823147}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    idx = members.index(identifier)\n    return partitions[idx::len(members)]", "CodeBleu_score": 33.50856907528368}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    index = sorted_members.index(identifier)\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    except Exception:\n        self._best_effort_cleanup()\n        raise\n    else:\n        self._best_effort_cleanup()\n\n", "CodeBleu_score": 43.251689773887485}, {"code": "def leave(self)\n\t\n    self._retry(self.client.set, self.create_path, False)\n    self.participating = False\n    try:\n        self._retry(self.client.delete, self.create_path)\n    except NoNodeError:\n        pass\n    self._best_effort_cleanup()\n\n", "CodeBleu_score": 44.25377613072079}, {"code": "def leave(self)\n\t\n    self._leave()\n    self._best_effort_cleanup()\n    self.participating = False", "CodeBleu_score": 23.220708597596364}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t  try {\n    if (!isRunning()) {\n      LOG.info(\"Starting HDFS over FTP server...\");\n      server.start();\n      LOG.info(\"HDFS over FTP server started successfully.\");\n      return Result.SUCCESS;\n    } else {\n      LOG.info(\"HDFS over FTP server is already running.\");\n      return Result.SUCCESS;\n    }\n  } catch (Exception e) {\n    LOG.error(\"Error starting HDFS over FTP server\", e);\n    return Result.FAILURE;\n  }\n}", "CodeBleu_score": 34.92305218301387}, {"code": "public Result start(){\n\t    try {\n        if (isRunning()) {\n            return Result.success(\"HDFS over FTP server is already running.\");\n        } else {\n            // Start the HDFS over FTP server\n            startServer();\n            return Result.success(\"HDFS over FTP server started successfully.\");\n        }\n    } catch (Exception e) {\n        return Result.error(\"Failed to start HDFS over FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 30.747239177649305}, {"code": "public Result start(){\n\t    try {\n        if (!isRunning()) {\n            startServer();\n        }\n        return Result.success();\n    } catch (Exception e) {\n        return Result.error(e);\n    }\n}", "CodeBleu_score": 28.29081730180047}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t    try {\n        if (server.isRunning()) {\n            server.stop();\n            return Result.success();\n        } else {\n            return Result.failure(\"The FTP server is not running.\");\n        }\n    } catch (Exception e) {\n        LOG.error(\"Error while stopping the FTP server: \" + e.getMessage());\n        return Result.failure(\"Error while stopping the FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 38.83709565740097}, {"code": "public Result stop(){\n\t    if (isRunning()) {\n        try {\n            ftpServer.stop();\n            return new Result(true, \"Server stopped\");\n        } catch (Exception e) {\n            log.error(\"Error stopping server\", e);\n            return new Result(false, \"Error stopping server\");\n        }\n    } else {\n        return new Result(false, \"Server is not running\");\n    }\n}", "CodeBleu_score": 33.861291230651574}, {"code": "public Result stop(){\n\t  if (ftpServer.isStopped()) {\n    return new Result(\"FTP server is already stopped\", Result.Status.FAILED);\n  }\n  try {\n    ftpServer.stop();\n    return new Result(\"FTP server stopped successfully\", Result.Status.SUCCESS);\n  } catch (Exception e) {\n    logger.error(\"Error while stopping FTP server\", e);\n    return new Result(\"Error while stopping FTP server\", Result.Status.FAILED);\n  }\n}", "CodeBleu_score": 35.40644115023147}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    List<Authority> authorities = getAuthorities();\n\n    // Check for no authorities at all\n    if (authorities == null) {\n        return null;\n    }\n\n    boolean someoneCouldAuthorize = false;\n    for (Authority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            someoneCouldAuthorize = true;\n\n            request = authority.authorize(request);\n\n            // Authorization failed, return null\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n\n    if (someoneCouldAuthorize) {\n        return request;\n    } else {\n        return null;\n    }\n}", "CodeBleu_score": 76.37074268764901}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    // Check if there are any authorities available\n    if (authorities == null) {\n        return null;\n    }\n\n    // Flag to track if at least one authority could authorize the request\n    boolean someoneCouldAuthorize = false;\n\n    // Iterate through each authority\n    for (Authority authority : authorities) {\n        // Check if the authority can authorize the request\n        if (authority.canAuthorize(request)) {\n            // Set the flag to true\n            someoneCouldAuthorize = true;\n\n            // Update the request with the result of the authorization\n            request = authority.authorize(request);\n\n            // If authorization failed, return null\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n\n    // If at least one authority could authorize the request, return the updated request\n    if (someoneCouldAuthorize) {\n        return request;\n    }\n\n    // Otherwise, return null\n    return null;\n}", "CodeBleu_score": 63.266265800760166}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    List<Authority> authorities = getAuthorities();\n\n    // check for no authorities at all\n    if (authorities == null) {\n        return null;\n    }\n\n    boolean someoneCouldAuthorize = false;\n    for (Authority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            someoneCouldAuthorize = true;\n\n            request = authority.authorize(request);\n\n            // authorization failed, return null\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n\n    if (someoneCouldAuthorize) {\n        return request;\n    } else {\n        return null;\n    }\n}", "CodeBleu_score": 76.37074268764901}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t  try {\n    FileSystem fs = FileSystem.get(getConf());\n    return fs.mkdirs(new Path(fullPath));\n  }\n catch (  IOException e) {\n    e.printStackTrace();\n    return false;\n  }\n}", "CodeBleu_score": 65.75347724217572}, {"code": "public boolean mkdir(){\n\t  try {\n    FileSystem fs=FileSystem.get(URI.create(hdfsPath),conf);\n    return fs.mkdirs(new Path(hdfsPath));\n  }\n catch (  IOException e) {\n    e.printStackTrace();\n    return false;\n  }\n}", "CodeBleu_score": 62.100658597245385}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = FileSystem.get(conf);\n        return fs.mkdirs(new Path(fullPath));\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.00291300026532}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem dfs = HdfsOverFtpSystem.getDfs();\n        dfs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 94.76795996911564}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem dfs = HdfsOverFtpSystem.getDfs();\n        dfs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 94.76795996911564}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem dfs = HdfsOverFtpSystem.getDfs();\n        dfs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 94.76795996911564}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\t\ttry {\n\t\t\tFileSystem fs = FileSystem.get(conf);\n\t\t\tfs.rename(new Path(ftpFile.getAbsolutePath()), new Path(path.toString() + \"/\" + ftpFile.getName()));\n\t\t\treturn true;\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\treturn false;\n\t\t}\n\t}", "CodeBleu_score": 65.95411974507529}, {"code": "public boolean move(FtpFile ftpFile){\n\t\t\ttry {\n\t\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\t\tPath newPath = new Path(path.getParent(), ftpFile.getName());\n\t\t\tfs.rename(path, newPath);\n\t\t\treturn true;\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\treturn false;\n\t\t}\n\t}", "CodeBleu_score": 61.230048547561665}, {"code": "public boolean move(FtpFile ftpFile){\n\t\t\ttry {\n\t\t\tFileSystem fs = FileSystem.get(URI.create(path.toString()), conf);\n\t\t\tfs.rename(path, new Path(ftpFile.getParentDirectory(), ftpFile.getName()));\n\t\t\treturn true;\n\t\t} catch (IOException e) {\n\t\t\te.printStackTrace();\n\t\t\treturn false;\n\t\t}\n\t}", "CodeBleu_score": 62.23411141590878}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t\t\tList<FtpFile> files = new ArrayList<>();\n\t\tFileStatus[] fss;\n\t\ttry {\n\t\t\tfss = fs.listStatus(path);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"listFiles error\", e);\n\t\t\treturn null;\n\t\t}\n\n\t\tString basePath = path.toString();\n\t\tif (!basePath.endsWith(File.separator)) {\n\t\t\tbasePath += File.separator;\n\t\t}\n\n\t\tfor (FileStatus fs : fss) {\n\t\t\tString name = fs.getPath().toString();\n\t\t\tname = name.substring(basePath.length());\n\t\t\tif (fs.isDirectory()) {\n\t\t\t\tname += File.separator;\n\t\t\t}\n\t\t\tfiles.add(new HdfsFtpFile(name, fs));\n\t\t}\n\n\t\treturn Collections.unmodifiableList(files);\n\t}", "CodeBleu_score": 32.276308409801516}, {"code": "public List<FtpFile> listFiles(){\n\t\t\ttry {\n\t\t\tFileSystem fs = FileSystem.get(conf);\n\t\t\tPath f = path;\n\t\t\tif (!fs.exists(f)) {\n\t\t\t\treturn null;\n\t\t\t}\n\n\t\t\tFileStatus[] stats = fs.listStatus(f);\n\t\t\tFtpFile[] files = new FtpFile[stats.length];\n\t\t\tString base = path.toString();\n\t\t\tif (!base.endsWith(\"/\")) {\n\t\t\t\tbase = base + \"/\";\n\t\t\t}\n\t\t\tint j = 0;\n\t\t\tfor (FileStatus stat : stats) {\n\t\t\t\tString name = stat.getPath().toString();\n\t\t\t\tif (name.startsWith(base)) {\n\t\t\t\t\tname = name.substring(base.length());\n\t\t\t\t}\n\t\t\t\tfiles[j++] = new HdfsFtpFile(name, stat);\n\t\t\t}\n\t\t\treturn Collections.unmodifiableList(Arrays.asList(files));\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"listFiles error\", e);\n\t\t\treturn null;\n\t\t}\n\t}", "CodeBleu_score": 40.37332201569291}, {"code": "public List<FtpFile> listFiles(){\n\t\t\ttry {\n\t\t\tFileSystem fs = FileSystem.get(context.getConf());\n\t\t\tFileStatus[] status = fs.listStatus(path);\n\t\t\tFtpFile[] files = new FtpFile[status.length];\n\t\t\tfor (int i = 0; i < status.length; i++) {\n\t\t\t\tfiles[i] = new HdfsFile(path.toString(), status[i]);\n\t\t\t}\n\n\t\t\treturn Arrays.asList(files);\n\t\t} catch (IOException e) {\n\t\t\tLOG.error(\"listFiles error\", e);\n\t\t\treturn null;\n\t\t}\n\t}", "CodeBleu_score": 36.845043131451185}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\t\tconfigured = true;\n\n\t\tuserDataProp = new Properties();\n\n\t\ttry {\n\t\t\tFile userDataFile = new File(userDataFilePath);\n\n\t\t\tif (userDataFile.exists()) {\n\t\t\t\tFileInputStream fis = new FileInputStream(userDataFile);\n\t\t\t\tuserDataProp.load(fis);\n\t\t\t\tfis.close();\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\"Failed to load user data file \"\n\t\t\t\t\t+ userDataFilePath, e);\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\t}", "CodeBleu_score": 54.9095757712606}, {"code": "public void configure(){\n\t\t\ttry {\n\t\t\tFile userDataFile = new File(userDataFilePath);\n\n\t\t\tif (!userDataFile.exists()) {\n\t\t\t\tuserDataFile.createNewFile();\n\t\t\t}\n\n\t\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\"Failed to load user data file \"\n\t\t\t\t\t+ userDataFilePath, e);\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\n\t\tconfigured = true;\n\t}", "CodeBleu_score": 34.82719982899215}, {"code": "public void configure(){\n\t\t\tconfigured = true;\n\n\t\tuserDataProp = new Properties();\n\n\t\ttry {\n\t\t\tFile userDataFile = new File(userDataPath);\n\n\t\t\tif (userDataFile.exists()) {\n\t\t\t\tFileInputStream fis = new FileInputStream(userDataFile);\n\t\t\t\tuserDataProp.load(fis);\n\t\t\t\tfis.close();\n\t\t\t}\n\t\t} catch (IOException e) {\n\t\t\tthrow new FtpServerConfigurationException(\"Failed to load user data from \"\n\t\t\t\t\t+ userDataPath, e);\n\t\t}\n\n\t\tconvertDeprecatedPropertyNames();\n\t}", "CodeBleu_score": 54.34732771057125}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t    String parent = userDataFile.getParent();\n    if (parent != null) {\n        File parentDir = new File(parent);\n        if (!parentDir.exists()) {\n            if (!parentDir.mkdirs()) {\n                throw new FtpException(FtpReply.REPLY_550_REQUESTED_ACTION_NOT_TAKEN, \"Unable to create parent directories for user data file\");\n            }\n        }\n    }\n    try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n        userData.store(fos, \"FTP Server User Data\");\n    } catch (IOException e) {\n        LOG.error(\"Failed to save user data\", e);\n        throw new FtpException(FtpReply.REPLY_550_REQUESTED_ACTION_NOT_TAKEN, \"Failed to save user data\");\n    }\n}", "CodeBleu_score": 38.768532869390086}, {"code": "private void saveUserData() throws FtpException{\n\t  File parent = userDataFile.getParentFile();\n  if (!parent.exists()) {\n    if (!parent.mkdirs()) {\n      throw new FtpException(FtpException.CONFIGURATION_PROBLEM, \"Unable to create directory for user data file\");\n    }\n  }\n  try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n    fos.write(userData.getBytes(StandardCharsets.UTF_8));\n  }\n catch (  IOException e) {\n    LOG.error(\"Error saving user data\", e);\n    throw new FtpException(FtpException.LOCAL_ERROR, \"Error saving user data\");\n  }\n}", "CodeBleu_score": 36.27804136296853}, {"code": "private void saveUserData() throws FtpException{\n\t  File userDataFile = new File(userDataFilePath);\n  if (!userDataFile.getParentFile().exists() && !userDataFile.getParentFile().mkdirs()) {\n    throw new FtpException(\"Could not create directory for user data file\");\n  }\n  try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n    fos.write(userData.getBytes(StandardCharsets.UTF_8));\n  } catch (IOException e) {\n    LOG.error(\"Failed to save user data\", e);\n    throw new FtpException(\"Failed to save user data\", e);\n  }\n}", "CodeBleu_score": 36.855603519332895}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t        try {\n            HdfsUserManager userManagerFactory = new HdfsUserManager();\n            userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n            userManagerFactory.delete(user);\n            return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n        }catch (Exception e) {\n            log.error(e);\n            return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n        }\n    }", "CodeBleu_score": 82.49668658648332}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager userManagerFactory = new HdfsUserManager();\n        userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n        userManagerFactory.delete(user);\n        return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    } catch (Exception e) {\n        log.error(e);\n        return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 82.52989637751922}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager userManagerFactory = new HdfsUserManager();\n        userManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n        userManagerFactory.delete(user);\n        return new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    } catch (Exception e) {\n        log.error(e);\n        return new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 82.52989637751922}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t        LOG.info(\"open: \" + path + \" bufferSize: \" + bufferSize);\n        path = qualify(path);\n        try {\n            return new FSDataInputStream(\n                    new BufferedInputStream(\n                            new FileInputStream(\n                                    new File(path.toUri().getPath()))));\n        } catch (Exception e) {\n            LOG.warn(\"open: \" + path + \" bufferSize: \" + bufferSize, e);\n            return null;\n        }\n    }", "CodeBleu_score": 35.859902211023034}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t        LOG.warn(\"Opening \" + path + \" with buffer size \" + bufferSize);\n        path = qualify(path);\n        try {\n            return new FSDataInputStream(new BufferedInputStream(store.open(path), bufferSize));\n        } catch (Exception e) {\n            LOG.warn(\"Exception opening \" + path, e);\n            return null;\n        }\n    }", "CodeBleu_score": 33.09454139308393}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t        LOG.warn(\"Opening \" + path + \" with buffer size \" + bufferSize);\n        Path qualifiedPath = qualify(path);\n        try {\n            return new FSDataInputStream(\n                    new BufferedInputStream(\n                            seaweedFileSystemStore.open(qualifiedPath), bufferSize));\n        } catch (Exception e) {\n            LOG.warn(\"Failed to open \" + path, e);\n            return null;\n        }\n    }", "CodeBleu_score": 32.14486667496005}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"rename path: {} => {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    Path adjustedDst = dst;\n\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n    return true;\n}", "CodeBleu_score": 99.91986673198495}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"rename path: {} => {}\", src, dst);\n\n    if (src.isRoot()) {\n        return false;\n    }\n\n    if (src.equals(dst)) {\n        return true;\n    }\n\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    Path adjustedDst = dst;\n\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n    return true;\n}", "CodeBleu_score": 99.91986673198495}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    // Log the rename operation\n    LOG.debug(\"rename path: {} => {}\", src, dst);\n\n    // Check if the source is the root\n    if (src.isRoot()) {\n        return false;\n    }\n\n    // Check if the source and destination are the same\n    if (src.equals(dst)) {\n        return true;\n    }\n\n    // Look up the destination entry\n    FilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\n    // Adjust the destination path if the entry exists and is a directory\n    Path adjustedDst = dst;\n    if (entry != null) {\n        FileStatus dstFileStatus = getFileStatus(dst);\n        String sourceFileName = src.getName();\n        if (!dstFileStatus.isDirectory()) {\n            return false;\n        }\n        adjustedDst = new Path(dst, sourceFileName);\n    }\n\n    // Qualify both the source and adjusted destination paths\n    Path qualifiedSrcPath = qualify(src);\n    Path qualifiedDstPath = qualify(adjustedDst);\n\n    // Perform the rename operation using the file system store\n    seaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n\n    // Return true if the rename is successful\n    return true;\n}", "CodeBleu_score": 99.96446340328713}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t  capability = capability.toLowerCase();\n  if (capability.equals(\"hsync\")) {\n    return supportFlush;\n  }\n else   if (capability.equals(\"hflush\")) {\n    return supportFlush;\n  }\n else {\n    return false;\n  }\n}", "CodeBleu_score": 36.189901122603615}, {"code": "public boolean hasCapability(String capability){\n\t  String cap = capability.toLowerCase();\n  if (cap.equals(\"hflush\")) {\n    return supportFlush;\n  }\n else   if (cap.equals(\"hsync\")) {\n    return supportSync;\n  }\n  return false;\n}", "CodeBleu_score": 31.380168780236804}, {"code": "public boolean hasCapability(String capability){\n\t    if (capability.toLowerCase().equals(\"hflush\")) {\n        return supportFlush;\n    } else if (capability.toLowerCase().equals(\"hsync\")) {\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 33.1834753848918}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t        if (offset <= lastFlushOffset) {\n            return;\n        }\n        if (writtenBytes.size() == 0) {\n            return;\n        }\n        try {\n            filerClient.write(fileHandle, offset, writtenBytes);\n        } catch (Throwable e) {\n            throw new IOException(e);\n        }\n        lastFlushOffset = offset;\n        writtenBytes.clear();\n    }", "CodeBleu_score": 41.53590310102007}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset < lastFlushOffset) {\n        throw new IOException(\"Flush offset \" + offset + \" is less than last flush offset \" + lastFlushOffset);\n    }\n    if (offset > lastFlushOffset) {\n        try {\n            filerClient.write(path, offset, writtenBytes.size(), writtenBytes);\n        } catch (Throwable t) {\n            throw new IOException(t);\n        }\n        lastFlushOffset = offset;\n    }\n}", "CodeBleu_score": 42.29014486788254}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t        if (offset <= lastFlushOffset) {\n            return;\n        }\n\n        if (offset > lastWrittenOffset) {\n            return;\n        }\n\n        if (lastWrittenOffset - offset > MAX_WRITE_BUFFER_SIZE) {\n            throw new IOException(\"flushWrittenBytesToServiceInternal: \" +\n                    \"lastWrittenOffset - offset > MAX_WRITE_BUFFER_SIZE\");\n        }\n\n        long start = System.currentTimeMillis();\n        long len = lastWrittenOffset - offset;\n        try {\n            filerClient.write(handle, offset,\n                    writtenBytes.subList((int) offset, (int) (offset + len)));\n        } catch (Exception e) {\n            throw new IOException(e);\n        }\n        long end = System.currentTimeMillis();\n        LOG.info(\"flushWrittenBytesToServiceInternal: \" +\n                \"flush written bytes from offset \" + offset + \" to offset \" + lastWrittenOffset +\n                \" to service in \" + (end - start) + \" ms\");\n\n        lastFlushOffset = lastWrittenOffset;\n    }", "CodeBleu_score": 36.70324953039146}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    bufferToWrite.flip();\n    int length = bufferToWrite.limit();\n\n    ensureWriteOperationQueueNotOverloaded();\n\n    final WriteOperation writeOperation = new WriteOperation(writePosition, length,\n        completionService.submit(new Callable<Object>() {\n            public Object call() throws IOException {\n                try {\n                    fileChannel.write(bufferToWrite, writePosition);\n                } finally {\n                    bufferToWrite.clear();\n                }\n                return null;\n            }\n        }));\n\n    writeOperations.add(writeOperation);\n    lastTotalAppendOffset += length;\n    return length;\n}", "CodeBleu_score": 42.487363476774675}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    if (lastError != null) {\n        throw lastError;\n    }\n\n    bufferToWrite.flip();\n    final int length = bufferToWrite.limit();\n    if (writeOperations.size() >= maxWriteOperations) {\n        waitForTaskToComplete();\n    }\n\n    final WriteOperation writeOperation = new WriteOperation(writePosition, length);\n    final Future<Integer> task = completionService.submit(new WriteTask(bufferToWrite, writeOperation));\n    writeOperation.task = task;\n    writeOperations.add(writeOperation);\n    return length;\n}", "CodeBleu_score": 38.1263883803974}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t        final int length = bufferToWrite.limit();\n        bufferToWrite.flip();\n        final WriteOperation writeOperation = new WriteOperation(length, writePosition, service.submit(new Callable<Void>() {\n            @Override\n            public Void call() throws Exception {\n                service.write(bufferToWrite, writePosition);\n                bufferToWrite.clear();\n                return null;\n            }\n        }));\n        writeOperations.add(writeOperation);\n        shrinkWriteOperationQueue();\n        return length;\n    }", "CodeBleu_score": 41.473029989807294}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        try {\n            Future<Integer> result = completionService.take();\n            if (result != null) {\n                if (result.get() == -1) {\n                    return;\n                }\n            }\n        } catch (InterruptedException e) {\n            throw new IOException(\"Interrupted while waiting for task to complete\", e);\n        } catch (ExecutionException e) {\n            throw new IOException(\"Error while waiting for task to complete\", e);\n        }\n    }\n}", "CodeBleu_score": 28.78834447127075}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        Future<Integer> result = completionService.poll();\n        if (result == null) {\n            break;\n        }\n        try {\n            result.get();\n        } catch (InterruptedException | ExecutionException e) {\n            throw new IOException(e);\n        }\n    }\n}", "CodeBleu_score": 27.719759325022665}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (completionService.poll() == null) {\n            try {\n                Thread.sleep(10);\n            } catch (InterruptedException e) {\n                throw new IOException(\"Interrupted while waiting for task to complete\", e);\n            }\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(\"Interrupted while waiting for task to complete\", e);\n    }\n}", "CodeBleu_score": 29.985116148371453}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t  while (!writeOperationQueue.isEmpty()) {\n    WriteOperation writeOperation = writeOperationQueue.peek();\n    if (writeOperation.isDone()) {\n      writeOperationQueue.poll();\n      totalAppendOffset += writeOperation.getLength();\n    } else {\n      break;\n    }\n  }\n}", "CodeBleu_score": 26.792983111133413}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t  Iterator<WriteOperation> iter = writeOperationQueue.iterator();\n  while (iter.hasNext()) {\n    WriteOperation op = iter.next();\n    if (op.isDone()) {\n      totalAppendOffset += op.getLength();\n      iter.remove();\n    }\n  }\n}", "CodeBleu_score": 24.443488310720568}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t  Iterator<WriteOperation> iterator = writeOperationQueue.iterator();\n  while (iterator.hasNext()) {\n    WriteOperation writeOperation = iterator.next();\n    try {\n      writeOperation.getFuture().get();\n    } catch (InterruptedException e) {\n      throw new IOException(e);\n    } catch (ExecutionException e) {\n      throw new IOException(e);\n    }\n    totalAppendOffset += writeOperation.getLength();\n    iterator.remove();\n  }\n}", "CodeBleu_score": 30.252578434267786}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\t\tif (user == null) {\n\t\t\tthrow new IllegalArgumentException(\"User can't be null\");\n\t\t}\n\t\tif (user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"Home directory can't be null\");\n\t\t}\n\t\thomePath = user.getHomeDirectory();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 67.53534410193676}, {"code": "protected HdfsFileSystemView(User user){\n\t\t\tif (user == null) {\n\t\t\tthrow new IllegalArgumentException(\"User can't be null\");\n\t\t}\n\t\tif (user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"User home can't be null\");\n\t\t}\n\t\tthis.homePath = user.getHomeDirectory();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 73.30714624013352}, {"code": "protected HdfsFileSystemView(User user){\n\t\t\tsuper(user);\n\t\tif (user == null) {\n\t\t\tthrow new IllegalArgumentException(\"User can't be null\");\n\t\t}\n\t\tif (user.getHomeDirectory() == null) {\n\t\t\tthrow new IllegalArgumentException(\"Home directory can't be null\");\n\t\t}\n\t\thomePath = user.getHomeDirectory();\n\t\tthis.user = user;\n\t}", "CodeBleu_score": 66.82391117335646}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath = Paths.get(dir);\n    if (!newPath.isAbsolute()) {\n        newPath = currentPath.resolve(newPath);\n    }\n    if (newPath.normalize().startsWith(rootPath)) {\n        if (Files.isDirectory(newPath)) {\n            currentPath = newPath.normalize();\n            return true;\n        }\n    }\n    return false;\n}", "CodeBleu_score": 19.73530154281657}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = Path.of(dir);\n    } else {\n        newPath = currentPath.resolve(dir);\n    }\n    if (newPath.startsWith(rootPath)) {\n        currentPath = newPath;\n        return true;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 20.90493977317002}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t  Path newPath = null;\n  if (dir.startsWith(\"/\")) {\n    newPath = Paths.get(dir);\n  } else {\n    newPath = Paths.get(currentPath.toString(), dir);\n  }\n  if (newPath.getParent() == null) {\n    return false;\n  }\n  if (Files.isDirectory(newPath)) {\n    currentPath = newPath;\n    return true;\n  } else {\n    return false;\n  }\n}", "CodeBleu_score": 25.82333833947849}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(\"seaweedfs.access.mode\", \"direct\");\n}", "CodeBleu_score": 34.69581495711102}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.volumeServerAccessMode = conf.get(VOLUME_SERVER_ACCESS_MODE, \"direct\");\n    this.filerClient = new FilerClient(host, port, grpcPort);\n}", "CodeBleu_score": 38.43808227925953}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t  this.host = host;\n  this.port = port;\n  this.grpcPort = grpcPort;\n  this.conf = conf;\n  this.filerClient = new FilerClient(host, port, grpcPort);\n  this.accessMode = conf.get(SeaweedFileSystem.ACCESS_MODE, SeaweedFileSystem.ACCESS_MODE_DEFAULT);\n}", "CodeBleu_score": 32.672455837275635}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n        LOG.debug(\"Opening file for read: {}\", path);\n\n        FilerProto.Entry entry = lookupEntry(path);\n\n        if (entry == null) {\n\n            throw new FileNotFoundException(path.toString());\n\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n    }", "CodeBleu_score": 74.2782073019549}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n        LOG.info(\"Opening {} for read\", path);\n\n        FilerProto.Entry entry = lookupEntry(path);\n\n        if (entry == null) {\n\n            throw new FileNotFoundException(\"File \" + path + \" could not be found.\");\n\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n    }", "CodeBleu_score": 73.06796742287767}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\n        LOG.info(\"Opening file for read: {}\", path);\n\n        FilerProto.Entry entry = lookupEntry(path);\n\n        if (entry == null) {\n\n            throw new FileNotFoundException(path.toString());\n\n        }\n\n        return new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n    }", "CodeBleu_score": 73.86997519378573}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    this.hostName = InetAddress.getLocalHost().getHostName();\n  }\n catch (  Exception e) {\n    this.hostName = \"localhost\";\n  }\n  this.mapThreads = conf.getInt(MRJobConfig.NUM_MAPS, 1);\n  this.filesPerThread = conf.getInt(MRJobConfig.NUM_FILES_PER_THREAD, 1);\n  this.threadPool = Executors.newFixedThreadPool(this.mapThreads, new ThreadFactory() {\n    private int count=0;\n    public Thread newThread(    Runnable r) {\n      Thread t = new Thread(r);\n      t.setDaemon(true);\n      t.setName(\"MRJobThread-\" + (count++));\n      return t;\n    }\n  }\n);\n}", "CodeBleu_score": 46.22649198235043}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  this.hostname = getLocalHostName();\n  this.numThreadsPerMap = conf.getInt(NUM_THREADS_PER_MAP, 1);\n  this.numFilesPerThread = conf.getInt(NUM_FILES_PER_THREAD, 1);\n  this.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 22.830496303869012}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    this.localHostName = InetAddress.getLocalHost().getHostName();\n  }\n catch (  Exception e) {\n    this.localHostName=\"localhost\";\n  }\n  this.numThreadsPerMap = conf.getInt(NUM_THREADS_PER_MAP,1);\n  this.numFilesPerThread = conf.getInt(NUM_FILES_PER_THREAD,1);\n  this.threadPool = Executors.newFixedThreadPool(this.numThreadsPerMap,new DaemonThreadFactory());\n}", "CodeBleu_score": 37.24454538602227}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    if (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\");\n    }\n  }", "CodeBleu_score": 94.23896749872512}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    if (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\");\n    }\n  }", "CodeBleu_score": 94.23896749872512}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    if (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\n      return;\n    }\n    try {\n      UserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\n      emptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        JuiceFileSystemImpl fs = new JuiceFileSystemImpl();\n        fs.initialize(uri, conf);\n        return fs;\n      });\n      BgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n    } catch (Exception e) {\n      throw new IOException(\"start trash failed!\");\n    }\n  }", "CodeBleu_score": 94.23896749872512}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t    String currentContext = getContext();\n    if (currentContext == null || currentContext.isEmpty()) {\n        currentContext = context;\n    } else if (!currentContext.contains(context)) {\n        currentContext += \",\" + context;\n    }\n    setContextInternal(currentContext);\n}", "CodeBleu_score": 24.1960817866931}, {"code": "public static void setContext(String context) throws Exception{\n\t    String currentContext = getContext();\n    if (currentContext == null || currentContext.equals(\"\")) {\n        currentContext = context;\n    } else if (currentContext.indexOf(context) == -1) {\n        currentContext = currentContext + \",\" + context;\n    }\n    setCallerContext(currentContext);\n}", "CodeBleu_score": 23.499275647026057}, {"code": "public static void setContext(String context) throws Exception{\n\t    CallerContext callerContext = CallerContext.getCallerContext();\n    if (callerContext == null) {\n        callerContext = new CallerContext(context);\n    } else {\n        if (callerContext.getSignature() == null) {\n            callerContext.setSignature(context);\n        } else {\n            callerContext.setSignature(callerContext.getSignature() + \",\" + context);\n        }\n    }\n    CallerContext.setCallerContext(callerContext);\n}", "CodeBleu_score": 36.37432708939298}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  int ret = hdfsDelete(hdfs_, uri.to_path().c_str());\n  if (ret == -1) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file \") + uri.to_string()));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 65.92407472413755}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  int ret = hdfsDelete(hdfs_, uri.c_str(), 0);\n  if (ret < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file \") + uri.c_str() + \"; \" +\n        hdfsGetLastError()));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 61.071502000324365}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  int ret = hdfsDelete(hdfs_, uri.to_path().c_str(), 0);\n  if (ret < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file \") + uri.to_string()));\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 71.80365783274293}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (!file) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to open HDFS file \") + uri.to_string()));\n  }\n  if (libhdfs_->hdfsFlush(fs, file)) {\n    libhdfs_->hdfsCloseFile(fs, file);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to flush HDFS file \") + uri.to_string()));\n  }\n  libhdfs_->hdfsCloseFile(fs, file);\n  return Status::Ok();\n}", "CodeBleu_score": 62.76002849391252}, {"code": "Status HDFS::sync(const URI& uri){\n\t  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (!file) {\n    return LOG_STATUS(Status_HDFSError(\"Cannot open file\"));\n  }\n  if (libhdfs_->hdfsFlush(fs, file)) {\n    libhdfs_->hdfsCloseFile(fs, file);\n    return LOG_STATUS(Status_HDFSError(\"Cannot flush file\"));\n  }\n  libhdfs_->hdfsCloseFile(fs, file);\n  return Status::Ok();\n}", "CodeBleu_score": 54.01911847700562}, {"code": "Status HDFS::sync(const URI& uri){\n\t  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(&fs));\n  int ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n  if (ret) {\n    return Status::Ok();\n  }\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (!file) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot open file \") + uri.to_string() + \" for syncing\"));\n  }\n  if (libhdfs_->hdfsFlush(fs, file)) {\n    libhdfs_->hdfsCloseFile(fs, file);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to flush file \") + uri.to_string()));\n  }\n  libhdfs_->hdfsCloseFile(fs, file);\n  return Status::Ok();\n}", "CodeBleu_score": 69.0253106760516}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  int ret = 0;\n  hdfsFileInfo* fileInfo = hdfsGetPathInfo(hdfs_, uri.to_path().c_str());\n  if (fileInfo == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to get file info for \" + uri.to_string())));\n  }\n  if (fileInfo->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(fileInfo, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to get file info for \" + uri.to_string())));\n  }\n  *nbytes = fileInfo->mSize;\n  hdfsFreeFileInfo(fileInfo, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 56.943074293253325}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to get file info for '\" + uri.to_string() + \"'\")));\n  }\n  if (!file_info->mKind == kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Path '\" + uri.to_string() + \"' is not a file\")));\n  }\n  *nbytes = file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 54.18770296508375}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Failed to get file info for \" + uri.to_string())));\n  }\n  if (file_info->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Path is not a file: \" + uri.to_string())));\n  }\n  *nbytes = file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 54.558874698870774}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String[] cfgParts = hbaseCfgString.split(\"\\\\|\");\n    String quorum = cfgParts[0];\n    String znodeParent = cfgParts.length > 1 ? cfgParts[1] : \"/hbase\";\n    if (!quorum.contains(\":\")) {\n        quorum += \":2181\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 24.53197967037031}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String[] cfgParts = hbaseCfgString.split(\";\");\n    String quorum = null;\n    String znodeParent = null;\n    for (String part : cfgParts) {\n        String[] keyValue = part.split(\"=\");\n        if (keyValue.length != 2) {\n            continue;\n        }\n        String key = keyValue[0].trim();\n        String value = keyValue[1].trim();\n        if (key.equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n            quorum = value;\n        } else if (key.equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n            znodeParent = value;\n        }\n    }\n    if (quorum == null) {\n        throw new IllegalArgumentException(\"HBase configuration string does not contain a valid quorum.\");\n    }\n    if (!quorum.contains(\":\")) {\n        quorum += \":2181\";\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 33.89352428437596}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t  String quorum = \"\";\n  String znodeParent = \"\";\n  String[] cfgPairs = hbaseCfgString.split(\",\");\n  for (String cfgPair : cfgPairs) {\n    String[] parts = cfgPair.split(\"=\");\n    if (parts.length != 2) {\n      continue;\n    }\n    String key = parts[0].trim();\n    String value = parts[1].trim();\n    if (key.equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n      quorum = value;\n      if (!quorum.contains(\":\")) {\n        quorum += \":2181\";\n      }\n    }\n else {\n      if (key.equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n        znodeParent = value;\n      }\n    }\n  }\n  if (quorum.isEmpty()) {\n    throw new IllegalArgumentException(\"HBase configuration string does not contain a valid Zookeeper quorum.\");\n  }\n  if (znodeParent.isEmpty()) {\n    znodeParent = \"/hbase\";\n  }\n  return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 33.14112733972952}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    Connection conn = getJdbcConnection(cfg);\n    try {\n        String namespace = cfg.getNamespace();\n        String tableName = cfg.getTable();\n        boolean isThinClient = cfg.isThinClient();\n        checkTable(conn, namespace, tableName, isThinClient);\n        PTable tableSchema = getTableSchema(conn, namespace + \".\" + tableName);\n        List<String> columnNames = tableSchema.getColumns().stream().map(Column::getName).collect(Collectors.toList());\n        List<String> configuredColumnNames = cfg.getColumn();\n        for (String configuredColumnName : configuredColumnNames) {\n            if (!columnNames.contains(configuredColumnName)) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                        \"The configured column '\" + configuredColumnName + \"' does not exist in the target table '\" + namespace + \".\" + tableName + \"'.\");\n            }\n        }\n    } catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                \"An error occurred while validating the configuration for HbaseSQLWriter.\", e);\n    } finally {\n        try {\n            if (conn != null) {\n                conn.close();\n            }\n        } catch (SQLException e) {\n            LOG.warn(\"Failed to close JDBC connection.\", e);\n        }\n    }\n}", "CodeBleu_score": 46.48738446430379}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    Connection conn = null;\n    try {\n        conn = getJdbcConnection(cfg);\n        checkTable(conn, cfg.getNamespace(), cfg.getTable(), cfg.isThinClient());\n        PTable tableSchema = getTableSchema(conn, cfg.getNamespace() + \".\" + cfg.getTable());\n        for (String column : cfg.getColumns()) {\n            if (tableSchema.getColumn(column) == null) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXISTS,\n                        String.format(\"The column [%s] does not exist in table [%s]\", column, cfg.getTable()));\n            }\n        }\n    } catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR, \"Failed to validate configuration for HbaseSQLWriter\", e);\n    } finally {\n        if (conn != null) {\n            try {\n                conn.close();\n            } catch (SQLException e) {\n                LOG.warn(\"Failed to close JDBC connection\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 43.66304561662379}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    Connection conn = null;\n    try {\n        conn = getJdbcConnection(cfg);\n        checkTable(conn, cfg.getNamespace(), cfg.getTable(), cfg.isThinClient());\n        PTable tableSchema = getTableSchema(conn, cfg.getNamespace() + \".\" + cfg.getTable());\n        Set<String> tableColumns = tableSchema.getColumns().stream().map(ColumnInfo::getName).collect(Collectors.toSet());\n        Set<String> configuredColumns = cfg.getColumn().stream().map(Column::getName).collect(Collectors.toSet());\n        if (!tableColumns.containsAll(configuredColumns)) {\n            throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                    \"The configured columns do not exist in the target table.\");\n        }\n    } catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                \"An error occurred while validating the configuration.\", e);\n    } finally {\n        if (conn != null) {\n            try {\n                conn.close();\n            } catch (SQLException e) {\n                LOG.warn(\"Failed to close JDBC connection.\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 47.20275480431167}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t  if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n    try {\n      UserGroupInformation.setConfiguration(new Configuration());\n      UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n    }\n catch (    IOException e) {\n      log.error(\"Kerberos login error\", e);\n      throw new RuntimeException(\"Kerberos login error\");\n    }\n  }\n}", "CodeBleu_score": 36.09395591834842}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (!kerberosPrincipal.isBlank() && !kerberosKeytabFilePath.isBlank()) {\n        UserGroupInformation.setConfiguration(new Configuration());\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            log.error(\"Kerberos login error\", e);\n            throw new RuntimeException(\"Kerberos login error\");\n        }\n    }\n}", "CodeBleu_score": 32.783990088694146}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (!kerberosPrincipal.isEmpty() && !kerberosKeytabFilePath.isEmpty()) {\n        System.setProperty(\"java.security.krb5.conf\", \"/etc/krb5.conf\");\n        Configuration conf = new Configuration();\n        conf.set(\"hadoop.security.authentication\", \"kerberos\");\n        conf.set(\"hadoop.security.authorization\", \"true\");\n        UserGroupInformation.setConfiguration(conf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOGGER.error(\"Kerberos login error: {}\", e.getMessage());\n            throw new RuntimeException(\"Kerberos login error\");\n        }\n    }\n}", "CodeBleu_score": 46.749034793095326}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        int numColumns = metaData.getColumnCount();\n        for (int i = 1; i <= numColumns; i++) {\n            String colName = metaData.getColumnLabel(i);\n            String colType = metaData.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Column name or type is null\");\n            }\n            colTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colType));\n        }\n        return colTypeMap;\n    }", "CodeBleu_score": 42.303192148271954}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypes = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int colCount = rsmd.getColumnCount();\n        for (int i = 1; i <= colCount; i++) {\n            String colName = rsmd.getColumnLabel(i);\n            String colType = rsmd.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Null column name or type encountered\");\n            }\n            colTypes.put(colName, new ThinClientPTable.ThinClientPColumn(colType));\n        }\n        return colTypes;\n    }", "CodeBleu_score": 41.15014779542294}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int colCount = rsmd.getColumnCount();\n    for (int i = 1; i <= colCount; i++) {\n        String colName = rsmd.getColumnLabel(i);\n        if (colName == null) {\n            throw new SQLException(\"Column name is null\");\n        }\n        int colType = rsmd.getColumnType(i);\n        if (colType == Types.NULL) {\n            throw new SQLException(\"Column type is null\");\n        }\n        colTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n    }\n    return colTypeMap;\n}", "CodeBleu_score": 43.43306676407298}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    PhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n        checkTable(admin, hTableName);\n        // \u6e05\u7a7a\u8868\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // \u6e05\u7a7a\u8868\u5931\u8d25\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 98.91872507973358}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    PhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n        checkTable(admin, hTableName);\n        // \u6e05\u7a7a\u8868\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // \u6e05\u7a7a\u8868\u5931\u8d25\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 98.91872507973358}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    PhoenixConnection sqlConn;\n    Admin admin = null;\n    try {\n        sqlConn = conn.unwrap(PhoenixConnection.class);\n        admin = sqlConn.getQueryServices().getAdmin();\n        TableName hTableName = getTableName(tableName);\n        // \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n        checkTable(admin, hTableName);\n        // \u6e05\u7a7a\u8868\n        admin.disableTable(hTableName);\n        admin.truncateTable(hTableName, true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (Throwable t) {\n        // \u6e05\u7a7a\u8868\u5931\u8d25\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n                \"Failed to truncate \" + tableName + \".\", t);\n    } finally {\n        if (admin != null) {\n            closeAdmin(admin);\n        }\n    }\n}", "CodeBleu_score": 98.91872507973358}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    try {\n        if (checkHdfsFileType(filePath, fileType)) {\n            LOG.info(\"File [{}] type is [{}]\", filePath, fileType);\n            sourceFiles.add(filePath);\n        } else {\n            String message = String.format(\"File [%s] type is not [%s]\", filePath, fileType);\n            LOG.error(message);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n        }\n    } catch (Exception e) {\n        String message = String.format(\"Can not get the file format for [%s]\uff0cit only supports [%s].\",\n                filePath, HdfsConstant.SUPPORT_FILE_TYPE);\n        LOG.error(message);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message, e);\n    }\n}", "CodeBleu_score": 47.17548037719851}, {"code": "private void addSourceFileByType(String filePath){\n\t        try {\n            if (checkHdfsFileType(filePath, specifiedFileType)) {\n                LOG.info(\"Add source file: {}\", filePath);\n                sourceFiles.add(filePath);\n            } else {\n                String message = String.format(\"File type of %s is not %s\", filePath, specifiedFileType);\n                LOG.error(message);\n                throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n            }\n        } catch (Exception e) {\n            LOG.error(\"Failed to add source file: {}\", filePath, e);\n            throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, e);\n        }\n    }", "CodeBleu_score": 48.02964646486334}, {"code": "private void addSourceFileByType(String filePath){\n\t    if (checkHdfsFileType(filePath, fileType)) {\n        LOG.info(\"The file {} is of the specified file type {}.\", filePath, fileType);\n        sourceFiles.add(filePath);\n    } else {\n        String message = String.format(\"The file %s is not of the specified file type %s.\", filePath, fileType);\n        LOG.error(message);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n    }\n}", "CodeBleu_score": 40.58546402504229}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"Start to read sequence file: {}\", sourceSequenceFilePath);\n        try {\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, new Path(sourceSequenceFilePath), readerSliceConfig);\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                String valueStr = value.toString();\n                if (StringUtils.isNotBlank(valueStr)) {\n                    StorageReaderUtil.transportRecord(recordSender, taskPluginCollector, key.toString(), valueStr);\n                }\n            }\n        } catch (Exception e) {\n            LOG.error(\"Failed to read sequence file: {}\", sourceSequenceFilePath);\n            throw new AddaxException(AddaxException.TASK_HANDLE_FAIL, e.getMessage());\n        }\n    }", "CodeBleu_score": 51.71998405286915}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        try {\n            LOG.info(\"Start to read sequence file from: {}\", sourceSequenceFilePath);\n            FileSystem fs = FileSystem.get(readerSliceConfig);\n            Path path = new Path(sourceSequenceFilePath);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n            Text key = new Text();\n            Text value = new Text();\n            while (reader.next(key, value)) {\n                if (value.getLength() > 0) {\n                    StorageReaderUtil.transportRecord(key.toString(), value.toString(), recordSender, taskPluginCollector);\n                }\n            }\n            reader.close();\n        } catch (IOException e) {\n            LOG.error(\"Failed to read sequence file from: {}\", sourceSequenceFilePath);\n            throw new AddaxException(AddaxException.TASK_ERROR_CODE, \"Failed to read sequence file from: \" + sourceSequenceFilePath, e);\n        }\n    }", "CodeBleu_score": 53.148678332008295}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"Start to read sequence file: {}\", sourceSequenceFilePath);\n        try (SequenceFile.Reader reader = new SequenceFile.Reader(FileSystem.get(new Configuration()),\n                new Path(sourceSequenceFilePath), readerSliceConfig)) {\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n            while (reader.next(key, value)) {\n                if (value.getClass().getSimpleName().equals(\"NullWritable\")) {\n                    continue;\n                }\n                StorageReaderUtil.transportRecord(key, value, recordSender, taskPluginCollector);\n            }\n        } catch (Exception e) {\n            LOG.error(\"Failed to read sequence file: {}\", sourceSequenceFilePath, e);\n            throw new AddaxException(AddaxException.TASK_ERROR, \"Failed to read sequence file: \" + sourceSequenceFilePath, e);\n        }\n    }", "CodeBleu_score": 49.284460345409215}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t        try {\n            FileSystem fs = FileSystem.get(hadoopConf);\n            Path file = new Path(filepath);\n            if (!fs.exists(file)) {\n                throw new FileNotFoundException(\"File not found: \" + filepath);\n            }\n\n            FSDataInputStream in = fs.open(file);\n            boolean isFileType = false;\n            switch (specifiedFileType.toLowerCase()) {\n                case \"orc\":\n                    isFileType = isORCFile(file, fs, in);\n                    break;\n                case \"rc\":\n                    isFileType = isRCFile(filepath, in);\n                    break;\n                case \"sequence\":\n                    isFileType = isSequenceFile(file, in);\n                    break;\n                case \"parquet\":\n                    isFileType = isParquetFile(file);\n                    break;\n                case \"csv\":\n                    isFileType = isCSVFile(file, in);\n                    break;\n                case \"text\":\n                    isFileType = isTextFile(file, in);\n                    break;\n                default:\n                    throw new IllegalArgumentException(\"Unsupported file type: \" + specifiedFileType);\n            }\n            in.close();\n            return isFileType;\n        }\n        catch (IOException e) {\n            LOG.error(\"Error checking file type: \" + e.getMessage(), e);\n            throw new RuntimeException(\"Error checking file type\", e);\n        }\n    }", "CodeBleu_score": 35.027627202877795}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(hadoopConf);\n        FSDataInputStream in = fs.open(new Path(filepath));\n        switch (specifiedFileType) {\n            case \"ORC\":\n                return isORCFile(new Path(filepath), fs, in);\n            case \"RC\":\n                return isRCFile(filepath, in);\n            case \"SEQUENCE\":\n                return isSequenceFile(new Path(filepath), in);\n            case \"PARQUET\":\n                return isParquetFile(new Path(filepath));\n            case \"CSV\":\n                return isCsvFile(filepath, in);\n            case \"TEXT\":\n                return isTextFile(filepath, in);\n            default:\n                LOG.info(\"The file [{}] is not [{}] file.\", filepath, specifiedFileType);\n                return false;\n        }\n    }\n    catch (IOException e) {\n        LOG.info(\"The file [{}] is not [{}] file.\", filepath, specifiedFileType);\n        return false;\n    }\n}", "CodeBleu_score": 38.156744319958115}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        // Create a Path object from the file path\n        Path path = new Path(filepath);\n\n        // Get the FileSystem object for the Hadoop configuration\n        FileSystem fs = path.getFileSystem(hadoopConf);\n\n        // Open the file for reading\n        FSDataInputStream in = fs.open(path);\n\n        // Check the file type based on the specified type\n        switch (specifiedFileType.toLowerCase()) {\n            case \"orc\":\n                return isORCFile(path, fs, in);\n            case \"rc\":\n                return isRCFile(filepath, in);\n            case \"sequence\":\n                return isSequenceFile(path, in);\n            case \"parquet\":\n                return isParquetFile(path);\n            case \"csv\":\n                return isCSVFile(filepath, in);\n            case \"text\":\n                return isTextFile(filepath, in);\n            default:\n                throw new Exception(\"Unsupported file type: \" + specifiedFileType);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error while checking file type: {}\", e.getMessage());\n        throw new RuntimeException(\"Error while checking file type\", e);\n    } catch (Exception e) {\n        LOG.error(\"Error while checking file type: {}\", e.getMessage());\n        throw new RuntimeException(\"Error while checking file type\", e);\n    }\n}", "CodeBleu_score": 41.223081651608865}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new HBaseException(HBaseErrorCode.HBASE_CLOSE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 53.65740349523595}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new CustomException(ErrorCode.HBASE_CONNECTION_CLOSE_ERROR);\n        }\n    }\n}", "CodeBleu_score": 47.37523978782352}, {"code": "public static void closeConnection(Connection hConnection){\n\t    try {\n        if (hConnection != null) {\n            hConnection.close();\n        }\n    } catch (IOException e) {\n        throw new HBaseException(HBaseErrorCode.CONNECTION_CLOSE_FAILED);\n    }\n}", "CodeBleu_score": 50.38089108487005}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new RuntimeException(ErrorCode.HBASE_ADMIN_CLOSE_ERROR, \"Error while closing HBase Admin\", e);\n        }\n    }\n}", "CodeBleu_score": 50.83114217445108}, {"code": "public static void closeAdmin(Admin admin){\n\t  if (admin != null) {\n    try {\n      admin.close();\n    }\n catch (    IOException e) {\n      throw new RuntimeException(\"Failed to close HBase Admin\", e);\n    }\n  }\n}", "CodeBleu_score": 38.09426652933985}, {"code": "public static void closeAdmin(Admin admin){\n\t  if (admin != null) {\n    try {\n      admin.close();\n    }\n catch (    IOException e) {\n      throw new HBaseException(e, \"Error while closing HBase admin\");\n    }\n  }\n}", "CodeBleu_score": 34.21576177257999}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t    String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n    String columnFamily = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n    String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n    String columnValue = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n    long timestamp = cell.getTimestamp();\n\n    Type rowKeyType = Type.STRING;\n    String rowKeyFormat = null;\n    if (rowKeyTypeMapping.containsKey(rowKey)) {\n        rowKeyType = rowKeyTypeMapping.get(rowKey);\n        rowKeyFormat = rowKeyFormatMapping.get(rowKey);\n    }\n\n    Type columnValueType = Type.STRING;\n    String columnValueFormat = null;\n    if (columnValueTypeMapping.containsKey(columnFamily)) {\n        columnValueType = columnValueTypeMapping.get(columnFamily);\n        columnValueFormat = columnValueFormatMapping.get(columnFamily);\n    }\n\n    record.addColumn(rowKey, rowKeyType, rowKeyFormat, rowKey);\n    record.addColumn(columnFamily, Type.STRING, null, columnFamily);\n    record.addColumn(qualifier, Type.STRING, null, qualifier);\n    record.addColumn(\"timestamp\", Type.LONG, null, timestamp);\n    record.addColumn(columnFamily, columnValueType, columnValueFormat, columnValue);\n}", "CodeBleu_score": 41.02137257304177}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t    String rowKey = Bytes.toString(cell.getRowArray(), cell.getRowOffset(), cell.getRowLength());\n    String columnFamily = Bytes.toString(cell.getFamilyArray(), cell.getFamilyOffset(), cell.getFamilyLength());\n    String qualifier = Bytes.toString(cell.getQualifierArray(), cell.getQualifierOffset(), cell.getQualifierLength());\n    long timestamp = cell.getTimestamp();\n    String value = Bytes.toString(cell.getValueArray(), cell.getValueOffset(), cell.getValueLength());\n    // Add row key as a column\n    record.addColumn(rowKey, rowKey);\n    // Add family and qualifier as columns\n    record.addColumn(columnFamily, columnFamily);\n    record.addColumn(qualifier, qualifier);\n    // Add timestamp as a column\n    record.addColumn(String.valueOf(timestamp), timestamp);\n    // Add value as a column\n    record.addColumn(value, value);\n}", "CodeBleu_score": 26.047193340362956}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        // Extract the row key, timestamp, column family, qualifier, and value from the cell\n        byte[] rowKey = cell.getRowArray();\n        long timestamp = cell.getTimestamp();\n        byte[] family = cell.getFamilyArray();\n        byte[] qualifier = cell.getQualifierArray();\n        byte[] value = cell.getValueArray();\n\n        // Determine the types and formats for the row key and column value based on predefined mappings\n        String rowKeyType = \"STRING\";\n        String rowKeyFormat = \"TEXT\";\n        String columnValueType = \"STRING\";\n        String columnValueFormat = \"TEXT\";\n\n        // Convert the extracted data to the appropriate types and add them as columns to the record\n        record.addColumn(new Column(\"row_key\", rowKeyType, rowKeyFormat, rowKey));\n        record.addColumn(new Column(\"family\", \"STRING\", \"TEXT\", family));\n        record.addColumn(new Column(\"qualifier\", \"STRING\", \"TEXT\", qualifier));\n        record.addColumn(new Column(\"timestamp\", \"LONG\", \"TEXT\", timestamp));\n        record.addColumn(new Column(\"column_value\", columnValueType, columnValueFormat, value));\n    }", "CodeBleu_score": 23.169662252022995}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.get(Constants.USER_START_ROWKEY);\n    if (startRowkey == null || startRowkey.trim().isEmpty()) {\n        return new byte[0];\n    }\n    boolean isBinaryRowkey = configuration.getBoolean(Constants.USER_IS_BINARY_ROWKEY, false);\n    return stringToBytes(startRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 55.32723631078209}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.get(HBaseConstant.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    boolean isBinaryRowkey = configuration.getBoolean(HBaseConstant.IS_BINARY_ROWKEY, false);\n    return stringToBytes(startRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 61.51038422100936}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.get(Constants.START_ROWKEY);\n    boolean isBinaryRowkey = configuration.getBoolean(Constants.IS_BINARY_ROWKEY, false);\n\n    if (startRowkey.isEmpty()) {\n        return new byte[0];\n    }\n\n    return stringToBytes(startRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 54.7306161247069}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t  String startRowkey = configuration.get(Constants.INNER_START_ROWKEY);\n  if (startRowkey == null || startRowkey.length() == 0) {\n    return new byte[0];\n  }\n  return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 60.149614155862075}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t  String startRowkey = configuration.get(Constants.STARTROWKEY);\n  if (startRowkey == null || startRowkey.length() == 0) {\n    return new byte[0];\n  }\n  return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 59.824135239942564}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t  String startRowkey = configuration.get(Constant.STARTROWKEY);\n  if (StringUtils.isBlank(startRowkey)) {\n    return new byte[0];\n  }\n  return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 65.79749540270143}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    for (Header header : record.headers()) {\n        this.headers.put(header.key(), new String(header.value()));\n    }\n    this.data = record.value();\n}", "CodeBleu_score": 53.70319883216632}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 42.67385534550532}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    super(UUID.fromString(record.key()));\n    this.headers = new TbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 35.03436324428697}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerSettings settings = tbKafkaSettings.getTransportNotificationsMsgProducer();\n    String clientId = tbServiceId + \"-transport-notifications-msg-producer\";\n    String defaultTopic = tbTransportNotificationsSettings.getDefaultTopic();\n    TbKafkaProducerTemplate<String, byte[]> template = new TbKafkaProducerTemplate<>(settings, clientId, defaultTopic);\n    TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(template);\n    template.setAdmin(kafkaAdmin);\n    return producer;\n}", "CodeBleu_score": 46.21650306812429}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t  TbKafkaSettings settings = tbTransportNotificationProperties.getKafkaSettings();\n  TbKafkaClientId clientId = new TbKafkaClientId(settings.getClientIdPrefix(), tbServiceInfo.getId());\n  TbKafkaTopicName defaultTopic = new TbKafkaTopicName(tbTransportNotificationProperties.getDefaultTopic());\n  TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbKafkaProtoQueueProducer<>(settings, clientId, defaultTopic);\n  producer.setAdmin(createAdmin());\n  return producer;\n}", "CodeBleu_score": 41.58606147942954}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t  TbKafkaProducerTemplate<String, byte[]> kafkaProducerTemplate = new TbKafkaProducerTemplate<>(kafkaSettings, serviceId + \"-transport-notifications\", true, true);\n  TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbKafkaProtoQueueProducer<>(kafkaProducerTemplate, transportNotificationsSettings.getDefaultTopic());\n  producer.setAdmin(new TbKafkaAdmin(kafkaSettings, serviceId + \"-transport-notifications\"));\n  return producer;\n}", "CodeBleu_score": 36.8892903379238}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t  TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(kafkaSettings,\n      kafkaSettings.getToCoreNotificationsMsgTopic(), kafkaSettings.getClientId(),\n      kafkaSettings.getGroupId());\n  template.setMessageDecoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class));\n  template.configureConsumer(admin, statisticsService);\n  return template.getConsumer();\n}", "CodeBleu_score": 27.271156089926805}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(settings, topic, clientId, groupId);\n    template.setMessageDecoder(new TbProtoQueueMsgDecoder<>(new ToCoreNotificationMsg()));\n    template.configure(admin, statisticsService);\n    return template;\n}", "CodeBleu_score": 21.03513951584019}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t  TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(kafkaSettings, topic, clientId, groupId);\n  template.setMessageDecoder(new TbProtoMsgDecoder<>(ToCoreNotificationMsg.class));\n  return new TbQueueConsumer<>(template, admin, statisticsService);\n}", "CodeBleu_score": 17.683797375649444}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t  if (!topicNames.isEmpty()) {\n    for (String topicName : topicNames) {\n      if (!topicExists(topicName)) {\n        createTopic(topicName);\n      }\n      subscribe(topicName);\n    }\n  } else {\n    logger.info(\"No topics provided. Unsubscribing from all topics.\");\n    unsubscribe();\n  }\n}", "CodeBleu_score": 59.94061927907877}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t  if (!topicNames.isEmpty()) {\n    ensureTopicsExist(topicNames);\n    consumer.subscribe(topicNames);\n  } else {\n    LOGGER.info(\"No topics provided for subscription - unsubscribing\");\n    consumer.unsubscribe();\n  }\n}", "CodeBleu_score": 67.91039576291105}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t  if (!topicNames.isEmpty()) {\n    ensureTopicsExist(topicNames);\n    consumer.subscribe(topicNames);\n  } else {\n    log.info(\"No topics provided for subscription - unsubscribing\");\n    consumer.unsubscribe();\n  }\n}", "CodeBleu_score": 68.30028550424136}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t  Stopwatch stopwatch = Stopwatch.createStarted();\n  LOGGER.debug(\"Polling records from topic {} for {} ms\", topic, durationInMillis);\n  ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n  stopwatch.stop();\n  LOGGER.debug(\"Polled {} records from topic {} in {} ms\", records.count(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n  if (records.isEmpty()) {\n    return Collections.emptyList();\n  }\n  return StreamSupport.stream(records.spliterator(),false).collect(Collectors.toList());\n}", "CodeBleu_score": 53.90658615859398}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t  Stopwatch stopwatch = Stopwatch.createStarted();\n  LOG.info(\"Polling topic {} for {} ms\", topic, durationInMillis);\n  ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n  stopwatch.stop();\n  LOG.info(\"Polled topic {} for {} ms, found {} records\", topic, stopwatch.elapsed(TimeUnit.MILLISECONDS), records.count());\n  if (records.isEmpty()) {\n    return Collections.emptyList();\n  }\n  return records.records(topic).stream().collect(Collectors.toList());\n}", "CodeBleu_score": 53.443295920898606}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t  Stopwatch stopwatch = Stopwatch.createStarted();\n  log.debug(\"Polling records from topic {} for {} ms\", topic, durationInMillis);\n  ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n  stopwatch.stop();\n  log.debug(\"Polled {} records from topic {} in {} ms\", records.count(), topic, stopwatch.elapsed(TimeUnit.MILLISECONDS));\n  if (records.count() == 0) {\n    return Collections.emptyList();\n  }\n  return StreamSupport.stream(records.spliterator(),false).collect(Collectors.toList());\n}", "CodeBleu_score": 52.91983235302469}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (initializationError != null) {\n        log.warn(\"[{}] Failed to initialize Kafka producer: {}\", ctx.getSelfId(), initializationError);\n        ctx.tellFailure(msg, initializationError);\n        return;\n    }\n    try {\n        String topic = getTopic(ctx, msg);\n        String key = getKey(ctx, msg);\n        if (log.isDebugEnabled()) {\n            log.debug(\"[{}] Publishing message to Kafka topic: {} key: {}\", ctx.getSelfId(), topic, key);\n        }\n        publish(ctx, msg, topic, key);\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 38.40189232845898}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t        try {\n            String topicPattern = getTopicPattern(ctx);\n            String keyPattern = getKeyPattern(ctx);\n\n            if (topicPattern == null || keyPattern == null) {\n                log.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n                ctx.tellFailure(new TbRuleNodeException(\"Failed to process message: \" + msg, msg));\n                return;\n            }\n\n            String topic = substitutePattern(ctx, topicPattern, msg);\n            String key = substitutePattern(ctx, keyPattern, msg);\n\n            log.debug(\"[{}] Publishing message to Kafka: topic={}, key={}\", ctx.getSelfId(), topic, key);\n\n            if (initializationError != null) {\n                log.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n                ctx.tellFailure(new TbRuleNodeException(\"Failed to process message: \" + msg, msg));\n                return;\n            }\n\n            publish(ctx, msg, topic, key);\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n            ctx.tellFailure(new TbRuleNodeException(\"Failed to process message: \" + msg, msg));\n        }\n    }", "CodeBleu_score": 41.714564685783365}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        if (initializationError != null) {\n            log.error(\"[{}] Failed to initialize Kafka producer: {}\", ctx.getSelfId(), initializationError);\n            ctx.tellFailure(msg, initializationError);\n            return;\n        }\n        String topic = getTopic(ctx, msg);\n        String key = getKey(ctx, msg);\n        if (topic == null || key == null) {\n            log.error(\"[{}] Topic or key is null for message: {}\", ctx.getSelfId(), msg);\n            ctx.tellFailure(msg, new IllegalArgumentException(\"Topic or key is null for message: \" + msg));\n            return;\n        }\n        log.debug(\"[{}] Publishing message to Kafka: topic={}, key={}\", ctx.getSelfId(), topic, key);\n        CompletableFuture.runAsync(() -> publish(ctx, msg, topic, key), executor);\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 42.65730624615364}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t        if (addMetadataAsHeaders) {\n            Map<String, String> headers = new HashMap<>();\n            msg.getMetaData().forEach(entry -> headers.put(entry.getKey(), entry.getValue()));\n            ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, key, msg.getData(), headers);\n            kafkaTemplate.send(record).addCallback(new ListenableFutureCallback<>() {\n                @Override\n                public void onSuccess(SendResult<String, String> result) {\n                    processRecord(ctx, msg, result.getRecordMetadata(), null);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    processRecord(ctx, msg, null, ex);\n                }\n            });\n        } else {\n            kafkaTemplate.send(topic, key, msg.getData()).addCallback(new ListenableFutureCallback<>() {\n                @Override\n                public void onSuccess(SendResult<String, String> result) {\n                    processRecord(ctx, msg, result.getRecordMetadata(), null);\n                }\n\n                @Override\n                public void onFailure(Throwable ex) {\n                    processRecord(ctx, msg, null, ex);\n                }\n            });\n        }\n    }", "CodeBleu_score": 33.29304847017967}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t        try {\n            if (addMetadataAsHeaders) {\n                ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, key, msg.getData(), msg.getMetadata().values());\n                kafkaTemplate.send(record).addCallback(new ListenableFutureCallback<SendResult<String, String>>() {\n                    @Override\n                    public void onSuccess(SendResult<String, String> result) {\n                        processRecord(ctx, msg, result.getRecordMetadata(), null);\n                    }\n\n                    @Override\n                    public void onFailure(Throwable ex) {\n                        processRecord(ctx, msg, null, ex);\n                    }\n                });\n            } else {\n                ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, key, msg.getData());\n                kafkaTemplate.send(record).addCallback(new ListenableFutureCallback<SendResult<String, String>>() {\n                    @Override\n                    public void onSuccess(SendResult<String, String> result) {\n                        processRecord(ctx, msg, result.getRecordMetadata(), null);\n                    }\n\n                    @Override\n                    public void onFailure(Throwable ex) {\n                        processRecord(ctx, msg, null, ex);\n                    }\n                });\n            }\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to send message to Kafka topic: {}\", ctx.getTenantId(), e.getMessage());\n            tellFailure(ctx, processException(msg, e), e);\n        }\n    }", "CodeBleu_score": 39.34537994929992}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t        try {\n            if (addMetadataAsHeaders) {\n                ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, msg.getData().orElse(null), msg.getMetadata().getValues());\n                ctx.getKafkaTemplate().send(record).addCallback(new ListenableFutureCallback<>() {\n                    @Override\n                    public void onSuccess(SendResult<String, byte[]> result) {\n                        processRecord(ctx, msg, result.getRecordMetadata(), null);\n                    }\n\n                    @Override\n                    public void onFailure(Throwable ex) {\n                        processRecord(ctx, msg, null, ex);\n                    }\n                });\n            } else {\n                ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, msg.getData().orElse(null));\n                ctx.getKafkaTemplate().send(record).addCallback(new ListenableFutureCallback<>() {\n                    @Override\n                    public void onSuccess(SendResult<String, byte[]> result) {\n                        processRecord(ctx, msg, result.getRecordMetadata(), null);\n                    }\n\n                    @Override\n                    public void onFailure(Throwable ex) {\n                        processRecord(ctx, msg, null, ex);\n                    }\n                });\n            }\n        } catch (Exception e) {\n            log.debug(\"[{}] Failed to publish message: {}\", ctx.getId(), msg);\n            throw e;\n        }\n    }", "CodeBleu_score": 39.51871340580533}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer: \" + e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 53.484598597435436}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            LOG.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 67.80667025052485}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t  TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new TbKafkaProducerTemplateBuilder<>();\n  builder.setKafkaSettings(kafkaSettings);\n  builder.setClientId(serviceInfoProvider.getServiceId());\n  builder.setDefaultTopic(queueProps.getRuleEngineEventsTopic());\n  builder.setAdmin(admin);\n  return builder.build();\n}", "CodeBleu_score": 40.321699651952294}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = new TbKafkaProducerTemplateBuilder<>();\n    KafkaSettings kafkaSettings = tbKafkaSettings();\n    builder.setKafkaSettings(kafkaSettings);\n    builder.setClientId(serviceInfoProvider.getServiceInfo().getId());\n    builder.setDefaultTopic(kafkaSettings.getRuleEngineRequestsTopic());\n    builder.setAdmin(kafkaAdmin());\n    return builder.build();\n}", "CodeBleu_score": 42.204022210416234}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t  KafkaProducerTemplateBuilder<String, TbProtoQueueMsg<ToRuleEngineMsg>> builder = new KafkaProducerTemplateBuilder<>(KafkaSettings.builder().bootstrapServers(kafkaBootstrapServers).build(), serviceInfoProvider.getServiceId(), ruleEngineTopic, admin);\n  return builder.build();\n}", "CodeBleu_score": 34.53585972829561}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t        long timeout = kafkaConfig.getResponseTimeoutMs();\n        ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor();\n        executor.scheduleWithFixedDelay(() -> {\n            if (isStatsPrintRequired()) {\n                for (String groupId : kafkaConfig.getConsumerGroupIds()) {\n                    try {\n                        Map<TopicPartition, OffsetAndMetadata> groupOffsets = consumer.offsetsForTimes(getOffsetsForTimeRequest(groupId));\n                        Map<TopicPartition, Long> endOffsets = consumer.endOffsets(getEndOffsetsRequest(groupId));\n                        List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n                        if (!consumerGroupStats.isEmpty()) {\n                            log.info(\"Kafka consumer group [{}] lagging topics: {}\", groupId, consumerGroupStats);\n                        }\n                    } catch (Exception e) {\n                        log.warn(\"Failed to get consumer group [{}] lagging topics\", groupId, e);\n                    }\n                }\n            }\n        }, timeout, timeout, TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 36.864847743684145}, {"code": "private void startLogScheduling(){\n\t        long timeout = kafkaConsumerProperties.getProperties().getOrDefault(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 10000);\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.scheduleWithFixedDelay(() -> {\n            try {\n                if (isStatsPrintRequired()) {\n                    for (String groupId : kafkaConsumerProperties.getConsumerGroups()) {\n                        List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(getGroupOffsets(groupId), getEndOffsets(groupId));\n                        if (!consumerGroupStats.isEmpty()) {\n                            log.info(\"Consumer group [{}] has lagging topics: {}\", groupId, consumerGroupStats);\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Failed to log Kafka consumer group [{}] stats\", groupId, e);\n            }\n        }, timeout, timeout, TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 29.983281074838995}, {"code": "private void startLogScheduling(){\n\t        long timeout = kafkaConsumerProps.getResponseTimeoutMs();\n        ScheduledExecutorService scheduledExecutorService = Executors.newSingleThreadScheduledExecutor();\n        scheduledExecutorService.scheduleWithFixedDelay(() -> {\n            try {\n                if (isStatsPrintRequired()) {\n                    for (String groupId : kafkaConsumerProps.getConsumerGroups()) {\n                        Map<TopicPartition, OffsetAndMetadata> groupOffsets = consumer.committed(new ConsumerGroupMetadata(groupId));\n                        Map<TopicPartition, Long> endOffsets = consumer.endOffsets(groupOffsets.keySet());\n                        List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n                        if (!consumerGroupStats.isEmpty()) {\n                            log.info(\"[{}] {}\", groupId, consumerGroupStats);\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Failed to collect kafka consumer group statistics for groupId [{}]\", groupId, e);\n            }\n        }, timeout, timeout, TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 36.95883771895973}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t        Properties props = toProps();\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n        return props;\n    }", "CodeBleu_score": 89.50348007366593}, {"code": "protected Properties toAdminProps(){\n\t        Properties props = toProps();\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n        return props;\n    }", "CodeBleu_score": 89.50348007366593}, {"code": "protected Properties toAdminProps(){\n\t        Properties props = toProps();\n\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n\n        return props;\n    }", "CodeBleu_score": 89.50348007366593}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t\t// Create a MetricEvent with a scoped name and tags derived from the metric name and group.\n\t\tMetricEvent event = new MetricEvent(getScopedName(metricName, group), getTags(group));\n\n\t\t// Add the metric and its event to the corresponding collection.\n\t\tif (metric instanceof Counter) {\n\t\t\tcounterMetrics.put(metric, event);\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tgaugeMetrics.put(metric, event);\n\t\t} else if (metric instanceof Histogram) {\n\t\t\thistogramMetrics.put(metric, event);\n\t\t} else if (metric instanceof Meter) {\n\t\t\tmeterMetrics.put(metric, event);\n\t\t} else {\n\t\t\tLOG.warn(\"Metric type {} is not supported.\", metric.getClass().getSimpleName());\n\t\t}\n\t}", "CodeBleu_score": 55.407162368150466}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t\tString scopedName = getScopedName(metricName, group);\n\t\tMap<String, String> tags = getTags(group);\n\t\tMetricEvent event = new MetricEvent(scopedName, tags);\n\t\tif (metric instanceof Counter) {\n\t\t\tcounters.put(scopedName, (Counter) metric);\n\t\t\tcounterEvents.add(event);\n\t\t} else if (metric instanceof Gauge) {\n\t\t\tgauges.put(scopedName, (Gauge) metric);\n\t\t\tgaugeEvents.add(event);\n\t\t} else if (metric instanceof Histogram) {\n\t\t\thistograms.put(scopedName, (Histogram) metric);\n\t\t\thistogramEvents.add(event);\n\t\t} else if (metric instanceof Meter) {\n\t\t\tmeters.put(scopedName, (Meter) metric);\n\t\t\tmeterEvents.add(event);\n\t\t} else {\n\t\t\tLOG.warn(\"The metric type {} is not supported.\", metric.getClass());\n\t\t}\n\t}", "CodeBleu_score": 48.531805721247345}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\t\tString scopedName = getScopedName(metricName, group);\n\t\tMetricEvent event = new MetricEvent(scopedName, getTags(group));\n\t\tif (metric instanceof Counter) {\n\t\t\tcounterEvents.add(event);\n\t\t\tcounters.put(event, (Counter) metric);\n\t\t} else if (metric instanceof Gauge<?>) {\n\t\t\tgaugeEvents.add(event);\n\t\t\tgauges.put(event, (Gauge<?>) metric);\n\t\t} else if (metric instanceof Histogram) {\n\t\t\thistogramEvents.add(event);\n\t\t\thistograms.put(event, (Histogram) metric);\n\t\t} else if (metric instanceof Meter) {\n\t\t\tmeterEvents.add(event);\n\t\t\tmeters.put(event, (Meter) metric);\n\t\t} else {\n\t\t\tLOG.warn(\"Metric type {} not supported\", metric.getClass().getSimpleName());\n\t\t}\n\t}", "CodeBleu_score": 51.453726526166975}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t  Object value = gauge.getValue();\n  if (value != null) {\n    if (metricEvent.getFields() != null) {\n      metricEvent.getFields().put(field,value instanceof Number ? value : value.toString());\n    }\n else {\n      Map<String,Object> fields=new HashMap<>();\n      fields.put(field,value instanceof Number ? value : value.toString());\n      metricEvent.setFields(fields);\n    }\n  }\n  return metricEvent;\n}", "CodeBleu_score": 44.37612405390014}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t  Number value = gauge.getValue();\n  Map<String, Object> fields = metricEvent.getFields();\n  if (fields != null) {\n    fields.put(field,value);\n  }\n else {\n    Map<String,Object> newFields=new HashMap<>();\n    newFields.put(field,value);\n    metricEvent.setFields(newFields);\n  }\n  return metricEvent;\n}", "CodeBleu_score": 42.57080841846944}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t  Object value = gauge.getValue();\n  if (metricEvent.hasFields()) {\n    Map<String,Object> fields=metricEvent.getFields();\n    if (value instanceof Number) {\n      fields.put(field,value);\n    }\n else {\n      fields.put(field,value.toString());\n    }\n    metricEvent.setFields(fields);\n  }\n else {\n    Map<String,Object> fields=new HashMap<>();\n    if (value instanceof Number) {\n      fields.put(field,value);\n    }\n else {\n      fields.put(field,value.toString());\n    }\n    metricEvent.setFields(fields);\n  }\n  return metricEvent;\n}", "CodeBleu_score": 53.714192154765364}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t\tMap<String, Long> kafkaLagTimes = new HashMap<>();\n\t\tString[] components = gauge.getValue().toString().split(\",\");\n\t\tfor (String component : components) {\n\t\t\tString[] kafkaLag = component.split(\":\");\n\t\t\tString topic = kafkaLag[0].split(\"-\")[1];\n\t\t\tlong offset = Long.parseLong(kafkaLag[1].split(\":\")[1]);\n\t\t\tlong dataTimestamp = Long.parseLong(kafkaLag[2].split(\":\")[1]);\n\t\t\tlong committedOffset = Long.parseLong(kafkaLag[3].split(\":\")[1]);\n\t\t\tif (kafkaLagTimes.get(topic) != null && kafkaLagTimes.get(topic) == dataTimestamp) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tkafkaLagTimes.put(topic, dataTimestamp);\n\t\t\tmetricEvent.addField(topic + \"_current_offset\", offset);\n\t\t\tmetricEvent.addField(topic + \"_data_timestamp\", dataTimestamp);\n\t\t\tmetricEvent.addField(topic + \"_committed_offset\", committedOffset);\n\t\t}\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\treturn metricEvent;\n\t}", "CodeBleu_score": 42.06803220024307}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t\tString[] split = gauge.getValue().toString().split(\";\");\n\t\tString[] currentOffsets = split[0].split(\",\");\n\t\tString[] committedOffsets = split[1].split(\",\");\n\t\tString[] dataTimestamps = split[2].split(\",\");\n\t\tfor (int i = 0; i < currentOffsets.length; i++) {\n\t\t\tString topic = currentOffsets[i].split(\":\")[0];\n\t\t\tLong currentOffset = Long.valueOf(currentOffsets[i].split(\":\")[1]);\n\t\t\tLong committedOffset = Long.valueOf(committedOffsets[i].split(\":\")[1]);\n\t\t\tLong dataTimestamp = Long.valueOf(dataTimestamps[i].split(\":\")[1]);\n\t\t\tif (kafkaLagTimes.containsKey(topic)) {\n\t\t\t\tlong lastTimestamp = kafkaLagTimes.get(topic);\n\t\t\t\tif (lastTimestamp == dataTimestamp) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t}\n\t\t\tkafkaLagTimes.put(topic, dataTimestamp);\n\t\t\tmetricEvent.addField(\"current_offset_\" + topic, currentOffset);\n\t\t\tmetricEvent.addField(\"committed_offset_\" + topic, committedOffset);\n\t\t\tmetricEvent.addField(\"data_timestamp_\" + topic, dataTimestamp);\n\t\t}\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\treturn metricEvent;\n\t}", "CodeBleu_score": 36.4172706294128}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t\t// Extract the current offsets, data timestamp, and committed offsets from the gauge value\n\t\tString[] components = gauge.getValue().toString().split(\",\");\n\t\tlong currentOffsets = Long.parseLong(components[0].split(\":\")[1]);\n\t\tlong dataTimestamp = Long.parseLong(components[1].split(\":\")[1]);\n\t\tlong committedOffsets = Long.parseLong(components[2].split(\":\")[1]);\n\n\t\t// Check if the Kafka lag metrics have changed since the last update\n\t\tif (currentOffsets == metricEvent.getKafkaLagCurrentOffsets() &&\n\t\t\t\tdataTimestamp == metricEvent.getKafkaLagDataTimestamp() &&\n\t\t\t\tcommittedOffsets == metricEvent.getKafkaLagCommittedOffsets()) {\n\t\t\treturn metricEvent;\n\t\t}\n\n\t\t// Update the MetricEvent object with the new Kafka lag metrics\n\t\tmetricEvent.setKafkaLagCurrentOffsets(currentOffsets);\n\t\tmetricEvent.setKafkaLagDataTimestamp(dataTimestamp);\n\t\tmetricEvent.setKafkaLagCommittedOffsets(committedOffsets);\n\t\tmetricEvent.setTimestamp(timestamp);\n\n\t\t// Update the kafkaLagTimes map with the current timestamp\n\t\tkafkaLagTimes.put(metricEvent.getKafkaLagMetricName(), timestamp);\n\n\t\treturn metricEvent;\n\t}", "CodeBleu_score": 30.928041779967252}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t        Properties properties = buildKafkaProps();\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> offsetByTime = buildOffsetByTime(properties, env.getConfig().getConfiguration(), time);\n            properties.setProperty(\"auto.offset.reset\", \"none\");\n            FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n                    topic,\n                    new MetricSchema(),\n                    properties);\n            consumer.setStartFromSpecificOffsets(offsetByTime);\n            env.addSource(consumer).name(\"Kafka Source\");\n        }\n        return env.addSource(new FlinkKafkaConsumer<>(\n                topic,\n                new MetricSchema(),\n                properties)).name(\"Kafka Source\");\n    }", "CodeBleu_score": 56.83172746491568}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t        ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n        Properties props = buildKafkaProps(parameterTool);\n        FlinkKafkaConsumer<MetricEvent> consumer;\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> offsetByTime = buildOffsetByTime(props, parameterTool, time);\n            consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), offsetByTime);\n        } else {\n            consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), parameterTool.getProperties());\n        }\n        DataStreamSource<MetricEvent> source = env.addSource(consumer);\n        return source;\n    }", "CodeBleu_score": 72.99169789580642}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t        Properties props = buildKafkaProps();\n        FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n        if (time != null) {\n            Map<KafkaTopicPartition, Long> offsetByTime = buildOffsetByTime(props, env.getConfig().getGlobalJobParameters(), time);\n            consumer.setStartFromSpecificOffsets(offsetByTime);\n        }\n        return env.addSource(consumer);\n    }", "CodeBleu_score": 59.726791190215465}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t  String groupId = parameterTool.getRequired(\"group\");\n  props.setProperty(\"group.id\", groupId + \"_\" + time);\n  KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n  Map<String, List<PartitionInfo>> topics = consumer.listTopics();\n  List<PartitionInfo> partitions = topics.get(parameterTool.getRequired(\"topic\"));\n  Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n  for (PartitionInfo partitionInfo : partitions) {\n    timestampToSearch.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n  }\n  Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampToSearch);\n  Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n  for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n    TopicPartition key = entry.getKey();\n    OffsetAndTimestamp value = entry.getValue();\n    if (value != null) {\n      partitionOffsets.put(new KafkaTopicPartition(key.topic(), key.partition()), value.offset());\n    }\n  }\n  consumer.close();\n  return partitionOffsets;\n}", "CodeBleu_score": 53.43706891653923}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t  props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, \"offset-by-time-\" + time);\n  try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n    Map<TopicPartition, Long> partitionToTime = consumer.partitionsFor(parameterTool.getRequired(TOPIC_OPTION)).stream().collect(Collectors.toMap(tp -> new TopicPartition(tp.topic(), tp.partition()), tp -> time));\n    Map<TopicPartition, OffsetAndTimestamp> partitionToOffset = consumer.offsetsForTimes(partitionToTime);\n    return partitionToOffset.entrySet().stream().collect(Collectors.toMap(entry -> new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), entry -> entry.getValue().offset()));\n  }\n}", "CodeBleu_score": 41.68652598433849}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t  props.put(ConsumerConfig.GROUP_ID_CONFIG, \"time-offsets-group-\" + time);\n  KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n  Map<TopicPartition, Long> partitionOffsets = new HashMap<>();\n  Map<KafkaTopicPartition, Long> offsets = new HashMap<>();\n  consumer.listTopics().forEach(( topic, partitions) -> partitions.forEach(( partition) -> partitionOffsets.put(new TopicPartition(topic, partition), time)));\n  Map<TopicPartition, OffsetAndTimestamp> offsetsByTime = consumer.offsetsForTimes(partitionOffsets);\n  offsetsByTime.forEach(( tp, offset) -> offsets.put(new KafkaTopicPartition(tp.topic(), tp.partition()), offset.offset()));\n  consumer.close();\n  return offsets;\n}", "CodeBleu_score": 45.79550814408791}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"cpu_usage\");\n    event.setTags(new HashMap<>());\n    event.getTags().put(\"host\", \"server1\");\n    event.setFields(new HashMap<>());\n    event.getFields().put(\"value\", 42.5);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"my-topic\", event.toString());\n    producer.send(record);\n\n    System.out.println(\"Sent data: \" + event.toString());\n    producer.flush();\n}", "CodeBleu_score": 49.043217109959016}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    String topic = \"my-topic\";\n    String bootstrapServers = \"localhost:9092\";\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", bootstrapServers);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.ByteArraySerializer\");\n    KafkaProducer<String, byte[]> producer = new KafkaProducer<>(props);\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my-metric\");\n    event.setTags(Arrays.asList(\"tag1\", \"tag2\"));\n    event.setFields(Arrays.asList(new Field(\"field1\", 1.0), new Field(\"field2\", 2.0)));\n    byte[] serializedEvent = event.toByteArray();\n    ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, serializedEvent);\n    producer.send(record);\n    System.out.println(\"Sent data: \" + event);\n    producer.flush();\n    producer.close();\n}", "CodeBleu_score": 45.45567519562782}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    // Set up Kafka producer properties\n    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"io.confluent.kafka.serializers.KafkaAvroSerializer\");\n    props.put(\"schema.registry.url\", \"http://localhost:8081\");\n\n    // Create Kafka producer\n    KafkaProducer<String, MetricEvent> producer = new KafkaProducer<>(props);\n\n    // Create MetricEvent\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"my_metric\");\n    event.setTags(new ArrayList<>(Arrays.asList(\"tag1\", \"tag2\")));\n    event.setFields(new ArrayList<>(Arrays.asList(new Field(\"field1\", 1.0), new Field(\"field2\", 2.0))));\n\n    // Send MetricEvent to Kafka topic\n    ProducerRecord<String, MetricEvent> record = new ProducerRecord<>(\"my_topic\", event);\n    producer.send(record);\n\n    // Print sent data\n    System.out.println(\"Sent data: \" + event);\n\n    // Flush producer to ensure all data is sent\n    producer.flush();\n}", "CodeBleu_score": 47.548304955738395}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t        try {\n            if (event.getLevel().isInRange(Level.ERROR, Level.FATAL)) {\n                if (!event.getLoggerName().contains(\"xxx\")) {\n                    String logMessage = subAppend(event);\n                    if (logMessage != null) {\n                        ProducerRecord<String, String> record = new ProducerRecord<>(topic, logMessage);\n                        producer.send(record);\n                    }\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"Error sending log event to Kafka\", e);\n        }\n    }", "CodeBleu_score": 47.56296462457316}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t        try {\n            if (event.getLevel().isInRange(org.apache.logging.log4j.Level.ERROR, org.apache.logging.log4j.Level.FATAL) && !event.getLoggerName().contains(\"xxx\")) {\n                String logMessage = subAppend(event);\n                if (logMessage != null) {\n                    producer.send(new ProducerRecord<>(topic, logMessage));\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"Error appending log event to Kafka topic\", e);\n        }\n    }", "CodeBleu_score": 62.076797336188896}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t        if (event.getLevel().isInRange(Level.ERROR, Level.FATAL)) {\n            try {\n                String logMessage = subAppend(event);\n                if (logMessage != null) {\n                    producer.send(new ProducerRecord<>(topic, logMessage));\n                }\n            } catch (Exception e) {\n                log.warn(\"Error sending log event to Kafka\", e);\n            }\n        }\n    }", "CodeBleu_score": 48.75040742878594}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"\", \":\", \"+\", \"#\"}\n\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 81.09260239861003}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t", "CodeBleu_score": 2.5579410414724593}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"get\", \"set\", \"delete\", \"list\"}\n\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 80.13301327056448}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"routing tag %q not found in metric %v\", k.RoutingTag, metric.Name())\n\t\t}\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 72.60573324006036}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\troutingTag := k.RoutingTag\n\n\tif routingTag != \"\" {\n\t\tif value, ok := metric.GetTag(routingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 74.41353613582264}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 77.88119308147466}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regex := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(regex)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %v\", regex, err)\n\t\t}\n\t\tregexps[i] = r\n\t}\n\tk.regexps = regexps\n\treturn nil\n}", "CodeBleu_score": 44.89390688226359}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexStr := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(regexStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp for topic %s: %v\", regexStr, err)\n\t\t}\n\t\tregexps[i] = regex\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 42.82712600660795}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regular expression %q: %v\", regexpStr, err)\n\t\t}\n\t\tregexps[i] = regexp\n\t}\n\tk.regexps = regexps\n\treturn nil\n}", "CodeBleu_score": 44.421384201128426}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID()]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.DeliveryInfo().Delivered() {\n\t\tmsg.Ack()\n\t\tdelete(h.undelivered, track.DeliveryID())\n\t\th.sem.Release(1)\n\t}\n}", "CodeBleu_score": 60.68349798719481}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.Lock()\n\tdefer h.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.Delivered {\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 46.84161871489646}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\th.logger.Debug(\"Delivery not found in undelivered map\", zap.Int64(\"deliveryID\", track.DeliveryID))\n\t\treturn\n\t}\n\n\tif msg.Delivered {\n\t\th.logger.Debug(\"Message already delivered\", zap.Int64(\"deliveryID\", track.DeliveryID))\n\t\treturn\n\t}\n\n\tmsg.Delivered = true\n\tmsg.DeliveryTag = track.DeliveryTag\n\tmsg.DeliveryErr = track.Err\n\n\th.session.MarkMessage(msg, \"\")\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 48.81567771290455}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.handleMessage(ctx, message)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Failed to handle message: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 53.07498644016161}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.handleMessage(ctx, message)\n\t\t\tif err != nil {\n\t\t\t\tlog.Printf(\"Error handling message: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 53.31411534189875}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.handleMessage(ctx, message); err != nil {\n\t\t\t\tlog.Printf(\"error handling message: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 52.146635739713666}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t    checkCondition(logkafka_id.nonEmpty, IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id != \".\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id != \"..\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.length <= maxLogkafkaIdLength, IllegalCharacterInLogkafkaId)\n    checkCondition(logkafkaIdRegex.pattern.matcher(logkafka_id).matches(), IllegalCharacterInLogkafkaId)\n  }", "CodeBleu_score": 37.08514607518775}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t    val logkafka_id_regex = \"^[a-zA-Z0-9\\\\.\\\\-_]+$\".r\n    checkCondition(logkafka_id.nonEmpty, IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.length <= LogkafkaIdMaxLength, LogkafkaIdTooLong)\n    checkCondition(logkafka_id != \".\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id != \"..\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id_regex.findFirstIn(logkafka_id).isDefined, IllegalCharacterInLogkafkaId)\n  }", "CodeBleu_score": 39.463715681801084}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t    checkCondition(logkafka_id != null && logkafka_id.length > 0, IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id != \".\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id != \"..\", IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.length <= LogkafkaIdMaxLength, IllegalCharacterInLogkafkaId)\n    checkCondition(logkafka_id.matches(LogkafkaIdPattern), IllegalCharacterInLogkafkaId)\n  }", "CodeBleu_score": 41.70815518136744}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    (kafkaManagerActor ? msg).mapTo[ApiError \\/ Output].map {\n      case -\\/(error) =>\n        logger.error(s\"Error while calling kafka manager actor $error\")\n        -\\/(error)\n      case \\/-(output) =>\n        try {\n          \\/-(fn(output))\n        } catch {\n          case e: Exception =>\n            logger.error(s\"Error while transforming output $e\")\n            -\\/(ApiError(INTERNAL_SERVER_ERROR, s\"Error while transforming output $e\"))\n        }\n    }\n  }", "CodeBleu_score": 38.08823918317587}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    kafkaManagerActor ? msg map {\n      case a: Output => Right(fn(a))\n      case error: ApiError =>\n        logger.error(s\"Kafka manager actor failed with $error\")\n        Left(error)\n    } recover {\n      case e: Exception =>\n        logger.error(s\"Kafka manager actor failed with $e\")\n        Left(ApiError(e.getMessage))\n    }\n  }", "CodeBleu_score": 30.281075222703368}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case akka.actor.Status.Failure(ex) =>\n        logger.error(s\"Error in Kafka manager actor\", ex)\n        ApiError.internalError(\"Error in Kafka manager actor\")\n      case res: Output =>\n        try {\n          Right(fn(res))\n        } catch {\n          case ex: Exception =>\n            logger.error(s\"Error in Kafka manager actor\", ex)\n            ApiError.internalError(\"Error in Kafka manager actor\")\n        }\n    }\n  }", "CodeBleu_score": 35.44073602580947}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case output: Output => fn(output)\n      case ActorErrorResponse(_, _) => ApiError.internalError.left\n      case _ => ApiError.internalError.left\n    }.recover {\n      case throwable => ApiError.internalError.left\n    }\n  }", "CodeBleu_score": 41.04160890304248}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val response = kafkaManagerActor ? msg\n    response.map {\n      case output: Output => fn(output)\n      case ActorErrorResponse(msg, cause) => ApiError(msg, cause)\n    }.recover {\n      case t: Throwable => ApiError(t.getMessage, t)\n    }\n  }", "CodeBleu_score": 45.53139827961999}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case output: Output => fn(output)\n      case ActorErrorResponse(error) => ApiError(error).left\n    }.recover {\n      case throwable => ApiError(throwable).left\n    }\n  }", "CodeBleu_score": 40.86873904473312}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElectionCommand(topics))\n    (kafkaManager ? command).mapTo[ApiError \\/ ClusterContext]\n  }", "CodeBleu_score": 21.02896182719644}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElectionCommand(topics))\n    val result = (kafkaManager ? command).mapTo[ApiError \\/ ClusterContext]\n    result\n  }", "CodeBleu_score": 23.22767388507622}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val commandRequest = KMClusterCommandRequest(clusterName, PreferredLeaderElectionCommand(topics))\n    (kafkaManager ? commandRequest).mapTo[ApiError \\/ ClusterContext]\n  }", "CodeBleu_score": 21.87020081499484}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t    implicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap {\n      case Right(topicList) =>\n        runPreferredLeaderElection(clusterName, topicList.topics.toSet)\n      case Left(error) =>\n        Future.successful(Left(error))\n    }\n  }", "CodeBleu_score": 65.69761098498856}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t    implicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap {\n      case Left(error) => Future.successful(Left(error))\n      case Right(topicList) => runPreferredLeaderElection(clusterName, topicList.topics.toSet)\n    }\n  }", "CodeBleu_score": 64.85239933001921}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t    implicit val ec = apiExecutionContext\n    getTopicList(clusterName).flatMap {\n      case Left(error) => Future.successful(Left(error))\n      case Right(topics) => runPreferredLeaderElection(clusterName, topics.topics.keySet)\n    }\n  }", "CodeBleu_score": 63.78065202487109}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = apiExecutionContext\n    val assignmentsMap = assignments.toMap\n    val partitions = assignmentsMap.values.flatMap(_.map(_._2)).flatten.toSet\n    val brokers = assignmentsMap.values.flatMap(_.map(_._1)).toSet\n    val errors = mutable.ListBuffer[ApiError]()\n    val partitionAssignments = mutable.ListBuffer[PartitionAssignment]()\n    for (partition <- partitions) {\n      for (broker <- brokers) {\n        val replicas = assignmentsMap.get(broker).flatMap(_.get(partition)).getOrElse(List())\n        partitionAssignments += PartitionAssignment(partition, broker, replicas)\n      }\n    }\n    val command = KMClusterCommandRequest(\n      clusterName,\n      ManualPartitionAssignments(partitionAssignments.toList)\n    )\n    tryWithKafkaManagerActor(command) {\n      case KMClusterCommandResponse(_, errors) =>\n        if (errors.isEmpty) {\n          \\/-(true)\n        } else {\n          -\\/(errors.head)\n        }\n    }\n  }", "CodeBleu_score": 30.44467107377176}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  implicit val ec = apiExecutionContext\n  val request = KMClusterCommandRequest(clusterName, ManualPartitionAssignments(assignments))\n  val results = tryWithKafkaManagerActor(request) { results =>\n    val errors = results.flatMap { result =>\n      result.errors.map { error =>\n        error(s\"Failed on input : $request\")\n        ApiError.from(error)\n      }\n    }\n    if (errors.isEmpty)\n      \\/-(true)\n    else\n      -\\/(errors)\n  }\n  results.map {\n    case \\/-(_) => Ok\n    case -\\/(errors) => InternalServerError(Json.toJson(errors))\n  }\n}", "CodeBleu_score": 44.57967249862692}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t  // Describe the cluster to get the available nodes within a specified timeout\n  DescribeClusterResult describeClusterResult = admin.describeCluster(new DescribeClusterOptions().timeoutMs(5000));\n  // If no nodes are available, throw a ConnectException\n  if (describeClusterResult.nodes().get().isEmpty()) {\n    throw new ConnectException(\"No nodes available in the cluster within the specified timeout.\");\n  }\n  // Select the first node's ID\n  String nodeId = describeClusterResult.nodes().get().get(0).idString();\n  // Request the node's configuration\n  DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singletonList(new ConfigResource(ConfigResource.Type.BROKER, nodeId)));\n  // If no configurations are received, throw a ConnectException\n  if (describeConfigsResult.values().get().isEmpty()) {\n    throw new ConnectException(\"No configurations received for the selected node.\");\n  }\n  // Return the broker's configuration\n  return describeConfigsResult.values().get().get(0);\n}", "CodeBleu_score": 49.69015359626036}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    DescribeClusterResult describeClusterResult = admin.describeCluster(new DescribeClusterOptions().timeoutMs(KAFKA_CONNECTOR_TIMEOUT_MS));\n    if (describeClusterResult.nodes().isEmpty()) {\n        throw new ConnectException(\"No Kafka nodes available within \" + KAFKA_CONNECTOR_TIMEOUT_MS + \" ms\");\n    }\n    String nodeId = describeClusterResult.nodes().get(0).idString();\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodeId);\n    DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singletonList(configResource));\n    if (describeConfigsResult.all().isEmpty()) {\n        throw new ConnectException(\"No Kafka broker configuration available within \" + KAFKA_CONNECTOR_TIMEOUT_MS + \" ms\");\n    }\n    return describeConfigsResult.all().get(configResource);\n}", "CodeBleu_score": 46.7826665710906}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    // Describe the cluster to get the available nodes within a specified timeout\n    DescribeClusterResult describeClusterResult = admin.describeCluster(new DescribeClusterOptions().timeoutMs(1000));\n    // If no nodes are available, throw a ConnectException\n    if (describeClusterResult.nodes().get().isEmpty()) {\n        throw new ConnectException(\"No nodes are available within the specified timeout.\");\n    }\n    // Select the first node's ID\n    Node node = describeClusterResult.nodes().get().get(0);\n    // Request the configuration of the selected node\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n    DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(configResource));\n    // If no configurations are received, throw a ConnectException\n    if (describeConfigsResult.all().get().isEmpty()) {\n        throw new ConnectException(\"No configurations received for the selected node.\");\n    }\n    // Return the broker's configuration\n    return describeConfigsResult.all().get().get(configResource);\n}", "CodeBleu_score": 48.890426654511806}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t  return (config, log) -> {\n    if (config.getString(SCHEMA_HISTORY_CONFIG) == null) {\n      return 0;\n    }\n    return validator.validate(config, log);\n  };\n}", "CodeBleu_score": 21.256125580950588}, {"code": "private static Validator forKafka(final Validator validator){\n\t  return (subject, config) -> {\n    if (config.schemaHistory() == KafkaSchemaHistory.class) {\n      return validator.validate(subject, config);\n    }\n    return Collections.emptySet();\n  }\n}", "CodeBleu_score": 22.762937247466585}, {"code": "private static Validator forKafka(final Validator validator){\n\t  return (configs, topic) -> {\n    if (configs.get(TopicConfig.SCHEMA_HISTORY_INTERVAL_CONFIG) == KafkaSchemaHistory.name()) {\n      return validator.validate(configs, topic);\n    }\n    return 0;\n  };\n}", "CodeBleu_score": 27.024256400030776}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t        Version version = parseVersion(version());\n        Boolean topicCreationEnabled = (Boolean) config.getOrDefault(\"topic.creation.enable\", true);\n        return version.isCompatible(KafkaVersion.KAFKA_0_10_0) && topicCreationEnabled;\n    }", "CodeBleu_score": 31.747475595914963}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t        Version version = parseVersion(config.get(KafkaConnect.VERSION_CONFIG).toString());\n        Boolean topicCreationEnable = (Boolean) config.getOrDefault(KafkaConnect.TOPIC_CREATION_ENABLE_CONFIG, true);\n        return version.isCompatible(Version.parse(\"2.0.0\")) && topicCreationEnable;\n    }", "CodeBleu_score": 38.52449586004336}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t        Boolean topicCreationEnabled = true;\n        if (kafkaConnectVersion != null) {\n            if (kafkaConnectVersion.compareTo(MIN_VERSION) < 0) {\n                topicCreationEnabled = false;\n            }\n            else {\n                topicCreationEnabled = (Boolean) config.getOrDefault(TOPIC_CREATION_ENABLE, true);\n            }\n        }\n        return topicCreationEnabled;\n    }", "CodeBleu_score": 37.82759276591434}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t        final String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n        if (clientId == null || clientId.trim().isEmpty()) {\n            throw new IllegalArgumentException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n        }\n\n        final Properties adminProps = new Properties();\n        adminProps.putAll(config);\n        adminProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId);\n        adminProps.put(CommonClientConfigs.METRIC_REPORTER_CLASSES_CONFIG, \"\");\n        adminProps.put(CommonClientConfigs.METRICS_NUM_SAMPLES_CONFIG, \"0\");\n        adminProps.put(CommonClientConfigs.METRICS_SAMPLE_WINDOW_MS_CONFIG, \"0\");\n        adminProps.put(CommonClientConfigs.METRICS_RECORDING_LEVEL_CONFIG, \"NONE\");\n        adminProps.put(CommonClientConfigs.METRIC_SAMPLES_CONFIG, \"\");\n\n        final SharedTopicAdmin sharedAdmin = new SharedTopicAdmin(adminProps);\n        return new KafkaOffsetBackingStore(sharedAdmin, clientId, converterForOffsetStore());\n    }", "CodeBleu_score": 43.87193085699875}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t        final String clientId = config.get(CLIENT_ID_CONFIG);\n        if (clientId == null) {\n            throw new IllegalArgumentException(\"Missing mandatory configuration: \" + CLIENT_ID_CONFIG);\n        }\n\n        final Properties adminProps = new Properties();\n        adminProps.putAll(config);\n        adminProps.remove(CLIENT_ID_CONFIG);\n\n        final SharedTopicAdmin admin = SharedTopicAdmin.create(adminProps);\n\n        return new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n    }", "CodeBleu_score": 32.030151380506545}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t        final String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n        if (clientId == null) {\n            throw new IllegalArgumentException(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG + \" must be set\");\n        }\n        final Map<String, Object> adminProps = new HashMap<>(config);\n        adminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId);\n        final SharedTopicAdmin sharedAdmin = SharedTopicAdmin.create(adminProps);\n        return new KafkaOffsetBackingStore(sharedAdmin, clientId, converterForOffsetStore());\n    }", "CodeBleu_score": 42.524710557823944}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t            if (!node.isObject()) {\n                throw new IllegalArgumentException(\"Key must be an object\");\n            }\n\n            JsonNode payload = node.get(PAYLOAD_FIELD);\n\n            // Schema + payload format\n            if (payload != null) {\n                node = payload;\n            }\n\n            // Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node);\n            }\n\n            // Extracted format\n            if (node.fieldNames().hasNext()) {\n                String fieldName = node.fieldNames().next();\n                if (node.size() == 1) {\n                    return reader.readValue(node.get(fieldName));\n                }\n                else {\n                    return reader.readValue(node);\n                }\n            }\n            else {\n                return null;\n            }\n        }", "CodeBleu_score": 45.801300462630955}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t            if (!node.isObject()) {\n                throw new DataException(\"Key must be an object\");\n            }\n\n            JsonNode payload = node.get(PAYLOAD_FIELD);\n\n            // Schema + payload format\n            if (payload != null) {\n                node = payload;\n            }\n\n            // Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node);\n            }\n            else {\n                // Extracted format\n                Iterator<String> fieldNames = node.fieldNames();\n                if (fieldNames.hasNext()) {\n                    String fieldName = fieldNames.next();\n                    if (fieldNames.hasNext()) {\n                        return reader.readValue(node);\n                    }\n                    else {\n                        return reader.readValue(node.get(fieldName));\n                    }\n                }\n                else {\n                    throw new DataException(\"Key does not contain any field\");\n                }\n            }\n        }", "CodeBleu_score": 44.93103253339251}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t            if (!node.isObject()) {\n                throw new DataException(\"Key must be an object\");\n            }\n\n            JsonNode payload = node.get(PAYLOAD_FIELD);\n\n            // Schema + payload format\n            if (payload != null) {\n                node = payload;\n            }\n\n            // Debezium envelope\n            if (config.asEnvelope()) {\n                return reader.readValue(node);\n            }\n            else if (node.has(Envelope.FieldName.SOURCE) && node.has(config.sourceField())) {\n                return reader.readValue(node.get(config.sourceField()));\n            }\n            // Extracted format\n            else {\n                Iterator<String> fieldNames = node.fieldNames();\n                if (fieldNames.hasNext()) {\n                    String fieldName = fieldNames.next();\n                    if (fieldNames.hasNext()) {\n                        return reader.readValue(node);\n                    }\n                    else {\n                        return reader.readValue(node.get(fieldName));\n                    }\n                }\n                else {\n                    return reader.readValue(node);\n                }\n            }\n        }", "CodeBleu_score": 47.246164804522714}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t        String topicName = topicNameFor(id);\n        StringBuilder sanitizedTopicName = new StringBuilder();\n        boolean changed = false;\n        for (char c : topicName.toCharArray()) {\n            if (isValidTopicNameCharacter(c)) {\n                sanitizedTopicName.append(c);\n            } else {\n                sanitizedTopicName.append(replacementCharacter);\n                changed = true;\n            }\n        }\n        if (changed) {\n            LOG.warn(\"Topic name {} contains invalid characters. Replacing them with {}.\", topicName, replacementCharacter);\n            return sanitizedTopicName.toString();\n        }\n        return topicName;\n    }", "CodeBleu_score": 45.6297421687547}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t        String topicName = delegate.topicNameFor(id, prefix, delimiter);\n        StringBuilder sanitizedTopicName = new StringBuilder();\n        boolean replaced = false;\n        for (char c : topicName.toCharArray()) {\n            if (isValidTopicNameCharacter(c)) {\n                sanitizedTopicName.append(c);\n            } else {\n                sanitizedTopicName.append(replacementCharacter);\n                replaced = true;\n            }\n        }\n        if (replaced) {\n            logger.warn(\"Topic name {} contains invalid characters. Sanitized name: {}\", topicName, sanitizedTopicName.toString());\n        }\n        return sanitizedTopicName.toString();\n    }", "CodeBleu_score": 48.2017696272069}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t        String topicName = delegate.topicNameFor(id, prefix, delimiter);\n        StringBuilder sanitizedTopicName = new StringBuilder();\n        boolean replaced = false;\n        for (int i = 0; i < topicName.length(); i++) {\n            char c = topicName.charAt(i);\n            if (isValidTopicNameCharacter(c)) {\n                sanitizedTopicName.append(c);\n            } else {\n                sanitizedTopicName.append(replacementCharacter);\n                replaced = true;\n            }\n        }\n        if (replaced) {\n            LOG.warn(\"Topic name {} contains invalid characters. Replacing with {}\", topicName, sanitizedTopicName);\n            return sanitizedTopicName.toString();\n        } else {\n            return topicName;\n        }\n    }", "CodeBleu_score": 63.47804394366404}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.retries = connectorConfig.getMaxRetries() == null ? Integer.MAX_VALUE : connectorConfig.getMaxRetries();\n        if (replacedErrorHandler != null) {\n            this.retries = replacedErrorHandler.getRetries();\n        }\n    }", "CodeBleu_score": 61.51102837786031}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.retryCount = replacedErrorHandler == null ? 0 : replacedErrorHandler.getRetries();\n        this.maxRetries = connectorConfig.getInt(CommonConnectorConfig.RETRY_COUNT);\n        this.producerThrowable = new AtomicReference<>();\n    }", "CodeBleu_score": 57.286983089631285}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.retries = connectorConfig.getInt(CommonConnectorConfig.RETRIES_CONFIG);\n        if (retries < 0) {\n            retries = Integer.MAX_VALUE;\n        }\n        if (replacedErrorHandler != null) {\n            this.retries = replacedErrorHandler.getRetries();\n        }\n    }", "CodeBleu_score": 64.20561953276061}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t        Map<String, ConfigValue> validations = configuration.validate(fields);\n        for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n            if (!entry.getValue().errorMessages().isEmpty()) {\n                final ConfigValue value = entry.getValue();\n                throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n            }\n        }\n    }", "CodeBleu_score": 86.24683910514167}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t        Map<String, ConfigValue> validations = configuration.validate(fields);\n        for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n            if (!entry.getValue().errorMessages().isEmpty()) {\n                final ConfigValue value = entry.getValue();\n                throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n            }\n        }\n    }", "CodeBleu_score": 86.24683910514167}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t        Map<String, ConfigValue> validations = configuration.validate(fields);\n        for (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n            if (!entry.getValue().errorMessages().isEmpty()) {\n                final ConfigValue value = entry.getValue();\n                throw new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n            }\n        }\n    }", "CodeBleu_score": 86.24683910514167}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\n    if (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        }\n        else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.7799116121701}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t\n    if (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        }\n        else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.7799116121701}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.type().isPrimitive()) {\n        return oldSchema;\n    }\n\n    // Get fields from original schema\n    SchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    for (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n        if (isContainedIn(field.name(), nestedFields)) {\n            newSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n        } else {\n            newSchemabuilder.field(field.name(), field.schema());\n        }\n    }\n\n    LOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n    for (int i = 0; i < headers.size(); i++) {\n        Header currentHeader = headerToProcess.get(headers.get(i));\n        Optional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n        LOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n        if (currentFieldName.isPresent() && currentHeader != null) {\n            newSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n        }\n    }\n    LOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n    return newSchemabuilder.build();\n}", "CodeBleu_score": 99.56338433231458}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source.schema().field(SnapshotRecord.SNAPSHOT_KEY) == null) {\n    return null;\n  }\n  String snapshotString=source.getString(SnapshotRecord.SNAPSHOT_KEY);\n  if (snapshotString == null) {\n    return null;\n  }\n  snapshotString=snapshotString.toUpperCase();\n  if (SnapshotRecord.SNAPSHOT_INITIAL.name().equals(snapshotString)) {\n    return SnapshotRecord.SNAPSHOT_INITIAL;\n  }\n else   if (SnapshotRecord.SNAPSHOT_TERMINAL.name().equals(snapshotString)) {\n    return SnapshotRecord.SNAPSHOT_TERMINAL;\n  }\n else {\n    return null;\n  }\n}", "CodeBleu_score": 44.3519425319542}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source.schema().field(SnapshotRecord.SNAPSHOT_KEY) != null && source.schema().field(SnapshotRecord.SNAPSHOT_KEY).schema().name().equals(SnapshotRecord.SNAPSHOT_KEY)) {\n    String snapshotString=source.getString(SnapshotRecord.SNAPSHOT_KEY);\n    if (snapshotString != null) {\n      snapshotString=snapshotString.toUpperCase();\n      return SnapshotRecord.valueOf(snapshotString);\n    }\n  }\n  return null;\n}", "CodeBleu_score": 60.483966975287416}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t  if (source.schema().field(SNAPSHOT_KEY) != null && source.schema().field(SNAPSHOT_KEY).schema().name().equals(SNAPSHOT_KEY)) {\n    String snapshotString=source.getString(SNAPSHOT_KEY);\n    if (snapshotString != null) {\n      snapshotString=snapshotString.toUpperCase();\n      if (snapshotString.equals(SnapshotRecord.TRUE.name())) {\n        return SnapshotRecord.TRUE;\n      }\n else       if (snapshotString.equals(SnapshotRecord.FALSE.name())) {\n        return SnapshotRecord.FALSE;\n      }\n else       if (snapshotString.equals(SnapshotRecord.ALL.name())) {\n        return SnapshotRecord.ALL;\n      }\n    }\n  }\n  return null;\n}", "CodeBleu_score": 53.574016946512174}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t  try {\n    String[] parts=version.split(\"\\\\.\");\n    if (parts.length > 2)     parts=new String[]{parts[0],parts[1]};\n    String[] subparts=parts[0].split(\"-\");\n    float f=Float.parseFloat(subparts[0]);\n    return Optional.of(f);\n  }\n catch (  NumberFormatException e) {\n    return Optional.empty();\n  }\n}", "CodeBleu_score": 60.29945392727578}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    if (version == null) {\n        return Optional.empty();\n    }\n    String[] parts = version.split(\"\\\\.\");\n    if (parts.length > 2) {\n        parts = Arrays.copyOfRange(parts, 0, 2);\n    }\n    String versionPart = parts[0];\n    if (parts.length > 1) {\n        versionPart += \".\" + parts[1];\n    }\n    return Optional.of(Float.parseFloat(versionPart));\n}", "CodeBleu_score": 56.649401654344736}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t  try {\n    String[] parts=version.split(\"\\\\.\");\n    if (parts.length > 2)     parts=Arrays.copyOf(parts,2);\n    String[] subparts=parts[0].split(\"-\");\n    return Optional.of(Float.parseFloat(subparts[0]));\n  }\n catch (  NumberFormatException e) {\n    return Optional.empty();\n  }\n}", "CodeBleu_score": 61.46850669141071}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.616906356027}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.616906356027}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n        .operationName(\"createConnector\")\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.616906356027}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 95.74751834071806}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.87733917357059}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n        .operationName(\"deleteConnector\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.87733917357059}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    ConnectAction[] connectActions;\n    if (RESTART_ACTIONS.contains(action)) {\n        connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n    } else {\n        connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n    }\n\n    var context = AccessContext.builder()\n            .cluster(clusterName)\n            .connect(connectName)\n            .connectActions(connectActions)\n            .operationName(\"updateConnectorState\")\n            .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n            .build();\n\n    return validateAccess(context).then(\n            kafkaConnectService\n                    .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n                    .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 96.70936033094512}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    ConnectAction[] connectActions;\n    if (RESTART_ACTIONS.contains(action)) {\n        connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n    } else {\n        connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n    }\n\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(connectActions)\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService\n            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 97.94113388169055}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    ConnectAction[] connectActions;\n    if (RESTART_ACTIONS.contains(action)) {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n    } else {\n      connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n    }\n\n    var context = AccessContext.builder()\n        .cluster(clusterName)\n        .connect(connectName)\n        .connectActions(connectActions)\n        .operationName(\"updateConnectorState\")\n        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n        .build();\n\n    return validateAccess(context).then(\n        kafkaConnectService\n            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n            .map(ResponseEntity::ok)\n    ).doOnEach(sig -> audit(context, sig));\n  }", "CodeBleu_score": 97.98462714091751}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService\n        .validateConnectorPluginConfig(\n            getCluster(clusterName), connectName, pluginName, requestBody)\n        .map(ResponseEntity::ok);\n}", "CodeBleu_score": 46.312924906194226}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService\n        .validateConnectorPluginConfig(\n            getCluster(clusterName), connectName, pluginName, requestBody)\n        .map(ResponseEntity::ok);\n}", "CodeBleu_score": 46.312924906194226}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new KafkaUiApplicationInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 43.16823957595757}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new KafkaUiInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 43.74698369285163}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t  SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n  builder.initializers(new KafkaUiApplicationInitializer());\n  return builder.run(args);\n}", "CodeBleu_score": 42.940329906241445}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n      return connector -> true;\n    }\n\n    final String searchTerm = search.toLowerCase();\n    return connector -> getStringsForSearch(connector)\n        .anyMatch(string -> string.toLowerCase().contains(searchTerm));\n  }", "CodeBleu_score": 62.98824386352305}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n      return connector -> true;\n    }\n    final String searchTerm = search.toLowerCase();\n    return connector -> getStringsForSearch(connector).anyMatch(string -> string.toLowerCase().contains(searchTerm));\n  }", "CodeBleu_score": 59.136031023006716}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n      return connector -> true;\n    }\n    final String searchTerm = search.toLowerCase();\n    return connector -> getStringsForSearch(connector).anyMatch(string -> string.toLowerCase().contains(searchTerm));\n  }", "CodeBleu_score": 59.136031023006716}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedMap;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 51.134673360329785}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return Collections.emptyMap();\n    }\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 50.36219958427755}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return Collections.emptyMap();\n    }\n\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 50.36219958427755}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t  ConfigDef configDef = new ConfigDef();\n  addSslSupport(configDef);\n  addSaslSupport(configDef);\n  return configDef.configKeys().stream().filter(k -> k.type == ConfigDef.Type.PASSWORD).map(ConfigKey::name).collect(Collectors.toSet());\n}", "CodeBleu_score": 59.98403013031914}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t  ConfigDef configDef = new ConfigDef();\n  SSLConfigs.addClientSSLSupport(configDef);\n  SaslConfigs.addClientMechanismSupport(configDef);\n  return configDef.configKeys().stream().filter(k -> configDef.get(k).type() == ConfigDef.Type.PASSWORD).collect(Collectors.toSet());\n}", "CodeBleu_score": 64.74156275450379}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t  final ConfigDef configDef = new ConfigDef();\n  SSLConfig.addClientConfig(configDef, true);\n  SaslConfig.addClientConfig(configDef, true);\n  return configDef.configKeys().stream().filter(k -> k.type == ConfigDef.Type.PASSWORD).map(ConfigKey::name).collect(Collectors.toSet());\n}", "CodeBleu_score": 64.77113632553453}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n      .filter(cd -> aclViewEnabled(adminClient))\n      .filter(cd -> cd.authorizedOperations().containsAll(ACL_EDIT_PERMISSIONS))\n      .map(cd -> ClusterFeature.KAFKA_ACL_EDIT);\n  }", "CodeBleu_score": 24.271772839174677}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n        .filter(desc -> aclViewEnabled(adminClient))\n        .map(desc -> desc.getAuthorizedOperations())\n        .filter(authOps -> authOps.contains(AclOperation.ALL) || authOps.contains(AclOperation.ALTER))\n        .map(authOps -> KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 36.3902806400328}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n            .filter(cluster -> aclViewEnabled(adminClient))\n            .filter(cluster -> cluster.authorizedOperations().containsAll(EnumSet.of(DescribeAclsOptions.ALL, DescribeAclsOptions.ALTER)))\n            .map(cluster -> KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 26.409935277048746}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize the map of offsets to read from based on the previous range or the offsets from seek operations\n    TreeMap<TopicPartition, FromToOffset> toPoll = new TreeMap<>(prevRange);\n    for (Map.Entry<TopicPartition, Long> entry : seekOperations.getSeekOffsets().entrySet()) {\n        toPoll.put(entry.getKey(), new FromToOffset(entry.getValue(), Long.MAX_VALUE));\n    }\n    // Calculate the number of messages to poll per partition\n    int numMessagesPerPartition = this.numMessagesPerPartition;\n    // Determine the start offset for each topic partition and adjust it based on the number of messages to poll\n    for (Map.Entry<TopicPartition, FromToOffset> entry : toPoll.entrySet()) {\n        long startOffset = entry.getValue().getFromOffset();\n        if (startOffset == Long.MIN_VALUE) {\n            startOffset = this.seekToBeginning ? 0 : entry.getKey().offset();\n        }\n        long endOffset = entry.getValue().getToOffset();\n        long numMessagesToPoll = Math.min(numMessagesPerPartition, endOffset - startOffset);\n        startOffset = Math.max(startOffset, startOffset - numMessagesToPoll);\n        entry.setValue(new FromToOffset(startOffset, endOffset));\n    }\n    return toPoll;\n}", "CodeBleu_score": 36.15700977275547}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    if (prevRange != null) {\n        for (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n            TopicPartition tp = entry.getKey();\n            FromToOffset prevOffsets = entry.getValue();\n            range.put(tp, prevOffsets);\n        }\n    } else {\n        for (Map.Entry<TopicPartition, Long> entry : seekOperations.getSeekOffsets().entrySet()) {\n            TopicPartition tp = entry.getKey();\n            Long offset = entry.getValue();\n            range.put(tp, new FromToOffset(offset, null));\n        }\n    }\n\n    int messagesToPollPerPartition = this.messagesToPollPerPartition;\n    for (TopicPartition tp : range.keySet()) {\n        FromToOffset offsets = range.get(tp);\n        Long startOffset = offsets.getFrom();\n        if (startOffset == null) {\n            startOffset = seekOperations.getSeekOffsets().get(tp);\n            if (startOffset == null) {\n                startOffset = this.initialOffsetProvider.getInitialOffset(tp);\n            }\n        }\n        if (startOffset != null) {\n            startOffset = Math.max(startOffset - messagesToPollPerPartition, 0);\n        }\n        range.put(tp, new FromToOffset(startOffset, null));\n    }\n\n    return range;\n}", "CodeBleu_score": 33.60680907303357}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    for (TopicPartition tp : seekOperations.getSeekOperations().keySet()) {\n        if (prevRange.containsKey(tp)) {\n            range.put(tp, prevRange.get(tp));\n        } else {\n            range.put(tp, new FromToOffset(seekOperations.getSeekOperations().get(tp), seekOperations.getSeekOperations().get(tp)));\n        }\n    }\n    int messagesPerPartition = calculateMessagesPerPartition(range.size());\n    for (TopicPartition tp : range.keySet()) {\n        long startOffset = range.get(tp).getFrom();\n        if (startOffset < seekOperations.getSeekOperations().get(tp)) {\n            startOffset = seekOperations.getSeekOperations().get(tp);\n        }\n        long endOffset = startOffset + messagesPerPartition - 1;\n        range.put(tp, new FromToOffset(startOffset, endOffset));\n    }\n    return range;\n}", "CodeBleu_score": 37.21244746557325}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t    final boolean legacyMode = configuration.getBoolean(CK_LEGACY_MODE);\n\n    if (legacyMode) {\n        final String zookeeper = configuration.getString(CK_ZOOKEEPER);\n        if (zookeeper == null || zookeeper.isEmpty()) {\n            throw new ConfigurationException(\"Missing configuration value for \" + CK_ZOOKEEPER);\n        }\n    } else {\n        final String bootstrap = configuration.getString(CK_BOOTSTRAP);\n        if (bootstrap == null || bootstrap.isEmpty()) {\n            throw new ConfigurationException(\"Missing configuration value for \" + CK_BOOTSTRAP);\n        }\n    }\n\n    // wait for the server to be running\n    final ServerStatus serverStatus = serverStatusService.get();\n    if (serverStatus != ServerStatus.RUNNING) {\n        serverStatusService.awaitRunning();\n    }\n\n    // register for server lifecycle events\n    serverStatusService.register(this);\n\n    if (legacyMode) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n\n    // schedule a task to update the last second bytes read every second\n    executor.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            lastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 55.6050250559351}, {"code": "public void doLaunch(final MessageInput input){\n\t    if (configuration.getBoolean(CK_LEGACY_MODE)) {\n        if (!configuration.hasKey(CK_ZOOKEEPER)) {\n            throw new IllegalStateException(\"Legacy mode is enabled, but no ZooKeeper is configured.\");\n        }\n    } else {\n        if (!configuration.hasKey(CK_BOOTSTRAP)) {\n            throw new IllegalStateException(\"Legacy mode is disabled, but no bootstrap servers are configured.\");\n        }\n    }\n\n    // Wait for the server to be running, so we can register for lifecycle events.\n    server.awaitRunning();\n\n    server.register(this);\n\n    if (configuration.getBoolean(CK_LEGACY_MODE)) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n\n    executor.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            lastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 42.06619939884015}, {"code": "public void doLaunch(final MessageInput input){\n\t    if (configuration.getBoolean(CK_LEGACY_MODE)) {\n        // Validate the required configuration for legacy mode.\n        validateLegacyModeConfiguration();\n    } else {\n        // Validate the required configuration for consumer mode.\n        validateConsumerModeConfiguration();\n    }\n\n    // Wait for the server to be running.\n    waitForServerRunning();\n\n    // Register for server lifecycle events.\n    lifecycleService.register(this);\n\n    // Launch the input based on the mode.\n    if (configuration.getBoolean(CK_LEGACY_MODE)) {\n        doLaunchLegacy(input);\n    } else {\n        doLaunchConsumer(input);\n    }\n\n    // Schedule a task to update the last second bytes read every second.\n    executor.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            lastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 30.256488078370264}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String config = \"custom.properties\";\n        Properties customProps = new Properties();\n        customProps.load(new StringReader(config));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        logger.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 47.13150225497533}, {"code": "private void insertCustomProperties(Properties props){\n\t    String config = getConfig();\n    try {\n        Properties customProps = new Properties();\n        customProps.load(new StringReader(config));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        logger.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 46.08256475893531}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String config = System.getProperty(\"config\");\n        if (config != null) {\n            Properties customProps = new Properties();\n            StringReader reader = new StringReader(config);\n            customProps.load(reader);\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 51.19305237025993}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t        final List<Journal.Entry> journalEntries = entries.stream()\n                .filter(Objects::nonNull)\n                .map(this::mapToJournalEntry)\n                .collect(Collectors.toList());\n\n        long totalMessageBytes = 0;\n        for (final Journal.Entry entry : journalEntries) {\n            totalMessageBytes += entry.getSize();\n        }\n\n        try {\n            final long lastOffset = kafkaJournal.write(journalEntries);\n\n            LOG.debug(\"Processed batch, last journal offset: {}, signalling reader.\",\n                    lastOffset);\n            journalFilled.release();\n\n            writtenMessages.mark(entries.size());\n            writtenBytes.mark(totalMessageBytes);\n        } catch (final Exception e) {\n            throw new MessageQueueException(\"Failed to write to journal\", e);\n        }\n    }", "CodeBleu_score": 45.669163543998856}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t        final List<Journal.Entry> journalEntries = entries.stream()\n                .filter(Objects::nonNull)\n                .map(this::mapEventToJournalEntry)\n                .collect(Collectors.toList());\n\n        final long totalMessageBytes = journalEntries.stream()\n                .mapToLong(Journal.Entry::getSize)\n                .sum();\n\n        int attempt = 0;\n        while (true) {\n            try {\n                kafkaJournal.write(journalEntries);\n                break;\n            } catch (JournalException e) {\n                attempt++;\n                if (attempt == MAX_RETRIES) {\n                    throw new MessageQueueException(e);\n                }\n                try {\n                    Thread.sleep((long) Math.pow(2, attempt) * 1000);\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                }\n            }\n        }\n\n        writtenMessages.mark(entries.size());\n        writtenBytes.mark(totalMessageBytes);\n    }", "CodeBleu_score": 43.7576663669178}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t        final List<Journal.Entry> journalEntries = entries.stream()\n                .filter(Objects::nonNull)\n                .map(e -> new Journal.Entry(e.getKey(), e.getPayload()))\n                .collect(Collectors.toList());\n\n        final long totalMessageBytes = journalEntries.stream()\n                .mapToLong(e -> e.value().length)\n                .sum();\n\n        final long startTime = System.currentTimeMillis();\n        long offset;\n        try {\n            offset = kafkaJournal.write(journalEntries);\n        } catch (JournalException e) {\n            throw new MessageQueueException(e);\n        }\n        final long endTime = System.currentTimeMillis();\n\n        final long elapsedTime = endTime - startTime;\n        if (elapsedTime > 0) {\n            final long messageRate = journalEntries.size() / elapsedTime;\n            final long byteRate = totalMessageBytes / elapsedTime;\n            LOG.debug(\"Wrote {} messages ({} bytes) to journal in {} ms ({} messages/sec, {} bytes/sec)\",\n                    journalEntries.size(), totalMessageBytes, elapsedTime, messageRate, byteRate);\n        }\n\n        writtenMessages.mark(journalEntries.size());\n        writtenBytes.mark(totalMessageBytes);\n    }", "CodeBleu_score": 51.66532636297569}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t  int maxQueueId = -1;\n  for (Message message : messages) {\n    int queueId = message.getQueueId();\n    if (queueId > maxQueueId) {\n      maxQueueId = queueId;\n    }\n  }\n  if (maxQueueId >= 0) {\n    this.acknowledge(maxQueueId);\n  }\n  this.metrics.markAcknowledged(messages.size());\n}", "CodeBleu_score": 21.82556720155943}, {"code": "public void acknowledge(List<Message> messages){\n\t    int maxValidId = -1;\n    for (Message message : messages) {\n        maxValidId = Math.max(maxValidId, message.getId());\n    }\n    if (maxValidId > -1) {\n        markMessagesAcknowledged(maxValidId);\n    }\n    metrics.acknowledgedMessages(messages.size());\n}", "CodeBleu_score": 24.793153271709482}, {"code": "public void acknowledge(List<Message> messages){\n\t  if (messages == null || messages.isEmpty()) {\n    return;\n  }\n  int maxValidMessageQueueId = -1;\n  for (    Message message : messages) {\n    if (message.getQueueId() > maxValidMessageQueueId) {\n      maxValidMessageQueueId = message.getQueueId();\n    }\n  }\n  if (maxValidMessageQueueId > -1) {\n    metrics.acknowledgedMessages.inc(maxValidMessageQueueId);\n  }\n}", "CodeBleu_score": 22.32501099307333}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    // Filter metrics to include only those starting with the LocalKafkaJournal class name\n    final MetricFilter filter = new MetricFilter() {\n        @Override\n        public boolean matches(String name, Metric metric) {\n            return name.startsWith(LocalKafkaJournal.class.getSimpleName());\n        }\n    };\n\n    // Register legacy metrics\n    for (final Map.Entry<String, Metric> entry : this.metrics.getMetrics().entrySet()) {\n        final String name = entry.getKey();\n        final Metric metric = entry.getValue();\n\n        // Filter metrics to include only those starting with the LocalKafkaJournal class name\n        if (filter.matches(name, metric)) {\n            // Construct legacy metric name\n            final String legacyName = \"kafka.journal.\" + name.substring(LocalKafkaJournal.class.getSimpleName().length() + 1);\n\n            // Attempt to register legacy metric\n            try {\n                this.metrics.register(legacyName, metric);\n            } catch (IllegalArgumentException e) {\n                // Log warning message if registration fails\n                LOG.warn(\"Unable to register legacy metric {} under the name {}\", name, legacyName);\n            }\n        }\n    }\n}", "CodeBleu_score": 46.235936719986206}, {"code": "private void registerLegacyMetrics(){\n\t    LocalKafkaJournal.this.getMetricsRegistry().getMetrics().forEach((name, metric) -> {\n        if (name.startsWith(LocalKafkaJournal.class.getName())) {\n            final String legacyName = name.replace(LocalKafkaJournal.class.getName(), \"kafka.log.Log\");\n            try {\n                LocalKafkaJournal.this.getMetricsRegistry().register(legacyName, metric);\n            } catch (final IllegalArgumentException e) {\n                log.warn(\"Unable to register metric {} under legacy name {}: {}\", name, legacyName, e.getMessage());\n            }\n        }\n    });\n}", "CodeBleu_score": 47.25419157844504}, {"code": "private void registerLegacyMetrics(){\n\t        for (final MetricName metricName : this.metricRegistry.getMetrics().keySet()) {\n            if (metricName.getGroup().equals(LocalKafkaJournal.class.getName())) {\n                final String legacyName = metricName.getGroup() + \".\" + metricName.getName();\n                try {\n                    this.metricRegistry.register(legacyName, this.metricRegistry.getMetrics().get(metricName));\n                } catch (final IllegalArgumentException e) {\n                    logger.warn(\"Failed to register legacy metric {} under new name {}\", metricName, legacyName, e);\n                }\n            }\n        }\n    }", "CodeBleu_score": 42.77023566534807}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t  try {\n    return metricRegistry.timer(metricName);\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 17.70230594711348}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t  try {\n    return metricRegistry.register(metricName, new HdrTimer());\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.timer(metricName);\n  }\n}", "CodeBleu_score": 17.674498324629205}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t  try {\n    return metricRegistry.timer(metricName);\n  }\n catch (  IllegalArgumentException e) {\n    return metricRegistry.getTimers().get(metricName);\n  }\n}", "CodeBleu_score": 17.70230594711348}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t        try {\n            metricRegistry.register(MetricRegistry.name(KafkaLogMetrics.class, name, \"UncommittedMessages\"), new Gauge<Long>() {\n                @Override\n                public Long getValue() {\n                    final long size = kafkaLog.size();\n                    if (size == 0) {\n                        return 0L;\n                    }\n                    final long committedOffset = kafkaLog.committedOffset();\n                    if (committedOffset == -1) {\n                        return kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n                    }\n                    return kafkaLog.logEndOffset() - committedOffset;\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // Ignore\n        }\n    }", "CodeBleu_score": 51.18418499778639}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t        try {\n            metricRegistry.register(MetricRegistry.name(name, \"UncommittedMessages\"), new Gauge<Integer>() {\n                @Override\n                public Integer getValue() {\n                    final long size = kafkaLog.size();\n                    if (size == 0) {\n                        return 0;\n                    }\n                    final long committedOffset = kafkaLog.committedOffset();\n                    if (committedOffset == KafkaLog.NO_COMMITTED_OFFSET) {\n                        return (int) (kafkaLog.logEndOffset() - kafkaLog.logStartOffset());\n                    }\n                    return (int) (kafkaLog.logEndOffset() - committedOffset);\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // already registered\n        }\n    }", "CodeBleu_score": 47.88217157859164}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t        try {\n            metricRegistry.register(MetricRegistry.name(name, \"UncommittedMessages\"), (Gauge<Long>) () -> {\n                final long size = size();\n                if (size == 0) {\n                    return 0L;\n                }\n                final long committedOffset = getCommittedOffset();\n                if (committedOffset == -1) {\n                    return getLogEndOffset() - getLogStartOffset();\n                }\n                return getLogEndOffset() - committedOffset;\n            });\n        } catch (IllegalArgumentException e) {\n        }\n    }", "CodeBleu_score": 56.44326147134263}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t        if (messages.isEmpty()) {\n            logger.debug(\"No messages to flush\");\n            return -1;\n        }\n        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n        logger.trace(\"Writing {} messages to log\", messageSet.size());\n        long lastWriteOffset = kafkaLog.append(messageSet);\n        logger.trace(\"Wrote {} messages to log\", messageSet.size());\n        logger.trace(\"Wrote {} bytes to log\", payloadSize);\n        markNumMessagesWritten(messages.size());\n        return lastWriteOffset;\n    }", "CodeBleu_score": 41.777353247652485}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t        if (messages.isEmpty()) {\n            logger.debug(\"No messages to flush\");\n            return kafkaLog.getLastOffset();\n        }\n\n        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages, payloadSize);\n        logger.debug(\"Flushing {} messages with {} bytes\", messageSet.size(), messageSet.sizeInBytes());\n\n        kafkaLog.append(messageSet);\n        long lastOffset = kafkaLog.getLastOffset();\n\n        logger.debug(\"Wrote {} messages with {} bytes to offset {}\", messageSet.size(), messageSet.sizeInBytes(), lastOffset);\n        metrics.recordBytesWritten(messageSet.sizeInBytes());\n        metrics.recordMessagesWritten(messageSet.size());\n\n        return lastOffset;\n    }", "CodeBleu_score": 45.40489431124494}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t        if (messages.isEmpty()) {\n            logger.debug(\"No messages to flush\");\n            return lastFlushOffset;\n        }\n        ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages, payloadSize, compressionCodec);\n        logger.debug(\"Writing {} messages with a full size of {} to log {}\", messageSet.size(), messageSet.getValidBytes(), log.name());\n        long lastOffset = log.append(messageSet).getLastOffset();\n        logger.debug(\"Wrote {} messages to log {}\", messageSet.size(), log.name());\n        markMessagesWritten(messageSet.size());\n        return lastOffset;\n    }", "CodeBleu_score": 42.50490549020965}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t        if (clusterPhyId == null) {\n            return;\n        }\n\n        // \u52a0\u9501\n        lock.lock();\n        try {\n            List<AdminClient> adminClientList = adminClientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"start to close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n            boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}\", clusterPhyId);\n            }\n        } finally {\n            // \u91ca\u653e\u9501\n            lock.unlock();\n        }\n    }", "CodeBleu_score": 71.59303318937651}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    if (clusterPhyId == null) {\n        return;\n    }\n\n    // \u9501\u4f4f\u5ba2\u6237\u7aef\u5217\u8868\n    synchronized (this.clientMap) {\n        // \u83b7\u53d6\u5ba2\u6237\u7aef\u5217\u8868\n        List<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n        if (adminClientList == null) {\n            return;\n        }\n\n        LOGGER.info(\"start to close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n\n        // \u5173\u95ed\u5ba2\u6237\u7aef\n        boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n\n        // \u6e05\u7a7a\u5ba2\u6237\u7aef\u5217\u8868\n        adminClientList.clear();\n\n        // \u6253\u5370\u65e5\u5fd7\n        if (allSuccess) {\n            LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n        } else {\n            LOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}\", clusterPhyId);\n        }\n    }\n}", "CodeBleu_score": 63.02545117826321}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t        if (clusterPhyId == null) {\n            return;\n        }\n\n        synchronized (this.clientMap) {\n            List<AdminClient> adminClientList = this.clientMap.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"start to close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n            boolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n            if (allSuccess) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient failed, clusterPhyId:{}\", clusterPhyId);\n            }\n        }\n    }", "CodeBleu_score": 60.40348659746566}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(30, TimeUnit.SECONDS);\n        } catch (Exception e) {\n            log.error(\"closeAdminClientList failed, clusterPhyId:{}, error:{}\", clusterPhyId, e.getMessage());\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 62.75269018468384}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(30, TimeUnit.SECONDS);\n        } catch (Exception e) {\n            LOGGER.error(\"close admin client error, clusterPhyId:{}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 71.38038971085396}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\"Close admin client failed, clusterPhyId: {}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 83.7107049698603}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        int attempts = 5;\n        while (app.isRunning() && attempts > 0) {\n            attempts = attempts - 1;\n            try {\n                Thread.sleep(1000);\n            }\n            catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 92.6848547076434}, {"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        int attempts = 5;\n        while (app.isRunning() && attempts > 0) {\n            attempts = attempts - 1;\n            try {\n                Thread.sleep(1000);\n            }\n            catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 92.6848547076434}, {"code": "public void stop() {\n\t\t\tif (app != null) {\n\t\t\tapp.stop();\n\t\t\tint attempts = 5;\n\t\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\t\tattempts = attempts - 1;\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(1000);\n\t\t\t\t}\n\t\t\t\tcatch (InterruptedException e) {\n\t\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t\t}\n\t\t\t}\n\t\t\tapp = null;\n\t\t}\n\t}", "CodeBleu_score": 93.64540182287362}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config);\n    server.enableTls();\n    server.setKeystore(keystore, keystorePassword);\n    server.setTruststore(truststore, truststorePassword);\n    server.start();\n    return server;\n}", "CodeBleu_score": 54.97393691085881}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner eurekaServer = new EurekaServerRunner(config);\n    eurekaServer.enableTls(true);\n    eurekaServer.setKeystore(\"classpath:server.keystore\", \"password\");\n    eurekaServer.setTruststore(\"classpath:server.truststore\", \"password\");\n    eurekaServer.start();\n    return eurekaServer;\n}", "CodeBleu_score": 38.730163736894156}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config);\n    runner.enableTLS();\n    runner.setKeystore(keystore, keystorePassword);\n    runner.setTruststore(truststore, truststorePassword);\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 40.93077342471786}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.20622575706126}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.20622575706126}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\t\tenableTlsClient(runner);\n\t\trunner.start();\n\t\treturn runner;\n\t}", "CodeBleu_score": 67.20622575706126}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\t\tKeyTool keyTool = new KeyTool(KEY_PASSWORD);\n\n\t\tKeyAndCert caCert = keyTool.createCertificate(CA_SUBJECT, CA_ALIAS, CA_PASSWORD);\n\t\tsaveCert(caCert);\n\n\t\tKeyAndCert serverCert = keyTool.createCertificate(SERVER_SUBJECT, SERVER_ALIAS, SERWER_PASSWORD);\n\t\tsaveKeyAndCert(serverCert);\n\n\t\tKeyAndCert clientCert = keyTool.createCertificate(CLIENT_SUBJECT, CLIENT_ALIAS, CLIENT_PASSWORD);\n\t\tsaveKeyAndCert(clientCert);\n\n\t\tKeyAndCert secondCa = keyTool.createCertificate(SECOND_CA_SUBJECT, SECOND_CA_ALIAS, SECOND_CA_PASSWORD);\n\t\tsaveCert(secondCa);\n\n\t\tKeyAndCert secondClient = keyTool.createCertificate(SECOND_CLIENT_SUBJECT, SECOND_CLIENT_ALIAS, SECOND_CLIENT_PASSWORD);\n\t\tsaveKeyAndCert(secondClient);\n\t}", "CodeBleu_score": 27.88085905553145}, {"code": "static void createCertificates() throws Exception{\n\t\t\tKeyTool keyTool = new KeyTool(KEY_PASSWORD);\n\t\tKeyAndCert caKeyCert = keyTool.createCA(\"ca\", \"CA\");\n\t\tKeyAndCert serverKeyCert = keyTool.createServerCert(\"server\", \"Server\", caKeyCert);\n\t\tKeyAndCert clientKeyCert = keyTool.createClientCert(\"client\", \"Client\", caKeyCert);\n\n\t\tsaveCert(caKeyCert);\n\t\tsaveKeyAndCert(serverKeyCert);\n\t\tsaveKeyAndCert(clientKeyCert);\n\n\t\tKeyAndCert secondCAKeyCert = keyTool.createCA(\"second-ca\", \"Second CA\");\n\t\tKeyAndCert secondClientKeyCert = keyTool.createClientCert(\"second-client\", \"Second Client\", secondCAKeyCert);\n\n\t\tsaveCert(secondCAKeyCert);\n\t\tsaveKeyAndCert(secondClientKeyCert);\n\t}", "CodeBleu_score": 32.16681484639824}, {"code": "static void createCertificates() throws Exception{\n\t\t\tKeyTool caKeyTool = new KeyTool(CA_KEY_PASSWORD);\n\t\tKeyTool serverKeyTool = new KeyTool(KEY_PASSWORD);\n\t\tKeyTool clientKeyTool = new KeyTool(KEY_PASSWORD);\n\n\t\tcaKeyTool.createKeyStore(CA_SUBJECT, CA_KEY_PASSWORD);\n\t\tserverKeyTool.createKeyStore(SERVER_SUBJECT, KEY_PASSWORD);\n\t\tclientKeyTool.createKeyStore(CLIENT_SUBJECT, KEY_PASSWORD);\n\n\t\tsaveCert(caKeyTool.createSelfSignedCert(CA_SUBJECT));\n\t\tsaveKeyAndCert(caKeyTool.signCert(CA_SUBJECT, serverKeyTool.createCSR(SERVER_SUBJECT)));\n\t\tsaveKeyAndCert(caKeyTool.signCert(CA_SUBJECT, clientKeyTool.createCSR(CLIENT_SUBJECT)));\n\n\t\tKeyTool secondCaKeyTool = new KeyTool(CA_KEY_PASSWORD);\n\t\tsecondCaKeyTool.createKeyStore(SECOND_CA_SUBJECT, CA_KEY_PASSWORD);\n\t\tKeyTool secondClientKeyTool = new KeyTool(KEY_PASSWORD);\n\t\tsecondClientKeyTool.createKeyStore(SECOND_CLIENT_SUBJECT, KEY_PASSWORD);\n\n\t\tsaveCert(secondCaKeyTool.createSelfSignedCert(SECOND_CA_SUBJECT));\n\t\tsaveKeyAndCert(secondCaKeyTool.signCert(SECOND_CA_SUBJECT, secondClientKeyTool.createCSR(SECOND_CLIENT_SUBJECT)));\n\t}", "CodeBleu_score": 17.80780370909777}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t  long startTime = System.currentTimeMillis();\n  long timeLimit = seconds * 1000L;\n  while (!assertion.getAsBoolean()) {\n    if (System.currentTimeMillis() - startTime >= timeLimit) {\n      throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n    }\n  }\n}", "CodeBleu_score": 41.87522727973167}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t  long startTime = System.currentTimeMillis();\n  long timeLimit = seconds * 1000;\n  while (!assertion.getAsBoolean() && System.currentTimeMillis() - startTime < timeLimit) {\n    try {\n      Thread.sleep(500);\n    } catch (InterruptedException e) {\n      throw new RuntimeException(e);\n    }\n  }\n  if (!assertion.getAsBoolean()) {\n    throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds.\");\n  }\n}", "CodeBleu_score": 37.554282493152705}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t  long startTime = System.currentTimeMillis();\n  long timeLimit = seconds * 1000;\n  while (!assertion.getAsBoolean()) {\n    long elapsedTime = System.currentTimeMillis() - startTime;\n    if (elapsedTime >= timeLimit) {\n      throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n    }\n  }\n}", "CodeBleu_score": 43.28469711317119}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\t\tbuilder.addExtension(Extension.keyUsage, false, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\t\tbuilder.addExtension(Extension.basicConstraints, false, new BasicConstraints(false));\n\n\t\treturn signCert(builder, keyPair.getPrivate());\n\t}", "CodeBleu_score": 74.84912981460779}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\t\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\t\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n\t\treturn signCert(builder, keyPair.getPrivate());\n\t}", "CodeBleu_score": 76.74321921144615}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\t\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\t\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n\t\treturn signCert(builder, keyPair.getPrivate());\n\t}", "CodeBleu_score": 76.74321921144615}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException | NoSuchFieldException e) {\n            log.error(\"Failed to retrieve EurekaHttpClient instance\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 47.40438066024314}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (EurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            EurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (NoSuchFieldException | IllegalAccessException e) {\n            logger.error(\"Failed to access registrationClient field in eurekaTransport\", e);\n        }\n    }\n    return EurekaHttpClient;\n}", "CodeBleu_score": 47.904465686348125}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (EurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            EurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            log.error(\"Failed to access registrationClient field\", e);\n        } catch (NoSuchFieldException e) {\n            log.error(\"Failed to find registrationClient field\", e);\n        }\n    }\n    return EurekaHttpClient;\n}", "CodeBleu_score": 52.19001665324781}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t        Applications applications = this.eurekaClient.getApplications();\n        if (applications == null) {\n            return Collections.emptyList();\n        }\n        List<String> names = new ArrayList<>();\n        for (Application app : applications.getRegisteredApplications()) {\n            if (!app.getInstances().isEmpty()) {\n                names.add(app.getName().toLowerCase());\n            }\n        }\n        return names;\n    }", "CodeBleu_score": 73.20777822787151}, {"code": "public List<String> getServices(){\n\t    Applications applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return Collections.emptyList();\n    }\n    List<String> services = new ArrayList<>();\n    for (Application app : applications.getRegisteredApplications()) {\n        if (!app.getInstances().isEmpty()) {\n            services.add(app.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 61.859258985603326}, {"code": "public List<String> getServices(){\n\t\t\tApplications applications = this.eurekaClient.getApplications();\n\t\tif (applications == null) {\n\t\t\treturn Collections.emptyList();\n\t\t}\n\t\tList<Application> registered = applications.getRegisteredApplications();\n\t\tList<String> names = new ArrayList<>();\n\t\tfor (Application app : registered) {\n\t\t\tif (!app.getInstances().isEmpty()) {\n\t\t\t\tnames.add(app.getName().toLowerCase());\n\t\t\t}\n\t\t}\n\t\treturn names;\n\t}", "CodeBleu_score": 87.07022243069571}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (HealthIndicator healthIndicator : discoveryCompositeHealthContributor.getHealthIndicators()) {\n                if (!(healthIndicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(healthIndicator.getClass().getSimpleName(), healthIndicator);\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 47.07859051515874}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.forEach((k, v) -> {\n        if (v instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) v;\n            discoveryCompositeHealthContributor.getContributors().forEach((k1, v1) -> {\n                if (!(v1 instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(k1, v1);\n                }\n            });\n        } else {\n            healthContributors.put(k, v);\n        }\n    });\n}", "CodeBleu_score": 35.211783239011055}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        String name = entry.getKey();\n        HealthContributor contributor = entry.getValue();\n        if (contributor instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryComposite = (DiscoveryCompositeHealthContributor) contributor;\n            for (Map.Entry<String, HealthIndicator> indicatorEntry : discoveryComposite.getIndicators().entrySet()) {\n                String indicatorName = indicatorEntry.getKey();\n                HealthIndicator indicator = indicatorEntry.getValue();\n                if (!(indicator instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(name + \".\" + indicatorName, indicator);\n                }\n            }\n        } else {\n            healthContributors.put(name, contributor);\n        }\n    }\n}", "CodeBleu_score": 39.73087043053417}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances == null || instances.isEmpty()) {\n        throw new RuntimeException(\"No service instance for provider-application found\");\n    }\n    ServiceInstance instance = instances.get(0);\n    String url = instance.getUri().toString() + \"/echo\";\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.postForEntity(url, \"hello\", String.class);\n    return response.getBody();\n}", "CodeBleu_score": 61.43049174772226}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances != null && !instances.isEmpty()) {\n        ServiceInstance instance = instances.get(0);\n        String url = instance.getUri().toString() + \"/echo\";\n        RestTemplate restTemplate = new RestTemplate();\n        String response = restTemplate.postForObject(url, \"Hello\", String.class);\n        return response;\n    } else {\n        throw new RuntimeException(\"Unable to discover any service instances for provider-application\");\n    }\n}", "CodeBleu_score": 58.23909749624534}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances != null && !instances.isEmpty()) {\n        ServiceInstance instance = instances.get(0);\n        String url = instance.getUri().toString() + \"/echo\";\n        RestTemplate restTemplate = new RestTemplate();\n        String response = restTemplate.postForObject(url, \"Hello from consumer-application\", String.class);\n        return response;\n    } else {\n        throw new RuntimeException(\"No instances of provider-application found\");\n    }\n}", "CodeBleu_score": 58.76907428738236}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t    List<ServiceInstance> instances = loadBalancerClient.choose(\"provider-application\");\n    if (instances != null && !instances.isEmpty()) {\n        ServiceInstance instance = instances.get(0);\n        String uri = instance.getUri().toString();\n        RestTemplate restTemplate = new RestTemplate();\n        String response = restTemplate.postForObject(uri + \"/echo\", \"Hello World\", String.class);\n        return response;\n    } else {\n        throw new RuntimeException(\"No service instance found for provider-application\");\n    }\n}", "CodeBleu_score": 56.703781461890635}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No instance available\");\n    }\n    URI uri = instance.getUri();\n    if (uri != null) {\n        return (new RestTemplate()).postForObject(uri.toString() + \"/echo\", \"hello\", String.class);\n    }\n    return null;\n}", "CodeBleu_score": 48.29694041888427}, {"code": "public String world(){\n\t    // Use a load balancer client to retrieve a service instance named \"provider-application\"\n    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    // Construct a URI to the \"/echo\" endpoint of the chosen instance\n    URI uri = URI.create(String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort()));\n    // Send a POST request to the \"/echo\" endpoint of the chosen instance using a RestTemplate\n    return restTemplate.postForObject(uri, \"hello\", String.class);\n}", "CodeBleu_score": 44.60797079781034}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    synchronized (serverMap) {\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n    }\n    logger.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    return true;\n}", "CodeBleu_score": 48.166359892913476}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    logger.info(\"Registered service {} with IP {} and port {}\", serviceName, ip, port);\n    return true;\n}", "CodeBleu_score": 59.09553471428977}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n    }\n    Server server = new Server(ip, port);\n    serverMap.get(serviceName).add(server);\n    logger.info(\"Registered service: {} with ip: {} and port: {}\", serviceName, ip, port);\n    return true;\n}", "CodeBleu_score": 71.16733363797523}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Deregistering service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers != null) {\n        Server server = new Server(ip, port);\n        servers.remove(server);\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 61.32070258296527}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"deregister service:{},ip:{},port:{}\", serviceName, ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        return false;\n    }\n    Server server = new Server(ip, port);\n    return servers.remove(server);\n}", "CodeBleu_score": 63.5157166581678}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"deregister service: {}, ip: {}, port: {}\", serviceName, ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers != null) {\n        Server server = new Server(ip, port);\n        servers.remove(server);\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 74.39985650511545}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t        Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n        if (attributes != null) {\n            Map<String, Object> clientsAttributes = (Map<String, Object>) attributes.get(\"value\");\n            if (clientsAttributes != null) {\n                clientsAttributes.keySet().forEach(name -> {\n                    Map<String, Object> clientAttributes = (Map<String, Object>) clientsAttributes.get(name);\n                    Object configuration = clientAttributes.get(\"defaultConfiguration\");\n                    if (configuration != null) {\n                        registerClientConfiguration(registry, name, configuration);\n                    }\n                });\n            }\n        }\n    }", "CodeBleu_score": 42.64825697112389}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t        Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n        if (attributes == null) {\n            return;\n        }\n        Map<String, Object> defaultAttributes = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\n        if (defaultAttributes != null) {\n            String name = \"default.\" + RibbonClientConfigurationRegistrar.class.getSimpleName();\n            registerClientConfiguration(registry, name, defaultAttributes);\n        }\n    }", "CodeBleu_score": 52.93602798043319}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t        Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n        Map<String, Object> defaultAttributes = metadata.getAnnotationAttributes(RibbonClient.class.getName());\n        if (defaultAttributes != null) {\n            attributes.putAll(defaultAttributes);\n        }\n        if (attributes != null) {\n            Object defaultConfiguration = attributes.remove(\"defaultConfiguration\");\n            if (defaultConfiguration != null) {\n                String name = \"default.\" + RibbonClientConfigurationRegistrar.class.getSimpleName();\n                this.registerClientConfiguration(registry, name, defaultConfiguration);\n            }\n            Object configurations = attributes.get(\"value\");\n            if (configurations != null && configurations.getClass().isArray()) {\n                for (RibbonClient client : (RibbonClient[]) configurations) {\n                    this.registerClientConfiguration(registry, client.name(), client.configuration());\n                }\n            }\n        }\n    }", "CodeBleu_score": 45.8544958958128}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance server = getInstance(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 46.14593270552219}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance server = getInstance(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(server);\n}", "CodeBleu_score": 28.021227384483684}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ServiceInstance instance = super.choose(serviceId, request);\n    if (instance == null) {\n        return null;\n    }\n    return new TutuServiceInstance(instance, serviceId);\n}", "CodeBleu_score": 31.79179436481502}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        // Extract the service name from the original URI\n        String serviceName = original.getHost();\n        // Replace the service name with the IP address and port of the service instance\n        String newURI = original.toString().replace(serviceName, server.getIp() + \":\" + server.getPort());\n        // If the original URI includes a query string, append it to the reconstructed URI\n        if (original.getQuery() != null) {\n            newURI += \"?\" + original.getQuery();\n        }\n        return new URI(newURI);\n    } catch (URISyntaxException e) {\n        // If any errors occur during URI construction, throw a RuntimeException\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 41.46918185768536}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        // Extract the service name from the original URI\n        String serviceName = original.getHost();\n        // Replace the service name with the IP address and port of the service instance\n        String newURI = original.getScheme() + \"://\" + server.getIP() + \":\" + server.getPort() + original.getPath();\n        // If the original URI includes a query string, append it to the reconstructed URI\n        if (original.getQuery() != null) {\n            newURI += \"?\" + original.getQuery();\n        }\n        // Return the reconstructed URI as a URI object\n        return new URI(newURI);\n    } catch (URISyntaxException e) {\n        // If any errors occur during URI construction, throw a RuntimeException\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 42.444687244400036}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    String uri = original.toString();\n    uri = uri.replaceFirst(server.getServiceId(), server.getHost() + \":\" + server.getPort());\n    try {\n        URI newURI = new URI(uri);\n        if (original.getQuery() != null) {\n            newURI = new URI(newURI.getScheme(), newURI.getUserInfo(), newURI.getHost(), newURI.getPort(), newURI.getPath(), original.getQuery(), newURI.getFragment());\n        }\n        return newURI;\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 46.78358286892963}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    List<TutuServer> list = new ArrayList<>();\n    String serviceName = \"tutu-service\";\n    String serverAddress = \"http://localhost:8080\";\n    String url = serverAddress + \"/list?serviceName=\" + serviceName;\n    try {\n        HttpGet request = new HttpGet(url);\n        HttpResponse response = httpClient.execute(request);\n        HttpEntity entity = response.getEntity();\n        if (entity != null) {\n            String result = EntityUtils.toString(entity, \"UTF-8\");\n            JSONArray jsonArray = new JSONArray(result);\n            for (int i = 0; i < jsonArray.length(); i++) {\n                JSONObject jsonObject = jsonArray.getJSONObject(i);\n                String ip = jsonObject.getString(\"ip\");\n                int port = jsonObject.getInt(\"port\");\n                TutuServer tutuServer = new TutuServer(ip, port);\n                list.add(tutuServer);\n            }\n        }\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    return list;\n}", "CodeBleu_score": 36.08312703485011}, {"code": "private List<TutuServer> getServer(){\n\t    String serverAddress = \"http://localhost:8080\";\n    String serviceName = \"tutu-server\";\n    String url = serverAddress + \"/list?serviceName=\" + serviceName;\n    try {\n        HttpClient client = HttpClient.newHttpClient();\n        HttpRequest request = HttpRequest.newBuilder()\n                .uri(URI.create(url))\n                .build();\n        HttpResponse<String> response = client.send(request, HttpResponse.BodyHandlers.ofString());\n        String json = response.body();\n        List<TutuServer> servers = new ArrayList<>();\n        JSONArray jsonArray = new JSONArray(json);\n        for (int i = 0; i < jsonArray.length(); i++) {\n            JSONObject jsonObject = jsonArray.getJSONObject(i);\n            String ip = jsonObject.getString(\"ip\");\n            int port = jsonObject.getInt(\"port\");\n            TutuServer server = new TutuServer(ip, port);\n            servers.add(server);\n        }\n        return servers;\n    } catch (Exception e) {\n        e.printStackTrace();\n        return null;\n    }\n}", "CodeBleu_score": 35.871191592532604}, {"code": "private List<TutuServer> getServer(){\n\t    String server = \"http://192.168.1.101:8080\";\n    String serviceName = \"tutu-server\";\n\n    String url = server + \"/list?serviceName=\" + serviceName;\n\n    RestTemplate restTemplate = new RestTemplate();\n    ResponseEntity<String> response = restTemplate.getForEntity(url, String.class);\n\n    String json = response.getBody();\n\n    List<TutuServer> serverList = new ArrayList<>();\n\n    try {\n        JSONArray jsonArray = new JSONArray(json);\n        for (int i = 0; i < jsonArray.length(); i++) {\n            JSONObject jsonObject = jsonArray.getJSONObject(i);\n            String ip = jsonObject.getString(\"ip\");\n            int port = jsonObject.getInt(\"port\");\n            serverList.add(new TutuServer(ip, port));\n        }\n    } catch (JSONException e) {\n        e.printStackTrace();\n    }\n\n    return serverList;\n}", "CodeBleu_score": 35.252668544000784}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : routes) {\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.substring(route.getPath().length());\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 35.30272111817438}, {"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : routes.values()) {\n        String pattern = route.getPath();\n        boolean isMatch = pathMatcher.match(pattern, path);\n        if (isMatch) {\n            String targetPath = path.substring(pattern.length());\n            return new Route(targetPath, route.getServiceId(), null, null, false, null);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 42.649954323450444}, {"code": "public Route getMatchingRoute(String path){\n\t    for (ZuulRoute route : routes) {\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.substring(route.getPath().length());\n            return new Route(targetPath, route.getLocation());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 34.74839055503531}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    // Get the package name of the importing class\n    String basePackage = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n\n    // Get all classes annotated with @FeignClient within the package\n    Set<BeanDefinitionHolder> beanDefinitions = new LinkedHashSet<>();\n    try {\n        // Scan for classes annotated with @FeignClient\n        ConfigurationClassParser parser = new ConfigurationClassParser(\n                this.metadataReaderFactory, this.problemReporter, this.environment,\n                this.resourceLoader, this.componentFactory, this.registry);\n        parser.registerBeanDefinitions(basePackage, beanDefinitions);\n    }\n    catch (BeanDefinitionStoreException ex) {\n        throw new IllegalStateException(\n                \"Cannot load configuration class: \" + ex.getMessage(), ex);\n    }\n\n    // Register the bean definitions\n    for (BeanDefinitionHolder holder : beanDefinitions) {\n        // Create a GenericBeanDefinition for the annotated class\n        GenericBeanDefinition definition = new GenericBeanDefinition();\n        definition.setBeanClass(FeignClientFactoryBean.class);\n        definition.getPropertyValues().add(\"contextId\", holder.getBeanName());\n        definition.getPropertyValues().add(\"type\", holder.getBeanClassName());\n        definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n\n        // Register the bean definition with the bean name as the bean name\n        registry.registerBeanDefinition(holder.getBeanName(), definition);\n    }\n}", "CodeBleu_score": 41.755866864487366}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n    scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n    Set<BeanDefinition> alreadyRegistered = new HashSet<>();\n    for (String basePackage : getBasePackages(importingClassMetadata)) {\n        Set<BeanDefinition> candidates = scanner.findCandidateComponents(basePackage);\n        for (BeanDefinition candidate : candidates) {\n            if (candidate instanceof AnnotatedBeanDefinition) {\n                AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidate;\n                if (beanDefinition.getMetadata().isIndependent()) {\n                    if (alreadyRegistered.contains(beanDefinition)) {\n                        continue;\n                    }\n                    alreadyRegistered.add(beanDefinition);\n                    String beanName = beanDefinition.getBeanClassName();\n                    BeanDefinitionBuilder definition = BeanDefinitionBuilder\n                            .genericBeanDefinition(FeignClientFactoryBean.class);\n                    definition.addConstructorArgValue(beanName);\n                    definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n                    definition.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n                    definition.getRawBeanDefinition().setSource(beanDefinition.getSource());\n                    registry.registerBeanDefinition(beanName, definition.getBeanDefinition());\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 33.47837785744119}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    ClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n    scanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n    for (String basePackage : getBasePackages(importingClassMetadata)) {\n        Set<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n        for (BeanDefinition candidateComponent : candidateComponents) {\n            if (candidateComponent instanceof AnnotatedBeanDefinition) {\n                AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n                AnnotationAttributes attributes = AnnotationAttributes.fromMap(beanDefinition.getMetadata().getAnnotationAttributes(FeignClient.class.getName()));\n                String contextId = attributes.getString(\"contextId\");\n                String type = attributes.getString(\"type\");\n                GenericBeanDefinition definition = new GenericBeanDefinition();\n                definition.setBeanClass(FeignClientFactoryBean.class);\n                definition.getConstructorArgumentValues().addGenericArgumentValue(contextId);\n                definition.getConstructorArgumentValues().addGenericArgumentValue(type);\n                definition.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n                String beanName = candidateComponent.getBeanClassName();\n                registry.registerBeanDefinition(beanName, definition);\n            }\n        }\n    }\n}", "CodeBleu_score": 35.44755913529227}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
