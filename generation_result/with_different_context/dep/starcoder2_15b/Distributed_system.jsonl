{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time, _ = self._orig_connect(*args)\n    wait_time = max(2, wait_time) * 1000\n    return wait_time, _\n\n", "CodeBleu_score": 44.27654276721716}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original method's return value. The wait time is determined by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original method_connect's return value. The wait time is determined by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original method_connect's return value. The wait time is determined by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original method_connect's return value. The wait time is determined by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original method_connect's return value. The wait time is determined by subtracting 2 from the loop_wait attribute, ensuring it does not go below 2, and then multiplying by 1000.\n    # This function, _kazoo_connect, calls an original connection method with any given arguments, captures its return value, and then returns a tuple. The tuple consists of a calculated wait time in milliseconds and the second element of the original", "CodeBleu_score": 23.214285714285715}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    self._log.debug(f\"Calling original connect method with args: {args}\")\n    result = self._orig_connect(*args)\n    self._log.debug(f\"Original connect method returned: {result}\")\n    wait_time = max(self.loop_wait - 2, 0) * 1000\n    return wait_time, result[1]\n\n", "CodeBleu_score": 46.64327320122694}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, dict):\n        config = Config(config)\n    if self._config!= config:\n        self._config = config\n        self.set_retry_timeout(self._config.retry_timeout)\n        self.set_ttl(self._config.ttl)\n        self.set_loop_wait(self._config.loop_wait)\n        if isinstance(self._client._handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(self._config.loop_wait)\n        if self.set_ttl(self._config.ttl) and self._config.loop_wait!= self._loop_wait:\n            self._client.close()\n", "CodeBleu_score": 41.138799741212495}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, Config):\n        config = config.data\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_loop_wait(config['loop_wait'])\n    if self.set_ttl(config['ttl']):\n        if isinstance(self._client._handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(config['loop_wait'])\n        else:\n            self._client._socket.close()\n", "CodeBleu_score": 43.10850577083316}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t    if isinstance(config, Config):\n        config = config.as_dict()\n    self.set_retry_timeout(config.get('retry_timeout', self._retry_timeout))\n    self.set_ttl(config.get('ttl', self._ttl))\n    self.set_loop_wait(config.get('loop_wait', self._loop_wait))\n    if isinstance(self._client._handler, PatroniSequentialThreadingHandler):\n        self.set_connect_timeout(config.get('connect_timeout', self._connect_timeout))\n    if self.set_ttl(config.get('ttl', self._ttl)):\n        try:\n            self._client.close()\n        except Exception:\n            pass\n\n", "CodeBleu_score": 39.40477607337158}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    init_state = self.get_node(path + self._INIT_STATE)\n    config = self.get_node(path + self._CONFIG)\n    timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    sync_state = self.get_node(path + self._SYNC_STATE)\n    members = self.load_members(path)\n    leader = self.get_node(path + self._LEADER)\n    status = self.get_status(path, leader)\n    failover_state = self.get_node(path + self._FAILOVER_STATE)\n    failsafe = self.get_node(path + self._FAILSAFE)\n    return Cluster(\n        init_state=init_state,\n        config=config,\n        timeline_history=timeline_history,\n        sync_state=sync_state,\n        members=members,\n        leader=leader,\n        status=status,\n        failover_state=failover_state,\n        failsafe=failsafe,\n    )", "CodeBleu_score": 16.221270239466378}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    cluster = Cluster(path)\n    cluster.initialized = self.get_node(path + self._INITIALIZED)\n    cluster.configuration = self.get_node(path + self._CONFIGURATION)\n    cluster.timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    cluster.synchronization = self.get_node(path + self._SYNCHRONIZATION)\n    cluster.members = self.load_members(path)\n    cluster.leader = self.get_leader(path)\n    cluster.status = self.get_status(path, cluster.leader)\n    cluster.failover = self.get_node(path + self._FAILOVER)\n    cluster.failsafe = self.get_node(path + self._FAILSAFE)\n    return cluster\n\n", "CodeBleu_score": 13.269505649400411}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    if not self.exists(path):\n        raise ValueError(f\"Cluster path {path} does not exist\")\n\n    # Check if the cluster is initialized\n    if self.exists(path + self._INITIALIZED):\n        initialized = True\n    else:\n        initialized = False\n\n    # Check if the cluster is running\n    if self.exists(path + self._RUNNING):\n        running = True\n    else:\n        running = False\n\n    # Load the configuration\n    config = self.get_node(path + self._CONFIG)\n    if config:\n        config = config[0]\n    else:\n        config = None\n\n    # Load the timeline history\n    timeline_history = self.get_node(path + self._TIMELINE_HISTORY)\n    if timeline_history:\n        timeline_history = timeline_history[0]\n    else:\n        timeline_history = None\n\n    # Load the synchronization state\n    sync_state = self.get_node(path + self._SYNC_STATE)\n    if sync_state:\n        sync_state = sync_state[0]\n    else:\n        sync_state = None\n\n    # Load the members\n    members = self.load_members(path)\n\n    # Load the leader information\n    leader = self.get_leader(path)\n\n    # Load the cluster status\n    status = self.get_status(path, leader)\n\n    # Load the failover state\n    failover_state = self.get_node(path + self._FAILOVER_STATE)\n    if failover_state:\n        failover_state = failover_state[0]\n    else:\n        failover_state = None\n\n    # Load the failsafe configuration\n    failsafe = self.get_node(path + self._FAILSAFE)\n    if failsafe:\n        failsafe = failsafe[0]\n    else:\n        failsafe = None\n\n    return Cluster(\n        initialized=initialized,\n        running=running,\n        config=config,\n        timeline_history=timeline_history,\n        sync_state=sync_state,\n        members=members,\n        leader=leader,\n        status=status,\n        failover_state=failover_state,\n        failsafe=failsafe,\n    )", "CodeBleu_score": 31.451948604011115}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._zk.create(self._path, ephemeral=True, sequence=True)\n        return True\n    except ZooKeeperError as e:\n        if self._zk.state == ZooKeeperState.CLOSED:\n            raise e\n        if not self._retry_on_connection_loss(e):\n            raise e\n    except NodeExistsError:\n        pass\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(f\"Error acquiring leader lock: {e}\")\n    logger.info(\"Failed to acquire leader lock\")\n    return False\n\n", "CodeBleu_score": 57.69914433302426}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self._zk is None:\n        raise ZooKeeperError(\"ZooKeeper connection is closed\")\n    try:\n        self._zk.create(self._path, ephemeral=True)\n        self._is_leader = True\n        return True\n    except NodeExistsError:\n        self._is_leader = False\n        return False\n    except Exception as e:\n        if isinstance(e, ZooKeeperError):\n            raise\n        if not self._retry_acquire_leader():\n            self._logger.info(\"Failed to acquire leader lock, retrying\")\n            return False\n        return True\n\n", "CodeBleu_score": 43.23109766846832}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, ephemeral=True, sequence=True)\n        return True\n    except ConnectionClosedError:\n        raise ZooKeeperError(\"Lost connection to ZooKeeper.\")\n    except ZooKeeperError as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(\"Failed to acquire lock: %s\", e)\n        return False\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logger.error(\"Failed to acquire lock: %s\", e)\n        return False\n\n", "CodeBleu_score": 57.636572355796666}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self._client_id!= leader.session:\n        logger.warning(\n            \"Client ID %d does not match leader session %d\",\n            self._client_id,\n            leader.session,\n        )\n        try:\n            self._zk.delete(self._leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        except ZooKeeperError as e:\n            logger.warning(\"Failed to delete leader: %s\", e)\n            return False\n        try:\n            self._zk.create(\n                self._leader_path,\n                ephemeral=True,\n                sequence=True,\n                value=self._client_id.to_bytes(8, \"big\"),\n            )\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError:\n            pass\n        except ZooKeeperError as e:\n            logger.warning(\"Failed to create leader: %s\", e)\n            return False\n    return True\n\n", "CodeBleu_score": 46.200638004133275}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session!= self.client_id:\n        self.logger.warning(\n            \"Client %s is not the leader, \"\n            \"but is trying to update the leader node\",\n            self.client_id,\n        )\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            pass\n        except RetryFailedError as exc:\n            self.logger.warning(\n                \"Failed to delete leader node: %s\", exc\n            )\n        else:\n            try:\n                self.zk.create(\n                    self.leader_path,\n                    self.client_id.encode(\"utf-8\"),\n                    ephemeral=True,\n                )\n            except NodeExistsError:\n                self.logger.warning(\n                    \"Failed to create leader node: \"\n                    \"node already exists\"\n                )\n                return False\n            except ConnectionClosedError:\n                self.logger.warning(\n                    \"Failed to create leader node: \"\n                    \"connection closed\"\n                )\n                return False\n            except RetryFailedError as exc:\n                self.logger.warning(\n                    \"Failed to create leader node: %s\", exc\n                )\n                return False\n            else:\n                self.logger.info(\n                    \"Client %s is the new leader\", self.client_id\n                )\n                return True\n    else:\n        self.logger.info(\n            \"Client %s is still the leader\", self.client_id\n        )\n        return True\n\n", "CodeBleu_score": 38.64012732128768}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session!= self.client_id:\n        logger.warning(\n            \"Client ID mismatch: %s!= %s\",\n            leader.session,\n            self.client_id,\n        )\n        try:\n            self.delete(leader.path)\n        except (\n            NoNodeError,\n            ConnectionClosedError,\n            RetryFailedError,\n        ) as e:\n            logger.debug(\"Ignoring error: %s\", e)\n        else:\n            try:\n                self.create(\n                    leader.path,\n                    self.client_id.encode(\"utf-8\"),\n                    ephemeral=True,\n                )\n                return True\n            except Exception as e:\n                logger.debug(\"Error creating leader: %s\", e)\n                return False\n    return True\n\n", "CodeBleu_score": 41.0303401306328}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None or time.time() - self._last_poll_time > self._poll_interval:\n        self._last_poll_time = time.time()\n        logging.debug('Polling for new connection string')\n        new_hosts = self._query_exhibitors(self._exhibitors)\n        if new_hosts is not None:\n            new_connection_string = ','.join(['{0}:{1}'.format(host['hostname'], host['port']) for host in new_hosts])\n            if new_connection_string!= self._connection_string:\n                logging.info('Connection string changed to %s', new_connection_string)\n                self._connection_string = new_connection_string\n                self._connection_string_changed = True\n                return True\n            else:\n                logging.debug('Connection string unchanged')\n        else:\n            logging.debug('No valid data returned from exhibitors')\n    return False", "CodeBleu_score": 38.159251229594524}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time + self._poll_interval > time.time():\n        return False\n\n    self._last_poll_time = time.time()\n    exhibitors = self._query_exhibitors(self._exhibitors)\n    if exhibitors is None:\n        return False\n\n    zk_conn_str = self._get_zk_conn_str(exhibitors)\n    if self._zk_conn_str!= zk_conn_str:\n        logging.info('ZooKeeper connection string changed from %s to %s', self._zk_conn_str, zk_conn_str)\n        self._zk_conn_str = zk_conn_str\n        return True\n\n    return False", "CodeBleu_score": 32.39862844134894}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll_time is None or time.time() - self._last_poll_time > self._poll_interval:\n        self._last_poll_time = time.time()\n        data = self._query_exhibitors(self._exhibitors)\n        if data is not None:\n            new_connection_string = self._build_connection_string(data)\n            if new_connection_string!= self._connection_string:\n                logging.info('Updating ZooKeeper connection string from %s to %s', self._connection_string, new_connection_string)\n                self._connection_string = new_connection_string\n                return True\n    return False", "CodeBleu_score": 32.53367345299023}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t   if self._ensemble_provider.poll():\n        self._client.set_hosts(self._ensemble_provider.zookeeper_hosts)\n    return super(Exhibitor, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 96.93873121769799}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t\tif (zookeeperListener!= null) {\n\t\tString group = zookeeperListener.getGroup();\n\t\tString dataId = zookeeperListener.getDataId();\n\t\tlogger.info(\"unsubscribe config from zookeeper, group: {}, dataId: {}\", group, dataId);\n\t\ttry {\n\t\t\tzookeeperListener.unsubscribe();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"unsubscribe config from zookeeper error\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 39.05816217207085}, {"code": "public void destroy(){\n\t\tif (zookeeperListener == null) {\n\t\treturn;\n\t}\n\tString group = zookeeperListener.getGroup();\n\tString dataId = zookeeperListener.getDataId();\n\tlog.info(\"unsubscribe config, group: {}, dataId: {}\", group, dataId);\n\ttry {\n\t\tzookeeperListener.unsubscribe();\n\t} catch (Exception e) {\n\t\tlog.error(\"unsubscribe config, group: {}, dataId: {}, error: {}\", group, dataId, e.getMessage());\n\t}\n}", "CodeBleu_score": 48.5804646291008}, {"code": "public void destroy(){\n\t\tif (zookeeperListener!= null) {\n\t\tString group = zookeeperListener.getGroup();\n\t\tString dataId = zookeeperListener.getDataId();\n\t\tlog.info(\"Unsubscribe configuration from Zookeeper, group: {}, dataId: {}\", group, dataId);\n\t\ttry {\n\t\t\tzookeeperListener.unsubscribe();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Unsubscribe configuration from Zookeeper error, group: {}, dataId: {}\", group, dataId, e);\n\t\t}\n\t}\n}", "CodeBleu_score": 38.08517928896975}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\tZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\t\treturn zookeeperServer.getMetadata();\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 62.972505512959145}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getMetadata();\n\t}\n\treturn new HashMap<String, String>();\n}", "CodeBleu_score": 35.57042353815384}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t\tif (server instanceof ZookeeperServer) {\n\t\treturn ((ZookeeperServer) server).getPayload().getMetadata();\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 38.65338413283172}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = ZookeeperUtils.getPath(group, serviceId);\n\treturn subscribeConfig(path, zookeeperSubscribeCallback);\n}", "CodeBleu_score": 13.404519285765065}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = String.format(\"/%s/%s/%s\", group, serviceId, \"config\");\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path);\n\tnodeCache.start();\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = convertConfig(curatorFramework, path);\n\t\t\tzookeeperSubscribeCallback.onConfigChange(config);\n\t\t}\n\t};\n\tnodeCache.getListenable().addListener(nodeCacheListener);\n\tZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n\tzookeeperListeners.add(zookeeperListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 68.8816319653282}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t\tString path = getPath(group, serviceId);\n\tNodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n\tnodeCache.start();\n\tNodeCacheListener nodeCacheListener = new NodeCacheListener() {\n\t\t@Override\n\t\tpublic void nodeChanged() throws Exception {\n\t\t\tString config = convertConfig(nodeCache.getCurrentData().getData());\n\t\t\tzookeeperSubscribeCallback.callback(config);\n\t\t}\n\t};\n\tZookeeperListener zookeeperListener = new ZookeeperListener();\n\tzookeeperListener.setNodeCache(nodeCache);\n\tzookeeperListener.setNodeCacheListener(nodeCacheListener);\n\tzookeeperListener.addListener(nodeCache, nodeCacheListener);\n\treturn zookeeperListener;\n}", "CodeBleu_score": 69.54363561347488}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList serverList = new ZookeeperServerList(config, serviceDiscovery);\n\tserverList.setServerListFilter(this.serverListFilter);\n\tserverList.setServerListUpdater(this.serverListUpdater);\n\treturn serverList;\n}", "CodeBleu_score": 44.84590659555758}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\treturn new ZookeeperServerListDecorator(serviceDiscovery, config, new ZookeeperLoadBalancerContext(config));\n}", "CodeBleu_score": 19.939859013587057}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t\tZookeeperServerList zsl = new ZookeeperServerList(serviceDiscovery, config);\n\tZookeeperServerListDecorator zslDecorator = new ZookeeperServerListDecorator(zsl, config);\n\tzslDecorator.setLoadBalancer(getLoadBalancer());\n\tzslDecorator.setServiceId(getServiceId());\n\treturn zslDecorator;\n}", "CodeBleu_score": 38.01990443941639}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onRegister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.72512978610983}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.79794007709059}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 87.79794007709059}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}, {"code": "public void deregister(ZookeeperRegistration registration){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onDeregister(registration);\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.deregister(registration);\n}", "CodeBleu_score": 87.78401070371797}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\ttry {\nRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\nregisterListenerExecutor.onClose();\n} catch (BeansException e) {\n// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 95.55281258320267}, {"code": "public void close(){\n\t\ttry {\n\t\tRegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n\t\tregisterListenerExecutor.onClose();\n\t} catch (BeansException e) {\n\t\t// LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n\t}\n\n\tserviceRegistry.close();\n}", "CodeBleu_score": 95.6448461355359}, {"code": "public void close(){\n\ttry {\n    RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n    registerListenerExecutor.onClose();\n} catch (BeansException e) {\n    // LOG.warn(\"Get bean for RegisterListenerExecutor failed, ignore to executor listener\");\n}\n\nserviceRegistry.close();\n}", "CodeBleu_score": 96.77129170072129}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalGroup : localGroup;\n\tString dataId = globalConfig? globalDataId : localDataId;\n\tlog.info(\"subscribe config, group: {}, dataId: {}\", group, dataId);\n\ttry {\n\t\treturn zookeeperOperation.subscribeConfig(group, dataId, (configInfo, ex) -> {\n\t\t\tif (ex == null) {\n\t\t\t\tlog.info(\"get config info: {}\", configInfo);\n\t\t\t\tif (globalConfig) {\n\t\t\t\t\tglobalConfigInfo = configInfo;\n\t\t\t\t} else {\n\t\t\t\t\tlocalConfigInfo = configInfo;\n\t\t\t\t}\n\t\t\t\tif (configInfo!= null) {\n\t\t\t\t\tString content = configInfo.getContent();\n\t\t\t\t\tif (StringUtils.isNotBlank(content)) {\n\t\t\t\t\t\tif (globalConfig) {\n\t\t\t\t\t\t\tglobalConfig = parseConfig(content);\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\tlocalConfig = parseConfig(content);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} else {\n\t\t\t\tlog.error(\"get config info error\", ex);\n\t\t\t}\n\t\t});\n\t} catch (Exception e) {\n\t\tlog.error(\"subscribe config error\", e);\n\t}\n\treturn null;\n}", "CodeBleu_score": 42.14662562345809}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? globalConfigGroup : localConfigGroup\n\tString dataId = globalConfig? globalConfigDataId : localConfigDataId\n\tlog.info(\"Subscribing to $group:$dataId\")\n\ttry {\n\t\tZookeeperListener listener = zookeeperOperation.subscribe(group, dataId) { String data ->\n\t\t\tlog.info(\"Received configuration update for $group:$dataId\")\n\t\t\tlog.debug(\"Received configuration update for $group:$dataId: $data\")\n\t\t\tupdateConfig(data, globalConfig)\n\t\t}\n\t\treturn listener\n\t} catch (Exception e) {\n\t\tlog.error(\"Failed to subscribe to $group:$dataId\", e)\n\t}\n\treturn null\n}", "CodeBleu_score": 32.78774446725144}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t\tString group = globalConfig? \"global\" : \"application\";\n\tString dataId = globalConfig? \"global.properties\" : applicationName + \".properties\";\n\tlogger.info(\"subscribeConfig {} {} {} {}\", group, dataId, applicationName, configService);\n\treturn zookeeperOperation.subscribeConfig(group, dataId, new ConfigListener() {\n\t\t@Override\n\t\tpublic void receiveConfigInfo(String configInfo) {\n\t\t\tlogger.info(\"receiveConfigInfo {}\", configInfo);\n\t\t\tif (configInfo == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tif (globalConfig) {\n\t\t\t\tglobalConfigInfo = configInfo;\n\t\t\t} else {\n\t\t\t\tconfigInfoMap.put(applicationName, configInfo);\n\t\t\t}\n\t\t\tif (configService!= null) {\n\t\t\t\tconfigService.receiveConfigInfo(applicationName, configInfo);\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 33.927416726708785}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = System.getenv(\"ZK_CONNECTION_STRING\");\n\tif (connectionString == null || connectionString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"Zookeeper connection string is empty\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZK_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZK_SLEEP_TIME\"));\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 33.95068891219803}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString connectionString = environment.getProperty(CONNECTION_STRING_PROPERTY);\n\tif (StringUtils.isEmpty(connectionString)) {\n\t\tthrow new DiscoveryException(\n\t\t\t\t\"Zookeeper connection string not specified in environment\");\n\t}\n\tint retryCount = environment.containsProperty(RETRY_COUNT_PROPERTY)?\n\t\t\tenvironment.getProperty(RETRY_COUNT_PROPERTY, Integer.class) : DEFAULT_RETRY_COUNT;\n\tint retrySleepTime = environment.containsProperty(RETRY_SLEEP_TIME_PROPERTY)?\n\t\t\tenvironment.getProperty(RETRY_SLEEP_TIME_PROPERTY, Integer.class) : DEFAULT_RETRY_SLEEP_TIME;\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(connectionString,\n\t\t\tnew ExponentialBackoffRetry(retrySleepTime, retryCount));\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 44.47260131750671}, {"code": "public CuratorFramework curatorFramework(){\n\t\tString zkConnectionString = System.getenv(\"ZK_CONNECTION_STRING\");\n\tif (zkConnectionString == null || zkConnectionString.isEmpty()) {\n\t\tthrow new DiscoveryException(\"ZK_CONNECTION_STRING is not set\");\n\t}\n\tint retryCount = Integer.parseInt(System.getenv(\"ZK_RETRY_COUNT\"));\n\tint sleepTime = Integer.parseInt(System.getenv(\"ZK_SLEEP_TIME\"));\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.newClient(zkConnectionString, new ExponentialBackoffRetry(sleepTime, retryCount));\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 32.7691073962136}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * GatewayStrategyRouteZookeeperProcessor is a bean of type {@link GatewayStrategyRouteZookeeperProcessor}\n\t * @return {@link GatewayStrategyRouteZookeeperProcessor}\n\t */\n\t@Bean\n\t@ConditionalOnMissingBean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n}", "CodeBleu_score": 56.50182960799176}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\tprivate final Environment environment;\n\n\tprotected GatewayRouteZookeeperConfiguration(Environment environment) {\n\t\tthis.environment = environment;\n\t}\n\n\t@Bean\n\t@ConditionalOnMissingBean(GatewayStrategyRouteLocator.class)\n\t@ConditionalOnProperty(value = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(this.environment);\n\t}\n}", "CodeBleu_score": 28.71183909368312}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\t/**\n\t * The GatewayRouteZookeeperConfiguration.gatewayStrategyRouteZookeeperProcessor method creates a new instance of GatewayStrategyRouteZookeeperProcessor.\nThe method is conditional, only executing if the property \"spring.cloud.gateway.discovery.locator.enabled\" is set to \"false\" or is missing.\n\t * @param routeLocator the routeLocator to use\n\t * @param discoveryClient the discoveryClient to use\n\t * @return a new instance of GatewayStrategyRouteZookeeperProcessor\n\t */\n\t@Bean\n\t@ConditionalOnMissingBean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", matchIfMissing = true, havingValue = \"false\")\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(RouteLocator routeLocator, DiscoveryClient discoveryClient) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(routeLocator, discoveryClient);\n\t}\n}", "CodeBleu_score": 26.82196186178646}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curator = null;\n\ttry {\n\t\tcurator = CuratorFrameworkFactory.builder().connectString(hosts).sessionTimeoutMs(sessionTimeout).namespace(namespace).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();\n\t\tcurator.start();\n\t} catch (Exception e) {\n\t\te.printStackTrace();\n\t}\n\treturn curator;\n}", "CodeBleu_score": 39.798239846273454}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\t// TODO: implement this method\n\t// Ensure variable self is set to this module instance\n\tif (self == null) {\n\t\tself = this;\n\t}\n\n\t// The method body begins here\n\t// Create a CuratorFramework instance\n\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(hosts)\n\t\t\t.sessionTimeoutMs(sessionTimeout)\n\t\t\t.namespace(namespace)\n\t\t\t.retryPolicy(new RetryNTimes(retryAttempts, retryInterval))\n\t\t\t.build();\n\n\t// Start the CuratorFramework instance\n\tcuratorFramework.start();\n\n\treturn curatorFramework;\n}", "CodeBleu_score": 43.7989596326199}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t\tCuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(hosts)\n\t\t\t.sessionTimeoutMs(sessionTimeoutMs)\n\t\t\t.namespace(namespace)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.build();\n\tcuratorFramework.start();\n\treturn curatorFramework;\n}", "CodeBleu_score": 38.28039889146264}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t\ttry {\n\t\tInterProcessMutex lock = locksMap.get(path);\n\t\tif (lock == null) {\n\t\t\tlock = new InterProcessMutex(client, path);\n\t\t\tlocksMap.put(path, lock);\n\t\t}\n\t\tif (!lock.acquire(10, TimeUnit.SECONDS)) {\n\t\t\tthrow new DistributedLockException(\"Could not acquire lock: \" + path);\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(e);\n\t}\n}", "CodeBleu_score": 20.77632452815096}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex lock = locksMap.get(path);\n\tif (lock == null) {\n\t\tlock = new InterProcessMutex(client, path);\n\t\ttry {\n\t\t\tif (!lock.acquire(10, TimeUnit.SECONDS)) {\n\t\t\t\tthrow new DistributedLockException(\"Could not acquire lock: \" + path);\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(e);\n\t\t}\n\t\tlocksMap.put(path, lock);\n\t} else {\n\t\ttry {\n\t\t\tif (!lock.isAcquiredInThisProcess()) {\n\t\t\t\tif (!lock.acquire(10, TimeUnit.SECONDS)) {\n\t\t\t\t\tthrow new DistributedLockException(\"Could not acquire lock: \" + path);\n\t\t\t\t}\n\t\t\t}\n\t\t} catch (Exception e) {\n\t\t\tthrow new DistributedLockException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 32.179409732167514}, {"code": "public void lock(String path) throws DistributedLockException{\n\t\tInterProcessMutex lock = null;\n\ttry {\n\t\tlock = getLock(path);\n\t\tlock.acquire();\n\t} catch (Exception e) {\n\t\tthrow new DistributedLockException(e);\n\t}\n}", "CodeBleu_score": 17.395929144454296}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tif (dtpProperties == null) {\n\t\treturn Collections.emptyMap();\n\t}\n\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tif (dtpProperties.getConfigType() == DtpProperties.ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType() == DtpProperties.ConfigType.JSON) {\n\t\tString configKey = dtpProperties.getConfigKey();\n\t\tString path = ZKPaths.makePath(nodePath, configKey);\n\t\tString value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parse(value);\n\t} else {\n\t\treturn Collections.emptyMap();\n\t}\n}", "CodeBleu_score": 48.55366210788629}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tCuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tString nodePath = nodePath(dtpProperties);\n\tif (dtpProperties.getConfigType() == ConfigType.PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (dtpProperties.getConfigType() == ConfigType.JSON) {\n\t\tString path = ZKPaths.makePath(nodePath, dtpProperties.getConfigKey());\n\t\tString value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parseJson(value);\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 44.77571082666678}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t\tif (dtpProperties == null) {\n\t\treturn Collections.emptyMap();\n\t}\n\tfinal CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n\tfinal DtpProperties.ConfigType configType = dtpProperties.getConfigType();\n\tfinal String nodePath = nodePath(dtpProperties);\n\tif (configType == PROPERTIES) {\n\t\treturn genPropertiesTypeMap(nodePath, curatorFramework);\n\t} else if (configType == JSON) {\n\t\tfinal String configKey = dtpProperties.getConfigKey();\n\t\tfinal String path = ZKPaths.makePath(nodePath, configKey);\n\t\tfinal String value = getVal(path, curatorFramework);\n\t\treturn ConfigHandler.parseConfig(value);\n\t}\n\treturn Collections.emptyMap();\n}", "CodeBleu_score": 47.09000196261503}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\tDtpProperties dtpProperties = new DtpProperties();\n\tBinder binder = Binder.get(environment);\n\tbinder.bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n\n\tMap<Object, Object> properties = dtpProperties.getProperties();\n\tif (!checkPropertyExist(environment)) {\n\t\tcreateZkPropertySource(environment, properties);\n\t}\n}", "CodeBleu_score": 67.59355407279125}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\tDtpProperties dtpProperties = new DtpProperties();\nBinder binder = Binder.get(environment);\nbinder.bind(\"dtp\", Bindable.ofInstance(dtpProperties));\nMap<Object, Object> properties = dtpProperties.generatePropertiesMap();\nif (!checkPropertyExist(environment)) {\ncreateZkPropertySource(environment, properties);\n}\n}", "CodeBleu_score": 68.02940501851661}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t\t// Get the DtpProperties instance\n\tDtpProperties dtpProperties = environment.getProperty(DtpProperties.class);\n\t// Bind the DtpProperties instance to the environment\n\tBinder.get(environment).bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n\t// Generate a properties map from DtpProperties\n\tMap<Object, Object> properties = generatePropertiesMap(dtpProperties);\n\t// Check if the required property exists in the environment\n\tif (!checkPropertyExist(environment)) {\n\t\t// Create a Zookeeper property source with the generated properties\n\t\tcreateZkPropertySource(environment, properties);\n\t}\n}", "CodeBleu_score": 67.07540630360414}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 4.435738909874791}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\tister(provider => new ZookeeperSerializer()).As<ISerializer<string>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<byte[]>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<object>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<RouteInfo>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<ServiceSubscriber>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<CommandDescriptor>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<CacheDescriptor>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperSerializer()).As<ISerializer<MqttRouteInfo>>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperRouteFactory(provider.Resolve<ISerializer<RouteInfo>>(), provider.Resolve<ISerializer<ServiceSubscriber>>(), provider.Resolve<ISerializer<CommandDescriptor>>(), provider.Resolve<ISerializer<CacheDescriptor>>(), provider.Resolve<ISerializer<MqttRouteInfo>>())).SingleInstance();\n\tbuilder.Register(provider => new ZookeeperRouteManager(provider.Resolve<ISerializer<RouteInfo>>(), provider.Resolve<ISerializer<ServiceSubscriber>>(), provider.Resolve<ISerializer<CommandDescriptor>>(), provider.Resolve<ISerializer<CacheDescriptor>>(), provider.Resolve<ISerializer<MqttRouteInfo>>(), provider.Resolve<ILogger<ZookeeperRouteManager>>(), provider.Resolve<IZookeeperClientProvider>(), provider.Resolve<IServiceRouteFactory>(), provider.Resolve<IServiceSubscriberFactory>(), provider.Resolve<ICommandDescriptorFactory>(), provider.Resolve<ICacheDescriptorFactory>(), provider.Resolve<IMqttRouteInfoFactory>(), configInfo)).As<IServiceRouteManager>().SingleInstance();\n\tbuilder.Register(provider => new ZookeeperClientProvider(provider.Resolve<ILogger<ZookeeperClientProvider>>(), configInfo)).As<IZookeeperClientProvider>().SingleInstance();\n\treturn this;\n}", "CodeBleu_score": 46.46791746028899}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t GetConfigInfo(configInfo);\nbuilder.Register(p => configInfo).SingleInstance();\nbuilder.RegisterType<ZookeeperRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceSubscriber>().As<IServiceSubscriber>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCommandProvider>().As<IServiceCommandProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCacheManager>().As<IServiceCacheManager>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCacheProvider>().As<IServiceCacheProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperClient>().As<IZookeeperClient>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCommandManager>().As<IServiceCommandManager>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCacheManager>().As<IServiceCacheManager>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceSubscriber>().As<IServiceSubscriber>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCommandProvider>().As<IServiceCommandProvider>().SingleInstance();\nbuilder.RegisterType<ZookeeperServiceCacheProvider>().As<IServiceCacheProvider>().SingleInstance();\nreturn this;\n}", "CodeBleu_score": 39.66272729960825}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 8.618059401316474}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t", "CodeBleu_score": 8.618059401316474}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t= GetConfigInfo(configInfo);\n return UseCommandManager(builder, provider => new ZookeeperServiceCommandManager(configInfo, provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(), provider.GetRequiredService<IServiceCommandProvider>()));\n }", "CodeBleu_score": 45.18415839912046}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) throw new ArgumentNullException(nameof(builder));\n\tif (path == null) throw new ArgumentNullException(nameof(path));\n\n\tif (provider == null &&!Path.IsPathRooted(path)) throw new ArgumentException(nameof(path));\n\n\tif (provider == null) provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\n\tbuilder.Add(new ZookeeperConfigurationSource(provider, path, optional, reloadOnChange));\n\n\treturn builder;\n}", "CodeBleu_score": 42.39739140071993}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"Path cannot be null or empty\", nameof(path));\n\t}\n\n\tif (!Path.IsPathRooted(path)) {\n\t\tthrow new ArgumentException(\"Path must be rooted\", nameof(path));\n\t}\n\n\tif (provider == null) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = path,\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\n\treturn builder.Add(source);\n}", "CodeBleu_score": 58.417907098170815}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) throw new ArgumentNullException(nameof(builder));\n\tif (path == null) throw new ArgumentNullException(nameof(path));\n\tif (!Path.IsPathRooted(path)) throw new ArgumentException(\"The path must be rooted\", nameof(path));\n\tif (provider == null) provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\tvar source = new ZookeeperConfigurationSource { FileProvider = provider, Path = path, Optional = optional, ReloadOnChange = reloadOnChange };\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 58.94231739529785}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tforeach (var route in _routes) {\n\t\tforeach (var address in Address) {\n\t\t\troute.Addresses.Remove(address);\n\t\t}\n\t}\n\tawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 38.99124453994056}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tforeach (ServiceRoute route in _routes) {\n\t\troute.Addresses = route.Addresses.Except(Address).ToList();\n\t}\n\tawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 47.151246600481066}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tawait EnterRoutes();\n\tforeach (var route in _routes) {\n\t\tforeach (var address in Address) {\n\t\t\troute.RemoveAddress(address);\n\t\t}\n\t}\n\tawait SetRoutesAsync(_routes);\n}", "CodeBleu_score": 37.187610013230135}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\t// Get all the routes from Zookeeper\n\tvar zkRoutes = await _zkClient.GetRoutesAsync();\n\t// Remove the routes from Zookeeper except those provided in the routes parameter\n\tforeach (var zkRoute in zkRoutes) {\n\t\t// If the addresses of the routes to be deleted contain the specified hostAddr\n\t\tif (zkRoute.Addresses.Any(addr => addr.Host == hostAddr.Host && addr.Port == hostAddr.Port)) {\n\t\t\t// Delete the corresponding node from Zookeeper\n\t\t\tawait _zkClient.DeleteRouteAsync(zkRoute.ServiceName);\n\t\t}\n\t}\n}", "CodeBleu_score": 21.32827292087274}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePaths = routes.Select(r => r.Path).Distinct().ToList();\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tforeach (var zkClient in zkClients) {\n\t\tvar routeNodes = await zkClient.GetChildrenAsync(RoutePath);\n\t\tvar routesToDelete = routeNodes.Except(routePaths).ToList();\n\t\tforeach (var routeToDelete in routesToDelete) {\n\t\t\tvar routeAddr = await zkClient.GetDataAsync($\"{RoutePath}/{routeToDelete}\");\n\t\t\tif (routeAddr.Equals(hostAddr)) {\n\t\t\t\tawait zkClient.DeleteAsync($\"{RoutePath}/{routeToDelete}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 25.562480360973584}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePaths = routes.Select(route => GetRoutePath(route)).ToList();\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tforeach (var zkClient in zkClients) {\n\t\tvar routeNodes = await zkClient.GetChildrenAsync(RoutePath);\n\t\tvar toDeleteNodes = routeNodes.Except(routePaths).ToList();\n\t\tforeach (var node in toDeleteNodes) {\n\t\t\tvar address = await GetAddressAsync(zkClient, node);\n\t\t\tif (address.Host == hostAddr.Host) {\n\t\t\t\tawait zkClient.DeleteAsync(Path.Combine(RoutePath, node));\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 24.316850480885073}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\tServiceRouteDescriptor descriptor = null;\n\ttry {\n\t\tdescriptor = await ServiceRouteDescriptor.DeserializeAsync(data);\n\t}\n\tcatch (Exception ex) {\n\t\tLogger.Log(LogLevel.Error, ex, \"Failed to deserialize service route descriptor\");\n\t\treturn null;\n\t}\n\tif (Logger.IsEnabled(LogLevel.Debug)) {\n\t\tLogger.Log(LogLevel.Debug, \"Service route descriptor: {0}\", descriptor.ToString());\n\t}\n\tServiceRoute route = null;\n\ttry {\n\t\troute = await ServiceRouteFactory.CreateAsync(descriptor);\n\t}\n\tcatch (Exception ex) {\n\t\tLogger.Log(LogLevel.Error, ex, \"Failed to create service route\");\n\t\treturn null;\n\t}\n\tif (Logger.IsEnabled(LogLevel.Debug)) {\n\t\tLogger.Log(LogLevel.Debug, \"Service route: {0}\", route.ToString());\n\t}\n\treturn route;\n}", "CodeBleu_score": 28.36819798823123}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\n\tif (Logger.IsEnabled(LogLevel.Debug)) {\n\t\tLogger.LogDebug(data);\n\t}\n\n\tvar descriptor = await Serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n\n\treturn ServiceRouteFactory.Create(descriptor);\n}", "CodeBleu_score": 29.60163782186388}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t\tif (data == null) {\n\t\treturn null;\n\t}\n\n\tvar routeDescriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n\tif (Logger.IsEnabled(LogLevel.Debug)) {\n\t\tLogger.LogDebug(\"Route Descriptor: {0}\", routeDescriptor);\n\t}\n\n\treturn _serviceRouteFactory.Create(routeDescriptor);\n}", "CodeBleu_score": 29.858598291636945}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tf (DataEquals(oldData, newData))\n\t\treturn;\n\tvar newRoute = await GetRoute(newData);\n\tif (newRoute == null)\n\t\treturn;\n\tvar oldRoute = await GetRoute(oldData);\n\tlock (_routes) {\n\t\tif (oldRoute!= null) {\n\t\t\t_routes.Remove(oldRoute);\n\t\t}\n\t\t_routes.Add(newRoute);\n\t}\n\tOnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 29.001290397600577}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\tf (DataEquals(oldData, newData)) {\n\t\treturn;\n\t}\n\n\tvar newRoute = await GetRoute(newData);\n\tvar oldRoute = await GetRoute(oldData);\n\n\tlock (_routes) {\n\t\t_routes.Remove(oldRoute);\n\t\t_routes.Add(newRoute);\n\t}\n\n\tOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 26.482501938268477}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t (DataEquals(oldData, newData)) return;\nvar newRoute = await GetRoute(newData);\nvar oldRoute = await GetRoute(oldData);\nif (newRoute == null) {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u670d\u52a1\u8def\u7531\u88ab\u79fb\u9664\uff0c\u8def\u7531\uff1a{oldRoute}\");\nlock (_routes) {\n_routes.Remove(oldRoute);\n}\n} else {\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u670d\u52a1\u8def\u7531\u88ab\u4fee\u6539\uff0c\u65e7\u8def\u7531\uff1a{oldRoute}\uff0c\u65b0\u8def\u7531\uff1a{newRoute}\");\nlock (_routes) {\n_routes.Remove(oldRoute);\n_routes.Add(newRoute);\n}\n}\nOnChanged?.Invoke(newRoute, oldRoute);\n}", "CodeBleu_score": 33.64718762655189}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar existingSubscribers = await GetSubscribersAsync();\n\tif (existingSubscribers!= null) {\n\t\tvar subscriberDictionary = existingSubscribers.ToDictionary(x => x.Id);\n\t\tforeach (var subscriber in subscribers) {\n\t\t\tif (subscriberDictionary.TryGetValue(subscriber.Id, out var existingSubscriber)) {\n\t\t\t\tsubscriber.Addresses = subscriber.Addresses.Union(existingSubscriber.Addresses).ToArray();\n\t\t\t}\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 52.98634013014997}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tvar rootPath = _configInfo.SubscriberPath;\n\tif (!rootPath.EndsWith(\"/\"))\n\t\trootPath += \"/\";\n\n\tvar existingSubscribers = await GetSubscribersAsync();\n\tvar existingSubscribersMap = new Dictionary<string, ServiceSubscriber>(existingSubscribers.Length);\n\tforeach (var subscriber in existingSubscribers) {\n\t\texistingSubscribersMap.Add(subscriber.Id, subscriber);\n\t}\n\n\tvar newSubscribers = new List<ServiceSubscriber>(subscribers.Count());\n\tforeach (var subscriber in subscribers) {\n\t\tif (existingSubscribersMap.TryGetValue(subscriber.Id, out var existingSubscriber)) {\n\t\t\texistingSubscriber.Addresses = subscriber.Addresses.Union(existingSubscriber.Addresses).ToArray();\n\t\t\tnewSubscribers.Add(existingSubscriber);\n\t\t} else {\n\t\t\tnewSubscribers.Add(subscriber);\n\t\t}\n\t}\n\n\tawait base.SetSubscribersAsync(newSubscribers);\n}", "CodeBleu_score": 45.36075062204529}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\tif (subscribers == null ||!subscribers.Any())\nreturn;\n\nvar existingSubscribers = await GetSubscribersAsync();\nif (existingSubscribers == null ||!existingSubscribers.Any())\nreturn;\n\nforeach (var subscriber in subscribers) {\nvar existingSubscriber = existingSubscribers.FirstOrDefault(s => s.ServiceName == subscriber.ServiceName && s.ServiceVersion == subscriber.ServiceVersion);\nif (existingSubscriber == null)\ncontinue;\n\nif (_logger.IsEnabled(LogLevel.Debug))\n_logger.LogDebug($\"\u51c6\u5907\u66f4\u65b0\u8ba2\u9605\u8005\uff1a{subscriber.ServiceName} {subscriber.ServiceVersion}\u3002\");\n\nsubscriber.Addresses = (existingSubscriber.Addresses?? Enumerable.Empty<ServiceAddress>()).Concat(subscriber.Addresses?? Enumerable.Empty<ServiceAddress>()).Distinct().ToArray();\n}\n\nawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 48.08425897425982}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar rootPath = Path.GetDirectoryName(Path);\n\tforeach (var child in childrens) {\n\t\tvar childPath = Path.Combine(rootPath, child);\n\t\tvar subscriber = await GetSubscriber(childPath);\n\t\tsubscribers.Add(subscriber);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 33.24640484787839}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar rootPath = Path.Combine(ServicePath, \"subscribers\");\n\tforeach (var child in childrens) {\n\t\tif (Logger.IsDebugEnabled) {\n\t\t\tLogger.DebugFormat(\"Getting subscribers for {0}\", child);\n\t\t}\n\t\tvar childPath = Path.Combine(rootPath, child);\n\t\tvar childSubscribers = await GetSubscribers(childPath);\n\t\tsubscribers.AddRange(childSubscribers);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 37.334958755892735}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar rootPath = Path.GetDirectoryName(this.Path);\n\tforeach (var child in childrens) {\n\t\tif (this.Logger.IsDebugEnabled) {\n\t\t\tthis.Logger.DebugFormat(\"Getting subscribers for child {0}\", child);\n\t\t}\n\t\tvar fullPath = Path.Combine(rootPath, child);\n\t\tvar subscriber = await this.Client.GetSubscribers(fullPath);\n\t\tsubscribers.AddRange(subscriber);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 36.73606217335998}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) return;\n\n\tvar (resetEvent, zooKeeper) = await GetZooKeeper();\n\tif (resetEvent.WaitOne(TimeSpan.FromSeconds(5))) {\n\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t_logger.LogDebug(\"\u5df2\u8fde\u63a5\u5230ZooKeeper\u3002\");\n\n\t\tvar rootPath = _configInfo.SubscriberPath;\n\t\tif (!rootPath.EndsWith(\"/\"))\n\t\t\trootPath += \"/\";\n\n\t\tif (await zooKeeper.ExistsAsync(rootPath, false)) {\n\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t_logger.LogDebug($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u5df2\u5b58\u5728\u3002\");\n\n\t\t\tvar childrens = await zooKeeper.GetChildrenAsync(rootPath, false);\n\t\t\tif (childrens.Any()) {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u5df2\u83b7\u53d6\u5230{childrens.Count()}\u4e2a\u8ba2\u9605\u8005\u3002\");\n\n\t\t\t\t_subscribers = await GetSubscribers(childrens);\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Debug))\n\t\t\t\t\t_logger.LogDebug($\"\u5df2\u83b7\u53d6\u5230{_subscribers.Length}\u4e2a\u8ba2\u9605\u8005\u3002\");\n\t\t\t} else {\n\t\t\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t\t\t_logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u5df2\u5b58\u5728\uff0c\u4f46\u6ca1\u6709\u5b50\u8282\u70b9\u3002\");\n\n\t\t\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t\t\t}\n\t\t} else {\n\t\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t\t_logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84\uff1a{rootPath}\u4e0d\u5b58\u5728\u3002\");\n\n\t\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t\t}\n\t} else {\n\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t_logger.LogWarning(\"\u672a\u80fd\u8fde\u63a5\u5230ZooKeeper\u3002\");\n\n\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t}\n}", "CodeBleu_score": 43.382728354353574}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) {\n\t\treturn;\n\t}\n\n\tvar (resetEvent, zooKeeper) = await GetZooKeeper();\n\n\ttry {\n\t\tawait resetEvent.WaitAsync();\n\n\t\tif (_logger.IsEnabled(LogLevel.Debug)) {\n\t\t\t_logger.LogDebug(\"\u5f00\u59cb\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\t\t}\n\n\t\tvar rootPath = _configInfo.SubscriberPath;\n\t\tif (!rootPath.EndsWith(\"/\")) {\n\t\t\trootPath += \"/\";\n\t\t}\n\n\t\tif (zooKeeper.Exists(rootPath, false)!= null) {\n\t\t\tvar childrens = await zooKeeper.GetChildrenAsync(rootPath, false);\n\t\t\t_subscribers = await GetSubscribers(childrens);\n\t\t}\n\t\telse {\n\t\t\t_logger.LogWarning($\"\u8ba2\u9605\u8005\u8def\u5f84{rootPath}\u4e0d\u5b58\u5728\u3002\");\n\t\t\t_subscribers = new ServiceSubscriber[0];\n\t\t}\n\n\t\tif (_logger.IsEnabled(LogLevel.Debug)) {\n\t\t\t_logger.LogDebug($\"\u83b7\u53d6\u5230{_subscribers.Length}\u4e2a\u8ba2\u9605\u8005\u4fe1\u606f\u3002\");\n\t\t}\n\t}\n\tcatch (Exception ex) {\n\t\t_logger.LogError(ex, \"\u83b7\u53d6\u8ba2\u9605\u8005\u4fe1\u606f\u65f6\u53d1\u751f\u5f02\u5e38\u3002\");\n\t}\n\tfinally {\n\t\tawait _zookeeperClientProvider.ReleaseZooKeeper(zooKeeper);\n\t}\n}", "CodeBleu_score": 48.50046753234232}, {"code": "private async Task EnterSubscribers(){\n\tif (_subscribers!= null) return;\n\tvar (manualResetEvent, zooKeeper) = await GetZooKeeper();\n\tawait manualResetEvent.WaitAsync();\n\tif (zooKeeper == null) return;\n\tvar childrens = await zooKeeper.GetChildrenAsync(_configInfo.SubscriberPath);\n\tif (childrens.Any()) {\n\t\tvar subscribers = await GetSubscribers(childrens);\n\t\t_subscribers = subscribers;\n\t} else {\n\t\tif (_logger.IsEnabled(LogLevel.Warning))\n\t\t\t_logger.LogWarning($\"The subscriber path {_configInfo.SubscriberPath} does not exist.\");\n\t\t_subscribers = Array.Empty<ServiceSubscriber>();\n\t}\n}", "CodeBleu_score": 45.239745954601695}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tar oldCommand = GetServiceCommand(oldData);\n\tvar newCommand = GetServiceCommand(newData);\n\tif (oldCommand!= null && newCommand!= null && oldCommand.ServiceId == newCommand.ServiceId)\n\t{\n\t\tvar index = _serviceCommands.FindIndex(c => c.ServiceId == oldCommand.ServiceId);\n\t\tif (index!= -1)\n\t\t\t_serviceCommands[index] = newCommand;\n\t}\n\tOnChanged?.Invoke(oldCommand, newCommand);\n}", "CodeBleu_score": 31.243798207016066}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tf (oldData == null && newData == null)\n\t\treturn;\n\tif (oldData == null && newData!= null) {\n\t\tvar descriptor = GetServiceCommand(newData);\n\t\tif (descriptor == null)\n\t\t\treturn;\n\t\t_serviceCommands.Add(descriptor);\n\t\tOnChanged?.Invoke(descriptor, null);\n\t\treturn;\n\t}\n\tif (oldData!= null && newData == null) {\n\t\tvar descriptor = GetServiceCommand(oldData);\n\t\tif (descriptor == null)\n\t\t\treturn;\n\t\t_serviceCommands.Remove(descriptor);\n\t\tOnChanged?.Invoke(null, descriptor);\n\t\treturn;\n\t}\n\tif (oldData!= null && newData!= null) {\n\t\tvar oldDescriptor = GetServiceCommand(oldData);\n\t\tvar newDescriptor = GetServiceCommand(newData);\n\t\tif (oldDescriptor == null || newDescriptor == null)\n\t\t\treturn;\n\t\tif (oldDescriptor.ServiceId!= newDescriptor.ServiceId)\n\t\t\treturn;\n\t\tif (DataEquals(oldDescriptor.Data, newDescriptor.Data))\n\t\t\treturn;\n\t\t_serviceCommands.Remove(oldDescriptor);\n\t\t_serviceCommands.Add(newDescriptor);\n\t\tOnChanged?.Invoke(newDescriptor, oldDescriptor);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 32.617481008222335}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\tf (oldData == null && newData == null)\n\t\treturn;\n\tif (oldData!= null && newData!= null && DataEquals(oldData, newData))\n\t\treturn;\n\tvar oldCommand = GetServiceCommand(oldData);\n\tvar newCommand = GetServiceCommand(newData);\n\tif (oldCommand!= null && newCommand!= null && oldCommand.ServiceId == newCommand.ServiceId)\n\t{\n\t\tvar index = _commands.FindIndex(c => c.ServiceId == oldCommand.ServiceId);\n\t\t_commands[index] = newCommand;\n\t}\n\telse\n\t{\n\t\tif (oldCommand!= null)\n\t\t\t_commands.RemoveAll(c => c.ServiceId == oldCommand.ServiceId);\n\t\tif (newCommand!= null)\n\t\t\t_commands.Add(newCommand);\n\t}\n\tOnChanged?.Invoke(this, new ServiceCommandEventArgs(oldCommand, newCommand));\n}", "CodeBleu_score": 39.12490610067747}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tstring currentData = await ZooKeeperClient.GetDataAsync(watchedEvent.Path);\n\t\tstring newData = await ZooKeeperClient.GetDataAsync(watchedEvent.Path, this);\n\t\tAction<string, string> action = Action?? throw new InvalidOperationException(\"Action must be specified\");\n\t\taction(currentData, newData);\n\t}\n}", "CodeBleu_score": 18.344884494031323}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar data = await _zooKeeper.GetDataAsync(watchedEvent.Path, this, null);\n\t\tAction<string, string> action = _action;\n\t\taction(watchedEvent.Path, Encoding.UTF8.GetString(data));\n\t}\n}", "CodeBleu_score": 42.84702460255658}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.Type == EventType.NodeDataChanged) {\n\t\tvar data = await _client.GetDataAsync(watchedEvent.Path);\n\t\tvar action = _actions.GetOrAdd(watchedEvent.Path, path => new Action<byte[], byte[]>(async (currentData, newData) => {\n\t\t\tawait _client.SetDataAsync(path, newData);\n\t\t}));\n\t\tawait action(data, data);\n\t}\n}", "CodeBleu_score": 21.46588779339805}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t== null) throw new ArgumentNullException(nameof(builder));\nif (configInfo == null) throw new ArgumentNullException(nameof(configInfo));\nconfigInfo = GetConfigInfo(configInfo);\nbuilder.Services.AddSingleton(configInfo);\nbuilder.Services.AddSingleton<IZookeeperClientProvider, DefaultZookeeperClientProvider>();\nbuilder.Services.AddSingleton<IAddressSelector, DefaultAddressSelector>();\nbuilder.Services.AddSingleton<IHealthCheckService, DefaultHealthCheckService>();\nreturn builder;\n}", "CodeBleu_score": 41.65863007664775}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\teeper client provider.\n\tbuilder.Services.AddSingleton<IServiceDiscoveryProvider, DefaultZookeeperClientProvider>(p => new DefaultZookeeperClientProvider(\n\t\tp.GetRequiredService<IHealthCheckService>(),\n\t\tp.GetRequiredService<IAddressSelector>(),\n\t\tp.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>(),\n\t\tconfigInfo));\n\treturn builder;\n}", "CodeBleu_score": 58.41182527975186}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\tvices.AddSingleton(new DefaultZookeeperClientProvider(configInfo));\n\treturn builder;\n}", "CodeBleu_score": 17.481465399174695}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tawait base.SetRoutesAsync(routes);\n\n\tif (routes == null) {\n\t\treturn;\n\t}\n\n\tvar clients = await GetClientsAsync();\n\tforeach (var client in clients) {\n\t\tvar clientPath = $\"{ZooKeeperPath}/{client.Id}\";\n\t\tvar routesPath = $\"{clientPath}/routes\";\n\t\tvar routesNode = await client.GetAsync(routesPath);\n\t\tif (routesNode == null) {\n\t\t\troutesNode = await client.CreateAsync(routesPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t}\n\n\t\tforeach (var route in routes) {\n\t\t\tvar routePath = $\"{routesPath}/{route.Id}\";\n\t\t\tvar routeNode = await client.GetAsync(routePath);\n\t\t\tif (routeNode == null) {\n\t\t\t\trouteNode = await client.CreateAsync(routePath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t\t}\n\t\t\tvar routeData = Encoding.UTF8.GetBytes(JsonConvert.SerializeObject(route));\n\t\t\tif (routeNode.Stat.DataLength!= routeData.Length ||!routeNode.Data.SequenceEqual(routeData)) {\n\t\t\t\tawait client.SetDataAsync(routePath, routeData);\n\t\t\t\tLog.Debug(\"Updated MQTT route: {0}\", route);\n\t\t\t}\n\t\t}\n\n\t\tLog.Debug(\"Added MQTT routes to ZooKeeper: {0}\", client.Id);\n\t}\n}", "CodeBleu_score": 37.378452016457615}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\t// Ensure the MQTT route path subdirectory exists\n\tawait EnsureRoutePathSubdirectoryExistsAsync(MqttRoutePath);\n\n\t// Iterate over the given routes\n\tforeach (var route in routes) {\n\t\t// Create or update the route node with the serialized route data\n\t\tawait CreateOrUpdateRouteNodeAsync(route, MqttRoutePath);\n\t}\n\n\t// Log the successful addition of routes\n\tawait LogRoutesAddedAsync(routes);\n}", "CodeBleu_score": 7.278965488114052}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t", "CodeBleu_score": 1.1257247766442258}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\t// The route path to be removed\n\tvar routePath = MqttServiceRoute.GetRoutePath(hostAddr);\n\n\t// Get Zookeeper clients\n\tvar zkClients = await _zkClientFactory.GetZooKeeperClientsAsync();\n\n\t// Traverse Zookeeper clients\n\tforeach (var zkClient in zkClients) {\n\t\t// Get the current routes\n\t\tvar currentRoutes = await GetRoutesAsync(zkClient, hostAddr);\n\n\t\t// Get the routes to be deleted\n\t\tvar removeRoutes = currentRoutes.Except(routes, new MqttServiceRouteEqualityComparer());\n\n\t\t// Traverse the routes to be deleted\n\t\tforeach (var route in removeRoutes) {\n\t\t\t// If the addresses of the routes to be deleted contain the specified hostAddr, delete the corresponding node from Zookeeper\n\t\t\tif (route.Addresses.Contains(hostAddr)) {\n\t\t\t\tawait zkClient.DeleteNodeAsync(route.GetRoutePath(hostAddr));\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 30.63260698447698}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\t// Construct the route path.\n\tstring routePath = GetRoutePath(hostAddr);\n\n\t// Get the current Zookeeper clients.\n\tList<ZooKeeper> zookeepers = await GetZookeepersAsync();\n\n\t// For each Zookeeper client, compare the existing routes with the new routes and identify routes to be deleted.\n\tforeach (ZooKeeper zookeeper in zookeepers) {\n\t\t// Get the existing routes.\n\t\tList<MqttServiceRoute> existingRoutes = await GetRoutesAsync(zookeeper, routePath);\n\n\t\t// Identify routes to be deleted.\n\t\tList<MqttServiceRoute> routesToBeDeleted = existingRoutes.Except(routes).ToList();\n\n\t\t// If the addresses of the routes to be deleted contain the specified hostAddr, delete the corresponding node from Zookeeper.\n\t\tforeach (MqttServiceRoute route in routesToBeDeleted) {\n\t\t\tif (route.Addresses.Contains(hostAddr)) {\n\t\t\t\tawait zookeeper.DeleteAsync(routePath + \"/\" + route.Name);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 28.38212217442109}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = $\"{ZookeeperPath.MqttServiceRoutePath}/{hostAddr.HostAddr}\";\n\tvar zkClients = await GetZookeeperClientsAsync();\n\tforeach (var zkClient in zkClients) {\n\t\tvar currentRoutes = await zkClient.GetChildrenAsync(routePath);\n\t\tvar routesToDelete = currentRoutes.Except(routes.Select(route => route.RouteName)).ToArray();\n\t\tforeach (var routeToDelete in routesToDelete) {\n\t\t\tif (routeToDelete.Contains(hostAddr.HostAddr)) {\n\t\t\t\tawait zkClient.DeleteAsync($\"{routePath}/{routeToDelete}\");\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 26.72289051232175}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tawait LogOperationAsync(Operation.SetCaches);\n\tvar cachePath = GetCachePath();\n\tvar clients = await GetClientsAsync();\n\tforeach (var client in clients) {\n\t\tawait client.CreatePathAsync(cachePath);\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cacheData = cacheDescriptor.Serialize();\n\t\t\tvar cacheNode = client.GetNode(cachePath, cacheDescriptor.Name);\n\t\t\tif (!await cacheNode.ExistsAsync()) {\n\t\t\t\tawait cacheNode.CreateAsync(cacheData);\n\t\t\t} else {\n\t\t\t\tvar cacheData2 = await cacheNode.GetDataAsync();\n\t\t\t\tif (cacheData!= cacheData2) {\n\t\t\t\t\tawait cacheNode.SetDataAsync(cacheData);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tawait LogOperationAsync(Operation.SetCaches, OperationResult.Success);\n}", "CodeBleu_score": 26.51261976104493}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tvar log = Log.ForContext(Constants.SourceContextPropertyName, nameof(ZookeeperServiceCacheProvider));\n\tlog.Debug(\"Updating service cache descriptors in Zookeeper\");\n\tvar cachePath = GetCachePath();\n\tvar clients = await GetClientsAsync();\n\tforeach (var client in clients) {\n\t\tawait client.EnsurePathAsync(cachePath);\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cacheDescriptorBytes = cacheDescriptor.Serialize();\n\t\t\tvar cacheDescriptorPath = $\"{cachePath}/{cacheDescriptor.Name}\";\n\t\t\tif (await client.ExistsAsync(cacheDescriptorPath) == null) {\n\t\t\t\tawait client.CreateAsync(cacheDescriptorPath, cacheDescriptorBytes);\n\t\t\t} else {\n\t\t\t\tvar cacheDescriptorBytesFromZookeeper = await client.GetDataAsync(cacheDescriptorPath);\n\t\t\t\tif (!cacheDescriptorBytesFromZookeeper.SequenceEqual(cacheDescriptorBytes)) {\n\t\t\t\t\tawait client.SetDataAsync(cacheDescriptorPath, cacheDescriptorBytes);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tlog.Debug(\"Successfully added service caches\");\n}", "CodeBleu_score": 30.01760480558794}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\t_logger.LogInformation($\"Setting caches for service {ServiceId}\");\n\n\tvar cachePath = Path.Combine(ServicePath, \"caches\");\n\tvar clients = await GetZookeeperClientsAsync();\n\n\tforeach (var client in clients) {\n\t\tawait client.CreateIfNotExistsAsync(cachePath);\n\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cacheDescriptorBytes = _serializer.Serialize(cacheDescriptor);\n\t\t\tvar cacheNodePath = Path.Combine(cachePath, cacheDescriptor.CacheId);\n\n\t\t\tif (await client.ExistsAsync(cacheNodePath) == null) {\n\t\t\t\tawait client.CreateAsync(cacheNodePath, cacheDescriptorBytes);\n\t\t\t} else {\n\t\t\t\tif (await client.GetDataAsync(cacheNodePath)!= cacheDescriptorBytes) {\n\t\t\t\t\tawait client.SetDataAsync(cacheNodePath, cacheDescriptorBytes);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t_logger.LogInformation($\"Added {cacheDescriptors.Count()} service caches for service {ServiceId}\");\n}", "CodeBleu_score": 33.39244214413568}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tawait zooKeeper.Item1.WaitOneAsync();\n\tif (zooKeeper.Item2.Exists(path) == null) {\n\t\tConsole.WriteLine($\"Creating Zookeeper node {path}\");\n\t\tvar subDirectories = path.Split(new[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\t\tvar pathBuilder = new StringBuilder();\n\t\tfor (var i = 0; i < subDirectories.Length; i++) {\n\t\t\tpathBuilder.Append($\"/{subDirectories[i]}\");\n\t\t\tvar subPath = pathBuilder.ToString();\n\t\t\tif (zooKeeper.Item2.Exists(subPath) == null) {\n\t\t\t\tConsole.WriteLine($\"Creating Zookeeper node {subPath}\");\n\t\t\t\tawait zooKeeper.Item2.CreateAsync(subPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.372441264689606}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\ttry {\n\t\tawait zooKeeper.Item2.ExistsAsync(path, false);\n\t\treturn;\n\t} catch (KeeperException.NoNodeException) {\n\t\tConsole.WriteLine($\"Creating Zookeeper node {path}\");\n\t\tstring[] subDirs = path.Split(new char[] { '/' }, StringSplitOptions.RemoveEmptyEntries);\n\t\tstring subPath = \"/\";\n\t\tforeach (string subDir in subDirs) {\n\t\t\tsubPath = Path.Combine(subPath, subDir);\n\t\t\ttry {\n\t\t\t\tawait zooKeeper.Item2.ExistsAsync(subPath, false);\n\t\t\t} catch (KeeperException.NoNodeException) {\n\t\t\t\tawait zooKeeper.Item2.CreateAsync(subPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 46.07741905614825}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tif (zooKeeper.Item1.WaitOne()) {\n\t\tif (await zooKeeper.Item2.ExistsAsync(path) == null) {\n\t\t\tLog.Information($\"Creating Zookeeper path {path}\");\n\t\t\tvar pathParts = path.Split(Path.DirectorySeparatorChar);\n\t\t\tvar currentPath = pathParts[0];\n\t\t\tfor (var i = 1; i < pathParts.Length; i++) {\n\t\t\t\tvar pathPart = pathParts[i];\n\t\t\t\tcurrentPath += Path.DirectorySeparatorChar + pathPart;\n\t\t\t\tif (await zooKeeper.Item2.ExistsAsync(currentPath) == null) {\n\t\t\t\t\tawait zooKeeper.Item2.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 44.84565694824859}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var ipAddress in _config.IpAddresses)\n{\n    if (await _healthCheckService.IsHealthy(ipAddress))\n    {\n        var zooKeeper = CreateZooKeeper(ipAddress);\n        result.Add(zooKeeper);\n    }\n}\nreturn result;\n}", "CodeBleu_score": 68.93724369682789}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tar result = new List<(ManualResetEvent, ZooKeeper)>();\nforeach (var address in _config.Addresses) {\nvar (connectionWait, zk) = CreateZooKeeper(address);\nif (await _healthCheckService.IsHealthyAsync(zk)) {\nresult.Add((connectionWait, zk));\n}\n}\nreturn result;\n}", "CodeBleu_score": 69.19603978137576}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\tvar zooKeepers = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var ipAddress in _config.Addresses) {\n\t\tvar (connectionWait, zooKeeper) = CreateZooKeeper(ipAddress);\n\t\tif (await _healthCheckService.IsHealthy(ipAddress)) {\n\t\t\tzooKeepers.Add((connectionWait, zooKeeper));\n\t\t}\n\t}\n\treturn zooKeepers;\n}", "CodeBleu_score": 65.10359507093774}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (zooKeeper == null) {\n\t\t\tzooKeeper = helper.getZooKeeper();\n\t\t}\n\t}\n\treturn zooKeeper;\n}", "CodeBleu_score": 14.470788566953097}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\thronized (this) {\n\t\tif (helper == null) {\n\t\t\thelper = new Helper();\n\t\t\thelper.initialize();\n\t\t}\n\t}\n\treturn helper.getZooKeeper();\n}", "CodeBleu_score": 13.478944728509113}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\thelper == null) {\n\t\tsynchronized (this) {\n\t\t\tif (helper == null) {\n\t\t\t\thelper = new Helper(this);\n\t\t\t}\n\t\t}\n\t}\n\treturn helper.getZooKeeper();\n}", "CodeBleu_score": 18.86260908436209}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (zk!= null) {\n\t\tif (waitForShutdownTimeoutMs == 0) {\n\t\t\tzk.close();\n\t\t} else {\n\t\t\tzk.register(new Watcher() {\n\t\t\t\t@Override\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t}\n\t}\n}", "CodeBleu_score": 26.114923661426033}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tZooKeeper zk = getZooKeeper();\n\tif (zk!= null) {\n\t\ttry {\n\t\t\t// register a dummy watcher to clear the default watcher\n\t\t\tzk.register(new Watcher() {\n\t\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t\t}\n\t\t\t});\n\t\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\t\tzk.close(waitForShutdownTimeoutMs);\n\t\t\t} else {\n\t\t\t\tzk.close();\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t}\n}", "CodeBleu_score": 30.720267050298634}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t\tif (this.zk!= null) {\n\t\t// register a dummy watcher to clear the default watcher, preventing new events from being processed\n\t\tthis.zk.register(new Watcher() {\n\t\t\t@Override\n\t\t\tpublic void process(WatchedEvent event) {\n\t\t\t}\n\t\t});\n\t\t// close the ZooKeeper instance\n\t\ttry {\n\t\t\tthis.zk.close();\n\t\t} catch (InterruptedException e) {\n\t\t\t// restore the thread's interrupt status\n\t\t\tThread.currentThread().interrupt();\n\t\t\tthrow e;\n\t\t}\n\t\t// wait for the shutdown to complete if a timeout is specified\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\tlong startTime = System.currentTimeMillis();\n\t\t\twhile (this.zk.getState()!= States.CLOSED && System.currentTimeMillis() - startTime < waitForShutdownTimeoutMs) {\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(10);\n\t\t\t\t} catch (InterruptedException e) {\n\t\t\t\t\t// restore the thread's interrupt status\n\t\t\t\t\tThread.currentThread().interrupt();\n\t\t\t\t\tthrow e;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 34.191100440256776}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\ttry (OperationTrace trace = startAdvancedTracer(\"blockUntilConnectedOrTimedOut\")) {\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\t\treturn isConnected();\n\t}\n}", "CodeBleu_score": 14.920597013128608}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tlog.info(\"blockUntilConnectedOrTimedOut start\");\n\tstartAdvancedTracer(\"blockUntilConnectedOrTimedOut\").logStart();\n\tinternalBlockUntilConnectedOrTimedOut();\n\tstartAdvancedTracer(\"blockUntilConnectedOrTimedOut\").logEnd();\n\tlog.info(\"blockUntilConnectedOrTimedOut end\");\n\treturn isConnected();\n}", "CodeBleu_score": 31.385516325722733}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t\tinternalBlockUntilConnectedOrTimedOut();\n\treturn isConnected();\n}", "CodeBleu_score": 6.452655696609913}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down the service\");\n\tstarted = false;\n\ttry {\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\tif (!state.close(waitForShutdownTimeoutMs)) {\n\t\t\t\tlog.error(\"Failed to shutdown the service within the given timeout\");\n\t\t\t}\n\t\t} else {\n\t\t\tstate.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\tlog.error(\"Interrupted while shutting down the service\", e);\n\t\t} else {\n\t\t\tlog.error(\"Failed to shutdown the service\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.52602960906411}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlogger.info(\"Attempting to close the service\");\n\tstarted = false;\n\ttry {\n\t\tservice.close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n\t} catch (IOException e) {\n\t\tif (Thread.interrupted()) {\n\t\t\tlogger.error(\"Thread interrupted while closing the service\");\n\t\t} else {\n\t\t\tlogger.error(\"IOException while closing the service\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 37.7108953032228}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t\tlog.info(\"Shutting down service\");\n\tstarted = false;\n\ttry {\n\t\tif (waitForShutdownTimeoutMs > 0) {\n\t\t\tstate.close(waitForShutdownTimeoutMs);\n\t\t} else {\n\t\t\tstate.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tif (Thread.currentThread().isInterrupted()) {\n\t\t\tlog.error(\"Interrupted while waiting for shutdown\");\n\t\t} else {\n\t\t\tlog.error(\"Error while waiting for shutdown\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 46.027207570396655}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tif (connectionState!= ConnectionState.CONNECTED) {\n\t\tif (connectionState == ConnectionState.DISCONNECTED) {\n\t\t\tthrow new RuntimeException(\"Disconnected\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTING) {\n\t\t\tthrow new RuntimeException(\"Connecting\");\n\t\t}\n\t\tif (connectionState == ConnectionState.DISCONNECTING) {\n\t\t\tthrow new RuntimeException(\"Disconnecting\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_FAILED) {\n\t\t\tthrow new RuntimeException(\"Connection failed\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_LOST) {\n\t\t\tthrow new RuntimeException(\"Connection lost\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_REFUSED) {\n\t\t\tthrow new RuntimeException(\"Connection refused\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_TIMEOUT) {\n\t\t\tthrow new RuntimeException(\"Connection timeout\");\n\t\t}\n\t\tif (connectionState == ConnectionState.INVALID_CREDENTIALS) {\n\t\t\tthrow new RuntimeException(\"Invalid credentials\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_AUTH_FAILED) {\n\t\t\tthrow new RuntimeException(\"Connection auth failed\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_CLOSED_BY_SERVER) {\n\t\t\tthrow new RuntimeException(\"Connection closed by server\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_STALLED) {\n\t\t\tthrow new RuntimeException(\"Connection stalled\");\n\t\t}\n\t\tif (connectionState == ConnectionState.RECONNECTING) {\n\t\t\tthrow new RuntimeException(\"Reconnecting\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_BLOCKED) {\n\t\t\tthrow new RuntimeException(\"Connection blocked\");\n\t\t}\n\t\tif (connectionState == ConnectionState.CONNECTION_TEMPORARILY_UNAVAILABLE) {\n\t\t\tthrow new RuntimeException(\"Connection temporarily unavailable\");\n\t\t}\n\t\tthrow new RuntimeException(\"Unknown connection state\");\n\t}\n}", "CodeBleu_score": 4.77850970508864}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t// TODO: implement\n}", "CodeBleu_score": 1.4820082928049525}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\t//TODO: implement this method\n}", "CodeBleu_score": 1.4820082928049525}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (createMode == CreateMode.EPHEMERAL) {\n\t\tif (client.getZookeeperClient().getZooKeeper().getSessionId()!= sessionId) {\n\t\t\tlog.info(\"Session changed. Deleting old node: {}\", foundNode);\n\t\t\tclient.getZookeeperClient().delete().forPath(foundNode);\n\t\t\tsessionId = client.getZookeeperClient().getZooKeeper().getSessionId();\n\t\t}\n\t}\n\n\treturn foundNode;\n}", "CodeBleu_score": 33.16749463424493}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tif (client.getZookeeperClient().getZooKeeper().getSessionId()!= sessionId) {\n\t\tclient.getZookeeperClient().getZooKeeper().delete(foundNode, -1);\n\t\tclient.getZookeeperClient().getZooKeeper().create(foundNode, null, createMode.toZooKeeperCreateMode(), true);\n\t\tsessionId = client.getZookeeperClient().getZooKeeper().getSessionId();\n\t}\n\treturn foundNode;\n}", "CodeBleu_score": 29.56843714914462}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\tf (createMode == CreateMode.EPHEMERAL) {\nif (client.getZookeeperClient().getZooKeeper().getSessionId()!= sessionId) {\nclient.getZookeeperClient().getZooKeeper().delete(foundNode, -1);\nsessionId = client.getZookeeperClient().getZooKeeper().getSessionId();\n}\n}\nreturn foundNode;\n}", "CodeBleu_score": 26.45724738546932}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal Trace trace = new Trace(this, \"pathInForeground\", path);\n\ttrace.start();\n\tStat stat = null;\n\ttry {\n\t\tstat = pathInForeground(trace, path, aclList);\n\t} finally {\n\t\ttrace.commit();\n\t}\n\treturn stat;\n}", "CodeBleu_score": 24.612117337610734}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal String traceId = startTrace(path, \"pathInForeground\");\n\ttry {\n\t\treturn retryLoop(path, aclList, traceId);\n\t} finally {\n\t\tendTrace(traceId);\n\t}\n}", "CodeBleu_score": 15.478639725022452}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t\tfinal String methodName = \"pathInForeground\";\n\tfinal AdvancedTrace trace = new AdvancedTrace(this.getClass().getSimpleName(), methodName);\n\ttrace.start();\n\tStat status = null;\n\ttry {\n\t\tstatus = retryLoop(path, aclList);\n\t} catch (Exception e) {\n\t\ttrace.addException(e);\n\t\tthrow e;\n\t} finally {\n\t\ttrace.commit();\n\t}\n\treturn status;\n}", "CodeBleu_score": 32.2450662447279}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\ttry {\n\t\tthis.memberNode = client.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Failed to create member node\", e);\n\t}\n}", "CodeBleu_score": 49.51971547832578}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tif (thisId == null || thisId.length() == 0) {\n\t\tthrow new IllegalArgumentException(\"id cannot be null or empty\");\n\t}\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\tthis.node = client.create().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n}", "CodeBleu_score": 50.53883515649281}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\tthis.client.start();\n\tvalidateId();\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\tthis.cache.listenable().addListener(this);\n\ttry {\n\t\tthis.node = client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(membershipPath + \"/\" + thisId, payload);\n\t} catch (Exception e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 47.469184217788595}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\tasync.watched().getData().forPath(path).whenComplete((data, ex) -> {\n\t\t\t\tif (ex!= null) {\n\t\t\t\t\tex.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Data for \" + path + \" is: \" + new String(data));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 70.69364173057593}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client); // normally you'd wrap early in your app and reuse the instance\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tSystem.out.println(\"Created node name is: \" + name);\n\t\t\t// set up a watch on the node to handle future events\n\t\t\tasync.watched().getData().forPath(name).whenComplete((data, exception) -> {\n\t\t\t\tif (exception!= null) {\n\t\t\t\t\texception.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Data: \" + new String(data));\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 71.97348115408764}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\tAsyncCuratorFramework async = AsyncCuratorFramework.wrap(client);\n\tasync.create().forPath(path).whenComplete((name, exception) -> {\n\t\tif (exception!= null) {\n\t\t\texception.printStackTrace();\n\t\t} else {\n\t\t\tasync.watched().exists().forPath(path).whenComplete((stat, ex) -> {\n\t\t\t\tif (ex!= null) {\n\t\t\t\t\tex.printStackTrace();\n\t\t\t\t} else {\n\t\t\t\t\tSystem.out.println(\"Node exists: \" + stat);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t});\n}", "CodeBleu_score": 72.93649770949546}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = transaction.doMulti(client);\n\tif (results.get(0).getErr()!= KeeperException.Code.OK.intValue()) {\n\t\tKeeperException.Code code = KeeperException.Code.get(results.get(0).getErr());\n\t\tthrow KeeperException.create(code);\n\t}\n\treturn results;\n}", "CodeBleu_score": 29.004704623375936}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = client.process(transaction);\n\tif (results.get(0).getErr()!= 0) {\n\t\tint err = results.get(0).getErr();\n\t\tKeeperException.Code code = KeeperException.Code.get(err);\n\t\tif (code == null) {\n\t\t\tthrow new KeeperException(KeeperException.Code.get(Code.get(err).intValue()), \"Unknown error code \" + err);\n\t\t} else {\n\t\t\tthrow KeeperException.create(code);\n\t\t}\n\t}\n\treturn results;\n}", "CodeBleu_score": 39.14446424423684}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t\tList<OpResult> results = transaction.doMulti();\n\tif (results.get(0) instanceof ErrorResult) {\n\t\tErrorResult errorResult = (ErrorResult) results.get(0);\n\t\tint code = errorResult.getErr();\n\t\tKeeperException ke = KeeperException.create(KeeperException.Code.get(code), errorResult.getPath());\n\t\tthrow ke;\n\t}\n\treturn results;\n}", "CodeBleu_score": 36.0725545526154}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\tList<String> serviceNames = serviceDiscovery.queryForNames();\n\tfor (String serviceName : serviceNames) {\n\t\tList<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName);\n\t\tSystem.out.println(serviceName);\n\t\tfor (ServiceInstance<InstanceDetails> instance : instances) {\n\t\t\toutputInstance(instance);\n\t\t}\n\t}\n}", "CodeBleu_score": 48.51422974075924}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\ttry {\n\t\tMap<String, List<ServiceInstance<InstanceDetails>>> services = serviceDiscovery.queryForInstances(null);\n\t\tfor (Map.Entry<String, List<ServiceInstance<InstanceDetails>>> entry : services.entrySet()) {\n\t\t\tSystem.out.println(entry.getKey());\n\t\t\tfor (ServiceInstance<InstanceDetails> instance : entry.getValue()) {\n\t\t\t\toutputInstance(instance);\n\t\t\t}\n\t\t}\n\t} catch (NoNodeException e) {\n\t\tSystem.out.println(\"No services registered.\");\n\t} finally {\n\t\tserviceDiscovery.close();\n\t}\n}", "CodeBleu_score": 42.19718354434758}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t\ttry {\n\t\tSystem.out.println(\"Service names and their instances:\");\n\t\tfor (String serviceName : serviceDiscovery.queryForNames()) {\n\t\t\tSystem.out.println(serviceName + \":\");\n\t\t\tfor (ServiceInstance<InstanceDetails> instance : serviceDiscovery.queryForInstances(serviceName)) {\n\t\t\t\toutputInstance(instance);\n\t\t\t}\n\t\t}\n\t} catch (NoNodeException e) {\n\t\tSystem.out.println(\"No instances registered\");\n\t} finally {\n\t\tserviceDiscovery.close();\n\t}\n}", "CodeBleu_score": 42.06832557327175}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeAll { it == READY_NODE }\n\tchildren = children.collect { it.substring(it.indexOf('-') + 1) }\n\tchildren.sort()\n}", "CodeBleu_score": 11.616284771037764}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\treturn children.findAll { it!= READY_NODE }.collect { it as String }.sort()\n}", "CodeBleu_score": 10.143038685302901}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t\tchildren.removeAll { it == READY_NODE }\n\tList<String> sortedChildren = children.collect { it as Integer } as List<String>\n\tsortedChildren.sort()\n\treturn sortedChildren\n}", "CodeBleu_score": 14.578604840742257}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, timeout, this);\n\tif (getOption(\"readonly\").equals(\"yes\")) {\n\t\tzk.setReadOnly(true);\n\t}\n}", "CodeBleu_score": 26.137718513242504}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tif (newHost.equals(\"localhost\")) {\n\t\tnewHost = \"127.0.0.1\";\n\t}\n\tzk = new ZooKeeper(newHost, 3000, this);\n\tif (getOption(\"readOnly\").equals(\"true\")) {\n\t\tzk.setReadOnly(true);\n\t}\n}", "CodeBleu_score": 30.125221146429524}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t\tif (zk!= null) {\n\t\tzk.close();\n\t}\n\tzk = new ZooKeeper(newHost, 3000, this);\n\tzk.setReadOnly(getOption(\"readonly\").equals(\"true\"));\n}", "CodeBleu_score": 24.26464945833671}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acls = new ArrayList<ACL>();\n\tString[] segments = aclString.split(\",\");\n\tfor (String segment : segments) {\n\t\ttry {\n\t\t\tString[] parts = segment.split(\":\");\n\t\t\tif (parts.length!= 3) {\n\t\t\t\toutputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tString scheme = parts[0];\n\t\t\tString id = parts[1];\n\t\t\tString perms = parts[2];\n\t\t\tint perm = getPermFromString(perms);\n\t\t\tId idObj = new Id(scheme, id);\n\t\t\tACL acl = new ACL(perm, idObj);\n\t\t\tacls.add(acl);\n\t\t} catch (Exception e) {\n\t\t\toutputStream.write((\"Failed to parse ACL segment: \" + segment).getBytes());\n\t\t}\n\t}\n\treturn acls;\n}", "CodeBleu_score": 26.39237772308254}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t\tList<ACL> acls = new ArrayList<ACL>();\n\tString[] segments = aclString.split(\",\");\n\tfor (String segment : segments) {\n\t\tString[] parts = segment.split(\":\");\n\t\tif (parts.length!= 3) {\n\t\t\toutputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\n\t\t\tcontinue;\n\t\t}\n\t\tString scheme = parts[0];\n\t\tString id = parts[1];\n\t\tint perms = getPermFromString(parts[2]);\n\t\tACL acl = new ACL(ZooDefs.Perms.ALL, new Id(scheme, id));\n\t\tacl.setPerms(perms);\n\t\tacls.add(acl);\n\t}\n\treturn acls;\n}", "CodeBleu_score": 24.907984919913474}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\tList<ACL> acls = new ArrayList<>();\nString[] segments = aclString.split(\",\");\nfor (String segment : segments) {\nString[] parts = segment.split(\":\");\nif (parts.length!= 3) {\noutputStream.write((\"Invalid ACL segment: \" + segment).getBytes());\ncontinue;\n}\nString scheme = parts[0];\nString id = parts[1];\nString perms = parts[2];\nint perm = getPermFromString(perms);\nId idObj = new Id(scheme, id);\nACL acl = new ACL(perm, idObj);\nacls.add(acl);\n}\nreturn acls;\n}", "CodeBleu_score": 24.924684425418945}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tObjects.requireNonNull(pathList);\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tzookeeperMap.get(serverId).delete(path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 93.68642587633285}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tObjects.requireNonNull(pathList);\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tzookeeperMap.get(serverId).delete(path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 93.68642587633285}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t\tObjects.requireNonNull(pathList);\n\tassertZookeeperExists(serverId);\n\tif (pathList.size() < 20) {\n\t\tfor (String path : pathList) {\n\t\t\tzookeeperMap.get(serverId).delete(path);\n\t\t}\n\t} else {\n\t\tzookeeperMap.get(serverId).deleteAsync(pathList);\n\t}\n}", "CodeBleu_score": 93.68642587633285}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to ZooKeeper at \" + url + \"...\n\");\n\tvar connection = new CuratorZookeeperConnectionFactory().create(url);\n\twriter.write(\"Connected to ZooKeeper at \" + url + \"\n\");\n\tvar zkMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zkMain);\n}", "CodeBleu_score": 26.76202235079566}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to Zookeeper instance: \" + url + \"\n\");\n\tCuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n\tZookeeperParams params = ZookeeperParams.builder()\n\t\t\t.id(id)\n\t\t\t.url(url)\n\t\t\t.build();\n\tZookeeperConnection connection = factory.create(params);\n\twriter.write(\"Successfully connected to Zookeeper instance: \" + url + \"\n\");\n\tZooKeeperMain zooKeeperMain = new ZooKeeperMain(connection.getClient());\n\treturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 53.130552136768216}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\tecting to \" + url + \"...\");\n\tvar connection = new CuratorZookeeperConnectionFactory().create(url);\n\twriter.write(\"success\n\");\n\tvar zooKeeperMain = new ZooKeeperMain(connection);\n\treturn new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 23.08738903461805}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\tnt retries = 0;\n\twhile (retries < 6) {\n\t\ttry {\n\t\t\tsshClient.connect();\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to connect to SSH server. Retrying...\", e);\n\t\t\tretries++;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException ie) {\n\t\t\t\tthrow new IllegalStateException(ie);\n\t\t\t}\n\t\t}\n\t}\n\tif (sshClient.isConnected()) {\n\t\ttry {\n\t\t\tsshClient.disconnect();\n\t\t} catch (IOException e) {\n\t\t\tthrow new IllegalStateException(e);\n\t\t}\n\t}\n\tthrow new IllegalStateException(\"Failed to connect to SSH server after 6 retries.\");\n}", "CodeBleu_score": 39.83883550540351}, {"code": "public void blockUntilConnected(){\n\tt retryCount = 0;\n        while (retryCount < 6) {\n            try {\n                sshClient.connect();\n                break;\n            } catch (IOException e) {\n                retryCount++;\n                LOGGER.warn(\"Retrying connection to SSH server (attempt \" + retryCount + \" of 6)\", e);\n                try {\n                    Thread.sleep(1000);\n                } catch (InterruptedException ie) {\n                    Thread.currentThread().interrupt();\n                    throw new IllegalStateException(ie);\n                }\n            }\n        }\n\n        if (!sshClient.isConnected()) {\n            try {\n                sshClient.close();\n            } catch (IOException e) {\n                throw new IllegalStateException(e);\n            }\n            throw new IllegalStateException(\"Failed to connect to SSH server\");\n        }\n    }", "CodeBleu_score": 40.95474958573866}, {"code": "public void blockUntilConnected(){\n\tnt attempts = 0;\n\twhile (attempts < 6) {\n\t\ttry {\n\t\t\tsshClient.connect();\n\t\t\treturn;\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to connect to \" + host + \":\" + port + \", attempt \" + attempts + \" of 6\", e);\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e1) {\n\t\t\t\tthrow new IllegalStateException(e1);\n\t\t\t}\n\t\t\tattempts++;\n\t\t}\n\t}\n\ttry {\n\t\tsshClient.close();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n\tthrow new IllegalStateException(\"Failed to connect to \" + host + \":\" + port + \" after 6 attempts\");\n}", "CodeBleu_score": 42.247407602437}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error deleting node\", e);\n\t\tthrow new IllegalStateException(\"Error deleting node\", e);\n\t}\n}", "CodeBleu_score": 65.58140481940595}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error deleting node: \" + e.getMessage());\n\t\tthrow new IllegalStateException(\"Error deleting node: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 56.32009613346348}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t\ttry {\n\t\tzookeeperDomainService.deleteNode(serverId, pathList);\n\t} catch (Exception e) {\n\t\tlog.error(\"Error deleting node(s) from Zookeeper: \" + e.getMessage());\n\t\tthrow new IllegalStateException(\"Error deleting node(s) from Zookeeper: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 54.81841797990341}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\tPlatform.runLater(() -> {\nServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\nzookeeperDomainService.disconnect(serverConfiguration.getId());\ntreeItemCache.remove(id);\n});\n}", "CodeBleu_score": 88.6474308207464}, {"code": "public void disconnect(String id){\n\t\tPlatform.runLater(() -> {\n\t\tServerConfiguration serverConfiguration = configurationDomainService.getById(id).orElseThrow();\n\t\tzookeeperDomainService.disconnect(serverConfiguration.getId());\n\t\ttreeItemCache.remove(id);\n\t});\n}", "CodeBleu_score": 88.7355923352014}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\tServer server = serverService.getServer(serverId);\n\tServerConfig serverConfig = server.getServerConfig();\n\tString connectionUrl = serverConfig.getTunnelEnabled()? \"localhost:\" + serverConfig.getTunnelPort() : server.getIp() + \":\" + server.getPort();\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 47.859372977448665}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// Get the server configuration\n\tServerConfiguration server = zookeeperDomainService.getServerConfiguration(serverId);\n\t\n\t// Determine the connection URL based on whether SSH tunneling is enabled\n\tString connectionUrl = server.isSshTunnelingEnabled()? server.getSshTunnelingUrl() : server.getConnectionUrl();\n\t\n\t// Start the terminal with the specified server ID and connection URL\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 40.7966846031986}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t\t// Get the server configuration\n\tServer server = serverService.getServer(serverId);\n\n\t// Determine the connection URL based on whether SSH tunneling is enabled\n\tString connectionUrl;\n\tif (server.isSshTunnelingEnabled()) {\n\t\tconnectionUrl = \"ssh://\" + server.getUsername() + \"@localhost:\" + server.getSshTunnelingPort() + \"/\" + server.getHomeDirectory();\n\t} else {\n\t\tconnectionUrl = \"ssh://\" + server.getUsername() + \"@\" + server.getHostname() + \":\" + server.getSshPort() + \"/\" + server.getHomeDirectory();\n\t}\n\n\t// Start the terminal with the specified server ID and connection URL\n\tzookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 47.50819305500893}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zooKeeper = zooKeeperMap.get(id);\n\t\tzooKeeper.create(command, command.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to execute command: \" + command + \" on server: \" + id);\n\t\tSystem.out.println(\"Failed to execute command: \" + command + \" on server: \" + id);\n\t}\n}", "CodeBleu_score": 36.549569958091546}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tZooKeeper zk = zookeepers.get(id);\n\t\tif (zk!= null) {\n\t\t\tzk.create(command, command.getBytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error executing command \" + command + \" on server \" + id, e);\n\t\tSystem.out.println(\"Command execution failed. Please try again.\");\n\t}\n}", "CodeBleu_score": 42.9297457834365}, {"code": "public void executeCommand(String id, String command){\n\t\ttry {\n\t\tString result = zk.executeCommand(id, command);\n\t\tSystem.out.println(result);\n\t} catch (Exception e) {\n\t\tSystem.out.println(\"Failed to execute command \" + command + \" on server \" + id + \" due to \" + e.getMessage());\n\t\tSystem.out.println(\"Please try again\");\n\t}\n}", "CodeBleu_score": 46.71477785232901}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tString path = \"zookeeper.properties\";\n\tFile file = new File(path);\n\tif (file.exists()) {\n\t\ttry (InputStream input = new FileInputStream(file)) {\n\t\t\tproperties.load(input);\n\t\t\tlog.info(\"Loaded Zookeeper system properties: {}\", properties);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Failed to load Zookeeper system properties from file: {}\", e.getMessage());\n\t\t}\n\t} else {\n\t\tlog.error(\"Zookeeper system properties file not found: {}\", path);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 41.96805869590631}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties zkProperties = new Properties();\n\tString zkPropertiesPath = System.getProperty(\"zookeeper.properties.path\");\n\tif (zkPropertiesPath == null) {\n\t\tzkPropertiesPath = \"zookeeper.properties\";\n\t}\n\tFile zkPropertiesFile = new File(zkPropertiesPath);\n\tif (zkPropertiesFile.exists()) {\n\t\ttry {\n\t\t\tzkProperties.load(new FileInputStream(zkPropertiesFile));\n\t\t\tlog.info(\"Loaded Zookeeper system properties from \" + zkPropertiesFile.getAbsolutePath());\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Unable to load Zookeeper system properties from \" + zkPropertiesFile.getAbsolutePath(), e);\n\t\t}\n\t} else {\n\t\tlog.warn(\"Unable to find Zookeeper system properties file at \" + zkPropertiesFile.getAbsolutePath());\n\t}\n\treturn zkProperties;\n}", "CodeBleu_score": 36.19735382581718}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t\tProperties properties = new Properties();\n\tString filePath = \"zookeeper.properties\";\n\ttry {\n\t\tFile file = new File(filePath);\n\t\tif (file.exists()) {\n\t\t\tproperties.load(new FileInputStream(file));\n\t\t\tlog.info(\"Loaded Zookeeper system properties from \" + filePath + \": \" + properties);\n\t\t} else {\n\t\t\tlog.warn(\"Zookeeper system properties file \" + filePath + \" does not exist\");\n\t\t}\n\t} catch (IOException e) {\n\t\tlog.warn(\"Failed to load Zookeeper system properties from \" + filePath, e);\n\t}\n\treturn properties;\n}", "CodeBleu_score": 38.93821067591398}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlog.error(\"Error while loading Zookeeper system properties from content: \" + content, e);\n\t\tshowNotification(\n\t\t\t\t\"Error while loading Zookeeper system properties from content: \" + content,\n\t\t\t\tNotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tprops.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n\t} catch (IOException e) {\n\t\tlog.error(\"Error while saving Zookeeper system properties to file: \" + SYS_PROP_PATH, e);\n\t\tshowNotification(\n\t\t\t\t\"Error while saving Zookeeper system properties to file: \" + SYS_PROP_PATH,\n\t\t\t\tNotificationType.ERROR);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 36.51269694432821}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\ttry {\n\t\tProperties properties = new Properties();\n\t\tproperties.load(new StringReader(content));\n\t\tFile file = new File(SYS_PROP_PATH);\n\t\tproperties.store(new FileOutputStream(file), \"Zookeeper System Properties\");\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to save Zookeeper system properties.\", e);\n\t\tNotification.show(\"Failed to save Zookeeper system properties.\", Notification.Type.ERROR_MESSAGE);\n\t}\n}", "CodeBleu_score": 27.646869851702295}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t\tProperties props = new Properties();\n\ttry {\n\t\tprops.load(new StringReader(content));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error loading Zookeeper system properties\", e);\n\t\tshowNotification(\"Error loading Zookeeper system properties\", e.getMessage(), NotificationType.ERROR);\n\t\treturn;\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\n\t\tprops.store(fos, \"Zookeeper system properties\");\n\t\tfos.close();\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error saving Zookeeper system properties\", e);\n\t\tshowNotification(\"Error saving Zookeeper system properties\", e.getMessage(), NotificationType.ERROR);\n\t\treturn;\n\t}\n}", "CodeBleu_score": 37.46615192601339}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\tBufferedReader reader = null;\n\tStringBuilder sb = new StringBuilder();\n\ttry {\n\t\treader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = reader.readLine())!= null) {\n\t\t\tsb.append(line).append(\"\n\");\n\t\t}\n\t\tcleanup(reader);\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Could not read from socket\", e);\n\t}\n}", "CodeBleu_score": 51.87736128710954}, {"code": "private String response(Socket client){\n\tStringBuilder sb = new StringBuilder();\n\ttry (BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()))) {\n\t\tString line;\n\t\twhile ((line = in.readLine())!= null) {\n\t\t\tsb.append(line).append(\"\n\");\n\t\t}\n\t\tcleanup(client);\n\t\treturn sb.toString();\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Cannot read from client\", e);\n\t}\n}", "CodeBleu_score": 38.43191097650857}, {"code": "private String response(Socket client){\n\tStringBuilder sb = new StringBuilder();\n\ttry {\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tString line;\n\t\twhile ((line = in.readLine())!= null) {\n\t\t\tsb.append(line);\n\t\t\tsb.append(\"\n\");\n\t\t}\n\t\tcleanup(in);\n\t} catch (IOException e) {\n\t\tthrow new IllegalStateException(\"Error reading from socket\", e);\n\t} finally {\n\t\tcleanup(client);\n\t}\n\treturn sb.toString();\n}", "CodeBleu_score": 48.957979076822355}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework client = curatorFramework(params);\n\ttry {\n\t\tclient.start();\n\t\tclient.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (Exception e) {\n\t\tclient.close();\n\t\tthrow new RuntimeException(\"Failed to connect to Zookeeper\", e);\n\t}\n\treturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 57.3087396226017}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tize the CuratorFramework client\nCuratorFramework client = curatorFramework(params);\nclient.start();\n\n// Wait up to 5 seconds for the connection to be established\ntry {\n    client.blockUntilConnected(5, TimeUnit.SECONDS);\n} catch (InterruptedException | TimeoutException e) {\n    client.close();\n    throw new RuntimeException(\"Failed to connect to Zookeeper\", e);\n}\n\n// Return a new CuratorZookeeperConnection with the provided parameters\nreturn new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 53.487651847863745}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\tamework curatorFramework = curatorFramework(params);\n\tcuratorFramework.start();\n\ttry {\n\t\tcuratorFramework.blockUntilConnected(5, TimeUnit.SECONDS);\n\t} catch (InterruptedException e) {\n\t\tcuratorFramework.close();\n\t\tthrow new RuntimeException(e);\n\t}\n\treturn new CuratorZookeeperConnection(params, curatorFramework);\n}", "CodeBleu_score": 41.000137875151395}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t//        if (!isSync.compareAndSet(false, true)) {\n//            log.info(\"Zookeeper sync already in progress, skipping...\");\n//            return;\n//        }\n//\n//        log.info(\"Starting zookeeper sync...\");\n//\n//        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n//\n//        try {\n//            treeCache.start();\n//        } catch (Exception e) {\n//            log.error(\"Failed to start Zookeeper tree cache\", e);\n//            try {\n//                treeCache.close();\n//            } catch (IOException e1) {\n//                log.error(\"Failed to close Zookeeper tree cache\", e1);\n//            }\n//        }\n    }", "CodeBleu_score": 2.6809899971628313}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\tif (isSync.getAndSet(true)) {\n\t\tlog.info(\"Zookeeper sync already in progress for connection string: {}\", connectionString);\n\t\treturn;\n\t}\n\tlog.info(\"Starting Zookeeper sync for connection string: {}\", connectionString);\n\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\ttry {\n\t\ttreeCache.start();\n\t} catch (Exception e) {\n\t\tlog.error(\"Error starting Zookeeper sync for connection string: {}\", connectionString, e);\n\t\tclose();\n\t}\n}", "CodeBleu_score": 50.68917736466758}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t\tString connectionString = curatorFramework.getZookeeperClient().getCurrentConnectionString();\n\tif (isSync.compareAndSet(false, true)) {\n\t\tlog.info(\"Start to sync zookeeper nodes, connectionString: {}\", connectionString);\n\t\ttreeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n\t\ttry {\n\t\t\ttreeCache.start();\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to start tree cache, connectionString: {}, error: {}\", connectionString, e.getMessage());\n\t\t\ttreeCache.close();\n\t\t}\n\t} else {\n\t\tlog.info(\"Sync zookeeper nodes is in progress, connectionString: {}\", connectionString);\n\t}\n}", "CodeBleu_score": 50.050624808990406}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 62.503226681462465}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.61037577866037}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t\t// Create a PathChildrenCache for the given path\n\tPathChildrenCache cache = new PathChildrenCache(client, path, true);\n\n\t// Start the cache in BUILD_INITIAL_CACHE mode\n\tcache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n\n\t// Add a listener to handle child node events\n\tcache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.56712611353464}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service\");\n\ttry {\n\t\tfor (String path : servicePaths) {\n\t\t\ttry {\n\t\t\t\tclient.delete().forPath(path);\n\t\t\t} catch (Exception e) {\n\t\t\t\tSystem.out.println(\"Error unregistering service: \" + e.getMessage());\n\t\t\t}\n\t\t}\n\t} finally {\n\t\tclient.close();\n\t}\n}", "CodeBleu_score": 44.597582919681386}, {"code": "public void unregisterService(){\n\t\tlogger.info(\"Unregistering service from Zookeeper\");\n\tfor (String path : servicePaths) {\n\t\ttry {\n\t\t\tcuratorClient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Error unregistering service from Zookeeper\", e);\n\t\t}\n\t}\n\tcuratorClient.close();\n}", "CodeBleu_score": 49.40384955443763}, {"code": "public void unregisterService(){\n\t\tSystem.out.println(\"Unregistering service...\");\n\tfor (String path : servicePaths) {\n\t\ttry {\n\t\t\tcuratorClient.delete().forPath(path);\n\t\t} catch (Exception e) {\n\t\t\tSystem.out.println(\"Error deleting path \" + path + \": \" + e.getMessage());\n\t\t}\n\t}\n\ttry {\n\t\tcuratorClient.close();\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t}\n}", "CodeBleu_score": 45.29203083409754}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> makeClientReady(client, null))\n\t\t.exceptionally(e -> {\n\t\t\tmakeClientReady(client, e);\n\t\t\treturn null;\n\t\t})\n\t\t.thenRun(() -> {\n\t\t\tclient.subscribeStateChanges(listener);\n\t\t});\n}", "CodeBleu_score": 36.9100155677579}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.runAsync(() -> {\n\t\tmakeClientReady(new ZkClient(this.connectionString, this.sessionTimeout, this.connectionTimeout, this.zkSerializer), null);\n\t\tif (this.client!= null) {\n\t\t\tthis.client.subscribeStateChanges(listener);\n\t\t}\n\t});\n}", "CodeBleu_score": 18.12528304387891}, {"code": "public void addListener(IZkStateListener listener){\n\tCompletableFuture.supplyAsync(() -> {\n\t\tmakeClientReady(null, null);\n\t\treturn null;\n\t}).exceptionally(e -> {\n\t\tmakeClientReady(null, e);\n\t\treturn null;\n\t}).thenAccept(v -> {\n\t\tif (client!= null) {\n\t\t\tclient.subscribeStateChanges(listener);\n\t\t}\n\t});\n}", "CodeBleu_score": 39.07813949600576}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\tthis.serverAddr = serverAddr;\n\tthis.authority = authority;\n\tthis.retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\tthis.connectionTimeout = 10000;\n\tthis.client = CuratorFrameworkFactory.builder()\n\t\t\t.connectString(serverAddr)\n\t\t\t.retryPolicy(retryPolicy)\n\t\t\t.connectionTimeoutMs(connectionTimeout)\n\t\t\t.build();\n\tif (authority!= null) {\n\t\tclient.getZookeeperClient().addAuthInfo(\"digest\", authority.getBytes());\n\t}\n\tclient.getConnectionStateListenable().addListener(this);\n\tclient.start();\n\ttry {\n\t\tclient.blockUntilConnected();\n\t} catch (InterruptedException e) {\n\t\tthrow new IllegalStateException(\"Interrupted while waiting for connection to Zookeeper\", e);\n\t}\n}", "CodeBleu_score": 31.204432681586198}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\ttry {\n\t\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\t\tCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()\n\t\t\t\t.connectString(serverAddr)\n\t\t\t\t.retryPolicy(retryPolicy)\n\t\t\t\t.connectionTimeoutMs(10000);\n\t\tif (authority!= null) {\n\t\t\tbuilder.authorization(\"digest\", authority.getBytes());\n\t\t}\n\t\tthis.client = builder.build();\n\t\tthis.client.getConnectionStateListenable().addListener(this);\n\t\tthis.client.start();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Failed to initialize CuratorZookeeperClient\", e);\n\t}\n}", "CodeBleu_score": 32.65250826481959}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t\ttry {\n\t\tRetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\t\tCuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder()\n\t\t\t\t.connectString(serverAddr)\n\t\t\t\t.retryPolicy(retryPolicy)\n\t\t\t\t.connectionTimeoutMs(5000);\n\t\tif (authority!= null) {\n\t\t\tbuilder.authorization(\"digest\", authority.getBytes());\n\t\t}\n\t\tthis.client = builder.build();\n\t\tthis.client.getConnectionStateListenable().addListener(this);\n\t\tthis.client.start();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(e);\n\t}\n}", "CodeBleu_score": 31.59531959391144}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tChildListenerMap map = getChildListenerMap(path);\n\tif (map!= null) {\n\t\tmap.remove(listener);\n\t\tif (map.isEmpty()) {\n\t\t\tremoveTargetChildListener(path, map);\n\t\t}\n\t}\n}", "CodeBleu_score": 31.8928117175784}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\tif (listener == null) {\n\t\treturn;\n\t}\n\n\tTargetChildListener targetListener = null;\n\tsynchronized (this.listeners) {\n\t\tMap<ChildListener, TargetChildListener> map = this.listeners.get(path);\n\t\tif (map!= null) {\n\t\t\ttargetListener = map.remove(listener);\n\t\t}\n\t}\n\n\tif (targetListener!= null) {\n\t\tremoveTargetChildListener(path, targetListener);\n\t}\n}", "CodeBleu_score": 59.68406341137279}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t\t// TODO: implement\n}", "CodeBleu_score": 6.4131329332144436}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tint ret = QCONF_ERR_OTHER;\n\tif (zh == NULL) {\n\t\tLOG_ERROR(\"zh is null\");\n\t\treturn ret;\n\t}\n\n\tstring idc;\n\tstring hosts;\n\tlock_ht_delete(g_zookeeper_handles, g_zookeeper_handles_mu, zh);\n\tzoo_close(zh);\n\n\tif (get_idc_and_hosts_from_zookeeper(idc, hosts)!= QCONF_OK) {\n\t\tLOG_ERROR(\"get_idc_and_hosts_from_zookeeper failed\");\n\t\treturn ret;\n\t}\n\n\tif (init_zookeeper_handle(idc, hosts, &zh)!= QCONF_OK) {\n\t\tLOG_ERROR(\"init_zookeeper_handle failed\");\n\t\treturn ret;\n\t}\n\n\tif (init_zookeeper_env(zh)!= QCONF_OK) {\n\t\tLOG_ERROR(\"init_zookeeper_env failed\");\n\t\treturn ret;\n\t}\n\n\tret = set_table_watcher(zh, g_table_path, g_table_watcher, g_table_watcher_context);\n\tif (ret!= ZOK) {\n\t\tLOG_ERROR(\"set_table_watcher failed\");\n\t\treturn ret;\n\t}\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 33.97508895899741}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t", "CodeBleu_score": 1.8025725052776684}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\tif (zh == NULL) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Get the IDC and host information associated with the handle\n\tstring idc;\n\tstring host;\n\tstring path;\n\tif (get_idc_host_path_from_handle(zh, idc, host, path)!= QCONF_OK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Close the old handle\n\tzookeeper_close(zh);\n\n\t// Deserialize the IDC and host information\n\tvector<string> hosts;\n\tif (deserialize_hosts(idc, host, hosts)!= QCONF_OK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Initialize a new ZooKeeper handle with the deserialized information\n\tzh = zookeeper_init(hosts[0].c_str(), watcher, 10000, 0, NULL, 0);\n\tif (zh == NULL) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Initialize the environment for the new handle\n\tif (init_handle_env(zh, idc, host, path)!= QCONF_OK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\t// Reset the table watcher\n\tif (watcher_set_table_watcher(zh)!= QCONF_OK) {\n\t\treturn QCONF_ERR_OTHER;\n\t}\n\n\treturn QCONF_OK;\n}", "CodeBleu_score": 31.763503719905366}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tstring host = idc_host;\n\tstring path = \"/notify\";\n\tstring data = idc;\n\tstring data_path = path + \"/\" + data;\n\tstring notify_path = path + \"/notify\";\n\n\t// Update internal tables with handle and host information\n\tlock_ht_update(idc_to_zh, idc_to_zh_mu, idc, zh);\n\tlock_ht_update(zh_to_idc, zh_to_idc_mu, zh, idc);\n\n\t// Check connection state of the Zookeeper handle\n\tint state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\tLOG(ERROR) << \"Zookeeper handle not connected\";\n\t\treturn;\n\t}\n\n\t// Register current host on Zookeeper server\n\tint rc = zoo_create(zh, data_path.c_str(), data.c_str(), data.size(), &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (rc!= ZOK) {\n\t\tLOG(ERROR) << \"Failed to register current host on Zookeeper server\";\n\t\treturn;\n\t}\n\n\t// Set watcher on notify node\n\trc = zoo_wexists(zh, notify_path.c_str(), watcher, NULL, NULL, 0);\n\tif (rc == ZNONODE) {\n\t\t// Add IDC to gray list\n\t\tgray_idc_mu.Lock();\n\t\tgray_idc.insert(idc);\n\t\tgray_idc_mu.Unlock();\n\t\tLOG(ERROR) << \"IDC is not registered on Zookeeper server\";\n\t} else if (rc!= ZOK) {\n\t\tLOG(ERROR) << \"Failed to set watcher on notify node\";\n\t}\n}", "CodeBleu_score": 45.55826285858515}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t", "CodeBleu_score": 4.2583564394715525}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\tif (zh == NULL) {\n\t\tLOG(ERROR) << \"Zookeeper handle is NULL\";\n\t\treturn;\n\t}\n\n\t// update internal tables\n\tlock_ht_update(zk_handles, zk_handles_mu, zh, idc_host);\n\tlock_ht_update(idc_to_zk, idc_to_zk_mu, idc, zh);\n\n\t// check connection state\n\tint state = zoo_state(zh);\n\tif (state!= ZOO_CONNECTED_STATE) {\n\t\tLOG(ERROR) << \"Zookeeper handle is not connected\";\n\t\treturn;\n\t}\n\n\t// register current host on Zookeeper server\n\tstring path = \"/idcs/\" + idc + \"/\" + idc_host;\n\tint rc = zoo_create(zh, path.c_str(), \"\", 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n\tif (rc!= ZOK) {\n\t\tLOG(ERROR) << \"Failed to register current host on Zookeeper server\";\n\t\treturn;\n\t}\n\n\t// set watcher on notify node\n\tstring notify_path = \"/notify/\" + idc;\n\trc = zoo_wexists(zh, notify_path.c_str(), &notify_watcher, NULL, NULL);\n\tif (rc!= ZOK) {\n\t\tLOG(ERROR) << \"Failed to set watcher on notify node\";\n\t\treturn;\n\t}\n\n\t// add IDC to gray list or log error\n\tif (rc == ZNONODE) {\n\t\tgray_list.insert(idc);\n\t\tLOG(INFO) << \"IDC added to gray list: \" << idc;\n\t} else if (rc!= ZOK) {\n\t\tLOG(ERROR) << \"Failed to add IDC to gray list: \" << idc;\n\t}\n}", "CodeBleu_score": 47.32653706727276}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    m = hashlib.sha1()\n    m.update(username)\n    m.update(password)\n    return username + ':' + base64.b64encode(m.digest())\n\n", "CodeBleu_score": 21.887767726950873}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    m = hashlib.sha1()\n    m.update(username)\n    m.update(password)\n    return username + \":\" + base64.b64encode(m.digest())\n\n", "CodeBleu_score": 26.668749717937466}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    m = hashlib.sha1()\n    m.update(username.encode('utf-8'))\n    m.update(b':')\n    m.update(password.encode('utf-8'))\n    return username + b':' + base64.b64encode(m.digest())\n\n", "CodeBleu_score": 31.42381548017149}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.get_lock_path()\n    try:\n        lock_value = self.zk.get(lock_path)[0]\n    except kazoo.exceptions.NoNodeError:\n        return False\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 41.215253192695656}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.get_lock_path()\n    try:\n        lock_value = self.zk.get(lock_path)[0]\n    except Exception as e:\n        print(e)\n        return False\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 34.99583512304517}, {"code": "def holds_lock(self)\n\t\n    if self.pe is None:\n        return False\n    lock_path = self.get_lock_path()\n    try:\n        lock_value = self.zk.get(lock_path)[0]\n    except kazoo.exceptions.NoNodeError:\n        return False\n    return lock_value == self.pe.id\n\n", "CodeBleu_score": 35.28369238319619}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    self.client.sync(lock_path)\n    self.client.sync(entry_path)\n    value, stat = self.client.retry(self.client.get, lock_path)\n    if value!= self.id:\n        return False\n    self.client.retry(self.client.delete, lock_path)\n    self.client.retry(self.client.delete, entry_path)\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 50.98392036188892}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    self.client.sync(lock_path)\n    self.client.sync(entry_path)\n    try:\n        self.client.retry(self.client.transaction, self.client.delete, lock_path, self.client.delete, entry_path)\n    except Exception:\n        return False\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 52.78535350911391}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_id, entry_id = self.processing_element\n    lock_path = \"{path}/{id}\".format(path=self._lock_path, id=lock_id)\n    entry_path = \"{path}/{id}\".format(path=self._entry_path, id=entry_id)\n    self.client.sync(lock_path)\n    self.client.sync(entry_path)\n    with self.client.transaction() as txn:\n        txn.delete(lock_path)\n        txn.delete(entry_path)\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 58.66701990308566}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except (\n        ConnectionResetError,\n        socket.timeout,\n        socket.error,\n        struct.error,\n    ):\n        self.logger.log(BLATHER, \"Read socket timed out\")\n        return\n    except Exception as exc:\n        self.logger.exception(\"Error reading socket\")\n        self.client.handler.dispatch_callback(Callback(\"error\", None, (exc,)))\n        return\n\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Received ping\")\n        self.outstanding_pings.clear()\n        return\n    elif header.xid == AUTH_XID:\n        self.logger.log(BLATHER, \"Received authentication response\")\n        if header.err:\n            self.client._auth_failed.set()\n            self.client._auth_failed.set_exception(\n                EXCEPTIONS[header.err]()\n            )\n        else:\n            self.client._auth_failed.set()\n            self.client._auth_failed.set_result(True)\n        return\n    elif header.xid == WATCH_XID:\n        self._read_watch_event(buffer, offset)\n        return\n    else:\n        self.logger.log(BLATHER, \"Received response(xid=%s)\", header.xid)\n        self._read_response(header, buffer, offset)\n", "CodeBleu_score": 49.380296540982805}, {"code": "def _read_socket(self, read_timeout)\n\t    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except (ConnectionLoss, ConnectionClosedError) as e:\n        self.logger.log(BLATHER, \"Connection loss: %s\", e)\n        self.handler.dispatch_callback(Callback(\"connection_loss\", None, (e,)))\n        raise\n    except TimeoutError as e:\n        self.logger.log(BLATHER, \"Timeout: %s\", e)\n        raise\n    except Exception as e:\n        self.logger.log(BLATHER, \"Error: %s\", e)\n        raise\n    else:\n        if header.xid == PING_XID:\n            self.logger.log(BLATHER, \"Received ping\")\n            self._outstanding_pings.clear()\n        elif header.xid == AUTH_XID:\n            if header.err:\n                self.logger.log(BLATHER, \"Authentication failed: %s\", header.err)\n                self._auth_failed.set()\n            else:\n                self.logger.log(BLATHER, \"Authentication successful\")\n                self._auth_failed.clear()\n        elif header.xid == WATCH_XID:\n            self._read_watch_event(buffer, offset)\n        else:\n            self.logger.log(BLATHER, \"Received header: %s\", header)\n            self._read_response(header, buffer, offset)\n", "CodeBleu_score": 50.709867846655555}, {"code": "def _read_socket(self, read_timeout)\n\t    try:\n        header, buffer, offset = self._read_header(read_timeout)\n    except ConnectionLoss:\n        self.logger.log(BLATHER, \"Connection loss\")\n        raise\n    except ReadTimeoutError:\n        self.logger.log(BLATHER, \"Read timeout\")\n        raise\n    except BadVersion:\n        self.logger.log(BLATHER, \"Bad version\")\n        raise\n    except NoAuth:\n        self.logger.log(BLATHER, \"No auth\")\n        raise\n    except BadAuth:\n        self.logger.log(BLATHER, \"Bad auth\")\n        raise\n    except SessionExpired:\n        self.logger.log(BLATHER, \"Session expired\")\n        raise\n    except SessionMoved:\n        self.logger.log(BLATHER, \"Session moved\")\n        raise\n\n    # Handle ping\n    if header.xid == PING_XID:\n        self.logger.log(BLATHER, \"Received ping\")\n        self.outstanding_pings.clear()\n        return\n\n    # Handle auth\n    if header.xid == AUTH_XID:\n        return self._handle_auth(buffer, offset)\n\n    # Handle watch\n    if header.xid == WATCH_XID:\n        return self._read_watch_event(buffer, offset)\n\n    # Handle other xids\n    return self._read_response(header, buffer, offset)\n\n", "CodeBleu_score": 45.28716002102862}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    logger.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.client.start()\n            self.client.stop()\n            break\n        except KazooException:\n            logger.warning(\"Failed to connect to Zookeeper\")\n    self.connection_stopped.set()\n    self.session_callback(State.LOST)\n    logger.info(\"Stopping ZK loop\")\n\n", "CodeBleu_score": 32.67889092069848}, {"code": "def zk_loop(self)\n\t\n    self.logger.debug('Starting zk_loop')\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.logger.debug('Connecting to Zookeeper')\n            self.client.start()\n        except KazooException:\n            self.logger.warning('Failed to connect to Zookeeper. Retrying in %s seconds', self.retry_policy.get_sleep_time())\n            self.retry_policy.sleep()\n            continue\n        else:\n            self.logger.debug('Connected to Zookeeper')\n            break\n\n    self.connection_stopped.set()\n    if self.stopped.is_set():\n        self.logger.debug('Stopping connection')\n    else:\n        self.logger.debug('Lost connection to Zookeeper')\n    self.client.stop()\n    self.logger.debug('Stopped connection')\n    self.session_callback(KazooState.LOST)\n\n", "CodeBleu_score": 38.70372857784342}, {"code": "def zk_loop(self)\n\t\n    self.logger.debug(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.logger.debug(\"Connecting to ZK\")\n            self.client.start(retry_policy=self.retry_policy)\n            self.logger.debug(\"Connected to ZK\")\n            break\n        except Exception as e:\n            self.logger.warning(f\"Failed to connect to ZK: {e}\")\n            time.sleep(self.retry_policy.sleep_func(self.retry_policy.attempts))\n    self.connection_stopped.set()\n    self.session_callback(State.CLOSED)\n    self.logger.debug(\"Stopped ZK loop\")\n\n", "CodeBleu_score": 47.727591775686044}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    # Sort the partitions and the members\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    # Find the index of the identifier in the sorted members list\n    index = sorted_members.index(identifier)\n    # Return every nth partition starting from the index, where n is the number of workers\n    return sorted_partitions[index::len(members)]\n\n", "CodeBleu_score": 37.493399878959686}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 33.6805163744097}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    try:\n        self.client.retry(self.client.delete, self.leave_path)\n    except NoNodeError:\n        pass\n    self._best_effort_cleanup()\n    self.participating = False\n\n", "CodeBleu_score": 56.013434918307695}, {"code": "def leave(self)\n\t\n    try:\n        self.client.retry(self.client.delete, self.leave_path)\n    except NoNodeError:\n        pass\n    finally:\n        self._best_effort_cleanup()\n        self.participating = False\n\n", "CodeBleu_score": 54.2658296971414}, {"code": "def leave(self)\n\t\n    self._participating = False\n    try:\n        self.client.retry(self.client.delete, self.leave_path)\n    except NoNodeError:\n        pass\n    except Exception as e:\n        self._best_effort_cleanup()\n        raise e\n\n", "CodeBleu_score": 44.64930436531076}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (serverStatus() == Status.STOPPED) {\n\t\t\tString cmd = \"hadoop-daemon.sh start ftpd\";\n\t\t\tProcessBuilder pb = new ProcessBuilder(\"/bin/sh\", \"-c\", cmd);\n\t\t\tProcess p = pb.start();\n\t\t\tp.waitFor();\n\t\t\tresult.setSuccess(true);\n\t\t} else {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMsg(\"server already started\");\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMsg(e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 25.228443724240456}, {"code": "public Result start(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (server.isServerRunning()) {\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"The server is already running.\");\n\t\t} else {\n\t\t\tserver.start();\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"The server has been started.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(e.getMessage());\n\t}\n\treturn result;\n}", "CodeBleu_score": 31.070832860204966}, {"code": "public Result start(){\n\t\ttry {\n\t\t// Check if the server is already running\n\t\tif (server.isRunning()) {\n\t\t\treturn new Result(Result.SUCCESS, \"Server is already running\");\n\t\t}\n\n\t\t// Start the server\n\t\tserver.start();\n\n\t\t// Check if the server is running\n\t\tif (server.isRunning()) {\n\t\t\treturn new Result(Result.SUCCESS, \"Server started successfully\");\n\t\t} else {\n\t\t\treturn new Result(Result.FAILURE, \"Server failed to start\");\n\t\t}\n\t} catch (Exception e) {\n\t\treturn new Result(Result.FAILURE, \"Exception occurred while starting the server: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 34.24004002678809}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"Server stopped successfully.\");\n\t\t} else {\n\t\t\treturn new Result(false, \"Server is not running.\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(e.getMessage());\n\t\treturn new Result(false, \"Error stopping server.\");\n\t}\n}", "CodeBleu_score": 29.647987781498315}, {"code": "public Result stop(){\n\t\tResult result = new Result();\n\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop();\n\t\t\tresult.setSuccess(true);\n\t\t\tresult.setMessage(\"FTP server stopped successfully\");\n\t\t} else {\n\t\t\tresult.setSuccess(false);\n\t\t\tresult.setMessage(\"FTP server is not running\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Error stopping FTP server\", e);\n\t\tresult.setSuccess(false);\n\t\tresult.setMessage(\"Error stopping FTP server\");\n\t}\n\treturn result;\n}", "CodeBleu_score": 30.818296945991403}, {"code": "public Result stop(){\n\t\ttry {\n\t\tif (server.isRunning()) {\n\t\t\tserver.stop();\n\t\t\treturn new Result(true, \"FTP server stopped successfully\");\n\t\t} else {\n\t\t\treturn new Result(false, \"FTP server is not running\");\n\t\t}\n\t} catch (Exception e) {\n\t\tlog.error(e.getMessage());\n\t\treturn new Result(false, e.getMessage());\n\t}\n}", "CodeBleu_score": 40.031158281204945}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.92963784073824}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.92963784073824}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\tList<Authority> authorities = getAuthorities();\n\n\t// check for no authorities at all\n\tif (authorities == null) {\n\t\treturn null;\n\t}\n\n\tboolean someoneCouldAuthorize = false;\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\tsomeoneCouldAuthorize = true;\n\n\t\t\trequest = authority.authorize(request);\n\n\t\t\t// authorization failed, return null\n\t\t\tif (request == null) {\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\n\t}\n\n\tif (someoneCouldAuthorize) {\n\t\treturn request;\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 79.92963784073824}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 75.3057384912722}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tfs.mkdirs(fullPath);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 73.01308123577155}, {"code": "public boolean mkdir(){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(new URI(hdfsURL), new Configuration());\n\t\tfs.mkdirs(new Path(fullPath));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 66.32266716909771}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}, {"code": "public boolean delete(){\n\t\ttry {\n\t\tFileSystem dfs = HdfsOverFtpSystem.getDfs();\n\t\tdfs.delete(fullPath, true);\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 96.17684673215308}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = path.getFileSystem();\n\t\treturn fs.rename(path, new Path(path.getParent(), ftpFile.getName()));\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 54.76976776849466}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tfs.rename(path, new Path(ftpFile.getParent().getPath() + \"/\" + ftpFile.getName()));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 67.32726015008694}, {"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tPath newPath = new Path(path.getParent(), ftpFile.getName());\n\t\treturn fs.rename(path, newPath);\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 56.50981560979843}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\t// get the HDFS file system\n\t\tFileSystem fs = FileSystem.get(new Configuration());\n\n\t\t// list the status of files in the directory\n\t\tFileStatus[] status = fs.listStatus(path);\n\n\t\t// construct virtual file names based on the base directory's virtual path\n\t\tList<FtpFile> files = new ArrayList<FtpFile>();\n\t\tfor (int i = 0; i < status.length; i++) {\n\t\t\tfiles.add(new FtpFile(path.toString(), status[i].getPath().getName(), status[i].getLen(), status[i].isDirectory()));\n\t\t}\n\n\t\t// return an unmodifiable list of these FtpFile objects\n\t\treturn Collections.unmodifiableList(files);\n\t} catch (IOException e) {\n\t\t// log the error\n\t\tSystem.err.println(e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 33.230608180382916}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\tFileSystem hdfs = FileSystem.get(new Configuration());\n\t\tFileStatus[] files = hdfs.listStatus(path);\n\t\tList<FtpFile> fileList = new ArrayList<FtpFile>();\n\t\tfor (FileStatus file : files) {\n\t\t\tString fullName = file.getPath().toString();\n\t\t\tint filelen = fullName.length();\n\t\t\tif ((filelen!= 1) && (fullName.charAt(filelen - 1) == '/')) {\n\t\t\t\tfullName = fullName.substring(0, filelen - 1);\n\t\t\t}\n\t\t\tFtpFile f = new FtpFile(fullName, file.isDirectory());\n\t\t\tfileList.add(f);\n\t\t}\n\t\treturn Collections.unmodifiableList(fileList);\n\t} catch (IOException e) {\n\t\tlogger.error(\"IOException in listFiles: \" + e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 35.125125271844}, {"code": "public List<FtpFile> listFiles(){\n\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tFileStatus[] status = fs.listStatus(path);\n\t\tList<FtpFile> list = new ArrayList<FtpFile>();\n\t\tfor (FileStatus s : status) {\n\t\t\tif (s.isFile()) {\n\t\t\t\tlist.add(new FtpFile(s.getPath().toString(), this));\n\t\t\t}\n\t\t}\n\t\treturn Collections.unmodifiableList(list);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Error listing files: \" + e.getMessage());\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 24.50740820965375}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t\tconfigured = true;\n\n\ttry {\n\t\tloadUserData();\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data from \" + userDataFile, e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 21.8368768035869}, {"code": "public void configure(){\n\t\tconfigured = true;\n\n\tuserDataProp = new Properties();\n\n\ttry {\n\t\tif (userDataFile.exists()) {\n\t\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data file: \" + userDataFile, e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 41.60700304341432}, {"code": "public void configure(){\n\t\tconfigured = true;\n\n\tinitUserDataProp();\n\n\tif (!userDataFile.exists()) {\n\t\treturn;\n\t}\n\n\ttry {\n\t\tuserDataProp.load(new FileInputStream(userDataFile));\n\t} catch (IOException e) {\n\t\tthrow new FtpServerConfigurationException(\n\t\t\t\t\"Failed to load user data file: \" + userDataFile.getPath(), e);\n\t}\n\n\tconvertDeprecatedPropertyNames();\n}", "CodeBleu_score": 34.348540683125975}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\tif (userDataFile.getParentFile()!= null &&!userDataFile.getParentFile().exists()) {\n\t\tif (!userDataFile.getParentFile().mkdirs()) {\n\t\t\tthrow new ConfigurationException(\"Could not create directory \" + userDataFile.getParentFile().getAbsolutePath());\n\t\t}\n\t}\n\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tuserData.store(fos, \"User data for \" + getServerAddress());\n\t} catch (IOException e) {\n\t\tlogger.log(Level.WARNING, \"Could not save user data to \" + userDataFile.getAbsolutePath(), e);\n\t\tthrow new FtpException(\"Could not save user data to \" + userDataFile.getAbsolutePath(), e);\n\t} finally {\n\t\tif (fos!= null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tlogger.log(Level.WARNING, \"Could not close file output stream for \" + userDataFile.getAbsolutePath(), e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 39.23397812634186}, {"code": "private void saveUserData() throws FtpException{\n\t\tString parentDir = userFile.getParent();\n\tif (parentDir!= null) {\n\t\tFile parent = new File(parentDir);\n\t\tif (!parent.exists()) {\n\t\t\tif (!parent.mkdirs()) {\n\t\t\t\tthrow new ConfigurationException(\"Unable to create parent directory for user data file: \" + parentDir);\n\t\t\t}\n\t\t}\n\t}\n\ttry {\n\t\tFileOutputStream fos = new FileOutputStream(userFile);\n\t\ttry {\n\t\t\tObjectOutputStream oos = new ObjectOutputStream(fos);\n\t\t\ttry {\n\t\t\t\toos.writeObject(userData);\n\t\t\t} finally {\n\t\t\t\toos.close();\n\t\t\t}\n\t\t} finally {\n\t\t\tfos.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tLOG.error(\"Error writing user data to file: \" + userFile, e);\n\t\tthrow new FtpException(\"Error writing user data to file: \" + userFile, e);\n\t}\n}", "CodeBleu_score": 43.94577093223607}, {"code": "private void saveUserData() throws FtpException{\n\t\tif (userDataFile!= null) {\n\t\tFile parentDir = userDataFile.getParentFile();\n\t\tif (!parentDir.exists()) {\n\t\t\tif (!parentDir.mkdirs()) {\n\t\t\t\tthrow new FtpException(\n\t\t\t\t\t\t\"Unable to create parent directory for user data file: \"\n\t\t\t\t\t\t\t\t+ userDataFile);\n\t\t\t}\n\t\t}\n\t\tFileOutputStream fos = null;\n\t\ttry {\n\t\t\tfos = new FileOutputStream(userDataFile);\n\t\t\tuserData.store(fos, \"User data for \" + username);\n\t\t} catch (IOException e) {\n\t\t\tlogger.log(Level.SEVERE, \"Error saving user data\", e);\n\t\t\tthrow new FtpException(\"Error saving user data\", e);\n\t\t} finally {\n\t\t\tif (fos!= null) {\n\t\t\t\ttry {\n\t\t\t\t\tfos.close();\n\t\t\t\t} catch (IOException e) {\n\t\t\t\t\tlogger.log(Level.SEVERE, \"Error closing user data file\", e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 47.107096492846104}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t\ttry {\n\t\tHdfsUserManager userManagerFactory = new HdfsUserManager();\n\t\tuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\n\t\tuserManagerFactory.delete(user);\n\t\treturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n\t} catch (Exception e) {\n\t\tlog.error(e);\n\t\treturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n\t}\n}", "CodeBleu_score": 77.74143874051694}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\ttry {\nHdfsUserManager userManagerFactory = new HdfsUserManager();\nuserManagerFactory.setFile(new File(System.getProperty(\"user.dir\") + File.separator + \"users.properties\"));\nuserManagerFactory.delete(user);\nreturn new Result(true, \"\u5220\u9664\u7528\u6237\u6210\u529f\");\n} catch (Exception e) {\nlog.error(e);\nreturn new Result(false, \"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n}\n}", "CodeBleu_score": 77.60398801197302}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tlog.info(\"Opening file {} with buffer size {}\", path, bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tlog.info(\"Qualified path is {}\", qualifiedPath);\n\tFSDataInputStream fsdis = null;\n\ttry {\n\t\tfsdis = seaweedFS.open(qualifiedPath.toString(), bufferSize);\n\t} catch (Exception e) {\n\t\tlog.warn(\"Failed to open file {} with buffer size {}\", qualifiedPath, bufferSize, e);\n\t}\n\treturn fsdis;\n}", "CodeBleu_score": 37.09068828905928}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tlog.info(\"Opening \" + path + \" with buffer size \" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\tSeaweedFileInStream in = null;\n\ttry {\n\t\tin = new SeaweedFileInStream(qualifiedPath.toString(), bufferSize);\n\t} catch (IOException e) {\n\t\tlog.warn(\"Got exception when opening \" + qualifiedPath, e);\n\t}\n\treturn (in == null)? null : new FSDataInputStream(in);\n}", "CodeBleu_score": 28.872228491577957}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t\tLOG.debug(\"open: path=\" + path + \", bufferSize=\" + bufferSize);\n\tPath qualifiedPath = qualify(path);\n\ttry {\n\t\treturn new FSDataInputStream(new BufferedFSInputStream(store.open(qualifiedPath), bufferSize));\n\t} catch (FileNotFoundException e) {\n\t\tLOG.warn(\"open: path=\" + path + \", bufferSize=\" + bufferSize + \", exception=\" + e);\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 28.106042939468473}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (src.isRoot()) {\nreturn false;\n}\n\nif (src.equals(dst)) {\nreturn true;\n}\nFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\nPath adjustedDst = dst;\n\nif (entry!= null) {\nFileStatus dstFileStatus = getFileStatus(dst);\nString sourceFileName = src.getName();\nif (!dstFileStatus.isDirectory()) {\nreturn false;\n}\nadjustedDst = new Path(dst, sourceFileName);\n}\n\nPath qualifiedSrcPath = qualify(src);\nPath qualifiedDstPath = qualify(adjustedDst);\n\nseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\nreturn true;\n}", "CodeBleu_score": 83.94906976433724}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t// TODO Auto-generated method stub\n\treturn false;\n}", "CodeBleu_score": 6.3650562262835235}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\tif (src.isRoot()) {\n\t\treturn false;\n\t}\n\tif (src.equals(dst)) {\n\t\treturn true;\n\t}\n\tFilerProto.Entry entry = seaweedFileSystemStore.lookupEntry(dst);\n\tPath adjustedDst = dst;\n\tif (entry!= null) {\n\t\tFileStatus dstFileStatus = getFileStatus(dst);\n\t\tString sourceFileName = src.getName();\n\t\tif (!dstFileStatus.isDirectory()) {\n\t\t\treturn false;\n\t\t}\n\t\tadjustedDst = new Path(dst, sourceFileName);\n\t}\n\tPath qualifiedSrcPath = qualify(src);\n\tPath qualifiedDstPath = qualify(adjustedDst);\n\tseaweedFileSystemStore.rename(qualifiedSrcPath, qualifiedDstPath);\n\treturn true;\n}", "CodeBleu_score": 84.19205025432}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\") || capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.619069546583695}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\"))\n\t\treturn true;\n\tif (capability.toLowerCase().equals(\"hflush\"))\n\t\treturn supportFlush;\n\treturn false;\n}", "CodeBleu_score": 40.69297456354647}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\"))\n\t\treturn true;\n\tif (capability.toLowerCase().equals(\"hflush\"))\n\t\treturn supportFlush;\n\treturn false;\n}", "CodeBleu_score": 40.69297456354647}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset > lastFlushOffset) {\n\t\tif (offset > writtenBytes.length) {\n\t\t\tthrow new IOException(\"The offset \" + offset + \" is larger than the written bytes length \" + writtenBytes.length);\n\t\t}\n\t\t// Flush the written bytes to the service.\n\t\tif (offset > 0) {\n\t\t\tbyte[] bytes = Arrays.copyOfRange(writtenBytes, (int) lastFlushOffset, (int) offset);\n\t\t\t// Write the bytes to the service.\n\t\t\tservice.write(path, bytes, lastFlushOffset);\n\t\t}\n\t\t// Update the last flush offset.\n\t\tlastFlushOffset = offset;\n\t\t// Write the metadata to the filer client.\n\t\twriteMetadataToFilerClient();\n\t}\n}", "CodeBleu_score": 30.153064149877974}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset > lastFlushOffset) {\n\t\tif (offset > length) {\n\t\t\tthrow new IOException(\"Offset \" + offset + \" is greater than length \" + length);\n\t\t}\n\t\tif (offset > writtenBytes.length) {\n\t\t\tthrow new IOException(\"Offset \" + offset + \" is greater than writtenBytes.length \" + writtenBytes.length);\n\t\t}\n\t\tif (offset == writtenBytes.length) {\n\t\t\treturn;\n\t\t}\n\t\tif (writtenBytes.length > 0) {\n\t\t\tbyte[] bytesToWrite = new byte[writtenBytes.length - (int) offset];\n\t\t\tSystem.arraycopy(writtenBytes, (int) offset, bytesToWrite, 0, bytesToWrite.length);\n\t\t\twrittenBytes = bytesToWrite;\n\t\t}\n\t\tif (writtenBytes.length > 0) {\n\t\t\ttry {\n\t\t\t\tif (isAppend) {\n\t\t\t\t\t// Append mode\n\t\t\t\t\t// Write the bytes to the service\n\t\t\t\t\tservice.append(path, writtenBytes, 0, writtenBytes.length);\n\t\t\t\t} else {\n\t\t\t\t\t// Overwrite mode\n\t\t\t\t\t// Write the bytes to the service\n\t\t\t\t\tservice.write(path, writtenBytes, 0, writtenBytes.length, offset);\n\t\t\t\t}\n\t\t\t\t// Update the last flush offset\n\t\t\t\tlastFlushOffset = offset + writtenBytes.length;\n\t\t\t\t// Update the length\n\t\t\t\tlength = lastFlushOffset;\n\t\t\t} catch (Exception e) {\n\t\t\t\tthrow new IOException(e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 36.32727532267056}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t\tif (offset < 0) {\n\t\tthrow new IOException(\"Invalid offset \" + offset + \" for flush\");\n\t}\n\tif (offset > this.writtenBytes) {\n\t\tthrow new IOException(\"Offset \" + offset + \" is greater than written bytes \" + this.writtenBytes);\n\t}\n\tif (offset == this.writtenBytes) {\n\t\treturn;\n\t}\n\tif (offset == this.lastFlushOffset) {\n\t\treturn;\n\t}\n\tif (offset > this.lastFlushOffset) {\n\t\tthis.writeWrittenBytesToService(offset);\n\t\tthis.lastFlushOffset = offset;\n\t}\n}", "CodeBleu_score": 37.512070123512174}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t flip the buffer to prepare for reading\n        bufferToWrite.flip();\n\n        // calculate the byte length\n        final int byteLength = bufferToWrite.remaining();\n\n        // ensure the task queue is not overloaded\n        waitForTaskToComplete();\n\n        // submit a write task to the completion service\n        final Future<Integer> future = completionService.submit(new Callable<Integer>() {\n            @Override\n            public Integer call() throws IOException {\n                try {\n                    return write(bufferToWrite, writePosition);\n                } catch (IOException e) {\n                    lastError = e;\n                    throw e;\n                }\n            }\n        });\n\n        // record the write operation\n        writeOperations.add(new WriteOperation(future, byteLength));\n\n        // manage the operation queue\n        shrinkWriteOperationQueue();\n\n        // return the number of bytes written\n        return byteLength;\n    }", "CodeBleu_score": 39.787121515861045}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t flip the buffer to prepare for reading\n        bufferToWrite.flip();\n\n        // calculate the byte length\n        int length = bufferToWrite.remaining();\n\n        // ensure the task queue is not overloaded\n        if (writeOperations.size() > maxWriteOperations) {\n            waitForTaskToComplete();\n        }\n\n        // submit the write task\n        Future<Integer> task = completionService.submit(new Callable<Integer>() {\n            public Integer call() throws IOException {\n                int bytesWritten = 0;\n                try {\n                    bytesWritten = writeBuffer(bufferToWrite, writePosition);\n                } catch (IOException e) {\n                    lastError = e;\n                }\n                return bytesWritten;\n            }\n        });\n\n        // record the write operation\n        writeOperations.add(new WriteOperation(task, length));\n\n        // manage the operation queue\n        shrinkWriteOperationQueue();\n\n        return length;\n    }", "CodeBleu_score": 40.91935691451052}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t flip the buffer to prepare for reading\n        bufferToWrite.flip();\n// calculate the byte length\n        int bytesToWrite = bufferToWrite.remaining();\n// ensure the task queue is not overloaded\n        waitForTaskToComplete();\n// submit the write task to the completion service\n        Future<Void> task = completionService.submit(new Callable<Void>() {\n            @Override\n            public Void call() throws Exception {\n                try {\n                    writeBufferToService(bufferToWrite, writePosition);\n                } catch (IOException e) {\n                    lastError = e;\n                    throw e;\n                }\n                return null;\n            }\n        });\n// record the write operation and manage the operation queue\n        writeOperations.add(new WriteOperation(task, bytesToWrite));\n        shrinkWriteOperationQueue();\n// return the number of bytes written\n        return bytesToWrite;\n    }", "CodeBleu_score": 39.94012448440453}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tFuture<String> future = completionService.take();\n\t\t\tif (future.isDone()) {\n\t\t\t\tfuture.get();\n\t\t\t\tbreak;\n\t\t\t}\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(\"Interrupted while waiting for task to complete\", e);\n\t\t} catch (ExecutionException e) {\n\t\t\tthrow new IOException(\"Task failed to complete\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 27.702483737101158}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\ttry {\n\t\twhile (true) {\n\t\t\tFuture<String> result = completionService.take();\n\t\t\tif (result == null) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tthrow new IOException(\"Interrupted while waiting for task to complete.\", e);\n\t}\n}", "CodeBleu_score": 25.15298884408537}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t\twhile (true) {\n\t\ttry {\n\t\t\tFuture<String> future = completionService.take();\n\t\t\tfuture.get();\n\t\t\tbreak;\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new IOException(e);\n\t\t} catch (ExecutionException e) {\n\t\t\tthrow new IOException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 24.61320196162775}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tint numTasks = writeOperationQueue.size();\n\tfor (int i = 0; i < numTasks; i++) {\n\t\tWriteOperation op = writeOperationQueue.get(i);\n\t\tif (op.isDone()) {\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t\twriteOperationQueue.remove(i);\n\t\t\tnumTasks--;\n\t\t\ti--;\n\t\t}\n\t}\n}", "CodeBleu_score": 23.05853222047139}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\ttry {\n\t\twhile (!writeOperationQueue.isEmpty() && writeOperationQueue.peek().isDone()) {\n\t\t\tWriteOperation op = writeOperationQueue.remove();\n\t\t\ttotalAppendOffset += op.getLength();\n\t\t}\n\t} catch (InterruptedException e) {\n\t\tthrow new IOException(e);\n\t}\n}", "CodeBleu_score": 36.09085778361886}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t\tif (writeOperationQueue.isEmpty()) {\n\t\treturn;\n\t}\n\ttry {\n\t\twhile (!writeOperationQueue.isEmpty()) {\n\t\t\tWriteOperation op = writeOperationQueue.peek();\n\t\t\tif (op.isDone()) {\n\t\t\t\ttotalAppendOffset += op.getLength();\n\t\t\t\twriteOperationQueue.remove();\n\t\t\t} else {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow new IOException(e);\n\t}\n}", "CodeBleu_score": 36.47611217933363}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null || user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user or user.getHomeDirectory() is null\");\n\t}\n\tthis.user = user;\n\thomePath = user.getHomeDirectory();\n}", "CodeBleu_score": 47.8362540484472}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user is null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory is null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 66.55666023987888}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user cannot be null\");\n\t}\n\tthis.user = user;\n\tthis.homePath = user.getHomeDirectory();\n\tif (this.homePath == null) {\n\t\tthrow new IllegalArgumentException(\"user's home directory cannot be null\");\n\t}\n}", "CodeBleu_score": 59.98399137245517}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = new Path(dir);\n\tif (newPath.isAbsolute()) {\n\t\tcurrentPath = newPath;\n\t} else {\n\t\tcurrentPath = currentPath.resolve(newPath);\n\t}\n\tif (currentPath.getParent() == null) {\n\t\treturn true;\n\t}\n\tif (currentPath.getParent().getParent() == null) {\n\t\treturn false;\n\t}\n\tcurrentPath = currentPath.getParent();\n\treturn true;\n}", "CodeBleu_score": 20.449590365904225}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = null;\n\tif (dir.startsWith(\"/\")) {\n\t\tnewPath = new Path(dir);\n\t} else {\n\t\tnewPath = currentPath.resolve(dir);\n\t}\n\tif (newPath.getParent().equals(Path.ROOT)) {\n\t\treturn false;\n\t}\n\tif (newPath.isDirectory()) {\n\t\tcurrentPath = newPath;\n\t\treturn true;\n\t}\n\treturn false;\n}", "CodeBleu_score": 24.29490792050281}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tPath newPath = new Path(dir);\n\tif (newPath.isAbsolute()) {\n\t\tcurrentPath = newPath;\n\t} else {\n\t\tcurrentPath = currentPath.resolve(newPath);\n\t}\n\tif (currentPath.getParent() == null) {\n\t\treturn false;\n\t}\n\treturn currentPath.toFile().isDirectory();\n}", "CodeBleu_score": 15.523073525262344}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.conf = conf;\n\tthis.filerClient = new FilerClient(host, grpcPort, conf);\n\tthis.accessMode = conf.get(ACCESS_MODE, DEFAULT_ACCESS_MODE);\n}", "CodeBleu_score": 28.523629805593743}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tsuper(conf);\n\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.filerClient = new FilerClient(host, grpcPort);\n\tthis.accessMode = conf.get(ACCESS_MODE, ACCESS_MODE_DEFAULT);\n}", "CodeBleu_score": 24.72110025653851}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t\tthis.host = host;\n\tthis.port = port;\n\tthis.grpcPort = grpcPort;\n\tthis.conf = conf;\n\tthis.filerClient = new FilerClient(host, port, grpcPort, conf);\n\tthis.accessMode = conf.get(\"seaweedfs.access.mode\", \"direct\");\n}", "CodeBleu_score": 33.042241866557376}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nLOG.info(\"openFileForRead: \" + path);\n\nFilerProto.Entry entry = lookupEntry(path);\n\nif (entry == null) {\n\nthrow new FileNotFoundException(\"File not found: \" + path);\n\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 71.62633017157086}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nLOG.info(\"Opening file for read: \" + path);\n\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(\"File not found: \" + path);\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 71.49268774158762}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t\nlog.info(\"openFileForRead: \" + path);\n\nFilerProto.Entry entry = lookupEntry(path);\nif (entry == null) {\nthrow new FileNotFoundException(path.toString());\n}\n\nreturn new SeaweedHadoopInputStream(filerClient, statistics, path);\n\n}", "CodeBleu_score": 68.90101896556533}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thost = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thost = \"localhost\";\n\t}\n\tnumThreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.threads\", 1);\n\tfilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.files\", 1);\n\tthreadPool = Executors.newFixedThreadPool(numThreadsPerMap);\n\tfor (int i = 0; i < numThreadsPerMap; i++) {\n\t\tthreadPool.execute(new Thread(new MapThread()));\n\t}\n\tthreadPool.shutdown();\n}", "CodeBleu_score": 44.96887042634946}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thostName = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thostName = \"localhost\";\n\t}\n\tnumThreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.threads\", 1);\n\tfilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.files\", 1);\n\tthreadPool = Executors.newFixedThreadPool(numThreadsPerMap);\n\tfor (int i = 0; i < numThreadsPerMap; i++) {\n\t\tthreadPool.execute(new SpeculativeMapperThread(hostName, i));\n\t}\n\tthreadPool.shutdown();\n}", "CodeBleu_score": 49.26283636686791}, {"code": "public void configure(JobConf conf){\n\t\tthis.conf = conf;\n\ttry {\n\t\thost = InetAddress.getLocalHost().getHostName();\n\t} catch (UnknownHostException e) {\n\t\thost = \"localhost\";\n\t}\n\tnumThreadsPerMap = conf.getInt(\"mapred.map.tasks.speculative.threads\", 1);\n\tfilesPerThread = conf.getInt(\"mapred.map.tasks.speculative.files\", 1);\n\tpool = Executors.newFixedThreadPool(numThreadsPerMap);\n\tfor (int i = 0; i < numThreadsPerMap; i++) {\n\t\tpool.execute(new MapperThread());\n\t}\n\tpool.shutdown();\n}", "CodeBleu_score": 45.964046468791594}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t(BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 94.22726092867568}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\tCheck if the trash emptier is already running for the specified host\nif (BgTaskUtil.isRunning(uri.getHost(), \"Trash emptier\")) {\nreturn;\n}\n// Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser\ntry {\nUserGroupInformation superUser = UserGroupInformation.createRemoteUser(getConf(conf, \"superuser\", \"hdfs\"));\nemptierFs = superUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\nJuiceFileSystemImpl fs = new JuiceFileSystemImpl();\nfs.initialize(uri, conf);\nreturn fs;\n});\n// Start the trash emptier task\nBgTaskUtil.startTrashEmptier(uri.getHost(), \"Trash emptier\", emptierFs, new Trash(emptierFs, conf).getEmptier(), TimeUnit.MINUTES.toMillis(10));\n} catch (Exception e) {\nthrow new IOException(\"start trash failed!\",e);\n}\n}", "CodeBleu_score": 88.94385097548239}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\ttry {\n\t\tString currentContext = getCallerContext();\n\t\tif (currentContext == null || currentContext.isEmpty()) {\n\t\t\tsetCallerContext(context);\n\t\t} else {\n\t\t\tif (currentContext.contains(context)) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\tcurrentContext = currentContext + \" \" + context;\n\t\t\tsetCallerContext(currentContext);\n\t\t}\n\t} catch (Exception e) {\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 26.431805108073558}, {"code": "public static void setContext(String context) throws Exception{\n\t\tcom.altova.db.Dbs.setContext(context);\n}", "CodeBleu_score": 3.5602174066450742}, {"code": "public static void setContext(String context) throws Exception{\n\t\ttry{\n\t\t// get current context\n\t\tString currentContext = getCallerContext();\n\t\t// if current context is invalid or not set\n\t\tif(currentContext == null || currentContext.equals(\"\")){\n\t\t\t// create new context\n\t\t\tString newContext = context + \"|\" + getSignature();\n\t\t\t// set new context\n\t\t\tsetCallerContext(newContext);\n\t\t}\n\t\t// if current context is valid but lacks a signature\n\t\telse if(!currentContext.contains(\"|\")){\n\t\t\t// append signature to context\n\t\t\tString newContext = currentContext + \"|\" + getSignature();\n\t\t\t// set new context\n\t\t\tsetCallerContext(newContext);\n\t\t}\n\t\t// if current context is valid and includes the provided context\n\t\telse if(currentContext.contains(context)){\n\t\t\t// do nothing\n\t\t}\n\t\t// if current context is valid and does not include the provided context\n\t\telse{\n\t\t\t// append context to current context\n\t\t\tString newContext = currentContext + \"|\" + context;\n\t\t\t// set new context\n\t\t\tsetCallerContext(newContext);\n\t\t}\n\t}catch(Exception e){\n\t\tthrow e;\n\t}\n}", "CodeBleu_score": 26.632539716708038}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef TILEDB_VERBOSE\n  std::cout << \"HDFS::remove_file; uri: \" << uri.to_string() << std::endl;\n#endif\n\n  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n\n  // Delete the file\n  if (hdfsDelete(hdfs_, uri.to_string().c_str(), 0)!= 0) {\n    return LOG_STATUS(Status_HDFSError(\n        \"Cannot remove file; URI: \" + uri.to_string()));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 52.60339901374347}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef TILEDB_VERBOSE\n  std::cout << \"HDFS::remove_file; uri: \" << uri << std::endl;\n#endif\n\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n\n  if (hdfsDelete(fs, uri.c_str()) < 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Error deleting file '\") + uri.c_str() + \"'\"));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 53.68456709629712}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t#ifdef TILEDB_SERIALIZATION\n  if (serialization_type_ == SerializationType::CAPNP) {\n    return remove_file_capnp(uri);\n  }\n#endif\n\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(&fs));\n\n  if (hdfsDelete(fs, uri.c_str()) == -1) {\n    RETURN_NOT_OK(libhdfs_->status());\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file '\") + uri.c_str() + \"'\"));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 56.6909455925648}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\treturn Status::Ok();\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == NULL) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not open file for syncing\"));\n\t}\n\tif (libhdfs_->hdfsHFlush(fs, file)!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not sync file\"));\n\t}\n\tif (libhdfs_->hdfsCloseFile(fs, file)!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Could not close file after syncing\"));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 53.85329084168697}, {"code": "Status HDFS::sync(const URI& uri){\n\t", "CodeBleu_score": 2.518609995321332}, {"code": "Status HDFS::sync(const URI& uri){\n\t\thdfsFS fs = nullptr;\n\tRETURN_NOT_OK(connect(&fs));\n\tint ret = libhdfs_->hdfsExists(fs, uri.to_path().c_str());\n\tif (!ret) {\n\t\treturn Status::Ok();\n\t}\n\thdfsFile file = libhdfs_->hdfsOpenFile(fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n\tif (file == nullptr) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot open file: \" + uri.to_string()));\n\t}\n\tif (libhdfs_->hdfsHFlush(fs, file)!= 0) {\n\t\tlibhdfs_->hdfsCloseFile(fs, file);\n\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot flush file: \" + uri.to_string()));\n\t}\n\tif (libhdfs_->hdfsCloseFile(fs, file)!= 0) {\n\t\treturn LOG_STATUS(Status_HDFSError(\"Cannot close file: \" + uri.to_string()));\n\t}\n\treturn Status::Ok();\n}", "CodeBleu_score": 56.97086426325762}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HDFS_DEPRECATED_FILE_SIZE\n  return file_size_deprecated(uri, nbytes);\n#else\n  RETURN_NOT_OK(connect());\n\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot get file info for file '\") + uri.c_str() + \"'\"));\n  }\n\n  if (file_info->mKind!= kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Path '\") + uri.c_str() + \"' is not a file\"));\n  }\n\n  *nbytes = file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n#endif\n}", "CodeBleu_score": 49.715099883437574}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef HDFS_DEPRECATED_FUNCTIONS\n  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n\n  // Get the file information\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot get file information for file '\") + uri.c_str() +\n        \"'\"));\n  }\n\n  // Check if the path is a file\n  if (file_info->mKind!= kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Path '\") + uri.c_str() + \"' is not a file\"));\n  }\n\n  // Set the file size\n  *nbytes = file_info->mSize;\n\n  // Free the file information\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n#else\n  return LOG_STATUS(Status_HDFSError(\n      \"file_size is deprecated, use file_info instead\"));\n#endif\n}", "CodeBleu_score": 50.942968186831926}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t#ifdef TILEDB_VERBOSE\n  std::cout << \"HDFS::file_size; uri: \" << uri.c_str() << std::endl;\n#endif\n\n  RETURN_NOT_OK(libhdfs_->status());\n  if (hdfs_ == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\"Not connected to HDFS namenode\"));\n  }\n\n  hdfsFileInfo* file_info = hdfsGetPathInfo(hdfs_, uri.c_str());\n  if (file_info == nullptr) {\n    return LOG_STATUS(Status_HDFSError(\n        \"Cannot get file information for file; uri: \" + uri.c_str()));\n  }\n\n  if (file_info->mKind!= kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status_HDFSError(\n        \"Cannot get file size; uri: \" + uri.c_str() +\n        \"; path is not a file\"));\n  }\n\n  *nbytes = file_info->mSize;\n  hdfsFreeFileInfo(file_info, 1);\n  return Status::Ok();\n}", "CodeBleu_score": 47.97173098394643}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfg = hbaseCfgString.split(\",\");\n\tString quorum = null;\n\tString znode = null;\n\tfor (String cfg : hbaseCfg) {\n\t\tif (cfg.startsWith(\"quorum\")) {\n\t\t\tquorum = cfg.split(\"=\")[1];\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum = quorum + \":2181\";\n\t\t\t}\n\t\t} else if (cfg.startsWith(\"znode\")) {\n\t\t\tznode = cfg.split(\"=\")[1];\n\t\t}\n\t}\n\tif (znode == null) {\n\t\tznode = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znode);\n}", "CodeBleu_score": 27.898768975467636}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\tString[] hbaseCfgArray = hbaseCfgString.split(\";\");\n\tString quorum = null;\n\tString znodeParent = null;\n\tfor (String hbaseCfg : hbaseCfgArray) {\n\t\tif (hbaseCfg.contains(\"zookeeper.quorum\")) {\n\t\t\tquorum = hbaseCfg.substring(hbaseCfg.indexOf(\"=\") + 1);\n\t\t\tif (!quorum.contains(\":\")) {\n\t\t\t\tquorum = quorum + \":2181\";\n\t\t\t}\n\t\t}\n\t\tif (hbaseCfg.contains(\"zookeeper.znode.parent\")) {\n\t\t\tznodeParent = hbaseCfg.substring(hbaseCfg.indexOf(\"=\") + 1);\n\t\t}\n\t}\n\tif (znodeParent == null) {\n\t\tznodeParent = \"/hbase\";\n\t}\n\treturn new Pair<String, String>(quorum, znodeParent);\n}", "CodeBleu_score": 29.92519775858769}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t\t// TODO: Implement me\n\treturn null;\n}", "CodeBleu_score": 3.9618255240264766}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t", "CodeBleu_score": 0.8577865379463421}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t/\u83b7\u53d6\u8fde\u63a5\n        Connection conn = getJdbcConnection(cfg);\n        try {\n            //\u83b7\u53d6\u8868\u540d\n            String fullTableName = cfg.getFullTableName();\n            //\u83b7\u53d6\u8868\u7684schema\n            PTable table = getTableSchema(conn, fullTableName);\n            //\u83b7\u53d6\u8868\u7684\u5217\u540d\n            Set<String> columnNames = new HashSet<>(table.getColumns().size());\n            for (PColumn column : table.getColumns()) {\n                columnNames.add(column.getColumnName().getString().toLowerCase());\n            }\n            //\u83b7\u53d6\u914d\u7f6e\u7684\u5217\u540d\n            List<Column> columns = cfg.getColumns();\n            //\u68c0\u67e5\u914d\u7f6e\u7684\u5217\u540d\u662f\u5426\u5728\u8868\u4e2d\u5b58\u5728\n            for (Column column : columns) {\n                if (!columnNames.contains(column.getName().toLowerCase())) {\n                    throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXISTS,\n                            \"Column \" + column.getName() + \" does not exist in table \" + fullTableName);\n                }\n            }\n        }\n        catch (SQLException e) {\n            throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                    \"Unable to validate the configuration for HbaseSQLWriter. Please check the configuration and cluster status\", e);\n        }\n        finally {\n            closeJdbcConnection(conn);\n        }\n    }", "CodeBleu_score": 47.9490938543954}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t/\u83b7\u53d6\u8fde\u63a5\n    Connection conn = getJdbcConnection(cfg);\n    String fullTableName = cfg.getFullTableName();\n    String namespace = SchemaUtil.getSchemaNameFromFullName(fullTableName);\n    String tableName = SchemaUtil.getTableNameFromFullName(fullTableName);\n    try {\n        //\u68c0\u67e5\u8868\u662f\u5426\u5b58\u5728\n        checkTable(conn, namespace, tableName, cfg.isThinClient());\n        //\u83b7\u53d6\u8868\u7684schema\n        PTable tableSchema = getTableSchema(conn, fullTableName);\n        //\u83b7\u53d6\u914d\u7f6e\u7684\u5217\n        List<String> columnList = cfg.getColumns();\n        //\u68c0\u67e5\u914d\u7f6e\u7684\u5217\u662f\u5426\u5728\u8868\u4e2d\u5b58\u5728\n        for (String column : columnList) {\n            if (tableSchema.getColumns().get(column) == null) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.COLUMN_NOT_EXIST,\n                        \"Column [\" + column + \"] does not exist in table [\" + fullTableName + \"]\");\n            }\n        }\n    }\n    catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.VALIDATE_CONFIG_ERROR,\n                \"Unable to validate the configuration for HbaseSQLWriter\", e);\n    }\n    finally {\n        JdbcUtil.close(conn);\n    }\n}", "CodeBleu_score": 44.0109004250527}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (!kerberosPrincipal.isEmpty() &&!kerberosKeytabFilePath.isEmpty()) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Kerberos login error: {}\", e.getMessage());\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 32.9496426967302}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosPrincipal!= null && kerberosKeytabFilePath!= null &&!kerberosPrincipal.isEmpty() &&!kerberosKeytabFilePath.isEmpty()) {\n\t\tConfiguration hadoopConf = new Configuration();\n\t\thadoopConf.set(\"hadoop.security.authentication\", \"kerberos\");\n\t\tUserGroupInformation.setConfiguration(hadoopConf);\n\t\ttry {\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t} catch (IOException e) {\n\t\t\tLOGGER.error(\"Kerberos login error\", e);\n\t\t\tthrow new RuntimeException(\"Kerberos login error\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 44.41828160191784}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t\tif (kerberosPrincipal!= null &&!kerberosPrincipal.isEmpty() && kerberosKeytabFilePath!= null &&!kerberosKeytabFilePath.isEmpty()) {\n\t\ttry {\n\t\t\tUserGroupInformation.setConfiguration(new Configuration());\n\t\t\tUserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n\t\t\tlogger.info(\"Successfully logged in with Kerberos principal: \" + kerberosPrincipal);\n\t\t} catch (IOException e) {\n\t\t\tlogger.error(\"Error while logging in with Kerberos principal: \" + kerberosPrincipal + \". Error: \" + e.getMessage());\n\t\t\tthrow new RuntimeException(\"Kerberos login error. Error: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 36.33500219374455}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> map = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint columnCount = rsmd.getColumnCount();\n\tfor (int i = 1; i <= columnCount; i++) {\n\t\tString name = rsmd.getColumnLabel(i);\n\t\tif (name == null) {\n\t\t\tthrow new SQLException(\"Column name is null\");\n\t\t}\n\t\tint type = rsmd.getColumnType(i);\n\t\tif (type == Types.NULL) {\n\t\t\tthrow new SQLException(\"Column type is null\");\n\t\t}\n\t\tmap.put(name, new ThinClientPTable.ThinClientPColumn(name, type));\n\t}\n\treturn map;\n}", "CodeBleu_score": 39.020610377119176}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> result = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tfor (int i = 1; i <= rsmd.getColumnCount(); i++) {\n\t\tString name = rsmd.getColumnLabel(i);\n\t\tif (name == null)\n\t\t\tthrow new SQLException(\"Column \" + i + \" has no name\");\n\t\tint type = rsmd.getColumnType(i);\n\t\tif (type == 0)\n\t\t\tthrow new SQLException(\"Column \" + i + \" has no type\");\n\t\tresult.put(name, new ThinClientPTable.ThinClientPColumn(name, type));\n\t}\n\treturn result;\n}", "CodeBleu_score": 32.123791325062314}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t\tMap<String, ThinClientPTable.ThinClientPColumn> colType = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n\tResultSetMetaData rsmd = rs.getMetaData();\n\tint colCount = rsmd.getColumnCount();\n\tfor (int i = 1; i <= colCount; i++) {\n\t\tString colName = rsmd.getColumnLabel(i);\n\t\tint colTypeInt = rsmd.getColumnType(i);\n\t\tif (colName == null || colTypeInt == 0)\n\t\t\tthrow new SQLException(\"Unable to get column type.\");\n\t\tcolType.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colTypeInt));\n\t}\n\treturn colType;\n}", "CodeBleu_score": 36.94396953790605}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\thoenixConnection sqlConn;\n\tAdmin admin = null;\n\ttry {\n\t\tsqlConn = conn.unwrap(PhoenixConnection.class);\n\t\tadmin = sqlConn.getQueryServices().getAdmin();\n\t\tTableName hTableName = getTableName(tableName);\n\t\t// \u786e\u4fdd\u8868\u5b58\u5728\u3001\u53ef\u7528\n\t\tcheckTable(admin, hTableName);\n\t\t// \u6e05\u7a7a\u8868\n\t\tadmin.disableTable(hTableName);\n\t\tadmin.truncateTable(hTableName, true);\n\t\tLOG.debug(\"Table {} has been truncated.\", tableName);\n\t} catch (Throwable t) {\n\t\t// \u6e05\u7a7a\u8868\u5931\u8d25\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.TRUNCATE_HBASE_ERROR,\n\t\t\t\t\"Failed to truncate \" + tableName + \".\", t);\n\t} finally {\n\t\tif (admin!= null) {\n\t\t\tcloseAdmin(admin);\n\t\t}\n\t}\n}", "CodeBleu_score": 90.34800410389485}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t\nif (checkHdfsFileType(filePath, fileType)) {\n    LOG.info(\"Add file to source files list: {}\", filePath);\n    sourceFiles.add(filePath);\n}\nelse {\n    String message = String.format(\"File [%s] is not a %s file, it only supports %s.\",\n            filePath, fileType, HdfsConstant.SUPPORT_FILE_TYPE);\n    LOG.error(message);\n    throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n}\n}", "CodeBleu_score": 38.02926545014623}, {"code": "private void addSourceFileByType(String filePath){\n\t\n// Check if the file path matches the specified file type\nif (checkHdfsFileType(filePath, fileType)) {\n\n// Log an info message\nLOG.info(\"Add file [{}] to source file list.\", filePath);\n\n// Add the file to the source files list\nsourceFiles.add(filePath);\n}\nelse {\n\n// Log an error message\nLOG.error(\"The file type of [{}] does not match the specified file type [{}].\", filePath, fileType);\n\n// Throw an exception indicating the unsupported file type\nthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR,\nString.format(\"The file type of [%s] does not match the specified file type [%s].\", filePath, fileType));\n}\n}", "CodeBleu_score": 23.51186964864302}, {"code": "private void addSourceFileByType(String filePath){\n\t\tif (checkHdfsFileType(filePath, fileType)) {\n\t\tLOG.info(String.format(\"Add file [%s] to source files list.\", filePath));\n\t\tsourceFiles.add(filePath);\n\t} else {\n\t\tString message = String.format(\"Unsupported file type for [%s]\uff0cit only supports [%s].\", filePath,\n\t\t\t\tHdfsConstant.SUPPORT_FILE_TYPE);\n\t\tLOG.error(message);\n\t\tthrow AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, message);\n\t}\n}", "CodeBleu_score": 36.256506186807044}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\tlog.info(\"start read sequence file from \" + sourceSequenceFilePath);\n\ttry {\n\t\tFileSystem fs = FileSystem.get(URI.create(sourceSequenceFilePath), readerSliceConfig);\n\t\tPath path = new Path(sourceSequenceFilePath);\n\t\tSequenceFile.Reader reader = new SequenceFile.Reader(fs, path, readerSliceConfig);\n\t\tText key = (Text) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n\t\tWritable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n\t\twhile (reader.next(key, value)) {\n\t\t\tif (StringUtils.isNotBlank(value.toString())) {\n\t\t\t\tStorageReaderUtil.sendRecord(recordSender, key, value);\n\t\t\t}\n\t\t}\n\t\treader.close();\n\t} catch (Exception e) {\n\t\tlog.error(\"read sequence file error, sourceSequenceFilePath: \" + sourceSequenceFilePath, e);\n\t\tthrow DataXException.asDataXException(HdfsReaderErrorCode.READ_SEQUENCE_FILE_ERROR, e);\n\t}\n}", "CodeBleu_score": 46.32691378259864}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.StartRead, \"start read\"));\n\ttry {\n\t\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.StartRead, \"open sequence file\"));\n\t\tSequenceFile.Reader reader = new SequenceFile.Reader(readerSliceConfig, SequenceFile.Reader.file(sourceSequenceFilePath));\n\t\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.EndRead, \"open sequence file\"));\n\n\t\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.StartRead, \"read sequence file\"));\n\t\tText key = new Text();\n\t\tBytesWritable value = new BytesWritable();\n\t\twhile (reader.next(key, value)) {\n\t\t\tif (value.getLength() > 0) {\n\t\t\t\tStorageReaderUtil.transport(key, value, recordSender, taskPluginCollector);\n\t\t\t}\n\t\t}\n\t\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.EndRead, \"read sequence file\"));\n\t\treader.close();\n\t} catch (Exception e) {\n\t\tthrow new AddaxException(e);\n\t}\n\ttaskPluginCollector.collectDirty(new DirtyRecord(DirtyRecord.EndRead, \"end read\"));\n}", "CodeBleu_score": 40.6473892322163}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t\n}", "CodeBleu_score": 4.241384187539755}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t", "CodeBleu_score": 2.382402701443833}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tystem fs = null;\n\tFSDataInputStream in = null;\n\ttry {\n\t\t// get the file system\n\t\tfs = FileSystem.get(hadoopConf);\n\t\t// open the file\n\t\tPath file = new Path(filepath);\n\t\tin = fs.open(file);\n\t\tif (isORCFile(file, fs, in)) {\n\t\t\treturn specifiedFileType.equals(\"ORC\");\n\t\t}\n\t\tif (isRCFile(filepath, in)) {\n\t\t\treturn specifiedFileType.equals(\"RC\");\n\t\t}\n\t\tif (isSequenceFile(file, in)) {\n\t\t\treturn specifiedFileType.equals(\"Sequence\");\n\t\t}\n\t\tif (isParquetFile(file)) {\n\t\t\treturn specifiedFileType.equals(\"Parquet\");\n\t\t}\n\t\tif (isCSVFile(file, in)) {\n\t\t\treturn specifiedFileType.equals(\"CSV\");\n\t\t}\n\t\tif (isTextFile(file, in)) {\n\t\t\treturn specifiedFileType.equals(\"Text\");\n\t\t}\n\t\treturn false;\n\t}\n\tcatch (Exception e) {\n\t\tLOG.error(\"Error occurred while checking the file type of file [{}].\", filepath, e);\n\t\tthrow new RuntimeException(\"Error occurred while checking the file type of file [\" + filepath + \"].\", e);\n\t}\n\tfinally {\n\t\ttry {\n\t\t\tif (in!= null) {\n\t\t\t\tin.close();\n\t\t\t}\n\t\t\tif (fs!= null) {\n\t\t\t\tfs.close();\n\t\t\t}\n\t\t}\n\t\tcatch (Exception e) {\n\t\t\tLOG.error(\"Error occurred while closing the file [{}].\", filepath, e);\n\t\t\tthrow new RuntimeException(\"Error occurred while closing the file [\" + filepath + \"].\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 38.09116447050083}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\tystem fs = null;\n\tFSDataInputStream in = null;\n\tPath path = new Path(filepath);\n\ttry {\n\t\tfs = path.getFileSystem(hadoopConf);\n\t\tin = fs.open(path);\n\t\tif (isORCFile(path, fs, in)) {\n\t\t\tif (specifiedFileType.equals(FileType.ORC.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\telse if (isRCFile(filepath, in)) {\n\t\t\tif (specifiedFileType.equals(FileType.RC.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\telse if (isSequenceFile(path, in)) {\n\t\t\tif (specifiedFileType.equals(FileType.SEQUENCE.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\telse if (isParquetFile(path)) {\n\t\t\tif (specifiedFileType.equals(FileType.PARQUET.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\telse if (isCSVFile(path, in)) {\n\t\t\tif (specifiedFileType.equals(FileType.CSV.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\telse if (isTextFile(path, in)) {\n\t\t\tif (specifiedFileType.equals(FileType.TEXT.name())) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t}\n\tcatch (IOException e) {\n\t\tLOG.error(\"Failed to check the file type of [{}].\", filepath, e);\n\t\tthrow new RuntimeException(ErrorCode.ERR_CHECK_HDFS_FILE_TYPE.getMessage(), e);\n\t}\n\tfinally {\n\t\tIOUtils.closeQuietly(in);\n\t}\n\treturn false;\n}", "CodeBleu_score": 40.421890562059104}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new CustomException(ErrorCodes.CONNECTION_CLOSE_ERROR, e.getMessage());\n\t}\n}", "CodeBleu_score": 44.11025787034547}, {"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection!= null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new CustomException(10000, \"Error closing HBase connection\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 41.45395235826969}, {"code": "public static void closeConnection(Connection hConnection){\n\t\ttry {\n\t\tif (hConnection!= null) {\n\t\t\thConnection.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new HBaseConnectionException(HBaseConnectionException.CLOSE_CONNECTION_EXCEPTION, e);\n\t}\n}", "CodeBleu_score": 50.13127106377744}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t\ttry {\n\t\tif (admin!= null) {\n\t\t\tadmin.close();\n\t\t}\n\t} catch (IOException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 38.0664803067614}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 34.27050202110527}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin!= null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n}", "CodeBleu_score": 34.27050202110527}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\t// Extract the row key, timestamp, column family, qualifier, and value from the cell\n\tbyte[] rowKeyBytes = CellUtil.cloneRow(cell);\n\tbyte[] columnFamilyBytes = CellUtil.cloneFamily(cell);\n\tbyte[] qualifierBytes = CellUtil.cloneQualifier(cell);\n\tbyte[] valueBytes = CellUtil.cloneValue(cell);\n\tlong timestamp = cell.getTimestamp();\n\n\t// Determine the types and formats for the row key and column value based on predefined mappings\n\tString rowKeyFormat = rowKeyMapping.get(Bytes.toString(columnFamilyBytes));\n\tString columnValueFormat = columnValueMapping.get(Bytes.toString(columnFamilyBytes) + \":\" + Bytes.toString(qualifierBytes));\n\n\t// Convert the extracted data to the appropriate types and add them as columns to the record\n\trecord.add(new RecordField(\"rowKey\", Bytes.toString(rowKeyBytes), rowKeyFormat));\n\trecord.add(new RecordField(\"family\", Bytes.toString(columnFamilyBytes), \"string\"));\n\trecord.add(new RecordField(\"qualifier\", Bytes.toString(qualifierBytes), \"string\"));\n\trecord.add(new RecordField(\"timestamp\", timestamp, \"long\"));\n\trecord.add(new RecordField(\"value\", Bytes.toString(valueBytes), columnValueFormat));\n}", "CodeBleu_score": 30.97113743563904}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t", "CodeBleu_score": 2.0379993148048974}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowKey = configuration.get(HBaseConstants.HBASE_STARTROWKEY);\n\tif (startRowKey == null || startRowKey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\tboolean isBinaryRowKey = configuration.getBoolean(HBaseConstants.HBASE_BINARY_ROWKEY, false);\n\treturn stringToBytes(startRowKey, isBinaryRowKey);\n}", "CodeBleu_score": 47.645105225725416}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(\"hbase.startrowkey\");\n\tif (startRowkey == null || startRowkey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\tboolean isBinaryRowkey = configuration.getBoolean(\"hbase.isbinaryrowkey\", false);\n\treturn stringToBytes(startRowkey, isBinaryRowkey);\n}", "CodeBleu_score": 39.65179669165997}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(HConstants.STARTROW);\n\tif (startRowkey == null || startRowkey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\treturn stringToBytes(startRowkey, configuration.getBoolean(HConstants.IS_BINARY_ROWKEY, false));\n}", "CodeBleu_score": 39.459406496477115}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (startRowkey == null || startRowkey.isEmpty()) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 42.45905360447133}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (StringUtils.isBlank(startRowkey)) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 50.5335921481463}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t\tString startRowkey = configuration.get(START_ROWKEY);\n\tif (startRowkey.equals(\"\")) {\n\t\treturn new byte[0];\n\t}\n\treturn Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 41.31793701852844}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\tfor (Header header : record.headers()) {\n\t\tthis.headers.add(header.key(), header.value());\n\t}\n\tthis.data = record.value();\n}", "CodeBleu_score": 49.32542515006202}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.msgId = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\tfor (Header header : record.headers()) {\n\t\tthis.headers.put(header.key(), header.value());\n\t}\n\tthis.data = record.value();\n}", "CodeBleu_score": 46.999120792316404}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t\tthis.key = UUID.fromString(record.key());\n\tthis.headers = new TbQueueMsgHeaders();\n\tfor (Header header : record.headers()) {\n\t\tthis.headers.put(header.key(), header.value());\n\t}\n\tthis.data = record.value();\n}", "CodeBleu_score": 49.65456860893265}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>(kafkaTemplate);\n\tproducer.setTopic(transportNotificationsTopic);\n\treturn producer;\n}", "CodeBleu_score": 23.796425030693808}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>();\n\tproducer.setTemplate(kafkaTemplate);\n\tproducer.setClientId(serviceId);\n\tproducer.setDefaultTopic(transportNotificationSettings.getTopic());\n\tproducer.setAdmin(admin);\n\treturn producer;\n}", "CodeBleu_score": 32.5726015553195}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> producer = new TbQueueProducer<>();\n\tproducer.setTemplate(createProducerTemplate(\n\t\t\ttransportNotificationsSettings.getKafkaSettings(),\n\t\t\tserviceId,\n\t\t\ttransportNotificationsSettings.getKafkaSettings().getTopicName()));\n\tproducer.setAdmin(createAdminTemplate(transportNotificationsSettings.getKafkaSettings()));\n\treturn producer;\n}", "CodeBleu_score": 32.26157852965432}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn TbKafkaConsumerTemplate.<TbProtoQueueMsg<ToCoreNotificationMsg>>builder()\n\t\t\t.topic(toCoreNotificationsTopic)\n\t\t\t.clientId(toCoreNotificationsClientId)\n\t\t\t.groupId(toCoreNotificationsGroupId)\n\t\t\t.decoder(new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.class))\n\t\t\t.admin(kafkaAdmin)\n\t\t\t.statisticsService(statisticsService)\n\t\t\t.build();\n}", "CodeBleu_score": 12.624227691260955}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\treturn createTbQueueConsumer(kafkaConsumerTemplate, toCoreNotificationsMsgTopic, toCoreNotificationsMsgClientId, toCoreNotificationsMsgGroupId,\n\t\t\t(message) -> TbProtoQueueMsg.parseFrom(message, ToCoreNotificationMsg.class),\n\t\t\tadmin, statisticsService);\n}", "CodeBleu_score": 9.41364550300135}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t\tTbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> template = new TbKafkaConsumerTemplate<>(\n\t\t\tkafkaTemplate,\n\t\t\tTbProtoQueueMsg.class,\n\t\t\tToCoreNotificationMsg.class,\n\t\t\tToCoreNotificationMsg.parser(),\n\t\t\tkafkaConsumerProperties.getToCoreNotificationsTopic(),\n\t\t\tkafkaConsumerProperties.getToCoreNotificationsClientId(),\n\t\t\tkafkaConsumerProperties.getToCoreNotificationsGroupId());\n\n\ttemplate.setAdmin(admin);\n\ttemplate.setStatisticsService(statisticsService);\n\n\treturn template;\n}", "CodeBleu_score": 30.412444465862155}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlogger.info(\"Unsubscribing consumer from all topics\");\n\t\tconsumer.unsubscribe();\n\t} else {\n\t\t// Ensure each topic exists by creating it if necessary\n\t\tfor (String topicName : topicNames) {\n\t\t\tlogger.info(\"Ensuring topic exists: {}\", topicName);\n\t\t\tadminClient.createTopics(Collections.singleton(new NewTopic(topicName, 1, (short) 1)));\n\t\t}\n\t\t// Subscribe to the list of topics\n\t\tlogger.info(\"Subscribing consumer to topics: {}\", topicNames);\n\t\tconsumer.subscribe(topicNames);\n\t}\n}", "CodeBleu_score": 52.19748897081331}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames.isEmpty()) {\n\t\tlog.info(\"Unsubscribing from all topics\");\n\t\tconsumer.unsubscribe();\n\t} else {\n\t\tList<String> topics = new ArrayList<>();\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!topicExists(topicName)) {\n\t\t\t\tlog.info(\"Creating topic {}\", topicName);\n\t\t\t\tcreateTopic(topicName);\n\t\t\t}\n\t\t\ttopics.add(topicName);\n\t\t}\n\t\tlog.info(\"Subscribing to topics {}\", topics);\n\t\tconsumer.subscribe(topics);\n\t}\n}", "CodeBleu_score": 52.03780571092642}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t\tif (topicNames!= null && topicNames.size() > 0) {\n\t\tfor (String topicName : topicNames) {\n\t\t\tif (!this.kafkaAdminClient.listTopics().names().get().contains(topicName)) {\n\t\t\t\tthis.kafkaAdminClient.createTopics(Collections.singletonList(new NewTopic(topicName, 1, (short) 1)));\n\t\t\t}\n\t\t}\n\t\tthis.consumer.subscribe(topicNames);\n\t}\n\telse {\n\t\tthis.logger.info(\"No topics provided, so subscribing to all topics\");\n\t\tthis.consumer.subscribe(Pattern.compile(\".*\"));\n\t}\n}", "CodeBleu_score": 45.640378922770154}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tStopwatch stopwatch = Stopwatch.createStarted();\n\tlogger.info(\"Polling topic {} for {}ms\", topic, durationInMillis);\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis).records(topic);\n\tstopwatch.stop();\n\tif (records.isEmpty()) {\n\t\tlogger.debug(\"No records found in topic {} for {}ms\", topic, durationInMillis);\n\t}\n\telse {\n\t\tlogger.info(\"Found {} records in topic {} for {}ms\", records.size(), topic, durationInMillis);\n\t}\n\treturn records;\n}", "CodeBleu_score": 44.674499427140034}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\t// Start the stopwatch\n\tlong startTime = System.currentTimeMillis();\n\t// Log the topic and duration\n\tlog.info(\"Polling topic {} for {} milliseconds\", topic, durationInMillis);\n\t// Poll the consumer for records\n\tList<ConsumerRecord<String, byte[]>> records = consumer.poll(durationInMillis).records(topic);\n\t// Stop the stopwatch\n\tlong endTime = System.currentTimeMillis();\n\tlong totalTime = endTime - startTime;\n\t// Log the total time taken\n\tlog.info(\"Total time taken to poll topic {}: {} milliseconds\", topic, totalTime);\n\t// If no records are found, return an empty list\n\tif (records.isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\t// Collect the records into a list and return them\n\treturn records.stream().collect(Collectors.toList());\n}", "CodeBleu_score": 46.4438779049389}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t\tlong startTime = System.currentTimeMillis();\n\tlogger.info(\"Polling topic {} for {} ms\", topic, durationInMillis);\n\tList<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n\tconsumer.poll(durationInMillis, TimeUnit.MILLISECONDS).forEach(records::add);\n\tlogger.info(\"Total time taken to poll records: {} ms\", System.currentTimeMillis() - startTime);\n\tif (records.isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\treturn records;\n}", "CodeBleu_score": 41.73733887623147}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tString topic = topicPattern.apply(msg);\n\tString key = keyPattern.apply(msg);\n\tif (topic == null || key == null) {\n\t\tlog.debug(\"[{}] Failed to apply topic or key pattern\", ctx.getSelfId());\n\t\tctx.notifyError(new IllegalStateException(\"Failed to apply topic or key pattern\"));\n\t\treturn;\n\t}\n\ttry {\n\t\tctx.getExecutorService().execute(() -> publish(ctx, msg, topic, key));\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.notifyError(e);\n\t}\n}", "CodeBleu_score": 28.01806540503598}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (initialized.get()) {\n\t\tString topic = topicPattern.get();\n\t\tString key = keyPattern.get();\n\t\tif (topic == null || key == null) {\n\t\t\tlog.error(\"[{}] Failed to initialize rule node. Topic and key patterns are not set.\", ctx.getSelfId());\n\t\t\tctx.notifyError(new RuntimeException(\"Topic and key patterns are not set.\"));\n\t\t\treturn;\n\t\t}\n\t\ttopic = topic.replace(TOPIC_KEY_PLACEHOLDER, msg.getMetaData().get(TOPIC_KEY_PLACEHOLDER));\n\t\tkey = key.replace(KEY_PLACEHOLDER, msg.getMetaData().get(KEY_PLACEHOLDER));\n\t\tif (topic == null || key == null) {\n\t\t\tlog.error(\"[{}] Failed to initialize rule node. Topic and key patterns are not set.\", ctx.getSelfId());\n\t\t\tctx.notifyError(new RuntimeException(\"Topic and key patterns are not set.\"));\n\t\t\treturn;\n\t\t}\n\t\ttry {\n\t\t\tpublish(ctx, msg, topic, key);\n\t\t} catch (Exception e) {\n\t\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\t}\n\t} else {\n\t\tlog.error(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n\t\tctx.notifyError(new RuntimeException(\"Rule node is not initialized.\"));\n\t}\n}", "CodeBleu_score": 37.04798474966625}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t\tif (!initialized) {\n\t\tlog.warn(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg);\n\t\tctx.notifyError(msg, new RuntimeException(\"Not initialized\"));\n\t\treturn;\n\t}\n\ttry {\n\t\tString topic = topicPattern.apply(msg);\n\t\tString key = keyPattern.apply(msg);\n\t\tpublish(ctx, msg, topic, key);\n\t} catch (Exception e) {\n\t\tlog.debug(\"[{}] Failed to process message: {}\", ctx.getSelfId(), msg, e);\n\t\tctx.notifyError(msg, e);\n\t}\n}", "CodeBleu_score": 27.264947464679878}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t", "CodeBleu_score": 5.441118430176013}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t\tif (topic == null || topic.isEmpty()) {\n\t\ttellFailure(ctx, \"Topic is null or empty\", new IllegalArgumentException(\"Topic is null or empty\"));\n\t\treturn;\n\t}\n\tif (key == null || key.isEmpty()) {\n\t\ttellFailure(ctx, \"Key is null or empty\", new IllegalArgumentException(\"Key is null or empty\"));\n\t\treturn;\n\t}\n\tif (msg == null) {\n\t\ttellFailure(ctx, \"Message is null\", new IllegalArgumentException(\"Message is null\"));\n\t\treturn;\n\t}\n\tif (msg.getMetadata() == null) {\n\t\ttellFailure(ctx, \"Message metadata is null\", new IllegalArgumentException(\"Message metadata is null\"));\n\t\treturn;\n\t}\n\tif (msg.getMetadata().get(METADATA_KEY_ADD_HEADERS) == null) {\n\t\ttellFailure(ctx, \"Message metadata does not contain key '\" + METADATA_KEY_ADD_HEADERS + \"'\", new IllegalArgumentException(\"Message metadata does not contain key '\" + METADATA_KEY_ADD_HEADERS + \"'\"));\n\t\treturn;\n\t}\n\tif (msg.getMetadata().get(METADATA_KEY_ADD_HEADERS).equals(\"true\")) {\n\t\tMap<String, String> headers = new HashMap<>();\n\t\tfor (Map.Entry<String, String> entry : msg.getMetadata().entrySet()) {\n\t\t\theaders.put(entry.getKey(), entry.getValue());\n\t\t}\n\t\tProducerRecord<String, String> record = new ProducerRecord<>(topic, key, msg.getData(), headers);\n\t\tproducer.send(record, (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n\t} else {\n\t\tProducerRecord<String, String> record = new ProducerRecord<>(topic, key, msg.getData());\n\t\tproducer.send(record, (metadata, exception) -> processRecord(ctx, msg, metadata, exception));\n\t}\n}", "CodeBleu_score": 40.953909040359605}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\tif (ctx.getDebugLevel() >= 1) {\n    ctx.logDebug(ctx.getMsgId(), \"Publishing message to topic: \" + topic);\n}\n\nif (addMetadata) {\n    if (ctx.getDebugLevel() >= 1) {\n        ctx.logDebug(ctx.getMsgId(), \"Adding metadata to message headers\");\n    }\n\n    Map<String, String> metadata = msg.getMetadata();\n    RecordMetadata recordMetadata = new RecordMetadata(new TopicPartition(topic, 0), 0, 0, 0, 0, 0, 0);\n    recordMetadata.setMetadata(metadata);\n    processRecord(ctx, msg, recordMetadata, null);\n} else {\n    if (ctx.getDebugLevel() >= 1) {\n        ctx.logDebug(ctx.getMsgId(), \"Sending message directly to topic: \" + topic);\n    }\n\n    producer.send(new ProducerRecord<String, String>(topic, key, msg.getPayload()), (metadata, e) -> processRecord(ctx, msg, metadata, e));\n}\n}", "CodeBleu_score": 44.089823220877236}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t\ttry {\n\t\tif (producer!= null) {\n\t\t\tproducer.close();\n\t\t}\n\t} catch (Exception e) {\n\t\tlogger.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 41.92371227788245}, {"code": "public void destroy(){\n\t\tif (producer!= null) {\n\t\ttry {\n\t\t\tproducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close Kafka producer: \" + e.getMessage());\n\t\t}\n\t}\n}", "CodeBleu_score": 43.557489643653824}, {"code": "public void destroy(){\n\t\tif (this.kafkaProducer!= null) {\n\t\ttry {\n\t\t\tthis.kafkaProducer.close();\n\t\t} catch (Exception e) {\n\t\t\tlogger.error(\"Failed to close Kafka producer.\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 72.95613493157946}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tString clientId = serviceInfoProvider.getServiceId();\n\treturn new TbQueueProducer<>(\n\t\t\tkafkaTemplateBuilder\n\t\t\t\t\t.clientId(clientId)\n\t\t\t\t\t.defaultTopic(TbQueueNames.TB_RULE_ENGINE_TOPIC)\n\t\t\t\t\t.admin(admin)\n\t\t\t\t\t.build(),\n\t\t\tToRuleEngineMsg.class);\n}", "CodeBleu_score": 33.87561853251192}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\treturn createProducer(KafkaProducerTemplateBuilder::ruleEngineMsgProducer,\n\t\t\tKafkaProducerTemplateBuilder::ruleEngineMsgAdmin);\n}", "CodeBleu_score": 7.74249125259879}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t\tTbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> producer = new TbQueueProducer<>();\n\tTbProtoQueueMsgProducerBuilder<ToRuleEngineMsg> builder = new TbProtoQueueMsgProducerBuilder<>(\n\t\t\tkafkaTemplate,\n\t\t\tkafkaTemplate.getProducerFactory(),\n\t\t\tkafkaTemplate.getAdmin(),\n\t\t\tkafkaTemplate.getKafkaAdmin(),\n\t\t\tserviceInfoProvider.getServiceId(),\n\t\t\tkafkaTemplate.getDefaultTopic(),\n\t\t\tkafkaTemplate.getProducerFactory().getConfigurationProperties(),\n\t\t\tkafkaTemplate.getAdmin().getConfigurationProperties());\n\tproducer.setBuilder(builder);\n\treturn producer;\n}", "CodeBleu_score": 34.07416299568886}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\tthe timeout duration based on the Kafka response timeout configuration\n        Duration timeout = Duration.ofMillis(kafkaProperties.getConsumer().getPollTimeout());\n// Schedule a task with a fixed delay\n        scheduler.scheduleAtFixedRate(() -> {\n            if (isStatsPrintRequired()) {\n                for (String groupId : consumerGroups) {\n                    try {\n                        Map<TopicPartition, OffsetAndMetadata> groupOffsets = kafkaAdminService.getConsumerGroupOffsets(groupId);\n                        Map<TopicPartition, Long> endOffsets = kafkaAdminService.getEndOffsets(groupOffsets.keySet());\n                        List<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n                        if (!consumerGroupStats.isEmpty()) {\n                            log.info(\"Kafka consumer group [{}] has lagging topics: {}\", groupId, consumerGroupStats);\n                        }\n                    } catch (Exception e) {\n                        log.warn(\"Failed to get consumer group offsets for group [{}]. Error: {}\", groupId, e.getMessage(), e);\n                    }\n                }\n            }\n        }, timeout.toMillis(), timeout.toMillis(), TimeUnit.MILLISECONDS);\n    }", "CodeBleu_score": 40.54361389482918}, {"code": "private void startLogScheduling(){\n\timeout = kafkaProperties.getConsumer().getPollTimeoutMs();\n\tif (timeout < 0) {\n\t\ttimeout = 10000L;\n\t}\n\tscheduler.scheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tif (isStatsPrintRequired()) {\n\t\t\t\ttry {\n\t\t\t\t\tfor (String consumerGroupId : consumerGroupIds) {\n\t\t\t\t\t\tMap<TopicPartition, OffsetAndMetadata> groupOffsets = kafkaConsumer.committed(Collections.singleton(new TopicPartition(consumerGroupId, 0)));\n\t\t\t\t\t\tMap<TopicPartition, Long> endOffsets = kafkaConsumer.endOffsets(groupOffsets.keySet());\n\t\t\t\t\t\tList<GroupTopicStats> consumerGroupStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\n\t\t\t\t\t\tif (!consumerGroupStats.isEmpty()) {\n\t\t\t\t\t\t\tlog.info(\"Consumer group [{}] has lagging topics: {}\", consumerGroupId, consumerGroupStats);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\t\t\t\t} catch (Exception e) {\n\t\t\t\t\tlog.warn(\"Failed to get consumer group stats for group [{}]. Error: {}\", consumerGroupId, e.getMessage(), e);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}, timeout, timeout, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 30.49588142434691}, {"code": "private void startLogScheduling(){\n\ttatsPrintRequired()) {\nlong timeout = kafkaProperties.getResponseTimeout() * 1000;\nscheduler.scheduleAtFixedRate(() -> {\ntry {\nMap<String, List<GroupTopicStats>> consumerGroupStats = new HashMap<>();\nList<String> consumerGroups = getConsumerGroups();\nfor (String consumerGroup : consumerGroups) {\nMap<TopicPartition, OffsetAndMetadata> groupOffsets = getGroupOffsets(consumerGroup);\nMap<TopicPartition, Long> endOffsets = getEndOffsets(groupOffsets.keySet());\nList<GroupTopicStats> groupTopicStats = getTopicsStatsWithLag(groupOffsets, endOffsets);\nif (!groupTopicStats.isEmpty()) {\nconsumerGroupStats.put(consumerGroup, groupTopicStats);\n}\n}\nif (!consumerGroupStats.isEmpty()) {\nlog.info(\"Kafka consumer groups with lag: {}\", consumerGroupStats);\n}\n} catch (Exception e) {\nlog.warn(\"Failed to get Kafka consumer group stats for group: {}\", e.getMessage(), e);\n}\n}, 0, timeout, TimeUnit.MILLISECONDS);\n}\n}", "CodeBleu_score": 29.70660676197537}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);\nreturn props;\n}", "CodeBleu_score": 77.68914593362697}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\n\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRY_BACKOFF_MS_CONFIG, retryBackoffMs);\n\nreturn props;\n}", "CodeBleu_score": 77.68914593362697}, {"code": "protected Properties toAdminProps(){\n\troperties props = toProps();\nprops.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\nprops.put(AdminClientConfig.RETRIES_CONFIG, retries);\nreturn props;\n}", "CodeBleu_score": 85.16384628277109}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(scopedName, tags, metric);\n\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, (Counter) metric);\n\t\tcounterEvents.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, (Gauge) metric);\n\t\tgaugeEvents.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, (Histogram) metric);\n\t\thistogramEvents.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, (Meter) metric);\n\t\tmeterEvents.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: {}\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 47.516789380740015}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tif (metric == null) {\n\t\tthrow new IllegalArgumentException(\"metric must not be null\");\n\t}\n\n\tif (metricName == null) {\n\t\tthrow new IllegalArgumentException(\"metricName must not be null\");\n\t}\n\n\tif (group == null) {\n\t\tthrow new IllegalArgumentException(\"group must not be null\");\n\t}\n\n\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\n\tMetricEvent event = new MetricEvent(metric, scopedName, tags);\n\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Unknown metric type: {}\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 45.47521879513556}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t\tString scopedName = getScopedName(metricName, group);\n\tMap<String, String> tags = getTags(group);\n\tMetricEvent event = new MetricEvent(scopedName, tags);\n\tif (metric instanceof Counter) {\n\t\tcounters.put(scopedName, event);\n\t} else if (metric instanceof Gauge) {\n\t\tgauges.put(scopedName, event);\n\t} else if (metric instanceof Histogram) {\n\t\thistograms.put(scopedName, event);\n\t} else if (metric instanceof Meter) {\n\t\tmeters.put(scopedName, event);\n\t} else {\n\t\tLOG.warn(\"Metric type not supported: {}\", metric.getClass().getName());\n\t}\n}", "CodeBleu_score": 45.831273578376944}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields()!= null) {\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tmetricEvent.addField(field, (Number) gauge.getValue());\n\t\t} else {\n\t\t\tmetricEvent.addField(field, gauge.getValue().toString());\n\t\t}\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tfields.put(field, (Number) gauge.getValue());\n\t\t} else {\n\t\t\tfields.put(field, gauge.getValue().toString());\n\t\t}\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 49.30181915864585}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields()!= null) {\n\t\tmetricEvent.getFields().put(field, gauge.getValue());\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tfields.put(field, gauge.getValue());\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 32.910419204235524}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t\tif (metricEvent.getFields()!= null) {\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tmetricEvent.getFields().put(field, (Number) gauge.getValue());\n\t\t} else {\n\t\t\tmetricEvent.getFields().put(field, String.valueOf(gauge.getValue()));\n\t\t}\n\t} else {\n\t\tMap<String, Object> fields = new HashMap<>();\n\t\tif (gauge.getValue() instanceof Number) {\n\t\t\tfields.put(field, (Number) gauge.getValue());\n\t\t} else {\n\t\t\tfields.put(field, String.valueOf(gauge.getValue()));\n\t\t}\n\t\tmetricEvent.setFields(fields);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 48.28957627006453}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString[] offsets = gauge.getValue().toString().split(\",\");\n\tString topic = offsets[0];\n\tString partition = offsets[1];\n\tString currentOffset = offsets[2];\n\tString dataTimestamp = offsets[3];\n\tString committedOffset = offsets[4];\n\tString kafkaLagKey = topic + partition;\n\tLong kafkaLagTime = Long.parseLong(currentOffset) - Long.parseLong(committedOffset);\n\tif (kafkaLagTime!= kafkaLagTimes.getOrDefault(kafkaLagKey, 0L)) {\n\t\tkafkaLagTimes.put(kafkaLagKey, kafkaLagTime);\n\t\tmetricEvent.setTimestamp(timestamp);\n\t\tmetricEvent.addField(\"kafkaLagTime\", kafkaLagTime);\n\t\tmetricEvent.addField(\"currentOffset\", currentOffset);\n\t\tmetricEvent.addField(\"dataTimestamp\", dataTimestamp);\n\t\tmetricEvent.addField(\"committedOffset\", committedOffset);\n\t}\n\treturn metricEvent;\n}", "CodeBleu_score": 34.63285818828502}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Extract the lag metrics from the gauge\n\tMap<String, Object> lagMetrics = (Map<String, Object>) gauge.getValue();\n\t// Split the lag metrics into components\n\tMap<String, Object> currentOffsets = (Map<String, Object>) lagMetrics.get(\"current-offsets\");\n\tMap<String, Object> committedOffsets = (Map<String, Object>) lagMetrics.get(\"committed-offsets\");\n\tMap<String, Object> dataTimestamps = (Map<String, Object>) lagMetrics.get(\"data-timestamps\");\n\n\t// Check for changes in the Kafka lag metrics\n\tString lagMetricKey = currentOffsets.toString() + committedOffsets.toString() + dataTimestamps.toString();\n\tif (kafkaLagTimes.containsKey(lagMetricKey)) {\n\t\t// If the lag metrics have not changed, skip the update\n\t\treturn metricEvent;\n\t}\n\n\t// Update the kafkaLagTimes map with the current lag metrics\n\tkafkaLagTimes.put(lagMetricKey, timestamp);\n\n\t// Update the metric event's fields with the current offsets, data timestamp, and committed offsets\n\tmetricEvent.setFields(currentOffsets);\n\tmetricEvent.setFields(dataTimestamps);\n\tmetricEvent.setFields(committedOffsets);\n\n\t// Set the event's timestamp to the current time\n\tmetricEvent.setTimestamp(timestamp);\n\n\treturn metricEvent;\n}", "CodeBleu_score": 34.524674559277756}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\t// Split the gauge name into components\n\tString[] gaugeNameComponents = gauge.getName().split(\"\\\\.\");\n\tString topic = gaugeNameComponents[1];\n\tString partition = gaugeNameComponents[2];\n\tString group = gaugeNameComponents[3];\n\n\t// Get the current offset and committed offset from the gauge\n\tdouble currentOffset = (double) gauge.getValue();\n\tdouble committedOffset = (double) gauge.getPreviousValue();\n\n\t// Check for changes in the Kafka lag metrics to avoid duplicates\n\tString key = topic + \"-\" + partition + \"-\" + group;\n\tlong previousTimestamp = kafkaLagTimes.getOrDefault(key, 0L);\n\tif (previousTimestamp == timestamp) {\n\t\treturn metricEvent;\n\t}\n\tkafkaLagTimes.put(key, timestamp);\n\n\t// Set the event's timestamp\n\tmetricEvent.setTimestamp(timestamp);\n\n\t// Update the metric event's fields with current offsets, data timestamp, and committed offsets\n\tmetricEvent.setMetricValue(currentOffset);\n\tmetricEvent.setMetricValue2(committedOffset);\n\tmetricEvent.setMetricValue3(timestamp);\n\n\treturn metricEvent;\n}", "CodeBleu_score": 32.85532923154015}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\tProperties props = buildKafkaProps(parameterTool);\n\tprops.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"earliest\");\n\tprops.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);\n\tprops.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName());\n\tprops.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, JsonDeserializer.class.getName());\n\tprops.put(JsonDeserializer.TRUSTED_PACKAGES, \"com.github.sdvillal.flink.domain\");\n\tprops.put(JsonDeserializer.VALUE_DEFAULT_TYPE, MetricEvent.class.getName());\n\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, \"query_time_\" + time);\n\tprops.put(ConsumerConfig.MAX_POLL_RECORDS_CONFIG, 1000);\n\tprops.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, 30000);\n\tprops.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 30000);\n\tprops.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 10000);\n\tprops.put(ConsumerConfig.AUTO_COMMIT_INTERVAL_MS_CONFIG, 10000);\n\tprops.put(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);\n\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new JsonDeserializationSchema(false), props);\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n\t\tconsumer.setStartFromSpecificOffsets(partitionOffset);\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 66.24760340579007}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n\tProperties props = buildKafkaProps(parameterTool);\n\tSchema<MetricEvent> schema = MetricEvent.getSchema();\n\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, schema, props);\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n\t\tconsumer.setStartFromSpecificOffsets(partitionOffset);\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 75.83469671352827}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\tParameterTool parameterTool = ParameterTool.fromSystemProperties();\n\tProperties props = buildKafkaProps(parameterTool);\n\tprops.setProperty(\"group.id\", \"query_time_\" + time);\n\tFlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<MetricEvent>(topic, new MetricEventDeserializationSchema(), props);\n\tif (time!= null) {\n\t\tMap<KafkaTopicPartition, Long> partitionOffset = buildOffsetByTime(props, parameterTool, time);\n\t\tconsumer.setStartFromSpecificOffsets(partitionOffset);\n\t}\n\treturn env.addSource(consumer);\n}", "CodeBleu_score": 65.38997420992028}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.setProperty(\"group.id\", \"time-based-\" + time)\n\tKafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)\n\tTopicPartitionInfo[] partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\")).toArray()\n\tMap<TopicPartition, Long> partitionTimestamps = new HashMap<>()\n\tfor (TopicPartitionInfo partitionInfo : partitions) {\n\t\tpartitionTimestamps.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time)\n\t}\n\tMap<KafkaTopicPartition, Long> partitionOffsets = consumer.offsetsForTimes(partitionTimestamps)\n\tconsumer.close()\n\treturn partitionOffsets\n}", "CodeBleu_score": 44.724244496262976}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tprops.put(\"group.id\", time.toString());\n\tKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n\tTopicPartitionInformation topicPartitionInformation = getTopicPartitionInformation(parameterTool.getRequired(\"topic\"));\n\tMap<Integer, Long> partitionTimestamps = topicPartitionInformation.getPartitions().stream()\n\t\t.collect(Collectors.toMap(TopicPartition::partition, p -> time));\n\tMap<TopicPartition, Long> offsets = consumer.offsetsForTimes(partitionTimestamps);\n\tconsumer.close();\n\treturn offsets.entrySet().stream()\n\t\t.collect(Collectors.toMap(entry -> new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), Map.Entry::getValue));\n}", "CodeBleu_score": 39.00728498029808}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\tString groupId = \"time-\" + time;\n\tprops.put(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n\tKafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n\tTopicPartitionInfo[] partitions = consumer.partitionsFor(parameterTool.getRequired(\"topic\")).toArray(new TopicPartitionInfo[0]);\n\tMap<TopicPartition, Long> timestampsToSearch = new HashMap<>();\n\tfor (TopicPartitionInfo partition : partitions) {\n\t\ttimestampsToSearch.put(new TopicPartition(partition.topic(), partition.partition()), time);\n\t}\n\tMap<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampsToSearch);\n\tconsumer.close();\n\treturn offsets.entrySet().stream().collect(Collectors.toMap(entry -> new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()), Map.Entry::getValue, (o1, o2) -> o1, LinkedHashMap::new));\n}", "CodeBleu_score": 49.52208024436528}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\n\tMetricEvent metricEvent = new MetricEvent();\n\tmetricEvent.setTimestamp(System.currentTimeMillis());\n\tmetricEvent.setName(\"test-event\");\n\tmetricEvent.addTag(\"host\", \"test-host\");\n\tmetricEvent.addTag(\"region\", \"us-east-1\");\n\tmetricEvent.addField(\"value\", 100.0);\n\tmetricEvent.addField(\"value2\", 200.0);\n\n\tProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test-topic\", metricEvent.serialize());\n\tproducer.send(record);\n\tSystem.out.println(\"Sent data: \" + metricEvent.serialize());\n\tproducer.flush();\n}", "CodeBleu_score": 54.6689706241402}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"cpu\");\n\tevent.getTags().put(\"host\", \"server1\");\n\tevent.getTags().put(\"region\", \"us-east-1\");\n\tevent.getFields().put(\"idle\", 90);\n\tevent.getFields().put(\"user\", 5);\n\tevent.getFields().put(\"system\", 5);\n\n\tProducerRecord<String, String> record = new ProducerRecord<String, String>(\"metrics\", event.toString());\n\tproducer.send(record);\n\n\tSystem.out.println(\"Sent data: \" + event);\n\n\tproducer.flush();\n}", "CodeBleu_score": 53.69541069310835}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t\tProperties props = new Properties();\n\tprops.put(\"bootstrap.servers\", \"localhost:9092\");\n\tprops.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tprops.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\tKafkaProducer<String, String> producer = new KafkaProducer<String, String>(props);\n\tMetricEvent event = new MetricEvent();\n\tevent.setTimestamp(System.currentTimeMillis());\n\tevent.setName(\"test\");\n\tevent.setTags(new HashMap<>());\n\tevent.getTags().put(\"tag1\", \"value1\");\n\tevent.setFields(new HashMap<>());\n\tevent.getFields().put(\"field1\", 100.0);\n\tProducerRecord<String, String> record = new ProducerRecord<String, String>(\"test\", event.toString());\n\tproducer.send(record);\n\tSystem.out.println(\"Sent data: \" + event);\n\tproducer.flush();\n\tproducer.close();\n}", "CodeBleu_score": 53.984899618793726}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tevent.getLevel().isAtLeastAsImportantAs(level) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<String, String>(topic, subAppend(event)));\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Error appending log event\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 37.252277394188674}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tevent.getLevel().isMoreSpecificThan(level) &&!event.getLoggerName().contains(\"xxx\")) {\n\t\ttry {\n\t\t\tproducer.send(new ProducerRecord<>(topic, subAppend(event)));\n\t\t} catch (Exception e) {\n\t\t\tlog.warn(\"Error sending log event to Kafka topic\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 39.43870399370579}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\tvent.getLevel().isMoreSpecificThan(Level.INFO) &&!event.getLoggerName().contains(\"xxx\")) {\ntry {\nString logEvent = subAppend(event);\nif (logEvent!= null) {\nproducer.send(new ProducerRecord<>(topic, logEvent));\n}\n} catch (Exception e) {\nlog.warn(\"Error appending log event: {}\", event, e);\n}\n}\n}", "CodeBleu_score": 43.93151798341109}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range ValidTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 92.41207029386057}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\ttag, ok := metric.GetTag(k.RoutingTag)\n\t\tif ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewString(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 59.37927470788106}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif tag, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn tag, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewString(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.65431082253627}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag!= \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewString(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.821152249922854}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, r := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(r)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %s\", r, err)\n\t\t}\n\t\tk.regexps[i] = re\n\t}\n\treturn nil\n}", "CodeBleu_score": 61.649439467720036}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\n\tfor i, re := range k.TopicRegexps {\n\t\tif k.regexps[i], _ = regexp.Compile(re); k.regexps[i] == nil {\n\t\t\treturn fmt.Errorf(\"Failed to compile topic regexp %s\", re)\n\t\t}\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 51.09618725924747}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, re := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(re)\n\t\tif err!= nil {\n\t\t\treturn fmt.Errorf(\"invalid topic regexp: %s: %v\", re, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 56.24842963706762}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.Lock()\n\tdefer h.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryTag]\n\tif!ok {\n\t\treturn\n\t}\n\n\tif msg.MarkDelivered() {\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\tdelete(h.undelivered, track.DeliveryTag)\n\th.sem <- 1\n}", "CodeBleu_score": 46.59820771733298}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryTag]\n\tif!ok {\n\t\treturn\n\t}\n\n\tif msg.MarkDelivered() {\n\t\th.session.MarkMessage(msg, \"\")\n\t}\n\n\tdelete(h.undelivered, track.DeliveryTag)\n\th.delivery.Release(1)\n}", "CodeBleu_score": 48.92468410546893}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryTag]\n\tif!ok {\n\t\treturn\n\t}\n\n\tmsg.MarkDelivered(h.session)\n\tdelete(h.undelivered, track.DeliveryTag)\n\th.sem.Release(1)\n}", "CodeBleu_score": 48.503559104402484}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\t// Obtain the session context.\n\tctx := session.Context()\n\n\t// Enter a loop to reserve processing capacity.\n\tfor {\n\t\t// Reserve processing capacity.\n\t\tif err := session.Reserve(ctx, 1); err!= nil {\n\t\t\treturn err\n\t\t}\n\n\t\t// If the context is done or the claim is closed, exit the loop.\n\t\tif ctx.Done() || claim.Done() {\n\t\t\tbreak\n\t\t}\n\n\t\t// Wait for a message from the claim.\n\t\tmsg := <-claim.Messages()\n\n\t\t// Handle the message.\n\t\tif err := h.HandleMessage(ctx, msg); err!= nil {\n\t\t\th.logger.Error(err, \"failed to handle message\", \"topic\", msg.Topic, \"partition\", msg.Partition, \"offset\", msg.Offset)\n\t\t}\n\n\t\t// Mark the message as processed.\n\t\tsession.MarkMessage(msg, \"\")\n\t}\n\n\treturn nil\n}", "CodeBleu_score": 53.471385885510415}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\t// NOTE:\n\t// Do not move the code below to a goroutine.\n\t// The `ConsumeClaim` itself is called within a goroutine, see:\n\t// https://github.com/Shopify/sarama/blob/master/consumer_group.go#L27-L29\n\n\tctx := context.Background()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif!ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.logger.Debug(\"Received message\", \"topic\", msg.Topic, \"partition\", msg.Partition, \"offset\", msg.Offset)\n\t\t\tif err := h.handleMessage(ctx, msg); err!= nil {\n\t\t\t\th.logger.Error(err, \"Failed to handle message\", \"topic\", msg.Topic, \"partition\", msg.Partition, \"offset\", msg.Offset)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 58.09568483948356}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := context.Background()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase <-claim.Messages():\n\t\t\terr := h.handleMessage(session, claim)\n\t\t\tif err!= nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 39.44561040020452}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id!= null && logkafka_id.trim.length > 0, IllegalLogkafkaId)\ncheckCondition(logkafka_id!= \".\", IllegalLogkafkaId)\ncheckCondition(logkafka_id!= \"..\", IllegalLogkafkaId)\ncheckCondition(logkafka_id.length <= 128, IllegalLogkafkaId)\ncheckCondition(logkafka_id.matches(\"[a-zA-Z0-9._-]+\"), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 36.52210171613689}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\tcheckCondition(logkafka_id.nonEmpty, IllegalLogkafkaId(logkafka_id))\ncheckCondition(logkafka_id!= \".\" && logkafka_id!= \"..\", IllegalLogkafkaId(logkafka_id))\ncheckCondition(logkafka_id.length <= 256, IllegalLogkafkaId(logkafka_id))\ncheckCondition(logkafka_id.matches(\"[a-zA-Z0-9-_.]+\"), IllegalCharacterInLogkafkaId(logkafka_id))\n}", "CodeBleu_score": 36.04781999748566}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\tcheckCondition(logkafka_id!= null, IllegalNullLogkafkaId)\n\tcheckCondition(logkafka_id.length > 0, IllegalEmptyLogkafkaId)\n\tcheckCondition(logkafka_id!= \".\", IllegalDotLogkafkaId)\n\tcheckCondition(logkafka_id!= \"..\", IllegalDotDotLogkafkaId)\n\tcheckCondition(logkafka_id.length <= 255, IllegalLengthLogkafkaId)\n\tcheckCondition(logkafka_id.matches(validLogkafkaIdRegex), IllegalCharacterInLogkafkaId)\n}", "CodeBleu_score": 47.61870992715113}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 5.120481927710843}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t//    val kafkaManagerActor = context.actorOf(KafkaManagerActor.props(kafkaManagerActorRef))\n    kafkaManagerActorRef? msg map {\n      case output: Output => fn(output)\n      case ActorErrorResponse(error) => Future.successful(ApiError(error.message).left)\n      case x => Future.successful(ApiError(s\"Unexpected response from Kafka Manager: $x\").left)\n    } recover {\n      case t => Future.successful(ApiError(t.getMessage).left)\n    }\n  }", "CodeBleu_score": 49.65858951720143}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t//    val actor = actorSystem.actorOf(Props(new KafkaManagerActor(kafkaManager)))\n    val actor = actorSystem.actorOf(Props(new KafkaManagerActor(kafkaManager)))\n    val promise = Promise[ApiError \\/ FOutput]()\n    actor! msg\n    actorSystem.scheduler.scheduleOnce(100 milliseconds) {\n      actor! PoisonPill\n    }\n    actorSystem.scheduler.scheduleOnce(100 milliseconds) {\n      promise.tryComplete(actor!? msg match {\n        case output: Output =>\n          fn(output)\n        case ActorErrorResponse(error) =>\n          Future.successful(Left(ApiError(error.message, error.code)))\n        case throwable: Throwable =>\n          Future.successful(Left(ApiError(throwable.getMessage, 500)))\n      })\n    }\n    promise.future\n  }", "CodeBleu_score": 23.04070303681605}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t", "CodeBleu_score": 8.47457627118644}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t", "CodeBleu_score": 8.064516129032258}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val req = KMClusterCommandRequest(clusterName, KMPreferredReplicaLeaderElectionCommand(topics))\n    askActor(req).map(_.disjunction)\n  }", "CodeBleu_score": 19.866277115724184}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t\n/**\n * The runPreferredLeaderElection function initiates a preferred leader election for specified topics in a given cluster.\nIt constructs a KMClusterCommandRequest with the cluster name and topics, then sends it to the Kafka manager actor.\nThe function returns a Future that maps the command result to a disjunction, indicating success or an error.\n */\n    val request = KMClusterCommandRequest(clusterName, PreferredReplicaLeaderElection, topics)\n    askActor(kafkaManagerActor, request).map {\n      case KMCommandResponse(_, clusterContext, _) => clusterContext.right\n      case KMError(error) => error.left\n    }\n  }", "CodeBleu_score": 22.79376449038365}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\ngetTopicList(clusterName).flatMap {\n  case -\\/(error) => Future.successful(-\\/(error))\n  case \\/-(topics) => runPreferredLeaderElection(clusterName, topics.map(_.name).toSet)\n}\n}", "CodeBleu_score": 61.58335099767713}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\ngetTopicList(clusterName).flatMap {\ncase -\\/(error) => Future.successful(-\\/(error))\ncase \\/-(topics) => runPreferredLeaderElection(clusterName, topics.map(_.name).toSet)\n}\n}", "CodeBleu_score": 61.15003283597896}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\timplicit val ec = apiExecutionContext\ngetTopicList(clusterName).flatMap {\n  case -\\/(error) => Future.successful(-\\/(error))\n  case \\/-(topicList) =>\n    runPreferredLeaderElection(clusterName, topicList.topics.map(_.name).toSet)\n}\n}", "CodeBleu_score": 64.14796736631854}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n}", "CodeBleu_score": 5.183114608858888}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t", "CodeBleu_score": 4.691447204482089}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tDescribeClusterResult cluster = admin.describeCluster();\n\tcluster.nodes().get(10, TimeUnit.SECONDS);\n\tif (cluster.nodes().isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka nodes available\");\n\t}\n\tNode node = cluster.nodes().get(0);\n\tDescribeConfigsResult configs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.id())));\n\tconfigs.all().get(10, TimeUnit.SECONDS);\n\tif (configs.all().isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka configurations received\");\n\t}\n\treturn configs.all().get(0).config();\n}", "CodeBleu_score": 43.683111334028624}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\ttry {\n\t\t// Describe the cluster\n\t\tClusterDescription clusterDescription = admin.describeCluster().nodes().get(30, TimeUnit.SECONDS);\n\t\tif (clusterDescription.nodes().isEmpty()) {\n\t\t\tthrow new ConnectException(\"No nodes available\");\n\t\t}\n\t\t// Get the first node's ID\n\t\tNode node = clusterDescription.nodes().get(0);\n\t\tint id = node.id();\n\t\t// Request the node's configuration\n\t\tConfig config = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, id))).all().get().get(id);\n\t\tif (config == null) {\n\t\t\tthrow new ConnectException(\"No configurations received\");\n\t\t}\n\t\treturn config;\n\t} catch (InterruptedException | ExecutionException e) {\n\t\tthrow new ConnectException(e);\n\t}\n}", "CodeBleu_score": 49.085420332548864}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t\tMap<String, List<Node>> nodes = admin.describeCluster().nodes().get(10, TimeUnit.SECONDS);\n\tif (nodes.isEmpty()) {\n\t\tthrow new ConnectException(\"No Kafka broker is available\");\n\t}\n\tNode node = nodes.get(nodes.keySet().iterator().next()).get(0);\n\tMap<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString()))).all().get(10, TimeUnit.SECONDS);\n\tif (configs.isEmpty()) {\n\t\tthrow new ConnectException(\"No configuration received\");\n\t}\n\treturn configs.values().iterator().next();\n}", "CodeBleu_score": 59.93281254382657}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (config, schema, topic) -> {\n\t\tif (config.getSchemaHistory() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n\t\t\treturn validator.validate(config, schema, topic);\n\t\t}\n\t\treturn 0;\n\t};\n}", "CodeBleu_score": 29.359638225272406}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (final Configuration configuration, final ValidationContext context) -> {\n\t\tif (configuration.getSchemaHistory() == SchemaHistory.KAFKA) {\n\t\t\treturn validator.validate(configuration, context);\n\t\t}\n\t\treturn 0;\n\t};\n}", "CodeBleu_score": 23.167308323591413}, {"code": "private static Validator forKafka(final Validator validator){\n\t\treturn (final Configuration configuration) -> {\n\t\tif (configuration.getSchemaHistory() == SchemaHistory.KafkaSchemaHistory) {\n\t\t\treturn validator.validate(configuration);\n\t\t}\n\t\treturn 0;\n\t};\n}", "CodeBleu_score": 21.53105508456241}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t// Get the Kafka Connect version\n\tString kafkaConnectVersion = (String) config.get(VERSION_CONFIG);\n\tVersion connectVersion = parseVersion(kafkaConnectVersion);\n\t// Check if topic creation is enabled\n\tif (connectVersion.compareTo(Version.parse(\"2.5.0\")) >= 0) {\n\t\treturn (Boolean) config.getOrDefault(TOPIC_CREATION_ENABLE_CONFIG, true);\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 33.235498495843515}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tString versionString = (String) config.get(VERSION_CONFIG);\n\tVersion version = parseVersion(versionString);\n\tBoolean topicCreationEnabled = (Boolean) config.get(TOPIC_CREATION_ENABLE_CONFIG);\n\tif (topicCreationEnabled == null) {\n\t\ttopicCreationEnabled = true;\n\t}\n\treturn version.isAtLeast(Version.parse(\"2.2.0\")) && topicCreationEnabled;\n}", "CodeBleu_score": 39.964570553137875}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\tVersion kafkaConnectVersion = parseVersion(KafkaConnect.getVersion());\n\tBoolean topicCreationEnabled = (Boolean) config.getOrDefault(\"topic.creation.enable\", true);\n\treturn kafkaConnectVersion.isAtLeast(1, 0, 0) && topicCreationEnabled;\n}", "CodeBleu_score": 38.96244223102511}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t", "CodeBleu_score": 3.7760788640614407}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\tif (clientId == null) {\n\t\tthrow new ConfigException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\t}\n\tfinal Properties adminProps = new Properties();\n\tadminProps.putAll(config);\n\tadminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId + \"-admin\");\n\tfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\treturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 37.4279208095781}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t\tfinal String clientId = config.get(KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\tif (clientId == null || clientId.isEmpty()) {\n\t\tthrow new IllegalArgumentException(\"Missing mandatory configuration option: \" + KafkaOffsetBackingStoreConfig.CLIENT_ID_CONFIG);\n\t}\n\n\tfinal Properties adminProps = new Properties();\n\tadminProps.putAll(config);\n\tadminProps.put(AdminClientConfig.CLIENT_ID_CONFIG, clientId + \"-admin\");\n\tadminProps.put(AdminClientConfig.REQUEST_TIMEOUT_MS_CONFIG, 10000);\n\n\tfinal SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\treturn new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore());\n}", "CodeBleu_score": 38.9272166293964}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t/ Check if the node is an object\nif (node.isObject()) {\n// Extract the payload field if present\nif (node.has(PAYLOAD_FIELD)) {\nnode = node.get(PAYLOAD_FIELD);\n}\n// Iterate through the field names\nIterator<String> fieldNames = node.fieldNames();\n// If there is only one field name, it's a simple key\nif (fieldNames.hasNext() &&!fieldNames.hasNext()) {\nreturn reader.readValue(node.get(fieldNames.next()));\n}\n// Otherwise, it's a composite key\nelse {\nreturn reader.readValue(node);\n}\n}\n// If it's not an object, it's an error\nelse {\nthrow new IOException(\"Invalid key: \" + node.toString());\n}\n}", "CodeBleu_score": 42.92545224347881}, {"code": "private T readKey(JsonNode node) throws IOException{\n\tf (!node.isObject()) {\nthrow new IllegalArgumentException(\"Key must be an object.\");\n}\n\nJsonNode payload = node.get(PAYLOAD_FIELD);\n\n// Schema + payload format\nif (payload!= null) {\nnode = payload;\n}\n// Debezium envelope\nif (config.asEnvelope()) {\nnode = node.get(Envelope.FieldName.KEY);\n}\n// Extracted format\nelse if (config.sourceField()!= null) {\nnode = node.get(config.sourceField());\n}\n\nif (node.fieldNames().hasNext()) {\n// Simple key\nif (!node.fieldNames().hasNext()) {\nreturn reader.readValue(node);\n}\n// Composite key\nreturn reader.readValue(node);\n}\n\nreturn null;\n}", "CodeBleu_score": 46.42258453274106}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t", "CodeBleu_score": 4.242655504045899}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t//        String topicName = dataCollectionTopicNamer.topicNameFor(id, prefix, delimiter);\n//        StringBuilder sanitizedTopicName = new StringBuilder(topicName.length());\n//        for (int i = 0; i < topicName.length(); i++) {\n//            char c = topicName.charAt(i);\n//            if (isValidTopicNameCharacter(c)) {\n//                sanitizedTopicName.append(c);\n//            } else {\n//                sanitizedTopicName.append(replacementCharacter);\n//                if (i == 0) {\n//                    logger.warn(\"Topic name {} contains an invalid character at index 0. The character will be replaced with '{}'.\", topicName, replacementCharacter);\n//                }\n//            }\n//        }\n//        if (sanitizedTopicName.length()!= topicName.length()) {\n//            logger.warn(\"Topic name {} contains invalid characters. The sanitized name is {}.\", topicName, sanitizedTopicName);\n//            return sanitizedTopicName.toString();\n//        }\n//        return topicName;\n        return dataCollectionTopicNamer.topicNameFor(id, prefix, delimiter);\n    }", "CodeBleu_score": 6.548872249708738}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = topicNameForDelegate(id, prefix, delimiter);\nStringBuilder sanitizedTopicName = new StringBuilder(topicName.length());\nboolean replaced = false;\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isValidTopicNameCharacter(c)) {\nsanitizedTopicName.append(c);\n} else {\nsanitizedTopicName.append(replacementCharacter);\nreplaced = true;\n}\n}\nif (replaced) {\nlogger.warn(\"Topic name '{}' was sanitized to '{}'\", topicName, sanitizedTopicName);\n}\nreturn sanitizedTopicName.toString();\n}", "CodeBleu_score": 54.19908880664155}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\tString topicName = dataCollectionTopicNamer.topicNameFor(id, prefix, delimiter);\nStringBuilder sanitizedTopicName = new StringBuilder();\nboolean replaced = false;\nfor (int i = 0; i < topicName.length(); i++) {\nchar c = topicName.charAt(i);\nif (isValidTopicNameCharacter(c)) {\nsanitizedTopicName.append(c);\n} else {\nsanitizedTopicName.append(replacementCharacter);\nreplaced = true;\n}\n}\nif (replaced) {\nlogger.warn(\"Topic name contains invalid characters, replacing them with '{}': {}\", replacementCharacter, topicName);\nreturn sanitizedTopicName.toString();\n} else {\nreturn topicName;\n}\n}", "CodeBleu_score": 55.597587878459095}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n}", "CodeBleu_score": 10.3990398260886}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t/*\n*\n*/\n        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = null;\n        if (replacedErrorHandler!= null) {\n            this.retries = replacedErrorHandler.getRetries();\n        } else {\n            this.retries = connectorConfig.getMaxRetries();\n        }\n    }", "CodeBleu_score": 61.592909168674566}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\tsuper();\n\tthis.connectorType = connectorType;\n\tthis.connectorConfig = connectorConfig;\n\tthis.queue = queue;\n\tthis.replacedErrorHandler = replacedErrorHandler;\n\tthis.producerThrowable = new AtomicReference<>();\n\tthis.retries = replacedErrorHandler == null? connectorConfig.getMaxRetries() : replacedErrorHandler.getRetries();\n}", "CodeBleu_score": 52.60020818020663}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\tMap<String, ConfigValue> validations = configuration.validate(fields);\nfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\nif (!entry.getValue().errorMessages().isEmpty()) {\nfinal ConfigValue value = entry.getValue();\nthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n}\n}\n}", "CodeBleu_score": 84.79394444051329}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 84.88633127461075}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t\tMap<String, ConfigValue> validations = configuration.validate(fields);\n\tfor (Map.Entry<String, ConfigValue> entry : validations.entrySet()) {\n\t\tif (!entry.getValue().errorMessages().isEmpty()) {\n\t\t\tfinal ConfigValue value = entry.getValue();\n\t\t\tthrow new ConfigException(value.name(), configuration.getString(value.name()), value.errorMessages().get(0));\n\t\t}\n\t}\n}", "CodeBleu_score": 84.88633127461075}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tf (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n}\nelse {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 92.29592307139589}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tf (oldSchema.type().isPrimitive()) {\nreturn oldSchema;\n}\nSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\nfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\nif (isContainedIn(field.name(), nestedFields)) {\nnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n} else {\nnewSchemabuilder.field(field.name(), field.schema());\n}\n}\nLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\nfor (int i = 0; i < headers.size(); i++) {\nHeader currentHeader = headerToProcess.get(headers.get(i));\nOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\nLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\nif (currentFieldName.isPresent() && currentHeader!= null) {\nnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n}\n}\nLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\nreturn newSchemabuilder.build();\n}", "CodeBleu_score": 92.30610134885706}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\tif (oldSchema.type().isPrimitive()) {\n\t\treturn oldSchema;\n\t}\n\tSchemaBuilder newSchemabuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n\tfor (org.apache.kafka.connect.data.Field field : oldSchema.fields()) {\n\t\tif (isContainedIn(field.name(), nestedFields)) {\n\t\t\tnewSchemabuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, ++level));\n\t\t} else {\n\t\t\tnewSchemabuilder.field(field.name(), field.schema());\n\t\t}\n\t}\n\tLOGGER.debug(\"Fields copied from the old schema {}\", newSchemabuilder.fields());\n\tfor (int i = 0; i < headers.size(); i++) {\n\t\tHeader currentHeader = headerToProcess.get(headers.get(i));\n\t\tOptional<String> currentFieldName = getFieldName(fields.get(i), fieldName, level);\n\t\tLOGGER.trace(\"CurrentHeader {} - currentFieldName {}\", headers.get(i), currentFieldName);\n\t\tif (currentFieldName.isPresent() && currentHeader!= null) {\n\t\t\tnewSchemabuilder = newSchemabuilder.field(currentFieldName.get(), currentHeader.schema());\n\t\t}\n\t}\n\tLOGGER.debug(\"Fields added from headers {}\", newSchemabuilder.fields());\n\treturn newSchemabuilder.build();\n}", "CodeBleu_score": 94.08900190869335}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source!= null) {\n\t\tif (source.schema().field(SNAPSHOT_KEY)!= null && source.schema().field(SNAPSHOT_KEY).schema().type() == Schema.Type.ENUM) {\n\t\t\tif (source.schema().field(SNAPSHOT_KEY).schema().name().equals(SNAPSHOT_KEY)) {\n\t\t\t\tif (source.get(SNAPSHOT_KEY)!= null) {\n\t\t\t\t\treturn SnapshotRecord.valueOf(source.get(SNAPSHOT_KEY).toString().toUpperCase());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 42.10787756649578}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source.schema().field(\"SNAPSHOT_KEY\").schema().type() == Schema.Type.ENUM) {\n\t\tif (source.schema().field(\"SNAPSHOT_KEY\").schema().name().equals(\"SnapshotRecord\")) {\n\t\t\tString snapshotString = source.get(\"SNAPSHOT_KEY\").toString().toUpperCase();\n\t\t\treturn SnapshotRecord.valueOf(snapshotString);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 45.08170426627917}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t\tif (source!= null && source.schema().field(\"SNAPSHOT_KEY\")!= null && source.schema().field(\"SNAPSHOT_KEY\").schema().name().equals(\"SnapshotKey\")) {\n\t\tString snapshotString = source.get(\"SNAPSHOT_KEY\").toString();\n\t\tif (snapshotString!= null) {\n\t\t\tsnapshotString = snapshotString.toUpperCase();\n\t\t\tswitch (snapshotString) {\n\t\t\t\tcase \"SNAPSHOT_KEY_FULL\":\n\t\t\t\t\treturn SnapshotRecord.SNAPSHOT_KEY_FULL;\n\t\t\t\tcase \"SNAPSHOT_KEY_INCREMENTAL\":\n\t\t\t\t\treturn SnapshotRecord.SNAPSHOT_KEY_INCREMENTAL;\n\t\t\t\tcase \"SNAPSHOT_KEY_MERGE\":\n\t\t\t\t\treturn SnapshotRecord.SNAPSHOT_KEY_MERGE;\n\t\t\t\tdefault:\n\t\t\t\t\treturn null;\n\t\t\t}\n\t\t} else {\n\t\t\treturn null;\n\t\t}\n\t} else {\n\t\treturn null;\n\t}\n}", "CodeBleu_score": 39.821426668273084}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tString[] versionParts = version.split(\"\\\\.\");\n\tif (versionParts.length > 2) {\n\t\tversionParts = Arrays.copyOfRange(versionParts, 0, 2);\n\t}\n\tString[] versionParts2 = versionParts[0].split(\"-\");\n\ttry {\n\t\treturn Optional.of(Float.parseFloat(versionParts2[0]));\n\t} catch (NumberFormatException e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 56.3984462779904}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tString[] parts2 = parts[0].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(parts2[0]));\n\t} catch (Exception e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 55.28180467328956}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\tif (version == null) {\n\t\treturn Optional.empty();\n\t}\n\tString[] parts = version.split(\"\\\\.\");\n\tif (parts.length > 2) {\n\t\tparts = Arrays.copyOf(parts, 2);\n\t}\n\tString[] subparts = parts[0].split(\"-\");\n\treturn Optional.of(Float.parseFloat(subparts[0]));\n}", "CodeBleu_score": 56.63674798335512}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\tontext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.CREATE)\n   .operationName(\"createConnector\")\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.createConnector(getCluster(clusterName), connectName, connector)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.00490138040098}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t", "CodeBleu_score": 9.923969587835135}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n.operationName(\"deleteConnector\")\n.operationParams(Map.of(CONNECTOR_NAME, connectName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 88.20371809231469}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n.operationName(\"deleteConnector\")\n.operationParams(Map.of(CONNECTOR_NAME, connectName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 88.20371809231469}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\tntext = AccessContext.builder()\n   .cluster(clusterName)\n   .connect(connectName)\n   .connectActions(ConnectAction.VIEW, ConnectAction.EDIT)\n   .operationName(\"deleteConnector\")\n   .operationParams(Map.of(CONNECTOR_NAME, connectName))\n   .build();\n\nreturn validateAccess(context).then(\n    kafkaConnectService.deleteConnector(getCluster(clusterName), connectName, connectorName)\n       .map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 90.46721568845263}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tction[] connectActions;\nif (RESTART_ACTIONS.contains(action)) {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n} else {\nconnectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n}\n\nvar context = AccessContext.builder()\n.cluster(clusterName)\n.connect(connectName)\n.connectActions(connectActions)\n.operationName(\"updateConnectorState\")\n.operationParams(Map.of(CONNECTOR_NAME, connectorName))\n.build();\n\nreturn validateAccess(context).then(\nkafkaConnectService\n.updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n.map(ResponseEntity::ok)\n).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 95.51539478476946}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tAction[] connectActions;\n\tif (RESTART_ACTIONS.contains(action)) {\n\t  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n\t} else {\n\t  connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n\t}\n\n\tvar context = AccessContext.builder()\n\t   .cluster(clusterName)\n\t   .connect(connectName)\n\t   .connectActions(connectActions)\n\t   .operationName(\"updateConnectorState\")\n\t   .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n\t   .build();\n\n\treturn validateAccess(context).then(\n\t    kafkaConnectService\n\t       .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n\t       .map(ResponseEntity::ok)\n\t).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 97.027728876196}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\tnectAction[] connectActions;\n//     if (RESTART_ACTIONS.contains(action)) {\n//       connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.RESTART};\n//     } else {\n//       connectActions = new ConnectAction[] {ConnectAction.VIEW, ConnectAction.EDIT};\n//     }\n\n//     var context = AccessContext.builder()\n//        .cluster(clusterName)\n//        .connect(connectName)\n//        .connectActions(connectActions)\n//        .operationName(\"updateConnectorState\")\n//        .operationParams(Map.of(CONNECTOR_NAME, connectorName))\n//        .build();\n\n//     return validateAccess(context).then(\n//         kafkaConnectService\n//            .updateConnectorState(getCluster(clusterName), connectName, connectorName, action)\n//            .map(ResponseEntity::ok)\n//     ).doOnEach(sig -> audit(context, sig));\n}", "CodeBleu_score": 9.314248730602849}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t", "CodeBleu_score": 7.1690436822820445}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\teturn kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n\t\t.map(ResponseEntity::ok);\n}", "CodeBleu_score": 26.659517850173685}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\tturn kafkaConnectService.validateConnectorPluginConfig(getCluster(clusterName), connectName, pluginName, requestBody).map(ResponseEntity::ok);\n}", "CodeBleu_score": 25.190586155315646}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new KafkaUiPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 38.89794963103099}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new DynamicConfigurationPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 41.33025083330208}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t\treturn new SpringApplicationBuilder(KafkaUiApplication.class)\n\t\t\t.initializers(new DynamicPropertiesInitializer())\n\t\t\t.run(args);\n}", "CodeBleu_score": 39.493198129107704}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\tif (search == null) {\nreturn t -> true;\n}\nreturn t -> getStringsForSearch(t).anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n}", "CodeBleu_score": 56.3894850125497}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn fullConnectorInfo -> {\n  if (search == null) {\n    return true;\n  }\n  return getStringsForSearch(fullConnectorInfo)\n     .map(s -> s.toLowerCase())\n     .anyMatch(s -> s.contains(search.toLowerCase()));\n};\n}", "CodeBleu_score": 53.48702605202722}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\treturn fullConnectorInfo -> {\n  if (search == null) {\n    return true;\n  }\n  return getStringsForSearch(fullConnectorInfo)\n     .anyMatch(s -> s.toLowerCase().contains(search.toLowerCase()));\n};\n}", "CodeBleu_score": 54.294137271755794}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t// TODO: Initialize the flattened map\n    Map<String, Object> flattenedMap = new HashMap<>();\n\n// TODO: Check if the properties map is null\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n\n// TODO: Check if the value is a map\n        if (value instanceof Map) {\n// TODO: Recursively flatten the nested map with the new key as the prefix\n          Map<String, Object> nestedMap = flattenClusterProperties(key, (Map<String, Object>) value);\n\n// TODO: Add the flattened nested map to the flattened map\n          flattenedMap.putAll(nestedMap);\n        } else {\n// TODO: Add the key-value pair to the flattened map\n          String flattenedKey = prefix!= null? prefix + \".\" + key : key;\n          flattenedMap.put(flattenedKey, value);\n        }\n      }\n    }\n\n// TODO: Return the flattened map\n    return flattenedMap;\n  }", "CodeBleu_score": 49.99043659277377}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    if (propertiesMap == null) {\n//      return Collections.emptyMap();\n//    }\n\n    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattened.put(prefix == null? key : prefix + \".\" + key, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 55.87517443475218}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t//    Map<String, Object> flattenedMap = new HashMap<>();\n//    if (propertiesMap!= null) {\n//      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n//        String key = entry.getKey();\n//        Object value = entry.getValue();\n//        String newKey = prefix!= null? prefix + \".\" + key : key;\n//        if (value instanceof Map) {\n//          flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n//        } else {\n//          flattenedMap.put(newKey, value);\n//        }\n//      }\n//    }\n//    return flattenedMap;\n\n    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap!= null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = entry.getKey();\n        Object value = entry.getValue();\n        String newKey = prefix!= null? prefix + \".\" + key : key;\n        if (value instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n        } else {\n          flattenedMap.put(newKey, value);\n        }\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 49.835249202341934}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t", "CodeBleu_score": 2.9334771606863974}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t\tConfigDef configDef = new ConfigDef();\n\tconfigDef.addImportKeys(SslConfigs.class);\n\tconfigDef.addImportKeys(SaslConfigs.class);\n\treturn configDef.configKeys().stream()\n\t\t.filter(configKey -> configKey.type() == ConfigDef.Type.PASSWORD)\n\t\t.map(configKey -> configKey.name())\n\t\t.collect(Collectors.toSet());\n}", "CodeBleu_score": 60.295128201999425}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t\tConfigDef configDef = new ConfigDef();\n\tconfigDef.define(SaslConfigs.SASL_JAAS_CONFIG, Type.PASSWORD, Importance.LOW, \"SASL JAAS config\");\n\tconfigDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD, Type.PASSWORD, Importance.LOW, \"SSL Keystore password\");\n\tconfigDef.define(SslConfigs.SSL_KEY_PASSWORD, Type.PASSWORD, Importance.LOW, \"SSL Key password\");\n\tconfigDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD, Type.PASSWORD, Importance.LOW, \"SSL Truststore password\");\n\treturn configDef.configKeys().stream()\n\t\t.filter(configKey -> configKey.type() == Type.PASSWORD)\n\t\t.map(ConfigKey::name)\n\t\t.collect(Collectors.toSet());\n}", "CodeBleu_score": 52.951236193551196}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\tif (aclViewEnabled(adminClient)) {\n\t\treturn adminClient.describeCluster()\n\t\t\t\t.map(description -> {\n\t\t\t\t\tif (description.authorizedOperations().contains(KafkaAclOperation.ALL) || description.authorizedOperations().contains(KafkaAclOperation.ALTER)) {\n\t\t\t\t\t\treturn ClusterFeature.KAFKA_ACL_EDIT;\n\t\t\t\t\t}\n\t\t\t\t\treturn null;\n\t\t\t\t})\n\t\t\t\t.filter(Objects::nonNull);\n\t}\n\treturn Mono.empty();\n}", "CodeBleu_score": 30.102942404708767}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn Mono.just(clusterDescription)\n\t\t\t.map(cd -> cd.getAuthorizedOperations())\n\t\t\t.map(ops -> ops.contains(AclOperation.ALL) || ops.contains(AclOperation.ALTER))\n\t\t\t.filter(allowed -> allowed)\n\t\t\t.map(allowed -> ReactiveAdminClient.SupportedFeature.KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 32.365604837151245}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t\treturn aclEditEnabled(adminClient, clusterDescription)? Mono.just(ClusterFeature.KAFKA_ACL_EDIT) : Mono.empty();\n}", "CodeBleu_score": 22.64110552538033}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n\t\tTopicPartition tp = entry.getKey();\n\t\tFromToOffset prevOffset = entry.getValue();\n\t\tFromToOffset nextOffset;\n\t\tif (prevOffset.isEmpty()) {\n\t\t\tnextOffset = seekOperations.getSeekOffset(tp);\n\t\t} else {\n\t\t\tnextOffset = prevOffset;\n\t\t}\n\t\tlong numMessagesToPoll = Math.min(maxPollRecords, nextOffset.to() - nextOffset.from());\n\t\tlong startOffset = Math.max(nextOffset.from(), nextOffset.to() - numMessagesToPoll);\n\t\tnextRange.put(tp, new FromToOffset(startOffset, startOffset + numMessagesToPoll));\n\t}\n\treturn nextRange;\n}", "CodeBleu_score": 31.42180218585028}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t", "CodeBleu_score": 3.709413387662834}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t\tTreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\tTreeMap<TopicPartition, Long> offsets = new TreeMap<>();\n\tif (prevRange!= null &&!prevRange.isEmpty()) {\n\t\tfor (Map.Entry<TopicPartition, FromToOffset> entry : prevRange.entrySet()) {\n\t\t\toffsets.put(entry.getKey(), entry.getValue().getTo());\n\t\t}\n\t}\n\tif (seekOperations!= null) {\n\t\tfor (Map.Entry<TopicPartition, Long> entry : seekOperations.getOffsets().entrySet()) {\n\t\t\toffsets.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n\tif (offsets.isEmpty()) {\n\t\tfor (TopicPartition topicPartition : partitions) {\n\t\t\toffsets.put(topicPartition, beginningOffsets.get(topicPartition));\n\t\t}\n\t}\n\tint numMessagesPerPartition = numMessages / partitions.size();\n\tfor (Map.Entry<TopicPartition, Long> entry : offsets.entrySet()) {\n\t\tTopicPartition topicPartition = entry.getKey();\n\t\tlong offset = entry.getValue();\n\t\tif (offset < beginningOffsets.get(topicPartition)) {\n\t\t\toffset = beginningOffsets.get(topicPartition);\n\t\t}\n\t\tnextRange.put(topicPartition, new FromToOffset(offset, offset + numMessagesPerPartition));\n\t}\n\treturn nextRange;\n}", "CodeBleu_score": 33.38859920253056}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t Legacy mode is enabled if the zookeeper configuration key is present.\nfinal boolean legacyMode = configuration.containsKey(CK_ZOOKEEPER);\n\nif (legacyMode) {\n    // Validate the ZooKeeper configuration.\n    if (!configuration.containsKey(CK_ZOOKEEPER)) {\n        throw new IllegalArgumentException(\"ZooKeeper configuration is missing\");\n    }\n} else {\n    // Validate the bootstrap servers configuration.\n    if (!configuration.containsKey(CK_BOOTSTRAP)) {\n        throw new IllegalArgumentException(\"Bootstrap servers configuration is missing\");\n    }\n}\n\n// Wait for the server to be running.\nwaitForServerRunning();\n\n// Register for server lifecycle events.\nlifecycleEventBus.register(this);\n\nif (legacyMode) {\n    // Launch the legacy input.\n    doLaunchLegacy(input);\n} else {\n    // Launch the consumer input.\n    doLaunchConsumer(input);\n}\n\n// Schedule a task to update the last second bytes read every second.\nexecutor.scheduleAtFixedRate(this::updateLastSecBytesRead, 0, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 44.685775199320496}, {"code": "public void doLaunch(final MessageInput input){\n\t/ check if legacy mode is enabled\n\tfinal boolean legacyMode = configuration.getBoolean(CK_LEGACY_MODE, false);\n\n\t// validate the corresponding configuration settings for ZooKeeper or bootstrap servers\n\tif (legacyMode) {\n\t\t// ZooKeeper\n\t\tfinal String zookeeper = configuration.getString(CK_ZOOKEEPER);\n\t\tif (Strings.isNullOrEmpty(zookeeper)) {\n\t\t\tthrow new RuntimeException(\"ZooKeeper must be specified for legacy mode.\");\n\t\t}\n\t} else {\n\t\t// bootstrap servers\n\t\tfinal String bootstrap = configuration.getString(CK_BOOTSTRAP);\n\t\tif (Strings.isNullOrEmpty(bootstrap)) {\n\t\t\tthrow new RuntimeException(\"Bootstrap servers must be specified for consumer mode.\");\n\t\t}\n\t}\n\n\t// wait for the server to be running\n\twaitForServerRunning();\n\n\t// register for server lifecycle events\n\teventBus.register(this);\n\n\t// launch the input based on the mode\n\tif (legacyMode) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\n\t// schedule a task to update the last second bytes read every second\n\tscheduler.scheduleAtFixedRate(new Runnable() {\n\t\t@Override\n\t\tpublic void run() {\n\t\t\tlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n\t\t}\n\t}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 62.459044855468136}, {"code": "public void doLaunch(final MessageInput input){\n\tinal boolean legacy = configuration.getBoolean(CK_LEGACY, false);\n\tif (legacy) {\n\t\tif (configuration.getString(CK_ZOOKEEPER) == null) {\n\t\t\tthrow new RuntimeException(\"Legacy mode is enabled, but no zookeeper is configured.\");\n\t\t}\n\t} else {\n\t\tif (configuration.getString(CK_BOOTSTRAP) == null) {\n\t\t\tthrow new RuntimeException(\"No bootstrap servers are configured.\");\n\t\t}\n\t}\n\n\t// wait for the server to be running\n\twhile (lifecycle.get()!= Lifecycle.RUNNING) {\n\t\ttry {\n\t\t\tThread.sleep(1000);\n\t\t} catch (InterruptedException e) {\n\t\t\t// ignore\n\t\t}\n\t}\n\n\t// register for lifecycle events\n\tlifecycle.register(this);\n\n\t// launch the input\n\tif (legacy) {\n\t\tdoLaunchLegacy(input);\n\t} else {\n\t\tdoLaunchConsumer(input);\n\t}\n\n\t// schedule a task to update the last second bytes read every second\n\texecutor.scheduleAtFixedRate(() -> {\n\t\tlastSecBytesRead.set(lastSecBytesReadTmp.getAndSet(0));\n\t}, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 42.709241200518164}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t\tString config = getCustomProperties();\n\tif (config == null) {\n\t\treturn;\n\t}\n\n\tProperties customProps = new Properties();\n\ttry {\n\t\tcustomProps.load(new StringReader(config));\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to load custom properties: \" + e.getMessage());\n\t\treturn;\n\t}\n\n\tprops.putAll(customProps);\n}", "CodeBleu_score": 36.71484072603814}, {"code": "private void insertCustomProperties(Properties props){\n\t\tString config = System.getProperty(\"config\");\n\tif (config!= null) {\n\t\tProperties customProps = new Properties();\n\t\ttry {\n\t\t\tcustomProps.load(new StringReader(config));\n\t\t\tprops.putAll(customProps);\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Unable to load custom properties\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 45.38580908119472}, {"code": "private void insertCustomProperties(Properties props){\n\t\ttry {\n\t\t// load custom properties from a configuration string\n\t\tProperties customProps = new Properties();\n\t\tcustomProps.load(new StringReader(customProperties));\n\n\t\t// merge custom properties with the existing properties\n\t\tprops.putAll(customProps);\n\t} catch (IOException e) {\n\t\tlogger.error(\"Failed to load custom properties: \" + e.getMessage());\n\t}\n}", "CodeBleu_score": 32.808557853216755}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries.isEmpty()) {\n\t\treturn;\n\t}\n\n\tList<Journal.Entry> journalEntries = new ArrayList<>(entries.size());\n\tlong totalMessageBytes = 0;\n\tfor (RawMessageEvent entry : entries) {\n\t\tif (entry == null) {\n\t\t\tcontinue;\n\t\t}\n\t\tJournal.Entry journalEntry = new Journal.Entry(entry.getTopic(), entry.getKey(), entry.getValue());\n\t\tjournalEntries.add(journalEntry);\n\t\ttotalMessageBytes += journalEntry.getMessageSize();\n\t}\n\n\tif (journalEntries.isEmpty()) {\n\t\treturn;\n\t}\n\n\tboolean success = false;\n\tfor (int attempt = 1; attempt <= maxWriteAttempts; attempt++) {\n\t\ttry {\n\t\t\twriteToJournal(journalEntries);\n\t\t\tsuccess = true;\n\t\t\tbreak;\n\t\t} catch (Exception e) {\n\t\t\tLOG.warn(\"Failed to write to journal, attempt {} of {}\", attempt, maxWriteAttempts, e);\n\t\t\tif (attempt < maxWriteAttempts) {\n\t\t\t\tlong sleepMillis = (long) (Math.pow(2, attempt) * writeBackoffSeconds * 1000);\n\t\t\t\tLOG.warn(\"Sleeping for {} ms before retrying\", sleepMillis);\n\t\t\t\ttry {\n\t\t\t\t\tThread.sleep(sleepMillis);\n\t\t\t\t} catch (InterruptedException ie) {\n\t\t\t\t\tLOG.warn(\"Interrupted while sleeping for {} ms before retrying\", sleepMillis);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\tif (!success) {\n\t\tthrow new MessageQueueException(\"Failed to write to journal after \" + maxWriteAttempts + \" attempts\");\n\t}\n\n\tmetrics.getWrittenMessages().inc(journalEntries.size());\n\tmetrics.getWrittenBytes().inc(totalMessageBytes);\n}", "CodeBleu_score": 39.03206232605716}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\tif (entries.isEmpty()) {\n\t\treturn;\n\t}\n\tList<Journal.Entry> journalEntries = entries.stream()\n\t\t\t.filter(Objects::nonNull)\n\t\t\t.map(this::toJournalEntry)\n\t\t\t.collect(Collectors.toList());\n\tlong totalMessageBytes = journalEntries.stream()\n\t\t\t.mapToLong(entry -> entry.getMessage().length)\n\t\t\t.sum();\n\tint attempts = 0;\n\tboolean success = false;\n\twhile (!success && attempts < MAX_WRITE_ATTEMPTS) {\n\t\ttry {\n\t\t\twriteToJournal(journalEntries);\n\t\t\tsuccess = true;\n\t\t} catch (KafkaException e) {\n\t\t\tattempts++;\n\t\t\tif (attempts == MAX_WRITE_ATTEMPTS) {\n\t\t\t\tthrow e;\n\t\t\t}\n\t\t\tLOG.warn(\"Failed to write to journal, retrying in {} seconds\",\n\t\t\t\t\tMath.pow(2, attempts), e);\n\t\t\ttry {\n\t\t\t\tThread.sleep((long) (Math.pow(2, attempts) * 1000));\n\t\t\t} catch (InterruptedException ie) {\n\t\t\t\tthrow new MessageQueueException(ie);\n\t\t\t}\n\t\t}\n\t}\n\twrittenMessages.inc(journalEntries.size());\n\twrittenBytes.inc(totalMessageBytes);\n}", "CodeBleu_score": 45.76823919503645}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t\n// Filter out null entries and map each event to a journal entry\n// while calculating the total message bytes\nfinal List<Journal.Entry> journalEntries = entries.stream()\n       .filter(Objects::nonNull)\n       .map(this::mapToJournalEntry)\n       .collect(Collectors.toList());\n\nif (journalEntries.isEmpty()) {\n    return;\n}\n\nfinal long totalMessageBytes = journalEntries.stream()\n       .mapToLong(Journal.Entry::size)\n       .sum();\n\n// Attempt to write the entries to the journal, and if it fails,\n// retry using an exponential back-off strategy\nint retryCount = 0;\nwhile (true) {\n    try {\n        writeToJournal(journalEntries);\n        break;\n    } catch (MessageQueueException e) {\n        if (retryCount >= maxRetries) {\n            throw e;\n        }\n        try {\n            Thread.sleep(Math.pow(2, retryCount) * retryIntervalMs);\n        } catch (InterruptedException ex) {\n            Thread.currentThread().interrupt();\n            throw new MessageQueueException(\"Interrupted while waiting for retry\", ex);\n        }\n        retryCount++;\n    }\n}\n\n// Update the written messages and bytes metrics\nwrittenMessages.inc(journalEntries.size());\nwrittenBytes.inc(totalMessageBytes);\n}", "CodeBleu_score": 49.022568035494196}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t\tif (messages!= null &&!messages.isEmpty()) {\n\t\tint maxValidQueueId = -1;\n\t\tfor (Message message : messages) {\n\t\t\tif (message!= null && message.getQueueId() > maxValidQueueId) {\n\t\t\t\tmaxValidQueueId = message.getQueueId();\n\t\t\t}\n\t\t}\n\t\tif (maxValidQueueId > -1) {\n\t\t\tacknowledge(maxValidQueueId);\n\t\t\tmetrics.updateAcknowledged(messages.size());\n\t\t}\n\t}\n}", "CodeBleu_score": 21.708349973980116}, {"code": "public void acknowledge(List<Message> messages){\n\t\tint maxQueueId = -1;\n\tfor (Message message : messages) {\n\t\tif (message.getQueueId() > maxQueueId) {\n\t\t\tmaxQueueId = message.getQueueId();\n\t\t}\n\t}\n\tif (maxQueueId >= 0) {\n\t\tacknowledge(maxQueueId);\n\t}\n\tmetrics.markAcknowledged(messages.size());\n}", "CodeBleu_score": 20.183901663521482}, {"code": "public void acknowledge(List<Message> messages){\n\t\t// Get the maximum valid message queue ID from the list of messages\n\tint maxValidMessageQueueId = -1;\n\tfor (Message message : messages) {\n\t\tif (message.getQueueId() > maxValidMessageQueueId) {\n\t\t\tmaxValidMessageQueueId = message.getQueueId();\n\t\t}\n\t}\n\n\t// Acknowledge the maximum valid message queue ID if present\n\tif (maxValidMessageQueueId >= 0) {\n\t\tacknowledge(maxValidMessageQueueId);\n\t}\n\n\t// Update metrics\n\tmetrics.addAcknowledgedMessages(messages.size());\n}", "CodeBleu_score": 22.087417825114823}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry metricRegistry = getMetricRegistry();\n\tfinal String className = getClass().getName();\n\tfinal String legacyPrefix = \"akka.persistence.kafka.journal.\";\n\tfor (final Map.Entry<String, Metric> entry : metricRegistry.getMetrics().entrySet()) {\n\t\tfinal String name = entry.getKey();\n\t\tif (name.startsWith(className)) {\n\t\t\tfinal String legacyName = legacyPrefix + name.substring(className.length());\n\t\t\ttry {\n\t\t\t\tmetricRegistry.register(legacyName, entry.getValue());\n\t\t\t} catch (final IllegalArgumentException e) {\n\t\t\t\tlog.warning(\"Unable to register legacy metric {}. Original name: {}\", legacyName, name);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 34.237815326067114}, {"code": "private void registerLegacyMetrics(){\n\t// Filter the metrics to include only those starting with the LocalKafkaJournal class name\nfinal Set<String> localKafkaJournalMetrics = this.metrics.keySet().stream()\n       .filter(metricName -> metricName.startsWith(LocalKafkaJournal.class.getName()))\n       .collect(Collectors.toSet());\n\n// For each filtered metric, construct a legacy metric name and attempt to register it under this name in the metric registry\nfor (final String metricName : localKafkaJournalMetrics) {\n    final String legacyMetricName = metricName.replace(LocalKafkaJournal.class.getName(), \"akka.persistence.kafka.journal\");\n    try {\n        this.legacyMetrics.put(legacyMetricName, this.metrics.remove(metricName));\n    } catch (final IllegalArgumentException e) {\n        log.warning(\"Failed to register legacy metric {} for original metric {}\", legacyMetricName, metricName);\n    }\n}\n}", "CodeBleu_score": 44.40670275511663}, {"code": "private void registerLegacyMetrics(){\n\t\tfinal MetricRegistry metricRegistry = this.metricRegistry();\n\tfinal Set<String> legacyNames = new HashSet<>();\n\tfor (final Map.Entry<String, Metric> entry : metricRegistry.getMetrics().entrySet()) {\n\t\tif (entry.getKey().startsWith(LocalKafkaJournal.class.getName())) {\n\t\t\tfinal String legacyName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"akka.persistence.kafka\");\n\t\t\tif (metricRegistry.getMetrics().containsKey(legacyName)) {\n\t\t\t\tlog().warning(\"Legacy metric name [{}] already registered. Original name [{}]\", legacyName, entry.getKey());\n\t\t\t} else {\n\t\t\t\ttry {\n\t\t\t\t\tmetricRegistry.register(legacyName, entry.getValue());\n\t\t\t\t\tlegacyNames.add(legacyName);\n\t\t\t\t} catch (final IllegalArgumentException e) {\n\t\t\t\t\tlog().warning(\"Failed to register legacy metric name [{}] for original name [{}].\", legacyName, entry.getKey());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\tfor (final String legacyName : legacyNames) {\n\t\tmetricRegistry.remove(legacyName);\n\t}\n}", "CodeBleu_score": 33.659246093935415}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 31.427533397383336}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\ttry {\n\t\treturn metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\treturn metricRegistry.getTimers().get(metricName);\n\t}\n}", "CodeBleu_score": 18.999020882357122}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t\tTimer timer = null;\n\ttry {\n\t\ttimer = metricRegistry.timer(metricName);\n\t} catch (IllegalArgumentException e) {\n\t\t// The metric name is already registered. Retrieve the existing timer.\n\t\ttimer = metricRegistry.getTimers().get(metricName);\n\t}\n\treturn timer;\n}", "CodeBleu_score": 31.427533397383336}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t\tmetricRegistry.register(name, new Gauge<Long>() {\n\t\t@Override\n\t\tpublic Long getValue() {\n\t\t\ttry {\n\t\t\t\tif (size() == 0) {\n\t\t\t\t\treturn 0L;\n\t\t\t\t}\n\t\t\t\tif (kafkaLog.lastOffset() == -1) {\n\t\t\t\t\treturn kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n\t\t\t\t}\n\t\t\t\treturn kafkaLog.logEndOffset() - kafkaLog.lastOffset();\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.warn(\"Error while calculating uncommitted messages\", e);\n\t\t\t\treturn 0L;\n\t\t\t}\n\t\t}\n\t});\n}", "CodeBleu_score": 52.483535604412545}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\ttry {\n            metricRegistry.register(name, new Gauge<Long>() {\n                @Override\n                public Long getValue() {\n                    long size = kafkaLog.size();\n                    if (size == 0) {\n                        return 0L;\n                    }\n                    long committedOffset = kafkaLog.lastOffset();\n                    if (committedOffset == KafkaLog.UNKNOWN_OFFSET) {\n                        return kafkaLog.logEndOffset() - kafkaLog.logStartOffset();\n                    }\n                    return kafkaLog.logEndOffset() - committedOffset;\n                }\n            });\n        } catch (IllegalArgumentException e) {\n            // ignore\n        }\n    }", "CodeBleu_score": 51.52785134247237}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\tmetricRegistry.register(MetricRegistry.name(name, \"uncommitted\"), new Gauge<Long>() {\n@Override\npublic Long getValue() {\nfinal long size = size();\nif (size == 0) {\nreturn 0L;\n}\nfinal long committedOffset = getCommittedOffset();\nif (committedOffset == KafkaLog.DEFAULT_COMMIT_OFFSET) {\nreturn getLogEndOffset() - getLogStartOffset();\n} else {\nreturn getLogEndOffset() - committedOffset;\n}\n}\n});\n}", "CodeBleu_score": 41.10378275859485}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to flush\");\nreturn 0;\n}\nByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\nlog.trace(\"Flushing {} messages with total size {} to {}\", messageSet.sizeInBytes(), payloadSize, kafkaLog.activeSegment().file().getAbsoluteFile());\nlong lastOffset = kafkaLog.append(messageSet, payloadSize);\nlog.trace(\"Wrote {} messages for {} with offset {} to log {}\", messageSet.sizeInBytes(), payloadSize, lastOffset, kafkaLog.activeSegment().file().getAbsoluteFile());\nnumMessagesFlushed.mark(messageSet.sizeInBytes());\nreturn lastOffset;\n}", "CodeBleu_score": 39.440921342508865}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to flush\");\nreturn kafkaLog.size();\n}\nByteBufferMessageSet messageSet = ByteBufferMessageSet.readFrom(messages);\nlog.trace(\"Flushing {} messages with {} bytes to {}\",\nmessages.size(),\nmessageSet.sizeInBytes(),\nkafkaLog.getLogFile());\nlong offset = kafkaLog.append(messageSet);\nlog.trace(\"Wrote {} to log {} with offset {}\",\nmessages.size(),\nkafkaLog.getLogFile(),\noffset);\nmessagesFlushed.mark(messages.size());\nreturn offset;\n}", "CodeBleu_score": 37.689645908512034}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\tif (messages.isEmpty()) {\nlog.debug(\"No messages to flush\");\nreturn -1L;\n}\nByteBufferMessageSet messageSet = ByteBufferMessageSet.readFrom(new ByteBufferMessageSet.Builder(messages));\nlog.debug(\"Flushing {} messages with total size {} to {}\", messageSet.sizeInBytes(), messageSet.sizeInBytes(), kafkaLog.file());\nlong lastOffset = kafkaLog.append(messageSet);\nlog.trace(\"Wrote {} messages with total size {} to log {} with offset {}\", messageSet.sizeInBytes(), messageSet.sizeInBytes(), kafkaLog.file(), lastOffset);\nthis.messagesAppended.mark(messageSet.sizeInBytes());\nthis.bytesAppended.mark(payloadSize);\nreturn lastOffset;\n}", "CodeBleu_score": 42.68815758891746}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u52a0\u9501\n        synchronized (this.adminClientMap) {\n            List<AdminClient> adminClientList = this.adminClientMap.remove(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"start to close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n            if (!this.closeAdminClientList(clusterPhyId, adminClientList)) {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            }\n        }\n    }", "CodeBleu_score": 48.26478253655809}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t// \u9501\u5b9a\u5ba2\u6237\u7aef\u6620\u5c04\u4ee5\u786e\u4fdd\u7ebf\u7a0b\u5b89\u5168\uff0c\u5e76\u68c0\u7d22\u4e0e\u6307\u5b9a\u96c6\u7fa4ID\u76f8\u5173\u8054\u7684AdminClient\u5b9e\u4f8b\u5217\u8868\u3002\n// \u5982\u679c\u627e\u4e0d\u5230\u5ba2\u6237\u7aef\uff0c\u5219\u51fd\u6570\u8fd4\u56de\u3002\n// \u5b83\u8bb0\u5f55\u5173\u95ed\u8fc7\u7a0b\u7684\u5f00\u59cb\uff0c\u5e76\u5c1d\u8bd5\u5173\u95ed\u5217\u8868\u4e2d\u7684\u6240\u6709AdminClient\u5b9e\u4f8b\u3002\n// \u5982\u679c\u6240\u6709\u5ba2\u6237\u7aef\u90fd\u6210\u529f\u5173\u95ed\uff0c\u5219\u8bb0\u5f55\u6210\u529f\u6d88\u606f\uff0c\u5982\u679c\u4efb\u4f55\u5173\u95ed\u5931\u8d25\uff0c\u5219\u8bb0\u5f55\u9519\u8bef\u6d88\u606f\u3002\n// \u5728\u6b64\u8fc7\u7a0b\u4e2d\u6355\u83b7\u5e76\u8bb0\u5f55\u4efb\u4f55\u5f02\u5e38\u3002\n// \u6700\u540e\uff0c\u91ca\u653e\u9501\u5b9a\u3002\n        this.adminClientMapLock.lock();\n        try {\n            List<AdminClient> adminClientList = this.adminClientMap.remove(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n            if (this.closeAdminClientList(clusterPhyId, adminClientList)) {\n                LOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n            } else {\n                LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId, e);\n        } finally {\n            this.adminClientMapLock.unlock();\n        }\n    }", "CodeBleu_score": 58.4500276909625}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t\t// \u52a0\u9501\uff0c\u4fdd\u8bc1\u7ebf\u7a0b\u5b89\u5168\n\tthis.lock.lock();\n\ttry {\n\t\t// \u83b7\u53d6\u6307\u5b9a\u96c6\u7fa4ID\u7684\u5ba2\u6237\u7aef\u5217\u8868\n\t\tList<AdminClient> adminClientList = this.kafkaAdminClientMap.remove(clusterPhyId);\n\t\t// \u5982\u679c\u6ca1\u6709\u5ba2\u6237\u7aef\uff0c\u5219\u76f4\u63a5\u8fd4\u56de\n\t\tif (adminClientList == null) {\n\t\t\treturn;\n\t\t}\n\n\t\t// \u65e5\u5fd7\u8bb0\u5f55\u5f00\u59cb\u5173\u95ed\u5ba2\u6237\u7aef\n\t\tLOGGER.info(\"start to close kafka AdminClient, clusterPhyId:{}\", clusterPhyId);\n\n\t\t// \u5c1d\u8bd5\u5173\u95ed\u6240\u6709\u5ba2\u6237\u7aef\n\t\tboolean allSuccess = this.closeAdminClientList(clusterPhyId, adminClientList);\n\n\t\t// \u65e5\u5fd7\u8bb0\u5f55\u5173\u95ed\u7ed3\u679c\n\t\tif (allSuccess) {\n\t\t\tLOGGER.info(\"close kafka AdminClient success, clusterPhyId:{}\", clusterPhyId);\n\t\t} else {\n\t\t\tLOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId);\n\t\t}\n\t} catch (Exception e) {\n\t\t// \u6355\u83b7\u5f02\u5e38\u5e76\u8bb0\u5f55\u65e5\u5fd7\n\t\tLOGGER.error(\"close kafka AdminClient exist failed, clusterPhyId:{}\", clusterPhyId, e);\n\t} finally {\n\t\t// \u91ca\u653e\u9501\n\t\tthis.lock.unlock();\n\t}\n}", "CodeBleu_score": 70.37594433899422}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Error closing AdminClient for cluster with phyId {}: {}\", clusterPhyId, e.getMessage());\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 55.92169307607199}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList == null) {\n\t\treturn true;\n\t}\n\tfor (AdminClient adminClient : adminClientList) {\n\t\ttry {\n\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t} catch (Exception e) {\n\t\t\tlog.error(\"Failed to close Kafka AdminClient for cluster {}\", clusterPhyId, e);\n\t\t\tsuccess = false;\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 63.95598447714743}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t\tboolean success = true;\n\tif (adminClientList!= null) {\n\t\tfor (AdminClient adminClient : adminClientList) {\n\t\t\ttry {\n\t\t\t\tadminClient.close(30, TimeUnit.SECONDS);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlogger.error(\"Error while closing AdminClient for cluster ID {}: {}\", clusterPhyId, e.getMessage());\n\t\t\t\tsuccess = false;\n\t\t\t}\n\t\t}\n\t}\n\treturn success;\n}", "CodeBleu_score": 48.74015555086402}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}, {"code": "public void stop() {\n\tif (app!= null) {\n\t\tapp.stop();\n\t\tint attempts = 5;\n\t\twhile (app.isRunning() && attempts > 0) {\n\t\t\tattempts = attempts - 1;\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t}\n\t\t\tcatch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 76.42781424310493}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableSelfPreservation(false);\n\trunner.setRegistrySyncRetries(0);\n\trunner.setEnableSelfPreservation(false);\n\trunner.setEvictionIntervalTimerInMs(10000);\n\trunner.setRenewalPercentThreshold(0.85);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 34.57260501645672}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\trunner.enableSsl();\n\trunner.setKeystore(KEYSTORE_FILE, KEYSTORE_PASSWORD);\n\trunner.setTruststore(TRUSTSTORE_FILE, TRUSTSTORE_PASSWORD);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 43.17235006102495}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t\tEurekaServerRunner runner = new EurekaServerRunner(config);\n\tboolean success = false;\n\ttry {\n\t\trunner.init();\n\t\trunner.start();\n\t\tsuccess = true;\n\t} finally {\n\t\tif (!success) {\n\t\t\trunner.stop();\n\t\t}\n\t}\n\treturn runner;\n}", "CodeBleu_score": 36.17066145963651}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 67.4093929884973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config);\n\trunner.setServerRunner(server);\n\trunner.setServiceName(\"testservice\");\n\tenableTlsClient(runner);\n\trunner.start();\n\treturn runner;\n}", "CodeBleu_score": 42.783152147503976}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner runner = new EurekaClientRunner(config, server);\n\tenableTlsClient(runner);\n\trunner.startService(\"testservice\");\n\treturn runner;\n}", "CodeBleu_score": 44.05402727537104}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t\t// Generate CA certificate\n\tKeyAndCert ca = KeyTool.generateCA(CA_SUBJECT, CA_VALIDITY_DAYS);\n\tFile caCertFile = saveCert(ca);\n\tFile caKeyFile = saveKeyAndCert(ca);\n\n\t// Generate server certificate\n\tKeyAndCert server = KeyTool.generateServer(ca, SERVER_SUBJECT, SERVER_VALIDITY_DAYS);\n\tFile serverCertFile = saveCert(server);\n\tFile serverKeyFile = saveKeyAndCert(server);\n\n\t// Generate client certificate\n\tKeyAndCert client = KeyTool.generateClient(ca, CLIENT_SUBJECT, CLIENT_VALIDITY_DAYS);\n\tFile clientCertFile = saveCert(client);\n\tFile clientKeyFile = saveKeyAndCert(client);\n\n\t// Generate second CA certificate\n\tKeyAndCert ca2 = KeyTool.generateCA(CA2_SUBJECT, CA2_VALIDITY_DAYS);\n\tFile ca2CertFile = saveCert(ca2);\n\tFile ca2KeyFile = saveKeyAndCert(ca2);\n\n\t// Generate second client certificate\n\tKeyAndCert client2 = KeyTool.generateClient(ca2, CLIENT2_SUBJECT, CLIENT2_VALIDITY_DAYS);\n\tFile client2CertFile = saveCert(client2);\n\tFile client2KeyFile = saveKeyAndCert(client2);\n\n\t// Print files\n\tSystem.out.println(\"CA certificate: \" + caCertFile.getAbsolutePath());\n\tSystem.out.println(\"CA key: \" + caKeyFile.getAbsolutePath());\n\tSystem.out.println(\"Server certificate: \" + serverCertFile.getAbsolutePath());\n\tSystem.out.println(\"Server key: \" + serverKeyFile.getAbsolutePath());\n\tSystem.out.println(\"Client certificate: \" + clientCertFile.getAbsolutePath());\n\tSystem.out.println(\"Client key: \" + clientKeyFile.getAbsolutePath());\n\tSystem.out.println(\"Second CA certificate: \" + ca2CertFile.getAbsolutePath());\n\tSystem.out.println(\"Second CA key: \" + ca2KeyFile.getAbsolutePath());\n\tSystem.out.println(\"Second client certificate: \" + client2CertFile.getAbsolutePath());\n\tSystem.out.println(\"Second client key: \" + client2KeyFile.getAbsolutePath());\n}", "CodeBleu_score": 26.97679682129024}, {"code": "static void createCertificates() throws Exception{\n\t", "CodeBleu_score": 1.403125619965593}, {"code": "static void createCertificates() throws Exception{\n\t\tKeyTool keyTool = new KeyTool();\n\tKeyAndCert ca = keyTool.createCA(CA_ALIAS);\n\tKeyAndCert server = keyTool.createServer(SERVER_ALIAS, CA_ALIAS, ca);\n\tKeyAndCert client = keyTool.createClient(CLIENT_ALIAS, CA_ALIAS, ca);\n\tKeyAndCert secondCa = keyTool.createCA(SECOND_CA_ALIAS);\n\tKeyAndCert secondClient = keyTool.createClient(SECOND_CLIENT_ALIAS, SECOND_CA_ALIAS, secondCa);\n\tsaveCert(ca);\n\tsaveCert(server);\n\tsaveCert(client);\n\tsaveCert(secondCa);\n\tsaveCert(secondClient);\n\tsaveKeyAndCert(ca);\n\tsaveKeyAndCert(server);\n\tsaveKeyAndCert(client);\n\tsaveKeyAndCert(secondCa);\n\tsaveKeyAndCert(secondClient);\n}", "CodeBleu_score": 37.514795895657905}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong timeLimit = seconds * 1000L;\n\twhile (System.currentTimeMillis() - startTime < timeLimit) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 48.9981111896481}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\tlong startTime = System.currentTimeMillis();\n\tlong endTime = startTime + seconds * 1000;\n\twhile (System.currentTimeMillis() < endTime) {\n\t\tif (assertion.getAsBoolean()) {\n\t\t\treturn;\n\t\t}\n\t}\n\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds\");\n}", "CodeBleu_score": 47.14197727619366}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t\t// Record the current time\n\tlong startTime = System.currentTimeMillis();\n\n\t// Calculate the time limit in milliseconds\n\tlong timeLimit = seconds * 1000;\n\n\t// Repeatedly evaluate the assertion until it's true or the time limit is reached\n\twhile (true) {\n\t\t// Evaluate the assertion\n\t\tboolean result = assertion.getAsBoolean();\n\n\t\t// Check if the assertion is true or the time limit is reached\n\t\tif (result || (System.currentTimeMillis() - startTime) >= timeLimit) {\n\t\t\t// If the assertion is true or the time limit is reached, exit the loop\n\t\t\tbreak;\n\t\t}\n\n\t\t// If the assertion is not true and the time limit is not reached, wait for a short period of time\n\t\ttry {\n\t\t\tThread.sleep(50);\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new RuntimeException(e);\n\t\t}\n\t}\n\n\t// If the assertion is not true after the time limit, throw an exception\n\tif (!assertion.getAsBoolean()) {\n\t\tthrow new RuntimeException(\"Assertion failed after \" + seconds + \" seconds.\");\n\t}\n}", "CodeBleu_score": 35.57844533151513}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tX509Certificate caCert = getCaCert(ca);\n\n\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), caCert.getIssuerDN().getName(), keyPair.getPublic().toString());\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 58.849286794224184}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder builder = certBuilder(keyPair.getPublic(), ca, ca);\n\tbuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n\tbuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\treturn signCert(builder, keyPair.getPrivate());\n}", "CodeBleu_score": 81.33855884143037}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t\tJcaX509v3CertificateBuilder certBuilder = certBuilder(keyPair.getPublic(), ca, ca);\n\n\tcertBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature));\n\tcertBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n\treturn signCert(certBuilder, keyPair.getPrivate());\n}", "CodeBleu_score": 72.63512312357456}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\tField registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n\t\t\tregistrationClientField.setAccessible(true);\n\t\t\teurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n\t\t} catch (IllegalAccessException | NoSuchFieldException e) {\n\t\t\tlogger.error(\"Error when accessing the registrationClient field from the eurekaTransport object\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 46.41871612999106}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) ReflectionUtils.getField(eurekaTransport, \"registrationClient\");\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access registrationClient\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 30.185806837462547}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t\tif (eurekaHttpClient == null) {\n\t\ttry {\n\t\t\teurekaHttpClient = (EurekaHttpClient) eurekaTransport.registrationClient.getClass().getDeclaredField(\"eurekaHttpClient\").get(eurekaTransport.registrationClient);\n\t\t} catch (IllegalAccessException e) {\n\t\t\tlogger.error(\"Cannot access the registrationClient field\", e);\n\t\t}\n\t}\n\treturn eurekaHttpClient;\n}", "CodeBleu_score": 42.92469721217571}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications() == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 66.56583330990317}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications() == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application application : applications.getRegisteredApplications()) {\n\t\tif (application.getInstances()!= null &&!application.getInstances().isEmpty()) {\n\t\t\tservices.add(application.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 66.56583330990317}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications() == null) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<>();\n\tfor (Application app : applications.getRegisteredApplications()) {\n\t\tif (app.getInstances()!= null &&!app.getInstances().isEmpty()) {\n\t\t\tservices.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 69.44251586379602}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tthis.healthContributors.forEach((key, value) -> {\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) value;\n\t\t\tcomposite.getIndicators().forEach((k, v) -> {\n\t\t\t\tif (!(v instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(k, v);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, value);\n\t\t}\n\t});\n}", "CodeBleu_score": 36.36747366558501}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tthis.healthContributors.each { key, value ->\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tvalue.getHealthIndicators().each { indicator ->\n\t\t\t\tif (!(indicator instanceof EurekaHealthIndicator)) {\n\t\t\t\t\thealthContributors.put(key + \".\" + indicator.getName(), indicator)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\thealthContributors.put(key, value)\n\t\t}\n\t}\n}", "CodeBleu_score": 25.250215449905483}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tMap<String, HealthContributor> contributors = new LinkedHashMap<String, HealthContributor>();\n\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tString key = entry.getKey();\n\t\tHealthContributor value = entry.getValue();\n\t\tif (value instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) value;\n\t\t\tfor (Map.Entry<String, HealthIndicator> entry2 : composite.getHealthIndicators().entrySet()) {\n\t\t\t\tString key2 = entry2.getKey();\n\t\t\t\tHealthIndicator value2 = entry2.getValue();\n\t\t\t\tif (value2 instanceof EurekaHealthIndicator) {\n\t\t\t\t\tcontinue;\n\t\t\t\t}\n\t\t\t\tcontributors.put(key + \":\" + key2, value2);\n\t\t\t}\n\t\t}\n\t\telse {\n\t\t\tcontributors.put(key, value);\n\t\t}\n\t}\n\thealthContributors.clear();\n\thealthContributors.putAll(contributors);\n}", "CodeBleu_score": 34.7504146632312}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t\tList<ServiceInstance> list = discoveryClient.getInstances(\"provider-application\");\n\tif (list!= null && list.size() > 0 ) {\n\t\treturn restTemplate.postForObject(list.get(0).getUri()+\"/echo\", \"hello\", String.class);\n\t}\n\telse {\n\t\treturn \"hello\";\n\t}\n}", "CodeBleu_score": 26.426647424146243}, {"code": "public String hello(){\n\t\tList<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n\tif (instances.isEmpty()) {\n\t\tthrow new RuntimeException(\"No instances found\");\n\t}\n\tServiceInstance serviceInstance = instances.get(0);\n\tString baseUrl = serviceInstance.getUri().toString();\n\tbaseUrl = baseUrl + \"/echo\";\n\tSystem.out.println(\"baseUrl: \" + baseUrl);\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(baseUrl, \"Hello from client\", String.class);\n}", "CodeBleu_score": 49.4601393313207}, {"code": "public String hello(){\n\t\t// 1. Find the service instance using the Discovery Client\n\t// 2. If found, retrieve the URI of the first instance\n\t// 3. Send a POST request to its \"/echo\" endpoint using RestTemplate\n\t// 4. Return the response\n\t// 5. If no instances are found, throw a RuntimeException indicating the absence of any service instance for \"provider-application\"\n\tServiceInstance serviceInstance = discoveryClient.getInstances(\"provider-application\").get(0);\n\tString baseUrl = serviceInstance.getUri().toString();\n\tbaseUrl = baseUrl + \"/echo\";\n\tSystem.out.println(\"baseUrl: \" + baseUrl);\n\tSystem.out.println(\"serviceInstance: \" + serviceInstance);\n\tRestTemplate restTemplate = new RestTemplate();\n\treturn restTemplate.postForObject(baseUrl, \"Hello from consumer\", String.class);\n}", "CodeBleu_score": 39.754699220292686}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t\t// TODO Auto-generated method stub\n\treturn null;\n}", "CodeBleu_score": 1.7608168826626815}, {"code": "public String world(){\n\t\tServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n\tURI uri = serviceInstance.getUri();\n\tif (uri!= null) {\n\t\treturn restTemplate.getForObject(uri + \"/echo\", String.class);\n\t} else {\n\t\tthrow new RuntimeException(\"No instances found\");\n\t}\n}", "CodeBleu_score": 47.16394864997987}, {"code": "public String world(){\n\t\t// TODO: Implement this function\n\treturn null;\n}", "CodeBleu_score": 1.7608168826626815}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tsynchronized (serverMap) {\n\t\tif (!serverMap.containsKey(serviceName)) {\n\t\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t\t}\n\t\tserverMap.get(serviceName).add(new Server(ip, port));\n\t\tlogger.info(\"Registered service \" + serviceName + \" at \" + ip + \":\" + port);\n\t\treturn true;\n\t}\n}", "CodeBleu_score": 46.62830593827285}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Registering service: \" + serviceName + \" at \" + ip + \":\" + port);\n\tif (!serverMap.containsKey(serviceName)) {\n\t\tserverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n\t}\n\tserverMap.get(serviceName).add(new Server(ip, port));\n\treturn true;\n}", "CodeBleu_score": 50.25634739313087}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"registering service: \" + serviceName + \" ip: \" + ip + \" port: \" + port);\n\tif (!serverMap.containsKey(serviceName)) {\n\t\tserverMap.put(serviceName, new HashSet<Server>());\n\t}\n\tserverMap.get(serviceName).add(new Server(ip, port));\n\treturn true;\n}", "CodeBleu_score": 46.179993592752155}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\tlogger.info(\"Deregistering server with serviceName: \" + serviceName + \", ip: \" + ip + \", and port: \" + port);\n\tServer server = new Server(ip, port);\n\tSet<Server> servers = serverMap.get(serviceName);\n\tif (servers == null) {\n\t\tlogger.error(\"No servers registered with serviceName: \" + serviceName);\n\t\treturn false;\n\t}\n\tif (servers.remove(server)) {\n\t\tlogger.info(\"Server with serviceName: \" + serviceName + \", ip: \" + ip + \", and port: \" + port + \" successfully deregistered\");\n\t\treturn true;\n\t}\n\tlogger.error(\"No servers registered with serviceName: \" + serviceName + \", ip: \" + ip + \", and port: \" + port);\n\treturn false;\n}", "CodeBleu_score": 50.02401231861151}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO Auto-generated method stub\n\treturn false;\n}", "CodeBleu_score": 15.915118860340804}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\t// TODO: implement deregister\n\treturn false;\n}", "CodeBleu_score": 15.915118860340804}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getCanonicalName());\nif (attributes!= null) {\n    List<Map<String, Object>> clients = (List<Map<String, Object>>) attributes.get(\"value\");\n    if (clients!= null) {\n        for (Map<String, Object> client : clients) {\n            String name = (String) client.get(\"name\");\n            if (name == null) {\n                throw new IllegalStateException(\"'name' attribute must be provided on @RibbonClients\");\n            }\n            registerClientConfiguration(registry, name, client.get(\"configuration\"));\n        }\n    }\n    Object defaultConfig = attributes.get(\"defaultConfiguration\");\n    if (defaultConfig!= null) {\n        String name = \"Default_\" + defaultConfig.toString();\n        registerClientConfiguration(registry, name, defaultConfig);\n        for (Map<String, Object> client : clients) {\n            String existingName = (String) client.get(\"name\");\n            if (client.get(\"configuration\") == null) {\n                client.put(\"configuration\", name);\n            }\n        }\n    }\n}\n}", "CodeBleu_score": 47.50257606696421}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(\n\t\t\tRibbonClients.class.getCanonicalName());\n\n\tList<Object> clients = (List) attributes.get(\"value\");\n\tfor (Object client : clients) {\n\t\tMap<String, Object> clientAttributes = (Map<String, Object>) client;\n\t\tString name = (String) clientAttributes.get(\"name\");\n\t\tregisterClientConfiguration(registry, name, clientAttributes.get(\"configuration\"));\n\t}\n\n\t// register default configuration\n\tObject defaultConfiguration = attributes.get(\"defaultConfiguration\");\n\tif (defaultConfiguration!= null) {\n\t\tregisterClientConfiguration(registry, name, defaultConfiguration);\n\t}\n}", "CodeBleu_score": 44.305482068604825}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\tap<String, Object> attrs = metadata.getAnnotationAttributes(RibbonClients.class.getName());\nif (attrs!= null && attrs.containsKey(\"defaultConfiguration\")) {\nregisterDefaultConfiguration(registry, attrs.get(\"defaultConfiguration\"));\n}\nMap<String, Object> clients = attrs == null? null : (Map<String, Object>) attrs.get(\"value\");\nif (clients!= null) {\nfor (Map.Entry<String, Object> entry : clients.entrySet()) {\nregisterClientConfiguration(registry, entry.getKey(), entry.getValue());\n}\n}\n}", "CodeBleu_score": 50.74172107633048}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn this.choose(serviceId, request.getContext());\n}", "CodeBleu_score": 14.67856276526076}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\t// TODO: Implement this method\n\treturn null;\n}", "CodeBleu_score": 11.883005940910579}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t\treturn this.choose(serviceId, request, null);\n}", "CodeBleu_score": 12.484524296095017}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString serviceId = server.getServiceId();\n\tString host = server.getHost();\n\tint port = server.getPort();\n\tString uri = original.toString();\n\tString path = original.getPath();\n\tString query = original.getQuery();\n\n\tString newURI = uri.replaceFirst(serviceId, host + \":\" + port);\n\tif (query!= null) {\n\t\tnewURI += \"?\" + query;\n\t}\n\ttry {\n\t\treturn new URI(newURI);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 38.966030370659766}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\tString serviceName = server.getServiceId();\n\tString serviceAddress = server.getHost();\n\tint servicePort = server.getPort();\n\n\tString uri = original.toString();\n\tString uriServiceName = uri.substring(uri.indexOf(\"//\") + 2, uri.indexOf(\":\"));\n\tString path = uri.substring(uri.indexOf(\"/\", 8));\n\tif (uri.contains(\"?\")) {\n\t\tpath = uri.substring(uri.indexOf(\"/\", 8), uri.indexOf(\"?\"));\n\t}\n\n\tif (!serviceName.equals(uriServiceName)) {\n\t\tthrow new RuntimeException(\"Requested service name \" + serviceName + \" does not match URI service name \" + uriServiceName);\n\t}\n\n\tString newURI = \"http://\" + serviceAddress + \":\" + servicePort + path;\n\tif (uri.contains(\"?\")) {\n\t\tnewURI += \"?\" + uri.substring(uri.indexOf(\"?\") + 1);\n\t}\n\n\ttry {\n\t\treturn new URI(newURI);\n\t} catch (URISyntaxException e) {\n\t\tthrow new RuntimeException(e);\n\t}\n}", "CodeBleu_score": 41.60197113331732}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t\t// TODO Auto-generated method stub\n\treturn null;\n}", "CodeBleu_score": 4.040153837282234}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t\t// Construct the URL for the discovery service\n\tString url = discoveryUrl + \"/list\";\n\n\t// Send a GET request to the discovery service\n\tString response = sendGetRequest(url);\n\n\t// Parse the JSON response into a list of TutuServer objects\n\tList<TutuServer> servers = new ArrayList<>();\n\ttry {\n\t\tJSONArray jsonArray = new JSONArray(response);\n\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\t\t\tString ip = jsonObject.getString(\"ip\");\n\t\t\tint port = jsonObject.getInt(\"port\");\n\t\t\tTutuServer server = new TutuServer(ip, port);\n\t\t\tservers.add(server);\n\t\t}\n\t} catch (JSONException e) {\n\t\te.printStackTrace();\n\t}\n\n\treturn servers;\n}", "CodeBleu_score": 34.334202220678726}, {"code": "private List<TutuServer> getServer(){\n\t\tList<TutuServer> serverList = new ArrayList<>();\n\ttry {\n\t\t// Create a URL object with the server address and the service name\n\t\tURL url = new URL(serverAddress + \"/list\");\n\n\t\t// Open a connection to the URL\n\t\tHttpURLConnection connection = (HttpURLConnection) url.openConnection();\n\n\t\t// Set the request method to GET\n\t\tconnection.setRequestMethod(\"GET\");\n\n\t\t// Set the content type to application/json\n\t\tconnection.setRequestProperty(\"Content-Type\", \"application/json\");\n\n\t\t// Set the read timeout to 5 seconds\n\t\tconnection.setReadTimeout(5000);\n\n\t\t// Set the connect timeout to 5 seconds\n\t\tconnection.setConnectTimeout(5000);\n\n\t\t// Send the request and get the response code\n\t\tint responseCode = connection.getResponseCode();\n\n\t\t// If the response code is 200 (OK), read the response body\n\t\tif (responseCode == 200) {\n\t\t\t// Read the response body as a JSON array\n\t\t\tJSONArray jsonArray = new JSONArray(IOUtils.toString(connection.getInputStream(), StandardCharsets.UTF_8));\n\n\t\t\t// Loop through the JSON array and extract the IP address and port for each server\n\t\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\t\t\t\tString ipAddress = jsonObject.getString(\"ip\");\n\t\t\t\tint port = jsonObject.getInt(\"port\");\n\n\t\t\t\t// Add the server to the list\n\t\t\t\tserverList.add(new TutuServer(ipAddress, port));\n\t\t\t}\n\t\t}\n\n\t\t// Close the connection\n\t\tconnection.disconnect();\n\t} catch (IOException | JSONException e) {\n\t\te.printStackTrace();\n\t}\n\n\t// Return the list of servers\n\treturn serverList;\n}", "CodeBleu_score": 35.88619515439164}, {"code": "private List<TutuServer> getServer(){\n\t\t// Create a new list to hold the retrieved TutuServer instances\n\tList<TutuServer> tutuServers = new ArrayList<>();\n\n\t// Construct the URL for the request\n\tString url = String.format(\"%s/list\", serverAddress);\n\n\t// Send a GET request to the specified URL\n\ttry {\n\t\t// Create a new URL object\n\t\tURL urlObject = new URL(url);\n\n\t\t// Open a connection to the URL\n\t\tHttpURLConnection connection = (HttpURLConnection) urlObject.openConnection();\n\t\tconnection.setRequestMethod(\"GET\");\n\n\t\t// Check if the response code is 200 (OK)\n\t\tif (connection.getResponseCode() == 200) {\n\t\t\t// Read the response as a JSON array\n\t\t\tJSONArray jsonArray = new JSONArray(connection.getInputStream());\n\n\t\t\t// Loop through each object in the JSON array\n\t\t\tfor (int i = 0; i < jsonArray.length(); i++) {\n\t\t\t\tJSONObject jsonObject = jsonArray.getJSONObject(i);\n\n\t\t\t\t// Extract the IP address and port from the JSON object\n\t\t\t\tString ipAddress = jsonObject.getString(\"ip\");\n\t\t\t\tint port = jsonObject.getInt(\"port\");\n\n\t\t\t\t// Create a new TutuServer instance with the extracted data\n\t\t\t\tTutuServer tutuServer = new TutuServer(ipAddress, port);\n\n\t\t\t\t// Add the TutuServer instance to the list\n\t\t\t\ttutuServers.add(tutuServer);\n\t\t\t}\n\t\t} else {\n\t\t\t// Handle the case when the response code is not 200 (OK)\n\t\t\tSystem.out.println(\"Error: Response code not 200 (OK)\");\n\t\t}\n\t} catch (IOException | JSONException e) {\n\t\t// Handle any exceptions that may occur\n\t\te.printStackTrace();\n\t}\n\n\t// Return the list of TutuServer instances\n\treturn tutuServers;\n}", "CodeBleu_score": 36.20041868521617}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routeLocator.getRoutes().keySet()) {\n\t\tif (this.pathMatcher.match(location, path)) {\n\t\t\tString routePath = this.pathMatcher.extractPath(location, path);\n\t\t\treturn new Route(routePath, this.routeLocator.getRoutes().get(location));\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 29.203885149848084}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routeLocator.getRoutes().keySet()) {\n\t\tif (this.pathMatcher.match(location, path)) {\n\t\t\tString serviceId = this.routeLocator.getRoutes().get(location);\n\t\t\tString targetPath = path.substring(location.length());\n\t\t\treturn new Route(serviceId, targetPath);\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 34.755931866106096}, {"code": "public Route getMatchingRoute(String path){\n\t\tfor (String location : this.routeLocations) {\n\t\tRoute route = getRoute(location);\n\t\tif (route!= null && pathMatcher.match(route.getPath(), path)) {\n\t\t\tString newPath = path.substring(pathMatcher.extractPathWithinPattern(route.getPath(), path));\n\t\t\treturn new Route(newPath, route.getId());\n\t\t}\n\t}\n\treturn null;\n}", "CodeBleu_score": 31.42068078333804}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t", "CodeBleu_score": 2.4248718776194633}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// Get the package name of the importing class\n\tString packageName = importingClassMetadata.getClassName().substring(0, importingClassMetadata.getClassName().lastIndexOf(\".\"));\n\n\t// Create a scanner to scan the package for classes annotated with @FeignClient\n\tClassPathScanningCandidateComponentProvider scanner = new ClassPathScanningCandidateComponentProvider(false);\n\tscanner.addIncludeFilter(new AnnotationTypeFilter(FeignClient.class));\n\n\t// Scan the package for classes annotated with @FeignClient\n\tfor (BeanDefinition beanDefinition : scanner.findCandidateComponents(packageName)) {\n\t\t// Get the class name of the annotated class\n\t\tString className = beanDefinition.getBeanClassName();\n\n\t\t// Check if the class is annotated with @FeignClient\n\t\tif (className!= null && AnnotationUtils.findAnnotation(ClassUtils.resolveClassName(className, this.classLoader), FeignClient.class)!= null) {\n\t\t\t// Create a GenericBeanDefinition for the annotated class\n\t\t\tGenericBeanDefinition definition = new GenericBeanDefinition();\n\t\t\tdefinition.setBeanClass(FeignClientFactoryBean.class);\n\t\t\tdefinition.getPropertyValues().add(\"type\", className);\n\n\t\t\t// Configure the bean definition with FeignClientFactoryBean settings\n\t\t\tdefinition.getPropertyValues().add(\"contextId\", className);\n\t\t\tdefinition.getPropertyValues().add(\"name\", \"\");\n\n\t\t\t// Register the bean definition with the BeanDefinitionRegistry using the class name as the bean name\n\t\t\tregistry.registerBeanDefinition(className, definition);\n\t\t}\n\t}\n}", "CodeBleu_score": 43.90872158095047}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\t// Get the package name of the importing class\n\tString packageName = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n\n\t// Scan for classes with the FeignClient annotation in the package of the importing class\n\tSet<BeanDefinition> candidateComponents = new LinkedHashSet<>(\n\t\t\tSpringFactoriesLoader.loadFactoryNames(FeignClient.class,\n\t\t\t\t\tgetClassLoader()));\n\n\t// Iterate over the candidate components and register bean definitions for each annotated class\n\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\t// If the candidate component is a GenericBeanDefinition, proceed with registration\n\t\tif (candidateComponent instanceof GenericBeanDefinition) {\n\t\t\tGenericBeanDefinition beanDefinition = (GenericBeanDefinition) candidateComponent;\n\t\t\t// If the bean definition has a target type set, proceed with registration\n\t\t\tif (beanDefinition.hasBeanClass()) {\n\t\t\t\t// Get the class of the bean definition\n\t\t\t\tClass<?> targetType = beanDefinition.getBeanClass();\n\t\t\t\t// If the target type is annotated with FeignClient, proceed with registration\n\t\t\t\tif (AnnotationUtils.isAnnotationDeclaredLocally(FeignClient.class, targetType)) {\n\t\t\t\t\t// Get the value of the FeignClient annotation on the target type\n\t\t\t\t\tFeignClient feignClient = AnnotationUtils.getAnnotation(targetType, FeignClient.class);\n\t\t\t\t\t// Get the name of the FeignClient annotation value\n\t\t\t\t\tString name = feignClient.name();\n\t\t\t\t\t// If the name is empty or default, use the class name as the name\n\t\t\t\t\tif (name.isEmpty()) {\n\t\t\t\t\t\tname = targetType.getSimpleName();\n\t\t\t\t\t}\n\t\t\t\t\t// Register the bean definition with the BeanDefinitionRegistry\n\t\t\t\t\tregisterClientConfiguration(registry, name, feignClient.configuration());\n\t\t\t\t\tregisterFeignClient(registry, feignClient, name, targetType,\n\t\t\t\t\t\t\timportingClassMetadata.getClassName());\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 41.17527679677618}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\treturn new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 72.530822855626}]}
