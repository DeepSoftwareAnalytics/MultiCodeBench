{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self.handler.connect(*args)\n\n", "CodeBleu_score": 47.68665877506066}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(2, self.loop_wait - 2) * 1000\n    return wait_time, self.connect_original(*args)\n\n", "CodeBleu_score": 47.82882069118573}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait_time = max(self.loop_wait - 2, 0) * 1000\n    return wait_time, self.connection.connect(*args)\n\n", "CodeBleu_score": 48.627919542878686}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    self.retry_timeout = config['retry_timeout']\n    self.loop_wait = config['loop_wait']\n    if self.handler.connect_timeout != config['connect_timeout']:\n        self.handler.connect_timeout = config['connect_timeout']\n    try:\n        self.set_ttl(config['session_timeout'])\n    except (ConnectionClosedError, SessionExpiredError):\n        if self.loop_wait != config['loop_wait']:\n            self.close()\n\n", "CodeBleu_score": 41.45549248775482}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(**config)\n    self.retry_timeout = config.retry_timeout\n    self.loop_wait = config.loop_wait\n    if self.loop_wait != self._loop_wait:\n        self._loop_wait = self.loop_wait\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.handler.connect_timeout = self.loop_wait\n    if self.ttl != config.ttl:\n        try:\n            self.set_ttl(config.ttl)\n        except (ConnectionClosedError, NoNodeError, NodeExistsError, SessionExpiredError, RetryFailedError):\n            if self.loop_wait != self._loop_wait:\n                self._loop_wait = self.loop_wait\n                self.handler.close()\n            raise\n        else:\n            self.ttl = config.ttl\n\n", "CodeBleu_score": 33.60901249279307}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if self.retry_timeout != config.retry_timeout:\n        self.retry_timeout = config.retry_timeout\n        self.retry = KazooRetry(max_tries=None, delay=0.1, max_jitter=0.2, max_delay=self.retry_timeout)\n\n    if self.loop_wait != config.loop_wait:\n        self.loop_wait = config.loop_wait\n\n    if self.ttl != config.ttl:\n        try:\n            self.set_ttl(config.ttl)\n        except (ConnectionClosedError, SessionExpiredError):\n            pass\n        except Exception as e:\n            self.logger.exception('Error setting TTL: %s', e)\n        else:\n            self.ttl = config.ttl\n\n    if isinstance(self.handler, PatroniSequentialThreadingHandler) and self.handler.connect_timeout != config.loop_wait:\n        self.handler.connect_timeout = config.loop_wait\n\n", "CodeBleu_score": 31.93055606313169}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    try:\n        self.logger.info(\"Loading cluster from %s\", path)\n\n        # Load the cluster initialization state\n        init_state = self._zk_client.get(path + \"/init_state\")[0]\n        init_state = json.loads(init_state)\n\n        # Load the cluster configuration\n        config = self._zk_client.get(path + \"/config\")[0]\n        config = json.loads(config)\n\n        # Load the timeline history\n        timeline_history = self._zk_client.get(path + \"/timeline_history\")[0]\n        timeline_history = json.loads(timeline_history)\n\n        # Load the synchronization state\n        sync_state = self._zk_client.get(path + \"/sync_state\")[0]\n        sync_state = json.loads(sync_state)\n\n        # Load the members\n        members = self._zk_client.get_children(path + \"/members\")\n        members = [self._zk_client.get(path + \"/members/\" + member)[0] for member in members]\n        members = [json.loads(member) for member in members]\n\n        # Load the leader information\n        leader_info = self._zk_client.get(path + \"/leader\")[0]\n        leader_info = json.loads(leader_info)\n\n        # Load the cluster status\n        cluster_status = self._zk_client.get(path + \"/status\")[0]\n        cluster_status = json.loads(cluster_status)\n\n        # Load the failover state\n        failover_state = self._zk_client.get(path + \"/failover_state\")[0]\n        failover_state = json.loads(failover_state)\n\n        # Load the failsafe configuration\n        failsafe_config = self._zk_client.get(path + \"/failsafe_config\")[0]\n        failsafe_config = json.loads(failsafe_config)\n\n        # Create a Cluster object with the loaded information\n        cluster = Cluster(\n            init_state=", "CodeBleu_score": 21.532502029113154}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n\n    # Retrieve the initialization state\n    init_state = self._get_init_state(path)\n\n    # Retrieve the configuration\n    config = self._get_config(path)\n\n    # Retrieve the timeline history\n    timeline_history = self._get_timeline_history(path)\n\n    # Retrieve the synchronization state\n    sync_state = self._get_sync_state(path)\n\n    # Retrieve the members\n    members = self._get_members(path)\n\n    # Retrieve the leader information\n    leader_info = self._get_leader_info(path)\n\n    # Retrieve the cluster status\n    cluster_status = self._get_cluster_status(path)\n\n    # Retrieve the failover state\n    failover_state = self._get_failover_state(path)\n\n    # Retrieve the failsafe configuration\n    failsafe_config = self._get_failsafe_config(path)\n\n    # Create a Cluster object with the gathered information\n    cluster = Cluster(\n        init_state=init_state,\n        config=config,\n        timeline_history=timeline_history,\n        sync_state=sync_state,\n        members=members,\n        leader_info=leader_info,\n        cluster_status=cluster_status,\n        failover_state=failover_state,\n        failsafe_config=failsafe_config,\n    )\n\n    return cluster\n\n", "CodeBleu_score": 7.392500232955883}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    logger = logging.getLogger(__name__)\n    logger.debug('Loading cluster configuration from %s', path)\n    try:\n        zk = self._zk\n        if not zk.exists(path):\n            raise NoNodeError(path)\n\n        cluster = Cluster(path)\n\n        # Load initialization state\n        cluster.init_state = self._get_init_state(path)\n\n        # Load configuration\n        cluster.config = self._get_config(path)\n\n        # Load timeline history\n        cluster.timeline_history = self._get_timeline_history(path)\n\n        # Load synchronization state\n        cluster.sync_state = self._get_sync_state(path)\n\n        # Load members\n        cluster.members = self._get_members(path)\n\n        # Load leader information\n        cluster.leader = self._get_leader(path)\n\n        # Load cluster status\n        cluster.status = self._get_status(path)\n\n        # Load failover state\n        cluster.failover_state = self._get_failover_state(path)\n\n        # Load failsafe configuration\n        cluster.failsafe = self._get_failsafe(path)\n\n        return cluster\n    except (ConnectionClosedError, NoNodeError, SessionExpiredError, RetryFailedError) as e:\n        logger.error('Error loading cluster configuration: %s', e)\n        raise\n\n", "CodeBleu_score": 15.617107888644044}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, self.data, ephemeral=True)\n        return True\n    except (ConnectionClosedError, NoNodeError) as e:\n        raise ZooKeeperError(str(e)) from e\n    except NodeExistsError:\n        return False\n    except RetryFailedError:\n        raise ZooKeeperError(\"Retries failed\") from RetryFailedError\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logging.error(\"Error while attempting to acquire leader lock: %s\", e)\n        return False\n\n", "CodeBleu_score": 54.74357987746517}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.leader_path, self.data, ephemeral=True, makepath=True)\n        return True\n    except (ConnectionClosedError, NoNodeError) as e:\n        raise ZooKeeperError(e)\n    except NodeExistsError:\n        return False\n    except RetryFailedError:\n        raise ZooKeeperError(f\"Retry failed for {self.leader_path}\")\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logging.error(f\"Error creating leader node for {self.leader_path}: {e}\")\n        return False\n\n", "CodeBleu_score": 51.33811396385298}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(\n            self.leader_path,\n            self.instance_id.encode(\"utf-8\"),\n            ephemeral=True,\n            acl=self.acl,\n        )\n        return True\n    except ConnectionClosedError:\n        raise ZooKeeperError(\"ZooKeeper connection closed\")\n    except RetryFailedError:\n        raise ZooKeeperError(\"ZooKeeper retries failed\")\n    except NodeExistsError:\n        return False\n    except Exception as e:\n        if not isinstance(e, NodeExistsError):\n            logging.error(f\"Error acquiring leader lock: {e}\")\n        return False\n\n", "CodeBleu_score": 46.52455300003046}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client.client_id != leader.session:\n        logging.warning(f\"Client ID mismatch: {self.client.client_id} != {leader.session}\")\n        try:\n            self.client.delete(self.leader_path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        try:\n            self.client.create(self.leader_path, self.client.client_id.encode(\"utf-8\"), make_acl(\"all\", \"all\", \"all\"), ephemeral=True)\n        except (NodeExistsError, ConnectionClosedError, RetryFailedError) as e:\n            logging.warning(f\"Error updating leader: {e}\")\n            return False\n        return True\n    return False\n\n", "CodeBleu_score": 35.70332006178701}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if self.client_id != leader.session:\n        self.logger.warning(\n            f\"Client ID mismatch: {self.client_id} != {leader.session}\"\n        )\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            pass\n        except ConnectionClosedError:\n            self.logger.warning(\"Connection closed\")\n            raise ZooKeeperError(\"Connection closed\") from None\n        except RetryFailedError:\n            self.logger.warning(\"Retry failed\")\n            raise ZooKeeperError(\"Retry failed\") from None\n\n    try:\n        self.zk.create(\n            self.leader_path,\n            self.client_id.encode(\"utf-8\"),\n            ephemeral=True,\n            makepath=True,\n        )\n    except NodeExistsError:\n        self.logger.warning(\"Leader already exists\")\n    except ConnectionClosedError:\n        self.logger.warning(\"Connection closed\")\n        raise ZooKeeperError(\"Connection closed\") from None\n    except RetryFailedError:\n        self.logger.warning(\"Retry failed\")\n        raise ZooKeeperError(\"Retry failed\") from None\n    except Exception as e:\n        self.logger.warning(f\"Failed to create leader: {e}\")\n        return False\n\n    return True\n\n", "CodeBleu_score": 45.29628909772781}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n\n    if self.client_id != leader.session:\n        logging.warning(f\"Client ID mismatch: {self.client_id} != {leader.session}\")\n        try:\n            self.zk.delete(self.leader_path)\n        except NoNodeError:\n            pass\n        except (ConnectionClosedError, RetryFailedError):\n            pass\n        except Exception as e:\n            logging.error(f\"Error deleting leader: {e}\")\n            raise ZooKeeperError(f\"Error deleting leader: {e}\") from e\n\n    try:\n        self.zk.create(self.leader_path, self.client_name.encode(\"utf-8\"), ephemeral=True)\n    except NodeExistsError:\n        pass\n    except (ConnectionClosedError, RetryFailedError):\n        pass\n    except Exception as e:\n        logging.error(f\"Error creating leader: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 46.90330259838953}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    if self.last_poll + self.poll_interval > time.time():\n        return False\n\n    self.last_poll = time.time()\n\n    status = self.get_status()\n    if not status:\n        return False\n\n    if self.zk_connection_string != status[\"zk_connection_string\"]:\n        logging.info(\n            \"ZooKeeper connection string changed from '%s' to '%s'\",\n            self.zk_connection_string,\n            status[\"zk_connection_string\"],\n        )\n        self.zk_connection_string = status[\"zk_connection_string\"]\n        self.update_state()\n        return True\n\n    return False\n\n", "CodeBleu_score": 29.43034656619029}, {"code": "def poll(self) -> bool\n\t\n    if self.poll_interval > 0 and time.time() - self.last_poll < self.poll_interval:\n        return False\n    try:\n        data = self.get_exhibitors()\n        if data is None:\n            return False\n        servers = data[\"servers\"]\n        if not servers:\n            return False\n        if self.zk_servers != servers:\n            logging.info(\"ZooKeeper servers changed from %s to %s\", self.zk_servers, servers)\n            self.zk_servers = servers\n            self.zk_connection_string = \",\".join(servers)\n            self.zk_client.set_servers(servers)\n            self.zk_client.connect()\n            self.zk_client.start()\n            self.zk_client.add_listener(self.zk_listener)\n            self.zk_client.set_state_listener(self.zk_state_listener)\n            self.zk_client.set_data_listener(self.zk_data_listener)\n            self.zk_client.set_child_listener(self.zk_child_listener)\n            self.zk_client.set_auth_info(self.zk_auth_info)\n            self.zk_client.set_acl_provider(self.zk_acl_provider)\n            self.zk_client.retry_policy = self.zk_retry_policy\n            self.zk_client.retry_policy.set_initial_sleep_ms(\n                self.zk_retry_policy.initial_sleep_ms\n            )\n            self.zk_client.retry_policy.set_max_sleep_ms(self.zk_retry_policy.max_sleep_ms)\n            self.zk_client.retry_policy.set_max_retries(self.zk_retry_policy.max_retries)\n            self.zk_client.retry_policy.set_retry_interval_ms(\n                self.zk_retry_policy.re", "CodeBleu_score": 26.621439516974597}, {"code": "def poll(self) -> bool\n\t\n\n    # Check if it's time to poll again\n    if self.last_poll + self.poll_interval > time.time():\n        return False\n\n    # Get the list of exhibitors\n    exhibitors = self.get_exhibitors()\n\n    # Check if the list of exhibitors is valid\n    if exhibitors is None:\n        return False\n\n    # Get the server and port information\n    server, port = self.get_server_and_port(exhibitors)\n\n    # Check if the server and port information is valid\n    if server is None or port is None:\n        return False\n\n    # Check if the server and port information has changed\n    if server != self.server or port != self.port:\n        # Log the change\n        logging.info(f\"Server and port changed from {self.server}:{self.port} to {server}:{port}\")\n\n        # Update the ZooKeeper connection string\n        self.zookeeper_connection_string = f\"{server}:{port}\"\n\n        # Update internal state\n        self.server = server\n        self.port = port\n\n        return True\n\n    return False\n\n", "CodeBleu_score": 26.18960914437248}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.client.hosts = self.ensemble_provider.hosts\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 59.81979644555211}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.hosts = self.ensemble_provider.hosts()\n    return super()._load_cluster(path, loader)\n", "CodeBleu_score": 59.77084464928859}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.hosts = self.ensemble_provider.hosts\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 58.91991454061567}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t        this.nodeCache = nodeCache;\n        this.nodeCacheListener = nodeCacheListener;\n    }", "CodeBleu_score": 78.43209421890232}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t  if (zookeeperListener == null) {\n    return;\n  }\n  String group=zookeeperListener.getGroup();\n  String dataId=zookeeperListener.getDataId();\n  LOG.info(\"Start to unsubscribe from Zookeeper configuration, group={}, dataId={}\", group, dataId);\n  try {\n    zookeeperListener.unsubscribe();\n  }\n catch (  Exception e) {\n    LOG.error(\"Failed to unsubscribe from Zookeeper configuration, group={}, dataId={}\", group, dataId, e);\n  }\n}", "CodeBleu_score": 44.58625909343243}, {"code": "public void destroy(){\n\t    if (zookeeperListener != null) {\n        String group = zookeeperListener.getGroup();\n        String dataId = zookeeperListener.getDataId();\n        LOG.info(\"Start to unsubscribe from Zookeeper configuration, group={}, dataId={}\", group, dataId);\n        try {\n            zookeeperListener.unsubscribe();\n        } catch (Exception e) {\n            LOG.error(\"Failed to unsubscribe from Zookeeper configuration, group={}, dataId={}\", group, dataId, e);\n        }\n    }\n}", "CodeBleu_score": 40.142579902315326}, {"code": "public void destroy(){\n\t  if (zookeeperListener == null) {\n    return;\n  }\n  String group=zookeeperListener.getGroup();\n  String dataId=zookeeperListener.getDataId();\n  LOG.info(\"Start to unsubscribe Zookeeper configuration, group={}, dataId={}\", group, dataId);\n  try {\n    zookeeperListener.unsubscribe();\n  } catch (Exception e) {\n    LOG.warn(\"Failed to unsubscribe Zookeeper configuration, group={}, dataId={}\", group, dataId, e);\n  }\n}", "CodeBleu_score": 47.25429781228267}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getInstance().getPayload();\n    } else {\n        return super.getServerMetadata(server);\n    }\n}", "CodeBleu_score": 65.33565070049102}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getInstance().getPayload().getMetadata();\n    } else {\n        return super.getServerMetadata(server);\n    }\n}", "CodeBleu_score": 71.32344256726617}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        return zookeeperServer.getInstance().getPayload();\n    } else {\n        return super.getServerMetadata(server);\n    }\n}", "CodeBleu_score": 65.33565070049102}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = \"/\" + group + \"/\" + serviceId;\n    NodeCache nodeCache = new NodeCache(client, path);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            ChildData childData = nodeCache.getCurrentData();\n            if (childData != null) {\n                String config = new String(childData.getData());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    listeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 63.450265993495826}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t        String path = ZookeeperUtils.getPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n        NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                ChildData childData = nodeCache.getCurrentData();\n                if (childData == null) {\n                    return;\n                }\n                String config = new String(childData.getData());\n                zookeeperSubscribeCallback.callback(config);\n            }\n        };\n        nodeCache.getListenable().addListener(nodeCacheListener);\n        nodeCache.start();\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n        listeners.add(zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 64.6915760867296}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t        String path = getConfigPath(group, serviceId);\n        NodeCache nodeCache = new NodeCache(curatorFramework, path, false);\n        nodeCache.getListenable().addListener(new NodeCacheListener() {\n            @Override\n            public void nodeChanged() throws Exception {\n                ChildData childData = nodeCache.getCurrentData();\n                if (childData == null) {\n                    return;\n                }\n                String config = new String(childData.getData(), StandardCharsets.UTF_8);\n                zookeeperSubscribeCallback.callback(config);\n            }\n        });\n        nodeCache.start();\n        ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache);\n        listeners.add(zookeeperListener);\n        return zookeeperListener;\n    }", "CodeBleu_score": 57.98162785857247}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(new LoadBalanceListenerExecutor());\n    serverList.setServiceId(config.getClientName());\n\n    return serverList;\n}", "CodeBleu_score": 77.3606890227696}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(new LoadBalanceListenerExecutor());\n    serverList.setServerList(serverList.getServerList());\n    serverList.setServiceId(config.getClientName());\n\n    return serverList;\n}", "CodeBleu_score": 73.5407662003079}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(new LoadBalanceListenerExecutor());\n    serverList.setServerList(serverList);\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 74.48085511491492}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = context.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 85.73497538641142}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 91.46429325894339}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.7694205192842}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n    }\n    serviceRegistry.close();\n}", "CodeBleu_score": 99.7694205192842}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        LOG.error(\"Failed to get bean for RegisterListenerExecutor\", e);\n    }\n    serviceRegistry.close();\n}", "CodeBleu_score": 84.47738498298078}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = configAdapter.getGroup();\n    String dataId = configAdapter.getDataId();\n    LOG.info(\"Subscribe config, group={}, dataId={}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n\n            @Override\n            public void callback(String config) {\n                ConfigType configType = ConfigType.from(config);\n                configAdapter.updateConfig(configType);\n            }\n        } , globalConfig);\n    } catch (Exception e) {\n        LOG.warn(\"Subscribe failed, group={}, dataId={}\", group, dataId, e);\n    }\n    return null;\n}", "CodeBleu_score": 55.03720575399468}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    try {\n        String group = configAdapter.getGroup();\n        String dataId = configAdapter.getDataId();\n        LOG.info(\"Start to subscribe config, group={}, dataId={}\", group, dataId);\n        return zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n\n            @Override\n            public void callback(String config) {\n                try {\n                    configAdapter.updateConfig(config, globalConfig ? ConfigType.GLOBAL : ConfigType.LOCAL);\n                } catch (Exception e) {\n                    LOG.warn(\"Callback config failed\", e);\n                }\n            }\n        });\n    } catch (Exception e) {\n        LOG.warn(\"Subscribe config failed\", e);\n    }\n    return null;\n}", "CodeBleu_score": 53.00292482841442}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = configAdapter.getGroup();\n    String dataId = configAdapter.getDataId();\n    LOG.info(\"Start to subscribe config, group={}, dataId={}\", group, dataId);\n    try {\n        return zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n\n            @Override\n            public void callback(String config) {\n                LOG.info(\"Subscribe callback, group={}, dataId={}, config=\n{}\", group, dataId, config);\n                configAdapter.updateConfig(config, globalConfig ? ConfigType.GLOBAL : ConfigType.LOCAL);\n            }\n        });\n    } catch (Exception e) {\n        LOG.warn(\"Subscribe failed, group={}, dataId={}\", group, dataId, e);\n    }\n    return null;\n}", "CodeBleu_score": 54.53892860084283}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING);\n    if (StringUtils.isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connect string isn't configured\");\n    }\n    int retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.DEFAULT_RETRY_COUNT);\n    int sleepTime = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_TIME, Integer.class, ZookeeperConstant.DEFAULT_SLEEP_TIME);\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(new ExponentialBackoffRetry(sleepTime, retryCount)).build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 81.71105464347495}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING);\n    if (StringUtils.isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connect string can't be null or empty\");\n    }\n    int retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_RETRY_COUNT);\n    int sleepMs = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_MS, Integer.class, ZookeeperConstant.ZOOKEEPER_DEFAULT_SLEEP_MS);\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(new ExponentialBackoffRetry(sleepMs, retryCount)).build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 82.68279017635551}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = environment.getProperty(ZookeeperConstant.ZOOKEEPER_CONNECT_STRING);\n    if (StringUtils.isEmpty(connectString)) {\n        throw new DiscoveryException(\"Zookeeper connect string can't be null or empty\");\n    }\n    int retryCount = environment.getProperty(ZookeeperConstant.ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.ZOOKEEPER_RETRY_COUNT_VALUE);\n    int sleepMs = environment.getProperty(ZookeeperConstant.ZOOKEEPER_SLEEP_MS, Integer.class, ZookeeperConstant.ZOOKEEPER_SLEEP_MS_VALUE);\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder().connectString(connectString).retryPolicy(new ExponentialBackoffRetry(sleepMs, retryCount)).build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 81.8673851028437}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n    @Autowired\n    private ConfigurableEnvironment environment;\n\n    @Autowired(required = false)\n    private ZookeeperProcessor zookeeperProcessor;\n\n    @Bean\n    @ConditionalOnProperty(value = GatewayStrategyConstant.SPRING_CLOUD_GATEWAY_STRATEGY_ROUTE_ENABLED, havingValue = GatewayStrategyConstant.SPRING_CLOUD_GATEGATEWAY_STRATEGY_ROUTE_ZOOKEEPER_ENABLED, matchIfMissing = true)\n    @ConditionalOnMissingBean\n    public GatewayStrategyRouteProcessor gatewayStrategyRouteZookeeperProcessor() {\n        return new GatewayStrategyRouteZookeeperProcessor(environment, zookeeperProcessor);\n    }\n}", "CodeBleu_score": 22.362795861766994}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t    @Bean\n    @ConditionalOnMissingBean\n    @ConditionalOnProperty(value = GatewayStrategyConstant.SPRING_APPLICATION_GATEWAY_STRATEGY_ROUTE_ZOOKEEPER_ENABLED, matchIfMissing = true)\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n        return new GatewayStrategyRouteZookeeperProcessor();\n    }\n}", "CodeBleu_score": 38.84646827936159}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t    @Bean\n    @ConditionalOnMissingBean\n    @ConditionalOnProperty(value = StrategyConstant.SPRING_APPLICATION_STRATEGY_GATEWAY_ROUTE_ENABLED, havingValue = \"false\", matchIfMissing = true)\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(ZookeeperProcessor zookeeperProcessor, GatewayStrategyContextListener gatewayStrategyContextListener) {\n        return new GatewayStrategyRouteZookeeperProcessor(zookeeperProcessor, gatewayStrategyContextListener);\n    }\n}", "CodeBleu_score": 32.50005683490565}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(zookeeperProperties.getHosts())\n            .sessionTimeoutMs(zookeeperProperties.getSessionTimeout())\n            .namespace(zookeeperProperties.getNamespace())\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 61.853605963132864}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    // Create a new CuratorFramework instance with the specified properties\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(zkClientProperties.getHosts())\n            .sessionTimeoutMs(zkClientProperties.getSessionTimeout())\n            .connectionTimeoutMs(zkClientProperties.getConnectionTimeout())\n            .namespace(zkClientProperties.getNamespace())\n            .retryPolicy(new ExponentialBackoffRetry(1000, 3))\n            .build();\n\n    // Start the CuratorFramework\n    curatorFramework.start();\n\n    return curatorFramework;\n}", "CodeBleu_score": 57.92778000074217}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(zookeeperClientProperties.getHosts())\n            .sessionTimeoutMs(zookeeperClientProperties.getSessionTimeout())\n            .namespace(zookeeperClientProperties.getNamespace())\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 61.699334540790964}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t        try {\n        if (locksMap.get(path) == null) {\n        InterProcessMutex lock = new InterProcessMutex(curatorFrameworkClient.getClient(), path);\n        lock.acquire();\n        locksMap.put(path, lock);\n        } else {\n        InterProcessLock lock = locksMap.get(path);\n        lock.acquire();\n        }\n        } catch (Exception e) {\n        throw new DistributedLockException(\"Error acquiring lock for path \" + path, e);\n        }\n        }", "CodeBleu_score": 34.81856004668716}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessLock lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client.getCuratorFramework(), path);\n        try {\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error acquiring lock for path: \" + path, e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Error re-acquiring lock for path: \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 42.00181233713284}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessLock lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(curatorFrameworkClient.getClient());\n        locksMap.put(path, lock);\n    }\n    try {\n        lock.acquire();\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}", "CodeBleu_score": 27.74501433032735}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework client = null;\n    try {\n        client = initZkClient(dtpProperties);\n        String nodePath = getNodePath(dtpProperties);\n        if (PROPERTIES.getType().equals(dtpProperties.getConfigType())) {\n            return genPropertiesTypeMap(client, nodePath);\n        } else if (JSON.getType().equals(dtpProperties.getConfigType())) {\n            String configKey = dtpProperties.getConfigKey();\n            String configPath = ZKPaths.makePath(nodePath, configKey);\n            GetDataBuilder<String> getDataBuilder = client.getData();\n            byte[] data = getDataBuilder.forPath(configPath);\n            return ConfigHandler.parseConfig(new String(data, StandardCharsets.UTF_8));\n        }\n    } catch (Exception e) {\n        log.error(\"genPropertiesMap error\", e);\n    } finally {\n        if (client != null) {\n            client.close();\n        }\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 40.470195882383855}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    val curatorFramework = initZkClient(dtpProperties);\n    String nodePath = getNodePath(dtpProperties);\n    if (dtpProperties.getConfigType() == PROPERTIES) {\n        return genPropertiesTypeMap(curatorFramework, nodePath);\n    } else if (dtpProperties.getConfigType() == JSON) {\n        GetDataBuilder dataBuilder = curatorFramework.getData();\n        byte[] data = dataBuilder.forPath(nodePath);\n        return ConfigHandler.parseConfig(new String(data, StandardCharsets.UTF_8), dtpProperties.getConfigType());\n    } else {\n        return Maps.newHashMap();\n    }\n}", "CodeBleu_score": 40.11530443150757}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    val properties = dtpProperties.getProperties();\n    val configType = dtpProperties.getConfigType();\n    CuratorFramework client = null;\n    try {\n        val zkAddress = properties.getProperty(\"zkAddress\");\n        val nodePath = properties.getProperty(\"nodePath\");\n        val retryPolicy = new ExponentialBackoffRetry(1000, 3);\n        client = CuratorFrameworkFactory.builder()\n                .connectString(zkAddress)\n                .sessionTimeoutMs(5000)\n                .connectionTimeoutMs(5000)\n                .retryPolicy(retryPolicy)\n                .build();\n        client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n            @Override\n            public void stateChanged(CuratorFramework client, ConnectionState newState) {\n                if (newState == ConnectionState.LOST) {\n                    // \u8fde\u63a5\u4e22\u5931\uff0c\u5c1d\u8bd5\u91cd\u65b0\u8fde\u63a5\n                    while (true) {\n                        try {\n                            if (client.getZookeeperClient().blockUntilConnectedOrTimedOut()) {\n                                System.out.println(\"Reconnected to ZooKeeper\");\n                                break;\n                            }\n                        } catch (InterruptedException e) {\n                            Thread.currentThread().interrupt();\n                            break;\n                        }\n                    }\n                }\n            }\n        });\n        client.start();\n        if (configType == PROPERTIES) {\n            return genPropertiesTypeMap(client, nodePath);\n        } else if (configType == JSON) {\n            String configKey = properties.getProperty(\"configKey\");\n            String configNodePath = ZKPaths.makePath(nodePath, configKey);\n            GetDataBuilder getDataBuilder = client.getData();\n            byte[] bytes = getDataBuilder.forPath(configNodePath);\n            String configValue = new String(bytes, StandardCharsets.UTF_8);\n            return ConfigHandler.parseMap(configValue, configType);\n        }\n    } catch (Exception e) {\n        log.error(\"genPropertiesMap error\", e);\n    } finally {\n        if (client != null) {\n            client.close();\n        }\n    }", "CodeBleu_score": 36.116946175932505}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = BinderHelper.bindDtpProperties(environment);\n    Map<String, Object> propertiesMap = dtpProperties.toMap();\n    if (!environment.containsProperty(DtpProperties.PREFIX)) {\n        String zkPath = CuratorUtil.getZkPath(dtpProperties);\n        OriginTrackedMapPropertySource zkPropertySource = new OriginTrackedMapPropertySource(zkPath, propertiesMap);\n        MutablePropertySources propertySources = environment.getPropertySources();\n        propertySources.addLast(zkPropertySource);\n    }\n}", "CodeBleu_score": 47.68504848182506}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = BinderHelper.bindConfig(environment, DtpProperties.class, DTP_PREFIX);\n    Map<String, Object> properties = dtpProperties.toMap();\n\n    if (!environment.containsProperty(DTP_PREFIX + \".enabled\")) {\n        // If the property does not exist, create a Zookeeper property source with the generated properties.\n        MutablePropertySources propertySources = environment.getPropertySources();\n        OriginTrackedMapPropertySource zkPropertySource = new OriginTrackedMapPropertySource(\"zkPropertySource\", properties);\n        propertySources.addFirst(zkPropertySource);\n    }\n}", "CodeBleu_score": 47.01542640004006}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = BinderHelper.bindDtpProperties(environment);\n    Map<String, Object> propertiesMap = dtpProperties.toMap();\n    MutablePropertySources propertySources = environment.getPropertySources();\n    if (!propertySources.contains(ZOOKEEPER_PROPERTY_SOURCE_NAME)) {\n        propertySources.addFirst(new OriginTrackedMapPropertySource(ZOOKEEPER_PROPERTY_SOURCE_NAME, propertiesMap));\n    }\n}", "CodeBleu_score": 48.98690359020661}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var serviceRouteProvider = provider.Resolve<IServiceRouteFactory>();\n        var logger = provider.Resolve<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.Resolve<ISerializer<ServiceRoute>>();\n        var zooKeeperClientProvider = provider.Resolve<IZooKeeperClientFactory>();\n        return new ZooKeeperServiceRouteManager(serviceRouteProvider, logger, serializer, zooKeeperClientProvider);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 35.45553072976938}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var section = configInfo.Configuration.GetSection(\"Surging.Zookeeper\")\n    var config = section.Get(Of(Of(ZooKeeperOption)))\n    if (config.IsNull()) {\n        config = section.Get(Of(Of(ZooKeeperConfig)))\n    }\n    if (config.IsNull()) {\n        config = section.Get(Of(Of(ZooKeeperOption)))\n    }\n    if (config.IsNull()) {\n        config = section.Get(Of(Of(ZooKeeperConfig)))\n    }\n    if (config.IsNull()) {\n        throw new Exception(\"\u672a\u80fd\u627e\u5230ZooKeeper\u914d\u7f6e\u8282\u70b9\")\n    }\n    if (config.ConnectionString.IsNullOrEmpty()) {\n        throw new Exception(\"\u672a\u80fd\u627e\u5230ZooKeeper\u8fde\u63a5\u5b57\u7b26\u4e32\")\n    }\n    if (config.SessionTimeout.IsNullOrEmpty()) {\n        config.SessionTimeout = 5000\n    }\n    if (config.ConnectionTimeout.IsNullOrEmpty()) {\n        config.ConnectionTimeout = 5000\n    }\n    if (config.OperatingTimeout.IsNullOrEmpty()) {\n        config.OperatingTimeout = 5000\n    }\n    if (config.BasePath.IsNullOrEmpty()) {\n        config.BasePath = \"/surging\"\n    }\n    if (config.RoutePath.IsNullOrEmpty()) {\n        config.RoutePath = \"/services\"\n    }\n    if (config.SubscriberPath.IsNullOrEmpty()) {\n        config.SubscriberPath = \"/subscribers\"\n    }\n    if (config.CommandPath.IsNullOrEmpty()) {\n        config.CommandPath = \"/commands\"\n    }\n    if (config.ChRoot.IsNullOrEmpty()) {\n        config.ChRoot = \"/\"\n    }\n    if (config.WatcherType.IsNullOrEmpty()) {\n        config.WatcherType = \"Children\"\n    }\n    if (config.WatcherMode.IsNullOrEmpty()) {\n        config.WatcherMode = \"Push\"\n    }\n    if (", "CodeBleu_score": 24.671433771976417}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var section = configInfo.Configuration.GetSection(\"Surging:Zookeeper\");\n    var config = section.Get<ZooKeeperOption>();\n    if (config == null || string.IsNullOrEmpty(config.ConnectionString)) {\n        throw new ArgumentException(\"Zookeeper configuration is not valid.\", nameof(config));\n    }\n\n    builder.RegisterType<ZooKeeperClientFactory>().As<IZooKeeperClientFactory>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteRepository>().As<IServiceRouteRepository>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteRepository>().As<IServiceRouteRepository>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteRepository>().As<IServiceRouteRepository>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteProvider>().As<IServiceRouteProvider>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteRepository>().As<IServiceRouteRepository>().SingleInstance();\n    builder.RegisterType<ZooKeeperServiceRouteManager>().As<IServiceRouteManager>().SingleInstance();\n    builder.Register", "CodeBleu_score": 38.207198056567414}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var services = builder.Services;\n    services.AddSingleton<ISerializer<byte[]>, JsonSerializer>();\n    services.AddSingleton<ISerializer<string>, JsonSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, MessagePackSerializer>();\n    services.AddSingleton<ISerializer<string>, MessagePackSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, ProtobufSerializer>();\n    services.AddSingleton<ISerializer<string>, ProtobufSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, XmlSerializer>();\n    services.AddSingleton<ISerializer<string>, XmlSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, YamlSerializer>();\n    services.AddSingleton<ISerializer<string>, YamlSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultSerializer>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultSerializer>();\n    services.AddSing", "CodeBleu_score": 31.478210595953865}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var section = configInfo.Configuration.GetSection(\"ZooKeeper\");\n    if (!section.Exists()) {\n        throw new Exception(\"\u672a\u627e\u5230 ZooKeeper \u8282\u70b9\");\n    }\n    var zooKeeperConfig = section.Get<ZooKeeperConfig>();\n    if (zooKeeperConfig == null) {\n        throw new Exception(\"ZooKeeper \u8282\u70b9\u672a\u914d\u7f6e\");\n    }\n    if (string.IsNullOrEmpty(zooKeeperConfig.ConnectionString)) {\n        throw new Exception(\"\u672a\u914d\u7f6e ZooKeeper \u8fde\u63a5\u5b57\u7b26\u4e32\");\n    }\n    if (zooKeeperConfig.SessionTimeout <= 0) {\n        zooKeeperConfig.SessionTimeout = 10000;\n    }\n    if (zooKeeperConfig.ConnectionTimeout <= 0) {\n        zooKeeperConfig.ConnectionTimeout = 10000;\n    }\n    if (zooKeeperConfig.OperatingTimeout <= 0) {\n        zooKeeperConfig.OperatingTimeout = 10000;\n    }\n    if (zooKeeperConfig.BaseSleepTimeMilliseconds <= 0) {\n        zooKeeperConfig.BaseSleepTimeMilliseconds = 2000;\n    }\n    if (zooKeeperConfig.MaxSleepTimeMilliseconds <= 0) {\n        zooKeeperConfig.MaxSleepTimeMilliseconds = 60000;\n    }\n    if (zooKeeperConfig.MaxRetries <= 0) {\n        zooKeeperConfig.MaxRetries = 10;\n    }\n    if (zooKeeperConfig.SyncTimeout <= 0) {\n        zooKeeperConfig.SyncTimeout = 5000;\n    }\n    if (zooKeeperConfig.WatchType <= 0) {\n        zooKeeperConfig.WatchType = 1;\n    }\n    if (string.IsNullOrEmpty(zooKeeperConfig.RootPath)) {\n        zooKeeperConfig.RootPath = \"/surging\";\n    }\n    if (", "CodeBleu_score": 34.74552143387476}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZooKeeperServiceCommandManager>>();\n        var routeService = provider.Resolve<IServiceRouteProvider>();\n        var serviceProvider = provider.Resolve<IServiceProvider>();\n        var cacheManager = provider.Resolve<ICacheManager>();\n        var serializer = provider.Resolve<ISerializer<byte[]>>();\n        var configuration = provider.Resolve<IConfiguration>();\n        var client = provider.Resolve<IServiceClientFactory>();\n        var healthCheckService = provider.Resolve<IHealthCheckService>();\n        var mqttBrokerProvider = provider.Resolve<IMqttBrokerProvider>();\n        var serviceCommandDescriptor = provider.Resolve<IServiceCommandDescriptor>();\n        var serviceEntryProvider = provider.Resolve<IServiceEntryProvider>();\n        var serviceCommandProvider = provider.Resolve<IServiceCommandProvider>();\n        var serviceCommandExecutor = provider.Resolve<IServiceCommandExecutor>();\n        var serviceCommandInvoker = provider.Resolve<IServiceCommandInvoker>();\n        var serviceCommandInvokerFactory = provider.Resolve<IServiceCommandInvokerFactory>();\n        var serviceCommandInvokerFactoryProvider = provider.Resolve<IServiceCommandInvokerFactoryProvider>();\n        var serviceCommandInvokerFactoryProviderFactory = provider.Resolve<IServiceCommandInvokerFactoryProviderFactory>();\n        var serviceCommandInvokerFactoryProviderFactoryProvider = provider.Resolve<IServiceCommandInvokerFactoryProviderFactoryProvider>();\n        var serviceCommandInvokerFactoryProviderFactoryProviderFactory = provider.Resolve<IServiceCommandInvokerFactoryProviderFactoryProviderFactory>();\n        var serviceCommandInvokerFactoryProviderFactoryProviderFactoryProvider = provider.Resolve<IServiceCommandInvokerFactoryProviderFactoryProviderProviderFactory>();\n        var serviceCommandInvokerFactoryProviderFactoryProviderFactoryProviderProvider = provider.Resolve<IServiceCommandInvokerFactoryProviderFactoryProviderProviderProviderFactory>();\n        var serviceCommandInvokerFactoryProviderFactoryProviderFactoryProviderProviderProvider = provider.Resolve<IServiceCommandInvokerFactoryProviderFactoryProviderProviderProviderProviderFactory>();\n        var serviceCommandInvokerFactoryProviderFactoryProviderFactoryProviderProviderProviderProvider =", "CodeBleu_score": 25.622164168575818}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder));\n\t}\n\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(Resources.Error_InvalidFilePath, nameof(path));\n\t}\n\n\tif (provider == null && Path.IsPathRooted(path)) {\n\t\t// This Configure method takes care of creating the default file provider\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path), Path.GetFileName(path), null, false);\n\t\tpath = Path.GetFileName(path);\n\t}\n\n\tsource = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = path,\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange\n\t};\n\n\tsource.ResolveFileProvider();\n\n\treturn builder.Add(source);\n}", "CodeBleu_score": 60.46719834796937}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentNullException(nameof(path));\n    }\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path), ExcludeDirectoriesFilter);\n        path = Path.GetFileName(path);\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 70.94191776623123}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Invalid file path\", nameof(path));\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n    source.ResolveFileProvider();\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 52.481094452895825}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address.RemoveAll(p => Address.Any(p2 => p2.ToString().Equals(p.ToString())));\n        await _cacheManager.SetHashAsync(route.ServiceDescriptor.Id, Encoding.UTF8.GetBytes(route.ServiceDescriptor.Id), route);\n    }\n}", "CodeBleu_score": 52.82776572792678}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        route.Address.RemoveAll(address => Address.Any(p => p.ToString() == address.ToString()));\n        if (route.Address.Count == 0) {\n            routes.Remove(route);\n        }\n    }\n    await SetRoutesAsync(routes);\n}", "CodeBleu_score": 54.355568689201824}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach (var route in routes) {\n        foreach (var address in Address) {\n            var addressList = route.Address.Where(p => p.ToString().Equals(address.ToString())).ToList();\n            foreach (var item in addressList) {\n                route.Address.Remove(item);\n            }\n        }\n        await SetRoutesAsync(new List<ServiceRoute>() { route });\n    }\n}", "CodeBleu_score": 52.98519480052396}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = await _serviceRouteProvider.GetRoutePathAsync();\n    var clients = _serviceRouteProvider.GetZooKeeperClient();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(routePath);\n        var childrens = children.Select(x => x.Split(\"_\")[0]).Distinct();\n        var exceptRoutes = routes.Where(x => !childrens.Contains(x.ServiceDescriptor.Id)).ToArray();\n        foreach (var exceptRoute in exceptRoutes) {\n            var address = exceptRoute.Address.Where(x => x.ToString().Contains(hostAddr.Host) && x.Port == hostAddr.Port).ToArray();\n            foreach (var add in address) {\n                var path = $\"{routePath}/{exceptRoute.ServiceDescriptor.Id}_{add.ToString()}\";\n                await client.DeleteAsync(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 35.78948109485759}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var serviceRoutes = routes.ToList();\n    var routePath = ZookeeperRoutePath.GetRoutePath(hostAddr.ServiceDescriptor.Id);\n    var clients = _zookeeperClientFactory.GetZooKeeperClients();\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var exceptRoutes = serviceRoutes.Where(route => !currentRoutes.Any(p => p.Equals(route.RoutePath))).ToList();\n        var exceptRoutePaths = exceptRoutes.Select(route => ZookeeperRoutePath.GetRoutePath(hostAddr.ServiceDescriptor.Id, route.RoutePath)).ToList();\n        foreach (var exceptRoutePath in exceptRoutePaths) {\n            if (exceptRoutePath.Contains(hostAddr.Host)) {\n                await client.DeleteAsync(exceptRoutePath);\n            }\n        }\n    }\n}", "CodeBleu_score": 31.566426649155527}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = GetRoutePath(hostAddr);\n    var clients = GetClients();\n\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var exceptRoutes = routes.Where(route => !currentRoutes.Contains(route.ServiceDescriptor.Id));\n\n        foreach (var exceptRoute in exceptRoutes) {\n            var routePath = GetRoutePath(hostAddr, exceptRoute.ServiceDescriptor.Id);\n            await client.DeleteAsync(routePath);\n        }\n    }\n}", "CodeBleu_score": 24.779019513351347}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    var routeDescriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n    var routes = await _serviceRouteFactory.CreateServiceRoutesAsync(routeDescriptor);\n    return routes.FirstOrDefault();\n}", "CodeBleu_score": 28.920467456271272}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null)\n        return null;\n\n    var routeDescriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n    return _serviceRouteFactory.CreateServiceRoutes(routeDescriptor).First();\n}", "CodeBleu_score": 30.985634759956383}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    var routeDescriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n\n    _logger.LogDebug($\"\u670d\u52a1\u8def\u7531\uff1a{routeDescriptor.ToString()}\");\n\n    return _serviceRouteFactory.CreateServiceRoutes(routeDescriptor).FirstOrDefault();\n}", "CodeBleu_score": 30.94817650895203}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData.SequenceEqual(newData)) {\n        return;\n    }\n\n    var newRoute = await _serializer.DeserializeAsync<ServiceRoute>(newData);\n    var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\n    lock (_locker) {\n        if (oldRoute != null) {\n            _routes.Remove(oldRoute);\n        }\n\n        _routes.Add(newRoute);\n    }\n\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 39.23797151136995}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    var oldRoute = await _serializer.DeserializeAsync<ServiceRoute>(oldData);\n    var newRoute = await _serializer.DeserializeAsync<ServiceRoute>(newData);\n\n    if (oldRoute == newRoute)\n        return;\n\n    var oldRouteTmp = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == oldRoute.ServiceDescriptor.Id);\n    if (oldRouteTmp != null) {\n        lock (_lock) {\n            _routes.Remove(oldRouteTmp);\n            _routes.Add(newRoute);\n        }\n    }\n    OnChanged(newRoute, oldRoute);\n}", "CodeBleu_score": 39.1032879191472}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (oldData == null && newData == null) {\n        return;\n    }\n\n    var oldRoute = oldData == null ? null : _serializer.Deserialize<ServiceRoute>(oldData);\n    var newRoute = newData == null ? null : _serializer.Deserialize<ServiceRoute>(newData);\n\n    if (oldRoute == null && newRoute != null) {\n        _routes.Add(newRoute);\n        OnChanged(newRoute, null);\n        return;\n    }\n\n    if (oldRoute != null && newRoute == null) {\n        _routes.Remove(oldRoute);\n        OnChanged(null, oldRoute);\n        return;\n    }\n\n    if (oldRoute.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id) {\n        var oldAddress = oldRoute.Address;\n        var newAddress = newRoute.Address;\n\n        if (oldAddress.Count == newAddress.Count && oldAddress.All(newAddress.Contains)) {\n            return;\n        }\n\n        lock (_locker) {\n            var oldRouteIndex = _routes.IndexOf(oldRoute);\n            _routes[oldRouteIndex] = newRoute;\n        }\n\n        OnChanged(newRoute, oldRoute);\n    }\n}", "CodeBleu_score": 34.13464166586947}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await GetServiceSubscribersAsync(subscribers);\n    foreach (var subscriber in subscribers) {\n        var serviceSubscriber = serviceSubscribers.FirstOrDefault(p => p.Address == subscriber.Address);\n        if (serviceSubscriber != null) {\n            serviceSubscriber.Address = subscriber.Address;\n            serviceSubscriber.ServiceId = subscriber.ServiceId;\n            serviceSubscriber.Items = subscriber.Items;\n        }\n        else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 51.065647299605246}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = subscribers.ToList();\n    var serviceName = serviceSubscribers.First().ServiceName;\n    var serviceSubscriber = serviceSubscribers.First();\n    var serviceSubscriberAddress = serviceSubscriber.AddressDescriptors.First().Value;\n    var serviceSubscribersPath = await _serviceSubscriberPath.GetServiceSubscriberPath(serviceName);\n    var serviceSubscriberPath = await _serviceSubscriberPath.GetServiceSubscriberPath(serviceName, serviceSubscriberAddress);\n    var serviceSubscriberData = await _serializer.SerializeAsync(serviceSubscriber);\n    var serviceSubscriberDataBytes = Encoding.UTF8.GetBytes(serviceSubscriberData);\n    var serviceSubscriberNode = await _zooKeeperClient.GetDataAsync(serviceSubscriberPath);\n    if (serviceSubscriberNode == null) {\n        if (serviceSubscriberAddress.Contains(\"|\")) {\n            var serviceSubscriberAddresses = serviceSubscriberAddress.Split(\"|\");\n            foreach (var address in serviceSubscriberAddresses) {\n                var serviceSubscriberAddressPath = await _serviceSubscriberPath.GetServiceSubscriberPath(serviceName, address);\n                if (await _zooKeeperClient.ExistsAsync(serviceSubscriberAddressPath) == null) {\n                    await _zooKeeperClient.CreateAsync(serviceSubscriberAddressPath, serviceSubscriberDataBytes, CreateMode.Persistent);\n                }\n            }\n        } else {\n            await _zooKeeperClient.CreateAsync(serviceSubscriberPath, serviceSubscriberDataBytes, CreateMode.Persistent);\n        }\n    } else {\n        await _zooKeeperClient.SetDataAsync(serviceSubscriberPath, serviceSubscriberDataBytes);\n    }\n    var serviceSubscriberNodes = await _zooKeeperClient.GetChildrenAsync(serviceSubscribersPath);\n    foreach (var serviceSubscriberNode in serviceSubscriberNodes) {\n        var serviceSubscriberNodePath = await _serviceSubscriberPath.GetService", "CodeBleu_score": 26.30955230630975}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var subscriberAddresses = new Dictionary<string, IEnumerable<string>>();\n    foreach (var subscriber in subscribers) {\n        var addresses = subscriber.Address;\n        if (subscriberAddresses.ContainsKey(subscriber.Address)) {\n            addresses = addresses.Union(subscriberAddresses[subscriber.Address]);\n        }\n        subscriberAddresses[subscriber.Address] = addresses;\n    }\n\n    var subscribersToSet = new List<ServiceSubscriber>();\n    foreach (var subscriberAddress in subscriberAddresses) {\n        var subscriber = new ServiceSubscriber {\n            Address = subscriberAddress.Key,\n            ServiceDescriptor = subscriberAddress.Value.First().GetServiceDescriptor()\n        };\n        subscribersToSet.Add(subscriber);\n    }\n\n    await base.SetSubscribersAsync(subscribersToSet);\n}", "CodeBleu_score": 46.23830222137863}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = GetRootPath(ZookeeperClient.SubscriberPath);\n    foreach (var children in childrens) {\n        var path = rootPath + children;\n        var subscriber = await GetSubscriber(path);\n        if (subscriber != null) {\n            subscribers.Add(subscriber);\n        }\n    }\n\n    return subscribers.ToArray();\n}", "CodeBleu_score": 42.27198815772204}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = GetSubscriberPath(_options.ClusterId, _options.GroupId);\n    foreach (var children in childrens) {\n        var nodePath = rootPath + \"/\" + children;\n        var subscriber = await GetSubscriber(nodePath);\n        if (subscriber != null) {\n            subscribers.Add(subscriber);\n        }\n    }\n    return subscribers.ToArray();\n}", "CodeBleu_score": 46.01838202367358}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t    var subscribers = new List<ServiceSubscriber>();\n    var rootPath = GetSubscriberPath();\n    foreach (var children in childrens) {\n        var path = $\"{rootPath}/{children}\";\n        var subscriber = await GetSubscriber(path);\n        subscribers.Add(subscriber);\n    }\n    return subscribers.ToArray();\n}", "CodeBleu_score": 38.240264458757366}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return\n    }\n\n    var zooKeeperClient = await _zookeeperClientFactory.Create();\n\n    await zooKeeperClient.WaitForConnectedAsync();\n\n    if (await zooKeeperClient.ExistsAsync(_subscriberPath)) {\n        var children = await zooKeeperClient.GetChildrenAsync(_subscriberPath);\n        _subscribers = new List<Subscriber>();\n\n        foreach (var child in children) {\n            var data = await zooKeeperClient.GetDataAsync($\"{_subscriberPath}/{child}\");\n            var subscriber = _serializer.Deserialize<Subscriber>(data);\n            _subscribers.Add(subscriber);\n        }\n    } else {\n        _logger.LogWarning($\"Subscriber path:{_subscriberPath} not exist\");\n        _subscribers = new List<Subscriber>();\n    }\n}", "CodeBleu_score": 36.94044336416287}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null)\n        return;\n\n    var client = await _zookeeperClientFactory.Create();\n    await client.WaitForConnected();\n\n    if (await client.ExistsAsync(_subscriberPath)) {\n        var children = await client.GetChildrenAsync(_subscriberPath);\n        var subscribers = new List<SubscriberDescriptor>();\n        foreach (var child in children) {\n            var path = string.Concat(_subscriberPath, \"/\", child);\n            var data = await client.GetDataAsync(path);\n            var subscriberDescriptor = _serializer.Deserialize<SubscriberDescriptor>(data);\n            subscribers.Add(subscriberDescriptor);\n        }\n        _subscribers = subscribers.ToArray();\n    } else {\n        _logger.LogWarning($\"zookeeper path {_subscriberPath} not exist\");\n        _subscribers = Array.Empty<SubscriberDescriptor>();\n    }\n}", "CodeBleu_score": 41.237954315174804}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return\n    }\n    var client = await GetClient()\n    await client.WaitForConnected()\n    var subscriberPath = $\"{_options.Path}/{_options.SubscriberPath}\"\n    if (await client.ExistsAsync(subscriberPath)) {\n        var children = await client.GetChildrenAsync(subscriberPath)\n        var subscriberData = await Task.WhenAll(children.Select(async x => await client.GetDataAsync($\"{subscriberPath}/{x}\")))\n        _subscribers = subscriberData.Select(x => _serializer.Deserialize<SubscriberDescriptor>(x)).ToArray()\n    } else {\n        _logger.LogWarning(\"zookeeper subscriber path not exists\")\n        _subscribers = Array.Empty<SubscriberDescriptor>()\n    }\n}", "CodeBleu_score": 26.069817542831707}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    var oldCommand = _serializer.Deserialize<ServiceCommandDescriptor>(oldData);\n    var newCommand = _serializer.Deserialize<ServiceCommandDescriptor>(newData);\n\n    if (oldCommand.Equals(newCommand)) {\n        return;\n    }\n\n    var oldCommands = _serviceCommands.GetValueOrDefault(oldCommand.ServiceId);\n    var newCommands = _serviceCommands.GetValueOrDefault(newCommand.ServiceId);\n\n    if (oldCommands != null && oldCommands.Any(p => p.Equals(oldCommand))) {\n        var oldCommandIndex = oldCommands.FindIndex(p => p.Equals(oldCommand));\n        oldCommands[oldCommandIndex] = newCommand;\n    }\n\n    if (newCommands != null && newCommands.Any(p => p.Equals(newCommand))) {\n        var newCommandIndex = newCommands.FindIndex(p => p.Equals(newCommand));\n        newCommands[newCommandIndex] = newCommand;\n    }\n\n    OnChanged(oldCommands, newCommands);\n}", "CodeBleu_score": 29.61949171909107}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    var oldServiceCommand = _serializer.Deserialize<ServiceCommandDescriptor>(oldData);\n    var newServiceCommand = _serializer.Deserialize<ServiceCommandDescriptor>(newData);\n    if (oldServiceCommand.ServiceDescriptor.Id != newServiceCommand.ServiceDescriptor.Id) {\n        return;\n    }\n    var oldCommand = _serviceCommands.FirstOrDefault(p => p.ServiceDescriptor.Id == oldServiceCommand.ServiceDescriptor.Id);\n    var newCommand = _serviceCommands.FirstOrDefault(p => p.ServiceDescriptor.Id == newServiceCommand.ServiceDescriptor.Id);\n    if (oldCommand != null) {\n        _serviceCommands.Remove(oldCommand);\n    }\n    _serviceCommands.Add(newServiceCommand);\n    OnChanged(newCommand, oldCommand);\n}", "CodeBleu_score": 28.341437105106454}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    var oldCommands = _serializer.Deserialize<IEnumerable<ServiceCommandDescriptor>>(oldData);\n    var newCommands = _serializer.Deserialize<IEnumerable<ServiceCommandDescriptor>>(newData);\n\n    var oldCommandsList = oldCommands.ToList();\n    var newCommandsList = newCommands.ToList();\n\n    if (oldCommandsList.Count != newCommandsList.Count) {\n        var oldCommandsIds = oldCommandsList.Select(p => p.ServiceId).ToList();\n        var newCommandsIds = newCommandsList.Select(p => p.ServiceId).ToList();\n\n        var addedCommands = newCommandsList.Where(p => !oldCommandsIds.Contains(p.ServiceId));\n        var removedCommands = oldCommandsList.Where(p => !newCommandsIds.Contains(p.ServiceId));\n\n        foreach (var addedCommand in addedCommands) {\n            var oldCommand = oldCommandsList.FirstOrDefault(p => p.ServiceId == addedCommand.ServiceId);\n            if (oldCommand != null) {\n                newCommandsList.Remove(oldCommand);\n                newCommandsList.Add(addedCommand);\n            }\n        }\n\n        foreach (var removedCommand in removedCommands) {\n            var newCommand = newCommandsList.FirstOrDefault(p => p.ServiceId == removedCommand.ServiceId);\n            if (newCommand != null) {\n                oldCommandsList.Remove(removedCommand);\n                oldCommandsList.Add(newCommand);\n            }\n        }\n    }\n\n    var oldCommandsArray = oldCommandsList.ToArray();\n    var newCommandsArray = newCommandsList.ToArray();\n\n    if (!oldCommandsArray.SequenceEqual(newCommandsArray)) {\n        _logger.LogInformation($\"\u670d\u52a1\u8def\u7531\u6570\u636e\u53d1\u751f\u53d8\u66f4\uff0c\u7248\u672c\u53f7\uff1a{_dataWatcher.DataVersion}\u3002\");\n        OnChanged(newCommandsArray, oldCommandsArray);\n    }\n}", "CodeBleu_score": 33.33376619829963}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t  if (watchedEvent.Type == EventType.NodeDataChanged) {\n    byte[] data = await client.GetDataAsync(watchedEvent.Path, this);\n    string newData = Encoding.UTF8.GetString(data);\n    action(currentData, newData);\n    currentData = newData;\n  }\n}", "CodeBleu_score": 42.645819641734825}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.Type == EventType.NodeDataChanged) {\n        var data = await zooKeeper.getDataAsync(watchedEvent.Path, false);\n        action(data.Data, currentData);\n        currentData = data.Data;\n        await zooKeeper.existsAsync(watchedEvent.Path, this);\n    }\n}", "CodeBleu_score": 45.86368258245233}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    try {\n        if (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n            byte[] data = await zooKeeper.getDataAsync(watchedEvent.getPath(), false);\n            string newData = Encoding.UTF8.GetString(data);\n            action(currentData, newData);\n            currentData = newData;\n            await zooKeeper.existsAsync(watchedEvent.getPath(), this);\n        }\n    } catch (Exception e) {\n        Console.WriteLine(e.ToString());\n    }\n}", "CodeBleu_score": 53.034288344123695}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    var services = builder.Services;\n    services.AddSingleton(provider => {\n        var logger = provider.GetService<ILogger<DefaultZookeeperClientProvider>>();\n        var healthCheckService = provider.GetService<IHealthCheckService>();\n        var addressSelector = provider.GetService<IServiceAddressSelector>();\n        var serializer = provider.GetService<ISerializer<byte[]>>();\n        var cacheManager = provider.GetService<ICacheManager<string>>();\n        var configInfo = provider.GetService<ConfigInfo>();\n        return new DefaultZookeeperClientProvider(logger, healthCheckService, addressSelector, serializer, cacheManager, configInfo);\n    });\n    return builder;\n}", "CodeBleu_score": 47.87510342019266}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    var services = builder.Services;\n    services.AddSingleton<IZookeeperClientProvider>(sp => {\n        var logger = sp.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>();\n        var healthCheckService = sp.GetRequiredService<IHealthCheckService>();\n        var addressSelector = sp.GetRequiredService<ISubscribeAddressSelector>();\n        return new DefaultZookeeperClientProvider(configInfo, healthCheckService, addressSelector, logger);\n    });\n    return builder;\n}", "CodeBleu_score": 44.440006085653394}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.AddSingleton<IServiceRouteProvider, ZookeeperServiceRouteProvider>();\n    builder.Services.AddSingleton<IServiceRouteManager, ZookeeperServiceRouteManager>();\n    builder.Services.AddSingleton<IServiceSubscribeProvider, ZookeeperServiceSubscribeProvider>();\n    builder.Services.AddSingleton<IServiceCommandProvider, ZookeeperServiceCommandProvider>();\n    builder.Services.AddSingleton<IServiceEntryProvider, ZookeeperServiceEntryProvider>();\n    builder.Services.AddSingleton<IServiceSubscriber, ZookeeperServiceSubscriber>();\n    builder.Services.AddSingleton<IServiceCommandExecutor, ZookeeperServiceCommandExecutor>();\n    builder.Services.AddSingleton<IServiceDiscoveryProvider, ZookeeperServiceDiscoveryProvider>();\n    builder.Services.AddSingleton<IServiceDiscovery, ZookeeperServiceDiscovery>();\n    builder.Services.AddSingleton<IServiceRegister, ZookeeperServiceRegister>();\n    builder.Services.AddSingleton<IServiceBehaviorProvider, ZookeeperServiceBehaviorProvider>();\n    builder.Services.AddSingleton<IServiceBehavior, ZookeeperServiceBehavior>();\n    builder.Services.AddSingleton<IServiceEngineBuilder, ZookeeperServiceEngineBuilder>();\n    builder.Services.AddSingleton<IServiceEngine, ZookeeperServiceEngine>();\n    builder.Services.AddSingleton<IServiceHost, ZookeeperServiceHost>();\n    builder.Services.AddSingleton<IServiceHostBuilder, ZookeeperServiceHostBuilder>();\n    builder.Services.AddSingleton<IServiceRouteFactory, DefaultServiceRouteFactory>();\n    builder.Services.AddSingleton<IServiceRouteManager, DefaultServiceRouteManager>();\n    builder.Services.AddSingleton<IServiceRouteProvider, DefaultServiceRouteProvider>();\n    builder.Services.AddSingleton<IServiceRouteProvider, DefaultServiceRouteProvider>();\n    builder.Services.AddSingleton<IServiceRouteManager, DefaultServiceRouteManager>();\n    builder.Services.AddSingleton<IServiceRouteProvider, DefaultServiceRouteProvider>();\n", "CodeBleu_score": 33.13901269824521}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var logger = _loggerFactory.CreateLogger<ZooKeeperMqttServiceRouteManager>();\n    var clients = await GetClients();\n    foreach (var client in clients) {\n        var path = GetServiceRoutePath(client.Config.Path);\n        var exists = await client.ExistsAsync(path);\n        if (!exists) {\n            await client.CreatePersistentAsync(path);\n        }\n        foreach (var route in routes) {\n            var routePath = GetRoutePath(client.Config.Path, route.Id);\n            var exists = await client.ExistsAsync(routePath);\n            if (!exists) {\n                await client.CreatePersistentAsync(routePath);\n            }\n            var data = Encoding.UTF8.GetBytes(JsonSerializer.Serialize(route));\n            await client.SetDataAsync(routePath, data);\n            logger.LogInformation($\"Add route:{routePath} data:{Encoding.UTF8.GetString(data)}\");\n        }\n    }\n    logger.LogInformation(\"Set routes success.\");\n}", "CodeBleu_score": 35.976475306436875}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var children = await _zooKeeperClientFactory.GetZooKeeperClient().GetChildrenAsync($\"/{_options.RootPath}\");\n    var nodeName = _options.RoutePath;\n    if (!children.Any(p => p == nodeName)) {\n        await _zooKeeperClientFactory.GetZooKeeperClient().CreateAsync($\"/{_options.RootPath}/{nodeName}\", null, CreateMode.Persistent);\n    }\n\n    var path = $\"/{_options.RootPath}/{nodeName}\";\n    var routeDatas = routes.Select(route => {\n        var data = Encoding.UTF8.GetBytes(JsonSerializer.Serialize(route));\n        return new {\n            route.Address,\n            Data = data\n        };\n    }).ToArray();\n\n    foreach (var zooKeeperClient in _zooKeeperClientFactory.GetZooKeeperClients()) {\n        var children = await zooKeeperClient.GetChildrenAsync(path);\n        foreach (var routeData in routeDatas) {\n            var routePath = $\"{path}/{routeData.Address.ToIpEndPoint()}\";\n            if (!children.Any(p => p == routeData.Address.ToIpEndPoint())) {\n                await zooKeeperClient.CreateAsync(routePath, routeData.Data, CreateMode.Persistent);\n                _logger.LogInformation($\"ZooKeeper\uff1a\u8282\u70b9\u521b\u5efa\u6210\u529f\uff0c\u8282\u70b9\u5730\u5740\uff1a{routePath}\uff0c\u8282\u70b9\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(routeData.Data)}\u3002\");\n            }\n            else {\n                await zooKeeperClient.SetDataAsync(routePath, routeData.Data);\n                _logger.LogInformation($\"ZooKeeper\uff1a\u8282\u70b9\u66f4\u65b0\u6210\u529f\uff0c\u8282\u70b9\u5730\u5740\uff1a{routePath}\uff0c\u8282\u70b9\u5185\u5bb9\uff1a{Encoding.UTF8.GetString(routeData.Data)}\u3002\");\n            }\n        }\n    }\n\n    _logger.LogInformation(\"ZooKeeper\uff1a\u6dfb\u52a0\u8def\u7531\u6210\u529f\u3002\");\n}", "CodeBleu_score": 42.48454427556682}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var logger = _loggerFactory.CreateLogger<ZooKeeperMqttServiceRouteManager>();\n    var clients = await GetZooKeeperClients();\n    foreach (var client in clients) {\n        var root = _configInfo.RootPath;\n        var routePath = $\"{root}/{client.ClientId}/{_configInfo.RoutePath}\";\n        if (await client.ExistsAsync(routePath) == null) {\n            await client.CreatePersistentAsync(routePath);\n        }\n        foreach (var route in routes) {\n            var routeData = _serializer.Serialize(route);\n            var routeAddress = route.AddressDescriptors.First();\n            var routePath = $\"{root}/{client.ClientId}/{_configInfo.RoutePath}/{route.ServiceDescriptor.Id}\";\n            var data = await client.GetDataAsync(routePath);\n            if (data == null) {\n                logger.LogInformation($\"ZooKeeper\uff1aAdding the route node\uff1a{routePath}\uff0cdata\uff1a{routeData}\");\n                await client.CreatePersistentAsync(routePath, routeData);\n            } else {\n                logger.LogInformation($\"ZooKeeper\uff1aModifying the route node\uff1a{routePath}\uff0cdata\uff1a{routeData}\");\n                await client.SetDataAsync(routePath, routeData);\n            }\n        }\n        logger.LogInformation(\"ZooKeeper\uff1aThe route has been added successfully.\");\n    }\n}", "CodeBleu_score": 40.98187215052157}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = GetRoutePath(hostAddr);\n    var currentRoutes = await _zookeeperClient.GetChildrenAsync(routePath);\n    var exceptRoutes = routes.ToDictionary(route => route.RoutePath);\n    var deleteRoutes = currentRoutes.Where(route => !exceptRoutes.ContainsKey(route));\n    foreach (var deleteRoute in deleteRoutes) {\n        var routePath = GetRoutePath(hostAddr, deleteRoute);\n        await _zookeeperClient.DeleteAsync(routePath);\n    }\n}", "CodeBleu_score": 21.58426734664837}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = ZookeeperClient.GetServiceRoutePath(hostAddr.Host, hostAddr.Port);\n    var zookeeperClients = await GetZookeeperClientsAsync();\n    foreach (var zkClient in zookeeperClients) {\n        var children = await zkClient.GetChildrenAsync(routePath);\n        var existRoutes = children.Select(child => {\n            var route = _serializer.Deserialize<MqttServiceRoute>(Encoding.UTF8.GetBytes(child));\n            route.ServiceDescriptor.Address = hostAddr;\n            return route;\n        });\n        var exceptRoutes = existRoutes.Except(routes);\n        var deleteRoutes = exceptRoutes.Where(route => route.AddressDescriptors.Any(address => address.ToString() == hostAddr.ToString()));\n        foreach (var deleteRoute in deleteRoutes) {\n            var routeNode = ZookeeperClient.GetServiceRoutePath(hostAddr.Host, hostAddr.Port, deleteRoute.ServiceDescriptor.Id);\n            await zkClient.DeleteAsync(routeNode);\n        }\n    }\n}", "CodeBleu_score": 34.34667928431105}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = GetRoutePath(hostAddr);\n    var clients = GetClients();\n    foreach (var client in clients) {\n        var oldRoutes = await client.GetChildrenAsync(routePath);\n        var exceptRoutes = routes.Select(route => route.ToJson());\n        var deleteRoutes = oldRoutes.Except(exceptRoutes);\n        foreach (var deleteRoute in deleteRoutes) {\n            var route = deleteRoute.FromJson<MqttServiceRoute>();\n            if (route.Address.Contains(hostAddr.ToString())) {\n                await client.DeleteAsync($\"{routePath}/{deleteRoute}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 31.441219957447508}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Updating service caches in Zookeeper.\");\n\n    var cachePath = _zookeeperClientFactory.GetCachePath();\n\n    var zookeeperClients = _zookeeperClientFactory.GetZookeeperClients();\n\n    foreach (var zookeeperClient in zookeeperClients) {\n        var cachePathExists = await zookeeperClient.ExistsAsync(cachePath);\n\n        if (!cachePathExists) {\n            await zookeeperClient.CreateAsync(cachePath, null, CreateMode.Persistent);\n        }\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cacheNodePath = _zookeeperClientFactory.GetCacheNodePath(cacheDescriptor.Descriptor);\n\n            var cacheNodeExists = await zookeeperClient.ExistsAsync(cacheNodePath);\n\n            var cacheNodeData = _serializer.Serialize(cacheDescriptor);\n\n            if (!cacheNodeExists) {\n                await zookeeperClient.CreateAsync(cacheNodePath, cacheNodeData, CreateMode.Persistent);\n            } else {\n                await zookeeperClient.SetDataAsync(cacheNodePath, cacheNodeData);\n            }\n        }\n    }\n\n    _logger.LogInformation(\"Successfully added service caches.\");\n}", "CodeBleu_score": 40.706739402795264}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"\u5f00\u59cb\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u5230Zookeeper\u3002\");\n    var cachePath = Path.Combine(${_options.ChRoot}/CacheDescriptor/Service\", _options.ClusterId);\n    var clients = GetZooKeeperClients();\n    foreach (var client in clients) {\n        await client.EnsurePathExistsAsync(cachePath);\n        foreach (var descriptor in cacheDescriptors) {\n            var data = _serializer.Serialize(descriptor);\n            var serviceId = descriptor.ServiceId;\n            var path = Path.Combine(cachePath, serviceId);\n            var exists = await client.ExistsAsync(path);\n            if (!exists) {\n                await client.CreateAsync(path, data, CreateMode.Persistent);\n            }\n            else {\n                await client.SetDataAsync(path, data);\n            }\n        }\n    }\n    _logger.LogInformation(\"\u6210\u529f\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u5230Zookeeper\u3002\");\n}", "CodeBleu_score": 31.52392136893653}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    var cachePath = GetCachePath();\n    var clients = GetZooKeeperClient();\n    foreach (var client in clients) {\n        await client.EnsurePathExistsAsync(cachePath);\n        foreach (var descriptor in cacheDescriptors) {\n            var data = Encoding.UTF8.GetBytes(JsonSerializer.Serialize(descriptor));\n            var nodePath = Path.Combine(cachePath, descriptor.Descriptor.Id);\n            if (!await client.ExistsAsync(nodePath)) {\n                await client.CreateAsync(nodePath, data, CreateMode.Persistent);\n            }\n            else {\n                var currentData = await client.GetDataAsync(nodePath);\n                if (!currentData.SequenceEqual(data)) {\n                    await client.SetDataAsync(nodePath, data);\n                }\n            }\n        }\n    }\n\n    Logger.LogInformation(\"Added service caches.\");\n}", "CodeBleu_score": 30.89294720025434}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, client) = zooKeeper;\n    await Task.Run(() => {\n        manualResetEvent.WaitOne();\n        if (!await client.ExistsAsync(path)) {\n            _logger.LogInformation($\"{path} not existed, begin create it.\");\n            var paths = path.Split('/');\n            var temp = \"\";\n            foreach (var p in paths) {\n                if (string.IsNullOrEmpty(p)) {\n                    continue;\n                }\n\n                temp += \"/\";\n                temp += p;\n                if (!await client.ExistsAsync(temp)) {\n                    _logger.LogInformation($\"{temp} not existed, begin create it.\");\n                    var node = await client.CreateAsync(temp, null, Ids.OPEN_ACL_UNSAFE, CreateMode.Persistent);\n                    _logger.LogInformation($\"{temp} create result is {node}.\");\n                }\n            }\n        }\n    });\n}", "CodeBleu_score": 43.969766980868975}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, client) = zooKeeper;\n    await Task.Run(() => {\n        manualResetEvent.WaitOne();\n        var paths = path.Split('/');\n        var currentPath = \"\";\n        foreach (var subPath in paths) {\n            currentPath += \"/\" + subPath;\n            if (client.ExistsAsync(currentPath).Result == null) {\n                client.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT).Wait();\n                _logger.LogInformation($\"Created Zookeeper node: {currentPath}\");\n            }\n        }\n    });\n}", "CodeBleu_score": 35.079769598546704}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, client) = zooKeeper;\n    await manualResetEvent.WaitOneAsync();\n    var exists = await client.ExistsAsync(path);\n    if (exists == null) {\n        var paths = path.Split(\"/\", StringSplitOptions.RemoveEmptyEntries);\n        var currentPath = \"\";\n        foreach (var subPath in paths) {\n            currentPath += \"/\" + subPath;\n            var exists = await client.ExistsAsync(currentPath);\n            if (exists == null) {\n                await client.CreateAsync(currentPath, null, Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 40.381337217487136}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new ConcurrentBag<(ManualResetEvent, ZooKeeper)>()\n    var cancellationTokenSource = new CancellationTokenSource()\n\n    try {\n        var healthCheckService = _serviceProvider.GetService<IHealthCheckService>()\n\n        foreach (var address in _options.GetClusterAddress()) {\n            var endpoint = await _selector.SelectAsync(address, cancellationTokenSource.Token)\n\n            if (endpoint == null) {\n                _logger.LogWarning($\"Failed to select a ZooKeeper instance from the address: {address}\")\n                continue\n            }\n\n            var healthReport = await healthCheckService.CheckHealthAsync(endpoint, cancellationTokenSource.Token)\n\n            if (healthReport.Status == HealthStatus.Healthy) {\n                var zooKeeper = new ZooKeeper(\n                    endpoint,\n                    _options.SessionTimeout,\n                    _watcherProvider,\n                    _options.CanBeReadOnly,\n                    _options.SessionId,\n                    _options.SessionPasswd,\n                    _options.MaxInFlightRequests,\n                    _options.DefaultWatcher\n                )\n\n                result.Add((new ManualResetEvent(false), zooKeeper))\n            }\n        }\n\n        if (result.IsEmpty) {\n            throw new ZooKeeperException(\"No available ZooKeeper instances found\")\n        }\n\n        return result\n    } catch (Exception exception) {\n        _logger.LogError(exception, \"An error occurred while retrieving ZooKeeper instances\")\n        throw\n    } finally {\n        cancellationTokenSource.Dispose()\n    }\n}", "CodeBleu_score": 24.436194456032094}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new ConcurrentBag<(ManualResetEvent, ZooKeeper)>();\n    var addresses = _addressSelector.SelectAsync();\n\n    await foreach (var address in addresses.WithCancellation(_cancellationTokenSource.Token)) {\n        var zooKeeper = await GetZooKeeper(address);\n        if (zooKeeper is not null) {\n            result.Add(zooKeeper);\n        }\n    }\n\n    return result;\n}", "CodeBleu_score": 66.03557283266687}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new ConcurrentBag<(ManualResetEvent, ZooKeeper)>()\n    var cts = new CancellationTokenSource()\n    var tasks = new List<Task>()\n    var addresses = await _addressResolver.ResolveAsync(_zookeeperConfig.ConnectionStrings, cts.Token)\n    foreach (var address in addresses) {\n        var task = Task.Run(async () => {\n            var endpoint = address.GetEndpoint()\n            if (await _healthCheckService.IsHealthy(endpoint, cts.Token)) {\n                var zooKeeper = new ZooKeeper(endpoint.ToString(), _zookeeperConfig.SessionTimeout, _watcherProvider)\n                result.Add((new ManualResetEvent(false), zooKeeper))\n            }\n        }, cts.Token)\n        tasks.Add(task)\n    }\n    await Task.WhenAll(tasks)\n    return result\n}", "CodeBleu_score": 42.61466465643578}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (data.zookeeper == null) {\n            data.zookeeper = ZookeeperFactory.newZooKeeper(data.ensembleProvider.getConnectionString(), data.sessionTimeoutMs, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    // process event\n                }\n            }, false);\n        }\n        return new Helper(data);\n    }\n}", "CodeBleu_score": 49.72714999099098}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zooKeeper == null) {\n            String connectString = ensembleProvider.getConnectionString();\n            int sessionTimeout = sessionTimeoutMs;\n            Watcher chrootWatcher = watcher;\n            ZooKeeperFactory factory = new ZooKeeperFactory();\n            zooKeeper = factory.newZooKeeper(connectString, sessionTimeout, new ZKWatcher(), canBeReadOnly);\n            zooKeeper.addAuthInfo(authInfo.getScheme(), authInfo.getAuth().getBytes());\n        }\n    }\n    return zooKeeper;\n}", "CodeBleu_score": 40.437448432817234}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zk != null) {\n            return zk;\n        }\n        zk = ZookeeperFactory.newClient(ensembleProvider.getConnectionString(), sessionTimeoutMs, canBeReadOnly, zookeeperWatcher);\n        zk.setData(dataPath, currentData, -1);\n        return zk;\n    }\n}", "CodeBleu_score": 38.29923794429243}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zk = null;\n    try {\n        if (helper != null) {\n            zk = helper.getZooKeeper();\n        }\n        if (zk != null) {\n            zk.register(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                }\n            });\n            zk.close();\n        }\n    } finally {\n        if (zk != null) {\n            waitForShutdown(zk, waitForShutdownTimeoutMs);\n        }\n    }\n}", "CodeBleu_score": 34.730719853660034}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zk = zookeeperHelper.getZooKeeper();\n    if (zk != null) {\n        Watcher watcher = new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n            }\n        };\n        zk.getData(\"/\", watcher, null);\n        zk.close();\n        if (waitForShutdownTimeoutMs > 0) {\n            Thread.sleep(waitForShutdownTimeoutMs);\n        }\n    }\n}", "CodeBleu_score": 42.090103298790325}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zk = null;\n    try {\n        zk = zkHelper.getZooKeeper();\n        if (zk != null) {\n            zk.register(new Watcher() {\n\n                @Override\n                public void process(WatchedEvent event) {\n                }\n            });\n            zk.close();\n        }\n    } finally {\n        if (zk != null) {\n            zkHelper.clear();\n        }\n    }\n    if (waitForShutdownTimeoutMs > 0) {\n        try {\n            Thread.sleep(waitForShutdownTimeoutMs);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        }\n    }\n}", "CodeBleu_score": 48.45190027356332}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    long startMs = System.currentTimeMillis();\n    Preconditions.checkState(started.get(), \"Client not started\");\n    LOG.debug(\"Starting wait for client connection\");\n    boolean connected = connectedSignal.await(sessionTimeoutMs, TimeUnit.MILLISECONDS);\n    long elapsedMs = System.currentTimeMillis() - startMs;\n    LOG.debug(\"Client connection completed (connected = {}) in {} ms\", connected, elapsedMs);\n    return connected;\n}", "CodeBleu_score": 47.07224893770465}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    Preconditions.checkState(started.get(), \"Client must be started before calling this method\");\n    LOG.debug(\"Blocking until connected\");\n    try {\n        return connected.await(sessionTimeoutMs, TimeUnit.MILLISECONDS);\n    } finally {\n        LOG.debug(\"Done blocking\");\n    }\n}", "CodeBleu_score": 29.60569566105451}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    long startMs = System.currentTimeMillis();\n    log.debug(\"Starting\");\n    boolean result = false;\n    try {\n        if (client.started()) {\n            result = client.getZookeeperClient().blockUntilConnectedOrTimedOut();\n        }\n    } finally {\n        log.debug(\"Finished in {} ms\", (System.currentTimeMillis() - startMs));\n    }\n    return result;\n}", "CodeBleu_score": 38.287686390538035}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    LOG.info(\"Shutting down {}\", this);\n    started.set(false);\n    try {\n        close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (IOException e) {\n        if (!Thread.interrupted()) {\n            LOG.error(\"Error closing\", e);\n        }\n    }\n}", "CodeBleu_score": 58.0821749493481}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    Preconditions.checkArgument((waitForShutdownTimeoutMs >= 0), \"waitForShutdownTimeoutMs cannot be negative\");\n    LOG.info(\"Closing {}\", this);\n    started.set(false);\n    try {\n        if (!closeable.await(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS)) {\n            LOG.warn(\"{} did not shut down within {}ms\", this, waitForShutdownTimeoutMs);\n        }\n    } catch (InterruptedException e) {\n        LOG.warn(\"Interrupted while waiting for {} to close\", this);\n        Thread.currentThread().interrupt();\n    }\n}", "CodeBleu_score": 40.25697818000474}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    LOG.info(\"Shutting down CuratorFramework: {}\", this);\n    started.set(false);\n    try {\n        close(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (IOException e) {\n        if (!Thread.currentThread().isInterrupted()) {\n            LOG.error(\"Error on shutdown\", e);\n        }\n    }\n}", "CodeBleu_score": 56.584502311432786}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    long startMs = System.currentTimeMillis();\n    long remainingMs = connectionTimeoutMs;\n    while ((state.get() != CuratorFrameworkState.STARTED) && (remainingMs > 0)) {\n        final CountDownLatch connectedLatch = new CountDownLatch(1);\n        final AtomicReference<Watcher> watcherRef = new AtomicReference<Watcher>();\n        watcherRef.set(new Watcher() {\n\n            @Override\n            public void process(WatchedEvent event) {\n                if (event.getType() == Event.EventType.None) {\n                    switch(event.getState()) {\n                        case SyncConnected:\n                            connectedLatch.countDown();\n                            break;\n                        case Expired:\n                            break;\n                        default:\n                            break;\n                    }\n                }\n            }\n        });\n        try {\n            client.addWatch(watcherRef.get(), null, null);\n            remainingMs = connectionTimeoutMs - (System.currentTimeMillis() - startMs);\n            if (remainingMs > 0) {\n                connectedLatch.await(remainingMs, TimeUnit.MILLISECONDS);\n            }\n        } finally {\n            client.removeWatch(watcherRef.get(), null, null);\n        }\n    }\n    if (state.get() != CuratorFrameworkState.STARTED) {\n        throw new TimeoutException(\"Timed out waiting for client to connect\");\n    }\n}", "CodeBleu_score": 39.058331165152026}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    CountDownLatch latch = new CountDownLatch(1);\n    AtomicReference<Watcher> watcherRef = new AtomicReference<>();\n    AtomicBoolean timedOut = new AtomicBoolean(false);\n    long remaining = connectionTimeoutMs;\n    while (true) {\n        if (state.get() == CuratorFrameworkState.STARTED) {\n            ZooKeeper zk = zookeeper.get();\n            if (zk != null) {\n                if (zk.getState() == ZooKeeper.States.CONNECTED) {\n                    return;\n                }\n                if (remaining <= 0) {\n                    timedOut.set(true);\n                    break;\n                }\n            }\n        } else {\n            timedOut.set(true);\n            break;\n        }\n        long startTicks = System.currentTimeMillis();\n        try {\n            watcherRef.set(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    latch.countDown();\n                }\n            });\n            zookeeper.addAndGet(watcherRef.get());\n            latch.await(remaining, TimeUnit.MILLISECONDS);\n        } finally {\n            zookeeper.remove(watcherRef.get());\n            remaining -= (System.currentTimeMillis() - startTicks);\n        }\n    }\n    if (timedOut.get()) {\n        throw new ConnectionTimeoutException(String.format(\"Zookeeper session timed out after %d ms\", connectionTimeoutMs));\n    }\n}", "CodeBleu_score": 43.736608958420064}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    long remainingWaitTime = connectionTimeoutMs;\n    CountDownLatch connectionLatch = new CountDownLatch(1);\n    while (remainingWaitTime > 0) {\n        long startTime = System.currentTimeMillis();\n        Watcher watcher = new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                if (event.getState() == Watcher.Event.KeeperState.SyncConnected) {\n                    connectionLatch.countDown();\n                }\n            }\n        };\n        try {\n            zookeeper.addWatch(\"/\", watcher, AddWatchMode.PERSISTENT);\n        } catch (Exception e) {\n            // ignore\n        }\n        try {\n            if (!connectionLatch.await(remainingWaitTime, TimeUnit.MILLISECONDS)) {\n                break;\n            }\n        } finally {\n            try {\n                zookeeper.removeWatches(\"/\", watcher, true);\n            } catch (Exception e) {\n                // ignore\n            }\n        }\n        remainingWaitTime -= (System.currentTimeMillis() - startTime);\n    }\n}", "CodeBleu_score": 42.489243485982364}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL && client.getZookeeperClient().getSessionId() != client.getZookeeperClient().getSessionId()) {\n        LOG.info(\"Session changed for {} from {} to {}. Closing old session.\", foundNode, client.getZookeeperClient().getSessionId(), client.getZookeeperClient().getSessionId());\n        client.getZookeeperClient().delete(foundNode);\n        client.getZookeeperClient().setSessionId(client.getZookeeperClient().getSessionId());\n    }\n    return foundNode;\n}", "CodeBleu_score": 28.591544975562456}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL) {\n        String sessionId = client.getZookeeperClient().getSessionId().toString();\n        if (!sessionId.equals(client.getZookeeperClient().getSessionId().toString())) {\n            LOGGER.info(\"Session changed during protected mode operation, deleting old node: {}\", foundNode);\n            client.delete().deletingChildrenIfNeeded().forPath(foundNode);\n            client.getZookeeperClient().setSessionId(UUID.fromString(sessionId));\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 40.41818791109891}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL) {\n        if (!client.getZookeeperClient().getSessionId().equals(client.getZookeeperClient().getSessionId())) {\n            LOG.warn(\"Session changed while trying to create node \" + foundNode);\n            client.getZookeeperClient().delete().forPath(foundNode);\n            client.getZookeeperClient().setSessionId(client.getZookeeperClient().getSessionId());\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 28.45104265001202}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final OperationTrace trace = curatorFramework.instrumentation().operationTrace();\n    trace.setTimeMs(System.currentTimeMillis());\n    trace.setType(CuratorEventType.SET_ACL);\n    trace.setPath(path);\n    final Stat result = curatorFramework.setACL().withACL(aclList).forPath(path);\n    trace.setResultCode(result);\n    trace.commit();\n    return result;\n}", "CodeBleu_score": 33.80512776246242}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final OperationTrace trace = new OperationTrace(this);\n    final Stat stat = new Stat();\n    final RetryLoop retryLoop = new RetryLoop(trace, this.getZookeeperClient().getRetryPolicy());\n    final BackgroundCallback callback = new BackgroundCallback() {\n        @Override\n        public void processResult(CuratorFramework client, CuratorEvent event) throws Exception {\n            trace.record(event);\n            if (event.getType() == CuratorEventType.SET_DATA) {\n                retryLoop.commit();\n            }\n        }\n    };\n    try {\n        retryLoop.start();\n        this.getZookeeperClient().setACL(path, aclList, stat, callback);\n    } finally {\n        retryLoop.commit();\n    }\n    return stat;\n}", "CodeBleu_score": 44.207167333739584}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final OperationTrace trace = new OperationTrace(\"setACL\");\n    final RetryLoop retry = client.newRetryLoop();\n    final Stat result = retry.call(new Callable<Stat>() {\n        @Override\n        public Stat call() throws Exception {\n            return client.setACL().inBackground(path, aclList).forPath(path);\n        }\n    });\n    trace.commit(result);\n    return result;\n}", "CodeBleu_score": 59.76082035030541}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkNotNull(payload, \"payload cannot be null\");\n    Preconditions.checkArgument(!thisId.contains(\"/\"), \"thisId cannot contain '/'\");\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n    this.memberPath = ZKPaths.makePath(membershipPath, thisId);\n    this.memberNode = new PersistentNode(client, memberPath, CreateMode.EPHEMERAL, payload);\n    this.cache = new CuratorCache(client, membershipPath, parentPathFilter);\n    this.cache.start();\n}", "CodeBleu_score": 48.97861149730343}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkArgument(!thisId.isEmpty(), \"thisId cannot be empty\");\n    Preconditions.checkArgument(!ZKPaths.isAbsolute(thisId), \"thisId cannot be absolute\");\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n    this.memberNode = new PersistentNode(client, ZKPaths.makePath(membershipPath, thisId), CreateMode.EPHEMERAL, payload);\n    this.cache = CuratorCache.build(client, membershipPath, parentPathFilter);\n    this.cache.start();\n}", "CodeBleu_score": 50.54497475944423}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    Preconditions.checkArgument(!ZKPaths.isAbsolute(thisId), \"id cannot be an absolute path\");\n    Preconditions.checkArgument(!ZKPaths.hasWildcard(thisId), \"id cannot contain a wildcard\");\n    this.payload = payload;\n    this.thisPath = ZKPaths.makePath(membershipPath, thisId);\n    this.cache = CuratorCache.build(client, membershipPath, parentPathFilter);\n    this.cache.start();\n    try {\n        client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).forPath(thisPath, payload);\n    } catch (Exception e) {\n        CloseableUtils.closeQuietly(this);\n        throw Throwables.propagate(e);\n    }\n}", "CodeBleu_score": 43.13973249107973}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    CompletionStage<Void> create = client.create().forPathAsync(path);\n    create.whenComplete((result, exception) -> {\n        if (exception == null) {\n            System.out.println(\"Node created: \" + path);\n            AsyncCuratorFramework asyncClient = (AsyncCuratorFramework) client;\n            asyncClient.checkExists().usingWatcher((curatorWatchedEvent) -> {\n                WatchedEvent event = curatorWatchedEvent.getWatchedEvent();\n                if (event.getType() == Watcher.Event.EventType.NodeCreated) {\n                    System.out.println(\"Node created: \" + event.getPath());\n                } else if (event.getType() == Watcher.Event.EventType.NodeDeleted) {\n                    System.out.println(\"Node deleted: \" + event.getPath());\n                }\n            }).forPath(path);\n        } else {\n            exception.printStackTrace();\n        }\n    });\n}", "CodeBleu_score": 52.63119197201187}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework asyncClient = client.async();\n    CompletionStage<Void> createStage = asyncClient.create().forPath(path);\n    createStage.whenComplete((result, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n            return;\n        }\n        asyncClient.checkExists().usingWatcher((event) -> {\n            if (event.getType() == WatchedEvent.EventType.NodeCreated) {\n                System.out.println(\"Node created: \" + event.getPath());\n            } else if (event.getType() == WatchedEvent.EventType.NodeDataChanged) {\n                System.out.println(\"Node data changed: \" + event.getPath());\n            } else if (event.getType() == WatchedEvent.EventType.NodeDeleted) {\n                System.out.println(\"Node deleted: \" + event.getPath());\n            }\n        }).forPath(path, WatchMode.persistent());\n    });\n}", "CodeBleu_score": 52.089485813429214}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework asyncClient = client.async();\n    CompletionStage<String> createResult = asyncClient.create().withMode(CreateMode.PERSISTENT).forPath(path);\n    createResult.whenComplete((result, exception) -> {\n        if (exception != null) {\n            exception.printStackTrace();\n        } else {\n            System.out.println(\"Node created: \" + result);\n            // Set up a watch on the node\n            CompletionStage<WatchedEvent> watchResult = asyncClient.checkExists().usingWatcher((curatorWatchedEvent) -> {\n                System.out.println(\"Watch event: \" + curatorWatchedEvent);\n            }).inBackground().forPath(path);\n            watchResult.whenComplete((watchEvent, watchException) -> {\n                if (watchException != null) {\n                    watchException.printStackTrace();\n                } else {\n                    System.out.println(\"Watch set up: \" + watchEvent);\n                }\n            });\n        }\n    });\n}", "CodeBleu_score": 55.40135632524594}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = zk.multi(ops);\n    if (!results.isEmpty()) {\n        OpResult firstResult = results.get(0);\n        if (firstResult.getErr() != KeeperException.Code.OK.intValue()) {\n            throw KeeperException.create(firstResult.getErr());\n        }\n    }\n    return results;\n}", "CodeBleu_score": 30.791447289189662}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = client.transaction().forOperations(ops).commit();\n    if (!results.isEmpty()) {\n        OpResult firstResult = results.get(0);\n        if (firstResult.getType() == OpResult.Type.ERROR) {\n            int code = firstResult.getErr();\n            throw KeeperException.create(code);\n        }\n    }\n    return results;\n}", "CodeBleu_score": 41.10453333971185}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = client.multi(ops);\n    if (!results.isEmpty() && results.get(0).getErr() != 0) {\n        int errorCode = results.get(0).getErr();\n        throw KeeperException.create(errorCode);\n    }\n    return results;\n}", "CodeBleu_score": 23.083983723906943}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    Collection<String> serviceNames = serviceDiscovery.queryForNames();\n    for (String serviceName : serviceNames) {\n        Collection<ServiceInstance<InstanceDetails>> serviceInstances = serviceDiscovery.queryForInstances(serviceName);\n        System.out.println(\"Instances of service: \" + serviceName);\n        for (ServiceInstance<InstanceDetails> serviceInstance : serviceInstances) {\n            System.out.println(\"Instance: \" + serviceInstance.getId() + \", Payload: \" + serviceInstance.getPayload());\n        }\n    }\n}", "CodeBleu_score": 46.69819587710033}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        Collection<String> serviceNames = serviceDiscovery.queryForNames();\n        for (String serviceName : serviceNames) {\n            Collection<ServiceInstance<InstanceDetails>> serviceInstances = serviceDiscovery.queryForInstances(serviceName);\n            System.out.println(\"Instances of service \" + serviceName + \":\");\n            for (ServiceInstance<InstanceDetails> serviceInstance : serviceInstances) {\n                System.out.println(serviceInstance.toString());\n            }\n        }\n    } catch (KeeperException.NoNodeException e) {\n        System.out.println(\"No instances registered yet.\");\n    } finally {\n        CloseableUtils.closeQuietly(serviceDiscovery);\n    }\n}", "CodeBleu_score": 68.29920746558358}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    Collection<String> services = serviceDiscovery.queryForNames();\n    System.out.println(\"Services: \" + services);\n    for (String service : services) {\n        Collection<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(service);\n        System.out.println(\"Instances of service \\\"\" + service + \"\\\": \" + instances);\n    }\n}", "CodeBleu_score": 41.00921680871607}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n        @Override\n        public boolean apply(String child) {\n            return !READY_NODE.equals(child);\n        }\n    }));\n}", "CodeBleu_score": 40.58081886541103}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    List<String> filteredChildren = Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n        @Override\n        public boolean apply(String child) {\n            return !READY_NODE.equals(child);\n        }\n    }));\n    Collections.sort(filteredChildren);\n    return filteredChildren;\n}", "CodeBleu_score": 64.49430623766241}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    Preconditions.checkNotNull(children);\n    List<String> filteredChildren = Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n        @Override\n        public boolean apply(String child) {\n            return !READY_NODE.equals(child);\n        }\n    }));\n    Collections.sort(filteredChildren);\n    return filteredChildren;\n}", "CodeBleu_score": 64.6069576688439}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n    readOnly = false;\n}", "CodeBleu_score": 24.676928834821624}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    close();\n    zk = new ZooKeeper(newHost, timeout, this);\n    readOnly = readOnly;\n}", "CodeBleu_score": 16.09164357314382}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    closeZK();\n    zk = new ZooKeeper(newHost, SESSION_TIMEOUT, this);\n    readOnly = false;\n}", "CodeBleu_score": 14.689307396855458}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<>();\n    String[] segments = aclString.split(\",\");\n    for (String segment : segments) {\n        String[] parts = segment.split(\":\");\n        if (parts.length != 3) {\n            log.error(\"Invalid ACL segment: \" + segment);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        String permissions = parts[2];\n        if (!scheme.equals(\"auth\")) {\n            log.error(\"Invalid ACL scheme: \" + scheme);\n            continue;\n        }\n        try {\n            Id aclId = new Id(scheme, id);\n            int perms = Integer.parseInt(permissions);\n            acls.add(new ACL(perms, aclId));\n        } catch (NumberFormatException e) {\n            log.error(\"Invalid ACL permissions: \" + permissions);\n        }\n    }\n    return acls;\n}", "CodeBleu_score": 27.728337732770967}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<>();\n    StringTokenizer st = new StringTokenizer(aclString, \",\");\n    while (st.hasMoreTokens()) {\n        String acl = st.nextToken();\n        StringTokenizer st2 = new StringTokenizer(acl, \":\");\n        if (st2.countTokens() != 3) {\n            throw new IOException(\"invalid acl \\\"\" + acl + \"\\\"\");\n        }\n        String scheme = st2.nextToken();\n        String id = st2.nextToken();\n        String permsString = st2.nextToken();\n        if (!scheme.equals(\"auth\")) {\n            throw new IOException(\"invalid acl \\\"\" + acl + \"\\\": unknown scheme\");\n        }\n        try {\n            byte[] idBytes = id.getBytes(StandardCharsets.UTF_8);\n            Id id2 = new Id(scheme, idBytes);\n            int perms = Integer.parseInt(permsString);\n            acls.add(new ACL(perms, id2));\n        } catch (NumberFormatException e) {\n            throw new IOException(\"invalid acl \\\"\" + acl + \"\\\": invalid permission\");\n        }\n    }\n    return acls;\n}", "CodeBleu_score": 26.239938525085947}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<>();\n    String[] aclSegments = aclString.split(\",\");\n    for (String aclSegment : aclSegments) {\n        String[] aclParts = aclSegment.split(\":\");\n        if (aclParts.length != 3) {\n            logger.error(\"Invalid ACL format: {}\", aclSegment);\n            continue;\n        }\n        String scheme = aclParts[0];\n        String id = aclParts[1];\n        String permissions = aclParts[2];\n        ACL acl = new ACL();\n        acl.setId(new Id(scheme, id));\n        acl.setPerms(Integer.parseInt(permissions));\n        acls.add(acl);\n    }\n    return acls;\n}", "CodeBleu_score": 33.58023112313735}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null) {\n        throw new IllegalArgumentException(\"Path list cannot be null\");\n    }\n\n    Zookeeper zookeeper = zookeeperFactory.getZookeeper(serverId);\n    if (zookeeper == null) {\n        throw new IllegalArgumentException(\"Zookeeper connection not found for server ID: \" + serverId);\n    }\n\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeper.delete(path);\n        }\n    } else {\n        zookeeper.deleteAsync(pathList);\n    }\n}", "CodeBleu_score": 56.033647929378816}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null) {\n        return;\n    }\n    Zookeeper zookeeper = zookeeperFactory.getZookeeper(serverId);\n    if (!zookeeper.isConnected()) {\n        throw new Exception(\"Zookeeper is not connected\");\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeper.delete(path);\n        }\n    } else {\n        for (String path : pathList) {\n            zookeeper.deleteAsync(path);\n        }\n    }\n}", "CodeBleu_score": 56.7391961391434}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null) {\n        throw new IllegalArgumentException(\"The path list cannot be null.\");\n    }\n    Zookeeper zookeeper = zookeeperFactory.getZookeeper(serverId);\n    if (zookeeper == null) {\n        throw new IllegalArgumentException(\"The server ID is invalid.\");\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            zookeeper.delete(path);\n        }\n    } else {\n        for (String path : pathList) {\n            zookeeper.deleteAsync(path);\n        }\n    }\n}", "CodeBleu_score": 55.21852377003346}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t        writer.write(\"connecting to \" + url);\n        var connection = CuratorZookeeperConnectionFactory.create(\n                ZookeeperParams.builder()\n                        .connectionString(url)\n                        .connectionTimeoutMs(5000)\n                        .sessionTimeoutMs(5000)\n                        .build());\n        var zk = connection.getZookeeper();\n        writer.write(\"connect to \" + url + \" success\");\n        return new Terminal(id, url, connection, new ZooKeeperMain(zk));\n    }", "CodeBleu_score": 48.33643998788473}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t        writer.write(\"Connecting to Zookeeper: \" + url);\n        ZookeeperParams params = ZookeeperParams.builder().url(url).build();\n        CuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n        Zookeeper zookeeper = factory.create(params);\n        writer.write(\"Successfully connected to Zookeeper: \" + url);\n        ZooKeeperMain main = new ZooKeeperMain(zookeeper);\n        return new Terminal(id, url, zookeeper, main);\n    }", "CodeBleu_score": 46.8130446903089}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    ZookeeperParams params = new ZookeeperParams(id, url);\n    writer.write(\"connecting to zookeeper: \" + id + \" \" + url);\n    CuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n    Zookeeper zookeeper = factory.create(params);\n    writer.write(\"success\");\n    ZooKeeperMain zooKeeperMain = new ZooKeeperMain(zookeeper);\n    return new Terminal(id, url, zookeeper, zooKeeperMain);\n}", "CodeBleu_score": 41.556356418000775}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (retries > 0) {\n        try {\n            sshClient.connect(sshHost, sshPort);\n            sshClient.authPassword(sshUser, sshPassword);\n            sshClient.newLocalPortForwarder(new LocalPortForwarder.Parameters(sshLocalPort, sshRemoteHost, sshRemotePort), new LocalPortForwarder.Callback() {\n                @Override\n                public void onOpen(LocalPortForwarder.Forwarding forwarding) {\n                    log.info(\"SSH tunnel established\");\n                }\n\n                @Override\n                public void onClose(LocalPortForwarder.Forwarding forwarding) {\n                    log.info(\"SSH tunnel closed\");\n                }\n            });\n            return;\n        } catch (IOException e) {\n            log.error(\"Error establishing SSH tunnel\", e);\n            try {\n                sshClient.close();\n            } catch (IOException e1) {\n                log.error(\"Error closing SSH tunnel\", e1);\n            }\n        }\n        retries--;\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            log.error(\"Error sleeping\", e);\n        }\n    }\n    throw new IllegalStateException(\"SSH tunnel failed to establish\");\n}", "CodeBleu_score": 34.189044541326346}, {"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (retries > 0) {\n        try {\n            sshClient.connect(host, port);\n            sshClient.authPassword(username, password);\n            sshClient.newLocalPortForwarder(\n                    new InetSocketAddress(\"localhost\", localPort),\n                    new InetSocketAddress(remoteHost, remotePort),\n                    Parameters.DEFAULT\n            ).call();\n            return;\n        } catch (IOException e) {\n            log.error(\"Failed to connect to SSH tunnel\", e);\n            try {\n                sshClient.close();\n            } catch (IOException ex) {\n                log.error(\"Failed to close SSH client\", ex);\n            }\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException ex) {\n                log.error(\"Interrupted while waiting for SSH tunnel\", ex);\n            }\n            retries--;\n        }\n    }\n    try {\n        sshClient.close();\n    } catch (IOException e) {\n        log.error(\"Failed to close SSH client\", e);\n    }\n    throw new IllegalStateException(\"Failed to establish SSH tunnel connection\");\n}", "CodeBleu_score": 34.90265701385907}, {"code": "public void blockUntilConnected(){\n\t    int retries = 6;\n    while (retries > 0) {\n        try {\n            sshClient.connect(sshHost, sshPort);\n            sshClient.authPassword(sshUsername, sshPassword);\n            sshClient.newLocalPortForwarder(new LocalPortForwarder.Parameters(localPort, remoteHost, remotePort), new RemotePortForwardingCallback());\n            return;\n        } catch (IOException e) {\n            log.error(\"Failed to establish SSH tunnel connection. Retrying...\", e);\n            try {\n                sshClient.close();\n            } catch (IOException ex) {\n                log.error(\"Failed to close SSH client.\", ex);\n            }\n        }\n        retries--;\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            log.error(\"Thread interrupted while waiting for SSH tunnel connection.\", e);\n            Thread.currentThread().interrupt();\n        }\n    }\n    try {\n        sshClient.close();\n    } catch (IOException e) {\n        log.error(\"Failed to close SSH client.\", e);\n    }\n    throw new IllegalStateException(\"Failed to establish SSH tunnel connection.\");\n}", "CodeBleu_score": 35.0938703233496}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        LOGGER.error(\"delete node error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 84.41755236224664}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"delete node error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 84.76376463468107}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"delete node error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 88.00958964464397}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfigurationVO serverConfigurationVO = configurationDomainService.getServerConfigurationById(id);\n        zookeeperDomainService.disconnect(id);\n        treeItemCache.removeServer(id);\n    });\n}", "CodeBleu_score": 47.50976357479726}, {"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfigurationVO serverConfigurationVO = configurationDomainService.getServerConfigurationById(id);\n        zookeeperDomainService.disconnect(serverConfigurationVO.getId());\n        treeItemCache.remove(serverConfigurationVO);\n    });\n}", "CodeBleu_score": 51.87774234610774}, {"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        ServerConfigurationVO serverConfigurationVO = getServerConfigurationVOById(id);\n        if (serverConfigurationVO == null) {\n            return;\n        }\n        ConfigurationDomainService configurationDomainService = SpringContext.getBean(ConfigurationDomainService.class);\n        ServerConfiguration serverConfiguration = configurationDomainService.findServerConfigurationById(serverConfigurationVO.getId());\n        if (serverConfiguration == null) {\n            return;\n        }\n        ZookeeperDomainService zookeeperDomainService = SpringContext.getBean(ZookeeperDomainService.class);\n        zookeeperDomainService.disconnect(serverConfiguration.getId());\n        TreeItemCache.remove(id);\n    });\n}", "CodeBleu_score": 48.89253409975724}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfiguration serverConfiguration = configurationDomainService.findServerConfigurationById(serverId);\n    String connectionUrl = serverConfiguration.getSshTunnelConfiguration().isEnabled()\n            ? serverConfiguration.getSshTunnelConfiguration().getConnectionUrl()\n            : serverConfiguration.getConnectionUrl();\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 42.742989832276315}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfiguration serverConfiguration = configurationDomainService.getServerConfiguration(serverId);\n    String connectionUrl = serverConfiguration.getConnectionUrl();\n    if (serverConfiguration.isSshTunnelEnabled()) {\n        SSHTunnelConfiguration sshTunnelConfiguration = serverConfiguration.getSshTunnelConfiguration();\n        connectionUrl = String.format(\"ssh://%s:%d@%s:%d\",\n                sshTunnelConfiguration.getUsername(),\n                sshTunnelConfiguration.getPort(),\n                sshTunnelConfiguration.getHost(),\n                sshTunnelConfiguration.getPort());\n    }\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 40.67626723245949}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfiguration serverConfiguration = configurationDomainService.getServerConfiguration(serverId);\n    String connectionUrl = serverConfiguration.getConnectionUrl();\n    if (serverConfiguration.isEnableSshTunnel()) {\n        SSHTunnelConfiguration sshTunnelConfiguration = serverConfiguration.getSshTunnelConfiguration();\n        connectionUrl = sshTunnelConfiguration.getHost() + \":\" + sshTunnelConfiguration.getPort();\n    }\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 46.054537932621464}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t    Try.run(() -> {\n        Optional<ServerConfigurationVO> server = serverList.stream()\n                .filter(s -> s.getId().equals(id))\n                .findFirst();\n        if (server.isEmpty()) {\n            return;\n        }\n        ServerConfigurationVO serverConfigurationVO = server.get();\n        Optional<ConnectionConfigurationVO> connectionConfiguration = connectionList.stream()\n                .filter(c -> c.getId().equals(serverConfigurationVO.getConnectionId()))\n                .findFirst();\n        if (connectionConfiguration.isEmpty()) {\n            return;\n        }\n        ConnectionConfigurationVO connectionConfigurationVO = connectionConfiguration.get();\n        String commandResult = commandService.executeCommand(connectionConfigurationVO, command);\n        if (Strings.isNullOrEmpty(commandResult)) {\n            return;\n        }\n        StringWriter stringWriter = new StringWriter();\n        stringWriter.write(\"\u6267\u884c\u7ed3\u679c\uff1a\n\");\n        stringWriter.write(commandResult);\n        VToast.show(stringWriter.toString());\n    }).onFailure(e -> {\n        LOGGER.error(\"server:{} command:{}\", id, command, e);\n        VToast.show(\"\u6267\u884c\u5931\u8d25\uff0c\u8bf7\u91cd\u8bd5\");\n    });\n}", "CodeBleu_score": 33.429301449800874}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        configurationDomainService.executeCommand(id, command);\n    } catch (Exception e) {\n        LOGGER.error(\"execute command error, server id: {}, command: {}\", id, command, e);\n        Platform.runLater(() -> VToast.error(ResourceBundleUtils.get(LocaleContext.getLocale(), \"execute.command.failed.and.should.be.retried\")));\n    }\n}", "CodeBleu_score": 53.650428266476084}, {"code": "public void executeCommand(String id, String command){\n\t    ServerConfiguration serverConfiguration = configurationDomainService.getServerConfiguration(id);\n    if (serverConfiguration == null) {\n        logger.error(\"server not found, id: {}\", id);\n        return;\n    }\n\n    try {\n        zookeeperDomainService.executeCommand(serverConfiguration, command);\n    } catch (Exception e) {\n        logger.error(\"execute command error, id: {}, command: {}\", id, command, e);\n        Platform.runLater(() -> {\n            VToast.error(ResourceBundleUtils.getString(\"command.execute.error\", LocaleContext.getLocale()));\n        });\n    }\n}", "CodeBleu_score": 41.29593896126511}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t    String zkSystemPropertiesPath = System.getProperty(\"zk.system.properties.path\");\n    Properties properties = new Properties();\n    if (zkSystemPropertiesPath != null) {\n        File file = new File(zkSystemPropertiesPath);\n        if (file.exists()) {\n            try (InputStream inputStream = new FileInputStream(file)) {\n                properties.load(inputStream);\n                LOGGER.info(\"Load zk system properties from {}\", zkSystemPropertiesPath);\n            } catch (IOException e) {\n                LOGGER.error(\"Load zk system properties from {} failed\", zkSystemPropertiesPath, e);\n            }\n        } else {\n            LOGGER.warn(\"Zk system properties file not found: {}\", zkSystemPropertiesPath);\n        }\n    }\n    return properties;\n}", "CodeBleu_score": 45.19424727386847}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    String filePath = System.getProperty(\"user.home\") + File.separator + \".zkui\" + File.separator + \"zkui.properties\";\n    File file = new File(filePath);\n    if (file.exists()) {\n        try (InputStream inputStream = new FileInputStream(file)) {\n            properties.load(inputStream);\n            logger.info(\"load zkui.properties success, file path: {}\", filePath);\n        } catch (IOException e) {\n            logger.error(\"load zkui.properties error\", e);\n        }\n    } else {\n        logger.info(\"zkui.properties not found, file path: {}\", filePath);\n    }\n    return properties;\n}", "CodeBleu_score": 46.25830795068634}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    String path = System.getProperty(\"user.home\") + \"/.zoo.properties\";\n    File file = new File(path);\n    if (!file.exists()) {\n        logger.warn(\"zoo.properties not found\");\n        return new Properties();\n    }\n    try (InputStream inputStream = new FileInputStream(file)) {\n        Properties properties = new Properties();\n        properties.load(inputStream);\n        logger.info(\"load zoo properties: {}\", properties);\n        return properties;\n    } catch (IOException e) {\n        logger.error(\"load zoo properties error\", e);\n        return new Properties();\n    }\n}", "CodeBleu_score": 52.080254469776186}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try (StringReader reader = new StringReader(content)) {\n        properties.load(reader);\n    } catch (IOException e) {\n        LOGGER.error(\"load zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.get(\"save.zookeeper.system.properties.error\"));\n        return;\n    }\n\n    try (OutputStream outputStream = Files.newOutputStream(Paths.get(SYS_PROP_PATH))) {\n        properties.store(outputStream, \"\");\n    } catch (IOException e) {\n        LOGGER.error(\"save zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.get(\"save.zookeeper.system.properties.error\"));\n        return;\n    }\n    VToast.success(ResourceBundleUtils.get(\"save.zookeeper.system.properties.success\"));\n}", "CodeBleu_score": 49.98150966220144}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try (StringReader reader = new StringReader(content)) {\n        properties.load(reader);\n    } catch (IOException e) {\n        LOGGER.error(\"load zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.get(\"message.zookeeper.system.properties.load.error\"));\n        return;\n    }\n    try (OutputStream out = new FileOutputStream(SYS_PROP_PATH)) {\n        properties.store(out, \"\");\n    } catch (IOException e) {\n        LOGGER.error(\"save zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.get(\"message.zookeeper.system.properties.save.error\"));\n    }\n}", "CodeBleu_score": 48.76377375686859}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try (StringReader reader = new StringReader(content)) {\n        properties.load(reader);\n    } catch (IOException e) {\n        LOGGER.error(\"load zookeeper system properties failed\", e);\n        VToast.error(ResourceBundleUtils.getString(\"save_zookeeper_system_properties_failed\"));\n        return;\n    }\n    try (OutputStream outputStream = Files.newOutputStream(Paths.get(SYS_PROP_PATH))) {\n        properties.store(outputStream, null);\n    } catch (IOException e) {\n        LOGGER.error(\"save zookeeper system properties failed\", e);\n        VToast.error(ResourceBundleUtils.getString(\"save_zookeeper_system_properties_failed\"));\n    }\n}", "CodeBleu_score": 52.72691177837171}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line).append(\"\n\");\n        }\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.114013476423445}, {"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line).append(\"\n\");\n        }\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.114013476423445}, {"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder response = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            response.append(line).append(\"\n\");\n        }\n        client.close();\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.114013476423445}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    // Create a logger for the class\n    Logger logger = LoggerFactory.getLogger(ZookeeperConnectionFactory.class);\n\n    // Create a RetryPolicy with an exponential backoff strategy\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n\n    // Create an AuthInfo object with the provided username and password\n    AuthInfo authInfo = new AuthInfo(params.getUsername(), params.getPassword().getBytes());\n\n    // Create an ACLProvider object with the provided ACLs\n    ACLProvider aclProvider = new ACLProvider() {\n        @Override\n        public List<ACL> getDefaultAcl() {\n            return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n        }\n\n        @Override\n        public List<ACL> getAclForPath(String path) {\n            return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n        }\n    };\n\n    // Create a CuratorFramework client with the provided parameters\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(params.getConnectionString())\n            .retryPolicy(retryPolicy)\n            .authorization(authInfo)\n            .aclProvider(aclProvider)\n            .build();\n\n    // Start the client\n    client.start();\n\n    // Wait up to 5 seconds for the connection to be established\n    try {\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            // If the connection fails, close the client and throw an exception\n            client.close();\n            throw new RuntimeException(\"Failed to connect to Zookeeper\");\n        }\n    } catch (InterruptedException e) {\n        // If the connection is interrupted, close the client and throw an exception\n        client.close();\n        throw new RuntimeException(\"Interrupted while waiting for Zookeeper connection\", e);\n    }\n\n    // Add a ConnectionStateListener to the client\n    client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState newState) {\n           ", "CodeBleu_score": 52.17900725728934}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    final Logger logger = LoggerFactory.getLogger(CuratorZookeeperConnectionFactory.class);\n    try {\n        // Create a new CuratorFramework client with the provided parameters\n        CuratorFramework client = CuratorFrameworkFactory.builder()\n                .connectString(params.getConnectionString())\n                .sessionTimeoutMs(params.getSessionTimeoutMs())\n                .connectionTimeoutMs(params.getConnectionTimeoutMs())\n                .retryPolicy(new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries()))\n                .namespace(params.getNamespace())\n                .aclProvider(new ACLProvider() {\n                    @Override\n                    public List<ACL> getDefaultAcl() {\n                        return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n                    }\n\n                    @Override\n                    public List<ACL> getAclForPath(String s) {\n                        return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n                    }\n                })\n                .build();\n\n        // Start the client\n        client.start();\n\n        // Wait up to 5 seconds for the connection to be established\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            throw new IllegalStateException(\"Failed to connect to Zookeeper within 5 seconds\");\n        }\n\n        // Return a new CuratorZookeeperConnection with the provided parameters\n        return new CuratorZookeeperConnection(client, params);\n    } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n        throw new IllegalStateException(\"Interrupted while waiting for Zookeeper connection\", e);\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to create Zookeeper connection\", e);\n    }\n}", "CodeBleu_score": 49.501751613936364}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    Logger logger = LoggerFactory.getLogger(CuratorZookeeperConnectionFactory.class);\n\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(params.getAddress())\n            .sessionTimeoutMs(params.getSessionTimeout())\n            .connectionTimeoutMs(params.getConnectionTimeout())\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    try {\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            throw new IllegalStateException(\"Failed to connect to Zookeeper\");\n        }\n    } catch (InterruptedException e) {\n        client.close();\n        throw new IllegalStateException(\"Interrupted while waiting for Zookeeper connection\", e);\n    }\n\n    return new CuratorZookeeperConnection(client, params.getNamespace(), params.getAuthInfo(), params.getAclProvider());\n}", "CodeBleu_score": 55.038559966461484}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = zookeeperConnection.getConnectionString();\n    if (!synchronizing.get()) {\n        LOGGER.info(\"Starting synchronization for connection string: {}\", connectionString);\n        TreeCache cache = new TreeCache(client, \"/\");\n        cache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        try {\n            cache.start();\n        } catch (Exception e) {\n            LOGGER.error(\"Error starting synchronization for connection string: {}\", connectionString, e);\n            cache.close();\n        }\n        synchronizing.set(true);\n    } else {\n        LOGGER.info(\"Synchronization already in progress for connection string: {}\", connectionString);\n    }\n}", "CodeBleu_score": 45.07631203453083}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t        String connectionString = zookeeperConnection.getConnectionString();\n        if (!syncing.getAndSet(true)) {\n            LOGGER.info(\"Start syncing nodes from zookeeper: {}\", connectionString);\n            treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n            try {\n                treeCache.start();\n            } catch (Exception e) {\n                LOGGER.error(\"Failed to start tree cache for zookeeper: {}\", connectionString, e);\n                treeCache.close();\n            }\n        } else {\n            LOGGER.info(\"Syncing nodes from zookeeper: {} is already in progress\", connectionString);\n        }\n    }", "CodeBleu_score": 45.21206787558577}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t        String connectionString = zookeeperConnection.getConnectionString();\n        if (!synchronizing.get()) {\n            LOGGER.info(\"Start synchronizing nodes from Zookeeper [{}]\", connectionString);\n            treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n            try {\n                treeCache.start();\n            } catch (Exception e) {\n                LOGGER.error(\"Error synchronizing nodes from Zookeeper [{}]\", connectionString, e);\n                treeCache.close();\n            }\n        } else {\n            LOGGER.info(\"Already synchronizing nodes from Zookeeper [{}]\", connectionString);\n        }\n    }", "CodeBleu_score": 44.92618713309782}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 73.84492591071368}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 61.61525132234349}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache pathChildrenCache = new PathChildrenCache(client, path, true);\n    //BUILD_INITIAL_CACHE \u4ee3\u8868\u4f7f\u7528\u540c\u6b65\u7684\u65b9\u5f0f\u8fdb\u884c\u7f13\u5b58\u521d\u59cb\u5316\u3002\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 99.8143270836795}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t        logger.info(\"Unregister all service on zookeeper\");\n        List<String> paths = new ArrayList<>();\n        for (Map.Entry<String, RpcServiceInfo> entry : handlerMap.entrySet()) {\n        paths.add(Constant.ZK_REGISTRY_PATH + \"/\" + entry.getKey());\n        }\n        for (String path : paths) {\n        try {\n        client.delete().forPath(path);\n        } catch (Exception e) {\n        logger.error(\"Delete node error: \" + e.getMessage());\n        }\n        }\n        client.close();\n        }", "CodeBleu_score": 39.52397520824032}, {"code": "public void unregisterService(){\n\t    LOGGER.info(\"Unregister all service on zookeeper\");\n    // get node info from local cache\n    Map<String, Object> serviceMap = ServiceUtil.getServiceMap();\n    if (serviceMap.isEmpty()) {\n        return;\n    }\n    List<String> pathList = new ArrayList<>();\n    for (String key : serviceMap.keySet()) {\n        pathList.add(Constant.ZK_REGISTRY_PATH + \"/\" + key);\n    }\n    // delete service node\n    for (String path : pathList) {\n        try {\n            if (null != client.checkExists().forPath(path)) {\n                client.delete().forPath(path);\n                LOGGER.info(\"Service node delete: {}\", path);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"Delete service node exception: {}\", e.getMessage());\n        }\n    }\n    client.close();\n}", "CodeBleu_score": 33.21482152877893}, {"code": "public void unregisterService(){\n\t        logger.info(\"Unregister all service on zookeeper\");\n        for (String path : pathList) {\n            try {\n                if (null != path) {\n                    client.delete().forPath(path);\n                }\n            } catch (Exception ex) {\n                logger.error(\"Delete path error: \" + ex.getMessage());\n            }\n        }\n        this.close();\n    }", "CodeBleu_score": 71.51612016161147}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture.runAsync(() -> {\n        try {\n            makeClientReady();\n            client.subscribeStateChanges(listener);\n        } catch (Exception e) {\n            LOG.error(\"Failed to subscribe state changes\", e);\n        }\n    });\n}", "CodeBleu_score": 31.20640482311715}, {"code": "public void addListener(IZkStateListener listener){\n\t  CompletableFuture.runAsync(() -> {\n    try {\n      makeClientReady();\n    } catch (Exception e) {\n      logger.error(\"Error while making client ready\", e);\n    }\n  }).thenRun(() -> {\n    client.subscribeStateChanges(listener);\n  });\n}", "CodeBleu_score": 31.07504287596068}, {"code": "public void addListener(IZkStateListener listener){\n\t  CompletableFuture.runAsync(() -> {\n    try {\n      makeClientReady();\n    } catch (Exception e) {\n      LOG.error(\"Exception while making client ready\", e);\n    }\n  }).thenRun(() -> {\n    client.subscribeStateChanges(listener);\n  });\n}", "CodeBleu_score": 31.54844179902202}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this(serverAddr, authority, 1000, 3000, 3000, 1000);\n}", "CodeBleu_score": 3.410257438317601}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this(serverAddr, authority, 1000, 3000, 3000);\n}", "CodeBleu_score": 3.410257375945607}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    // 1.Connect string to zookeeper server\n    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder().connectString(serverAddr)\n            .retryPolicy(new RetryNTimes(1, 1000))\n            .connectionTimeoutMs(5000);\n    if (authority != null && authority.length() > 0) {\n        builder.authorization(\"digest\", authority.getBytes());\n    }\n    client = builder.build();\n    // 2.Connection state listener\n    client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState state) {\n            if (state == ConnectionState.LOST) {\n                CuratorZookeeperClient.this.state = State.DISCONNECTED;\n                if (stateListener != null) {\n                    stateListener.disconnected();\n                }\n            } else if (state == ConnectionState.CONNECTED) {\n                CuratorZookeeperClient.this.state = State.CONNECTED;\n                if (stateListener != null) {\n                    stateListener.connected();\n                }\n            } else if (state == ConnectionState.RECONNECTED) {\n                CuratorZookeeperClient.this.state = State.RECONNECTED;\n                if (stateListener != null) {\n                    stateListener.reconnected();\n                }\n            }\n        }\n    });\n    // 3.Start client\n    client.start();\n    // 4.Wait init\n    init();\n}", "CodeBleu_score": 67.3997785510992}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    ConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener();\n        }\n    }\n}", "CodeBleu_score": 77.45650802326878}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    ConcurrentMap<ChildListener, TargetChildListener> listeners = this.childListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener();\n        }\n    }\n}", "CodeBleu_score": 75.03033435714444}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    ConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.removeListener();\n            if (listeners.isEmpty()) {\n                childListeners.remove(path);\n            }\n        }\n    }\n}", "CodeBleu_score": 75.98072630092874}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (NULL == zh) {\n        return QCONF_ERR_OTHER;\n    }\n\n    std::string idc;\n    std::string host;\n\n    if (QCONF_OK != qconf_zk_get_idc_host(zh, idc, host)) {\n        return QCONF_ERR_OTHER;\n    }\n\n    qconf_zk_close(zh);\n\n    zh = qconf_zk_init(idc.c_str(), host.c_str(), g_zk_recv_timeout);\n    if (NULL == zh) {\n        return QCONF_ERR_OTHER;\n    }\n\n    if (QCONF_OK != qconf_zk_set_idc_host(zh, idc, host)) {\n        qconf_zk_close(zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    if (QCONF_OK != qconf_zk_init_env(zh)) {\n        qconf_zk_close(zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    if (QCONF_OK != qconf_zk_reset_table_watcher(zh)) {\n        qconf_zk_close(zh);\n        return QCONF_ERR_OTHER;\n    }\n\n    return QCONF_OK;\n}", "CodeBleu_score": 36.65632723568508}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    if (NULL == zh) {\n        return QCONF_ERR_ZHANDLE;\n    }\n\n    // retrieve and delete the IDC host information associated with the handle\n    std::string idc;\n    std::string host;\n    if (QCONF_OK != qconf_shm_get_idc_host(idc, host)) {\n        return QCONF_ERR_SHM;\n    }\n    qconf_shm_del_idc_host();\n\n    // close the old handle\n    zookeeper_close(zh);\n\n    // deserialize the IDC and host information\n    std::vector < std::string > idc_host_vec;\n    if (QCONF_OK != qconf_format_idc_host(idc_host_vec, idc, host)) {\n        return QCONF_ERR_FORMAT;\n    }\n\n    // initialize a new ZooKeeper handle with this information\n    zh = zookeeper_init(idc_host_vec[0].c_str(), watcher_global_watcher, 10000, 0, 0, 0);\n    if (NULL == zh) {\n        return QCONF_ERR_ZHANDLE;\n    }\n\n    // initialize the environment for the new handle\n    if (QCONF_OK != qconf_env_init(zh)) {\n        return QCONF_ERR_ENV;\n    }\n\n    // reset the table watcher\n    if (QCONF_OK != qconf_watcher_reset()) {\n        return QCONF_ERR_WATCHER;\n    }\n\n    return QCONF_OK;\n}", "CodeBleu_score": 33.7892763499005}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\n    if (NULL == zh) {\n\n        QCONF_LOG_ERROR(\"The zookeeper handle is null.\");\n\n        return QCONF_ERR_OTHER;\n\n    }\n\n    std::string idc;\n\n    std::string host;\n\n    int ret = qconf_shm_get_idc_host(idc, host);\n\n    if (QCONF_OK != ret) {\n\n        QCONF_LOG_ERROR(\"Failed to get the idc host information from shared memory, errno: %d\", ret);\n\n        return ret;\n\n    }\n\n    qconf_shm_del_idc_host();\n\n    ret = qconf_zoo_deserialize_idc_host(idc, host);\n\n    if (QCONF_OK != ret) {\n\n        QCONF_LOG_ERROR(\"Failed to deserialize the idc host information, errno: %d\", ret);\n\n        return ret;\n\n    }\n\n    zookeeper_close(zh);\n\n    zh = qconf_zoo_init(idc, host, g_qconf_zoo_recv_timeout);\n\n    if (NULL == zh) {\n\n        QCONF_LOG_ERROR(\"Failed to initialize the zookeeper handle.\");\n\n        return QCONF_ERR_OTHER;\n\n    }\n\n    ret = qconf_watcher_init_env(zh);\n\n    if (QCONF_OK != ret) {\n\n        QCONF_LOG_ERROR(\"Failed to initialize the environment for the zookeeper handle, errno: %d\", ret);\n\n        return ret;\n\n    }\n\n    ret = qconf_watcher_reset_table_watcher();\n\n    if (QCONF_OK != ret) {\n\n        QCONF_LOG_ERROR(\"Failed to reset the table watcher, errno: %d\", ret);\n\n        return ret;\n\n    }\n\n    return QCONF_OK;\n\n}", "CodeBleu_score": 41.49135830856821}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n    if (NULL == zh) {\n\n        QCONF_LOG_ERROR << \"zh is null\" << endl;\n\n        return;\n\n    }\n\n    if (idc_host.empty()) {\n\n        QCONF_LOG_ERROR << \"idc_host is empty\" << endl;\n\n        return;\n\n    }\n\n    if (idc.empty()) {\n\n        QCONF_LOG_ERROR << \"idc is empty\" << endl;\n\n        return;\n\n    }\n\n    zoo_state_t state = zoo_state(zh);\n\n    if (state != ZOO_CONNECTED_STATE) {\n\n        QCONF_LOG_ERROR << \"zk is not connected, state:\" << state << endl;\n\n        return;\n\n    }\n\n    int ret = zoo_register(zh, ZK_NOTIFY_NODE, idc_host.c_str(), idc_host.size());\n\n    if (ret != ZOK) {\n\n        QCONF_LOG_ERROR << \"zoo_register failed, ret:\" << ret << endl;\n\n        return;\n\n    }\n\n    ret = zoo_awexists(zh, ZK_NOTIFY_NODE, zk_watcher, (void *) idc.c_str(), NULL);\n\n    if (ret != ZOK) {\n\n        QCONF_LOG_ERROR << \"zoo_awexists failed, ret:\" << ret << endl;\n\n        return;\n\n    }\n\n    if (ZOK == ret) {\n\n        QCONF_LOG_INFO << \"zoo_awexists success\" << endl;\n\n        return;\n\n    }\n\n    if (ZNONODE == ret) {\n\n        QCONF_LOG_ERROR << \"zoo_awexists failed, ret:\" << ret << endl;\n\n        return;\n\n    }\n\n    if (ZNOAUTH == ret) {\n\n        QCONF_LOG_ERROR << \"zoo_awexists failed, ret:\" << ret << endl;\n\n        return;", "CodeBleu_score": 42.53583281787484}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n    if (!zh) {\n\n        return;\n\n    }\n\n    ZkHostInfo host_info;\n\n    host_info.host = idc_host;\n\n    host_info.idc = idc;\n\n    zk_host_map[zh] = host_info;\n\n    zk_handle_map[idc_host] = zh;\n\n    int ret = zoo_exists(zh, ZK_NOTIFY_PATH, 0, NULL);\n\n    if (ret != ZOK) {\n\n        LOG_ERR(\"zoo_exists failed, ret: %d\", ret);\n\n        return;\n\n    }\n\n    ret = zoo_wget(zh, ZK_NOTIFY_PATH, zk_watcher, NULL, zk_watcher_ctx, NULL);\n\n    if (ret != ZOK) {\n\n        LOG_ERR(\"zoo_wget failed, ret: %d\", ret);\n\n        return;\n\n    }\n\n    if (ret == ZOK) {\n\n        if (idc_host.find(\"gray\") != string::npos) {\n\n            gray_list.insert(idc);\n\n            LOG_INFO(\"add gray idc: %s\", idc.c_str());\n\n        }\n\n    }\n\n}", "CodeBleu_score": 47.696608279431956}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n    if (!zh) {\n        return;\n    }\n\n    // update internal tables with the handle and host information\n    ZkHandleTable::Instance()->SetHandle(idc_host, zh);\n    ZkHostTable::Instance()->SetHost(zh, idc_host);\n\n    // check the connection state of the Zookeeper handle\n    if (ZOK != zoo_state(zh)) {\n        return;\n    }\n\n    // register the current host on the Zookeeper server\n    RegisterHost(zh, idc_host);\n\n    // set a watcher on the notify node\n    int ret = zoo_wexists(zh, ZK_NOTIFY_NODE, ZkWatcher, NULL, NULL);\n\n    // add the IDC to a gray list if the operation fails\n    if (ZOK != ret) {\n        LOG_ERR(\"failed to set watcher on zk node:%s, ret:%d\", ZK_NOTIFY_NODE, ret);\n        ZkGrayTable::Instance()->AddGray(idc);\n    }\n}", "CodeBleu_score": 42.36595014883846}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    credential = username + ':' + b64encode(hashlib.sha1(password).digest()).decode('utf-8')\n    return credential\n\n", "CodeBleu_score": 27.48518671811613}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    credential = username + \":\" + hashlib.sha1(password.encode()).hexdigest()\n    return b64encode(credential.encode()).decode()\n\n", "CodeBleu_score": 26.90069114636269}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    credential = username + \":\" + b64encode(hashlib.sha1(password).digest()).decode()\n    return credential\n\n", "CodeBleu_score": 29.514933736580883}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.client is None:\n        return False\n    lock_path = self.lock_path\n    if lock_path is None:\n        return False\n    try:\n        self.client.sync(lock_path)\n        lock_value = self.client.get(lock_path)[0]\n        return lock_value == self.instance_id\n    except NoNodeError:\n        return False\n\n", "CodeBleu_score": 41.15892589904478}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    lock_path = self.processing_element.get_lock_path()\n    try:\n        data, _ = self.zk.get(lock_path)\n        return data.decode('utf-8') == self.instance_id\n    except NoNodeError:\n        return False\n\n", "CodeBleu_score": 42.92883539894596}, {"code": "def holds_lock(self)\n\t\n    if not self._id:\n        return False\n\n    lock_path = self._lock_path\n    if not lock_path:\n        return False\n\n    try:\n        data, _ = self._zk.get(lock_path)\n        return data == self._id\n    except NoNodeError:\n        return False\n\n", "CodeBleu_score": 33.212416330044}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    try:\n        self.processing_element.delete(self.client.handler.guid)\n    except NoNodeError:\n        return False\n    self.processing_element = None\n    return True\n\n", "CodeBleu_score": 22.609098799346658}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    try:\n        self.client.transaction(\n            function=self.delete_lock_and_entry,\n            function_args=(self.processing_element,),\n            function_kwargs={},\n            sync=True,\n        )\n        self.processing_element = None\n        return True\n    except ForceRetryError:\n        return False\n\n", "CodeBleu_score": 30.449230663846844}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if not self.is_acquired:\n        return False\n    try:\n        self.zk.delete(self.processing_element, recursive=True)\n        self.processing_element = None\n        return True\n    except NoNodeError:\n        return False\n    except ForceRetryError:\n        return False\n\n", "CodeBleu_score": 27.685451430375196}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        readable, _, _ = select.select([self.sock], [], [], read_timeout)\n        if not readable:\n            return\n        header, buffer = self._read_header_and_buffer()\n        if header.xid == Ping.PING_XID:\n            self.logger.debug(\"Received ping response\")\n            self.outstanding_ping = False\n        elif header.xid == Auth.AUTH_XID:\n            self._handle_auth_response(header, buffer)\n        elif header.xid == Watch.WATCH_XID:\n            self._process_watch_events(header, buffer)\n        else:\n            self.logger.debug(\"Received response: %s\", header)\n            self._read_response(header, buffer)\n    except socket.error as exc:\n        self.logger.error(\"Error reading from socket: %s\", exc)\n        self.state = KeeperState.LOST\n        self.exception = exc\n\n", "CodeBleu_score": 37.123820544740056}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = self._read_struct(ReplyHeader)\n    except socket.timeout:\n        raise TimeoutError\n    except socket.error as e:\n        raise ConnectionDropped(e)\n\n    if header.xid == Ping.PING_XID:\n        self._logger.debug(\"Received ping\")\n        self._outstanding_ping = False\n        return\n\n    if header.xid == Auth.AUTH_XID:\n        self._handle_auth(header)\n        return\n\n    if header.xid == Watch.WATCH_XID:\n        self._handle_watch(header)\n        return\n\n    self._logger.debug(\"Received %s\", header)\n    if header.xid not in self._pending_requests:\n        self._logger.warning(\n            \"Received a response for a request we didn't send: %s\", header\n        )\n        return\n\n    self._process_response(header)\n\n", "CodeBleu_score": 34.26160892188298}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = self._read_struct(ReplyHeader)\n    except socket.timeout:\n        raise ConnectionDropped\n    except socket.error as e:\n        if e.errno == errno.ECONNRESET:\n            raise ConnectionDropped\n        else:\n            raise\n    xid = header.xid\n    if xid == Ping.PING_XID:\n        self._log_debug(\"Received ping\")\n        self._clear_outstanding_ping()\n        return\n    if xid == Auth.AUTH_XID:\n        self._handle_auth_response(header)\n        return\n    if xid == Watch.WATCH_XID:\n        self._handle_watch_event(header)\n        return\n    self._log_debug(\"Received header: %s\", header)\n    response = self._read_response(header)\n    if response:\n        self._log_debug(\"Received response: %s\", response)\n\n", "CodeBleu_score": 32.89531843946696}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self._log.info(\"Starting ZK loop\")\n    self._connection_stopped.clear()\n    while not self._stopped.is_set():\n        try:\n            self._retry_policy.attempt(self._connect)\n        except RetryFailedError:\n            self._log.warning(\"ZK connection failed\")\n            break\n        except ForceRetryError:\n            self._log.warning(\"ZK connection failed\")\n        except:\n            self._log.exception(\"ZK connection failed\")\n            break\n        if self._stopped.is_set():\n            break\n        self._connection_stopped.set()\n        self._session_callback(KeeperState.CONNECTED)\n        self._log.info(\"ZK loop stopped\")\n\n", "CodeBleu_score": 46.900924222813224}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    try:\n        self._zk_loop()\n    except ForceRetryError:\n        self.logger.warning(\"Connection to Zookeeper failed\")\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED)\n    self.logger.info(\"Stopping ZK loop\")\n\n", "CodeBleu_score": 32.44542273983905}, {"code": "def zk_loop(self)\n\t\n    self.log.info(\"Starting ZK loop\")\n    self.connection_stopped.clear()\n    while not self.stopped.is_set():\n        try:\n            self.retry(self._connect)\n            break\n        except ForceRetryError:\n            self.log.warning(\"Force retry, retrying\")\n        except RetryFailedError:\n            self.log.warning(\"Retry failed, stopping\")\n            break\n        except Exception:\n            self.log.exception(\"Error connecting, retrying\")\n            time.sleep(1)\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED)\n    self.log.info(\"ZK loop stopped\")\n\n", "CodeBleu_score": 45.84977053815915}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    idx = members.index(identifier)\n    return partitions[idx::len(members)]\n\n", "CodeBleu_score": 39.64689755031}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    self._participating = False\n    try:\n        self._zk.delete(self._path, self._guid)\n    except KazooException:\n        pass\n    try:\n        self._zk.delete(self._guid_path, makepath=True)\n    except KazooException:\n        pass\n\n", "CodeBleu_score": 38.00293811998898}, {"code": "def leave(self)\n\t\n    try:\n        self.client.retry(self._inner_leave)\n    except KazooException:\n        self.logger.error(\"Failed to leave the barrier\")\n        self.logger.exception(\"Exception occurred while leaving the barrier\")\n    finally:\n        self.participating = False\n\n", "CodeBleu_score": 55.3282292836028}, {"code": "def leave(self)\n\t\n    try:\n        self.client.delete(self.path, self.identifier)\n    except NoNodeError:\n        # we are already gone\n        pass\n    except KazooException:\n        # cleanup\n        self.remove_identifier()\n        raise\n    else:\n        self.participating = False\n\n", "CodeBleu_score": 44.17812276893241}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t        try {\n            if (hFtpService.isStarted()) {\n                return Result.success(\"The server has already started\");\n            } else {\n                hFtpService.start();\n                return Result.success(\"The server started successfully\");\n            }\n        } catch (Exception e) {\n            logger.error(\"An exception occurred while starting the server\", e);\n            return Result.error(\"An exception occurred while starting the server\");\n        }\n    }", "CodeBleu_score": 31.614478770402567}, {"code": "public Result start(){\n\t        try {\n            if (hFtpService.isRunning()) {\n                return Result.success(\"HDFS over FTP server is already running.\");\n            } else {\n                hFtpService.start();\n                return Result.success(\"HDFS over FTP server started successfully.\");\n            }\n        } catch (Exception e) {\n            return Result.error(\"Failed to start HDFS over FTP server: \" + e.getMessage());\n        }\n    }", "CodeBleu_score": 29.884691395924733}, {"code": "public Result start(){\n\t    try {\n        if (hFtpService.isRunning()) {\n            return Result.success(\"HDFS over FTP server is already running.\");\n        }\n        hFtpService.start();\n        return Result.success(\"HDFS over FTP server started successfully.\");\n    } catch (Exception e) {\n        logger.error(\"Error starting HDFS over FTP server: \" + e.getMessage(), e);\n        return Result.error(\"Error starting HDFS over FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 38.214020260364954}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t    try {\n        if (hFtpService.isRunning()) {\n            hFtpService.stop();\n            return Result.success(\"FTP server stopped successfully.\");\n        } else {\n            return Result.failure(\"FTP server is not running.\");\n        }\n    } catch (Exception e) {\n        logger.error(\"Error stopping FTP server\", e);\n        return Result.failure(\"Error stopping FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 33.717785529429996}, {"code": "public Result stop(){\n\t    try {\n        if (ftpService.isRunning()) {\n            ftpService.stop();\n            return Result.success(\"FTP server stopped successfully.\");\n        } else {\n            return Result.failure(\"FTP server is not running.\");\n        }\n    } catch (Exception e) {\n        logger.error(\"Error stopping FTP server: \" + e.getMessage());\n        return Result.failure(\"Error stopping FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 38.66799629488939}, {"code": "public Result stop(){\n\t    try {\n        if (ftpService.isRunning()) {\n            ftpService.stop();\n            return Result.success(\"FTP server stopped successfully\");\n        } else {\n            return Result.failure(\"FTP server is not running\");\n        }\n    } catch (Exception e) {\n        logger.error(\"Error stopping FTP server\", e);\n        return Result.failure(\"Error stopping FTP server: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 33.66227077486039}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities == null) {\n        return null;\n    }\n    for (Authority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        }\n    }\n    return request;\n}", "CodeBleu_score": 45.85368665059725}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    List<Authority> authorities = getAuthorities();\n    if (authorities == null) {\n        return null;\n    }\n    for (Authority authority : authorities) {\n        if (authority.canAuthorize(request)) {\n            authority.authorize(request);\n        }\n    }\n    if (request.getAuthority() != null) {\n        return request;\n    }\n    return null;\n}", "CodeBleu_score": 51.43270232314697}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    List<Authority> authorities = getAuthorities();\n    if (authorities != null) {\n        for (Authority authority : authorities) {\n            if (authority.canAuthorize(request)) {\n                request = authority.authorize(request);\n                if (request != null) {\n                    return request;\n                }\n            }\n        }\n    }\n    return null;\n}", "CodeBleu_score": 49.814078094008664}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fileSystem = getFileSystem();\n        Path fullPath = getFullPath();\n        fileSystem.mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 61.58759108085449}, {"code": "public boolean mkdir(){\n\t        try {\n            FileSystem fs = FileSystem.get(new Configuration());\n            Path fullPath = new Path(getFullPath());\n            if (!fs.mkdirs(fullPath)) {\n                return false;\n            }\n            return true;\n        } catch (IOException e) {\n            e.printStackTrace();\n            return false;\n        }\n    }", "CodeBleu_score": 65.37796252598986}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = FileSystem.get(this.getUser().getHomeDirectory());\n        fs.mkdirs(this.getFullPath());\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 67.90113321122081}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        fs.delete(new Path(fullPath), true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.8534751984003}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        fs.delete(new Path(fullPath), true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.8534751984003}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = FileSystem.get(this.user.getHdfsUri(), this.user.getConfiguration());\n        return fs.delete(this.fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 61.197913023208336}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(config);\n        Path oldPath = new Path(ftpFile.getAbsolutePath());\n        Path newPath = new Path(ftpFile.getParent() + File.separator + ftpFile.getName());\n        fs.rename(oldPath, newPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 61.41441814519338}, {"code": "public boolean move(FtpFile ftpFile){\n\t    FileSystem fs = null;\n    try {\n        fs = FileSystem.get(new Configuration());\n        Path oldPath = new Path(ftpFile.getAbsolutePath());\n        Path newPath = new Path(ftpFile.getParent() + File.separator + ftpFile.getName());\n        fs.rename(oldPath, newPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 59.303232052371456}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        Path oldPath = new Path(ftpFile.getAbsolutePath());\n        Path newPath = new Path(ftpFile.getParent() + File.separator + ftpFile.getName());\n        fs.rename(oldPath, newPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 63.45644002675874}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = FileSystem.get(HdfsUser.getHdfsConfiguration());\n        Path path = new Path(getBaseDir());\n        FileStatus[] files = fs.listStatus(path);\n        FtpFile[] ftpFiles = new FtpFile[files.length];\n        for (int i = 0; i < files.length; i++) {\n            FileStatus file = files[i];\n            String filePath = file.getPath().toString();\n            String virtualPath = getBaseDir() + File.separator + filePath.substring(filePath.lastIndexOf(\"/\") + 1);\n            ftpFiles[i] = new HdfsFtpFile(file, virtualPath, this);\n        }\n        return Collections.unmodifiableList(Arrays.asList(ftpFiles));\n    } catch (IOException e) {\n        LOG.error(\"Error listing files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 44.1015946609188}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = FileSystem.get(HdfsUser.getHdfsConfiguration());\n        FileStatus[] fileStatuses = fs.listStatus(new Path(getBaseDir()));\n        FtpFile[] files = new FtpFile[fileStatuses.length];\n        for (int i = 0; i < fileStatuses.length; i++) {\n            FileStatus fileStatus = fileStatuses[i];\n            String fileName = fileStatus.getPath().getName();\n            String virtualPath = getBaseDir() + \"/\" + fileName;\n            files[i] = new HdfsFile(virtualPath, fileStatus);\n        }\n        return Collections.unmodifiableList(Arrays.asList(files));\n    } catch (IOException e) {\n        logger.error(\"Error listing files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 47.23157890235761}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem hdfs = FileSystem.get(user.getHdfsUri(), user.getHdfsConf());\n        FileStatus[] files = hdfs.listStatus(new Path(user.getBaseDir()));\n        String baseDir = user.getBaseDir();\n        FtpFile[] ftpFiles = new FtpFile[files.length];\n        for (int i = 0; i < files.length; i++) {\n            String filePath = files[i].getPath().toString();\n            String virtualPath = baseDir + \"/\" + new File(filePath).getName();\n            ftpFiles[i] = new HdfsFtpFile(user, virtualPath, files[i]);\n        }\n        return Collections.unmodifiableList(Arrays.asList(ftpFiles));\n    } catch (IOException e) {\n        logger.error(\"Error listing files\", e);\n        return null;\n    }\n}", "CodeBleu_score": 48.02137541001972}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t    if (isConfigured()) {\n        return;\n    }\n    setConfigured(true);\n    if (getUserDataFile() != null) {\n        try {\n            if (getUserDataFile().exists()) {\n                loadUserDataProperties();\n            } else {\n                getUserDataFile().createNewFile();\n            }\n        } catch (IOException e) {\n            throw new FtpServerConfigurationException(\"Could not load user data file \" + getUserDataFile().getAbsolutePath(), e);\n        }\n    }\n    convertDeprecatedProperties();\n}", "CodeBleu_score": 28.363359842662554}, {"code": "public void configure(){\n\t    if (isConfigured()) {\n        return;\n    }\n    setConfigured(true);\n    File userDataFile = getUserDataFile();\n    if (userDataFile.exists()) {\n        FileInputStream in = null;\n        try {\n            in = new FileInputStream(userDataFile);\n            BaseProperties props = new BaseProperties();\n            props.load(in);\n            IoUtils.close(in);\n            setProperties(props);\n        } catch (IOException e) {\n            throw new FtpServerConfigurationException(\"Failed to load user data file \" + userDataFile.getAbsolutePath(), e);\n        } finally {\n            IoUtils.close(in);\n        }\n    }\n    convertDeprecatedProperties();\n}", "CodeBleu_score": 54.18525710619095}, {"code": "public void configure(){\n\t    if (configured) {\n        return;\n    }\n\n    // load user data properties\n    try {\n        File userDataFile = new File(getUserDataFilePath());\n        if (userDataFile.exists()) {\n            FileInputStream fis = new FileInputStream(userDataFile);\n            try {\n                BaseProperties properties = new BaseProperties();\n                properties.load(fis);\n                userDataProperties = properties;\n            } finally {\n                IoUtils.close(fis);\n            }\n        }\n    } catch (IOException e) {\n        throw new FtpServerConfigurationException(\"Could not load user data file \" + getUserDataFilePath(), e);\n    }\n\n    // convert deprecated property names\n    convertDeprecatedPropertyNames();\n\n    configured = true;\n}", "CodeBleu_score": 50.114860993118796}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t    File userDataFile = new File(userDataFilePath);\n    File parentDir = userDataFile.getParentFile();\n    if (!parentDir.exists() && !parentDir.mkdirs()) {\n        throw new FtpServerConfigurationException(\"Unable to create parent directory for user data file: \" + userDataFilePath);\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        userData.store(fos, \"User data\");\n    } catch (IOException e) {\n        LOG.error(\"Failed to save user data to file: \" + userDataFilePath, e);\n        throw new FtpException(\"Failed to save user data to file: \" + userDataFilePath, e);\n    } finally {\n        IoUtils.close(fos);\n    }\n}", "CodeBleu_score": 52.122154915790055}, {"code": "private void saveUserData() throws FtpException{\n\t    File userDataFile = new File(userDataFilePath);\n    File parentDir = userDataFile.getParentFile();\n    if (!parentDir.exists() && !parentDir.mkdirs()) {\n        throw new FtpServerConfigurationException(\"Failed to create parent directory for user data file\");\n    }\n    try (FileOutputStream fos = new FileOutputStream(userDataFile)) {\n        userData.store(fos, \"User Data\");\n    } catch (IOException e) {\n        LOG.error(\"Failed to save user data to file\", e);\n        throw new FtpException(\"Failed to save user data to file\", e);\n    }\n}", "CodeBleu_score": 42.54690338318013}, {"code": "private void saveUserData() throws FtpException{\n\t    File parentDir = userDataFile.getParentFile();\n    if (!parentDir.exists() && !parentDir.mkdirs()) {\n        throw new FtpException(\"Failed to create parent directory for user data file: \" + parentDir);\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        userData.store(fos, \"FTP Server User Data\");\n    } catch (IOException e) {\n        logger.error(\"Failed to save user data\", e);\n        throw new FtpException(\"Failed to save user data\", e);\n    } finally {\n        IoUtils.close(fos);\n    }\n}", "CodeBleu_score": 56.15720603366544}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.delete(user);\n        return Result.success(\"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    } catch (Exception e) {\n        logger.error(\"\u5220\u9664\u7528\u6237\u5931\u8d25\", e);\n        return Result.fail(\"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 50.59317345083034}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t        HdfsUserManager manager = new HdfsUserManager();\n        manager.setFile(new File(\"users.properties\"));\n        try {\n            manager.delete(user);\n            return Result.success(\"delete user success\");\n        } catch (Exception e) {\n            log.error(\"delete user error\", e);\n            return Result.failure(\"delete user error\");\n        }\n    }", "CodeBleu_score": 48.067901669007796}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager userManager = new HdfsUserManager();\n        userManager.setFile(new File(\"users.properties\"));\n        userManager.delete(user);\n        return Result.success();\n    } catch (Exception e) {\n        logger.error(e.getMessage());\n        return Result.failure(e.getMessage());\n    }\n}", "CodeBleu_score": 49.70662102867619}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    LOG.info(\"Opening file {} with buffer size {}\", path, bufferSize);\n    Path qualifiedPath = qualify(path);\n    try {\n        FilerProto.Entry entry = seaweedFS.getFileStatus(qualifiedPath);\n        return new FSDataInputStream(new BufferedInputStream(new FSInputStream(entry), bufferSize));\n    } catch (Exception e) {\n        LOG.warn(\"Failed to open file {}\", qualifiedPath, e);\n        return null;\n    }\n}", "CodeBleu_score": 39.097223884859524}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    LOG.info(\"open path={} bufferSize={}\", path, bufferSize);\n    Path qualifiedPath = qualifyPath(path);\n    try {\n        FilerProto.Entry entry = store.getEntry(qualifiedPath);\n        return new FSDataInputStream(new BufferedInputStream(new SeaweedFSInputStream(store, entry), bufferSize));\n    } catch (Exception e) {\n        LOG.warn(\"open path={} bufferSize={}\", path, bufferSize, e);\n        return null;\n    }\n}", "CodeBleu_score": 44.40830594293339}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t        LOG.debug(\"open {} with buffer size {}\", path, bufferSize);\n        Path qualifiedPath = qualifyPath(path);\n        try {\n            FilerProto.LookupVolumeResponse lookupVolumeResponse = seaweedfsFileSystemStore.lookupVolume(qualifiedPath);\n            if (lookupVolumeResponse == null) {\n                throw new FileNotFoundException(path.toString());\n            }\n            return new FSDataInputStream(new BufferedInputStream(new SeaweedFSInputStream(seaweedfsFileSystemStore, lookupVolumeResponse.getVolumeOrBuilder(), qualifiedPath, bufferSize)));\n        } catch (Exception e) {\n            LOG.warn(\"open {} with buffer size {} failed\", path, bufferSize, e);\n            return null;\n        }\n    }", "CodeBleu_score": 43.179679144098806}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    LOG.debug(\"rename: \" + src + \" to \" + dst);\n    if (src.isRoot()) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    FileStatus dstEntry = getFileStatus(dst);\n    if (dstEntry != null && dstEntry.isDirectory()) {\n        dst = new Path(dst, src.getName());\n    }\n    Path srcQualified = qualify(src);\n    Path dstQualified = qualify(dst);\n    return store.rename(srcQualified, dstQualified);\n}", "CodeBleu_score": 46.3959998485949}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t        LOG.info(\"rename: {} -> {}\", src, dst);\n        if (src.equals(ROOT)) {\n            return false;\n        }\n        if (src.equals(dst)) {\n            return true;\n        }\n        FileStatus dstEntry = getFileStatus(dst);\n        if (dstEntry != null && dstEntry.isDirectory()) {\n            dst = new Path(dst, src.getName());\n        }\n        Path srcPath = qualify(src);\n        Path dstPath = qualify(dst);\n        return store.rename(srcPath, dstPath);\n    }", "CodeBleu_score": 50.702039040764}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t        LOG.info(\"Renaming {} to {}\", src, dst);\n        if (src.equals(ROOT_PATH)) {\n            return false;\n        }\n        if (src.equals(dst)) {\n            return true;\n        }\n        Path adjustedDst = adjustDestinationPath(src, dst);\n        Path qualifiedSrc = qualify(src);\n        Path qualifiedDst = qualify(adjustedDst);\n        return store.rename(qualifiedSrc, qualifiedDst);\n    }", "CodeBleu_score": 40.064810447890686}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t        String lowerCap = capability.toLowerCase(Locale.ENGLISH);\n        if (lowerCap.equals(StreamCapabilities.HSYNC)) {\n            return supportFlush;\n        } else if (lowerCap.equals(StreamCapabilities.HFLUSH)) {\n            return supportFlush;\n        } else {\n            return false;\n        }\n    }", "CodeBleu_score": 45.018820453403826}, {"code": "public boolean hasCapability(String capability){\n\t    return supportFlush && (capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HSYNC) || capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HFLUSH));\n}", "CodeBleu_score": 47.82414182394395}, {"code": "public boolean hasCapability(String capability){\n\t    return supportFlush && (capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HSYNC) || capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HFLUSH));\n}", "CodeBleu_score": 47.82414182394395}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset < lastFlushOffset) {\n        throw new IOException(\"Flush offset \" + offset + \" is less than last flush offset \" + lastFlushOffset);\n    }\n    if (offset > lastFlushOffset) {\n        // flush written bytes to the service\n        int bytesToFlush = (int) (offset - lastFlushOffset);\n        if (bytesToFlush > writtenBytes.remaining()) {\n            throw new IOException(\"Flush offset \" + offset + \" is greater than the number of written bytes \" + writtenBytes.remaining());\n        }\n        try {\n            if (bytesToFlush > 0) {\n                // write metadata to the filer client\n                filerClient.write(fileHandle, lastFlushOffset, writtenBytes.array(), writtenBytes.arrayOffset() + writtenBytes.position(), bytesToFlush);\n            }\n        } catch (Exception e) {\n            throw new IOException(e);\n        }\n        // update the last flush offset\n        lastFlushOffset = offset;\n        // reset the written bytes buffer\n        writtenBytes.clear();\n    }\n}", "CodeBleu_score": 37.61682413506784}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset <= lastFlushedOffset) {\n        return;\n    }\n    final ByteBuffer buffer = ByteBuffer.wrap(writtenBytes, (int) lastFlushedOffset, (int) (offset - lastFlushedOffset));\n    try {\n        filerClient.write(buffer, offset);\n        lastFlushedOffset = offset;\n    } catch (IOException e) {\n        LOG.error(\"Failed to flush written bytes to service\", e);\n        throw e;\n    }\n}", "CodeBleu_score": 34.59779638006803}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    if (offset <= lastFlushOffset) {\n        return;\n    }\n    if (offset > lastFlushOffset + buffer.limit()) {\n        throw new IllegalArgumentException(\"offset (\" + offset + \") is beyond the end of the buffer (\" + (lastFlushOffset + buffer.limit()) + \")\");\n    }\n    if (buffer.limit() == 0) {\n        return;\n    }\n    final long flushLen = offset - lastFlushOffset;\n    if (flushLen > buffer.limit()) {\n        throw new IllegalArgumentException(\"offset (\" + offset + \") is beyond the end of the buffer (\" + (lastFlushOffset + buffer.limit()) + \")\");\n    }\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Flushing \" + flushLen + \" bytes to the service starting from offset \" + lastFlushOffset);\n    }\n    final ByteBuffer flushBuffer = buffer.duplicate();\n    flushBuffer.limit((int) flushLen);\n    flushBuffer.position((int) (lastFlushOffset - offset));\n    try {\n        filerClient.write(inode, flushBuffer, lastFlushOffset, null);\n    } catch (IOException e) {\n        LOG.error(\"Failed to flush written bytes to the service\", e);\n        throw e;\n    }\n    lastFlushOffset = offset;\n    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Flushed \" + flushLen + \" bytes to the service starting from offset \" + lastFlushOffset);\n    }\n}", "CodeBleu_score": 29.659894080372577}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    final int bufferSize = bufferToWrite.limit();\n    bufferToWrite.flip();\n    final WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n    writeTaskQueue.add(writeTask);\n    writeTaskQueue.notifyAll();\n    completionService.submit(writeTask);\n    return bufferSize;\n}", "CodeBleu_score": 22.002222754184803}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    // Flip the buffer to prepare for reading\n    ((Buffer) bufferToWrite).flip();\n    // Calculate the byte length of the buffer\n    int bytesToWrite = bufferToWrite.remaining();\n    // Ensure the task queue is not overloaded\n    if (taskQueue.size() >= MAX_TASKS) {\n        // If the task queue is overloaded, wait for a task to complete\n        try {\n            // Wait for a task to complete\n            completionService.take().get();\n        } catch (ExecutionException | InterruptedException e) {\n            // If an exception occurs, log the error\n            LOG.error(\"Error while waiting for task completion\", e);\n        }\n    }\n    // Submit a write task to the completion service\n    completionService.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n            // Write the data to the service\n            OutputStream outputStream = service.write(writePosition, bufferToWrite);\n            // Release the buffer\n            bufferToWrite.clear();\n            // Return null\n            return null;\n        }\n    });\n    // Record the write operation\n    recordWriteOperation(writePosition, bytesToWrite);\n    // Manage the operation queue\n    manageOperationQueue();\n    // Return the number of bytes written\n    return bytesToWrite;\n}", "CodeBleu_score": 36.75745100342805}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    bufferToWrite.flip();\n    final int byteLength = bufferToWrite.limit();\n    ensureTaskQueueNotOverloaded();\n    final WriteTask writeTask = new WriteTask(bufferToWrite, writePosition);\n    writeTask.future = completionService.submit(writeTask);\n    writeTask.position = writePosition;\n    writeTask.length = byteLength;\n    writeTask.buffer = bufferToWrite;\n    operationQueue.add(writeTask);\n    return byteLength;\n}", "CodeBleu_score": 29.495976689626712}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (true) {\n            Future<Integer> result = completionService.poll(100, TimeUnit.MILLISECONDS);\n            if (result == null) {\n                break;\n            }\n        }\n    } catch (InterruptedException e) {\n        throw new InterruptedIOException(e.getMessage());\n    }\n}", "CodeBleu_score": 33.24652162605165}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        Future<?> task = completionService.poll();\n        if (task == null) {\n            break;\n        }\n        try {\n            task.get();\n        } catch (InterruptedException e) {\n            throw new InterruptedIOException(e.getMessage());\n        } catch (ExecutionException e) {\n            logger.error(\"Execution error: \" + e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 33.399753461898655}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        try {\n            Future<Integer> result = completionService.poll(100, TimeUnit.MILLISECONDS);\n            if (result == null) {\n                break;\n            }\n            result.get();\n        } catch (InterruptedException e) {\n            throw new InterruptedIOException();\n        } catch (ExecutionException e) {\n            throw new IOException(e.getCause());\n        }\n    }\n}", "CodeBleu_score": 33.19177657771591}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    // Iterate through the queue\n    for (Iterator<WriteOperation> iterator = writeOperationQueue.iterator(); iterator.hasNext(); ) {\n        WriteOperation writeOperation = iterator.next();\n        // Check if the task is done\n        if (writeOperation.isDone()) {\n            // Remove the completed task from the queue\n            iterator.remove();\n            // Update the total append offset with the length of the completed operation\n            totalAppendOffset += writeOperation.getLength();\n        }\n    }\n}", "CodeBleu_score": 27.929716082962003}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    while (!writeOperationQueue.isEmpty()) {\n        WriteOperation operation = writeOperationQueue.peek();\n        if (operation.getFuture().isDone()) {\n            try {\n                operation.getFuture().get();\n                totalAppendOffset += operation.getBuffer().limit();\n                writeOperationQueue.poll();\n            } catch (InterruptedException e) {\n                throw new InterruptedIOException(e.getMessage());\n            } catch (ExecutionException e) {\n                throw new IOException(e.getCause());\n            }\n        } else {\n            break;\n        }\n    }\n}", "CodeBleu_score": 32.17578561639519}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    Iterator<Future<Integer>> iterator = writeOperationQueue.iterator();\n    while (iterator.hasNext()) {\n        Future<Integer> future = iterator.next();\n        if (future.isDone()) {\n            try {\n                totalAppendOffset += future.get();\n                iterator.remove();\n            } catch (InterruptedException e) {\n                throw new InterruptedIOException(e.getMessage());\n            } catch (ExecutionException e) {\n                if (e.getCause() instanceof IOException) {\n                    throw (IOException) e.getCause();\n                } else {\n                    throw new IOException(e.getCause());\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 25.687515667896033}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"User can not be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"User home can not be null\");\n  }\n  this.homePath=new Path(user.getHomeDirectory());\n  this.user=user;\n}", "CodeBleu_score": 72.14959569847277}, {"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"user can not be null\");\n  } \n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"User home directory can not be null\");\n  } \n  homePath=new Path(user.getHomeDirectory());\n  this.user=user;\n}", "CodeBleu_score": 75.2028461048543}, {"code": "protected HdfsFileSystemView(User user){\n\t    if (user == null) {\n        throw new IllegalArgumentException(\"user can not be null\");\n    }\n    if (user.getHomeDirectory() == null) {\n        throw new IllegalArgumentException(\"user home can not be null\");\n    }\n    this.homePath = new Path(user.getHomeDirectory());\n    this.user = user;\n}", "CodeBleu_score": 74.10376823566389}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = new Path(dir);\n    } else {\n        newPath = new Path(currentPath, dir);\n    }\n    if (!newPath.isAbsolute()) {\n        return false;\n    }\n    if (newPath.depth() < root.depth()) {\n        return false;\n    }\n    if (new File(newPath.toString()).isDirectory()) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 29.992783496376823}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = new Path(root, dir);\n    } else {\n        newPath = new Path(currentPath, dir);\n    }\n    if (!newPath.isAbsolute()) {\n        return false;\n    }\n    if (newPath.getParent().equals(root)) {\n        currentPath = newPath;\n        return true;\n    }\n    if (new File(newPath.toString()).isDirectory()) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 27.98136866784252}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    Path oldPath = getCurrentPath();\n    Path newPath;\n    if (dir.startsWith(\"/\")) {\n        newPath = new Path(dir);\n    } else {\n        newPath = new Path(oldPath, dir);\n    }\n    if (!newPath.isAbsolute()) {\n        return false;\n    }\n    if (newPath.getParent().equals(root)) {\n        return false;\n    }\n    if (isDirectory(newPath)) {\n        currentPath = newPath;\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 31.017977842943772}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE, \"direct\");\n}", "CodeBleu_score": 36.26947872912887}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE, \"publicUrl\");\n\n    if (this.accessMode.equals(\"filerProxy\")) {\n        this.filerClient = new FilerClient(host, grpcPort);\n    } else {\n        this.filerClient = new FilerClient(host, port);\n    }\n}", "CodeBleu_score": 40.61296719231618}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessMode = conf.get(SEAWEEDFS_ACCESS_MODE);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.", "CodeBleu_score": 31.156636089367566}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"openFileForRead: {}\", path);\n    final FileEntry fileEntry = lookup(path);\n    if (fileEntry == null) {\n        throw new FileNotFoundException(path.toString());\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 64.3368293029832}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.info(\"Opening file for read: \" + path);\n    FileEntry fileEntry = lookup(path);\n    if (fileEntry == null) {\n        throw new FileNotFoundException(\"File not found: \" + path);\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 66.39499271084445}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.info(\"Opening file for read: {}\", path);\n    FileEntry fileEntry = lookupFileEntry(path);\n    if (fileEntry == null) {\n        throw new FileNotFoundException(\"File not found: \" + path);\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, path);\n}", "CodeBleu_score": 69.20692538472679}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    this.hostname = InetAddress.getLocalHost().getHostName();\n  } catch (IOException e) {\n    this.hostname = \"localhost\";\n  }\n  this.threadsPerMap = conf.getInt(\"mapred.linerecordreader.threads.per.map\", 1);\n  this.filesPerThread = conf.getInt(\"mapred.linerecordreader.files.per.thread\", 1);\n  this.threadPool = Executors.newFixedThreadPool(this.threadsPerMap, new DaemonThreadFactory());\n}", "CodeBleu_score": 40.17635679928372}, {"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        this.hostName = InetAddress.getLocalHost().getHostName();\n    } catch (Exception e) {\n        this.hostName = \"localhost\";\n    }\n    this.threadsPerMap = conf.getInt(\"mapred.map.parallelism\", 1);\n    this.filesPerThread = conf.getInt(\"mapred.map.files.per.thread\", 1);\n    this.pool = Executors.newFixedThreadPool(threadsPerMap);\n}", "CodeBleu_score": 42.67911091758927}, {"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        host = InetAddress.getLocalHost().getHostName();\n    } catch (IOException e) {\n        host = \"localhost\";\n    }\n    threadsPerMap = conf.getInt(FileInputFormat.NUM_THREADS_PER_MAP, 1);\n    filesPerThread = conf.getInt(FileInputFormat.NUM_FILES_PER_THREAD, 1);\n    pool = Executors.newFixedThreadPool(threadsPerMap);\n    for (int i = 0; i < threadsPerMap; i++) {\n        pool.submit(new Thread() {\n\n            @Override\n            public void run() {\n                while (true) {\n                    try {\n                        Thread.sleep(1000);\n                    } catch (InterruptedException e) {\n                        break;\n                    }\n                }\n            }\n        });\n    }\n}", "CodeBleu_score": 39.396032608974586}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    String host = uri.getHost();\n    if (trashEmptier.containsKey(host)) {\n        return;\n    }\n\n    UserGroupInformation ugi = UserGroupInformation.getSuperUser();\n    try {\n        ugi.doAs(new PrivilegedExceptionAction<Void>() {\n            @Override\n            public Void run() throws Exception {\n                try {\n                    FileSystem fs = new JuiceFileSystemImpl();\n                    fs.initialize(uri, conf);\n                    trashEmptier.put(host, BgTaskUtil.schedule(new Runnable() {\n                        @Override\n                        public void run() {\n                            try {\n                                fs.emptyTrash(conf);\n                            } catch (IOException e) {\n                                LOG.warn(\"failed to empty trash for \" + host, e);\n                            }\n                        }\n                    }, 10, TimeUnit.MINUTES));\n                } catch (IOException e) {\n                    throw new IOException(\"failed to start trash emptier for \" + host, e);\n                }\n                return null;\n            }\n        });\n    } catch (InterruptedException e) {\n        throw new IOException(\"failed to start trash emptier for \" + host, e);\n    }\n}", "CodeBleu_score": 34.677119577672435}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    if (BgTaskUtil.isTrashEmptierRunning(uri)) {\n        return;\n    }\n    try {\n        UserGroupInformation.createSuperUser();\n    } catch (IOException e) {\n        LOG.error(\"Failed to create superuser\", e);\n        throw new IOException(\"Failed to create superuser\", e);\n    }\n    try {\n        final FileSystem fs = FileSystem.get(uri, conf);\n        final Path trashRoot = ((JuiceFileSystem) fs).getTrashRoot();\n        final Configuration trashConf = new Configuration(conf);\n        trashConf.set(JuiceFileSystem.TRASH_ROOT, trashRoot.toString());\n        BgTaskUtil.startTrashEmptier(uri, new PrivilegedExceptionAction<Void>() {\n            @Override\n            public Void run() throws Exception {\n                try {\n                    final FileSystem trashFs = FileSystem.get(uri, trashConf);\n                    final FileStatus[] trashDirs = trashFs.listStatus(trashRoot);\n                    for (FileStatus trashDir : trashDirs) {\n                        final Path trashPath = trashDir.getPath();\n                        final Path trashMetaPath = new Path(trashPath, MetaFile.META_FILE);\n                        final FileStatus trashMetaFile = trashFs.getFileStatus(trashMetaPath);\n                        final MetaFile metaFile = MetaFile.parse(trashMetaFile.getPath(), trashFs);\n                        final Path trashBasePath = new Path(trashPath, metaFile.getBasePath());\n                        final Path trashBaseParent = trashBasePath.getParent();\n                        final FileStatus trashBaseFile = trashFs.getFileStatus(trashBasePath);\n                        final FileStatus trashBaseParentFile = trashFs.getFileStatus(trashBaseParent);\n                        if (trashBaseFile.isDirectory()) {\n                            trashFs.delete(trashBasePath, true);\n                        } else {\n                            trashFs.delete(trashBaseParent, true);\n                        }\n                        trashFs.delete(trashPath, true);\n                    }\n                } catch (Exception e) {\n                    LOG.error(\"Failed to empty", "CodeBleu_score": 38.01317933730011}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    String host = uri.getHost();\n    if (trashEmptier.containsKey(host)) {\n        return;\n    }\n    UserGroupInformation.createSuperUser();\n    try {\n        final FileSystem fs = FileSystem.get(uri, conf);\n        if (!(fs instanceof JuiceFileSystemImpl)) {\n            return;\n        }\n        final JuiceFileSystemImpl jfs = (JuiceFileSystemImpl) fs;\n        final Trash trash = jfs.getTrash();\n        if (trash == null) {\n            return;\n        }\n        final Configuration trashConf = trash.getConf();\n        BgTaskUtil.schedule(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    trash.emptyTrash(trashConf);\n                } catch (IOException e) {\n                    LOG.warn(\"Trash emptier failed\", e);\n                }\n            }\n        }, 10, TimeUnit.MINUTES);\n        trashEmptier.put(host, true);\n    } catch (IOException e) {\n        throw new IOException(\"Failed to start trash emptier\", e);\n    }\n}", "CodeBleu_score": 35.45125800775511}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t    CallerContext callerContext = CallerContext.getCurrentContext();\n    if (callerContext == null || callerContext.getSignature() == null) {\n        callerContext = new CallerContext(context);\n    } else if (!callerContext.getSignature().contains(context)) {\n        callerContext = new CallerContext(callerContext.getSignature() + \",\" + context);\n    }\n    CallerContext.setCurrentContext(callerContext);\n}", "CodeBleu_score": 42.40624741203114}, {"code": "public static void setContext(String context) throws Exception{\n\t    // Retrieve the current caller context\n    CallerContext callerContext = CallerContext.getCurrentCallerContext();\n    // Check if the current caller context is valid\n    if (callerContext == null || callerContext.getSignature() == null) {\n        // If the current caller context is not valid, create a new caller context using the provided context\n        callerContext = new CallerContext(context);\n    } else {\n        // If the current caller context is valid, check if it already includes the provided context\n        if (!callerContext.getSignature().contains(context)) {\n            // If the current caller context does not already include the provided context, append the new context to the existing one and set it\n            callerContext = new CallerContext(callerContext.getSignature() + \":\" + context);\n        }\n    }\n    // Set the caller context to the specified context string\n    CallerContext.setCurrentCallerContext(callerContext);\n}", "CodeBleu_score": 42.481519569272805}, {"code": "public static void setContext(String context) throws Exception{\n\t    CallerContext callerContext = CallerContext.getCurrentContext();\n    if (callerContext == null || !callerContext.isValid()) {\n        callerContext = new CallerContext(context);\n        CallerContext.setCurrentContext(callerContext);\n    } else if (!callerContext.hasSignature()) {\n        callerContext = new CallerContext(callerContext.toString() + \",\" + context);\n        CallerContext.setCurrentContext(callerContext);\n    }\n}", "CodeBleu_score": 43.765717624865005}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t  hdfsFS fs = connect();\n  int rc = hdfsDelete(fs, uri.to_string().c_str());\n  if (rc != 0) {\n    LOG_ERROR(\"Failed to delete file '\" << uri.to_string() << \"'\");\n    return Status::Error(\"Failed to delete file\");\n  }\n  return Status::Ok();\n}", "CodeBleu_score": 56.173920686031174}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t    hdfsFS fs = hdfsConnect(uri.host.c_str(), uri.port);\n    if (fs == NULL) {\n        return Status::Error(\"Failed to connect to HDFS\");\n    }\n\n    int result = hdfsDelete(fs, uri.path.c_str());\n    if (result == -1) {\n        return Status::Error(\"Failed to delete file\");\n    }\n\n    hdfsDisconnect(fs);\n    return Status::OK();\n}", "CodeBleu_score": 52.34110185344324}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  std::string path = uri.to_path();\n  if (path.empty())\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot remove file \") + uri.to_string() +\n        \"; Invalid HDFS path\"))\n\n  hdfsFS fs = connect();\n  if (fs == nullptr)\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot remove file \") + uri.to_string() +\n        \"; File system not initialized\"))\n\n  int rc = hdfsDelete(fs, path.c_str());\n  if (rc < 0)\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot remove file \") + uri.to_string() +\n        \"; File system returned error in hdfsDelete\"));\n\n  return Status::Ok();\n}", "CodeBleu_score": 48.82816773782639}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t    std::string path = uri.get_path();\n    if (path.empty()) {\n        return Status::InvalidArgument(\"path is empty\");\n    }\n    if (path[0] != '/') {\n        return Status::InvalidArgument(\"path is not absolute\");\n    }\n\n    hdfsFS fs = _connect();\n    if (fs == nullptr) {\n        return Status::RuntimeError(\"Could not connect to HDFS\");\n    }\n\n    int exists = hdfsExists(fs, path.c_str());\n    if (exists == 0) {\n        return Status::OK();\n    }\n\n    hdfsFile file = hdfsOpenFile(fs, path.c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n    if (file == nullptr) {\n        return Status::RuntimeError(\"Could not open file for writing\");\n    }\n\n    int result = hdfsFlush(fs, file);\n    if (result != 0) {\n        return Status::RuntimeError(\"Could not flush file to HDFS\");\n    }\n\n    result = hdfsCloseFile(fs, file);\n    if (result != 0) {\n        return Status::RuntimeError(\"Could not close file\");\n    }\n\n    return Status::OK();\n}", "CodeBleu_score": 45.01639854798126}, {"code": "Status HDFS::sync(const URI& uri){\n\t    if (uri.getScheme() != \"hdfs\") {\n        return Status::InvalidArgument(\"URI scheme should be hdfs\");\n    }\n\n    const std::string& host = uri.getHost();\n    const uint16_t port = uri.getPort();\n    const std::string& path = uri.getPath();\n\n    hdfsFS fs = hdfsConnect(host.c_str(), port);\n    if (fs == nullptr) {\n        return Status::IOError(\"Failed to connect to HDFS\");\n    }\n\n    hdfsFile file = hdfsOpenFile(fs, path.c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n    if (file == nullptr) {\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to open file in HDFS\");\n    }\n\n    int ret = hdfsFlush(fs, file);\n    if (ret != 0) {\n        hdfsCloseFile(fs, file);\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to flush file to HDFS\");\n    }\n\n    ret = hdfsCloseFile(fs, file);\n    if (ret != 0) {\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to close file in HDFS\");\n    }\n\n    hdfsDisconnect(fs);\n    return Status::OK();\n}", "CodeBleu_score": 47.63836691826616}, {"code": "Status HDFS::sync(const URI& uri){\n\t    // Check if the file exists in HDFS\n    if (!exists(uri)) {\n        return Status::OK();\n    }\n\n    // Open the file in write and append mode\n    hdfsFS fs = hdfsConnect(host.c_str(), port);\n    if (!fs) {\n        LOG(ERROR) << \"Failed to connect to HDFS: \" << hdfsGetLastError();\n        return Status::IOError(\"Failed to connect to HDFS\");\n    }\n    hdfsFile file = hdfsOpenFile(fs, uri.path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n    if (!file) {\n        LOG(ERROR) << \"Failed to open file in HDFS: \" << hdfsGetLastError();\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to open file in HDFS\");\n    }\n\n    // Flush the file's data to HDFS\n    if (hdfsFlush(fs, file)) {\n        LOG(ERROR) << \"Failed to flush file to HDFS: \" << hdfsGetLastError();\n        hdfsCloseFile(fs, file);\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to flush file to HDFS\");\n    }\n\n    // Close the file\n    if (hdfsCloseFile(fs, file)) {\n        LOG(ERROR) << \"Failed to close file in HDFS: \" << hdfsGetLastError();\n        hdfsDisconnect(fs);\n        return Status::IOError(\"Failed to close file in HDFS\");\n    }\n\n    // Disconnect from HDFS\n    if (hdfsDisconnect(fs)) {\n        LOG(ERROR) << \"Failed to disconnect from HDFS: \" << hdfsGetLastError();\n        return Status::IOError(\"Failed to disconnect from HDFS\");\n    }\n\n    return Status::OK();\n}", "CodeBleu_score": 47.05240794302931}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to the HDFS file system\n  hdfsFS fs = hdfsConnect(uri.host().c_str(), uri.port());\n  if (!fs) {\n    LOG_ERROR(\"Cannot connect to HDFS %s:%d\", uri.host().c_str(), uri.port());\n    return Status::Error(\"Cannot connect to HDFS\");\n  }\n\n  // Get the file information\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (!file_info) {\n    LOG_ERROR(\"Cannot get file info from HDFS %s:%d\", uri.host().c_str(), uri.port());\n    hdfsDisconnect(fs);\n    return Status::Error(\"Cannot get file info from HDFS\");\n  }\n\n  // Check if the path is a file\n  if (file_info->mKind != kObjectKindFile) {\n    LOG_ERROR(\"Path %s is not a file in HDFS %s:%d\", uri.to_path().c_str(), uri.host().c_str(), uri.port());\n    hdfsFreeFileInfo(file_info, 1);\n    hdfsDisconnect(fs);\n    return Status::Error(\"Path is not a file in HDFS\");\n  }\n\n  // Set the file size\n  *nbytes = file_info->mSize;\n\n  // Free the file information\n  hdfsFreeFileInfo(file_info, 1);\n\n  // Disconnect from the HDFS file system\n  hdfsDisconnect(fs);\n\n  return Status::Ok();\n}", "CodeBleu_score": 47.381639730235406}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  assert(util::starts_with(uri.to_string(), \"hdfs://\"));\n\n  // Connect to HDFS\n  hdfsFS fs = connect();\n  if (!fs) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Failed to connect to HDFS\")));\n  }\n\n  // Get file info\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (!file_info) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Failed to get file info\")));\n  }\n\n  // Check if the path is a file\n  if (file_info->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot get file size; Path is not a file\")));\n  }\n\n  // Set file size\n  *nbytes = file_info->mSize;\n\n  // Clean up\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 50.97254842801331}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to the HDFS file system\n  hdfsFS fs = hdfsConnect(uri.host().c_str(), uri.port());\n  if (!fs) {\n    LOG_ERROR(\"Failed to connect to HDFS\");\n    return LOG_STATUS(Status_HDFSError(\"Failed to connect to HDFS\"));\n  }\n\n  // Get the file information\n  hdfsFileInfo* fileInfo = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (!fileInfo) {\n    LOG_ERROR(\"Failed to get file information\");\n    return LOG_STATUS(Status_HDFSError(\"Failed to get file information\"));\n  }\n\n  // Check if the path is a file\n  if (fileInfo->mKind != kObjectKindFile) {\n    LOG_ERROR(\"Path is not a file\");\n    hdfsFreeFileInfo(fileInfo, 1);\n    return LOG_STATUS(Status_HDFSError(\"Path is not a file\"));\n  }\n\n  // Set the size in bytes\n  *nbytes = fileInfo->mSize;\n\n  // Free the file information\n  hdfsFreeFileInfo(fileInfo, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 51.867949068149024}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    if (hbaseCfgString != null) {\n        String[] cfg = hbaseCfgString.split(\",\");\n        for (String c : cfg) {\n            String[] kv = c.split(\"=\");\n            if (kv.length != 2) {\n                continue;\n            }\n            if (kv[0].equals(\"hbase.zookeeper.quorum\")) {\n                quorum = kv[1];\n                if (!quorum.contains(\":\")) {\n                    quorum += \":2181\";\n                }\n            } else if (kv[0].equals(\"zookeeper.znode.parent\")) {\n                znodeParent = kv[1];\n            }\n        }\n    }\n    if (quorum == null) {\n        throw new AddaxException(\"hbase.zookeeper.quorum is missing in hbase config\");\n    }\n    if (znodeParent == null) {\n        znodeParent = \"/hbase\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 29.652362657397603}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = \"\";\n    String znodeParent = \"\";\n\n    if (StringUtils.isNotBlank(hbaseCfgString)) {\n        Map<String, String> hbaseCfgMap = JSON.parseObject(hbaseCfgString, new TypeReference<Map<String, String>>() {\n        });\n        quorum = hbaseCfgMap.get(HBaseConstant.QUORUM);\n        znodeParent = hbaseCfgMap.get(HBaseConstant.ZNODE_PARENT);\n    }\n\n    if (StringUtils.isBlank(quorum)) {\n        throw new AddaxException(\"hbase quorum is empty\");\n    }\n\n    if (StringUtils.isBlank(znodeParent)) {\n        znodeParent = \"/hbase\";\n    }\n\n    if (!quorum.contains(\":\")) {\n        quorum += \":2181\";\n    }\n\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 52.346727793291834}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    if (StringUtils.isBlank(hbaseCfgString)) {\n        return new Pair<>(quorum, znodeParent);\n    }\n    Map<String, String> hbaseCfgMap = JSON.parseObject(hbaseCfgString, new TypeReference<Map<String, String>>() {\n    });\n    quorum = hbaseCfgMap.get(HBaseKey.HBASE_ZOOKEEPER_QUORUM);\n    if (StringUtils.isBlank(quorum)) {\n        return new Pair<>(quorum, znodeParent);\n    }\n    String[] quorums = quorum.split(\",\");\n    StringBuilder sb = new StringBuilder();\n    for (int i = 0; i < quorums.length; i++) {\n        String quorumItem = quorums[i];\n        if (!quorumItem.contains(\":\")) {\n            quorumItem = quorumItem + \":2181\";\n        }\n        if (i != quorums.length - 1) {\n            sb.append(quorumItem).append(\",\");\n        } else {\n            sb.append(quorumItem);\n        }\n    }\n    quorum = sb.toString();\n    znodeParent = hbaseCfgMap.get(HBaseKey.HBASE_ZOOKEEPER_PROPERTY_CLIENT_PORT);\n    if (StringUtils.isBlank(znodeParent)) {\n        znodeParent = HBaseConstant.DEFAULT_ZNODE_PARENT;\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 50.60289986332434}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    // \u83b7\u53d6\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u914d\u7f6e\u4fe1\u606f\n    String jdbcUrl = cfg.getJdbcUrl();\n    String username = cfg.getUsername();\n    String password = cfg.getPassword();\n    String tableName = cfg.getTableName();\n    String namespace = cfg.getNamespace();\n    String writeMode = cfg.getWriteMode();\n    String hbaseConfig = cfg.getHbaseConfig();\n    List<String> column = cfg.getColumn();\n\n    // \u68c0\u67e5\u5fc5\u8981\u7684\u914d\u7f6e\u9879\u662f\u5426\u5b58\u5728\n    if (StringUtils.isBlank(jdbcUrl)) {\n        throw new AddaxException(\"jdbcUrl is required\");\n    }\n    if (StringUtils.isBlank(username)) {\n        throw new AddaxException(\"username is required\");\n    }\n    if (StringUtils.isBlank(password)) {\n        throw new AddaxException(\"password is required\");\n    }\n    if (StringUtils.isBlank(tableName)) {\n        throw new AddaxException(\"tableName is required\");\n    }\n    if (StringUtils.isBlank(namespace)) {\n        throw new AddaxException(\"namespace is required\");\n    }\n    if (StringUtils.isBlank(writeMode)) {\n        throw new AddaxException(\"writeMode is required\");\n    }\n    if (StringUtils.isBlank(hbaseConfig)) {\n        throw new AddaxException(\"hbaseConfig is required\");\n    }\n    if (column == null || column.isEmpty()) {\n        throw new AddaxException(\"column is required\");\n    }\n\n    // \u68c0\u67e5writeMode\u662f\u5426\u5408\u6cd5\n    if (!HBaseConstant.WRITE_MODE_APPEND.equalsIgnoreCase(writeMode) && !HBaseConstant.WRITE_MODE_UPSERT.equalsIgnoreCase(writeMode)) {\n        throw new AddaxException(\"writeMode must be append or upsert\");\n    }\n\n    // \u68c0\u67e5column\u662f\u5426\u5408\u6cd5\n    for (String col : column) {\n        if (StringUtils.isBlank(col)) {\n            throw new AddaxException(\"column cannot be empty\");\n        }\n    }\n\n    // \u68c0\u67e5hbaseConfig\u662f\u5426\u5408\u6cd5\n    Configuration h", "CodeBleu_score": 34.135719857448635}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    // Establish a JDBC connection to the Phoenix server\n    try (Connection connection = DriverManager.getConnection(cfg.getPhoenixUrl(), cfg.getUsername(), cfg.getPassword())) {\n        // Check if the specified table exists in the given namespace\n        String tableName = cfg.getTable();\n        String namespace = cfg.getNamespace();\n        if (StringUtils.isNotBlank(namespace)) {\n            tableName = namespace + \":\" + tableName;\n        }\n        if (!tableExists(connection, tableName)) {\n            throw new AddaxException(String.format(\"Table %s does not exist in namespace %s.\", cfg.getTable(), cfg.getNamespace()));\n        }\n\n        // Retrieve the table schema and check if all configured columns exist\n        Map<String, String> columnMap = getColumnMap(connection, tableName);\n        List<String> columnList = cfg.getColumn();\n        for (String column : columnList) {\n            if (!columnMap.containsKey(column)) {\n                throw new AddaxException(String.format(\"Column %s does not exist in table %s.\", column, cfg.getTable()));\n            }\n        }\n    } catch (SQLException e) {\n        throw new AddaxException(e);\n    }\n}", "CodeBleu_score": 34.30664124123883}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    String jdbcUrl = cfg.getJdbcUrl();\n    String table = cfg.getTable();\n    String namespace = cfg.getNamespace();\n    String username = cfg.getUsername();\n    String password = cfg.getPassword();\n    String columns = cfg.getColumns();\n    String where = cfg.getWhere();\n    String querySql = cfg.getQuerySql();\n\n    if (StringUtils.isBlank(jdbcUrl)) {\n        throw new AddaxException(\"jdbcUrl is required.\");\n    }\n    if (StringUtils.isBlank(table)) {\n        throw new AddaxException(\"table is required.\");\n    }\n    if (StringUtils.isBlank(columns)) {\n        throw new AddaxException(\"columns is required.\");\n    }\n    if (StringUtils.isBlank(querySql)) {\n        throw new AddaxException(\"querySql is required.\");\n    }\n\n    try (Connection connection = DriverManager.getConnection(jdbcUrl, username, password)) {\n        Statement statement = connection.createStatement();\n        String sql = \"SELECT 1 FROM \" + table;\n        if (StringUtils.isNotBlank(namespace)) {\n            sql += \"@\" + namespace;\n        }\n        ResultSet resultSet = statement.executeQuery(sql);\n        if (!resultSet.next()) {\n            throw new AddaxException(\"Table \" + table + \" does not exist.\");\n        }\n\n        Map<String, PDataType> columnTypes = getColumnTypes(connection, table, namespace);\n        List<String> columnList = JSON.parseObject(columns, new TypeReference<List<String>>() {});\n        for (String column : columnList) {\n            if (!columnTypes.containsKey(column)) {\n                throw new AddaxException(\"Column \" + column + \" does not exist in the target table.\");\n            }\n        }\n\n        if (StringUtils.isNotBlank(where)) {\n            sql = \"SELECT 1 FROM \" + table;\n            if (StringUtils.isNotBlank(namespace)) {\n                sql += \"@\" + namespace;\n            }\n            sql += \" WHERE \" + where;\n            resultSet", "CodeBleu_score": 32.0185837230245}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        Configuration hadoopConf = new Configuration();\n        hadoopConf.set(HConstants.HBASE_SECURITY_AUTHENTICATION, HBaseConstant.KERBEROS);\n        hadoopConf.set(HConstants.HBASE_SECURITY_AUTHORIZATION, HBaseConstant.TRUE);\n        hadoopConf.set(HConstants.HBASE_SECURITY_PRINCIPAL, kerberosPrincipal);\n        hadoopConf.set(HConstants.HBASE_SECURITY_KEYTAB_FILE, kerberosKeytabFilePath);\n        try {\n            UserGroupInformation.setConfiguration(hadoopConf);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Kerberos login error: {}\", e.getMessage());\n            throw new AddaxException(\"Kerberos login error: \" + e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 51.52057028366153}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            UserGroupInformation.setConfiguration(HBaseConstant.HBASE_CONFIG);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Kerberos login error\", e);\n            throw new AddaxException(\"Kerberos login error\", e);\n        }\n    }\n}", "CodeBleu_score": 39.82043340662503}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            Configuration.set(HBaseConstant.HBASE_SECURITY_AUTHENTICATION, HBaseKey.KERBEROS);\n            UserGroupInformation.setConfiguration(Configuration.get());\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            throw new AddaxException(\"Kerberos login error: \" + e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 39.665944601268485}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        ResultSetMetaData metaData = rs.getMetaData();\n        Map<String, ThinClientPTable.ThinClientPColumn> columnMap = new HashMap<>();\n        for (int i = 1; i <= metaData.getColumnCount(); i++) {\n            String name = metaData.getColumnLabel(i);\n            String type = metaData.getColumnTypeName(i);\n            if (StringUtils.isEmpty(name) || StringUtils.isEmpty(type)) {\n                throw new SQLException(String.format(\"Column name or type is null, name: %s, type: %s\", name, type));\n            }\n            columnMap.put(name, new ThinClientPTable.ThinClientPColumn(type));\n        }\n        return columnMap;\n    }", "CodeBleu_score": 36.06004894959222}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    Map<String, ThinClientPTable.ThinClientPColumn> columnMap = new HashMap<>();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int colCount = rsmd.getColumnCount();\n    for (int i = 1; i <= colCount; i++) {\n        String columnName = rsmd.getColumnLabel(i);\n        if (columnName == null) {\n            throw new SQLException(\"Column name is null\");\n        }\n        String columnType = rsmd.getColumnTypeName(i);\n        if (columnType == null) {\n            throw new SQLException(\"Column type is null\");\n        }\n        columnMap.put(columnName, new ThinClientPTable.ThinClientPColumn(columnType));\n    }\n    return columnMap;\n}", "CodeBleu_score": 40.90856183110522}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> colTypeMap = new HashMap<>();\n        ResultSetMetaData metaData = rs.getMetaData();\n        int colCount = metaData.getColumnCount();\n        for (int i = 1; i <= colCount; i++) {\n            String colName = metaData.getColumnLabel(i);\n            String colType = metaData.getColumnTypeName(i);\n            if (StringUtils.isBlank(colName) || StringUtils.isBlank(colType)) {\n                throw new SQLException(\"column name or type is null\");\n            }\n            colTypeMap.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n        }\n        return colTypeMap;\n    }", "CodeBleu_score": 43.20504121004517}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection phoenixConnection = (PhoenixConnection) conn;\n        Admin admin = phoenixConnection.getAdmin();\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw new AddaxException(\"Table \" + tableName + \" does not exist.\");\n        }\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        LOG.debug(\"Table {} has been truncated.\", tableName);\n    } catch (IOException e) {\n        throw new AddaxException(\"Failed to truncate table \" + tableName, e);\n    } finally {\n        try {\n            conn.close();\n        } catch (SQLException e) {\n            LOG.error(\"Failed to close connection\", e);\n        }\n    }\n}", "CodeBleu_score": 44.590430609615694}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection phoenixConn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = phoenixConn.getAdmin();\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw new AddaxException(HBaseConstant.HBASE_TABLE_NOT_EXISTS, String.format(HBaseConstant.HBASE_TABLE_NOT_EXISTS_MSG, tableName));\n        }\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        LOG.debug(\"Truncated table {}\", tableName);\n    } catch (IOException e) {\n        throw new AddaxException(HBaseConstant.HBASE_TRUNCATE_TABLE_ERROR, String.format(HBaseConstant.HBASE_TRUNCATE_TABLE_ERROR_MSG, tableName, e.getMessage()));\n    } finally {\n        try {\n            conn.unwrap(PhoenixConnection.class).getAdmin().close();\n        } catch (SQLException e) {\n            LOG.warn(\"Failed to close admin connection\", e);\n        }\n    }\n}", "CodeBleu_score": 42.663541063438046}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try (Admin admin = getAdmin(conn)) {\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw new AddaxException(HBaseKey.HBASE_TABLE_NOT_EXISTS, tableName);\n        }\n        admin.disableTable(TableName.valueOf(tableName));\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        LOG.debug(\"truncate table {} success\", tableName);\n    } catch (Exception e) {\n        throw new AddaxException(HBaseKey.HBASE_TRUNCATE_TABLE_ERROR, tableName, e);\n    } finally {\n        if (admin != null) {\n            try {\n                admin.close();\n            } catch (IOException e) {\n                LOG.error(\"close admin error\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 39.586307590074945}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    if (filePath.endsWith(fileType)) {\n        LOG.info(\"add file: {}\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        LOG.error(\"unsupported file type: {}\", filePath);\n        throw new AddaxException(StorageReaderErrorCode.UNSUPPORTED_FILE_TYPE, \"unsupported file type: \" + filePath);\n    }\n}", "CodeBleu_score": 16.954120280173786}, {"code": "private void addSourceFileByType(String filePath){\n\t    String fileType = this.fileType;\n    if (StringUtils.isBlank(fileType)) {\n        fileType = StorageReaderUtil.getFileType(filePath);\n    }\n    if (StringUtils.isBlank(fileType)) {\n        throw new AddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"File type is illegal\");\n    }\n    if (fileType.equals(FileType.ORC.getTypeName())) {\n        this.sourceFiles.add(filePath);\n        logger.info(\"Add source file: {}\", filePath);\n    } else {\n        throw new AddaxException(StorageReaderErrorCode.UNSUPPORTED_FILE_TYPE, \"Unsupported file type: \" + fileType);\n    }\n}", "CodeBleu_score": 35.85056822676568}, {"code": "private void addSourceFileByType(String filePath){\n\t    if (StringUtils.isEmpty(filePath)) {\n        return;\n    }\n    String fileType = getFileType(filePath);\n    if (fileType.equals(fileType)) {\n        LOG.info(\"file type is {}, add source file {}\", fileType, filePath);\n        sourceFiles.add(filePath);\n    } else {\n        LOG.error(\"unsupported file type {}\", fileType);\n        throw new AddaxException(StorageReaderErrorCode.UNSUPPORTED_FILE_TYPE, fileType);\n    }\n}", "CodeBleu_score": 30.821963641055028}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        try {\n            LOG.info(\"Start read sequence file: {}\", sourceSequenceFilePath);\n\n            FileSystem fs = FileSystem.get(new JobConf());\n            Path path = new Path(sourceSequenceFilePath);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, new JobConf());\n\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), new JobConf());\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), new JobConf());\n\n            while (reader.next(key, value)) {\n                if (value != null && !value.toString().trim().equals(\"\")) {\n                    StorageReaderUtil.transport(value.toString(), readerSliceConfig, recordSender, taskPluginCollector);\n                }\n            }\n        } catch (Exception e) {\n            LOG.error(\"sequence file read failed.\", e);\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.SEQUENCE_FILE_READ_FAILED, e);\n        }\n    }", "CodeBleu_score": 52.27855832424824}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    try {\n        LOG.info(\"Start read sequence file {}\", sourceSequenceFilePath);\n        FileSystem fileSystem = StorageReaderUtil.getFileSystem(readerSliceConfig);\n        Path path = new Path(sourceSequenceFilePath);\n        FileStatus fileStatus = fileSystem.getFileStatus(path);\n        SequenceFile.Reader reader = new SequenceFile.Reader(fileSystem, path, fileSystem.getConf());\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), fileSystem.getConf());\n        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), fileSystem.getConf());\n        long start = System.currentTimeMillis();\n        while (reader.next(key, value)) {\n            String valueStr = value.toString();\n            if (StringUtils.isNotBlank(valueStr)) {\n                StorageReaderUtil.transport(recordSender, valueStr);\n            }\n        }\n        reader.close();\n        LOG.info(\"Read sequence file {} success, cost {} ms\", sourceSequenceFilePath, System.currentTimeMillis() - start);\n    } catch (Exception e) {\n        LOG.error(\"Read sequence file {} error\", sourceSequenceFilePath, e);\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.READ_SEQUENCE_FILE_ERROR,\n                String.format(\"Read sequence file %s error\", sourceSequenceFilePath), e);\n    }\n}", "CodeBleu_score": 49.09173854043735}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    try {\n        LOG.info(\"Start read sequence file:{}\", sourceSequenceFilePath);\n        FileSystem fileSystem = StorageReaderUtil.getFileSystem(readerSliceConfig);\n        Path path = new Path(sourceSequenceFilePath);\n        SequenceFile.Reader reader = new SequenceFile.Reader(fileSystem, path, readerSliceConfig);\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), readerSliceConfig);\n        while (reader.next(key, value)) {\n            String valueStr = value.toString();\n            if (StringUtils.isNotBlank(valueStr)) {\n                StorageReaderUtil.transportRecord(recordSender, valueStr);\n            }\n        }\n        reader.close();\n    } catch (IOException | AddaxException e) {\n        LOG.error(\"sequence file read error\", e);\n        throw new AddaxException(StorageReaderErrorCode.SEQUENCE_FILE_READ_ERROR, e);\n    }\n}", "CodeBleu_score": 48.9857900117252}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        // Get the Hadoop configuration\n        Configuration conf = new Configuration();\n        conf.set(\"fs.hdfs.impl\", \"org.apache.hadoop.hdfs.DistributedFileSystem\");\n        conf.set(\"fs.file.impl\", \"org.apache.hadoop.fs.LocalFileSystem\");\n        conf.set(\"fs.defaultFS\", \"hdfs://localhost:9000\");\n\n        // Create a FileSystem instance\n        FileSystem fs = FileSystem.get(conf);\n\n        // Open the file using the FileSystem\n        FSDataInputStream inputStream = fs.open(new Path(filepath));\n\n        // Check the file format based on the specified file type\n        switch (specifiedFileType) {\n            case \"orc\":\n                // Check if the file is an ORC file\n                OrcFile.ReaderOptions options = OrcFile.readerOptions(conf);\n                Reader reader = OrcFile.createReader(inputStream, options);\n                return true;\n            case \"rc\":\n                // Check if the file is an RC file\n                RCFile.Reader reader = new RCFile.Reader(inputStream, conf);\n                return true;\n            case \"sequence\":\n                // Check if the file is a Sequence file\n                SequenceFile.Reader sequenceReader = new SequenceFile.Reader(conf, SequenceFile.Reader.file(inputStream));\n                return true;\n            case \"parquet\":\n                // Check if the file is a Parquet file\n                ParquetReader<Group> parquetReader = new ParquetReader<>(new HadoopInputFile(inputStream), new GroupReadSupport());\n                return true;\n            case \"csv\":\n                // Check if the file is a CSV file\n                String line = inputStream.readLine();\n                return line != null && line.split(\",\").length > 1;\n            case \"text\":\n                // Check if the file is a Text file\n                String text = inputStream.readUTF();\n                return text != null && text.split(\" \").length > 1;\n            default:\n                // Return false if the file type is not supported\n                return false;\n        }\n    } catch (IOException e) {\n        //", "CodeBleu_score": 34.25124669418367}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        FileStatus fileStatus = fs.getFileStatus(new Path(filepath));\n        switch (specifiedFileType.toLowerCase()) {\n            case \"orc\":\n                return OrcFile.isOrcFile(fileStatus.getPath(), fs);\n            case \"rc\":\n                return RCFile.isRCFile(fileStatus.getPath(), fs);\n            case \"sequence\":\n                return SequenceFile.isSequenceFile(fileStatus.getPath(), fs);\n            case \"parquet\":\n                return ParquetFileReader.isParquetFile(fileStatus.getPath(), fs);\n            case \"csv\":\n                return fileStatus.getPath().getName().endsWith(\".csv\");\n            case \"text\":\n                return fileStatus.getPath().getName().endsWith(\".txt\");\n            default:\n                return false;\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error checking file type: {}\", e.getMessage());\n        throw new AddaxException(StorageReaderErrorCode.CHECK_FILE_TYPE_ERROR, e.getMessage());\n    }\n}", "CodeBleu_score": 33.56365119103387}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        Path path = new Path(filepath);\n        FileStatus fileStatus = fs.getFileStatus(path);\n        switch (specifiedFileType) {\n            case \"ORC\":\n                return OrcFile.isOrcFile(fs, fileStatus.getPath(), new JobConf());\n            case \"RC\":\n                return RCFile.isRCFile(fs, fileStatus.getPath(), new JobConf());\n            case \"Sequence\":\n                return SequenceFile.isSequenceFile(fs, fileStatus.getPath());\n            case \"Parquet\":\n                return ParquetFileReader.isParquetFile(fs, fileStatus.getPath(), new JobConf());\n            case \"CSV\":\n                return filepath.endsWith(\".csv\");\n            case \"Text\":\n                return filepath.endsWith(\".txt\");\n            default:\n                return false;\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error while checking file type: {}\", e.getMessage());\n        throw new AddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, e.getMessage());\n    }\n}", "CodeBleu_score": 33.341485522485605}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t    try {\n        if (hConnection != null) {\n            hConnection.close();\n        }\n    } catch (IOException e) {\n        throw new AddaxException(\"Failed to close connection.\", e);\n    }\n}", "CodeBleu_score": 52.31147085875409}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(\"Close hbase connection error\", e, AddaxException.ErrorCode.CLOSE_HBASE_CONNECTION_ERROR);\n        }\n    }\n}", "CodeBleu_score": 55.59921129482729}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(\"Failed to close connection\", e, AddaxException.ErrorCode.HBASE_CONNECTION_CLOSE_FAILED);\n        }\n    }\n}", "CodeBleu_score": 54.641765414650266}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.HBASE_CLOSE_ADMIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 52.899792022145306}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.ERROR_CODE_ADMIN_CLOSE_FAIL, \"Failed to close admin.\", e);\n        }\n    }\n}", "CodeBleu_score": 50.51927920145034}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.HBASE_CLOSE_ADMIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 52.899792022145306}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n        long timestamp = cell.getTimestamp();\n        String family = Bytes.toString(CellUtil.cloneFamily(cell));\n        String qualifier = Bytes.toString(CellUtil.cloneQualifier(cell));\n        String value = Bytes.toString(CellUtil.cloneValue(cell));\n\n        String rowKeyType = hbaseConfig.getString(HBaseKey.HBASE_ROWKEY_TYPE, HBaseConstant.HBASE_ROWKEY_TYPE_STRING);\n        String rowKeyFormat = hbaseConfig.getString(HBaseKey.HBASE_ROWKEY_FORMAT, HBaseConstant.HBASE_ROWKEY_FORMAT_STRING);\n        String columnValueType = hbaseConfig.getString(HBaseKey.HBASE_COLUMN_VALUE_TYPE, HBaseConstant.HBASE_COLUMN_VALUE_TYPE_STRING);\n        String columnValueFormat = hbaseConfig.getString(HBaseKey.HBASE_COLUMN_VALUE_FORMAT, HBaseConstant.HBASE_COLUMN_VALUE_FORMAT_STRING);\n\n        if (StringUtils.isNotEmpty(rowKeyType) && StringUtils.isNotEmpty(rowKeyFormat)) {\n            switch (rowKeyType) {\n                case HBaseConstant.HBASE_ROWKEY_TYPE_STRING:\n                    record.addColumn(new LongColumn(HBaseConstant.HBASE_ROWKEY_NAME, Long.parseLong(rowKey)));\n                    break;\n                case HBaseConstant.HBASE_ROWKEY_TYPE_BINARY:\n                    record.addColumn(new LongColumn(HBaseConstant.HBASE_ROWKEY_NAME, Bytes.toLong(rowKey.getBytes(StandardCharsets.UTF_8))));\n                    break;\n                default:\n                    throw new Exception(\"Invalid row key type: \" + rowKeyType);\n            }\n        }\n\n        if (StringUtils.isNotEmpty(columnValueType) && StringUtils.isNotEmpty(columnValueFormat)) {\n            switch (columnValueType) {\n                case HBaseConstant.HBASE_COLUMN_VALUE_TYPE_STRING:\n                    record.addColumn(new LongColumn(HBaseConstant.H", "CodeBleu_score": 35.442079486201244}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        byte[] rowKey = CellUtil.cloneRow(cell);\n        long timestamp = cell.getTimestamp();\n        byte[] family = CellUtil.cloneFamily(cell);\n        byte[] qualifier = CellUtil.cloneQualifier(cell);\n        byte[] value = CellUtil.cloneValue(cell);\n\n        String rowKeyType = HBaseConstant.HBASE_DEFAULT_ROW_KEY_TYPE;\n        String rowKeyFormat = HBaseConstant.HBASE_DEFAULT_ROW_KEY_FORMAT;\n        if (rowKeyMapping != null) {\n            rowKeyType = rowKeyMapping.get(HBaseKey.HBASE_ROW_KEY_TYPE);\n            rowKeyFormat = rowKeyMapping.get(HBaseKey.HBASE_ROW_KEY_FORMAT);\n        }\n\n        if (rowKey != null) {\n            if (StringUtils.isNotEmpty(rowKeyFormat)) {\n                String rowKeyString = new String(rowKey, StandardCharsets.UTF_8);\n                record.addColumn(new LongColumn(rowKeyString));\n            } else {\n                record.addColumn(new LongColumn(Bytes.toLong(rowKey)));\n            }\n        }\n\n        if (timestamp > 0) {\n            record.addColumn(new LongColumn(timestamp));\n        }\n\n        if (family != null) {\n            record.addColumn(new LongColumn(Bytes.toString(family)));\n        }\n\n        if (qualifier != null) {\n            record.addColumn(new LongColumn(Bytes.toString(qualifier)));\n        }\n\n        if (value != null) {\n            String columnValueType = HBaseConstant.HBASE_DEFAULT_COLUMN_VALUE_TYPE;\n            String columnValueFormat = HBaseConstant.HBASE_DEFAULT_COLUMN_VALUE_FORMAT;\n            if (columnValueMapping != null) {\n                columnValueType = columnValueMapping.get(HBaseKey.HBASE_COLUMN_VALUE_TYPE);\n                columnValueFormat = columnValueMapping.get(HBaseKey.HBASE_COLUMN_VALUE_FORMAT);\n            }\n\n            if (StringUtils.isNotEmpty(columnValueFormat)) {\n                String column", "CodeBleu_score": 45.128661606574575}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        // Extract the row key from the cell\n        byte[] rowKeyBytes = CellUtil.cloneRow(cell);\n        String rowKey = Bytes.toString(rowKeyBytes);\n\n        // Extract the timestamp from the cell\n        long timestamp = cell.getTimestamp();\n\n        // Extract the column family and qualifier from the cell\n        byte[] familyBytes = CellUtil.cloneFamily(cell);\n        String family = Bytes.toString(familyBytes);\n        byte[] qualifierBytes = CellUtil.cloneQualifier(cell);\n        String qualifier = Bytes.toString(qualifierBytes);\n\n        // Extract the column value from the cell\n        byte[] valueBytes = CellUtil.cloneValue(cell);\n        String value = Bytes.toString(valueBytes);\n\n        // Determine the type and format for the row key\n        String rowKeyType = getType(rowKey);\n        String rowKeyFormat = getFormat(rowKey);\n\n        // Determine the type and format for the column value\n        String columnValueType = getType(value);\n        String columnValueFormat = getFormat(value);\n\n        // Add the row key, family, qualifier, timestamp, and column value as columns to the record\n        record.addColumn(new LongColumn(HBaseKey.ROW_KEY, rowKey, rowKeyType, rowKeyFormat));\n        record.addColumn(new LongColumn(HBaseKey.FAMILY, family, HBaseConstant.STRING, HBaseConstant.STRING));\n        record.addColumn(new LongColumn(HBaseKey.QUALIFIER, qualifier, HBaseConstant.STRING, HBaseConstant.STRING));\n        record.addColumn(new LongColumn(HBaseKey.TIMESTAMP, timestamp, HBaseConstant.LONG, HBaseConstant.LONG));\n        record.addColumn(new LongColumn(HBaseKey.VALUE, value, columnValueType, columnValueFormat));\n    }", "CodeBleu_score": 42.95834813619571}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY, StringUtils.EMPTY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    boolean isBinaryRowkey = configuration.getBoolean(HBaseKey.BINARY_ROWKEY, false);\n    if (isBinaryRowkey) {\n        return startRowkey.getBytes(Charset.defaultCharset());\n    } else {\n        return Bytes.toBytes(startRowkey);\n    }\n}", "CodeBleu_score": 53.95761127674656}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROW_KEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    if (configuration.getBoolean(HBaseKey.IS_BINARY_ROW_KEY, false)) {\n        return startRowkey.getBytes(Charset.defaultCharset());\n    } else {\n        return Bytes.toBytes(startRowkey);\n    }\n}", "CodeBleu_score": 57.83117320114395}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.HBASE_START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return Bytes.EMPTY_BYTES;\n    }\n    if (configuration.getBoolean(HBaseKey.HBASE_ROWKEY_BINARY)) {\n        return Bytes.toBytes(startRowkey);\n    }\n    return Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 54.17347726424892}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY, StringUtils.EMPTY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 68.98984925805559}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 68.85142156936116}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY, StringUtils.EMPTY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 68.98984925805559}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t        this.key = UUID.fromString(record.key());\n        this.data = record.value();\n        this.headers = new DefaultTbQueueMsgHeaders(record.headers());\n    }", "CodeBleu_score": 44.72499908338363}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    super(UUID.fromString(record.key()), new DefaultTbQueueMsgHeaders(record.headers()), record.value());\n}", "CodeBleu_score": 18.565586427345067}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new DefaultTbQueueMsgHeaders();\n    record.headers().forEach(header -> headers.put(header.key(), header.value()));\n    this.data = record.value();\n}", "CodeBleu_score": 58.04168473126362}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producer = new TbKafkaProducerTemplate<>(kafkaSettings,\n            \"tb-transport-notifications-\" + serviceId,\n            transportNotificationSettings.getDefaultTopic());\n    producer.setAdmin(new TbKafkaAdmin(kafkaSettings));\n    return producer;\n}", "CodeBleu_score": 33.02642155510925}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> template = new TbKafkaProducerTemplate<>(\n            kafkaSettings,\n            kafkaSettings.getClientId() + \"-\" + transportNotificationSettings.getServiceId(),\n            transportNotificationSettings.getDefaultTopic(),\n            new TbKafkaAdmin(kafkaSettings, kafkaSettings.getClientId() + \"-\" + transportNotificationSettings.getServiceId()));\n    template.setDefaultTopic(transportNotificationSettings.getDefaultTopic());\n    return template;\n}", "CodeBleu_score": 38.20732509426452}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate = new TbKafkaProducerTemplate<>(\n            kafkaSettings,\n            kafkaSettings.getClientId() + \"-transport-notifications\",\n            transportNotificationSettings.getDefaultTopic()\n    );\n    producerTemplate.setAdmin(new TbKafkaAdmin(kafkaSettings));\n    return producerTemplate;\n}", "CodeBleu_score": 36.44769919714999}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n            new TbKafkaAdmin(kafkaSettings),\n            new TbKafkaConsumerStatsService(),\n            kafkaSettings,\n            topicService.getTopicFullName(ServiceType.TB_CORE, TopicType.TB_CORE_NOTIFICATIONS),\n            \"tb-core-notifications-consumer\",\n            \"tb-core-notifications-group\",\n            new ProtoMsgDecoder<>(ToCoreNotificationMsg.parser())\n    );\n    consumerTemplate.configure(new TbQueueAdmin(kafkaSettings), new TbQueueConsumerStatsService());\n    return consumerTemplate;\n}", "CodeBleu_score": 33.408710717084986}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n            kafkaSettings,\n            topicService.getNotificationsTopic(),\n            kafkaSettings.getClientId(),\n            kafkaSettings.getGroupId(),\n            new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.parser()));\n    consumerTemplate.setAdmin(kafkaAdmin);\n    consumerTemplate.setConsumerStatsService(kafkaConsumerStatsService);\n    return consumerTemplate;\n}", "CodeBleu_score": 33.16093609211456}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate = new TbKafkaConsumerTemplate<>(\n            new TbKafkaSettings(kafkaSettings),\n            kafkaSettings.getNotificationsTopic(),\n            kafkaSettings.getNotificationsConsumerClientId(),\n            kafkaSettings.getNotificationsConsumerGroupId(),\n            new TbKafkaTopicConfigs(kafkaSettings),\n            new TbProtoQueueMsgDecoder<>(ToCoreNotificationMsg.parser())\n    );\n    consumerTemplate.setAdmin(kafkaAdmin);\n    consumerTemplate.setConsumerStatsService(consumerStatsService);\n    return consumerTemplate;\n}", "CodeBleu_score": 34.27093077109058}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        for (String topicName : topicNames) {\n            if (!kafkaAdmin.topicExists(topicName)) {\n                kafkaAdmin.createTopic(topicName, topicProperties);\n            }\n        }\n        consumer.subscribe(topicNames);\n    } else {\n        log.info(\"[{}] Unsubscribe from all topics\", getName());\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 60.74391831350212}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        topicNames.forEach(topic -> {\n            try {\n                admin.createTopicIfNotExists(topic);\n            } catch (IOException e) {\n                log.error(\"[{}] Failed to create topic: {}\", consumerId, topic, e);\n            }\n        });\n        consumer.subscribe(topicNames);\n    } else {\n        log.info(\"[{}] No topics to subscribe to.\", consumerId);\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 59.860593596323284}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        for (String topicName : topicNames) {\n            try {\n                if (!topicExists(topicName)) {\n                    createTopic(topicName);\n                }\n            } catch (IOException e) {\n                log.error(\"Failed to create topic [{}]\", topicName, e);\n            }\n        }\n        consumer.subscribe(topicNames);\n    } else {\n        log.info(\"No topic names provided. Unsubscribing from all topics.\");\n        consumer.unsubscribe();\n    }\n}", "CodeBleu_score": 61.24215596572981}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t        StopWatch stopWatch = new StopWatch();\n        stopWatch.start();\n        log.trace(\"Starting to poll records from topic: [{}] for [{}] ms\", topic, durationInMillis);\n        ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n        stopWatch.stop();\n        log.trace(\"Polled records from topic [{}] in [{}] ms\", topic, stopWatch.getTotalTimeMillis());\n        if (records.isEmpty()) {\n            return Collections.emptyList();\n        }\n        List<ConsumerRecord<String, byte[]>> consumerRecords = new ArrayList<>();\n        records.forEach(consumerRecords::add);\n        return consumerRecords;\n    }", "CodeBleu_score": 70.58263530309925}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t        StopWatch stopWatch = new StopWatch();\n        stopWatch.start();\n        ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n        stopWatch.stop();\n        log.trace(\"Poll records from topic {} completed in {} ms\", topic, stopWatch.getTotalTimeMillis());\n        if (records.isEmpty()) {\n            return Collections.emptyList();\n        }\n        List<ConsumerRecord<String, byte[]>> result = new ArrayList<>();\n        for (ConsumerRecord<String, byte[]> record : records) {\n            result.add(record);\n        }\n        return result;\n    }", "CodeBleu_score": 60.61350871060927}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    StopWatch stopWatch = new StopWatch();\n    stopWatch.start();\n    log.trace(\"Starting to poll records from topic [{}]\", topic);\n    ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopWatch.stop();\n    log.trace(\"Polled records from topic [{}] in [{}] ms\", topic, stopWatch.getTotalTimeMillis());\n    if (records.isEmpty()) {\n        return Collections.emptyList();\n    } else {\n        List<ConsumerRecord<String, byte[]>> recordList = new ArrayList<>();\n        records.forEach(recordList::add);\n        return recordList;\n    }\n}", "CodeBleu_score": 71.38971871367129}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        if (initializationFailed) {\n            log.error(\"Kafka node failed to initialize. Please check the configuration.\");\n            ctx.tellFailure(new TbNodeException(\"Kafka node failed to initialize. Please check the configuration.\"));\n            return;\n        }\n\n        String topic = TbNodeUtils.processPattern(topicPattern, msg, ctx);\n        String key = TbNodeUtils.processPattern(keyPattern, msg, ctx);\n\n        TbMsgMetaData metaData = msg.getMetaData();\n        byte[] value = msg.getBytes();\n        Headers headers = new RecordHeaders();\n        metaData.getHeaders().forEach((k, v) -> headers.add(new RecordHeader(k, v.getBytes(StandardCharsets.UTF_8))));\n\n        ctx.getExecutor().execute(() -> {\n            try {\n                RecordMetadata metadata = producer.send(new ProducerRecord<>(topic, key, value, headers)).get();\n                log.info(\"Message sent to Kafka topic {} with key {} and offset {}\", metadata.topic(), metadata.key(), metadata.offset());\n            } catch (Exception e) {\n                log.error(\"Failed to send message to Kafka\", e);\n                ctx.tellFailure(new TbNodeException(\"Failed to send message to Kafka\", e));\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"Failed to process message\", e);\n        ctx.tellFailure(new TbNodeException(\"Failed to process message\", e));\n    }\n}", "CodeBleu_score": 37.4616970051941}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        init();\n        if (initializationError != null) {\n            log.error(\"[{}] Kafka Producer initialization error: {}\", ctx.getRuleNodeId(), initializationError);\n            ctx.onError(initializationError);\n            return;\n        }\n        TbMsgMetaData metaData = msg.getMetaData();\n        String topic = TbNodeUtils.processPattern(topicPattern, ctx, metaData);\n        String key = TbNodeUtils.processPattern(keyPattern, ctx, metaData);\n        log.debug(\"[{}] Kafka Producer: topic: {}, key: {}\", ctx.getRuleNodeId(), topic, key);\n        TbNodeUtils.executeAsync(() -> {\n            try {\n                Headers headers = new RecordHeaders();\n                for (String headerName : headerNames) {\n                    String headerValue = TbNodeUtils.processPattern(headerName, ctx, metaData);\n                    headers.add(new RecordHeader(headerName, headerValue.getBytes(StandardCharsets.UTF_8)));\n                }\n                ProducerRecord<String, String> record = new ProducerRecord<>(topic, 0, key, msg.getData(), headers);\n                producer.send(record, (RecordMetadata metadata, Exception exception) -> {\n                    if (exception != null) {\n                        log.error(\"[{}] Kafka Producer: Failed to send message to topic: {}, key: {}\", ctx.getRuleNodeId(), topic, key, exception);\n                        ctx.onError(new TbNodeException(exception));\n                    } else {\n                        log.debug(\"[{}] Kafka Producer: Message sent to topic: {}, key: {}\", ctx.getRuleNodeId(), topic, key);\n                    }\n                });\n            } catch (Exception e) {\n                log.error(\"[{}] Kafka Producer: Failed to send message to topic: {}, key: {}\", ctx.getRuleNodeId(), topic, key, e);\n                ctx.onError(new TbNodeException(e));\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"[{}] Kafka Producer: Failed to process message\", ctx.", "CodeBleu_score": 37.53078831309994}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        if (initializationFailed) {\n            ctx.reportError(new TbNodeException(\"Initialization failed\"));\n        } else {\n            String topicPattern = topicPattern.isEmpty() ? null : topicPattern;\n            String keyPattern = keyPattern.isEmpty() ? null : keyPattern;\n            TbMsgMetaData metaData = msg.getMetaData();\n            String topic = TbNodeUtils.processPattern(topicPattern, ctx, metaData);\n            String key = TbNodeUtils.processPattern(keyPattern, ctx, metaData);\n            TbNodeUtils.executeAsync(() -> {\n                try {\n                    producer.send(new ProducerRecord<>(topic, key, msg.getPayload())).get();\n                } catch (Exception e) {\n                    ctx.reportError(new TbNodeException(e));\n                }\n            });\n        }\n    } catch (Exception e) {\n        ctx.reportError(new TbNodeException(e));\n    }\n}", "CodeBleu_score": 44.78755784391635}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        Headers headers = null;\n        if (BooleanUtils.isTrue(addMetadata)) {\n            headers = createHeaders(msg.getMetaData());\n        }\n        ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, key, msg.getData(), headers);\n        producer.send(record, (RecordMetadata metadata, Exception exception) -> {\n            if (exception != null) {\n                log.debug(\"[{}] Failed to send message to Kafka topic: {}\", ctx.getTenantId(), exception.getMessage());\n            }\n        });\n    } catch (Exception e) {\n        throw new TbNodeException(e);\n    }\n}", "CodeBleu_score": 37.221633377801275}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    ProducerRecord<String, String> record;\n    Headers headers;\n    if (addMetadataAsKafkaHeaders) {\n        headers = new RecordHeaders();\n        for (TbMsgMetaData metaData : msg.getMetaData().values()) {\n            headers.add(new RecordHeader(metaData.getKey(), metaData.getValue().getBytes(StandardCharsets.UTF_8)));\n        }\n        record = new ProducerRecord<>(topic, null, key, msg.getPayload(), headers);\n    } else {\n        record = new ProducerRecord<>(topic, null, key, msg.getPayload());\n    }\n    try {\n        producer.send(record, (RecordMetadata recordMetadata, Exception e) -> {\n            if (e != null) {\n                log.debug(\"[{}] Failed to send message to Kafka topic: {}\", ctx.getTenantId(), e.getMessage());\n            }\n        });\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to send message to Kafka topic: {}\", ctx.getTenantId(), e.getMessage());\n    }\n}", "CodeBleu_score": 40.71817442719522}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        if (BooleanUtils.isTrue(addMetadataAsHeaders)) {\n            Headers headers = new RecordHeaders();\n            for (String metadataKey : metadataKeys) {\n                String metadataValue = msg.getMetaData().getValue(metadataKey);\n                if (metadataValue != null) {\n                    headers.add(new RecordHeader(metadataKey, metadataValue.getBytes(StandardCharsets.UTF_8)));\n                }\n            }\n            producer.send(new ProducerRecord<>(topic, null, key, msg.getData(), headers), (RecordMetadata recordMetadata, Exception e) -> {\n                if (e != null) {\n                    log.debug(\"[{}] Failed to send message to Kafka topic [{}]: {}\", ctx.getTenantId(), topic, e.getMessage());\n                }\n            });\n        } else {\n            producer.send(new ProducerRecord<>(topic, null, key, msg.getData()), (RecordMetadata recordMetadata, Exception e) -> {\n                if (e != null) {\n                    log.debug(\"[{}] Failed to send message to Kafka topic [{}]: {}\", ctx.getTenantId(), topic, e.getMessage());\n                }\n            });\n        }\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to send message to Kafka topic [{}]: {}\", ctx.getTenantId(), topic, e.getMessage());\n    }\n}", "CodeBleu_score": 38.895956648536014}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(\n            TbKafkaProducerTemplate.KafkaProducerTemplateBuilder\n                    .<TbProtoQueueMsg<ToRuleEngineMsg>>builder()\n                    .withKafkaSettings(kafkaSettings)\n                    .withClientId(serviceInfoProvider.getServiceId())\n                    .withDefaultTopic(queueRuleEngineSettings.getDefaultRuleEngineTopic())\n                    .withAdmin(kafkaAdmin)\n                    .build()\n    );\n}", "CodeBleu_score": 27.2351234654441}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToRuleEngineMsg>> template = new TbKafkaProducerTemplate<>();\n    template.setKafkaSettings(kafkaSettings);\n    template.setClientId(serviceInfoProvider.getServiceId());\n    template.setDefaultTopic(ruleEngineQueue.getTopic());\n    template.setAdmin(kafkaAdmin);\n    return template;\n}", "CodeBleu_score": 37.693802576199964}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(\n            TbKafkaProducerTemplate.builder()\n                    .settings(kafkaSettings)\n                    .clientId(serviceInfoProvider.getServiceId())\n                    .defaultTopic(ruleEngineSettings.getRuleEngineTopic())\n                    .admin(kafkaAdmin)\n    );\n}", "CodeBleu_score": 23.796930599125155}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t    long timeout = kafkaConsumerProperties.getProperties().getOrDefault(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000);\n    scheduledExecutorService.scheduleWithFixedDelay(() -> {\n        try {\n            if (logStats.get() && !monitoredConsumerGroups.isEmpty()) {\n                for (String groupId : monitoredConsumerGroups) {\n                    Map<TopicPartition, Long> laggingTopics = new ConcurrentHashMap<>();\n                    Map<TopicPartition, Long> groupOffsets = consumer.endOffsets(consumer.assignment(), Duration.ofMillis(timeout));\n                    Map<TopicPartition, Long> endOffsets = consumer.endOffsets(consumer.assignment(), Duration.ofMillis(timeout));\n                    for (TopicPartition partition : groupOffsets.keySet()) {\n                        long groupOffset = groupOffsets.get(partition);\n                        long endOffset = endOffsets.get(partition);\n                        if (groupOffset < endOffset) {\n                            laggingTopics.put(partition, endOffset - groupOffset);\n                        }\n                    }\n                    if (!laggingTopics.isEmpty()) {\n                        log.warn(\"[{}] Lagging topics: {}\", groupId, laggingTopics);\n                    }\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"Failed to log consumer group statistics for group [{}]\", groupId, e);\n        }\n    }, 0, 10, TimeUnit.SECONDS);\n}", "CodeBleu_score": 38.72383785083301}, {"code": "private void startLogScheduling(){\n\t    Duration timeout = Duration.ofMillis(kafkaConsumerProperties.getProperties().getOrDefault(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 30000));\n    scheduledExecutorService.scheduleWithFixedDelay(() -> {\n        try {\n            if (logStats) {\n                for (String groupId : monitoredConsumerGroups) {\n                    List<String> laggingTopics = new ArrayList<>();\n                    for (TopicPartition partition : consumer.partitionsFor(groupId)) {\n                        OffsetAndMetadata committedOffset = consumer.committed(partition);\n                        long endOffset = consumer.endOffsets(List.of(partition)).get(partition);\n                        if (committedOffset.offset() < endOffset) {\n                            laggingTopics.add(partition.topic() + \":\" + partition.partition());\n                        }\n                    }\n                    if (!laggingTopics.isEmpty()) {\n                        log.info(\"Group: {}, Lagging topics: {}\", groupId, StringUtils.join(laggingTopics, \",\"));\n                    }\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"Failed to log Kafka consumer group statistics for group: {}\", groupId, e);\n        }\n    }, 10, 10, TimeUnit.SECONDS);\n}", "CodeBleu_score": 36.38783592200618}, {"code": "private void startLogScheduling(){\n\t    Duration timeout = Duration.ofMillis(kafkaProperties.getProperties().getOrDefault(ConsumerConfig.REQUEST_TIMEOUT_MS_CONFIG, 60000));\n    ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor(ThingsBoardThreadFactory.forName(\"kafka-stats-logger\"));\n    executor.scheduleWithFixedDelay(() -> {\n        try {\n            if (logStats.get()) {\n                for (ConsumerGroupStats stats : consumerGroupsStats.values()) {\n                    if (stats.getConsumer() != null) {\n                        Map<TopicPartition, Long> endOffsets = stats.getConsumer().endOffsets(stats.getConsumer().assignment(), timeout);\n                        Map<TopicPartition, Long> groupOffsets = stats.getConsumer().committed(stats.getConsumer().assignment(), timeout);\n                        List<TopicPartition> laggingTopics = new ArrayList<>();\n                        for (TopicPartition tp : endOffsets.keySet()) {\n                            Long endOffset = endOffsets.get(tp);\n                            Long groupOffset = groupOffsets.get(tp);\n                            if (endOffset - groupOffset > 0) {\n                                laggingTopics.add(tp);\n                            }\n                        }\n                        if (!laggingTopics.isEmpty()) {\n                            log.info(\"[{}] Lagging topics: {}\", stats.getConsumer().groupMetadata().groupId(), laggingTopics);\n                        }\n                    }\n                }\n            }\n        } catch (Exception e) {\n            log.warn(\"[{}] Failed to log kafka consumer group stats: {}\", stats.getConsumer().groupMetadata().groupId(), e.getMessage());\n            log.debug(\"[{}] Failed to log kafka consumer group stats: \", stats.getConsumer().groupMetadata().groupId(), e);\n        }\n    }, 0, logStatsPeriod, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 41.506165706498045}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t        Properties props = toProps();\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n        return props;\n    }", "CodeBleu_score": 89.50348007366593}, {"code": "protected Properties toAdminProps(){\n\t        Properties props = toProps();\n        props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n        props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n        return props;\n        }", "CodeBleu_score": 89.10950668408421}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.69084212730418}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t        // Create a scoped name for the metric\n        String scopedName = group.getScopeComponent(metricName);\n\n        // Extract the tags from the metric name\n        Map<String, String> tags = extractTags(metricName);\n\n        // Create a MetricEvent with the scoped name and tags\n        MetricEvent event = new MetricEvent(scopedName, tags);\n\n        // Add the metric and its event to the corresponding collection based on the metric type\n        if (metric instanceof Counter) {\n            counters.put(metric, event);\n        } else if (metric instanceof Gauge) {\n            gauges.put(metric, event);\n        } else if (metric instanceof Histogram) {\n            histograms.put(metric, event);\n        } else if (metric instanceof Meter) {\n            meters.put(metric, event);\n        } else {\n            // Log a warning message if the metric type is unknown\n            LOG.warn(\"Unknown metric type for metric {}\", metricName);\n        }\n    }", "CodeBleu_score": 47.695111491953476}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t        // Create a MetricEvent with a scoped name and tags derived from the metric name and group\n        MetricEvent event = new MetricEvent(metricName, group.getAllVariables(), System.currentTimeMillis(), metric.getValue());\n        // Add the metric and its event to the corresponding collection based on the metric type\n        if (metric instanceof Counter) {\n            counters.put(metric, event);\n        } else if (metric instanceof Gauge) {\n            gauges.put(metric, event);\n        } else if (metric instanceof Histogram) {\n            histograms.put(metric, event);\n        } else if (metric instanceof Meter) {\n            meters.put(metric, event);\n        } else {\n            LOG.warn(\"Metric type {} is not supported.\", metric.getClass().getName());\n        }\n    }", "CodeBleu_score": 51.21265931073573}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = group.getScopeComponent(metricName);\n    Map<String, String> tags = new HashMap<>();\n    tags.put(\"name\", metricName);\n    tags.put(\"scope\", scopedName);\n    if (group instanceof AbstractMetricGroup) {\n        AbstractMetricGroup abstractMetricGroup = (AbstractMetricGroup) group;\n        tags.put(\"parent\", abstractMetricGroup.getParent().getScope());\n    }\n    MetricEvent event = new MetricEvent(scopedName, tags);\n    if (metric instanceof Counter) {\n        Counter counter = (Counter) metric;\n        counters.add(counter, event);\n    } else if (metric instanceof Gauge) {\n        Gauge gauge = (Gauge) metric;\n        gauges.add(gauge, event);\n    } else if (metric instanceof Histogram) {\n        Histogram histogram = (Histogram) metric;\n        histograms.add(histogram, event);\n    } else if (metric instanceof Meter) {\n        Meter meter = (Meter) metric;\n        meters.add(meter, event);\n    } else {\n        LOG.warn(\"Unknown metric type: \" + metric.getClass().getName());\n    }\n}", "CodeBleu_score": 42.4325052292721}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (metricEvent.hasFields()) {\n        if (value instanceof Number) {\n            metricEvent.addField(field, (Number) value);\n        } else {\n            metricEvent.addField(field, value.toString());\n        }\n    } else {\n        Map<String, Object> fields = new HashMap<>();\n        if (value instanceof Number) {\n            fields.put(field, (Number) value);\n        } else {\n            fields.put(field, value.toString());\n        }\n        metricEvent.setFields(fields);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 65.07430097086714}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (metricEvent.hasFields()) {\n        Map<String, Object> fields = metricEvent.getFields();\n        if (value instanceof Number) {\n            fields.put(field, value);\n        } else {\n            fields.put(field, value.toString());\n        }\n    } else {\n        Map<String, Object> fields = new HashMap<>();\n        if (value instanceof Number) {\n            fields.put(field, value);\n        } else {\n            fields.put(field, value.toString());\n        }\n        metricEvent.setFields(fields);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 60.859283108290626}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (metricEvent.hasFields()) {\n        if (value instanceof Number) {\n            metricEvent.addField(field, (Number) value);\n        } else {\n            metricEvent.addField(field, value.toString());\n        }\n    } else {\n        Map<String, Object> fields = new HashMap<>();\n        if (value instanceof Number) {\n            fields.put(field, (Number) value);\n        } else {\n            fields.put(field, value.toString());\n        }\n        metricEvent.setFields(fields);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 65.07430097086714}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    // Extract values from the Gauge object\n    String[] values = gauge.getValue().toString().split(\",\");\n    String topic = values[0];\n    String partition = values[1];\n    String currentOffset = values[2];\n    String dataTimestamp = values[3];\n    String committedOffset = values[4];\n\n    // Check for changes in the Kafka lag metrics\n    if (!kafkaLagTimes.containsKey(topic + \"-\" + partition)) {\n        kafkaLagTimes.put(topic + \"-\" + partition, timestamp);\n    } else {\n        if (kafkaLagTimes.get(topic + \"-\" + partition) == timestamp) {\n            return metricEvent;\n        } else {\n            kafkaLagTimes.put(topic + \"-\" + partition, timestamp);\n        }\n    }\n\n    // Update the MetricEvent's fields with current offsets, data timestamp, and committed offsets\n    metricEvent.setFields(\n            new HashMap<String, String>() {{\n                put(\"currentOffset\", currentOffset);\n                put(\"dataTimestamp\", dataTimestamp);\n                put(\"committedOffset\", committedOffset);\n            }}\n    );\n\n    // Set the event's timestamp\n    metricEvent.setTimestamp(timestamp);\n\n    return metricEvent;\n}", "CodeBleu_score": 35.86307892772127}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String name = gauge.getName();\n    String value = gauge.getValue().toString();\n    String[] parts = value.split(Pattern.quote(\"|\"));\n    if (parts.length == 3) {\n        String currentOffsets = parts[0];\n        String dataTimestamp = parts[1];\n        String committedOffsets = parts[2];\n        metricEvent.addField(\"currentOffsets\", currentOffsets);\n        metricEvent.addField(\"dataTimestamp\", dataTimestamp);\n        metricEvent.addField(\"committedOffsets\", committedOffsets);\n    }\n    metricEvent.setTimestamp(timestamp);\n    return metricEvent;\n}", "CodeBleu_score": 35.04952605992187}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    // Extract values from the gauge\n    String[] values = gauge.getValue().toString().split(Pattern.quote(\"|\"));\n    String currentOffsets = values[0];\n    String dataTimestamp = values[1];\n    String committedOffsets = values[2];\n\n    // Check for changes in the Kafka lag metrics\n    if (kafkaLagTimes.containsKey(currentOffsets) && kafkaLagTimes.get(currentOffsets) == timestamp) {\n        return metricEvent;\n    }\n\n    // Update the kafkaLagTimes map\n    kafkaLagTimes.put(currentOffsets, timestamp);\n\n    // Set the event's timestamp\n    metricEvent.setTimestamp(timestamp);\n\n    // Update the event's fields with current offsets, data timestamp, and committed offsets\n    metricEvent.addField(\"currentOffsets\", currentOffsets);\n    metricEvent.addField(\"dataTimestamp\", dataTimestamp);\n    metricEvent.addField(\"committedOffsets\", committedOffsets);\n\n    return metricEvent;\n}", "CodeBleu_score": 34.13191264625734}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n    Properties properties = parameterTool.getProperties();\n    properties.setProperty(\"bootstrap.servers\", properties.getProperty(PropertiesConstants.KAFKA_BROKER));\n    properties.setProperty(\"group.id\", properties.getProperty(PropertiesConstants.KAFKA_GROUP_ID));\n    FlinkKafkaConsumer<MetricEvent> consumer;\n    if (time == null) {\n        consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), properties);\n    } else {\n        consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), properties);\n        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(properties);\n        List<PartitionInfo> partitionInfos = kafkaConsumer.partitionsFor(topic);\n        Map<KafkaTopicPartition, Long> specificStartOffsets = new HashMap<>();\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            TopicPartition topicPartition = new TopicPartition(topic, partitionInfo.partition());\n            List<OffsetAndTimestamp> offsets = kafkaConsumer.offsetsForTimes(Map.of(topicPartition, time));\n            if (offsets.size() > 0) {\n                Long offset = offsets.get(0).offset();\n                specificStartOffsets.put(new KafkaTopicPartition(topic, partitionInfo.partition()), offset);\n            }\n        }\n        consumer.setStartFromSpecificOffsets(specificStartOffsets);\n    }\n    DataStreamSource<MetricEvent> dataStreamSource = env.addSource(consumer);\n    return dataStreamSource;\n}", "CodeBleu_score": 52.87986247788308}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // get parameters\n    ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n    parameterTool.getRequired(PropertiesConstants.PROPERTIES_FILE_NAME);\n    Properties props = parameterTool.getProperties();\n    props.setProperty(\"bootstrap.servers\", KAFKA_HOST);\n    props.setProperty(\"group.id\", \"metric-group\");\n    // create kafka consumer\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricSchema(),\n            props);\n    // set consumer starting offset\n    if (time != null) {\n        Map<KafkaTopicPartition, Long> specificStartOffsets = new HashMap<>();\n        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(props);\n        List<PartitionInfo> partitionInfos = kafkaConsumer.partitionsFor(topic);\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            TopicPartition topicPartition = new TopicPartition(topic, partitionInfo.partition());\n            long timestamp = time;\n            Map<TopicPartition, OffsetAndTimestamp> offsets = kafkaConsumer.offsetsForTimes(Map.of(topicPartition, timestamp));\n            long offset = offsets.get(topicPartition).offset();\n            specificStartOffsets.put(new KafkaTopicPartition(topic, partitionInfo.partition()), offset);\n        }\n        consumer.setStartFromSpecificOffsets(specificStartOffsets);\n    }\n    // add source\n    DataStreamSource<MetricEvent> data = env.addSource(consumer);\n    return data;\n}", "CodeBleu_score": 60.75863296765311}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // \u83b7\u53d6\u5168\u5c40\u53c2\u6570\n    ParameterTool parameterTool = (ParameterTool) env.getConfig().getGlobalJobParameters();\n    parameterTool.getRequired(PropertiesConstants.PROPERTIES_FILE_NAME);\n    Properties properties = parameterTool.getProperties();\n    properties.put(ConsumerConfig.GROUP_ID_CONFIG, \"flink-group\");\n    properties.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, \"latest\");\n\n    // \u521b\u5efaFlinkKafkaConsumer\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricSchema(),\n            properties\n    );\n\n    // \u5982\u679c\u6307\u5b9a\u4e86\u65f6\u95f4\uff0c\u5219\u4ece\u6307\u5b9a\u65f6\u95f4\u5f00\u59cb\u6d88\u8d39\n    if (time != null) {\n        Map<KafkaTopicPartition, Long> timestampToSearch = new HashMap<>();\n        for (PartitionInfo partitionInfo : consumer.getPartitions()) {\n            timestampToSearch.put(new KafkaTopicPartition(topic, partitionInfo.partition()), time);\n        }\n\n        Map<TopicPartition, OffsetAndTimestamp> startOffsets = consumer.getKafkaConsumer().offsetsForTimes(timestampToSearch);\n        consumer.setStartFromSpecificOffsets(startOffsets);\n    }\n\n    // \u5c06\u6d88\u8d39\u8005\u6dfb\u52a0\u4e3a\u6570\u636e\u6e90\n    DataStreamSource<MetricEvent> dataStreamSource = env.addSource(consumer);\n    return dataStreamSource;\n}", "CodeBleu_score": 59.36966508426107}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String groupId = \"flink-group-\" + time;\n    props.setProperty(ConsumerConfig.GROUP_ID_CONFIG, groupId);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.get(PropertiesConstants.KAFKA_TOPIC));\n    Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        timestampToSearch.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), time);\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampToSearch);\n    Map<KafkaTopicPartition, Long> offsetByPartition = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        OffsetAndTimestamp offsetAndTimestamp = entry.getValue();\n        if (offsetAndTimestamp != null) {\n            offsetByPartition.put(new KafkaTopicPartition(topicPartition.topic(), topicPartition.partition()), offsetAndTimestamp.offset());\n        }\n    }\n    consumer.close();\n    return offsetByPartition;\n}", "CodeBleu_score": 54.611576352831946}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String topic = parameterTool.get(KAFKA_TOPIC);\n    String groupId = String.valueOf(time);\n    props.setProperty(GROUP_ID_CONFIG, groupId);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(topic);\n    Map<TopicPartition, Long> timestampMap = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        timestampMap.put(new TopicPartition(topic, partitionInfo.partition()), time);\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsetMap = consumer.offsetsForTimes(timestampMap);\n    Map<KafkaTopicPartition, Long> partitionOffsetMap = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsetMap.entrySet()) {\n        KafkaTopicPartition kafkaTopicPartition = new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition());\n        partitionOffsetMap.put(kafkaTopicPartition, entry.getValue().offset());\n    }\n    consumer.close();\n    return partitionOffsetMap;\n}", "CodeBleu_score": 48.5193920161715}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    props.setProperty(\"group.id\", \"flink-consumer-\" + time);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.get(PropertiesConstants.KAFKA_TOPIC));\n    Map<TopicPartition, Long> timestampToSearch = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        timestampToSearch.put(new TopicPartition(parameterTool.get(PropertiesConstants.KAFKA_TOPIC), partitionInfo.partition()), time);\n    }\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampToSearch);\n    consumer.close();\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        TopicPartition topicPartition = entry.getKey();\n        long offset = entry.getValue() != null ? entry.getValue().offset() : 0;\n        partitionOffsets.put(new KafkaTopicPartition(topicPartition.topic(), topicPartition.partition()), offset);\n    }\n    return partitionOffsets;\n}", "CodeBleu_score": 59.84788604743688}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    String topic = \"zhisheng\";\n    String brokers = \"localhost:9092\";\n    String metrics = \"metrics\";\n\n    Properties kafkaProps = new Properties();\n    kafkaProps.put(\"bootstrap.servers\", brokers);\n    kafkaProps.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    kafkaProps.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer producer = new KafkaProducer<String, String>(kafkaProps);\n\n    MetricEvent metric = new MetricEvent();\n    metric.setTimestamp(System.currentTimeMillis());\n    metric.setName(\"mem\");\n    Map<String, String> tags = new HashMap<>();\n    Map<String, Object> fields = new HashMap<>();\n\n    tags.put(\"cluster\", \"zhisheng\");\n    tags.put(\"host_ip\", \"127.0.0.1\");\n\n    fields.put(\"used_percent\", 90d);\n    fields.put(\"max\", 27244873728d);\n    fields.put(\"used\", 17244873728d);\n    fields.put(\"init\", 27244873728d);\n\n    metric.setTags(tags);\n    metric.setFields(fields);\n\n    ProducerRecord record = new ProducerRecord<String, String>(topic, null, null, GsonUtil.toJson(metric));\n    producer.send(record);\n    System.out.println(\"\u53d1\u9001\u6570\u636e: \" + GsonUtil.toJson(metric));\n    producer.flush();\n}", "CodeBleu_score": 73.1483369568944}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    String topic = \"zhisheng\";\n    String brokers = \"localhost:9092\";\n    Properties properties = new Properties();\n    properties.put(\"bootstrap.servers\", brokers);\n    properties.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    properties.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer<String, String> producer = new KafkaProducer<>(properties);\n    MetricEvent metric = new MetricEvent();\n    metric.setTimestamp(System.currentTimeMillis());\n    metric.setName(\"mem\");\n    Map<String, String> tags = new HashMap<>();\n    Map<String, Object> fields = new HashMap<>();\n    tags.put(\"cluster\", \"zhisheng\");\n    tags.put(\"host_ip\", \"127.0.0.1\");\n    fields.put(\"used_percent\", 90d);\n    fields.put(\"max\", 27244873728d);\n    fields.put(\"used\", 17244873728d);\n    fields.put(\"init\", 27244873728d);\n    metric.setTags(tags);\n    metric.setFields(fields);\n    ProducerRecord<String, String> record = new ProducerRecord<>(topic, null, null, GsonUtil.toJson(metric));\n    producer.send(record);\n    System.out.println(\"\u53d1\u9001\u6570\u636e: \" + GsonUtil.toJson(metric));\n    producer.flush();\n}", "CodeBleu_score": 73.27652081893379}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    String topic = \"metrics\";\n    String brokers = \"localhost:9092\";\n\n    Properties kafkaProps = new Properties();\n    kafkaProps.put(\"bootstrap.servers\", brokers);\n    kafkaProps.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    kafkaProps.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(kafkaProps);\n\n    MetricEvent metric = new MetricEvent();\n    metric.setTimestamp(System.currentTimeMillis());\n    metric.setName(\"cpu_usage\");\n    metric.setTags(new HashMap<>());\n    metric.getTags().put(\"host\", \"localhost\");\n    metric.setFields(new HashMap<>());\n    metric.getFields().put(\"value\", 90.0);\n\n    String data = GsonUtil.toJson(metric);\n    ProducerRecord<String, String> record = new ProducerRecord<>(topic, data);\n    producer.send(record);\n    System.out.println(\"Sent data: \" + data);\n    producer.flush();\n}", "CodeBleu_score": 48.74034233193205}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event == null) {\n        return;\n    }\n    if (event.getLevel().isInRange(levels)) {\n        if (!event.getLoggerName().contains(\"xxx\")) {\n            try {\n                String message = new String(this.getLayout().toByteArray(event));\n                LogEvent logEvent = new LogEvent(UUID.randomUUID().toString(),\n                        InetAddress.getLocalHost().getHostName(),\n                        event.getLoggerName(),\n                        event.getLevel().toString(),\n                        message,\n                        System.currentTimeMillis());\n                String logEventJson = JacksonUtil.toJsonString(logEvent);\n                ProducerRecord<String, String> record = new ProducerRecord<>(topic, logEventJson);\n                producer.send(record);\n            } catch (JsonProcessingException e) {\n                log.warn(\"Failed to convert log event to JSON: {}\", e.getMessage());\n            } catch (Exception e) {\n                log.warn(\"Failed to send log event to Kafka: {}\", e.getMessage());\n            }\n        }\n    }\n}", "CodeBleu_score": 46.633757174307064}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    // Get the event's level and logger name\n    String level = event.getLevel().name();\n    String loggerName = event.getLoggerName();\n\n    // Check if the event's level is in the specified list\n    if (levels.contains(level) && !loggerName.contains(\"xxx\")) {\n        // Get the event's message and timestamp\n        String message = event.getMessage().getFormattedMessage();\n        long timestamp = event.getTimeMillis();\n\n        // Create a LogEvent object with the message and timestamp\n        LogEvent logEvent = new LogEvent(message, timestamp);\n\n        // Convert the LogEvent object to a JSON string\n        String json = null;\n        try {\n            json = JacksonUtil.toJsonString(logEvent);\n        } catch (JsonProcessingException e) {\n            log.warn(\"Failed to convert LogEvent to JSON: {}\", ExceptionUtil.getExceptionMessageWithStackTrace(e));\n            return;\n        }\n\n        // Create a ProducerRecord with the JSON string as the value\n        ProducerRecord<String, String> record = new ProducerRecord<>(topic, json);\n\n        // Send the ProducerRecord to the Kafka topic\n        try {\n            producer.send(record);\n        } catch (Exception e) {\n            log.warn(\"Failed to send log event to Kafka: {}\", ExceptionUtil.getExceptionMessageWithStackTrace(e));\n        }\n    }\n}", "CodeBleu_score": 43.26681377457774}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isInRange(this.levelMin, this.levelMax)) {\n        try {\n            String loggerName = event.getLoggerName();\n            if (!loggerName.contains(\"xxx\")) {\n                String message = new String(this.getLayout().toByteArray(event));\n                LogEvent logEvent = LogEvent.builder()\n                        .id(UUID.randomUUID().toString())\n                        .level(event.getLevel().toString())\n                        .message(message)\n                        .timestamp(event.getTimeMillis())\n                        .threadName(event.getThreadName())\n                        .loggerName(loggerName)\n                        .build();\n                String logEventJson = JacksonUtil.toJsonString(logEvent);\n                ProducerRecord<String, String> record = new ProducerRecord<>(topic, logEventJson);\n                producer.send(record);\n            }\n        } catch (JsonProcessingException e) {\n            log.warn(\"Failed to process log event: {}\", event, e);\n        } catch (Exception e) {\n            log.warn(\"Failed to send log event: {}\", event, e);\n        }\n    }\n}", "CodeBleu_score": 41.42500050774144}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"measurement\", \"tag\", \"none\"}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 80.25274190600692}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"measurement\", \"tag\", \"none\"}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method %q\", method)\n}", "CodeBleu_score": 80.31973972678522}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"measurement\", \"tag\", \"none\"}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 80.25274190600692}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t} else {\n\t\t\treturn \"\", fmt.Errorf(\"metric has no '%s' tag\", k.RoutingTag)\n\t\t}\n\t} else if k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 77.68736011019767}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 77.88119308147466}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t\treturn \"\", fmt.Errorf(\"routing tag %q not found in metric %v\", k.RoutingTag, metric.Name())\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tuuid, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", fmt.Errorf(\"unable to generate a random UUID: %v\", err)\n\t\t}\n\t\treturn uuid.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 71.3883648592319}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tr, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"compiling regexp %q failed: %v\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = r\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.246181093627335}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegex := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(topicRegex)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"compiling topic regex [%s]: %w\", topicRegex, err)\n\t\t}\n\t\tregexps[i] = regex\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 43.0684375058339}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tregexps := make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegex := range k.TopicRegexps {\n\t\tregex, err := regexp.Compile(topicRegex)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"compiling regex %q failed: %v\", topicRegex, err)\n\t\t}\n\t\tregexps[i] = regex\n\t}\n\tk.topicRegexps = regexps\n\treturn nil\n}", "CodeBleu_score": 43.22345073935272}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.wg.Add(1)\n\tdefer h.wg.Done()\n\n\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.delivered {\n\t\ttrack.Session.MarkMessage(msg.msg, \"\")\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 61.029679496874664}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.wg.Add(1)\n\tdefer h.wg.Done()\n\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmessage, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tmessage.Delivered = true\n\th.session.MarkMessage(message.Message, \"\")\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 51.45182671246695}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.Lock()\n\tdefer h.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif msg.MarkedDelivered {\n\t\th.session.MarkMessage(msg.Message, \"\")\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.sem.Release(1)\n}", "CodeBleu_score": 49.41752845592843}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\th.processMessage(ctx, message)\n\t\t}\n\t}\n}", "CodeBleu_score": 39.92573164984845}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.handleMessage(message)\n\t\t}\n\t}\n}", "CodeBleu_score": 40.043604052131485}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\th.handleMessage(message)\n\t\t}\n\t}\n}", "CodeBleu_score": 40.043604052131485}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t  val max_length = 255\n  val valid_id_regex = \"^[a-zA-Z0-9._-]+$\"\n\n  if (logkafka_id.isEmpty) {\n    throw new Exception(\"Logkafka ID cannot be empty.\")\n  }\n\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new Exception(\"Logkafka ID cannot be '.' or '..'.\")\n  }\n\n  if (logkafka_id.length > max_length) {\n    throw new Exception(s\"Logkafka ID cannot exceed $max_length characters.\")\n  }\n\n  if (!logkafka_id.matches(valid_id_regex)) {\n    throw new Exception(\"Logkafka ID can only contain alphanumeric characters, '.', '_', and '-'.\")\n  }\n}", "CodeBleu_score": 25.83857828084646}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n  }\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n  }\n  if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters\")\n  }\n  if (!logkafka_id.matches(\"^[a-zA-Z0-9_.-]+$\")) {\n    throw new IllegalArgumentException(\"Logkafka ID can only contain alphanumeric characters, underscores, periods, and hyphens\")\n  }\n}", "CodeBleu_score": 21.492774701811097}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  val max_length = 255\n  val regex = \"\"\"^[a-zA-Z0-9_.-]*$\"\"\"\n\n  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty.\")\n  }\n\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'.\")\n  }\n\n  if (logkafka_id.length > max_length) {\n    throw new IllegalArgumentException(s\"Logkafka ID cannot exceed $max_length characters.\")\n  }\n\n  if (!logkafka_id.matches(regex)) {\n    throw new IllegalArgumentException(\"Logkafka ID can only contain alphanumeric characters, underscores, periods, and hyphens.\")\n  }\n}", "CodeBleu_score": 25.14025262319819}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case akka.actor.Status.Failure(e) =>\n        logger.error(s\"Failed to process message $msg\", e)\n        ApiError.internalError(s\"Failed to process message $msg\", e)\n      case akka.actor.Status.Success(output) =>\n        try {\n          output match {\n            case ApiError.error(e) => e\n            case output => fn(output)\n          }\n        } catch {\n          case e: Exception =>\n            logger.error(s\"Failed to process message $msg\", e)\n            ApiError.internalError(s\"Failed to process message $msg\", e)\n        }\n    }\n  }", "CodeBleu_score": 42.35893351923505}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case a: ApiError => -\\/(a)\n      case output: Output =>\n        try {\n          val transformed = fn(output)\n          \\/-(transformed)\n        } catch {\n          case e: Exception =>\n            logger.error(s\"Failed to transform output $output\", e)\n            -\\/(ApiError(s\"Failed to transform output $output\", e.getMessage))\n        }\n    }\n  }", "CodeBleu_score": 32.06661195151531}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future: Future[ApiError \\/ Output] = (kafkaManagerActor ? msg).mapTo[ApiError \\/ Output]\n    future.map {\n      case -\\/(e) => -\\/(e)\n      case \\/-(output) =>\n        try {\n          \\/-(fn(output))\n        } catch {\n          case e: Exception =>\n            logger.error(s\"Exception while processing output: ${e.getMessage}\")\n            -\\/(ApiError(e.getMessage))\n        }\n    }\n  }", "CodeBleu_score": 25.99213735078373}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val response = kafkaManagerActor ? msg\n    response.map {\n      case output: Output => fn(output)\n      case error: ActorErrorResponse => Left(ApiError(error.toString))\n      case _ => Left(ApiError(\"Unexpected response from Kafka Manager actor\"))\n    }.recover {\n      case t: Throwable => Left(ApiError(t.getMessage))\n    }\n  }", "CodeBleu_score": 45.839708796157836}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = kafkaManagerActor ? msg\n    future.map {\n      case m: ActorErrorResponse =>\n        Left(ApiError(m.errorMessage))\n      case m: Output =>\n        fn(m)\n    }.recover {\n      case t: Throwable =>\n        Left(ApiError(t.getMessage))\n    }\n  }", "CodeBleu_score": 46.668532918890335}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    kafkaManagerActor ? msg.mapTo[Output] map {\n      case response: ActorErrorResponse =>\n        Left(ApiError(response.errorCode, response.errorMessage))\n      case output =>\n        fn(output)\n    } recover {\n      case throwable: Throwable =>\n        Left(ApiError(throwable))\n    }\n  }", "CodeBleu_score": 39.947141807745034}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val request = KMClusterCommandRequest(clusterName, PreferredLeaderElectionCommand(topics))\n    (kafkaManager ? request).map {\n      case Success(ClusterCommandResult(_, _, _, _, _, _, _, _, _, _, _, _)) =>\n        Right(ClusterContext(clusterName, topics))\n      case Failure(e) => Left(ApiError(s\"Failed to run preferred leader election for topics $topics in cluster $clusterName: ${e.getMessage}\"))\n    }\n  }", "CodeBleu_score": 21.752075548824614}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val commandRequest = KMClusterCommandRequest(clusterName, PreferredLeaderElectionCommand(topics))\n    val commandResult = KafkaManager ! commandRequest\n    commandResult.map {\n      case Success(clusterContext) => Right(clusterContext)\n      case Failure(error) => Left(ApiError(error.getMessage))\n    }\n  }", "CodeBleu_score": 24.653437757034613}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    (kafkaManager ? command).mapTo[ApiError \\/ ClusterContext]\n  }", "CodeBleu_score": 20.67165610091638}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicsForCluster(clusterName).map { topicList =>\n    runPreferredLeaderElection(clusterName, topicList)\n  }.recover {\n    case e: Exception =>\n      logger.error(s\"Error while running preferred leader election for cluster $clusterName\", e)\n      e\n  }\n}", "CodeBleu_score": 25.38772328350839}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t    getTopics(clusterName).flatMap { topics =>\n        runPreferredLeaderElection(clusterName, topics)\n    }\n}", "CodeBleu_score": 12.352251518385593}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  val topicList: Future[Set[String]] = getTopicList(clusterName)\n  topicList.map { topics =>\n    runPreferredLeaderElectionForTopics(clusterName, topics)\n  }\n}", "CodeBleu_score": 17.930086163107685}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = context.dispatcher\n    val future = KMClusterCommandRequest(clusterName, assignments).execute()\n    val result = Await.result(future, 30 seconds)\n    val errors = result.filter(_.isFailure).map(_.failed.get).toList\n    if (errors.isEmpty) {\n        Success(true)\n    } else {\n        Failure(errors)\n    }\n}", "CodeBleu_score": 23.465842115394818}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = context.dispatcher\n    val result = KMClusterCommandRequest(clusterName, ManualPartitionAssignments(assignments)).sendToKM()\n    val errors = result.collect {\n        case ManualPartitionAssignmentsError(_, error) => error\n    }\n    if (errors.isEmpty) {\n        Success(())\n    } else {\n        Failure(errors)\n    }\n}", "CodeBleu_score": 26.52758259558331}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t    implicit val ec = system.dispatcher\n    val cmd = KMClusterCommandRequest(clusterName, KMClusterCommand.ManualPartitionAssignments(assignments))\n    val result = KafkaManager ! cmd\n    val errors = Await.result(result, timeout.duration).errors\n    if (errors.isEmpty) {\n      Success(s\"Successfully assigned partitions for cluster $clusterName\")\n    } else {\n      Failure(errors.mkString(\", \"))\n    }\n  }", "CodeBleu_score": 24.86808361158409}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, \"0\");\n    DescribeConfigsResult describeConfigs = admin.describeConfigs(Collections.singleton(configResource));\n    Map<ConfigResource, Config> configs = describeConfigs.all().get();\n    Config config = configs.get(configResource);\n    if (config == null) {\n        throw new ConnectException(\"Could not retrieve the configuration for broker 0\");\n    }\n    return config;\n}", "CodeBleu_score": 37.81500235786934}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Duration timeout = Duration.ofSeconds(30);\n\n    DescribeClusterResult describeClusterResult = admin.describeCluster();\n    Collection<Node> nodes = describeClusterResult.nodes().get(timeout.toMillis(), TimeUnit.MILLISECONDS);\n\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"No Kafka nodes available\");\n    }\n\n    Node node = nodes.iterator().next();\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n\n    Config config = admin.describeConfigs(Collections.singleton(configResource)).get(timeout.toMillis(), TimeUnit.MILLISECONDS).get(configResource);\n\n    if (config == null) {\n        throw new ConnectException(\"No configuration received\");\n    }\n\n    return config;\n}", "CodeBleu_score": 59.89904164272104}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Duration timeout = Duration.of(10, ChronoUnit.SECONDS);\n    DescribeClusterResult describeClusterResult = admin.describeCluster(timeout);\n    Collection<Node> nodes = describeClusterResult.nodes().get(timeout);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"No nodes are available within the specified timeout\");\n    }\n    String nodeId = nodes.iterator().next().idString();\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodeId);\n    Config config = admin.describeConfigs(Collections.singleton(configResource)).get(timeout).get(configResource);\n    if (config == null) {\n        throw new ConnectException(\"No configurations received for the specified node\");\n    }\n    return config;\n}", "CodeBleu_score": 59.94392107680277}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t    return (s, o) -> {\n        if (o instanceof HistorizedRelationalDatabaseConnectorConfig && ((HistorizedRelationalDatabaseConnectorConfig) o).schemaHistory() instanceof KafkaSchemaHistory) {\n            return validator.isValid(s, o);\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 26.541298655083484}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (config, name, value) -> {\n        final SchemaHistory schemaHistory = config.getString(HistorizedRelationalDatabaseConnectorConfig.SCHEMA_HISTORY.name()).equals(\"KafkaSchemaHistory\") ? validator : null;\n        return schemaHistory != null ? schemaHistory.validate(config, name, value) : 0;\n    };\n}", "CodeBleu_score": 51.93611219124907}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (s, o) -> {\n        if (o instanceof HistorizedRelationalDatabaseConnectorConfig) {\n            final HistorizedRelationalDatabaseConnectorConfig config = (HistorizedRelationalDatabaseConnectorConfig) o;\n            if (config.getSchemaHistory() instanceof KafkaSchemaHistory) {\n                return validator.isValid(s, config);\n            }\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 29.945431164363235}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    Version version = new Version();\n    String versionString = version.getVersion();\n    Pattern pattern = Pattern.compile(\"(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)\");\n    Matcher matcher = pattern.matcher(versionString);\n\n    if (matcher.find()) {\n        int majorVersion = Integer.parseInt(matcher.group(1));\n        int minorVersion = Integer.parseInt(matcher.group(2));\n        int patchVersion = Integer.parseInt(matcher.group(3));\n\n        if (majorVersion == 2 && minorVersion >= 8) {\n            Boolean topicCreationEnabled = (Boolean) config.getOrDefault(\"topic.creation.enable\", true);\n            return topicCreationEnabled;\n        }\n    }\n\n    return true;\n}", "CodeBleu_score": 38.2328432306081}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    Version version = Version.parse(AppInfoParser.getVersion());\n    if (version.feature() >= 3) {\n        return Boolean.parseBoolean(config.getOrDefault(\"topic.creation.enable\", \"true\").toString());\n    }\n    return true;\n}", "CodeBleu_score": 25.422212199004058}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (config.get(\"topic.creation.enable\") == null) {\n        return true;\n    }\n    String version = (String) config.get(\"topic.creation.enable\");\n    if (version.isEmpty()) {\n        return true;\n    }\n    try {\n        Version currentVersion = Version.parse(version);\n        Version minVersion = Version.parse(\"2.7.0\");\n        return currentVersion.compareTo(minVersion) >= 0;\n    } catch (Exception e) {\n        return true;\n    }\n}", "CodeBleu_score": 51.55625322300399}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    final String clientId = config.get(CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new DebeziumException(\"No client ID provided\");\n    }\n    final Map<String, Object> adminProps = new HashMap<>(config);\n    adminProps.put(DistributedConfig.CLIENT_ID_CONFIG, clientId);\n    final SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n    final Converter offsetStoreConverter = new JsonConverter();\n    offsetStoreConverter.configure(Collections.singletonMap(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, \"false\"));\n    return new KafkaOffsetBackingStore(admin, clientId, offsetStoreConverter);\n}", "CodeBleu_score": 40.41217794017975}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    final String clientId = config.get(CLIENT_ID_CONFIG);\n    final Map<String, String> adminProps = new HashMap<>(config);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_FILE_FILENAME_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_PARTITIONS_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_KEY_CONVERTER_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_VALUE_CONVERTER_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_KEY_CONVERTER_SCHEMAS_ENABLE_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_VALUE_CONVERTER_SCHEMAS_ENABLE_CONFIG);\n    adminProps.remove(DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG);\n    final Set<String> mandatoryOptions = Stream.of(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, DistributedConfig.OFFSET_STORAGE_PARTITIONS_CONFIG, DistributedConfig.OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG).collect(Collectors.toSet());\n    final Set<String> missingOptions = mandatoryOptions.stream().filter((  option) -> !config.containsKey(option)).collect(Collectors.toSet());\n    if (!missingOptions.isEmpty()) {\n        throw new DebeziumException(String.format(\"The following configuration options are mandatory when using the Kafka offset store: %s\", missingOptions));\n    }\n    final SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n    return new KafkaOffsetBackingStore(admin, clientId, offsetStoreConverter(config));\n}", "CodeBleu_score": 43.83853671470758}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    final String clientId = config.get(CLIENT_ID_CONFIG);\n    if (clientId == null) {\n        throw new DebeziumException(\"No client ID provided\");\n    }\n    Map<String, Object> adminProps = new HashMap<>();\n    adminProps.put(DistributedConfig.CLIENT_ID_CONFIG, clientId);\n    adminProps.put(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG, config.get(DistributedConfig.BOOTSTRAP_SERVERS_CONFIG));\n    adminProps.put(DistributedConfig.GROUP_ID_CONFIG, config.get(DistributedConfig.GROUP_ID_CONFIG));\n    adminProps.put(DistributedConfig.GROUP_INSTANCE_ID_CONFIG, config.get(DistributedConfig.GROUP_INSTANCE_ID_CONFIG));\n    adminProps.put(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.STATUS_STORAGE_TOPIC_CONFIG));\n    adminProps.put(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.OFFSET_STORAGE_TOPIC_CONFIG));\n    adminProps.put(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG, config.get(DistributedConfig.CONFIG_STORAGE_TOPIC_CONFIG));\n    adminProps.put(DistributedConfig.KEY_CONVERTER_CLASS_CONFIG, config.get(DistributedConfig.KEY_CONVERTER_CLASS_CONFIG));\n    adminProps.put(DistributedConfig.VALUE_CONVERTER_CLASS_CONFIG, config.get(DistributedConfig.VALUE_CONVERTER_CLASS_CONFIG));\n    SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n    return new KafkaOffsetBackingStore(admin, clientId, offsetStoreConverter(config));\n}", "CodeBleu_score": 40.15689918433666}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IllegalArgumentException(\"Key must be a JSON object\");\n    }\n    JsonNode payload = node.get(Envelope.FieldName.PAYLOAD);\n    if (payload != null) {\n        node = payload;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return objectReader.readValue(node, keyType);\n        } else {\n            return objectReader.readValue(node.get(fieldName), keyType);\n        }\n    } else {\n        return null;\n    }\n}", "CodeBleu_score": 45.79979028825928}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IllegalArgumentException(\"Expected JSON object, got \" + node);\n    }\n    JsonNode payload = node.get(\"payload\");\n    if (payload != null) {\n        node = payload;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return objectMapper.treeToValue(node, compositeKeyType);\n        }\n        return objectMapper.treeToValue(node.get(fieldName), keyType);\n    }\n    return null;\n}", "CodeBleu_score": 44.57094832827342}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Key must be a JSON object\");\n    }\n    JsonNode payload = node.get(\"payload\");\n    if (payload != null) {\n        node = payload;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (fieldNames.hasNext()) {\n        String fieldName = fieldNames.next();\n        if (fieldNames.hasNext()) {\n            return objectMapper.treeToValue(node, keyType);\n        } else {\n            return objectMapper.treeToValue(node.get(fieldName), keyType);\n        }\n    } else {\n        return null;\n    }\n}", "CodeBleu_score": 42.46547430467758}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id);\n    if (prefix != null) {\n        topicName = prefix + delimiter + topicName;\n    }\n    StringBuilder sanitizedTopicName = new StringBuilder();\n    boolean changed = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedTopicName.append(c);\n        } else {\n            sanitizedTopicName.append(replacementCharacter);\n            changed = true;\n        }\n    }\n    if (changed) {\n        LOGGER.warn(\"Sanitized topic name '{}' to '{}'\", topicName, sanitizedTopicName.toString());\n    }\n    return sanitizedTopicName.toString();\n}", "CodeBleu_score": 55.06740521966823}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id);\n    if (prefix != null) {\n        topicName = prefix + delimiter + topicName;\n    }\n    StringBuilder sanitizedTopicName = new StringBuilder(topicName.length());\n    boolean changed = false;\n    for (int i = 0; i != topicName.length(); ++i) {\n        char c = topicName.charAt(i);\n        if (isValidTopicNameCharacter(c)) {\n            sanitizedTopicName.append(c);\n        } else {\n            sanitizedTopicName.append(replacementCharacter);\n            changed = true;\n        }\n    }\n    if (changed) {\n        LOGGER.warn(\"Topic name '{}' contains invalid characters; these have been replaced with '{}'\", topicName, sanitizedTopicName);\n    }\n    return sanitizedTopicName.toString();\n}", "CodeBleu_score": 60.100178410789695}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id);\n    if (prefix != null) {\n        topicName = prefix + delimiter + topicName;\n    }\n    StringBuilder sanitizedName = new StringBuilder();\n    boolean changed = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        char c = topicName.charAt(i);\n        if (! isValidTopicNameCharacter(c)) {\n            sanitizedName.append(replacementCharacter);\n            changed = true;\n        } else {\n            sanitizedName.append(c);\n        }\n    }\n    if (changed) {\n        LOGGER.warn(\"Sanitizing topic name '{}' to '{}'\", topicName, sanitizedName);\n    }\n    return sanitizedName.toString();\n}", "CodeBleu_score": 53.26563065500797}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = new AtomicReference<>();\n        this.retryCount = new AtomicInteger(0);\n        this.maxRetries = connectorConfig.getMaxRetries();\n        if (replacedErrorHandler != null) {\n            this.retryCount.set(replacedErrorHandler.getRetryCount());\n        }\n    }", "CodeBleu_score": 63.76212963722403}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = new AtomicReference<>();\n        this.maxRetries = connectorConfig.getMaxRetries();\n        if (replacedErrorHandler != null) {\n            this.retryCount = replacedErrorHandler.retryCount;\n        }\n    }", "CodeBleu_score": 64.15168235115011}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = new AtomicReference<>();\n        this.maxRetries = connectorConfig.getInt(CommonConnectorConfig.MAX_RETRIES);\n        if (replacedErrorHandler != null) {\n            this.retryCount = replacedErrorHandler.retryCount;\n        }\n    }", "CodeBleu_score": 62.23185235878892}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t  final Map<String, ConfigValue> values = configuration.validate(fields);\n  for (Map.Entry<String, ConfigValue> entry : values.entrySet()) {\n    if (entry.getValue().errorMessages() != null && !entry.getValue().errorMessages().isEmpty()) {\n      throw new ConfigException(entry.getValue().name(), entry.getValue().errorMessages().get(0));\n    }\n  }\n}", "CodeBleu_score": 54.42693925363788}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t  final Map<String, ConfigValue> config = configuration.asMap();\n  for (Field field : fields) {\n    final ConfigValue value = config.get(field.name());\n    if (value == null) {\n      continue;\n    }\n    if (field.validate(value).stream().filter(ConfigValue::errorMessages).findFirst().isPresent()) {\n      throw new ConfigException(field.name(), value, field.validate(value).stream().filter(ConfigValue::errorMessages).findFirst().get().errorMessages().get(0));\n    }\n  }\n}", "CodeBleu_score": 52.74714091789503}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t  for (ConfigValue value : configuration.validate(fields)) {\n    if (value.errorMessages() != null && !value.errorMessages().isEmpty()) {\n      throw new ConfigException(value.name(), value.errorMessages().get(0));\n    }\n  }\n}", "CodeBleu_score": 33.290261783464594}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t        if (oldSchema.type() == Schema.Type.STRUCT) {\n            SchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n            for (Field field : oldSchema.fields()) {\n                String newFieldName = fieldName + (fieldName.isEmpty() ? \"\" : \".\") + field.name();\n                Schema newFieldSchema = buildNewSchema(newFieldName, field.schema(), headerToProcess, nestedFields, level + 1);\n                newSchemaBuilder.field(field.name(), newFieldSchema);\n            }\n            if (headerToProcess != null) {\n                for (Map.Entry<String, Header> entry : headerToProcess.entrySet()) {\n                    Header header = entry.getValue();\n                    String headerName = entry.getKey();\n                    if (nestedFields.contains(headerName)) {\n                        String[] nestedFieldNames = headerName.split(\"\\\\.\");\n                        Schema nestedFieldSchema = newSchemaBuilder.field(nestedFieldNames[0]).schema();\n                        for (int i = 1; i < nestedFieldNames.length - 1; i++) {\n                            nestedFieldSchema = nestedFieldSchema.field(nestedFieldNames[i]).schema();\n                        }\n                        newSchemaBuilder.field(nestedFieldNames[nestedFieldNames.length - 1], nestedFieldSchema);\n                    } else {\n                        newSchemaBuilder.field(headerName, SchemaUtil.headerSchema(header));\n                    }\n                }\n            }\n            return newSchemaBuilder.build();\n        } else {\n            return oldSchema;\n        }\n    }", "CodeBleu_score": 38.95818119508901}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t        if (oldSchema.type() == Schema.Type.STRUCT) {\n            SchemaBuilder builder = SchemaBuilder.struct();\n            for (Field field : oldSchema.fields()) {\n                String newFieldName = field.name();\n                if (nestedFields != null && !nestedFields.isEmpty()) {\n                    newFieldName = fieldName + \".\" + newFieldName;\n                }\n                Schema newSchema = buildNewSchema(newFieldName, field.schema(), headerToProcess, nestedFields, level + 1);\n                builder.field(newFieldName, newSchema);\n            }\n            for (Map.Entry<String, Header> entry : headerToProcess.entrySet()) {\n                String headerName = entry.getKey();\n                Header header = entry.getValue();\n                Schema headerSchema = SchemaUtil.headerSchema(header.schema());\n                builder.field(headerName, headerSchema);\n            }\n            return builder.build();\n        } else {\n            return oldSchema;\n        }\n    }", "CodeBleu_score": 35.38985833082853}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.type() == Schema.Type.STRUCT) {\n        SchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n        for (Field field : oldSchema.fields()) {\n            String nestedFieldName = field.name();\n            Schema nestedFieldSchema = field.schema();\n            String fullFieldName = fieldName + \".\" + nestedFieldName;\n            if (nestedFields.contains(fullFieldName)) {\n                Header header = headerToProcess.get(fullFieldName);\n                if (header != null) {\n                    log.debug(\"Adding field {} to schema\", fullFieldName);\n                    newSchemaBuilder.field(nestedFieldName, Schema.STRING_SCHEMA);\n                } else {\n                    log.debug(\"Copying field {} to schema\", fullFieldName);\n                    newSchemaBuilder.field(nestedFieldName, buildNewSchema(fullFieldName, nestedFieldSchema, headerToProcess, nestedFields, level + 1));\n                }\n            }\n        }\n        return newSchemaBuilder.build();\n    } else {\n        return oldSchema;\n    }\n}", "CodeBleu_score": 38.82649077715593}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) != null && source.schema().field(SNAPSHOT_KEY).schema().name().equals(LOGICAL_NAME)) {\n        String snapshotString = source.getString(SNAPSHOT_KEY);\n        if (snapshotString != null) {\n            snapshotString = snapshotString.toUpperCase();\n            if (SnapshotRecord.COMPLETE.toString().equals(snapshotString)) {\n                return SnapshotRecord.COMPLETE;\n            } else if (SnapshotRecord.INCREMENTAL.toString().equals(snapshotString)) {\n                return SnapshotRecord.INCREMENTAL;\n            }\n        }\n    }\n    return null;\n}", "CodeBleu_score": 55.42312307355457}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SnapshotRecord.SNAPSHOT_KEY) != null && source.schema().field(SnapshotRecord.SNAPSHOT_KEY).schema().name().equals(SnapshotRecord.SNAPSHOT_KEY)) {\n        String snapshotString = source.getString(SnapshotRecord.SNAPSHOT_KEY);\n        if (snapshotString != null) {\n            snapshotString = snapshotString.toUpperCase();\n            if (SnapshotRecord.Snapshot.contains(snapshotString)) {\n                return new SnapshotRecord(SnapshotRecord.Snapshot.valueOf(snapshotString));\n            }\n        }\n    }\n    return null;\n}", "CodeBleu_score": 60.603313393684346}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SnapshotRecord.SNAPSHOT_KEY) == null) {\n        return null;\n    } \n    String snapshotString = ((String) source.get(SnapshotRecord.SNAPSHOT_KEY)).toUpperCase();\n    for (SnapshotRecord snapshotRecord : SnapshotRecord.values()) {\n        if (snapshotRecord.toString().equals(snapshotString)) {\n            return snapshotRecord;\n        } \n    }\n    return null;\n}", "CodeBleu_score": 51.02571598141887}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = new String[] { parts[0], parts[1] };\n        }\n        String[] subParts = parts[0].split(\"-\");\n        return Optional.of(Float.parseFloat(subParts[0]));\n    } catch (NumberFormatException e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 63.809962099046245}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    String[] parts = version.split(\"\\\\.\");\n    if (parts.length > 2) {\n        parts = new String[] { parts[0], parts[1] };\n    }\n    String versionString = parts[0];\n    if (parts.length > 1) {\n        versionString += \".\" + parts[1];\n    }\n    try {\n        return Optional.of(Float.parseFloat(versionString));\n    } catch (NumberFormatException e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 61.02189101587088}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOf(parts, 2);\n        }\n        String versionPart = parts[0];\n        if (versionPart.contains(\"-\")) {\n            versionPart = versionPart.split(\"-\")[0];\n        }\n        return Optional.of(Float.parseFloat(versionPart));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 65.15338342635027}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return validateAndGetAccessContext(clusterName, connectName, exchange)\n        .flatMap(context ->\n            kafkaConnectService.createConnector(context, connector)\n                .flatMap(created -> auditConnector(context, created, exchange)\n                    .thenReturn(created))\n        )\n        .map(ResponseEntity::ok);\n}", "CodeBleu_score": 31.525030470078164}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return connector\n        .map(newConnector -> {\n            var context = new AccessContext(\n                newConnector.getConnectorClass(),\n                Set.of(ConnectAction.CREATE)\n            );\n            return new AccessContext(\n                newConnector.getConnectorClass(),\n                Set.of(ConnectAction.CREATE)\n            );\n        })\n        .filter(accessContext -> accessService.validateAccess(accessContext, exchange))\n        .flatMap(accessContext -> kafkaConnectService.createConnector(clusterName, connectName, accessContext, connector)\n            .doOnNext(createdConnector -> auditService.audit(exchange, accessContext, createdConnector))\n            .map(ResponseEntity::ok));\n}", "CodeBleu_score": 38.380506651605984}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return connector\n        .map(newConnector -> {\n            var accessContext = new AccessContext(\n                newConnector.getName(),\n                clusterName,\n                connectName,\n                Set.of(ConnectAction.CREATE)\n            );\n            return accessContext;\n        })\n        .filter(accessContext -> accessControlService.validateAccess(accessContext, exchange))\n        .flatMap(accessContext -> kafkaConnectService.createConnector(clusterName, connectName, newConnector))\n        .map(ResponseEntity::ok)\n        .doOnNext(response -> auditService.audit(accessContext, exchange, response));\n}", "CodeBleu_score": 39.10099634961046}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    var accessContext = new AccessContext(\n        clusterName,\n        connectName,\n        Set.of(ConnectAction.DELETE)\n    );\n    return accessControlService.validateAccess(accessContext, exchange)\n        .flatMap(allowed -> {\n            if (!allowed) {\n                return Mono.error(new AccessDeniedException(\"DELETE\", ConnectAction.DELETE));\n            }\n            return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n                .then(Mono.just(ResponseEntity.ok().build()));\n        })\n        .doOnSuccess(r -> auditService.auditDeleteConnector(clusterName, connectName, connectorName));\n}", "CodeBleu_score": 32.43169012787487}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    var context = AccessContext.of(clusterName, connectName, Set.of(ConnectAction.DELETE));\n    return kafkaConnectService.validateAccess(context)\n        .then(kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n        .map(ResponseEntity::ok)\n        .doOnSuccess(r -> auditService.audit(exchange, \"delete connector\", clusterName, connectName, connectorName));\n}", "CodeBleu_score": 35.155113512694186}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext context = AccessContext.forClusterAndConnect(clusterName, connectName)\n        .withAction(ConnectAction.DELETE)\n        .withResourceName(connectorName);\n    return validateAccess(context, exchange)\n        .flatMap(isValid -> {\n            if (isValid) {\n                return kafkaConnectService.deleteConnector(clusterName, connectName, connectorName)\n                    .then(Mono.just(ResponseEntity.ok().build()));\n            } else {\n                return Mono.just(ResponseEntity.status(FORBIDDEN).build());\n            }\n        })\n        .doOnSuccess(r -> auditService.audit(exchange, r));\n}", "CodeBleu_score": 37.91808671771532}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t        var context = new AccessContext(clusterName, connectName, Set.of(ConnectAction.WRITE),\n                \"updateConnectorState\", Map.of(\"connectorName\", connectorName, \"action\", action));\n        return validateAccess(context, exchange)\n                .flatMap(r -> {\n                    switch (action) {\n                        case PAUSE:\n                            return kafkaConnectService.pauseConnector(clusterName, connectName, connectorName);\n                        case RESUME:\n                            return kafkaConnectService.resumeConnector(clusterName, connectName, connectorName);\n                        case RESTART:\n                            return kafkaConnectService.restartConnector(clusterName, connectName, connectorName);\n                        case RESTART_ALL_TASKS:\n                            return kafkaConnectService.restartAllConnectorTasks(clusterName, connectName, connectorName);\n                        case RESTART_FAILED_TASKS:\n                            return kafkaConnectService.restartFailedConnectorTasks(clusterName, connectName, connectorName);\n                        default:\n                            return Mono.error(new IllegalArgumentException(\"Unknown action: \" + action));\n                    }\n                })\n                .map(ResponseEntity::ok)\n                .doOnEach(auditOnNext(r -> log.info(\"Connector {} state updated to {}\", connectorName, action)))\n                .doOnEach(auditOnError(e -> log.error(\"Connector {} state update failed\", connectorName, e)));\n    }", "CodeBleu_score": 29.504836971774616}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n    var accessContext = new AccessContext(clusterName, connectName,\n            Set.of(ConnectAction.valueOf(action.name())),\n            \"updateConnectorState\",\n            Map.of(\"connectorName\", connectorName, \"action\", action.name()));\n\n    return validateAccess(accessContext, exchange)\n            .then(kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action))\n            .then(Mono.just(ResponseEntity.ok().build()))\n            .doOnEach(auditUtil.onResponse(exchange, accessContext));\n}", "CodeBleu_score": 31.26915663225275}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    AccessContext context = new AccessContext(clusterName, connectName,\n            Set.of(ConnectAction.READ, ConnectAction.WRITE), \"updateConnectorState\",\n            Map.of(\"connectorName\", connectorName, \"action\", action.name()));\n    return validateAccess(context, exchange)\n            .then(kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action))\n            .map(ResponseEntity::ok)\n            .doOnEach(signal -> auditEvent(exchange, signal, context));\n}", "CodeBleu_score": 33.02188186831479}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t  @Override\n  public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n      String clusterName,\n      String connectName,\n      String pluginName,\n      Mono<Map<String, Object>> requestBody,\n      ServerWebExchange exchange\n  ) {\n    return requestBody\n        .flatMap(body -> kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, body))\n        .map(ResponseEntity::ok);\n  }\n}", "CodeBleu_score": 61.5806030606065}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t  /**\n   * The validateConnectorPluginConfig function validates the configuration of a connector plugin in a specified Kafka Connect cluster.\nIt calls the kafkaConnectService to perform the validation using the cluster name, connect name, plugin name, and request body.\nThe function then maps the validation result to an HTTP response entity with a status of OK.\n   */\n  public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(String clusterName, String connectorName, String pluginName, Map<String, String> requestBody) {\n    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectorName, pluginName, requestBody)\n        .map(ResponseEntity::ok);\n  }\n}", "CodeBleu_score": 53.8365141022608}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t\n    private final KafkaConnectService kafkaConnectService;\n\n    public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig(\n        String clusterName, String connectName, String pluginName, @Valid Mono<Map<String, Object>> requestBody,\n        ServerWebExchange exchange) {\n        return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n            .map(ResponseEntity::ok);\n    }\n\n\n    /**\n     * The getConnectors function retrieves a list of connectors from a specified Kafka Connect cluster.", "CodeBleu_score": 70.86143567228352}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n        .initializers(new DynamicConfigOperations())\n        .run(args);\n}", "CodeBleu_score": 41.97670580114618}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n        .initializers(new DynamicConfigOperations())\n        .run(args);\n}", "CodeBleu_score": 41.97670580114618}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n        .initializers(new DynamicConfigOperations())\n        .run(args);\n}", "CodeBleu_score": 41.97670580114618}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return connector -> true;\n    }\n    return connector -> Stream.of(connector.getName(), connector.getType(), connector.getConnect(), connector.getTopics())\n        .anyMatch(s -> StringUtils.containsIgnoreCase(s, search));\n}", "CodeBleu_score": 62.54902903973283}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    return search == null ? (c) -> true : (c) -> Stream.of(c.getName(), c.getConnect(), c.getType(), c.getState().name(), c.getConfig())\n        .anyMatch(s -> StringUtils.containsIgnoreCase(s, search));\n}", "CodeBleu_score": 43.207315454147874}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    return Optional.ofNullable(search)\n            .map(term -> (Predicate<FullConnectorInfoDTO>) connector -> connector.getConnector()\n                    .getConfig()\n                    .values()\n                    .stream()\n                    .anyMatch(s -> StringUtils.containsIgnoreCase(s, term)))\n            .orElse(connector -> true);\n}", "CodeBleu_score": 38.90582064665411}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap != null) {\n      for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n        String key = StringUtils.hasText(prefix) ? prefix + \".\" + entry.getKey() : entry.getKey();\n        if (entry.getValue() instanceof Map) {\n          flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) entry.getValue()));\n        } else {\n          flattenedMap.put(key, entry.getValue());\n        }\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 46.7074326580646}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return Map.of();\n    }\n    Map<String, Object> flattened = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String newKey = StringUtils.hasText(prefix)\n          ? prefix + \".\" + entry.getKey()\n          : entry.getKey();\n      if (entry.getValue() instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) entry.getValue()));\n      } else {\n        flattened.put(newKey, entry.getValue());\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 44.914248687756455}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return Map.of();\n    }\n    Map<String, Object> flattened = new HashMap<>();\n    propertiesMap.forEach((key, value) -> {\n      String newKey = StringUtils.hasText(prefix) ? prefix + \".\" + key : key;\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattened.put(newKey, value);\n      }\n    });\n    return flattened;\n  }", "CodeBleu_score": 57.12821154638}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    ConfigDef configDef = new ConfigDef();\n    SslConfigs.addClientSslSupport(configDef);\n    SaslConfigs.addClientMechanismSupport(configDef);\n    return configDef.configKeys().stream()\n        .filter(key -> configDef.configKeys().get(key).type() == ConfigDef.Type.PASSWORD)\n        .collect(Collectors.toSet());\n  }", "CodeBleu_score": 69.66676982144351}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    final ConfigDef configDef = new ConfigDef();\n    SslConfigs.addClientConfig(configDef, true);\n    SaslConfigs.addClientConfig(configDef, true);\n\n    return configDef.configKeys().stream()\n            .filter(k -> configDef.get(k).type() == ConfigDef.Type.PASSWORD)\n            .collect(Collectors.toSet());\n}", "CodeBleu_score": 69.68485244707625}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    ConfigDef configDef = new ConfigDef();\n    SslConfigs.addClientConfig(configDef);\n    SaslConfigs.addClientConfig(configDef);\n    return configDef.configKeys().stream()\n            .filter(configKey -> configDef.get(configKey).type() == ConfigDef.Type.PASSWORD)\n            .collect(Collectors.toSet());\n}", "CodeBleu_score": 66.36275683536789}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n        .filter(cd -> cd.getAuthorizedOperations().contains(AclOperation.ALTER))\n        .filter(cd -> cd.getAuthorizedOperations().contains(AclOperation.VIEW))\n        .map(cd -> ClusterFeature.KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 30.273652570573656}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    final Set<AclOperation> authorizedOperations = clusterDescription.authorizedOperations();\n    final boolean aclViewEnabled = authorizedOperations.contains(AclOperation.VIEW);\n    final boolean alterOrAllOperations = authorizedOperations.contains(AclOperation.ALTER) || authorizedOperations.contains(AclOperation.ALL);\n    if (aclViewEnabled && alterOrAllOperations) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n    }\n    return Mono.empty();\n}", "CodeBleu_score": 40.620848795139864}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(clusterDescription)\n        .filter(d -> d.getAuthorizedOperations().contains(AclOperation.ANY))\n        .filter(d -> d.isAclViewEnabled())\n        .filter(d -> d.getAuthorizedOperations().containsAll(Set.of(AclOperation.ALTER, AclOperation.ALTER_CONFIGS)))\n        .map(d -> ClusterFeature.KAFKA_ACL_EDIT);\n}", "CodeBleu_score": 32.11607151971109}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    Map<TopicPartition, FromToOffset> offsetsToRead = prevRange.isEmpty()\n        ? seekOperations.getSeekOperations().entrySet().stream()\n        .collect(Collectors.toMap(\n            Map.Entry::getKey,\n            e -> new FromToOffset(e.getValue(), e.getValue())))\n        : prevRange;\n    long messagesToRead = calcMessagesToRead(offsetsToRead);\n    return offsetsToRead.entrySet().stream()\n        .collect(Collectors.toMap(\n            Map.Entry::getKey,\n            e -> {\n                long start = e.getValue().getFrom();\n                start = Math.max(start - messagesToRead, 0);\n                return new FromToOffset(start, e.getValue().getTo());\n            },\n            (a, b) -> a,\n            TreeMap::new\n        ));\n}", "CodeBleu_score": 37.5342055222811}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // Initialize the map of offsets to read from\n    Map<TopicPartition, Long> offsetsToReadFrom = prevRange.isEmpty()\n        ? seekOperations.getSeekOperations().stream()\n        .collect(Collectors.toMap(\n            SeekOperation::getTopicPartition,\n            SeekOperation::getOffset\n        ))\n        : prevRange.entrySet().stream()\n        .collect(Collectors.toMap(\n            Map.Entry::getKey,\n            e -> e.getValue().to + 1\n        ));\n\n    // Calculate the number of messages to poll per partition\n    int messagesPerPartition = Math.max(1, Math.min(maxMessagesPerPoll, maxBytesPerPoll / maxMessageBytes));\n\n    // Determine the start offset for each topic partition\n    return offsetsToReadFrom.entrySet().stream()\n        .collect(Collectors.toMap(\n            Map.Entry::getKey,\n            e -> {\n                long startOffset = e.getValue();\n                long endOffset = startOffset + messagesPerPartition;\n                return new FromToOffset(startOffset, endOffset);\n            },\n            (o1, o2) -> o1,\n            TreeMap::new\n        ));\n}", "CodeBleu_score": 41.35649382223644}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    var offsetsToRead = prevRange.isEmpty()\n        ? prevRange\n        : seekOperations.getSeekOperations().entrySet().stream()\n            .collect(Collectors.toMap(\n                Map.Entry::getKey,\n                e -> new FromToOffset(e.getValue().getSeekTo() + 1, e.getValue().getSeekTo()),\n                (prev, next) -> next,\n                TreeMap::new\n            ));\n\n    int messagesToRead = messagesPerTopicPartition.get();\n    TreeMap<TopicPartition, FromToOffset> result = new TreeMap<>(Comparator.comparing(TopicPartition::toString));\n    for (TopicPartition tp : offsetsToRead.keySet()) {\n        long startOffset = offsetsToRead.get(tp).getFrom();\n        if (startOffset < beginningOffset.get(tp)) {\n            startOffset = beginningOffset.get(tp);\n        }\n        long endOffset = startOffset + messagesToRead;\n        result.put(tp, new FromToOffset(startOffset, endOffset));\n    }\n    return result;\n}", "CodeBleu_score": 48.55934416989346}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t    if (isLegacyMode()) {\n        validateLegacyMode();\n    } else {\n        validateConsumerMode();\n    }\n\n    final Lifecycle lifecycle = serverStatus.lifecycle();\n    lifecycle.addListener(new Lifecycle.Listener() {\n        @Override\n        public void lifecycleEvent(Lifecycle.Event event) {\n            if (event == Lifecycle.Event.SERVER_RUNNING) {\n                LOG.info(\"Server is running, launching input [{}]\", input.getName());\n                if (isLegacyMode()) {\n                    launchLegacyInput(input);\n                } else {\n                    launchConsumerInput(input);\n                }\n                scheduleLastSecondBytesReadUpdate();\n            }\n        }\n    });\n\n    if (lifecycle.isServerRunning()) {\n        LOG.info(\"Server is running, launching input [{}]\", input.getName());\n        if (isLegacyMode()) {\n            launchLegacyInput(input);\n        } else {\n            launchConsumerInput(input);\n        }\n        scheduleLastSecondBytesReadUpdate();\n    }\n}", "CodeBleu_score": 34.794699815651406}, {"code": "public void doLaunch(final MessageInput input){\n\t    final Configuration configuration = input.getConfiguration();\n    final boolean legacyMode = configuration.getBoolean(KafkaInput.LEGACY_MODE_CONFIG_NAME);\n    final String bootstrapServers = configuration.getString(KafkaInput.BOOTSTRAP_SERVERS_CONFIG_NAME);\n    final String zookeeperConnect = configuration.getString(KafkaInput.ZOOKEEPER_CONNECT_CONFIG_NAME);\n    final String topicFilter = configuration.getString(KafkaInput.TOPIC_FILTER_CONFIG_NAME);\n    final boolean useMessageId = configuration.getBoolean(KafkaInput.USE_MESSAGE_ID_CONFIG_NAME);\n    final boolean useMessageTimestamp = configuration.getBoolean(KafkaInput.USE_MESSAGE_TIMESTAMP_CONFIG_NAME);\n    final boolean useMessageOffset = configuration.getBoolean(KafkaInput.USE_MESSAGE_OFFSET_CONFIG_NAME);\n    final boolean useMessageKey = configuration.getBoolean(KafkaInput.USE_MESSAGE_KEY_CONFIG_NAME);\n    final boolean useMessageHeaders = configuration.getBoolean(KafkaInput.USE_MESSAGE_HEADERS_CONFIG_NAME);\n    final boolean useMessagePartition = configuration.getBoolean(KafkaInput.USE_MESSAGE_PARTITION_CONFIG_NAME);\n    final boolean useMessageTopic = configuration.getBoolean(KafkaInput.USE_MESSAGE_TOPIC_CONFIG_NAME);\n    final boolean useMessageTimestampType = configuration.getBoolean(KafkaInput.USE_MESSAGE_TIMESTAMP_TYPE_CONFIG_NAME);\n    final boolean useMessageKeyAsId = configuration.getBoolean(KafkaInput.USE_MESSAGE_KEY_AS_ID_CONFIG_NAME);\n    final boolean useMessageKeyAsSource = configuration.getBoolean(KafkaInput.USE_MESSAGE_KEY_AS_SOURCE_CONFIG_NAME);\n    final boolean useMessageKeyAsSourceHost = configuration.getBoolean(KafkaInput.USE_MESSAGE_KEY_AS_SOURCE_HOST_CONFIG_NAME);\n    final boolean useMessageKeyAsSourceInput = configuration.getBoolean(", "CodeBleu_score": 25.19254607032963}, {"code": "public void doLaunch(final MessageInput input){\n\t    // Check if legacy mode is enabled and validate the corresponding configuration settings\n    if (legacyMode) {\n        if (Strings.isNullOrEmpty(zookeeper)) {\n            throw new IllegalArgumentException(\"ZooKeeper is required for legacy mode\");\n        }\n        if (Strings.isNullOrEmpty(group)) {\n            throw new IllegalArgumentException(\"Group is required for legacy mode\");\n        }\n    } else {\n        if (Strings.isNullOrEmpty(bootstrapServers)) {\n            throw new IllegalArgumentException(\"Bootstrap servers are required for consumer mode\");\n        }\n    }\n\n    // Wait for the server to be running\n    serverStatus.awaitRunning();\n\n    // Register for server lifecycle events\n    serverStatus.register(new Lifecycle.Listener() {\n        @Override\n        public void lifecycleEvent(Lifecycle.Event event) {\n            if (event == Lifecycle.Event.SERVER_STOPPING) {\n                LOG.info(\"Stopping Kafka input\");\n                stop();\n            }\n        }\n    });\n\n    // Launch the input based on the mode\n    if (legacyMode) {\n        launchLegacyInput(input);\n    } else {\n        launchConsumerInput(input);\n    }\n\n    // Schedule a task to update the last second bytes read every second\n    scheduledExecutorService.scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            lastSecondBytesRead.set(bytesRead.get());\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 41.12985240869703}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        final Properties customProps = new Properties();\n        customProps.load(new ByteArrayInputStream(customProperties.getBytes(StandardCharsets.UTF_8)));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        LOG.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 54.432767998083776}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        final Properties customProps = new Properties();\n        final String customPropsString = configuration.getString(Configuration.KafkaInput.CUSTOM_PROPERTIES);\n        if (!Strings.isNullOrEmpty(customPropsString)) {\n            customProps.load(new ByteArrayInputStream(customPropsString.getBytes(StandardCharsets.UTF_8)));\n            props.putAll(customProps);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 53.58506206407673}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        props.load(new ByteArrayInputStream(customProperties.getBytes(StandardCharsets.UTF_8)));\n    } catch (IOException e) {\n        LOG.error(\"Could not load custom properties\", e);\n    }\n}", "CodeBleu_score": 34.927912665960456}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    // Filter out null entries\n    final List<RawMessageEvent> filteredEntries = entries.stream()\n            .filter(Objects::nonNull)\n            .collect(Collectors.toList());\n\n    // Map each event to a journal entry\n    final List<Journal.Entry> journalEntries = filteredEntries.stream()\n            .map(event -> new Journal.Entry(event.getRawMessage(), event.getTimestamp()))\n            .collect(Collectors.toList());\n\n    // Calculate the total message bytes\n    final long totalMessageBytes = filteredEntries.stream()\n            .mapToLong(event -> event.getRawMessage().length)\n            .sum();\n\n    // Attempt to write the entries to the journal\n    Retryer<Void> retryer = RetryerBuilder.<Void>newBuilder()\n            .retryIfExceptionOfType(MessageQueueException.class)\n            .withWaitStrategy(WaitStrategies.exponentialWait(100, 1000, TimeUnit.MILLISECONDS))\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n\n    try {\n        retryer.call(() -> {\n            journal.write(journalEntries);\n            return null;\n        });\n    } catch (RetryException | ExecutionException e) {\n        throw new MessageQueueException(\"Failed to write entries to journal\", e);\n    }\n\n    // Update the written messages and bytes metrics\n    writtenMessages.addAndGet(filteredEntries.size());\n    writtenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 53.76661158081715}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    final List<RawMessageEvent> nonNullEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n    final long totalMessageBytes = nonNullEntries.stream().mapToLong(RawMessageEvent::getBytes).sum();\n    final List<Journal.Entry> journalEntries = nonNullEntries.stream().map(RawMessageEvent::toJournalEntry).collect(Collectors.toList());\n    final Retryer<Void> retry = RetryerBuilder.<Void>newBuilder().retryIfException()\n            .withWaitStrategy(WaitStrategies.exponentialWait(100, 1000, TimeUnit.MILLISECONDS))\n            .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n            .build();\n    try {\n        retry.call(() -> {\n            journal.write(journalEntries);\n            return null;\n        });\n    } catch (RetryException | ExecutionException e) {\n        throw new MessageQueueException(\"Could not write entries to journal\", e);\n    }\n    writtenMessages.addAndGet(nonNullEntries.size());\n    writtenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 52.816860579478806}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    final List<RawMessageEvent> nonNullEntries = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n    final List<Journal.Entry> journalEntries = nonNullEntries.stream().map(RawMessageEvent::toJournalEntry).collect(Collectors.toList());\n    final long totalMessageBytes = nonNullEntries.stream().mapToLong(RawMessageEvent::getMessageSize).sum();\n\n    try {\n        // Attempt to write to the journal\n        journal.write(journalEntries);\n\n        // Update metrics\n        writtenMessages.addAndGet(nonNullEntries.size());\n        writtenBytes.addAndGet(totalMessageBytes);\n    } catch (Exception e) {\n        // If the write operation fails, retry using an exponential back-off strategy\n        Retryer<Void> retryer = RetryerBuilder.<Void>newBuilder()\n                .retryIfExceptionOfType(Exception.class)\n                .withWaitStrategy(WaitStrategies.exponentialWait(50, 500, TimeUnit.MILLISECONDS))\n                .withStopStrategy(StopStrategies.stopAfterAttempt(3))\n                .build();\n\n        try {\n            retryer.call(() -> {\n                journal.write(journalEntries);\n                return null;\n            });\n\n            // Update metrics\n            writtenMessages.addAndGet(nonNullEntries.size());\n            writtenBytes.addAndGet(totalMessageBytes);\n        } catch (RetryException | ExecutionException e1) {\n            throw new MessageQueueException(\"Unable to write messages to journal\", e1);\n        }\n    }\n}", "CodeBleu_score": 53.04086756151881}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t    final Optional<Long> maxMessageQueueId = messages.stream().map(Message::getMessageQueueId).filter(Optional::isPresent).map(Optional::get).max(Long::compareTo);\n    if (maxMessageQueueId.isPresent()) {\n        final long messageQueueId = maxMessageQueueId.get();\n        if (messageQueueId > lastAcknowledgedMessageQueueId) {\n            lastAcknowledgedMessageQueueId = messageQueueId;\n            if (messageQueueId > journal.getMaximumMessageQueueId()) {\n                journal.setMaximumMessageQueueId(messageQueueId);\n            }\n        }\n    }\n    metrics.markAcknowledgedMessages(messages.size());\n}", "CodeBleu_score": 46.11924094598664}, {"code": "public void acknowledge(List<Message> messages){\n\t    Optional<Long> maxMessageQueueId = messages.stream().map(Message::getQueueId).filter(Optional::isPresent).map(Optional::get).max(Long::compare);\n    maxMessageQueueId.ifPresent(messageQueueId -> {\n        messageQueueAcknowledger.acknowledge(messageQueueId);\n        messagesAcknowledged.mark(messages.size());\n    });\n}", "CodeBleu_score": 45.5700860754482}, {"code": "public void acknowledge(List<Message> messages){\n\t    Optional<Long> maxQueueId = messages.stream().map(Message::getQueueId).filter(Optional::isPresent).map(Optional::get).max(Long::compareTo);\n    maxQueueId.ifPresent(this.kafkaJournal::acknowledge);\n    this.metrics.markAcknowledged(messages.size());\n}", "CodeBleu_score": 42.69917680948934}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    final MetricRegistry metricRegistry = this.metricRegistry;\n    final String className = LocalKafkaJournal.class.getSimpleName();\n\n    final MetricFilter metricFilter = (name, metric) -> name.startsWith(className);\n    final Map<String, Metric> metrics = metricRegistry.getMetrics(metricFilter);\n\n    for (Map.Entry<String, Metric> entry : metrics.entrySet()) {\n        final String originalName = entry.getKey();\n        final Metric originalMetric = entry.getValue();\n\n        final String legacyName = originalName.replace(className, \"kafka-journal\");\n        final Metric legacyMetric = metricRegistry.register(legacyName, originalMetric);\n\n        if (legacyMetric != originalMetric) {\n            LOG.warn(\"Legacy metric name [{}] registered under [{}]\", originalName, legacyName);\n        }\n    }\n}", "CodeBleu_score": 38.423678859883964}, {"code": "private void registerLegacyMetrics(){\n\t    final String className = LocalKafkaJournal.class.getName();\n    final MetricRegistry metricRegistry = new MetricRegistry();\n    final MetricFilter metricFilter = (name, metric) -> name.startsWith(className);\n    final SortedMap<String, Metric> metrics = metricRegistry.getMetrics(metricFilter);\n    for (Map.Entry<String, Metric> entry : metrics.entrySet()) {\n        final String originalName = entry.getKey();\n        final String legacyName = originalName.substring(className.length() + 1);\n        try {\n            metricRegistry.register(legacyName, entry.getValue());\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\"Could not register legacy metric [{}] under name [{}]\", originalName, legacyName);\n        }\n    }\n}", "CodeBleu_score": 40.49501828626163}, {"code": "private void registerLegacyMetrics(){\n\t    final MetricRegistry metricRegistry = this.metricRegistry;\n    final String className = LocalKafkaJournal.class.getName();\n    final MetricFilter metricFilter = (name, metric) -> name.startsWith(className);\n    final SortedMap<String, Metric> metrics = metricRegistry.getMetrics(metricFilter);\n    for (final Map.Entry<String, Metric> metricEntry : metrics.entrySet()) {\n        final String metricName = metricEntry.getKey();\n        final String legacyMetricName = metricName.substring(className.length() + 1);\n        try {\n            metricRegistry.register(legacyMetricName, metricEntry.getValue());\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\"Failed to register legacy metric {} under {}\", metricName, legacyMetricName);\n        }\n    }\n}", "CodeBleu_score": 40.55401891860582}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    Timer timer = metricRegistry.timer(metricName);\n    try {\n        metricRegistry.register(metricName, timer);\n    } catch (IllegalArgumentException e) {\n        timer = metricRegistry.timer(metricName);\n    }\n    return timer;\n}", "CodeBleu_score": 31.100623073370492}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    metricRegistry.register(name, new Gauge<Integer>() {\n        @Override\n        public Integer getValue() {\n            return getUncommittedMessages();\n        }\n    });\n}", "CodeBleu_score": 15.663821148098766}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    metricRegistry.register(name, (Gauge<Integer>) () -> {\n        try {\n            return getUncommittedMessages();\n        } catch (IOException e) {\n            LOG.error(\"Unable to get uncommitted messages\", e);\n            return 0;\n        }\n    });\n}", "CodeBleu_score": 26.878406817127065}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    metricRegistry.register(name, new Gauge<Long>() {\n        @Override\n        public Long getValue() {\n            return getUncommittedMessages();\n        }\n    });\n}", "CodeBleu_score": 15.54277940554662}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        LOG.debug(\"No messages to write\");\n        return -1;\n    }\n    final ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    LOG.debug(\"Writing {} messages ({} bytes) to Kafka\", messages.size(), messageSet.sizeInBytes());\n    final LogAppendInfo appendInfo = log.append(messageSet);\n    LOG.debug(\"Wrote {} messages to Kafka ({} bytes) at offset {}\", messages.size(), messageSet.sizeInBytes(), appendInfo.lastOffset());\n    writtenMessages.mark(messages.size());\n    return appendInfo.lastOffset();\n}", "CodeBleu_score": 46.50188924248593}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        LOG.debug(\"No messages to write\");\n        return 0;\n    }\n\n    final ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    LOG.debug(\"Writing {} messages with payload size {}\", messageSet.sizeInBytes(), payloadSize);\n\n    final LogAppendInfo appendInfo = log.append(messageSet);\n    final long lastWriteOffset = appendInfo.lastOffset();\n\n    LOG.debug(\"Wrote {} messages with payload size {} to offset {}\", messageSet.sizeInBytes(), payloadSize, lastWriteOffset);\n    messagesWritten.mark();\n    return lastWriteOffset;\n}", "CodeBleu_score": 46.2399662880981}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        LOG.debug(\"No messages to write\");\n        return -1;\n    }\n    final ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    LOG.debug(\"Writing {} messages with payload size {} bytes\", messageSet.size(), payloadSize);\n    final LogAppendInfo appendInfo = log.append(messageSet);\n    LOG.debug(\"Wrote {} messages with payload size {} bytes to offset {}\", messageSet.size(), payloadSize, appendInfo.getLastOffset());\n    writtenMessages.mark(messageSet.size());\n    return appendInfo.getLastOffset();\n}", "CodeBleu_score": 45.359248755982456}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    List<AdminClient> clients = clusterPhyId2AdminClient.get(clusterPhyId);\n    if (clients == null) {\n        return;\n    }\n\n    LOGGER.info(\"method=closeKafkaAdminClient||msg=start to close kafkaAdminClient||clusterPhyId={}\", clusterPhyId);\n\n    try {\n        for (AdminClient client : clients) {\n            client.close();\n        }\n    } catch (Exception e) {\n        LOGGER.error(\"method=closeKafkaAdminClient||msg=close kafkaAdminClient failed||clusterPhyId={}||e={}\", clusterPhyId, e.getMessage());\n    }\n\n    LOGGER.info(\"method=closeKafkaAdminClient||msg=close kafkaAdminClient success||clusterPhyId={}\", clusterPhyId);\n}", "CodeBleu_score": 44.434868128815324}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t        List<AdminClient> adminClientList = null;\n        try {\n            adminClientList = CLIENT_MAP.get(clusterPhyId);\n            if (adminClientList == null) {\n                return;\n            }\n\n            LOGGER.info(\"method=closeKafkaAdminClient||msg=start to close kafka admin client||clusterPhyId={}||adminClientList={}\", clusterPhyId, adminClientList);\n            for (AdminClient adminClient : adminClientList) {\n                adminClient.close();\n            }\n            LOGGER.info(\"method=closeKafkaAdminClient||msg=success to close kafka admin client||clusterPhyId={}||adminClientList={}\", clusterPhyId, adminClientList);\n        } catch (Exception e) {\n            LOGGER.error(\"method=closeKafkaAdminClient||msg=fail to close kafka admin client||clusterPhyId={}||adminClientList={}\", clusterPhyId, adminClientList, e);\n        } finally {\n            CLIENT_MAP.remove(clusterPhyId);\n        }\n    }", "CodeBleu_score": 47.14678011993135}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    List<AdminClient> adminClients = new ArrayList<>();\n    synchronized (kafkaAdminClientMap) {\n        adminClients = kafkaAdminClientMap.get(clusterPhyId);\n        if (adminClients == null) {\n            return;\n        }\n    }\n\n    LOGGER.info(\"method=closeKafkaAdminClient||msg=start to close kafka admin client||clusterPhyId={}||adminClients={}\", clusterPhyId, adminClients);\n    try {\n        for (AdminClient adminClient : adminClients) {\n            adminClient.close();\n        }\n    } catch (Exception e) {\n        LOGGER.error(\"method=closeKafkaAdminClient||msg=close kafka admin client failed||clusterPhyId={}||adminClients={}\", clusterPhyId, adminClients, e);\n    }\n\n    LOGGER.info(\"method=closeKafkaAdminClient||msg=close kafka admin client success||clusterPhyId={}||adminClients={}\", clusterPhyId, adminClients);\n\n    synchronized (kafkaAdminClientMap) {\n        kafkaAdminClientMap.remove(clusterPhyId);\n    }\n}", "CodeBleu_score": 47.31845673486098}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\n                    \"method=closeAdminClientList||clusterPhyId={}||msg=close admin client failed\",\n                    clusterPhyId,\n                    e\n            );\n            success = false;\n        }\n    }\n\n    return success;\n}", "CodeBleu_score": 80.38780984793486}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\"method=closeAdminClientList||clusterPhyId={}||msg=close adminClient failed\", clusterPhyId, e);\n            success = false;\n        }\n    }\n\n    return success;\n}", "CodeBleu_score": 83.78650681571831}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\"method=closeAdminClientList||clusterPhyId={}||msg=close AdminClient failed\", clusterPhyId, e);\n            success = false;\n        }\n    }\n\n    return success;\n}", "CodeBleu_score": 83.86273775558833}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        for (int i = 0; i < 5; i++) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException ex) {\n                throw new IllegalStateException(ex);\n            }\n            if (!app.isRunning()) {\n                break;\n            }\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 50.09813464688556}, {"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        int attempts = 0;\n        while (app.isRunning() && attempts < 5) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n            attempts++;\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 69.36796139569984}, {"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        try {\n            app.waitFor(5, 1000);\n        } catch (InterruptedException ex) {\n            Thread.currentThread().interrupt();\n            throw new IllegalStateException(\"Interrupted while waiting for app to stop\", ex);\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 35.57623287986018}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    return startEurekaServer(config, null);\n}", "CodeBleu_score": 7.160574376176218}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    return startEurekaServer(config, null, null, null);\n}", "CodeBleu_score": 7.533793748578726}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    return startEurekaServer(config, null);\n}", "CodeBleu_score": 7.160574376176218}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n    runner.enableTLS();\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 61.86273241185795}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner runner = new EurekaClientRunner(config, server, \"testservice\");\n    runner.enableTls();\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 62.1928102044044}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\");\n    client.enableTLS();\n    client.start();\n    return client;\n}", "CodeBleu_score": 62.32865147470914}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t    // Create a KeyTool instance for creating certificates\n    KeyTool keyTool = new KeyTool(\"src/test/resources/keystore.jks\", \"password\", \"password\");\n    // Create a CA certificate and save it\n    keyTool.createCACert(\"ca\");\n    // Create a server certificate and sign it with the CA\n    keyTool.createServerCert(\"server\", \"ca\");\n    // Create a client certificate and sign it with the CA\n    keyTool.createClientCert(\"client\", \"ca\");\n    // Create a second CA certificate and save it\n    keyTool.createCACert(\"ca2\");\n    // Create a client certificate and sign it with the second CA\n    keyTool.createClientCert(\"client2\", \"ca2\");\n}", "CodeBleu_score": 19.68198328160379}, {"code": "static void createCertificates() throws Exception{\n\t    // Create a KeyTool instance for creating certificates\n    KeyTool keyTool = new KeyTool(new File(\"target/test-classes/keytool.conf\"));\n    // Create a CA certificate and save it\n    keyTool.createCACert(\"ca\", \"CN=ca,OU=ca,O=ca,L=ca,ST=ca,C=ca\");\n    saveCert(keyTool.getCertificate(\"ca\"), \"target/test-classes/ca.crt\");\n    // Create a server certificate and sign it with the CA certificate\n    keyTool.createServerCert(\"server\", \"CN=server,OU=server,O=server,L=server,ST=server,C=server\", \"ca\");\n    saveCert(keyTool.getCertificate(\"server\"), \"target/test-classes/server.crt\");\n    // Create a client certificate and sign it with the CA certificate\n    keyTool.createClientCert(\"client\", \"CN=client,OU=client,O=client,L=client,ST=client,C=client\", \"ca\");\n    saveCert(keyTool.getCertificate(\"client\"), \"target/test-classes/client.crt\");\n    // Create a second CA certificate and save it\n    keyTool.createCACert(\"ca2\", \"CN=ca2,OU=ca2,O=ca2,L=ca2,ST=ca2,C=ca2\");\n    saveCert(keyTool.getCertificate(\"ca2\"), \"target/test-classes/ca2.crt\");\n    // Create a client certificate and sign it with the second CA certificate\n    keyTool.createClientCert(\"client2\", \"CN=client2,OU=client2,O=client2,L=client2,ST=client2,C=client2\", \"ca2\");\n    saveCert(keyTool.getCertificate(\"client2\"), \"target/test-classes/client2.crt\");\n}", "CodeBleu_score": 19.714955810630258}, {"code": "static void createCertificates() throws Exception{\n\t    KeyTool keyTool = new KeyTool(\"src/test/resources/keystore.jks\", \"password\");\n    // Create CA certificate\n    keyTool.createSelfSignedCert(\"CN=Test CA, O=Test Org\", \"TestCA\", 365);\n    // Create server certificate\n    keyTool.createCert(\"CN=Test Server, O=Test Org\", \"TestServer\", 365, \"TestCA\");\n    // Create client certificate\n    keyTool.createCert(\"CN=Test Client, O=Test Org\", \"TestClient\", 365, \"TestCA\");\n    // Save certificates and keys\n    keyTool.saveCert(\"TestCA\", \"src/test/resources/TestCA.crt\");\n    keyTool.saveKeyAndCert(\"TestServer\", \"src/test/resources/TestServer.key\", \"src/test/resources/TestServer.crt\");\n    keyTool.saveKeyAndCert(\"TestClient\", \"src/test/resources/TestClient.key\", \"src/test/resources/TestClient.crt\");\n    // Create second CA and client certificate pair\n    keyTool.createSelfSignedCert(\"CN=Test CA 2, O=Test Org\", \"TestCA2\", 365);\n    keyTool.createCert(\"CN=Test Client 2, O=Test Org\", \"TestClient2\", 365, \"TestCA2\");\n    keyTool.saveCert(\"TestCA2\", \"src/test/resources/TestCA2.crt\");\n    keyTool.saveKeyAndCert(\"TestClient2\", \"src/test/resources/TestClient2.key\", \"src/test/resources/TestClient2.crt\");\n}", "CodeBleu_score": 13.822704119997177}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long start = System.currentTimeMillis();\n    long timeLimit = seconds * 1000;\n    while (!assertion.getAsBoolean()) {\n        if (System.currentTimeMillis() - start > timeLimit) {\n            throw new RuntimeException(\"Assertion failed\");\n        }\n    }\n}", "CodeBleu_score": 44.591075469141686}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (!assertion.getAsBoolean()) {\n        if (System.currentTimeMillis() > timeLimit) {\n            throw new RuntimeException(\"Assertion failed within \" + seconds + \" seconds.\");\n        }\n    }\n}", "CodeBleu_score": 36.533271217465334}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }\n    throw new RuntimeException(\"Assertion not met within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 40.654614353530825}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a new X509CertificateBuilder\n    JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(\"CN=\" + ca),\n            new BigInteger(\"1\"),\n            new Date(),\n            new Date(System.currentTimeMillis() + 365L * 24 * 60 * 60 * 1000),\n            new X500Name(\"CN=\" + ca),\n            keyPair.getPublic());\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the private key\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\n    // Convert the certificate holder to an X509Certificate\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}", "CodeBleu_score": 37.37963974673972}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a content signer using the private key\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n\n    // Create a certificate builder\n    JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(ca),\n            new BigInteger(64, new SecureRandom()),\n            new Date(System.currentTimeMillis() - 365L * 24 * 60 * 60 * 1000),\n            new Date(System.currentTimeMillis() + 365L * 24 * 60 * 60 * 1000),\n            new X500Name(ca),\n            keyPair.getPublic());\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the content signer\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\n    // Convert the certificate holder to an X509 certificate\n    return new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(certHolder);\n}", "CodeBleu_score": 39.44546603166019}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Get the public key and private key from the key pair\n    PublicKey publicKey = keyPair.getPublic();\n    PrivateKey privateKey = keyPair.getPrivate();\n\n    // Create a new X509 certificate builder\n    X509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n        new X500Name(ca),\n        new BigInteger(64, new SecureRandom()),\n        new Date(),\n        new Date(new Date().getTime() + 365 * 24 * 60 * 60 * 1000),\n        new X500Name(ca),\n        publicKey\n    );\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(false));\n\n    // Sign the certificate with the private key\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(privateKey);\n    X509CertificateHolder certHolder = certBuilder.build(contentSigner);\n\n    // Convert the certificate holder to an X509 certificate\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}", "CodeBleu_score": 38.55303343956271}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    EurekaHttpClient eurekaHttpClient = null;\n    try {\n        Field registrationClientField = TransportClientFactories.class.getDeclaredField(\"registrationClient\");\n        registrationClientField.setAccessible(true);\n        eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(null);\n    } catch (IllegalAccessException | NoSuchFieldException e) {\n        LOG.error(\"Error getting EurekaHttpClient\", e);\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 38.5103772361941}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    EurekaHttpClient eurekaHttpClient = null;\n    try {\n        Field registrationClient = TransportClientFactories.class.getDeclaredField(\"registrationClient\");\n        registrationClient.setAccessible(true);\n        eurekaHttpClient = (EurekaHttpClient) registrationClient.get(null);\n    } catch (IllegalAccessException | NoSuchFieldException e) {\n        logger.error(\"Failed to access EurekaHttpClient using reflection\", e);\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 35.397930149273336}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t  EurekaHttpClient eurekaHttpClient = null;\n  try {\n    Field registrationClientField = TransportClientFactories.class.getDeclaredField(\"registrationClient\");\n    registrationClientField.setAccessible(true);\n    eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(null);\n  } catch (IllegalAccessException | NoSuchFieldException e) {\n    log.error(\"Failed to access EurekaHttpClient\", e);\n  }\n  return eurekaHttpClient;\n}", "CodeBleu_score": 35.96481068538917}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t        List<String> services = new ArrayList<>();\n        Applications applications = this.eurekaClient.getApplications();\n        if (applications == null) {\n            return services;\n        }\n        for (Application application : applications.getRegisteredApplications()) {\n            if (!application.getInstances().isEmpty()) {\n                services.add(application.getName().toLowerCase());\n            }\n        }\n        return services;\n    }", "CodeBleu_score": 58.64691231201239}, {"code": "public List<String> getServices(){\n\t    Applications applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return Collections.emptyList();\n    }\n    List<String> names = new ArrayList<>();\n    for (Application app : applications.getRegisteredApplications()) {\n        if (!app.getInstances().isEmpty()) {\n            names.add(app.getName().toLowerCase());\n        }\n    }\n    return names;\n}", "CodeBleu_score": 65.82969643396464}, {"code": "public List<String> getServices(){\n\t    Applications applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return Collections.emptyList();\n    }\n    List<String> services = new ArrayList<String>();\n    for (Application application : applications.getRegisteredApplications()) {\n        if (!application.getInstances().isEmpty()) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 58.440265986573635}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor composite = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (Map.Entry<String, HealthContributor> contributor : composite.getContributors().entrySet()) {\n                if (!(contributor.getValue() instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(contributor.getKey(), (HealthIndicator) contributor.getValue());\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 41.4840817814063}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        String key = entry.getKey();\n        HealthContributor value = entry.getValue();\n        if (value instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) value;\n            for (NamedContributor<HealthContributor> namedContributor : discoveryCompositeHealthContributor.getNamedContributors()) {\n                HealthContributor contributor = namedContributor.getContributor();\n                if (!(contributor instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(key + \".\" + namedContributor.getName(), contributor);\n                }\n            }\n        } else {\n            healthContributors.put(key, value);\n        }\n    }\n}", "CodeBleu_score": 37.01051608679572}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        HealthContributor contributor = entry.getValue();\n        if (contributor instanceof DiscoveryCompositeHealthContributor) {\n            for (NamedContributor<HealthContributor> namedContributor : ((DiscoveryCompositeHealthContributor) contributor).getNamedContributors()) {\n                if (!(namedContributor.getContributor() instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(namedContributor.getName(), namedContributor.getContributor());\n                }\n            }\n        } else {\n            healthContributors.put(entry.getKey(), contributor);\n        }\n    }\n}", "CodeBleu_score": 39.594341501686905}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances != null && !instances.isEmpty()) {\n        URI uri = instances.get(0).getUri();\n        if (uri != null) {\n            return (new RestTemplate()).postForObject(uri + \"/echo\", \"Hello World\", String.class);\n        }\n    }\n    throw new RuntimeException(\"Unable to discover any service instances for: provider-application\");\n}", "CodeBleu_score": 44.656367816212104}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances of provider-application found\");\n    }\n    URI providerUri = instances.get(0).getUri();\n    String response = restTemplate.postForObject(providerUri + \"/echo\", \"Hello\", String.class);\n    return response;\n}", "CodeBleu_score": 53.554695585449494}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = tutuDiscoveryClient.getInstances(\"provider-application\");\n    if (instances != null && !instances.isEmpty()) {\n        URI uri = instances.get(0).getUri();\n        if (uri != null) {\n            return (new RestTemplate()).postForObject(uri + \"/echo\", \"hello\", String.class);\n        }\n    }\n    throw new RuntimeException(\"No instance available for provider-application\");\n}", "CodeBleu_score": 45.5502136718899}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"unable to discover service instance\");\n    }\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri.resolve(\"/echo\"), \"hello\", String.class);\n}", "CodeBleu_score": 44.024253571903785}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"unable to find instance of provider-application\");\n    }\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri.resolve(\"/echo\"), \"hello\", String.class);\n}", "CodeBleu_score": 44.93505413251045}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No instance available\");\n    }\n\n    URI uri = instance.getUri();\n    if (uri != null) {\n        return (restTemplate().postForObject(uri.toString() + \"/echo\", \"Hello World\", String.class));\n    }\n\n    return \"Hello World\";\n}", "CodeBleu_score": 48.4296936001128}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering service: {} with IP: {} and port: {}\", serviceName, ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}", "CodeBleu_score": 62.74460383731686}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"register service {} with {} : {}\", serviceName, ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    Server server = new Server(ip, port);\n    serverMap.get(serviceName).add(server);\n    return true;\n}", "CodeBleu_score": 76.58736627218451}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering service: {}, ip: {}, port: {}\", serviceName, ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    Server server = new Server(ip, port);\n    serverMap.get(serviceName).add(server);\n    return true;\n}", "CodeBleu_score": 80.66982883580366}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    log.info(\"deregister serviceName:{},ip:{},port:{}\", serviceName, ip, port);\n    Set<Server> serverSet = serverMap.get(serviceName);\n    if (serverSet == null) {\n        log.info(\"deregister serviceName:{},ip:{},port:{}\", serviceName, ip, port);\n        return false;\n    }\n    Server server = new Server(ip, port);\n    return serverSet.remove(server);\n}", "CodeBleu_score": 65.61414846102231}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Deregistering service: {} with IP: {} and port: {}\", serviceName, ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers != null) {\n        Server server = new Server(ip, port);\n        boolean removed = servers.remove(server);\n        if (removed) {\n            logger.info(\"Deregistered service: {} with IP: {} and port: {}\", serviceName, ip, port);\n            return true;\n        }\n    }\n    return false;\n}", "CodeBleu_score": 65.64666805624127}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        return false;\n    }\n    Server server = new Server(ip, port);\n    boolean removed = servers.remove(server);\n    if (removed) {\n        logger.info(\"Deregistered server: {}\", server);\n    }\n    return removed;\n}", "CodeBleu_score": 55.60057423387712}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes == null) {\n        return;\n    }\n    Map<String, Object> defaultAttributes = (Map<String, Object>) attributes.get(\"defaultConfiguration\");\n    if (defaultAttributes != null) {\n        String name = (String) defaultAttributes.get(\"name\");\n        registerClientConfiguration(name, (Class<?>) defaultAttributes.get(\"configuration\"), registry);\n    }\n}", "CodeBleu_score": 51.051134495461994}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfigurationRegistrar.class);\n        builder.addConstructorArgValue(attributes);\n        builder.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n        registry.registerBeanDefinition(RibbonClientConfigurationRegistrar.class.getName(), builder.getBeanDefinition());\n    }\n}", "CodeBleu_score": 38.844606322890925}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfigurationRegistrar.class);\n        if (attributes.containsKey(\"defaultConfiguration\")) {\n            builder.addPropertyValue(\"defaultConfiguration\", attributes.get(\"defaultConfiguration\"));\n        }\n        String name = \"ribbonClientConfiguration\";\n        if (attributes.containsKey(\"name\")) {\n            name = (String) attributes.get(\"name\");\n        }\n        registry.registerBeanDefinition(name, builder.getBeanDefinition());\n    }\n}", "CodeBleu_score": 45.13640287274113}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n    if (loadBalancer == null) {\n        return null;\n    }\n    Server server = loadBalancer.chooseServer(request.getLoadBalancerKey());\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 61.04964113055571}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n    if (loadBalancer == null) {\n        return null;\n    }\n    Server server = loadBalancer.chooseServer(request);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n}", "CodeBleu_score": 59.23972794341933}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t        ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n        if (loadBalancer == null) {\n            return null;\n        }\n        Server server = loadBalancer.chooseServer(request);\n        if (server == null) {\n            return null;\n        }\n        return new TutuServiceInstance(serviceId, server.getHost(), server.getPort());\n    }", "CodeBleu_score": 57.03046730120668}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        if (StrUtil.isNotBlank(server.getHost())) {\n            return new URI(String.format(\"%s://%s:%d%s\", original.getScheme(), server.getHost(), server.getPort(), original.getPath()));\n        } else {\n            return new URI(String.format(\"%s://%s:%d%s\", original.getScheme(), server.getServiceId(), server.getPort(), original.getPath()));\n        }\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 38.894495575829815}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    String svcId = server.getServiceId();\n    String host = server.getHost();\n    int port = server.getPort();\n    try {\n        String query = original.getQuery();\n        String reconstructed = \"http://\" + host + \":\" + port + original.getPath();\n        if (StrUtil.isNotBlank(query)) {\n            reconstructed += \"?\" + query;\n        }\n        return new URI(reconstructed);\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 41.35223421145982}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        StringBuilder uri = new StringBuilder();\n        uri.append(original.getScheme()).append(\"://\").append(server.getHost()).append(\":\").append(server.getPort());\n        if (StrUtil.isNotBlank(original.getRawPath())) {\n            uri.append(original.getRawPath());\n        }\n        if (StrUtil.isNotBlank(original.getRawQuery())) {\n            uri.append(\"?\").append(original.getRawQuery());\n        }\n        return new URI(uri.toString());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 67.68597625934389}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    String serverAddress = tutuDiscoveryProperties.getServerAddress();\n    String serviceName = tutuDiscoveryProperties.getServiceName();\n    Map<String, Object> params = new HashMap<>();\n    params.put(\"serviceName\", serviceName);\n    String result = HttpUtil.get(serverAddress + \"/list\", params);\n    JSONObject jsonObject = JSON.parseObject(result);\n    List<TutuServer> tutuServerList = jsonObject.getJSONArray(\"data\").stream().map(obj -> {\n        JSONObject json = (JSONObject) obj;\n        return new TutuServer(json.getString(\"ip\"), json.getInteger(\"port\"));\n    }).collect(Collectors.toList());\n    return tutuServerList;\n}", "CodeBleu_score": 45.42384431069993}, {"code": "private List<TutuServer> getServer(){\n\t    // Construct parameters including the serviceName\n    Map<String, Object> params = new HashMap<>();\n    params.put(\"serviceName\", serviceName);\n\n    // Send a request to the specified server address concatenated with \"/list\"\n    String result = HttpUtil.get(discoveryProperties.getServerAddr() + \"/list\", params);\n\n    // Parse the JSON array into a list of TutuServer objects\n    List<JSONObject> jsonList = JSON.parseArray(result, JSONObject.class);\n    return jsonList.stream().map(json -> {\n        TutuServer server = new TutuServer();\n        server.setIp(json.getString(\"ip\"));\n        server.setPort(json.getInteger(\"port\"));\n        return server;\n    }).collect(Collectors.toList());\n}", "CodeBleu_score": 52.42884889259615}, {"code": "private List<TutuServer> getServer(){\n\t    String server = tutuDiscoveryProperties.getServer();\n    String serviceName = tutuDiscoveryProperties.getServiceName();\n    Map<String, Object> paramMap = new HashMap<>();\n    paramMap.put(\"serviceName\", serviceName);\n    String url = server + \"/list\";\n    String result = HttpUtil.get(url, paramMap);\n    List<JSONObject> jsonObjects = JSON.parseArray(result, JSONObject.class);\n    return jsonObjects.stream().map(jsonObject -> new TutuServer(jsonObject.getString(\"ip\"), jsonObject.getInteger(\"port\"))).collect(Collectors.toList());\n}", "CodeBleu_score": 44.28935370645366}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (Map.Entry<String, ZuulProperties.ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n        String pattern = entry.getValue().getPath();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = path.replaceFirst(pattern, entry.getValue().getUrl());\n            return new Route(targetPath, entry.getValue().getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 57.27262491826024}, {"code": "public Route getMatchingRoute(String path){\n\t    for (Map.Entry<String, ZuulProperties.ZuulRoute> entry : this.properties.getRoutes().entrySet()) {\n        String pattern = entry.getValue().getPath();\n        boolean isMatch = pathMatcher.match(pattern, path);\n        if (isMatch) {\n            String targetPath = path.substring(path.indexOf(pattern));\n            return new Route(targetPath, entry.getValue().getServiceId(), null, null, false, null);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 52.82079148540847}, {"code": "public Route getMatchingRoute(String path){\n\t    PathMatcher pathMatcher = new AntPathMatcher();\n    for (Map.Entry<String, ZuulProperties.ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n        ZuulProperties.ZuulRoute route = entry.getValue();\n        if (pathMatcher.match(route.getPath(), path)) {\n            String targetPath = path.replaceFirst(route.getPath(), \"\");\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 54.01605398551943}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    Set<Class<?>> classes = ClassUtil.scanPackageByAnnotation(FeignClient.class, ClassUtils.getPackageName(importingClassMetadata.getClassName()));\n    for (Class<?> clazz : classes) {\n        FeignClient feignClient = clazz.getAnnotation(FeignClient.class);\n        String contextId = feignClient.contextId();\n        String type = feignClient.type();\n        GenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n        beanDefinition.setBeanClass(FeignClientFactoryBean.class);\n        beanDefinition.getPropertyValues().add(\"contextId\", contextId);\n        beanDefinition.getPropertyValues().add(\"type\", type);\n        registry.registerBeanDefinition(clazz.getName(), beanDefinition);\n    }\n}", "CodeBleu_score": 55.80838096576646}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    // Get the package name of the importing class\n    String packageName = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n    // Use Hutool's ClassUtil to scan for classes annotated with @FeignClient within the package\n    Set<Class<?>> classes = ClassUtil.scanPackageByAnnotation(packageName, FeignClient.class);\n    // Iterate over the classes\n    for (Class<?> clazz : classes) {\n        // Create a GenericBeanDefinition instance for the class\n        GenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n        // Set the bean class to the class itself\n        beanDefinition.setBeanClass(clazz);\n        // Set the bean factory to the FeignClientFactoryBean\n        beanDefinition.setBeanClass(FeignClientFactoryBean.class);\n        // Set the contextId to the class name\n        beanDefinition.getPropertyValues().add(\"contextId\", clazz.getName());\n        // Set the type to the class itself\n        beanDefinition.getPropertyValues().add(\"type\", clazz);\n        // Register the bean definition with the registry using the class name as the bean name\n        registry.registerBeanDefinition(clazz.getName(), beanDefinition);\n    }\n}", "CodeBleu_score": 59.21864766730624}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    // Get the package name of the importing class\n    String packageName = ClassUtils.getPackageName(importingClassMetadata.getClassName());\n\n    // Scan for classes annotated with @FeignClient within the package\n    Set<Class<?>> classes = ClassUtil.scanPackageByAnnotation(packageName, FeignClient.class);\n\n    // Iterate over the classes\n    for (Class<?> clazz : classes) {\n        // Get the FeignClient annotation from the class\n        FeignClient feignClient = clazz.getAnnotation(FeignClient.class);\n\n        // Create a GenericBeanDefinition instance\n        GenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n\n        // Configure the bean definition with the FeignClientFactoryBean settings\n        beanDefinition.getPropertyValues().add(\"contextId\", feignClient.contextId());\n        beanDefinition.getPropertyValues().add(\"type\", clazz);\n        beanDefinition.setBeanClass(FeignClientFactoryBean.class);\n\n        // Register the bean definition with the BeanDefinitionRegistry using the class name as the bean name\n        registry.registerBeanDefinition(clazz.getSimpleName(), beanDefinition);\n    }\n}", "CodeBleu_score": 59.16030712764483}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
