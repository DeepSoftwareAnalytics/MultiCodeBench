{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    try:\n        return (self.loop_wait - 2) * 1000, self.connection._connect(*args)\n    finally:\n        self.loop_wait = max(2, self.loop_wait - 1)\n\n", "CodeBleu_score": 54.01049050422304}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait, _ = self._original_connect(*args)\n    return min(2, self.loop_wait - 2) * 1000, wait\n\n", "CodeBleu_score": 52.448790463151404}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait, _ = self.connection._connect(*args)\n    wait = max(2, wait - 2) * 1000\n    return wait, _\n\n", "CodeBleu_score": 45.6160344400735}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n\n    if self._retry is not None and self._retry.timeout != config.retry_timeout:\n        self._retry.timeout = config.retry_timeout\n\n    if self._loop_wait != config.loop_wait:\n        self._loop_wait = config.loop_wait\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.handler.connect_timeout = config.connect_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session_timeout:\n        self._session_timeout = config.session_timeout\n\n    if self._session_timeout != config.session", "CodeBleu_score": 26.784015449871546}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.copy()\n    else:\n        config = Config(config)\n    self.retry = config.retry\n    self.loop_wait = config.loop_wait\n    self.ttl = config.ttl\n    if isinstance(self.handler, PatroniSequentialThreadingHandler) and self.loop_wait != self.connect_timeout:\n        self.handler.connect_timeout = self.connect_timeout = self.loop_wait\n        if self.connected:\n            self.handler.close_zk()\n\n", "CodeBleu_score": 38.97256838117666}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, dict):\n        config = Config(config)\n    self._retry = config.retry\n    self._retry_timeout = config.retry_timeout\n    self._loop_wait = config.loop_wait\n    self._session_timeout = config.session_timeout\n    self._connect_timeout = config.connect_timeout\n    if self._handler.name == 'PatroniSequentialThreadingHandler':\n        self._handler.connect_timeout = self._connect_timeout\n    if self._session_timeout != self._session_expire_interval:\n        self._session_expire_interval = self._session_timeout\n        try:\n            self.retry(self.set_session_timeout, self._session_timeout)\n        except (ConnectionClosedError, SessionExpiredError):\n            if self._loop_wait != self._handler.timeout:\n                self._handler.close()\n                self._handler.timeout = self._loop_wait\n\n", "CodeBleu_score": 31.353400591785253}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n\n    # Check if the path exists\n    if not self.exists(path):\n        raise NoNodeError(path)\n\n    # Check if the path is a directory\n    if not self.is_dir(path):\n        raise NotADirectoryError(path)\n\n    # Get the cluster configuration\n    configuration = self.get_children(path + \"/config\")\n    if not configuration:\n        raise NoNodeError(path + \"/config\")\n\n    # Get the cluster initialization state\n    initialization_state = self.get_children(path + \"/init\")\n    if not initialization_state:\n        raise NoNodeError(path + \"/init\")\n\n    # Get the cluster timeline history\n    timeline_history = self.get_children(path + \"/timeline\")\n    if not timeline_history:\n        raise NoNodeError(path + \"/timeline\")\n\n    # Get the cluster synchronization state\n    synchronization_state = self.get_children(path + \"/sync\")\n    if not synchronization_state:\n        raise NoNodeError(path + \"/sync\")\n\n    # Get the cluster members\n    members = self.get_children(path + \"/members\")\n    if not members:\n        raise NoNodeError(path + \"/members\")\n\n    # Get the cluster leader information\n    leader = self.get_children(path + \"/leader\")\n    if not leader:\n        raise NoNodeError(path + \"/leader\")\n\n    # Get the cluster status\n    status = self.get_children(path + \"/status\")\n    if not status:\n        raise NoNodeError(path + \"/status\")\n\n    # Get the cluster failover state\n    failover = self.get_children(path + \"/failover\")\n    if not failover:\n        raise NoNodeError(path + \"/failover\")\n\n    # Get the cluster failsafe configuration\n    failsafe_configuration = self.get_children(path + \"/failsafe\")\n    if not failsafe_configuration:\n        raise NoNodeError(path + \"/failsafe\")\n\n    # Return the cluster\n    return Cluster(\n        self,\n        path,\n        configuration,\n        initialization_state,\n       ", "CodeBleu_score": 18.849733594466024}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    from .cluster import Cluster\n    from .config import Configuration\n    from .failover import Failover\n    from .fsm import FSM\n    from .history import TimelineHistory\n    from .initdb import InitDB\n    from .leader import Leader\n    from .member import Member\n    from .pg_rewind import PGrewind\n    from .synchronous import Synchronous\n    from .status import ClusterStatus\n    from .utils import ClusterError\n\n    # Create the cluster object\n    cluster = Cluster()\n\n    # Check if the cluster configuration exists\n    if not self.exists(path):\n        raise ClusterError(\"Cluster configuration does not exist\")\n\n    # Get the cluster configuration\n    cluster.config = Configuration(self.get(path)[0])\n\n    # Check if the initialization state exists\n    if self.exists(path + \"/initdb\"):\n        # Get the initialization state\n        cluster.initdb = InitDB(self.get(path + \"/initdb\")[0])\n\n    # Check if the timeline history exists\n    if self.exists(path + \"/history\"):\n        # Get the timeline history\n        cluster.history = TimelineHistory(self.get(path + \"/history\")[0])\n\n    # Check if the synchronization state exists\n    if self.exists(path + \"/sync\") and self.exists(path + \"/sync/state\"):\n        # Get the synchronization state\n        cluster.sync = Synchronous(self.get(path + \"/sync\")[0])\n\n    # Check if the members list exists\n    if self.exists(path + \"/members\"):\n        # Get the members list\n        members = self.get_children(path + \"/members\")\n\n        # Create the members list\n        cluster.members = {}\n\n        # Iterate over the members list\n        for member in members:\n            # Get the member configuration\n            member_config = self.get(path + \"/members/\" + member)[0]\n\n            # Create the member object\n            cluster.members[member] = Member(member_config)\n\n    # Check if the leader information exists\n    if self.exists(path + \"/leader\"):\n        # Get the leader information\n", "CodeBleu_score": 19.078528935045114}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    # TODO: Implement this function\n    pass\n\n", "CodeBleu_score": 0.8139927031915872}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    if self._closed:\n        raise ConnectionClosedError()\n    try:\n        self._retry(self.create, self._leader_path, b'', makepath=True, acl=self._acl)\n        self._is_leader = True\n        return True\n    except NodeExistsError:\n        self._is_leader = False\n        self._logger.info(\"Another instance has the leader lock\")\n        return False\n    except RetryFailedError as e:\n        self._is_leader = False\n        raise e\n\n", "CodeBleu_score": 39.134606327278135}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self._retry(self.create, self.leader_path, makepath=True)\n        return True\n    except (ConnectionClosedError, RetryFailedError) as e:\n        raise self.handler.zconn.lost_connection(e)\n    except NodeExistsError:\n        return False\n    except Exception as e:\n        if self.handler.event_object.stopped:\n            return False\n        self.handler.event_object.logger.exception(\"Unable to acquire leader lock\")\n        return False\n\n", "CodeBleu_score": 59.008755737052844}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.retry(self.client.create, self.path, self.ephemeral_owner, self.acls, self.sequence, self.makepath)\n        self.logger.debug(\"Acquired leader lock\")\n        return True\n    except (ConnectionClosedError, RetryFailedError):\n        raise\n    except Exception as e:\n        if isinstance(e, NodeExistsError):\n            self.logger.debug(\"Failed to acquire leader lock: %s\", e)\n            return False\n        self.logger.exception(\"Failed to acquire leader lock\")\n        raise\n\n", "CodeBleu_score": 51.76443653589886}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session != self.client_id[0]:\n        self.log.warning(\"Leader session ID mismatch: %s != %s\", leader.session, self.client_id[0])\n        try:\n            self.delete(leader.path, version=leader.version)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        return False\n    try:\n        self.create(leader.path, self.client_id[1], acl=leader.acl, ephemeral=True, sequence=True)\n    except (NoNodeError, ConnectionClosedError, RetryFailedError):\n        pass\n    return True\n\n", "CodeBleu_score": 31.33408534094545}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    # check if leader is stale\n    if leader.session != self.client_id[0]:\n        self.log.warning(\"Leader session is stale, attempting to delete leader ZNode\")\n        try:\n            self.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            pass\n        return False\n    # create new leader\n    try:\n        self.create(leader.path, self.client_id[0].encode(), makepath=True)\n    except Exception as e:\n        self.log.error(f\"Error creating leader ZNode: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 30.70480301320866}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.session != self.client_id[0]:\n        self.log.warning(\"Leader ZNode session ID does not match client session ID. Deleting leader ZNode.\")\n        try:\n            self.delete(leader.path)\n        except NoNodeError:\n            self.log.warning(\"Leader ZNode does not exist. Ignoring.\")\n        except ConnectionClosedError:\n            self.log.warning(\"Connection to ZooKeeper server closed. Ignoring.\")\n        except RetryFailedError:\n            self.log.warning(\"Retry failed. Ignoring.\")\n        except Exception as e:\n            self.log.exception(f\"Unhandled exception: {e}\")\n        return False\n    try:\n        self.create(leader.path, leader.name.encode(\"utf-8\"), makepath=True)\n    except NodeExistsError:\n        self.log.warning(\"Leader ZNode already exists. Ignoring.\")\n    except ConnectionClosedError:\n        self.log.warning(\"Connection to ZooKeeper server closed. Ignoring.\")\n    except RetryFailedError:\n        self.log.warning(\"Retry failed. Ignoring.\")\n    except Exception as e:\n        self.log.exception(f\"Unhandled exception: {e}\")\n        return False\n    return True\n\n", "CodeBleu_score": 48.025771917648804}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n    # Check if it's time to poll again\n    now = time.time()\n    if now - self.last_poll_time < self.poll_interval:\n        return False\n\n    # Query the exhibitors for their status\n    try:\n        status = self.exhibitors.get_status()\n    except Exception as e:\n        self.logger.error(f\"Failed to query the exhibitors for status: {e}\")\n        return False\n\n    # If the status is empty, we have a problem\n    if not status:\n        self.logger.error(f\"Failed to query the exhibitors for status: No status returned\")\n        return False\n\n    # Check if the connection string has changed\n    connection_string = self.exhibitors.get_connection_string(status)\n    if self.connection_string != connection_string:\n        self.logger.info(f\"ZooKeeper connection string changed from {self.connection_string} to {connection_string}\")\n        self.connection_string = connection_string\n        self.zookeeper.set_connection_string(self.connection_string)\n        return True\n\n    # No change occurred\n    return False\n\n", "CodeBleu_score": 31.77741192338608}, {"code": "def poll(self) -> bool\n\t\n    # check if it's time to poll\n    if self.poll_time > time.time():\n        return False\n\n    # query the exhibitors\n    exhibitors = self.query_exhibitors()\n\n    # if we got valid data, update the ZooKeeper connection string if it has changed\n    if exhibitors:\n        # update the ZooKeeper connection string if it has changed\n        if self.zookeeper_connection_string != self.get_zookeeper_connection_string(exhibitors):\n            self.zookeeper_connection_string = self.get_zookeeper_connection_string(exhibitors)\n            self.logger.info(\n                f\"Updated ZooKeeper connection string to {self.zookeeper_connection_string}\"\n            )\n\n        # update the internal state\n        self.exhibitors = exhibitors\n        self.poll_time = time.time() + self.poll_interval\n        return True\n\n    return False\n\n", "CodeBleu_score": 29.772770019733606}, {"code": "def poll(self) -> bool\n\t\n    if self.last_poll_time is None:\n        self.last_poll_time = time.time()\n\n    if time.time() - self.last_poll_time > self.poll_interval:\n        self.last_poll_time = time.time()\n        self.exhibitors = self.get_exhibitors()\n        if self.exhibitors:\n            self.update_connection_string()\n            return True\n\n    return False\n\n", "CodeBleu_score": 16.587803780731225}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    cluster = loader(path)\n    if self._ensemble_provider is not None:\n        self._update_hosts_with_zookeeper_hosts()\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 57.718292431331285}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n\n    # load cluster\n    cluster = loader(path)\n\n    # update client hosts\n    if self.zookeeper_hosts:\n        self.hosts = self.zookeeper_hosts\n\n    # load cluster\n    return super()._load_cluster(cluster)\n\n", "CodeBleu_score": 52.64334352001454}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self._ensemble_provider is not None:\n        self._ensemble_provider.update_hosts(self._hosts)\n\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 61.04751755551}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n\n    String group = getGroup();\n    String dataId = getDataId();\n\n    LOG.info(\"Destroying {}...\", getConfigType().toString());\n\n    try {\n        zookeeperListener.unsubscribeConfig(group, dataId);\n\n        LOG.info(\"Destroyed {}\", getConfigType().toString());\n    } catch (Exception e) {\n        LOG.error(\"Destroy {} failed\", getConfigType().toString(), e);\n    }\n}", "CodeBleu_score": 71.52575335310054}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n\n    String group = configType.toString();\n    String dataId = configType.toString();\n    LOG.info(\"Unsubscribing from Zookeeper config, group={}, dataId={}\", group, dataId);\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n    } catch (Exception e) {\n        LOG.error(\"Unsubscribe from Zookeeper config failed, group={}, dataId={}\", group, dataId, e);\n    }\n}", "CodeBleu_score": 54.4838244689275}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n\n    String group = configType.toString();\n    String dataId = getDataId();\n\n    LOG.info(\"Unsubscribe config from zookeeper, group={}, dataId={}\", group, dataId);\n\n    try {\n        zookeeperListener.unsubscribe(group, dataId);\n    } catch (Exception e) {\n        LOG.error(\"Unsubscribe config from zookeeper failed, group={}, dataId={}\", group, dataId, e);\n    }\n}", "CodeBleu_score": 55.379629256732656}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        ZookeeperRegistration registration = zookeeperServer.getPayload();\n        return registration.getMetadata();\n    }\n\n    return null;\n}", "CodeBleu_score": 63.66972774902724}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n        ZookeeperRegistration registration = zookeeperServer.getPayload();\n        return registration.getMetadata();\n    }\n\n    return AbstractPluginAdapter.EMPTY_METADATA;\n}", "CodeBleu_score": 61.72520108319326}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zookeeperServer = (ZookeeperServer) server;\n\n        ZookeeperRegistration zookeeperRegistration = zookeeperServer.getPayload();\n        if (zookeeperRegistration != null) {\n            return zookeeperRegistration.getMetadata();\n        }\n    }\n\n    return null;\n}", "CodeBleu_score": 59.53576577764108}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = ZK_PATH_SEPARATOR + group + ZK_PATH_SEPARATOR + serviceId;\n    NodeCache nodeCache = new NodeCache(curatorClient, path, false);\n    nodeCache.getListenable().addListener(new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            ChildData childData = nodeCache.getCurrentData();\n            if (childData == null) {\n                zookeeperSubscribeCallback.doSomething(null);\n                return;\n            }\n            String configInfo = new String(childData.getData());\n            ConfigInfo configInfo1 = JsonUtil.json2Object(configInfo, ConfigInfo.class);\n            zookeeperSubscribeCallback.doSomething(configInfo1);\n        }\n    });\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, path);\n    zookeeperListener.setZookeeperSubscribeCallback(zookeeperSubscribeCallback);\n    zookeeperListeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 57.82768553824883}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = getPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(curator, path);\n    nodeCache.getListenable().addListener(new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            ChildData data = nodeCache.getCurrentData();\n            if (data == null) {\n                return;\n            }\n            String config = new String(data.getData(), \"UTF-8\");\n            try {\n                zookeeperSubscribeCallback.callback(config);\n            } catch (Exception e) {\n                logger.error(\"Failed to process zookeeper config change event\", e);\n            }\n        }\n    });\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCache.getListenable());\n    addListener(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 65.17561895391904}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = ZookeeperPathUtils.getServiceConfigPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(curator, path);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            ChildData childData = nodeCache.getCurrentData();\n            if (childData == null) {\n                return;\n            }\n            String content = new String(childData.getData());\n            Config config = JsonUtils.toObject(content, Config.class);\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    addListener(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 64.36927674638542}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator decorator = new ZookeeperServerListDecorator(config, serviceDiscovery);\n    decorator.setLoadBalanceListenerExecutor(new LoadBalanceListenerExecutor());\n    decorator.setServiceId(config.getClientName());\n    return decorator;\n}", "CodeBleu_score": 52.22916939904363}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    return new ZookeeperServerListDecorator<>(config, serviceDiscovery);\n}", "CodeBleu_score": 17.132142081639877}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(config, serviceDiscovery);\n    serverList.setLoadBalanceListenerExecutor(loadBalanceListenerExecutor());\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 68.07755478412197}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = context.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 85.73497538641142}, {"code": "public void register(ZookeeperRegistration registration){\n\t    // \u8c03\u7528\u76d1\u542c\u5668\u7684onRegister\u65b9\u6cd5\n    if (applicationContext != null) {\n        try {\n            RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n            registerListenerExecutor.onRegister(registration);\n        } catch (BeansException e) {\n            // Ignore\n        }\n    }\n\n    // \u8c03\u7528ZookeeperServiceRegistry\u7684register\u65b9\u6cd5\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 77.7734427032269}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 91.46133830544045}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    ZookeeperServiceRegistry serviceRegistry = getServiceRegistry();\n    if (serviceRegistry != null) {\n        try {\n            ConfigurableApplicationContext applicationContext = serviceRegistry.getApplicationContext();\n            if (applicationContext != null) {\n                RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n                if (registerListenerExecutor != null) {\n                    registerListenerExecutor.onDeregister(registration);\n                }\n            }\n        } catch (BeansException e) {\n            // Ignore\n        }\n\n        serviceRegistry.deregister(registration);\n    }\n}", "CodeBleu_score": 64.39092722162604}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        ConfigurableApplicationContext applicationContext = getApplicationContext();\n        if (applicationContext != null) {\n            RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n            if (registerListenerExecutor != null) {\n                registerListenerExecutor.onDeregister(registration);\n            }\n        }\n    } catch (BeansException e) {\n        // Ignore\n    }\n\n    ZookeeperServiceRegistry serviceRegistry = getServiceRegistry();\n    if (serviceRegistry != null) {\n        serviceRegistry.deregister(registration);\n    }\n}", "CodeBleu_score": 64.18786920047252}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        LOG.debug(\"RegisterListenerExecutor not found, ignore it\", e);\n    }\n\n    serviceRegistry.deregister(registration);\n}", "CodeBleu_score": 77.11895734869707}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        // ignore\n    }\n\n    // \u5173\u95ed\u670d\u52a1\u6ce8\u518c\n    serviceRegistry.close();\n}", "CodeBleu_score": 97.49455430206703}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        LOG.error(\"RegisterListenerExecutor not found\", e);\n    }\n\n    try {\n        ZookeeperServiceRegistry serviceRegistry = applicationContext.getBean(ZookeeperServiceRegistry.class);\n        serviceRegistry.close();\n    } catch (BeansException e) {\n        LOG.error(\"ZookeeperServiceRegistry not found\", e);\n    }\n\n    try {\n        ZookeeperRegistration registration = applicationContext.getBean(ZookeeperRegistration.class);\n        registration.close();\n    } catch (BeansException e) {\n        LOG.error(\"ZookeeperRegistration not found\", e);\n    }\n\n    try {\n        ConfigurableApplicationContext applicationContext = applicationContext.getParent();\n        applicationContext.close();\n    } catch (Exception e) {\n        LOG.error(\"ConfigurableApplicationContext not found\", e);\n    }\n}", "CodeBleu_score": 70.52269575034902}, {"code": "public void close(){\n\t    ConfigurableApplicationContext applicationContext = getApplicationContext();\n    if (applicationContext != null) {\n        try {\n            RegisterListenerExecutor registerListenerExecutor = applicationContext.getBean(RegisterListenerExecutor.class);\n            registerListenerExecutor.onClose();\n        } catch (BeansException e) {\n            // Ignore\n        }\n    }\n\n    try {\n        ((ZookeeperServiceRegistry) serviceRegistry).close();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to close service registry\", e);\n    }\n}", "CodeBleu_score": 72.85519667841794}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = configAdapter.getGroup();\n    String dataId = configAdapter.getDataId(globalConfig);\n\n    ZookeeperListener listener = null;\n    try {\n        logSubscribeStart(group, dataId);\n\n        listener = zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n            @Override\n            public void callback(String config) {\n                logSubscribeCallback(group, dataId, config);\n\n                String oldConfig = configAdapter.getConfig();\n                configAdapter.setConfig(config);\n\n                if (!config.equals(oldConfig)) {\n                    logSubscribeChanged(group, dataId, config);\n\n                    configAdapter.onConfigChanged(config);\n                }\n            }\n        });\n\n        logSubscribeSuccess(group, dataId);\n    } catch (Exception e) {\n        logSubscribeFailed(group, dataId, e);\n    }\n\n    return listener;\n}", "CodeBleu_score": 47.04745984235317}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = getGroup();\n    String dataId = getDataId(globalConfig);\n\n    LOG.info(\"Subscribing to configuration group={}, dataId={}\", group, dataId);\n\n    ZookeeperListener listener = null;\n    try {\n        listener = zookeeperOperation.subscribeData(group, dataId, new ZookeeperSubscribeCallback() {\n            @Override\n            public void callback(String config) {\n                try {\n                    ConfigAdapter configAdapter = getConfigAdapter();\n                    configAdapter.updateConfig(config);\n                } catch (Exception e) {\n                    LOG.error(\"Failed to update config, group={}, dataId={}\", group, dataId, e);\n                }\n            }\n        });\n    } catch (Exception e) {\n        LOG.error(\"Failed to subscribe config, group={}, dataId={}\", group, dataId, e);\n    }\n\n    return listener;\n}", "CodeBleu_score": 50.67167398323058}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = configAdapter.getGroup();\n    String dataId = configAdapter.getDataId(globalConfig);\n\n    logSubscribeStart(group, dataId);\n\n    ZookeeperListener zookeeperListener = null;\n    try {\n        zookeeperListener = zookeeperOperation.subscribeConfig(group, dataId, new ZookeeperSubscribeCallback() {\n            @Override\n            public void callback(String config) {\n                callbackConfig(config, globalConfig);\n            }\n        });\n    } catch (Exception e) {\n        logSubscribeFailure(group, dataId, e);\n    }\n\n    return zookeeperListener;\n}", "CodeBleu_score": 62.95627514921984}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    String zkAddress = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_ADDRESS);\n    if (StringUtils.isEmpty(zkAddress)) {\n        throw new DiscoveryException(\"Zookeeper address is null or empty\");\n    }\n\n    int sessionTimeout = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SESSION_TIMEOUT, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SESSION_TIMEOUT_VALUE);\n    int connectionTimeout = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_CONNECTION_TIMEOUT, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_CONNECTION_TIMEOUT_VALUE);\n    int baseSleepTime = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_BASE_SLEEP_TIME, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_BASE_SLEEP_TIME_VALUE);\n    int maxRetries = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_MAX_RETRIES, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_MAX_RETRIES_VALUE);\n\n    CuratorFramework curatorFramework = CuratorFrameworkFactory.builder()\n            .connectString(zkAddress)\n            .sessionTimeoutMs(sessionTimeout)\n            .connectionTimeoutMs(connectionTimeout)\n            .retryPolicy(new ExponentialBackoffRetry(baseSleepTime, maxRetries))\n            .build();", "CodeBleu_score": 54.81300995928382}, {"code": "public CuratorFramework curatorFramework(){\n\t    String zookeeperAddress = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_ADDRESS);\n    if (StringUtils.isEmpty(zookeeperAddress)) {\n        throw new DiscoveryException(\"Zookeeper address is null or empty\");\n    }\n\n    int retryCount = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_RETRY_COUNT, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_RETRY_COUNT_VALUE);\n    int sleepTime = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SLEEP_TIME, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SLEEP_TIME_VALUE);\n    int connectionTimeout = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_CONNECTION_TIMEOUT, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_CONNECTION_TIMEOUT_VALUE);\n    int sessionTimeout = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SESSION_TIMEOUT, Integer.class, ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_SESSION_TIMEOUT_VALUE);\n\n    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n    builder.connectString(zookeeperAddress);\n    builder.retryPolicy(new ExponentialBackoffRetry(sleepTime, retryCount));\n    builder.connectionTimeoutMs(connectionTimeout);\n    builder.sessionTimeoutMs(sessionTimeout);\n\n    CuratorFramework", "CodeBleu_score": 54.91887826838659}, {"code": "public CuratorFramework curatorFramework(){\n\t    String zkAddress = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_ADDRESS);\n    if (StringUtils.isEmpty(zkAddress)) {\n        throw new DiscoveryException(\"Zookeeper address is null or empty\");\n    }\n\n    int baseSleepTimeMs = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_RETRY_SLEEP_TIME, Integer.class, ZookeeperConstant.DEFAULT_ZOOKEEPER_RETRY_SLEEP_TIME);\n    int maxRetries = environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_RETRY_TIMES, Integer.class, ZookeeperConstant.DEFAULT_ZOOKEEPER_RETRY_TIMES);\n\n    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n    builder.connectString(zkAddress);\n    builder.retryPolicy(new ExponentialBackoffRetry(baseSleepTimeMs, maxRetries));\n    builder.namespace(environment.getProperty(ZookeeperConstant.SPRING_APPLICATION_REGISTER_CONTROL_ZOOKEEPER_NAMESPACE, String.class, ZookeeperConstant.DEFAULT_ZOOKEEPER_NAMESPACE));\n\n    CuratorFramework curatorFramework = builder.build();\n    curatorFramework.start();\n\n    return curatorFramework;\n}", "CodeBleu_score": 56.14878789969092}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t    @Bean\n    @ConditionalOnMissingBean\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n        return new GatewayStrategyRouteZookeeperProcessor();\n    }\n}", "CodeBleu_score": 33.12836865667273}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t    @Bean\n    @ConditionalOnMissingBean\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(ConfigurableEnvironment environment, ZookeeperProcessor zookeeperProcessor) {\n        return new GatewayStrategyRouteZookeeperProcessor(environment, zookeeperProcessor);\n    }\n}", "CodeBleu_score": 20.287248447713775}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n    @Bean\n    @ConditionalOnMissingBean\n    public GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n        return new GatewayStrategyRouteZookeeperProcessor();\n    }\n}", "CodeBleu_score": 33.207374987692916}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    CuratorFramework client = CuratorFrameworkFactory.newClient(\n        zookeeperHosts,\n        sessionTimeout,\n        connectionTimeout,\n        retryPolicy);\n    client.start();\n    return client;\n}", "CodeBleu_score": 34.522912740930316}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n    builder.connectString(zkHosts);\n    builder.sessionTimeoutMs(zkSessionTimeout);\n    builder.namespace(zkNamespace);\n    builder.retryPolicy(retryPolicy);\n    CuratorFramework curatorFramework = builder.build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 33.10663182884224}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    RetryPolicy retryPolicy = new ExponentialBackoffRetry(1000, 3);\n    CuratorFrameworkFactory.Builder builder = CuratorFrameworkFactory.builder();\n    builder = builder.connectString(zooKeeperHosts).sessionTimeoutMs(sessionTimeout).namespace(namespace).retryPolicy(retryPolicy);\n    CuratorFramework curatorFramework = builder.build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 53.97666670100521}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessLock lock = locksMap.get(path);\n    if (lock == null) {\n        lock = new InterProcessMutex(client, path);\n        try {\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Failed to acquire lock for path \" + path, e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(\"Failed to re-acquire lock for path \" + path, e);\n        }\n    }\n}", "CodeBleu_score": 37.3000991575802}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    if (path == null) {\n        throw new DistributedLockException(\"path is null\");\n    }\n\n    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        try {\n            lock = new InterProcessMutex(client, path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(e);\n        }\n    }\n}", "CodeBleu_score": 36.64721079325394}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    InterProcessMutex lock = locksMap.get(path);\n    if (lock == null) {\n        try {\n            lock = new InterProcessMutex(client, path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(e);\n        }\n    } else {\n        try {\n            lock.acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(e);\n        }\n    }\n}", "CodeBleu_score": 33.87694622209257}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    val zkConfig = dtpProperties.getZkConfig();\n    val curatorFramework = CuratorFrameworkFactory.builder()\n        .connectString(zkConfig.getZkServerList())\n        .retryPolicy(new ExponentialBackoffRetry(zkConfig.getBaseSleepTimeMs(), zkConfig.getMaxRetries(), zkConfig.getMaxSleepMs()))\n        .sessionTimeoutMs(zkConfig.getSessionTimeoutMs())\n        .connectionTimeoutMs(zkConfig.getConnectionTimeoutMs())\n        .namespace(zkConfig.getNamespace())\n        .build();\n    curatorFramework.start();\n    curatorFramework.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(final CuratorFramework client, final ConnectionState newState) {\n            if (newState == ConnectionState.LOST) {\n                client.close();\n            }\n        }\n    });\n    val configFileType = dtpProperties.getConfigFileType();\n    val configPath = ZKPaths.makePath(zkConfig.getRootNodePath(), dtpProperties.getConfigPath());\n    val propertiesMap = Maps.newHashMap();\n    if (PROPERTIES.equals(configFileType)) {\n        propertiesMap.putAll(genPropertiesTypeMap(curatorFramework, configPath));\n    } else if (JSON.equals(configFileType)) {\n        val configKeys = getConfigKeys(curatorFramework, configPath);\n        for (val configKey : configKeys) {\n            val nodePath = ZKPaths.makePath(configPath, configKey);\n            val data = getData(curatorFramework, nodePath);\n            if (data == null) {\n                continue;\n            }\n            propertiesMap.putAll(ConfigHandler.parse(data));\n        }\n    }\n    return propertiesMap;\n}", "CodeBleu_score": 40.79061659549032}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    val zkConfig = dtpProperties.getZkConfig();\n    val curatorFramework = CuratorFrameworkFactory.builder().connectString(zkConfig.getZkAddress()).namespace(zkConfig.getNamespace()).retryPolicy(new ExponentialBackoffRetry(1000, 3)).build();\n    curatorFramework.start();\n    curatorFramework.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState newState) {\n            if (newState.isConnected()) {\n                log.info(\"zookeeper connection state changed to CONNECTED\");\n            } else {\n                log.info(\"zookeeper connection state changed to DISCONNECTED\");\n            }\n        }\n    });\n    val configFileType = dtpProperties.getConfigFileType();\n    val configMap = Maps.newConcurrentMap();\n    val configKey = dtpProperties.getConfigKey();\n    if (PROPERTIES.equals(configFileType)) {\n        configMap.putAll(genPropertiesTypeMap(curatorFramework, configKey));\n    } else if (JSON.equals(configFileType)) {\n        configMap.putAll(ConfigHandler.parse(curatorFramework.getData().forPath(ZKPaths.makePath(configKey, dtpProperties.getConfigKey()))));\n    }\n    return configMap;\n}", "CodeBleu_score": 41.06359922169253}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    val curatorFramework = getCuratorFramework(dtpProperties);\n    val configFileTypeEnum = dtpProperties.getConfigFileTypeEnum();\n    val nodePath = ZKPaths.makePath(dtpProperties.getConfigPath(), dtpProperties.getConfigKey());\n    if (PROPERTIES == configFileTypeEnum) {\n        return genPropertiesTypeMap(curatorFramework, nodePath);\n    }\n    if (JSON == configFileTypeEnum) {\n        return ConfigHandler.parse(new String(curatorFramework.getData().forPath(nodePath), StandardCharsets.UTF_8));\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 40.9453525947654}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    // \u83b7\u53d6\u914d\u7f6e\u6587\u4ef6\n    DtpProperties dtpProperties = BinderHelper.bind(environment, DtpProperties.PREFIX, DtpProperties.class);\n    // \u83b7\u53d6\u914d\u7f6e\u6587\u4ef6\u4e2d\u7684\u914d\u7f6e\n    Map<String, Object> map = dtpProperties.getConfig();\n    // \u5224\u65ad\u662f\u5426\u9700\u8981\u4eceZookeeper\u4e2d\u83b7\u53d6\u914d\u7f6e\n    if (dtpProperties.getConfigFromZookeeper()) {\n        // \u4eceZookeeper\u4e2d\u83b7\u53d6\u914d\u7f6e\n        Map<String, Object> zookeeperMap = CuratorUtil.getZookeeperConfig(dtpProperties.getZookeeperConfig());\n        // \u5408\u5e76\u914d\u7f6e\n        map.putAll(zookeeperMap);\n    }\n    // \u83b7\u53d6\u5f53\u524d\u73af\u5883\n    MutablePropertySources propertySources = environment.getPropertySources();\n    // \u83b7\u53d6\u5f53\u524d\u73af\u5883\u4e2d\u7684\u914d\u7f6e\u6e90\n    OriginTrackedMapPropertySource originTrackedMapPropertySource = (OriginTrackedMapPropertySource) propertySources.get(OriginTrackedMapPropertySource.class.getName());\n    // \u5224\u65ad\u5f53\u524d\u73af\u5883\u4e2d\u662f\u5426\u5b58\u5728\u914d\u7f6e\u6e90\n    if (originTrackedMapPropertySource == null) {\n        // \u4e0d\u5b58\u5728\u5219\u521b\u5efa\n        originTrackedMapPropertySource = new OriginTrackedMapPropertySource(OriginTrackedMapPropertySource.class.getName(), map);\n        // \u6dfb\u52a0\u5230\u5f53\u524d\u73af\u5883\u4e2d\n        propertySources.addFirst(originTrackedMapPropertySource);\n    } else {\n        // \u5b58\u5728\u5219\u5408\u5e76\n        originTrackedMapPropertySource.getSource().putAll(map);\n    }\n}", "CodeBleu_score": 38.36286504585641}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    log.info(\"Dynamictp environment post-processor start...\");\n    DtpProperties dtpProperties = BinderHelper.bind(environment, DtpProperties.class);\n    if (dtpProperties == null) {\n        log.info(\"Dynamictp environment post-processor end...\");\n        return;\n    }\n    Map<String, Object> properties = dtpProperties.toMap();\n    if (properties.isEmpty()) {\n        log.info(\"Dynamictp environment post-processor end...\");\n        return;\n    }\n    MutablePropertySources propertySources = environment.getPropertySources();\n    OriginTrackedMapPropertySource originTrackedMapPropertySource = new OriginTrackedMapPropertySource(DTP_PROPERTY_SOURCE_NAME, properties);\n    propertySources.addLast(originTrackedMapPropertySource);\n    if (!environment.containsProperty(DTP_ENABLE_KEY)) {\n        CuratorUtil.createDtpProperties(dtpProperties, environment);\n    }\n    log.info(\"Dynamictp environment post-processor end...\");\n}", "CodeBleu_score": 43.588400494042155}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    // \u83b7\u53d6DtpProperties\u5b9e\u4f8b\n    DtpProperties properties = BinderHelper.getDtpProperties(environment);\n    // \u7ed1\u5b9aDtpProperties\u5230\u5f53\u524d\u73af\u5883\n    BinderHelper.bind(environment, properties);\n    // \u4eceDtpProperties\u751f\u6210properties\n    Map<String, Object> propertiesMap = BinderHelper.getPropertiesMap(properties);\n    // \u68c0\u67e5\u662f\u5426\u5b58\u5728\u5fc5\u8981\u7684\u5c5e\u6027\n    if (!environment.containsProperty(propertiesMap.get(DtpProperties.DTP_NAMESPACE).toString())) {\n        // \u521b\u5efaZookeeper\u5c5e\u6027\u6e90\n        CuratorUtil.createZookeeperPropertySource(environment, propertiesMap);\n    }\n}", "CodeBleu_score": 46.333228905995455}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ConfigInfo>>();\n        var config = new ZookeeperConfig();\n        configInfo.CopyTo(config);\n        return config;\n    }).AsSelf().SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperClientProvider>>();\n        var config = provider.Resolve<ZookeeperConfig>();\n        var zookeeperClient = new ZookeeperClientProvider(config);\n        return zookeeperClient;\n    }).AsSelf().SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceCommandProvider>>();\n        var config = provider.Resolve<ZookeeperConfig>();\n        var zookeeperClient = provider.Resolve<ZookeeperClientProvider>();\n        var zookeeperServiceCommandProvider = new ZookeeperServiceCommandProvider(config, zookeeperClient);\n        return zookeeperServiceCommandProvider;\n    }).AsSelf().SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceSubscribeManager>>();\n        var config = provider.Resolve<ZookeeperConfig>();\n        var zookeeperClient = provider.Resolve<ZookeeperClientProvider>();\n        var zookeeperServiceSubscribeManager = new ZookeeperServiceSubscribeManager(config, zookeeperClient);\n        return zookeeperServiceSubscribeManager;\n    }).AsSelf().SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceRouteFactory>>();\n        var config = provider.Resolve<ZookeeperConfig>();\n        var zookeeperClient = provider.Resolve<ZookeeperClientProvider>();\n        var zookeeperServiceRouteFactory = new ZookeeperServiceRouteFactory(config, zookeeperClient);\n        return zookeeperServiceRouteFactory;\n    }).AsSelf().SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceRouteManager>>();\n        var zookeeperServiceRouteFactory = provider.Resolve<ZookeeperServiceRouteFactory>();\n        var zoo", "CodeBleu_score": 35.05532467170296}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var section = CPlatform.AppConfig.GetSection(\"ZooKeeper\");\n    var zooKeeperConfig = section.Get<ZooKeeperConfiguration>();\n    zooKeeperConfig.ConfigInfo = configInfo;\n    zooKeeperConfig.NodeId = CPlatform.AppConfig.ServerOptions.NodeId;\n    zooKeeperConfig.NodeName = CPlatform.AppConfig.ServerOptions.NodeName;\n    zooKeeperConfig.NodeIPAddress = CPlatform.AppConfig.ServerOptions.NodeIPAddress;\n    zooKeeperConfig.NodeIP = CPlatform.AppConfig.ServerOptions.NodeIP;\n    zooKeeperConfig.DataChanged += (sender, e) =>\n    {\n        if (e.Data != null)\n        {\n            var route = e.Data.ToObject<ServiceRoute>();\n            if (route != null)\n            {\n                CPlatform.RouteManager.TryUpdateRoute(route);\n            }\n        }\n    };\n    builder.Register(provider => zooKeeperConfig).AsSelf().SingleInstance();\n    builder.Register(provider => new ZookeeperClientProvider(zooKeeperConfig)).As<IZookeeperClientProvider>().SingleInstance();\n    builder.Register(provider => new ZookeeperServiceRouteManager(provider.Resolve<IZookeeperClientProvider>(), zooKeeperConfig)).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 27.034253964165323}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<DefaultRouteFactory>>();\n        var serializer = provider.Resolve<ISerializer<byte[]>>();\n        var factory = new DefaultRouteFactory(serializer, logger);\n        return factory;\n    }).As(typeof(IRouteFactory)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<DefaultServiceCommandFactory>>();\n        var serializer = provider.Resolve<ISerializer<string>>();\n        var factory = new DefaultServiceCommandFactory(serializer, logger);\n        return factory;\n    }).As(typeof(IServiceCommandFactory)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<DefaultServiceHealthCheck>>();\n        var factory = new DefaultServiceHealthCheck(logger);\n        return factory;\n    }).As(typeof(IServiceHealthCheck)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceSubscriber>>();\n        var factory = new ZookeeperServiceSubscriber(logger, configInfo);\n        return factory;\n    }).As(typeof(IServiceSubscriber)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServicePublisher>>();\n        var factory = new ZookeeperServicePublisher(logger, configInfo);\n        return factory;\n    }).As(typeof(IServicePublisher)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServiceSubscriber>>();\n        var factory = new ZookeeperServiceSubscriber(logger, configInfo);\n        return factory;\n    }).As(typeof(IServiceSubscriber)).SingleInstance();\n\n    builder.Register(provider => {\n        var logger = provider.Resolve<ILogger<ZookeeperServicePublisher>>();\n        var factory = new ZookeeperServicePublisher(logger, configInfo);\n        return factory;\n    }).As(typeof(IServicePublisher)).SingleInstance", "CodeBleu_score": 43.41584310835487}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n \n", "CodeBleu_score": 8.618059401316474}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var config = new ZookeeperConfig(configInfo);\n    builder.Register(provider => new DefaultServiceCommandManager(\n        provider.Resolve<IServiceCommandProvider>(),\n        provider.Resolve<ILogger<DefaultServiceCommandManager>>(),\n        provider.Resolve<ISerializer<byte[]>>(),\n        provider.Resolve<ISerializer<string>>(),\n        provider.Resolve<ISerializer<RemoteInvokeMessage>>(),\n        provider.Resolve<ISerializer<RemoteResultMessage>>(),\n        provider.Resolve<ISerializer<ExceptionMessage>>(),\n        provider.Resolve<ISerializer<GatewayAddress>>(),\n        provider.Resolve<ISerializer<ServiceCommandDescriptor>>(),\n        provider.Resolve<ISerializer<ServiceCommand>>(),\n        provider.Resolve<ISerializer<ServiceCommandResult>>(),\n        provider.Resolve<ISerializer<HeartbeatMessage>>(),\n        provider.Resolve<ISerializer<HeartbeatResultMessage>>(),\n        provider.Resolve<ISerializer<SubscribeMessage>>(),\n        provider.Resolve<ISerializer<SubscribeResultMessage>>(),\n        provider.Resolve<ISerializer<UnsubscribeMessage>>(),\n        provider.Resolve<ISerializer<UnsubscribeResultMessage>>(),\n        provider.Resolve<ISerializer<DiscoveryMessage>>(),\n        provider.Resolve<ISerializer<DiscoveryResultMessage>>(),\n        provider.Resolve<ISerializer<NotifyMessage>>(),\n        provider.Resolve<ISerializer<NotifyResultMessage>>(),\n        provider.Resolve<ISerializer<NotifyCollectionMessage>>(),\n        provider.Resolve<ISerializer<NotifyCollectionResultMessage>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider.Resolve<ISerializer<WatcherChangeArgs>>(),\n        provider", "CodeBleu_score": 45.65887641136639}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    if (builder == null)\n        throw new ArgumentNullException(nameof(builder));\n    if (configInfo == null)\n        throw new ArgumentNullException(nameof(configInfo));\n    builder.Register(provider => new ZookeeperServiceCommandManager(\n        provider.Resolve<IServiceCommandProvider>(),\n        provider.Resolve<ISerializer<byte[]>>(),\n        configInfo,\n        provider.Resolve<ILogger<ZookeeperServiceCommandManager>>(),\n        provider.Resolve<ILoggerFactory>()\n    ))\n    .As<IServiceCommandManager>()\n    .SingleInstance();\n    return this;\n}", "CodeBleu_score": 54.55808052417274}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tif (builder == null) {\n\t\tthrow new ArgumentNullException(nameof(builder))\n\t}\n\tif (string.IsNullOrEmpty(path)) {\n\t\tthrow new ArgumentException(\"File path must be a non-empty string.\", nameof(path))\n\t}\n\tif (provider == null && Path.IsPathRooted(path)) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path))\n\t}\n\treturn builder.AddZookeeperFile(s => {\n\t\ts.FileProvider = provider\n\t\ts.Path = path\n\t\ts.Optional = optional\n\t\ts.ReloadOnChange = reloadOnChange\n\t\ts.ResolveFileProvider()\n\t})\n}", "CodeBleu_score": 44.836742357656355}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"Zookeeper configuration path is required.\", nameof(path));\n    }\n\n    return builder.AddZookeeperFile(s => {\n        s.FileProvider = provider;\n        s.Path = path;\n        s.Optional = optional;\n        s.ReloadOnChange = reloadOnChange;\n        s.ResolveFileProvider();\n    });\n}", "CodeBleu_score": 35.12184511548435}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (string.IsNullOrEmpty(path)) {\n        throw new ArgumentException(\"File path must be a non-empty string.\", nameof(path));\n    }\n\n    return builder.AddZookeeperFile(s => {\n        s.FileProvider = provider;\n        s.Path = path;\n        s.Optional = optional;\n        s.ReloadOnChange = reloadOnChange;\n        s.ResolveFileProvider();\n    });\n}", "CodeBleu_score": 34.635654832905495}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tif (Address == null || !Address.Any())\n\t\treturn;\n\tvar routes = await GetRoutesAsync();\n\tforeach (var route in routes) {\n\t\troute.Address = route.Address.Except(Address).ToList();\n\t}\n\tawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 69.25045163653878}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    var newRoutes = routes.Select(route => {\n        var newAddress = route.Address.Except(Address).ToList();\n        return new ServiceRouteDescriptor\n        {\n            ServiceDescriptor = route.ServiceDescriptor,\n            Address = newAddress\n        };\n    });\n    await SetRoutesAsync(newRoutes);\n}", "CodeBleu_score": 34.81815255633221}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\tif (Address == null) {\n\t\treturn;\n\t}\n\tvar routes = await GetRoutesAsync();\n\tforeach (var route in routes) {\n\t\tvar newAddress = route.Address.Except(Address);\n\t\troute.Address = newAddress.ToList();\n\t}\n\tawait SetRoutesAsync(routes);\n}", "CodeBleu_score": 60.047015779729186}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = ZooKeeperPathManager.GetRoutePath(hostAddr);\n    var clients = await _zookeeperClientProvider.GetZooKeeperClients();\n    foreach (var client in clients) {\n        var currentRoutes = await GetRoutesAsync(client, routePath);\n        var routesToDelete = currentRoutes.Except(routes).ToArray();\n        if (routesToDelete.Length > 0) {\n            var addressPaths = routesToDelete.Select(p => ZooKeeperPathManager.GetAddressPath(p.ServiceDescriptor.Id, p.Address, hostAddr)).ToArray();\n            var routePaths = routesToDelete.Select(p => ZooKeeperPathManager.GetRoutePath(p.ServiceDescriptor.Id, hostAddr)).ToArray();\n            var deleteAddressTasks = addressPaths.Select(p => client.DeleteAsync(p));\n            var deleteRouteTasks = routePaths.Select(p => client.DeleteAsync(p));\n            await Task.WhenAll(deleteAddressTasks.Concat(deleteRouteTasks));\n        }\n    }\n}", "CodeBleu_score": 32.95739522967763}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var path = await _configInfo.GetRoutePathAsync();\n    var clients = await _zookeeperClientProvider.GetZooKeeperClientsAsync();\n    foreach (var client in clients) {\n        var children = await client.GetChildrenAsync(path);\n        foreach (var child in children) {\n            var route = await GetRouteFromZookeeper(client, path, child);\n            if (route != null && routes.All(p => p.ServiceDescriptor.Id != route.ServiceDescriptor.Id)) {\n                if (route.Address.Any(p => p.Host == hostAddr.Host && p.Port == hostAddr.Port)) {\n                    await client.DeleteRecursiveAsync(path + \"/\" + child);\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 39.37857793948608}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routePath = _zookeeperNodeManager.GetRoutePath();\n    var clients = await _zookeeperClientProvider.GetZooKeeperClients();\n    foreach (var client in clients) {\n        var currentRoutes = await client.GetChildrenAsync(routePath);\n        var exceptRoutes = routes.Select(p => p.RoutePath).ToArray();\n        var deleteRoutes = currentRoutes.Except(exceptRoutes).ToArray();\n        foreach (var deleteRoute in deleteRoutes) {\n            var route = await client.GetDataAsync(deleteRoute);\n            var serviceRoute = _serializer.Deserialize<ServiceRoute>(route);\n            if (serviceRoute.Address.Any(p => p.IpAddress == hostAddr.Ip && p.Port == hostAddr.Port)) {\n                await client.DeleteAsync(deleteRoute);\n            }\n        }\n    }\n}", "CodeBleu_score": 36.37940205462279}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"\u51c6\u5907\u5c06\u8def\u7531\u4fe1\u606f\u53cd\u5e8f\u5217\u5316\u4e3a\u5bf9\u8c61\uff0c\u6570\u636e\uff1a{Encoding.UTF8.GetString(data)}\");\n    }\n    var descriptor = await _serializer.DeserializeAsync<ServiceRouteDescriptor>(data);\n    if (descriptor == null) {\n        return null;\n    }\n    var routes = await _serviceRouteFactory.CreateServiceRoutesAsync(descriptor);\n    if (routes == null || routes.Count() == 0) {\n        return null;\n    }\n    return routes.First();\n}", "CodeBleu_score": 40.26705542493778}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Receive route changed,route data: {Encoding.UTF8.GetString(data)}\");\n    }\n    var descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n    return await _serviceRouteFactory.CreateServiceRoute(descriptor);\n}", "CodeBleu_score": 38.60190478180163}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Get route data,data: {Encoding.UTF8.GetString(data)}\");\n    }\n    var descriptor = _serializer.Deserialize<ServiceRouteDescriptor>(data);\n    return await Task.FromResult(new ServiceRoute(_serviceRouteFactory.Create(descriptor)));\n}", "CodeBleu_score": 38.14142517515782}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (oldData == null) {\n\t\toldData = new byte[0];\n\t}\n\tif (newData == null) {\n\t\tnewData = new byte[0];\n\t}\n\tif (oldData.Length == newData.Length && oldData.SequenceEqual(newData)) {\n\t\treturn;\n\t}\n\tvar newRoute = _serializer.Deserialize<ServiceRoute>(newData);\n\tvar oldRoute = _serializer.Deserialize<ServiceRoute>(oldData);\n\tif (newRoute.Equals(oldRoute)) {\n\t\treturn;\n\t}\n\tif (newRoute.Status == Status.Running) {\n\t\tvar oldRoute = _routes.Where(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (oldRoute != null) {\n\t\t\tvar serviceDescriptor = oldRoute.ServiceDescriptor;\n\t\t\tvar addressModel = oldRoute.Address;\n\t\t\tawait _watchManager.RemoveWatcherAsync(serviceDescriptor, addressModel);\n\t\t\t_routes.Remove(oldRoute);\n\t\t}\n\t\t_routes.Add(newRoute);\n\t\tawait _watchManager.AddWatcherAsync(newRoute);\n\t}\n\telse {\n\t\tvar oldRoute = _routes.Where(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id).FirstOrDefault();\n\t\tif (oldRoute != null) {\n\t\t\tvar serviceDescriptor = oldRoute.ServiceDescriptor;\n\t\t\tvar addressModel = oldRoute.Address;\n\t\t\tawait _watchManager.RemoveWatcherAsync(serviceDescriptor, addressModel);\n\t\t\t_routes.Remove(oldRoute);\n\t\t}\n\t}\n\tOnChanged(new RouteEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 33.95276124688565}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (oldData == null && newData == null) {\n\t\treturn;\n\t}\n\tvar oldRoute = oldData == null ? null : _serializer.Deserialize<ServiceRoute>(oldData);\n\tvar newRoute = newData == null ? null : _serializer.Deserialize<ServiceRoute>(newData);\n\tif (oldRoute != null && newRoute != null && Equals(oldRoute, newRoute)) {\n\t\treturn;\n\t}\n\tvar oldRoutes = oldRoute == null ? new List<ServiceRoute>() : new List<ServiceRoute>() { oldRoute };\n\tvar newRoutes = newRoute == null ? new List<ServiceRoute>() : new List<ServiceRoute>() { newRoute };\n\tvar routes = new List<ServiceRoute>();\n\tlock (_routes) {\n\t\tvar routesToRemove = oldRoutes.Where(p => _routes.Any(r => r.ServiceDescriptor.Id == p.ServiceDescriptor.Id)).ToList();\n\t\tvar routesToAdd = newRoutes.Where(p => !_routes.Any(r => r.ServiceDescriptor.Id == p.ServiceDescriptor.Id)).ToList();\n\t\troutes.AddRange(routesToRemove);\n\t\troutes.AddRange(routesToAdd);\n\t\t_routes.RemoveAll(p => routesToRemove.Any(r => r.ServiceDescriptor.Id == p.ServiceDescriptor.Id));\n\t\t_routes.AddRange(routesToAdd);\n\t}\n\tawait Task.WhenAll(routes.Select(async route => await OnChanged(new ServiceRouteEventArgs(route, oldRoutes.FirstOrDefault(p => p.ServiceDescriptor.Id == route.ServiceDescriptor.Id)))));\n}", "CodeBleu_score": 31.378996463563443}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t\tif (newData == null) {\n\t\treturn;\n\t}\n\tif (oldData != null && newData != null && Encoding.UTF8.GetString(oldData) == Encoding.UTF8.GetString(newData)) {\n\t\treturn;\n\t}\n\tvar newRoute = _serializer.Deserialize<ServiceRoute>(newData);\n\tif (newRoute == null) {\n\t\treturn;\n\t}\n\tvar oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id == newRoute.ServiceDescriptor.Id);\n\tif (oldRoute != null) {\n\t\tlock (_routes) {\n\t\t\tvar index = _routes.IndexOf(oldRoute);\n\t\t\tif (index >= 0) {\n\t\t\t\t_routes.RemoveAt(index);\n\t\t\t\t_routes.Insert(index, newRoute);\n\t\t\t}\n\t\t}\n\t\tif (oldRoute.Address != newRoute.Address) {\n\t\t\tawait OnChanged(newRoute, oldRoute);\n\t\t}\n\t}\n\telse {\n\t\tlock (_routes) {\n\t\t\t_routes.Add(newRoute);\n\t\t}\n\t\tawait OnChanged(newRoute, null);\n\t}\n}", "CodeBleu_score": 37.75370040975879}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tif (subscribers == null || !subscribers.Any())\n\t\treturn;\n\tvar oldSubscribers = await GetSubscribersAsync();\n\tvar newSubscribers = new List<ServiceSubscriber>();\n\tforeach (var subscriber in subscribers) {\n\t\tvar oldSubscriber = oldSubscribers.FirstOrDefault(p => p.Descriptor.Id == subscriber.Descriptor.Id);\n\t\tif (oldSubscriber == null) {\n\t\t\tnewSubscribers.Add(subscriber);\n\t\t}\n\t\telse {\n\t\t\tvar descriptor = oldSubscriber.Descriptor;\n\t\t\tvar addresses = oldSubscriber.Address.Concat(subscriber.Address).Distinct().ToArray();\n\t\t\tnewSubscribers.Add(new ServiceSubscriber(descriptor, addresses));\n\t\t}\n\t}\n\tawait base.SetSubscribersAsync(newSubscribers);\n}", "CodeBleu_score": 38.18912401209331}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var subscriberList = await GetSubscribersAsync();\n    var newSubscribers = new List<ServiceSubscriber>();\n    foreach (var subscriber in subscribers) {\n        var oldSubscriber = subscriberList.FirstOrDefault(p => p.Descriptor.Id == subscriber.Descriptor.Id);\n        if (oldSubscriber != null) {\n            var addresses = new List<AddressModel>();\n            if (oldSubscriber.Address.IsNotNullOrEmpty()) {\n                addresses.AddRange(oldSubscriber.Address);\n            }\n            if (subscriber.Address.IsNotNullOrEmpty()) {\n                addresses.AddRange(subscriber.Address);\n            }\n            oldSubscriber.Address = addresses;\n            newSubscribers.Add(oldSubscriber);\n        }\n        else {\n            newSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(newSubscribers);\n}", "CodeBleu_score": 47.74497787646551}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t\tvar path = CreateSubscriberPath();\n\tvar nodeData = await GetDataAsync(path);\n\tvar data = nodeData.Data;\n\tif (data != null) {\n\t\tvar existingSubscribers = _serializer.Deserialize<IEnumerable<ServiceSubscriber>>(data);\n\t\tvar newSubscribers = subscribers.ToList();\n\t\tforeach (var existingSubscriber in existingSubscribers) {\n\t\t\tvar newSubscriber = newSubscribers.FirstOrDefault(p => p.Descriptor.Id == existingSubscriber.Descriptor.Id);\n\t\t\tif (newSubscriber != null) {\n\t\t\t\texistingSubscriber.Address = existingSubscriber.Address.Concat(newSubscriber.Address).Distinct().ToArray();\n\t\t\t\tnewSubscribers.Remove(newSubscriber);\n\t\t\t}\n\t\t}\n\t\texistingSubscribers = existingSubscribers.Concat(newSubscribers).Distinct().ToList();\n\t\tvar newData = _serializer.Serialize(existingSubscribers);\n\t\tawait SetDataAsync(path, newData);\n\t}\n\telse {\n\t\tawait CreateEphemeralNodeAsync(path, _serializer.Serialize(subscribers));\n\t}\n\tawait base.SetSubscribersAsync(subscribers);\n}", "CodeBleu_score": 44.349479048577244}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar rootPath = string.Format(\"{0}/{1}\", _options.RootPath, _options.SubscriberPath);\n\tforeach (var children in childrens) {\n\t\tvar path = string.Format(\"{0}/{1}\", rootPath, children);\n\t\t_logger.LogDebug($\"Get subscriber information from path: {path}.\");\n\t\tvar data = await _zkClient.GetDataAsync(path);\n\t\tvar subscriber = _serializer.Deserialize<ServiceSubscriber>(data);\n\t\tsubscribers.Add(subscriber);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 41.432658586776796}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tvar path = string.Concat(_options.RootPath, \"/\", _options.SubscriberPath);\n\t_logger.LogDebug($\"Getting subscribers from path: {path}\");\n\tforeach (var children in childrens) {\n\t\tvar subscriberPath = string.Concat(path, \"/\", children);\n\t\t_logger.LogDebug($\"Getting subscriber from path: {subscriberPath}\");\n\t\tvar subscriber = await GetSubscriber(subscriberPath);\n\t\tif (subscriber != null) {\n\t\t\tsubscribers.Add(subscriber);\n\t\t}\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 46.66729240299252}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\tvar subscribers = new List<ServiceSubscriber>();\n\tforeach (var children in childrens) {\n\t\tvar subscriberPath = $\"{_options.RootPath}/{children}\";\n\t\t_logger.LogDebug($\"Retrieving subscriber information for path: {subscriberPath}\");\n\t\tvar subscriber = await GetSubscriber(subscriberPath);\n\t\tsubscribers.Add(subscriber);\n\t}\n\treturn subscribers.ToArray();\n}", "CodeBleu_score": 37.67795280421788}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null)\n        return;\n\n    var zooKeeper = await GetZooKeeper().ConfigureAwait(false);\n\n    var subscriberPath = _options.RoutePath;\n\n    if (zooKeeper.existsAsync(subscriberPath, false).Result != null) {\n        var children = zooKeeper.getChildrenAsync(subscriberPath, false).Result;\n        var subscribers = new List<Subscriber>(children.Count);\n        foreach (var child in children) {\n            var data = zooKeeper.getDataAsync(subscriberPath + \"/\" + child, false).Result;\n            var subscriber = _serializer.Deserialize<Subscriber>(data);\n            subscriber.Id = child;\n            subscribers.Add(subscriber);\n        }\n        _subscribers = subscribers.ToArray();\n    }\n    else {\n        _logger.LogWarning($\"The subscriber path \\\"{subscriberPath}\\\" does not exist.\");\n        _subscribers = Array.Empty<Subscriber>();\n    }\n}", "CodeBleu_score": 44.886673217204795}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null)\n        return;\n\n    var client = await _zookeeperProvider.GetZooKeeper();\n    await client.getStateAsync().ContinueWith(task => {\n        if (task.Result == KeeperState.SyncConnected) {\n            client.getChildrenAsync(this._subscriberPath, false, new SubscriberWatcher(this, client)).ContinueWith(task2 => {\n                if (task2.IsCompletedSuccessfully) {\n                    if (task2.Result.Children.Count > 0) {\n                        _subscribers = task2.Result.Children.Select(p => {\n                            return new SubscriberDescriptor(p, Encoding.UTF8.GetString(client.getDataAsync(this._subscriberPath + \"/\" + p, false, new SubscriberWatcher(this, client)).Result.Data));\n                        }).ToArray();\n                    }\n                    else {\n                        _logger.LogWarning($\"The subscriber path {_subscriberPath} is empty.\");\n                        _subscribers = Array.Empty<SubscriberDescriptor>();\n                    }\n                }\n            });\n        }\n        else {\n            _logger.LogWarning($\"ZooKeeper state is {task.Result}, can not enter subscribers.\");\n        }\n    });\n}", "CodeBleu_score": 41.664210262632984}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var client = await _zookeeperClientProvider.GetZooKeeperClient();\n    var watcher = new SubscriberWatcher(client, _loggerFactory.CreateLogger<SubscriberWatcher>());\n    var path = _zookeeperOption.Value.RoutePath;\n    var children = await client.GetChildrenAsync(path, watcher);\n    if (children != null && children.Length > 0) {\n        _subscribers = children.Select(p => _serializer.Deserialize<Subscriber>(p)).ToArray();\n    } else {\n        _logger.LogWarning($\"The subscriber path {path} does not exist.\");\n        _subscribers = new Subscriber[0];\n    }\n}", "CodeBleu_score": 46.96280289777547}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t    if (newData == null) {\n        return;\n    }\n    var newServiceCommand = _serializer.Deserialize<ServiceCommand>(newData);\n    if (newServiceCommand == null) {\n        return;\n    }\n    var oldServiceCommand = _serializer.Deserialize<ServiceCommand>(oldData);\n    if (oldServiceCommand == null) {\n        return;\n    }\n    if (newServiceCommand.ServiceId != oldServiceCommand.ServiceId) {\n        return;\n    }\n    var newServiceCommandDescriptor = newServiceCommand.ToDescriptor();\n    var oldServiceCommandDescriptor = oldServiceCommand.ToDescriptor();\n    if (newServiceCommandDescriptor.Equals(oldServiceCommandDescriptor)) {\n        return;\n    }\n    var serviceDescriptor = newServiceCommandDescriptor.ToServiceDescriptor();\n    var oldServiceDescriptor = oldServiceCommandDescriptor.ToServiceDescriptor();\n    if (serviceDescriptor.Equals(oldServiceDescriptor)) {\n        return;\n    }\n    _logger.LogInformation($\"{newServiceCommandDescriptor.ServiceId}\u670d\u52a1\u4fe1\u606f\u53d1\u751f\u53d8\u66f4\uff0c\u65b0\u7684\u670d\u52a1\u547d\u4ee4\u4e3a\uff1a{newServiceCommandDescriptor.ToString()}\");\n    var serviceCommand = _serviceCommandManager.GetOrAdd(newServiceCommandDescriptor.ServiceId, newServiceCommandDescriptor);\n    if (serviceCommand != null) {\n        _serviceCommandManager.TryUpdate(newServiceCommandDescriptor.ServiceId, newServiceCommandDescriptor, serviceCommand);\n        _onChanged(newServiceCommandDescriptor, oldServiceCommandDescriptor);\n    }\n}", "CodeBleu_score": 25.753371418785903}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\tif (oldData == null) {\n\t\tvar command = _serializer.Deserialize<ServiceCommand>(newData);\n\t\t_commands.Add(command);\n\t}\n\telse if (newData == null) {\n\t\tvar command = _serializer.Deserialize<ServiceCommand>(oldData);\n\t\t_commands.Remove(command);\n\t}\n\telse {\n\t\tvar oldCommand = _serializer.Deserialize<ServiceCommand>(oldData);\n\t\tvar newCommand = _serializer.Deserialize<ServiceCommand>(newData);\n\t\tif (oldCommand.Equals(newCommand))\n\t\t\treturn;\n\t\t_commands.Remove(oldCommand);\n\t\t_commands.Add(newCommand);\n\t}\n\tOnChanged(new CommandChangedEventArgs(oldData, newData));\n}", "CodeBleu_score": 29.349836899707014}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t\tvar oldCommand = _serializer.Deserialize<ServiceCommand>(oldData);\n\tvar newCommand = _serializer.Deserialize<ServiceCommand>(newData);\n\tif (newCommand != null && oldCommand != null) {\n\t\tif (newCommand.ServiceDescriptor != null && oldCommand.ServiceDescriptor != null &&\n\t\t\tnewCommand.ServiceDescriptor.Id != oldCommand.ServiceDescriptor.Id) {\n\t\t\tthrow new ArgumentException($\"\u670d\u52a1Id\u4e0d\u4e00\u81f4\uff0c\u65e7\u670d\u52a1Id\uff1a{oldCommand.ServiceDescriptor.Id},\u65b0\u670d\u52a1Id\uff1a{newCommand.ServiceDescriptor.Id}\");\n\t\t}\n\t}\n\tif (newCommand != null && oldCommand != null && newCommand.ServiceDescriptor.Id == oldCommand.ServiceDescriptor.Id) {\n\t\tif (newCommand.Status != oldCommand.Status) {\n\t\t\t_logger.LogInformation($\"\u670d\u52a1\u72b6\u6001\u53d8\u66f4\uff0c\u670d\u52a1Id\uff1a{newCommand.ServiceDescriptor.Id},\u65e7\u72b6\u6001\uff1a{oldCommand.Status},\u65b0\u72b6\u6001\uff1a{newCommand.Status}\");\n\t\t\tif (newCommand.Status == CommandStatus.Enabled) {\n\t\t\t\t_logger.LogInformation($\"\u670d\u52a1{newCommand.ServiceDescriptor.Id}\u542f\u7528\u6210\u529f\");\n\t\t\t\t_commands.TryAdd(newCommand.ServiceDescriptor.Id, newCommand);\n\t\t\t\tOnChanged(newCommand, oldCommand);\n\t\t\t}\n\t\t\telse if (newCommand.Status == CommandStatus.Disabled) {\n\t\t\t\t_logger.LogInformation($\"\u670d\u52a1{newCommand.ServiceDescriptor.Id}\u7981\u7528\u6210\u529f\");\n\t\t\t\t_commands.TryRemove(newCommand.ServiceDescriptor.Id, out var command);\n\t\t\t\tOnChanged(newCommand, oldCommand);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 30.164555182395205}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\ttry {\n\t\tif (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n\t\t\tstring path = watchedEvent.get_Path();\n\t\t\tbyte[] data = await _zooKeeper.getDataAsync(path, true);\n\t\t\tstring newData = Encoding.UTF8.GetString(data);\n\t\t\t_action(path, _data, newData);\n\t\t\t_data = newData;\n\t\t}\n\t} catch (KeeperException e) {\n\t\tif (e.get_Code() == KeeperException.Code.ConnectionLoss) {\n\t\t\tthrow new TaskCanceledException();\n\t\t}\n\t\tthrow;\n\t}\n}", "CodeBleu_score": 46.816212515125535}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        // Get the new data from the node.\n        var newData = await client.getDataAsync(watchedEvent.get_Path());\n\n        // Execute the action with the current and new data.\n        action(data, newData);\n\n        // Update the watcher with the new data.\n        data = newData;\n    }\n}", "CodeBleu_score": 43.205707233254465}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t\tif (watchedEvent.get_Type() == Event.EventType.NodeDataChanged) {\n\t\ttry {\n\t\t\tvar nodeData = await _client.GetDataAsync(watchedEvent.get_Path());\n\t\t\tvar newData = nodeData.get_Data();\n\t\t\tvar oldData = _data;\n\t\t\t_data = newData;\n\t\t\t_action(oldData, newData);\n\t\t\tawait _client.SetWatcherAsync(watchedEvent.get_Path(), this);\n\t\t} catch (KeeperException e) {\n\t\t\tif (e.get_Code() == KeeperException.Code.NoNode) {\n\t\t\t\tawait _client.SetWatcherAsync(watchedEvent.get_Path(), this);\n\t\t\t} else {\n\t\t\t\tthrow;\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 50.256235015166894}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    if (builder == null)\n        throw new ArgumentNullException(nameof(builder));\n    if (configInfo == null)\n        throw new ArgumentNullException(nameof(configInfo));\n    builder.Services.AddSingleton<IZookeeperClientProvider>(p => {\n        var logger = p.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>();\n        var addressSelector = p.GetRequiredService<IAddressSelector>();\n        var healthCheckService = p.GetRequiredService<IHealthCheckService>();\n        var serializer = p.GetRequiredService<ISerializer<string>>();\n        var mqttService = p.GetRequiredService<IMqttService>();\n        var cacheManager = p.GetRequiredService<ICacheManager>();\n        var clientProvider = new DefaultZookeeperClientProvider(configInfo, addressSelector, healthCheckService, logger, serializer, mqttService, cacheManager);\n        return clientProvider;\n    });\n    return builder;\n}", "CodeBleu_score": 44.21681703128465}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t\tvar services = builder.Services;\n\tservices.RegisterType(typeof(DefaultZookeeperClientProvider)).As(typeof(IZookeeperClientProvider)).SingleInstance();\n\tservices.RegisterType(typeof(DefaultZookeeperClientProvider)).As(typeof(IZookeeperClientProvider)).SingleInstance();\n\tservices.RegisterType(typeof(DefaultZookeeperClientProvider)).As(typeof(IZookeeperClientProvider)).SingleInstance();\n\treturn builder;\n}", "CodeBleu_score": 45.29051285803305}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.AddSingleton<IZookeeperClientProvider>(p => {\n        var logger = p.GetRequiredService<ILogger<DefaultZookeeperClientProvider>>();\n        var healthCheckService = p.GetRequiredService<IHealthCheckService>();\n        var addressSelector = p.GetRequiredService<IAddressSelector>();\n        var serializer = p.GetRequiredService<ISerializer<string>>();\n        var mqttService = p.GetRequiredService<IMqttService>();\n        var cacheManager = p.GetRequiredService<ICacheManager>();\n        var serviceRouteManager = p.GetRequiredService<IServiceRouteManager>();\n        var serviceCommandManager = p.GetRequiredService<IServiceCommandManager>();\n        var clientProvider = new DefaultZookeeperClientProvider(configInfo, logger, healthCheckService, addressSelector, serializer, mqttService, cacheManager, serviceRouteManager, serviceCommandManager);\n        return clientProvider;\n    });\n    return builder;\n}", "CodeBleu_score": 35.99079373247639}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var logger = ServiceLocator.GetService(typeof(ILogger<DefaultMqttServiceCommand>)) as ILogger<DefaultMqttServiceCommand>;\n    var mqttAddress = await _mqttAddressProvider.GetAddressAsync();\n    var client = await _zookeeperClientProvider.GetZooKeeperClientAsync();\n    logger.LogDebug($\"\u51c6\u5907\u4e3aMqtt\u670d\u52a1\u8bbe\u7f6e\u8def\u7531\u4fe1\u606f,\u5730\u5740\uff1a{mqttAddress}\");\n    var path = $\"{_configInfo.RoutePath}/{mqttAddress.Host}:{mqttAddress.Port}\";\n    var result = await client.CreateRecursiveAsync(path);\n    if (result.Name.IsNullOrEmpty())\n    {\n        throw new Exception($\"\u521b\u5efa\u8282\u70b9\u5931\u8d25\uff0c\u8282\u70b9\uff1a{path}\");\n    }\n    foreach (var route in routes)\n    {\n        var routePath = $\"{path}/{route.ServiceDescriptor.Id}\";\n        var data = ServiceLocator.GetService<ISerializer<byte[]>>().Serialize(route);\n        var node = await client.CreateOrUpdateAsync(routePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        if (node.Name.IsNullOrEmpty())\n        {\n            throw new Exception($\"\u521b\u5efa\u8282\u70b9\u5931\u8d25\uff0c\u8282\u70b9\uff1a{routePath}\");\n        }\n    }\n    logger.LogDebug($\"\u4e3aMqtt\u670d\u52a1\u8bbe\u7f6e\u8def\u7531\u4fe1\u606f\u6210\u529f,\u5730\u5740\uff1a{mqttAddress}\");\n}", "CodeBleu_score": 36.21674526483635}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tif (routes == null)\n\t\tthrow new ArgumentNullException(nameof(routes));\n\tif (routes.Any()) {\n\t\t_logger.LogDebug($\"\u51c6\u5907\u4e3a\u670d\u52a1\u8def\u7531[{string.Join(\",\", routes.Select(p => p.ServiceDescriptor.Id))}]\u6ce8\u518cMqtt\u8def\u7531\u4fe1\u606f,\u5e94\u7528\uff1a{_zookeeperOption.ApplicationKey}\u3002\");\n\t\tvar zooKeeper = await GetZooKeeperAsync();\n\t\tvar routePath = CreateRoutePath();\n\t\tvar routeNodes = await zooKeeper.GetChildrenAsync(routePath);\n\t\tforeach (var node in routeNodes) {\n\t\t\tvar address = await zooKeeper.GetDataAsync(CreateRoutePath(node));\n\t\t\tvar addressModel = _serializer.Deserialize<AddressModel>(address);\n\t\t\tvar addressDescriptor = new AddressModel(addressModel.Protocol, addressModel.Host, addressModel.Port, addressModel.Token, addressModel.IsDefault, addressModel.Weight, addressModel.Metadata);\n\t\t\tvar serviceDescriptor = new ServiceDescriptor(addressModel.ServiceDescriptor.Id, addressModel.ServiceDescriptor.ServiceType, addressModel.ServiceDescriptor.Group, addressModel.ServiceDescriptor.Version, addressDescriptor);\n\t\t\tvar descriptor = new MqttServiceDescriptor(serviceDescriptor, addressModel.MqttServiceDescriptor.Topic, addressModel.MqttServiceDescriptor.QosLevel);\n\t\t\troutes = routes.Concat(new[] { descriptor });\n\t\t}\n\t\tforeach (var route in routes) {\n\t\t\tvar data = _serializer.Serialize(route);\n\t\t\tvar nodePath = CreateRoutePath(route.MqttServiceDescriptor.Topic);\n\t\t\tvar nodeData = _serializer.Serialize(new AddressModel(route.Address, route.MqttServiceDescriptor));\n\t\t\tawait zooKeeper.CreateOrUpdatePersistentNodeAsync(nodePath, nodeData);\n\t\t\t_logger.LogDebug($\"\u6210\u529f\u4e3a\u670d\u52a1\u8def\u7531[{route.ServiceDescriptor.Id}]\u6ce8\u518cMqtt\u8def\u7531\u4fe1\u606f,\u5e94\u7528\uff1a{_zo", "CodeBleu_score": 38.75498052096111}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t\tvar path = _zookeeperOption.RoutePath;\n\tvar client = await _zookeeperClientProvider.GetZooKeeperClient();\n\tvar exists = await client.ExistsAsync(path);\n\tif (!exists) {\n\t\tawait client.CreateAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t}\n\tforeach (var route in routes) {\n\t\tvar nodePath = $\"{path}/{route.ServiceDescriptor.Id}\";\n\t\texists = await client.ExistsAsync(nodePath);\n\t\tif (!exists) {\n\t\t\tawait client.CreateAsync(nodePath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t}\n\t\tvar data = _serializer.Serialize(route);\n\t\tawait client.SetDataAsync(nodePath, data);\n\t}\n\t_logger.LogDebug($\"Mqtt routes has been set, routes count: {routes.Count()}\");\n}", "CodeBleu_score": 39.42142281223807}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar routePath = await _zookeeperNodeProvider.GetRoutePathAsync();\n\tforeach (var zookeeperClient in _zookeeperClients) {\n\t\tvar exists = await zookeeperClient.ExistsAsync(routePath);\n\t\tif (exists != null) {\n\t\t\tvar children = await zookeeperClient.GetChildrenAsync(routePath);\n\t\t\tforeach (var child in children) {\n\t\t\t\tvar childPath = $\"{routePath}/{child}\";\n\t\t\t\tvar data = await zookeeperClient.GetDataAsync(childPath);\n\t\t\t\tvar route = _serializer.Deserialize<MqttServiceRoute>(data);\n\t\t\t\tif (!routes.Any(p => p.Path == route.Path && p.ServiceDescriptor.Id == route.ServiceDescriptor.Id)) {\n\t\t\t\t\tif (hostAddr != null && route.Address.Any(p => p.Host == hostAddr.Host && p.Port == hostAddr.Port)) {\n\t\t\t\t\t\tawait zookeeperClient.DeleteAsync(childPath);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 47.0468247518839}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var path = $\"{_configInfo.RoutePath}/{hostAddr.ToString()}\";\n    var result = await _zookeeperClientProvider.GetChildrenAsync(path);\n    foreach (var node in result) {\n        var childPath = $\"{path}/{node}\";\n        var children = await _zookeeperClientProvider.GetChildrenAsync(childPath);\n        foreach (var child in children) {\n            var childPath1 = $\"{childPath}/{child}\";\n            var route = await _zookeeperClientProvider.GetDataAsync(childPath1);\n            if (route != null && !routes.Any(p => p.ServiceDescriptor.Id == child)) {\n                await _zookeeperClientProvider.DeleteAsync(childPath1);\n            }\n        }\n    }\n}", "CodeBleu_score": 33.61847946096778}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t\tvar path = string.Format(\"{0}/{1}\", _zookeeperNodeManager.RoutePath, hostAddr.ToString());\n\tvar clients = await _zookeeperClientManager.GetClients();\n\tforeach (var client in clients) {\n\t\tvar currentRoutes = await client.GetChildrenAsync(path);\n\t\tvar deleteRoutes = currentRoutes.Except(routes.Select(p => p.ServiceDescriptor.Id));\n\t\tforeach (var deleteRoute in deleteRoutes) {\n\t\t\tvar deletePath = $\"{path}/{deleteRoute}\";\n\t\t\tawait client.DeleteRecursiveAsync(deletePath);\n\t\t}\n\t}\n}", "CodeBleu_score": 29.774843032968217}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\ttry {\n\t\tif (cacheDescriptors == null || !cacheDescriptors.Any())\n\t\t\treturn;\n\t\t_logger.LogInformation($\"\u51c6\u5907\u66f4\u65b0\u7f13\u5b58\uff0c\u7f13\u5b58\u6570\u91cf\uff1a{cacheDescriptors.Count()}\u3002\");\n\t\tvar path = _configInfo.CachePath;\n\t\tforeach (var client in _zookeeperClients) {\n\t\t\tvar exists = await client.ExistsAsync(path);\n\t\t\tif (!exists) {\n\t\t\t\tawait client.CreateAsync(path, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\t\tvar data = _serializer.Serialize(cacheDescriptor);\n\t\t\t\tvar cachePath = $\"{path}/{cacheDescriptor.CacheId}\";\n\t\t\t\tvar existsCache = await client.ExistsAsync(cachePath);\n\t\t\t\tif (!existsCache) {\n\t\t\t\t\tawait client.CreateAsync(cachePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t\t}\n\t\t\t\telse {\n\t\t\t\t\tvar currentData = await client.GetDataAsync(cachePath);\n\t\t\t\t\tif (!data.SequenceEqual(currentData)) {\n\t\t\t\t\t\tawait client.SetDataAsync(cachePath, data);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t_logger.LogInformation($\"\u66f4\u65b0\u7f13\u5b58\u6210\u529f\uff0c\u7f13\u5b58\u6570\u91cf\uff1a{cacheDescriptors.Count()}\u3002\");\n\t}\n\tcatch (Exception ex) {\n\t\t_logger.LogError(ex, \"\u66f4\u65b0\u7f13\u5b58\u5931\u8d25\u3002\");\n\t}\n}", "CodeBleu_score": 42.947890736764336}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\t_logger.LogDebug($\"\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\uff0c\u7f13\u5b58\u6570\u91cf\uff1a{cacheDescriptors.Count()}\");\n\tvar path = _configInfo.CachePath;\n\tvar clients = await _zookeeperClientProvider.GetZooKeeperClients();\n\tforeach (var client in clients) {\n\t\tawait client.EnsureExistsAsync(path);\n\t\tforeach (var descriptor in cacheDescriptors) {\n\t\t\tvar nodePath = $\"{path}/{descriptor.CacheId}\";\n\t\t\tvar data = _serializer.Serialize(descriptor);\n\t\t\tvar stat = await client.ExistsAsync(nodePath);\n\t\t\tif (stat == null) {\n\t\t\t\tawait client.CreateAsync(nodePath, data);\n\t\t\t}\n\t\t\telse {\n\t\t\t\tif (!(await client.GetDataAsync(nodePath)).SequenceEqual(data)) {\n\t\t\t\t\tawait client.SetDataAsync(nodePath, data);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\t_logger.LogDebug($\"\u6210\u529f\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\uff0c\u7f13\u5b58\u6570\u91cf\uff1a{cacheDescriptors.Count()}\");\n}", "CodeBleu_score": 32.046412696452485}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t\tif (cacheDescriptors == null)\n\t\tthrow new ArgumentNullException(nameof(cacheDescriptors));\n\tvar cachePath = $\"{_options.CachePath}/{_options.CacheDescriptorPath}\";\n\t_logger.LogDebug($\"\u66f4\u65b0\u670d\u52a1\u7f13\u5b58\u4fe1\u606f\uff1a{cachePath}\");\n\tforeach (var client in _clients) {\n\t\tif (await client.ExistsAsync(cachePath))\n\t\t\tcontinue;\n\t\tawait client.CreateRecursiveAsync(cachePath);\n\t}\n\tvar serializer = _serializerProvider.GetSerializer();\n\tforeach (var client in _clients) {\n\t\tforeach (var cacheDescriptor in cacheDescriptors) {\n\t\t\tvar cachePath = $\"{_options.CachePath}/{_options.CacheDescriptorPath}/{cacheDescriptor.CacheId}\";\n\t\t\tvar data = serializer.Serialize(cacheDescriptor);\n\t\t\tif (!await client.ExistsAsync(cachePath))\n\t\t\t\tawait client.CreateAsync(cachePath, data);\n\t\t\telse {\n\t\t\t\tvar result = await client.GetDataAsync(cachePath);\n\t\t\t\tif (!data.SequenceEqual(result))\n\t\t\t\t\tawait client.SetDataAsync(cachePath, data);\n\t\t\t}\n\t\t}\n\t}\n\t_logger.LogDebug($\"\u670d\u52a1\u7f13\u5b58\u4fe1\u606f\u66f4\u65b0\u6210\u529f\uff1a{cachePath}\");\n}", "CodeBleu_score": 34.63551642267371}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tvar (manualResetEvent, zookeeperClient) = zooKeeper\n\tmanualResetEvent.WaitOne()\n\tif (zookeeperClient.exists(path, false) == null) {\n\t\t_logger.LogInformation($\"Creating zookeeper node path: {path}\");\n\t\tvar nodes = path.Split('/');\n\t\tvar currentPath = string.Empty;\n\t\tforeach (var node in nodes) {\n\t\t\tif (node != string.Empty) {\n\t\t\t\tcurrentPath += \"/\" + node;\n\t\t\t\tif (zookeeperClient.exists(currentPath, false) == null) {\n\t\t\t\t\tzookeeperClient.create(currentPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t\t\t_logger.LogInformation($\"Created zookeeper node path: {currentPath}\");\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 35.998963087320845}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    var (manualResetEvent, zooKeeperClient) = zooKeeper;\n    manualResetEvent.WaitOne();\n    if (!zooKeeperClient.Exists(path, false)) {\n        _logger.LogInformation($\"Creating zookeeper node path: {path}\");\n        var pathParts = path.Split('/');\n        var currentPath = string.Empty;\n        foreach (var pathPart in pathParts) {\n            currentPath = string.IsNullOrEmpty(currentPath) ? pathPart : $\"{currentPath}/{pathPart}\";\n            if (!zooKeeperClient.Exists(currentPath, false)) {\n                zooKeeperClient.Create(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 44.76662827570532}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t\tvar @event = zooKeeper.Item1\n\tvar zooKeeperClient = zooKeeper.Item2\n\t@event.WaitOne()\n\tif (!zooKeeperClient.exists(path, false)) {\n\t\t_logger.LogInformation($\"Creating path: {path}\");\n\t\tvar segments = path.Split('/').Where(p => !string.IsNullOrEmpty(p)).ToList();\n\t\tvar currentPath = string.Empty;\n\t\tforeach (var segment in segments) {\n\t\t\tcurrentPath = string.IsNullOrEmpty(currentPath) ? segment : $\"{currentPath}/{segment}\";\n\t\t\tif (!zooKeeperClient.exists(currentPath, false)) {\n\t\t\t\tawait zooKeeperClient.createAsync(currentPath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 38.4611148275623}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar zooKeepers = new ConcurrentBag<(ManualResetEvent, ZooKeeper)>();\n\tvar tasks = new List<Task>();\n\tforeach (var address in _addressModel.Address) {\n\t\ttasks.Add(Task.Run(async () => {\n\t\t\tvar zooKeeper = await _zookeeperProvider.GetZooKeeper(address, _zookeeperOption.SessionTimeout, _zookeeperOption.ConnectionTimeout);\n\t\t\tvar manualResetEvent = new ManualResetEvent(false);\n\t\t\tvar watcher = new ZookeeperWatcher(manualResetEvent);\n\t\t\tawait zooKeeper.existsAsync(address.ToZooKeeperPath(), watcher);\n\t\t\tawait Task.Run(() => manualResetEvent.WaitOne(_zookeeperOption.SessionTimeout));\n\t\t\tif (manualResetEvent.WaitOne(0)) {\n\t\t\t\tzooKeepers.Add((manualResetEvent, zooKeeper));\n\t\t\t}\n\t\t}));\n\t}\n\tawait Task.WhenAll(tasks);\n\treturn zooKeepers;\n}", "CodeBleu_score": 50.730724024324616}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar zooKeepers = new ConcurrentBag<(ManualResetEvent, ZooKeeper)>();\n\tvar zooKeeperAddresses = await _addressSelector.SelectAsync(_addresses);\n\tvar tasks = new List<Task>();\n\tvar healthChecker = new HealthChecker(_loggerFactory, _options.ClientTimeout, _options.ZooKeeperConnectionTimeout);\n\tforeach (var zooKeeperAddress in zooKeeperAddresses) {\n\t\tvar manualResetEvent = new ManualResetEvent(false);\n\t\tvar task = healthChecker.CheckHealthAsync(zooKeeperAddress.ToEndPoint(), manualResetEvent);\n\t\ttasks.Add(task);\n\t\ttask.ContinueWith((t) => {\n\t\t\tif (t.IsFaulted) {\n\t\t\t\t_logger.LogError(t.Exception, \"ZooKeeper {0} health check failed.\", zooKeeperAddress);\n\t\t\t\tmanualResetEvent.Set();\n\t\t\t}\n\t\t\telse {\n\t\t\t\t_logger.LogInformation(\"ZooKeeper {0} health check succeed.\", zooKeeperAddress);\n\t\t\t\ttry {\n\t\t\t\t\tvar zooKeeper = new ZooKeeper(zooKeeperAddress.ToEndPoint().ToString(), _options.ZooKeeperConnectionTimeout, new WatcherProvider(_loggerFactory, _options.ClientTimeout, _options.ZooKeeperConnectionTimeout));\n\t\t\t\t\tzooKeepers.Add((manualResetEvent, zooKeeper));\n\t\t\t\t}\n\t\t\t\tcatch (Exception exception) {\n\t\t\t\t\t_logger.LogError(exception, \"Create ZooKeeper {0} failed.\", zooKeeperAddress);\n\t\t\t\t\tmanualResetEvent.Set();\n\t\t\t\t}\n\t\t\t}\n\t\t});\n\t}\n\tawait Task.WhenAll(tasks);\n\treturn zooKeepers;\n}", "CodeBleu_score": 46.11072900304615}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t\tvar zooKeepers = new List<(ManualResetEvent, ZooKeeper)>();\n\tforeach (var address in _addresses) {\n\t\tvar health = await _healthCheckService.IsHealth(address);\n\t\tif (health) {\n\t\t\tvar zooKeeper = new ZooKeeper(address, _options.SessionTimeout, _watcherProvider);\n\t\t\tvar manualResetEvent = new ManualResetEvent(false);\n\t\t\tzooKeepers.Add((manualResetEvent, zooKeeper));\n\t\t}\n\t}\n\treturn zooKeepers;\n}", "CodeBleu_score": 61.353917426044}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zooKeeper == null) {\n            zooKeeper = zookeeperFactory.newZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, watcher);\n        }\n        return zooKeeper;\n    }\n}", "CodeBleu_score": 36.573406350043804}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zooKeeper == null) {\n            zooKeeper = new ZooKeeper(ensembleProvider.getConnectionString(), sessionTimeout, new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                    // do nothing\n                }\n            }, zkFactory);\n            helper = new Helper(zooKeeper, this);\n        }\n    }\n    return zooKeeper;\n}", "CodeBleu_score": 43.76089094360466}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    if ( zooKeeper == null ) {\n        zooKeeper = new ZooKeeper(ensembleProvider.getConnectionString(), sessionTimeoutMs, new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                if ( event.getState() == Watcher.Event.KeeperState.SyncConnected ) {\n                    connectedLatch.countDown();\n                }\n            }\n        }, zookeeperFactory);\n        connectedLatch.await();\n        zooKeeper.register(this);\n    }\n    return zooKeeper;\n}", "CodeBleu_score": 35.668584556783394}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zooKeeper = null;\n    try {\n        zooKeeper = getZooKeeper();\n        if (zooKeeper != null) {\n            zooKeeper.register(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                }\n            });\n        }\n    } catch (Exception e) {\n        // ignore\n    }\n\n    if (zooKeeper != null) {\n        if (waitForShutdownTimeoutMs <= 0) {\n            zooKeeper.close();\n        } else {\n            try {\n                zooKeeper.close(waitForShutdownTimeoutMs);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n        }\n    }\n}", "CodeBleu_score": 53.9412660845159}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    ZooKeeper zooKeeper = null;\n    try {\n        zooKeeper = getZooKeeper();\n        if (zooKeeper != null) {\n            zooKeeper.register(new Watcher() {\n                @Override\n                public void process(WatchedEvent watchedEvent) {\n                }\n            });\n        }\n        if (waitForShutdownTimeoutMs > 0) {\n            Thread.sleep(waitForShutdownTimeoutMs);\n        }\n    } finally {\n        if (zooKeeper != null) {\n            zooKeeper.close();\n        }\n    }\n}", "CodeBleu_score": 40.98966564983478}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    if (zooKeeper != null) {\n        try {\n            if (waitForShutdownTimeoutMs > 0) {\n                ZooKeeper newZooKeeper = zooKeeper.get();\n                if (newZooKeeper != null) {\n                    newZooKeeper.register(new Watcher() {\n                        @Override\n                        public void process(WatchedEvent event) {\n                            // do nothing\n                        }\n                    });\n                    zooKeeper.close(waitForShutdownTimeoutMs);\n                }\n            } else {\n                zooKeeper.close();\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n            throw e;\n        } finally {\n            zooKeeper = null;\n        }\n    }\n}", "CodeBleu_score": 54.699414031126636}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    if ( !isStarted() ) {\n        throw new IllegalStateException(\"The client is not started\");\n    }\n    if ( !isConnected() ) {\n        LOG.info(\"Blocking until connected\");\n        long startMs = System.currentTimeMillis();\n        if ( !blockUntilConnected(connectionTimeoutMs, TimeUnit.MILLISECONDS) ) {\n            LOG.error(\"Unable to connect to ZooKeeper.\");\n            return false;\n        }\n        long endMs = System.currentTimeMillis();\n        long elapsedMs = endMs - startMs;\n        LOG.info(\"Blocked for \" + elapsedMs + \" ms\");\n    }\n    return true;\n}", "CodeBleu_score": 38.128707319793506}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    return blockUntilConnectedOrTimedOut(CONNECTION_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 5.5211708708697245}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    return blockUntilConnectedOrTimedOut(CONNECTION_TIMEOUT_MS, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 5.5211708708697245}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if ( started.compareAndSet(true, false) ) {\n        log.info(\"Shutting down\");\n        try {\n            // close the client\n            client.close();\n        } catch (IOException e) {\n            if ( Thread.currentThread().isInterrupted() ) {\n                log.info(\"Shutdown interrupted\");\n            } else {\n                log.error(\"Error closing\", e);\n            }\n        }\n\n        // close the tracer driver\n        if ( tracerDriver != null ) {\n            tracerDriver.close();\n        }\n\n        // close the ensemble provider\n        if ( ensembleProvider instanceof Closeable ) {\n            try {\n                ((Closeable)ensembleProvider).close();\n            } catch (IOException e) {\n                log.error(\"Error closing ensemble provider\", e);\n            }\n        }\n\n        // close the zookeeper factory\n        if ( zookeeperFactory instanceof Closeable ) {\n            try {\n                ((Closeable)zookeeperFactory).close();\n            } catch (IOException e) {\n                log.error(\"Error closing zookeeper factory\", e);\n            }\n        }\n\n        if ( waitForShutdownTimeoutMs > 0 ) {\n            // wait for the background thread to finish\n            try {\n                backgroundThread.join(waitForShutdownTimeoutMs);\n            } catch (InterruptedException e) {\n                Thread.currentThread().interrupt();\n            }\n\n            if ( backgroundThread.isAlive() ) {\n                log.warn(\"Shutdown of background thread timed out\");\n            }\n        }\n    }\n}", "CodeBleu_score": 50.84821593901084}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if ( started.compareAndSet(true, false) ) {\n        if ( log.isDebugEnabled() ) {\n            log.debug(\"Shutting down\");\n        }\n\n        try {\n            closeZooKeeper();\n        } catch ( IOException e ) {\n            if ( Thread.currentThread().isInterrupted() ) {\n                log.debug(\"Shutdown interrupted\", e);\n            } else {\n                log.error(\"Error shutting down\", e);\n            }\n        }\n\n        if ( waitForShutdownTimeoutMs > 0 ) {\n            try {\n                if ( !shutdownLatch.await(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS) ) {\n                    log.warn(\"Timeout while waiting for shutdown\");\n                }\n            } catch ( InterruptedException e ) {\n                Thread.currentThread().interrupt();\n            }\n        }\n    }\n}", "CodeBleu_score": 39.17340072760811}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if ( started.compareAndSet(true, false) ) {\n        log.info(\"Shutting down\");\n        try {\n            if ( waitForShutdownTimeoutMs > 0 ) {\n                CloseableUtils.closeQuietly(closeable);\n            }\n            else {\n                CloseableUtils.closeQuietly(closeable);\n            }\n        }\n        catch ( IOException e ) {\n            if ( Thread.currentThread().isInterrupted() ) {\n                log.info(\"Shutdown interrupted\");\n            }\n            else {\n                log.warn(\"\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 41.23575823190282}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    long startMs = System.currentTimeMillis();\n    long maxWaitMs = sessionTimeoutMs;\n    long elapsedMs = 0;\n    long waitTimeMs = 100;\n\n    while ( elapsedMs < maxWaitMs ) {\n        if ( state.get() == State.CONNECTED ) {\n            return;\n        }\n\n        Watcher watcher = new Watcher() {\n            @Override\n            public void process(WatchedEvent event) {\n                if ( event.getState() == Event.KeeperState.SyncConnected ) {\n                    connectedLatch.countDown();\n                }\n            }\n        };\n\n        try {\n            zooKeeper.register(watcher);\n            connectedLatch.await(waitTimeMs, TimeUnit.MILLISECONDS);\n        }\n        catch ( InterruptedException e ) {\n            Thread.currentThread().interrupt();\n            return;\n        }\n        finally {\n            zooKeeper.register(UnhandledErrorListener.getInstance());\n        }\n\n        elapsedMs = System.currentTimeMillis() - startMs;\n        waitTimeMs = Math.min(waitTimeMs << 1, maxWaitMs - elapsedMs);\n    }\n\n    throw new IllegalStateException(\"Timed out waiting for connection\");\n}", "CodeBleu_score": 45.11457061928691}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    long startMs = System.currentTimeMillis();\n    long waitMs = sessionTimeoutMs;\n    boolean wasConnected = false;\n\n    while ( !wasConnected )\n    {\n        if ( waitMs <= 0 )\n        {\n            throw new IllegalStateException(String.format(\"Timed out while waiting for connection. Last Zookeeper state: %s\", client.getState()));\n        }\n\n        long startWaitMs = System.currentTimeMillis();\n        boolean connected = internalBlockUntilConnected(waitMs);\n        wasConnected = connected || wasConnected;\n        long endWaitMs = System.currentTimeMillis();\n        waitMs -= (endWaitMs - startWaitMs);\n    }\n\n    long endMs = System.currentTimeMillis();\n    long elapsedMs = endMs - startMs;\n    if ( elapsedMs > sessionTimeoutMs )\n    {\n        LOG.warn(\"Blocking until connected took {} ms (longer than the session timeout {})\", elapsedMs, sessionTimeoutMs);\n    }\n}", "CodeBleu_score": 26.74542807953487}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    final int maxSleepTimeMs = 100;\n    int sleepTimeMs = 1;\n    long startTimeMs = System.currentTimeMillis();\n    long elapsedTimeMs = 0;\n    while ( elapsedTimeMs < connectionTimeoutMs ) {\n        if ( state.get() == CuratorFrameworkState.STARTED ) {\n            if ( client.getZookeeperClient().isConnected() ) {\n                return;\n            }\n        }\n        Thread.sleep(sleepTimeMs);\n        elapsedTimeMs = System.currentTimeMillis() - startTimeMs;\n        sleepTimeMs = Math.min(maxSleepTimeMs, sleepTimeMs * 2);\n    }\n    throw new ConnectionTimeoutException();\n}", "CodeBleu_score": 28.067678028629793}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL) {\n        String sessionId = client.getZooKeeper().getSessionId() + \"\";\n        if (!sessionId.equals(foundNode.substring(foundNode.lastIndexOf(\"/\") + 1))) {\n            LOG.warn(\"Session ID has changed, deleting old ephemeral node: \" + foundNode);\n            client.delete().forPath(foundNode);\n            foundNode = createNode(client, createMode, foundNode);\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 36.541542009644836}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t  if (createMode == CreateMode.EPHEMERAL) {\n    String sessionId = client.getZookeeperClient().getZooKeeper().getSessionId();\n    if (sessionId != null && !sessionId.equals(client.getSessionId())) {\n      LOG.debug(\"Found ephemeral node {} with session {} but our session is {}\", foundNode, sessionId, client.getSessionId());\n      client.delete().forPath(foundNode);\n      client.getZookeeperClient().getZooKeeper().getTestable().injectSessionExpiration();\n      client.getZookeeperClient().getZooKeeper().getTestable().waitFor", "CodeBleu_score": 34.96622906357184}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode == CreateMode.EPHEMERAL || createMode == CreateMode.EPHEMERAL_SEQUENTIAL) {\n        // if the session has changed, delete the old node\n        if (!client.getZookeeperClient().getSessionId().equals(client.getZookeeperClient().getSessionId())) {\n            logger.info(\"session changed, deleting old node: {}\", foundNode);\n            client.delete().forPath(foundNode);\n            client.getZookeeperClient().setSessionId(client.getZookeeperClient().getSessionId());\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 33.59363058531407}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    OperationTrace trace = client.getZookeeperClient().startAdvancedTracer(\"SetACLBuilderImpl-Foreground\");\n    try {\n        return RetryLoop.callWithRetry(new Callable<Stat>() {\n            @Override\n            public Stat call() throws Exception {\n                return client.getZooKeeper().setACL(path, aclList, -1);\n            }\n        });\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 54.33701453279942}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    OperationTrace trace = client.beginAdvancedTracing(\"SetACLBuilderImpl-pathInForeground\");\n    trace.setPath(path);\n    try {\n        return RetryLoop.callWithRetry(client.getZookeeperClient(), new Callable<Stat>() {\n            @Override\n            public Stat call() throws Exception {\n                return client.getZooKeeper().setACL(path, aclList, -1);\n            }\n        });\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 54.79649241544519}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    OperationTrace trace = client.beginAdvancedTracing(\"SetACLBuilderImpl-Foreground\");\n    try {\n        return RetryLoop.callWithRetry(client.getZookeeperClient(), new Callable<Stat>() {\n            @Override\n            public Stat call() throws Exception {\n                return client.getZooKeeper().setACL(path, aclList, -1);\n            }\n        });\n    } finally {\n        trace.commit();\n    }\n}", "CodeBleu_score": 51.938410935660514}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkNotNull(payload, \"payload cannot be null\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    Preconditions.checkArgument(ZKPaths.validPath(membershipPath), \"Invalid membershipPath: \" + membershipPath);\n    Preconditions.checkArgument(ZKPaths.validPath(thisId), \"Invalid thisId: \" + thisId);\n\n    this.cache = CuratorCache.build(client, membershipPath);\n    this.cache.listenable().addListener(new CuratorCacheListener() {\n        @Override\n        public void event() throws Exception {\n            notifyListeners();\n        }\n    });\n    this.cache.start();\n\n    this.node = new PersistentNode(client, ZKPaths.makePath(membershipPath, thisId), CreateMode.EPHEMERAL, payload);\n    this.node.start();\n}", "CodeBleu_score": 47.824762766135045}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t\tPreconditions.checkNotNull(client, \"client cannot be null\");\n\tPreconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n\tPreconditions.checkNotNull(thisId, \"thisId cannot be null\");\n\tPreconditions.checkNotNull(payload, \"payload cannot be null\");\n\n\tthis.client = client;\n\tthis.membershipPath = membershipPath;\n\tthis.thisId = thisId;\n\tthis.payload = payload;\n\n\tif (!ZKPaths.isValidPath(membershipPath)) {\n\t\tthrow new IllegalArgumentException(\"Invalid membershipPath: \" + membershipPath);\n\t}\n\n\tif (!ZKPaths.isValidPath(thisId)) {\n\t\tthrow new IllegalArgumentException(\"Invalid thisId: \" + thisId);\n\t}\n\n\tif (ZKPaths.isRootPath(thisId)) {\n\t\tthrow new IllegalArgumentException(\"thisId cannot be the root path: \" + thisId);\n\t}\n\n\tif (ZKPaths.isRootPath(membershipPath)) {\n\t\tthrow new IllegalArgumentException(\"membershipPath cannot be the root path: \" + membershipPath);\n\t}\n\n\tthis.cache = CuratorCache.build(client, membershipPath);\n\tthis.cache.start();\n\n\tthis.cacheBridge = new CuratorCacheBridge(cache);\n\n\tthis.memberNode = new PersistentNode(client, ZKPaths.makePath(membershipPath, thisId), CreateMode.EPHEMERAL, payload);\n\tthis.memberNode.start();\n}", "CodeBleu_score": 45.963627034174834}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t  Preconditions.checkNotNull(client, \"client cannot be null\");\n  Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n  Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n  Preconditions.checkNotNull(payload, \"payload cannot be null\");\n  Preconditions.checkArgument(client.getZookeeperClient().isConnected(), \"client must be connected\");\n  Preconditions.checkArgument(ZKPaths.validPath(membershipPath), \"Invalid path: %s\", membershipPath);\n  Preconditions.checkArgument(ZKPaths.validId(thisId), \"Invalid id: %s\", thisId);\n  Preconditions.checkArgument(payload.length > 0, \"payload cannot be empty\");\n  this.client = client;\n  this.membershipPath = membershipPath;\n  this.thisId = thisId;\n  this.payload = payload;\n  this.cache = CuratorCache.build(client, membershipPath);\n  this.cache.listenable().addListener(new CuratorCacheListener() {\n    @Override\n    public void event(Type type, ChildData oldData, ChildData data) {\n      if (type == Type.NODE_CREATED) {\n        if (data.getPath().equals(memberPath)) {\n          if (state == State.STARTED) {\n            state = State.STARTED_AND_MEMBER;\n          } else {\n            state = State.MEMBER;\n          }\n        }\n      } else if (type == Type.NODE_REMOVED) {\n        if (data.getPath().equals(memberPath)) {\n          if (state == State.STARTED_AND_MEMBER) {\n            state = State.STARTED;\n          } else {\n            state = State.NONE;\n          }\n        }\n      }\n    }\n  });\n  this.cache.start();\n  this.cacheBridge = CuratorCacheBridge.newBuilder(cache).filter(parentPathFilter(membershipPath)).build();\n  this.cacheBridge.listenable().addListener(new Curator", "CodeBleu_score": 44.42699088044078}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    // Create an asynchronous CuratorFramework instance\n    AsyncCuratorFramework asyncClient = AsyncCuratorFramework.wrap(client);\n\n    // Create the node\n    asyncClient.create().forPath(path);\n\n    // Set up a watch on the node\n    asyncClient.create().withMode(WatchMode.PERSISTENT_RECURSIVE).forPath(path).whenComplete((path, e) -> {\n        if (e != null) {\n            e.printStackTrace();\n        } else {\n            System.out.println(\"Node created: \" + path);\n        }\n    });\n}", "CodeBleu_score": 59.496635870582615}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework asyncClient = AsyncCuratorFramework.wrap(client);\n    try {\n        CompletionStage<String> future = asyncClient.create().creatingParentsIfNeeded().forPath(path);\n        future.whenComplete((data, e) -> {\n            if (e != null) {\n                System.out.println(\"Exception: \" + e);\n            } else {\n                System.out.println(\"Created: \" + data);\n                asyncClient.getChildren().watched().withWatcher((curatorFramework, watchedEvent) -> {\n                    System.out.println(\"WatchedEvent: \" + watchedEvent);\n                }).forPath(path);\n            }\n        });\n    } catch (Exception e) {\n        System.out.println(\"Exception: \" + e);\n    }\n}", "CodeBleu_score": 52.35522180676742}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    AsyncCuratorFramework asyncClient = AsyncCuratorFramework.wrap(client);\n    CompletionStage<String> createStage = asyncClient.create().forPath(path);\n    createStage.whenComplete((path, error) -> {\n        if (error != null) {\n            System.out.println(\"Error creating node: \" + error.getMessage());\n            return;\n        }\n        CompletionStage<WatchedEvent> watchStage = asyncClient.watched().watching().withMode(WatchMode.PERSISTENT_RECURSIVE).forPath(path);\n        watchStage.whenComplete((event, error1) -> {\n            if (error1 != null) {\n                System.out.println(\"Error setting watch: \" + error1.getMessage());\n                return;\n            }\n            System.out.println(\"Watch set for path: \" + path);\n            System.out.println(\"Watch received event: \" + event);\n        });\n    });\n}", "CodeBleu_score": 49.03742344742311}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    final List<OpResult> results = RetryLoop.callWithRetry(new Callable<List<OpResult>>() {\n        @Override\n        public List<OpResult> call() throws Exception {\n            return getClient().getZooKeeper().multi(ops);\n        }\n    });\n    if (results.size() > 0) {\n        OpResult firstResult = results.get(0);\n        if (firstResult.getErr() != KeeperException.Code.OK.intValue()) {\n            KeeperException.Code code = KeeperException.Code.get(firstResult.getErr());\n            throw KeeperException.create(code, path);\n        }\n    }\n    return results;\n}", "CodeBleu_score": 54.16761200570922}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    final List<OpResult> results = new ImmutableList.Builder<OpResult>().build();\n    final List<Op> ops = new ImmutableList.Builder<Op>().build();\n    for (final Operation operation : operations) {\n        operation.validate();\n        ops.add(operation.getOp());\n    }\n    final Callable<List<OpResult>> callable = new Callable<List<OpResult>>() {\n        public List<OpResult> call() throws Exception {\n            return client.getZooKeeper().multi(ops);\n        }\n    };\n    final RetryLoop retryLoop = new RetryLoop(client.getRetryPolicy(), client.getRetryLoop(), client.getConnectionStateListenable());\n    results = retryLoop.callWithRetry(callable);\n    final OpResult firstResult = results.get(0);\n    if (firstResult.getType() != OpCode.CHECK) {\n        final KeeperException.Code code = KeeperException.Code.get(firstResult.getErr());\n        KeeperException.create(code, firstResult.getErr());\n    }\n    return results;\n}", "CodeBleu_score": 39.55318908085437}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = null;\n    try {\n        results = retryLoop.callWithRetry(new Callable<List<OpResult>>() {\n            @Override\n            public List<OpResult> call() throws Exception {\n                return client.getZooKeeper().multi(ops);\n            }\n        });\n    } catch (KeeperException.BadVersionException e) {\n        throw new KeeperException.BadVersionException(path, e);\n    } catch (KeeperException.NoNodeException e) {\n        throw new KeeperException.NoNodeException(path, e);\n    } catch (KeeperException.NodeExistsException e) {\n        throw new KeeperException.NodeExistsException(path, e);\n    } catch (KeeperException.NotEmptyException e) {\n        throw new KeeperException.NotEmptyException(path, e);\n    } catch (KeeperException.NoAuthException e) {\n        throw new KeeperException.NoAuthException(path, e);\n    } catch (KeeperException.BadArgumentsException e) {\n        throw new KeeperException.BadArgumentsException(path, e);\n    } catch (KeeperException.InvalidACLException e) {\n        throw new KeeperException.InvalidACLException(path, e);\n    } catch (KeeperException.AuthFailedException e) {\n        throw new KeeperException.AuthFailedException(path, e);\n    } catch (KeeperException.SessionExpiredException e) {\n        throw new KeeperException.SessionExpiredException(path, e);\n    } catch (KeeperException.SessionMovedException e) {\n        throw new KeeperException.SessionMovedException(path, e);\n    } catch (KeeperException.OperationTimeoutException e) {\n        throw new KeeperException.OperationTimeoutException(path, e);\n    }\n    if (results.isEmpty()) {\n        throw new IllegalStateException(\"Empty multi-op results\");\n    }\n    KeeperException.Code code = KeeperException.Code.get(results.get(0).getErr());\n    if (code != Kee", "CodeBleu_score": 33.79608997190461}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        Collection<String> serviceNames = serviceDiscovery.queryForNames();\n        for (String serviceName : serviceNames) {\n            ServiceProvider serviceProvider = serviceDiscovery.serviceProviderBuilder().serviceName(serviceName).build();\n            Collection<ServiceInstance<InstanceDetails>> instances = serviceProvider.getAllInstances();\n            System.out.println(serviceName + \" -> \" + instances);\n        }\n    } catch (KeeperException.NoNodeException e) {\n        System.out.println(\"No services registered\");\n    }\n    CloseableUtils.closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 54.557778504186516}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        Collection<String> serviceNames = serviceDiscovery.queryForNames();\n        for (String serviceName : serviceNames) {\n            ServiceProvider<InstanceDetails> serviceProvider = serviceDiscovery.serviceProviderBuilder().serviceName(serviceName).build();\n            try {\n                Collection<ServiceInstance<InstanceDetails>> instances = serviceProvider.getAllInstances();\n                System.out.println(serviceName + \" has \" + instances.size() + \" instances:\");\n                for (ServiceInstance<InstanceDetails> instance : instances) {\n                    System.out.println(instance.buildUriSpec());\n                }\n            } catch (KeeperException.NoNodeException e) {\n                System.out.println(serviceName + \" has no instances.\");\n            }\n        }\n    } finally {\n        CloseableUtils.closeQuietly(serviceDiscovery);\n    }\n}", "CodeBleu_score": 60.54683074801098}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    Collection<String> serviceNames = serviceDiscovery.queryForNames();\n    for (String serviceName : serviceNames) {\n        ServiceProvider<InstanceDetails> serviceProvider = serviceDiscovery.serviceProviderBuilder().serviceName(serviceName).build();\n        try {\n            List<ServiceInstance<InstanceDetails>> instances = serviceProvider.getAllInstances();\n            System.out.println(serviceName + \" has \" + instances.size() + \" instances.\");\n            for (ServiceInstance<InstanceDetails> instance : instances) {\n                System.out.println(\"  \" + instance.buildUriSpec());\n            }\n        } catch (KeeperException.NoNodeException e) {\n            System.out.println(\"No instances registered for \" + serviceName);\n        } finally {\n            serviceProvider.close();\n        }\n    }\n    serviceDiscovery.close();\n}", "CodeBleu_score": 54.91711279494458}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  List<String> filtered = Lists.newArrayList(Iterables.filter(children, new Predicate<String>() {\n    @Override\n    public boolean apply(String input) {\n      return !input.equals(READY_NODE);\n    }\n  }));\n\n  Collections.sort(filtered);\n  return filtered;\n}", "CodeBleu_score": 62.38944098215053}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t  List<String> filteredChildren = new ArrayList<String>();\n  for (String child : children) {\n    if (!child.equals(READY_NODE)) {\n      filteredChildren.add(child);\n    }\n  }\n  Collections.sort(filteredChildren);\n  return filteredChildren;\n}", "CodeBleu_score": 30.59513883980747}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return filterAndSortChildren(children, null);\n}", "CodeBleu_score": 9.649072996832425}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, 1000, this);\n    zk.register(this);\n    zk.addAuthInfo(\"digest\", \"cc1234:cc1234\".getBytes());\n    zk.create(\"/test\", \"test\".getBytes(), Ids.CREATOR_ALL_ACL, CreateMode.PERSISTENT);\n    zk.getData(\"/test\", false, new DataCallback() {\n        @Override\n        public void processResult(int i, String s, Object o, byte[] bytes, Stat stat) {\n            System.out.println(new String(bytes));\n        }\n    }, null);\n}", "CodeBleu_score": 31.68499178637067}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, 30000, this);\n    if (readOnly) {\n        zk.addAuthInfo(\"digest\", \"cc1234:cc1234\".getBytes(StandardCharsets.UTF_8));\n    }\n}", "CodeBleu_score": 31.00329961219573}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, 5000, new Watcher() {\n        public void process(WatchedEvent event) {\n            System.out.println(\"Watched event: \" + event.getType() + \" \" + event.getPath());\n        }\n    });\n}", "CodeBleu_score": 43.15139674435587}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> aclList = new ArrayList<>();\n    if (aclString == null || aclString.isEmpty()) {\n        return aclList;\n    }\n    String[] aclStrings = aclString.split(\",\");\n    for (String aclStr : aclStrings) {\n        String[] parts = aclStr.split(\":\");\n        if (parts.length != 3) {\n            logger.error(\"Invalid ACL string: \" + aclStr);\n            continue;\n        }\n        String scheme = parts[0];\n        String id = parts[1];\n        int perms = 0;\n        try {\n            perms = Integer.parseInt(parts[2]);\n        } catch (NumberFormatException e) {\n            logger.error(\"Invalid ACL string: \" + aclStr);\n            continue;\n        }\n        Id idObj;\n        if (scheme.equals(\"world\")) {\n            idObj = Ids.ANYONE_ID_UNSAFE;\n        } else if (scheme.equals(\"auth\")) {\n            idObj = new Id(\"auth\", id);\n        } else {\n            logger.error(\"Invalid ACL string: \" + aclStr);\n            continue;\n        }\n        ACL acl = new ACL(perms, idObj);\n        aclList.add(acl);\n    }\n    return aclList;\n}", "CodeBleu_score": 28.095272845850683}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> aclList = new ArrayList<ACL>();\n    if (aclString == null || aclString.length() == 0) {\n        return aclList;\n    }\n    String[] aclStrings = aclString.split(\",\");\n    for (String aclStr : aclStrings) {\n        String[] aclParts = aclStr.split(\":\");\n        if (aclParts.length != 3) {\n            LOG.error(\"Invalid ACL string: \" + aclStr);\n            continue;\n        }\n        try {\n            ACL acl = new ACL();\n            acl.setPerms(Integer.parseInt(aclParts[2]));\n            Id id = new Id(aclParts[0], aclParts[1]);\n            acl.setId(id);\n            aclList.add(acl);\n        } catch (NumberFormatException e) {\n            LOG.error(\"Invalid ACL string: \" + aclStr);\n        }\n    }\n    return aclList;\n}", "CodeBleu_score": 35.31263479038194}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acls = new ArrayList<>();\n    if (aclString != null) {\n        String[] aclArray = aclString.split(\",\");\n        for (String acl : aclArray) {\n            try {\n                ACL aclObj = new ACL();\n                String[] aclSegments = acl.split(\":\");\n                if (aclSegments.length != 3) {\n                    throw new IOException(\"Invalid ACL string. Expected format is scheme:id:permissions\");\n                }\n                aclObj.setId(new Id(aclSegments[0], aclSegments[1]));\n                aclObj.setPerms(Integer.parseInt(aclSegments[2]));\n                acls.add(aclObj);\n            } catch (Exception e) {\n                LOG.error(\"Invalid ACL string. Expected format is scheme:id:permissions\", e);\n            }\n        }\n    }\n    return acls;\n}", "CodeBleu_score": 29.550706019031498}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null || pathList.isEmpty()) {\n        throw new IllegalArgumentException(\"path list is null or empty\");\n    }\n    ServerConfiguration serverConfiguration = getServerConfiguration(serverId);\n    Zookeeper zookeeper = ZookeeperFactory.getInstance().connect(serverConfiguration);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(serverId, path);\n        }\n    } else {\n        deleteAsync(serverId, pathList);\n    }\n}", "CodeBleu_score": 55.76324702427695}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null || pathList.size() == 0) {\n        return;\n    }\n    Zookeeper zookeeper = ZookeeperFactory.getInstance(serverId);\n    if (zookeeper == null) {\n        throw new Exception(\"The server \" + serverId + \" is not connected.\");\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(zookeeper, path);\n        }\n    } else {\n        for (String path : pathList) {\n            deleteAsync(zookeeper, path);\n        }\n    }\n}", "CodeBleu_score": 55.08534041012073}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    if (pathList == null || pathList.isEmpty()) {\n        return;\n    }\n    ServerConfiguration serverConfiguration = getServerConfiguration(serverId);\n    if (serverConfiguration == null) {\n        throw new Exception(\"Server \" + serverId + \" not found.\");\n    }\n    Zookeeper zookeeper = ZookeeperFactory.getInstance().getZookeeper(serverId);\n    if (zookeeper == null) {\n        throw new Exception(\"Server \" + serverId + \" not connected.\");\n    }\n    if (pathList.size() <= 20) {\n        for (String path : pathList) {\n            zookeeper.delete(path, -1);\n        }\n    } else {\n        for (String path : pathList) {\n            zookeeper.delete(path, -1, new ZookeeperNodeListener() {\n                @Override\n                public void onSuccess(String path, String data, Stat stat) {\n                    log.info(\"delete {} success.\", path);\n                }\n\n                @Override\n                public void onError(String path, String data, Exception exception) {\n                    log.error(\"delete {} error.\", path, exception);\n                }\n            });\n        }\n    }\n}", "CodeBleu_score": 47.366781101004044}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \"...\n\");\n    CuratorZookeeperConnectionFactory factory = new CuratorZookeeperConnectionFactory();\n    ZookeeperParams params = new ZookeeperParams(url);\n    Zookeeper connection = factory.connect(params);\n    writer.write(\"Connected!\n\");\n    ZooKeeperMain main = new ZooKeeperMain(connection, new ServerListener() {\n        @Override\n        public void onServerChange(ServerConfiguration configuration) {\n        }\n\n        @Override\n        public void onSSHTunnelChange(SSHTunnelConfiguration configuration) {\n        }\n    }, new ZookeeperNodeListener() {\n        @Override\n        public void onZookeeperNodeChange(Zookeeper zookeeper) {\n        }\n    });\n    return new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 47.42089541965962}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url);\n    ZookeeperParams params = new ZookeeperParams(id, url);\n    CuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory();\n    Zookeeper connection = connectionFactory.create(params);\n    writer.write(\"Connected to \" + url);\n    ZooKeeperMain zooKeeperMain = new ZooKeeperMain(connection.getZooKeeper());\n    return new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 46.46033106601239}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to \" + url + \" ...\n\");\n    CuratorZookeeperConnectionFactory curatorZookeeperConnectionFactory = new CuratorZookeeperConnectionFactory();\n    ZookeeperParams params = new ZookeeperParams();\n    params.setUrl(url);\n    params.setTimeout(3000);\n    params.setSessionTimeout(3000);\n    params.setConnectionTimeout(3000);\n    params.setRetryPolicy(new RetryOneTime(3000));\n    params.setAuthScheme(\"digest\");\n    params.setAuthValue(\"cc1234:cc1234\");\n    Zookeeper zookeeper = curatorZookeeperConnectionFactory.connect(params);\n    writer.write(\"Successfully connected to \" + url + \".\n\");\n    ZooKeeperMain zooKeeperMain = new ZooKeeperMain(zookeeper.getClient());\n    return new Terminal(id, url, zookeeper, zooKeeperMain);\n}", "CodeBleu_score": 41.19745655533911}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t    int retries = 0;\n    while (retries < 6) {\n        try {\n            sshClient.connect(sshHost, sshPort);\n            sshClient.authPublickey(sshUser);\n            sshClient.startSession();\n            sshClient.getSession().allocateDefaultPTY();\n            sshClient.getSession().startShell();\n            sshClient.getSession().getStdin().write(sshCommand.getBytes());\n            sshClient.getSession().getStdin().flush();\n            sshClient.getSession().getStdin().close();\n            sshClient.getSession().getStdout().close();\n            sshClient.getSession().getStderr().close();\n            sshClient.getSession().close();\n            sshClient.disconnect();\n            return;\n        } catch (IOException e) {\n            log.error(\"SSH connection attempt {} failed: {}\", retries + 1, e.getMessage());\n            retries++;\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e1) {\n                log.error(\"SSH connection attempt {} failed: {}\", retries + 1, e.getMessage());\n            }\n        }\n    }\n    throw new IllegalStateException(\"SSH connection failed after \" + retries + \" attempts\");\n}", "CodeBleu_score": 37.69576359005447}, {"code": "public void blockUntilConnected(){\n\t    int retries = 0;\n    while (retries < 6) {\n        try {\n            if (sshClient.isConnected()) {\n                log.info(\"SSH tunnel is connected\");\n                return;\n            }\n            sshClient.connect(new InetSocketAddress(host, port), 5000);\n            sshClient.addHostKeyVerifier(new PromiscuousVerifier());\n            sshClient.authPassword(user, password);\n            log.info(\"SSH tunnel is connected\");\n            return;\n        } catch (IOException e) {\n            log.info(\"SSH tunnel connection attempt {} failed\", retries + 1);\n            retries++;\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e1) {\n                log.error(\"SSH tunnel connection attempt failed\", e1);\n                throw new IllegalStateException(\"SSH tunnel connection attempt failed\", e1);\n            }\n        }\n    }\n    log.error(\"SSH tunnel connection failed\");\n    throw new IllegalStateException(\"SSH tunnel connection failed\");\n}", "CodeBleu_score": 38.14084103700642}, {"code": "public void blockUntilConnected(){\n\t    final int maxAttempts = 6;\n    for (int attempt = 0; attempt < maxAttempts; attempt++) {\n        try {\n            if (attempt > 0) {\n                log.info(\"Attempt \" + (attempt + 1) + \" of \" + maxAttempts + \" to connect to \" + getHost() + \":\" + getPort());\n            }\n            connect();\n            return;\n        } catch (IOException e) {\n            log.warn(\"Failed to connect to \" + getHost() + \":\" + getPort() + \" on attempt \" + (attempt + 1) + \" of \" + maxAttempts + \": \" + e.getMessage());\n        }\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        }\n    }\n    throw new IllegalStateException(\"Failed to connect to \" + getHost() + \":\" + getPort() + \" after \" + maxAttempts + \" attempts\");\n}", "CodeBleu_score": 33.229714195060836}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        log.error(\"Delete node failed\", e);\n        throw new IllegalStateException(\"Delete node failed\");\n    }\n}", "CodeBleu_score": 73.42616023551119}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"delete node error\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 84.76376463468107}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"delete node error\", e);\n        throw new IllegalStateException(\"delete node error\");\n    }\n}", "CodeBleu_score": 69.56987178696313}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    CompletableFuture.runAsync(() -> {\n        TreeItemCache.remove(id);\n        ConfigurationVOTransfer.getInstance().remove(id);\n        ConfigurationDomainService.getInstance().remove(id);\n    }).thenRun(() -> {\n        Platform.runLater(() -> {\n            TreeItemCache.remove(id);\n            ConfigurationVOTransfer.getInstance().remove(id);\n            ConfigurationDomainService.getInstance().remove(id);\n        });\n    });\n}", "CodeBleu_score": 42.725476471204175}, {"code": "public void disconnect(String id){\n\t    CompletableFuture.runAsync(() -> {\n        try {\n            TreeItemCache.getInstance().getTreeItemById(id).ifPresent(treeItem -> {\n                ServerConfigurationVO vo = TreeItemCache.getInstance().getServerConfigurationVOById(id);\n                if (vo != null) {\n                    vo.setConnected(false);\n                    vo.setConnecting(false);\n                    vo.setDisconnecting(true);\n                    vo.setConnectionConfigurationVO(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZkNodeSearchResult(null);\n                    vo.setZ", "CodeBleu_score": 31.419762115046073}, {"code": "public void disconnect(String id){\n\t    CompletableFuture.runAsync(() -> {\n        TreeItemCache.remove(id);\n        ConfigurationVOTransfer.getInstance().remove(id);\n        ConfigurationDomainService.getInstance().disconnect(id);\n    }).exceptionally(throwable -> {\n        throwable.printStackTrace();\n        return null;\n    });\n}", "CodeBleu_score": 32.8429737490213}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfiguration server = configurationDomainService.getServerById(serverId);\n    ConnectionConfiguration connection = configurationDomainService.getConnectionById(server.getConnectionId());\n    String url = zookeeperDomainService.getConnectionUrl(server, connection);\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 43.541016213710876}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    // 1. get server configuration\n    ServerConfiguration serverConfiguration = configurationDomainService.getServerConfiguration(serverId);\n    // 2. get connection configuration\n    ConnectionConfiguration connectionConfiguration = configurationDomainService.getConnectionConfiguration(serverId);\n    // 3. get ssh tunnel configuration\n    SSHTunnelConfiguration sshTunnelConfiguration = configurationDomainService.getSSHTunnelConfiguration(serverId);\n    // 4. get connection url\n    String connectionUrl = zookeeperDomainService.getConnectionUrl(serverConfiguration, connectionConfiguration, sshTunnelConfiguration);\n    // 5. start terminal\n    zookeeperDomainService.startTerminal(serverId, connectionUrl, stream);\n}", "CodeBleu_score": 31.309038767065516}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    ServerConfigurationVO serverConfigurationVO = getServerConfigurationVO(serverId);\n    if (serverConfigurationVO == null) {\n        return;\n    }\n    if (serverConfigurationVO.getMode() == NodeMode.REMOTE) {\n        String sshTunnelUrl = getSSHTunnelUrl(serverConfigurationVO);\n        if (sshTunnelUrl != null) {\n            stream.println(\"Connecting to \" + sshTunnelUrl);\n            stream.println(\"\");\n            zookeeperDomainService.startTerminal(serverId, sshTunnelUrl, stream);\n        } else {\n            stream.println(\"Failed to connect to \" + serverConfigurationVO.getHost() + \":\" + serverConfigurationVO.getPort());\n            stream.println(\"\");\n        }\n    } else {\n        stream.println(\"Connecting to \" + serverConfigurationVO.getHost() + \":\" + serverConfigurationVO.getPort());\n        stream.println(\"\");\n        zookeeperDomainService.startTerminal(serverId, serverConfigurationVO.getHost() + \":\" + serverConfigurationVO.getPort(), stream);\n    }\n}", "CodeBleu_score": 37.39249393748646}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t    // TODO: 2019-08-19\n}", "CodeBleu_score": 7.627707831999869}, {"code": "public void executeCommand(String id, String command){\n\t    // TODO: 2019/8/10\n}", "CodeBleu_score": 7.627707831999869}, {"code": "public void executeCommand(String id, String command){\n\t    //TODO:\n}", "CodeBleu_score": 7.627707831999869}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties properties = new Properties();\n    FileInputStream fis = null;\n    try {\n        fis = new FileInputStream(System.getProperty(\"zookeeper.system.properties\", \"conf/zoo.cfg\"));\n        properties.load(fis);\n        fis.close();\n        return properties;\n    } catch (IOException e) {\n        System.out.println(\"Could not load zookeeper.system.properties from \" + System.getProperty(\"zookeeper.system.properties\", \"conf/zoo.cfg\"));\n        System.out.println(\"Exception: \" + e.getMessage());\n    } finally {\n        if (fis != null) {\n            try {\n                fis.close();\n            } catch (IOException e) {\n                // ignore\n            }\n        }\n    }\n    return properties;\n}", "CodeBleu_score": 41.34613791286266}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties props = new Properties();\n    try {\n        FileInputStream fis = new FileInputStream(System.getProperty(\"user.home\") + \"/.zookeeper/zookeeper.system.properties\");\n        props.load(fis);\n        fis.close();\n        System.out.println(\"Loaded \" + props.size() + \" system properties from \" + System.getProperty(\"user.home\") + \"/.zookeeper/zookeeper.system.properties\");\n    } catch (IOException e) {\n        System.out.println(\"Unable to load system properties from \" + System.getProperty(\"user.home\") + \"/.zookeeper/zookeeper.system.properties\");\n    }\n    return props;\n}", "CodeBleu_score": 38.28981400327485}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    Properties props = new Properties();\n    File file = new File(System.getProperty(\"user.home\") + File.separator + \".zookeeper\" + File.separator + \"zookeeper-env.sh\");\n    if (file.exists()) {\n        try (FileInputStream fis = new FileInputStream(file)) {\n            props.load(fis);\n            logger.info(\"Loaded system properties from {}\", file.getAbsolutePath());\n        } catch (IOException e) {\n            logger.error(\"Failed to load system properties from {}\", file.getAbsolutePath(), e);\n        }\n    } else {\n        logger.info(\"System properties file {} does not exist. Skipping.\", file.getAbsolutePath());\n    }\n    return props;\n}", "CodeBleu_score": 41.65980052734917}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    try {\n        Properties properties = new Properties();\n        properties.load(new StringReader(content));\n        File file = new File(SYS_PROP_PATH);\n        try (OutputStream out = new FileOutputStream(file)) {\n            properties.store(out, \"Zookeeper system properties\");\n        }\n    } catch (IOException e) {\n        LOGGER.error(\"save zookeeper system properties failed\", e);\n        VToast.error(\"save zookeeper system properties failed\");\n    }\n}", "CodeBleu_score": 34.981236818688195}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"failed to load properties from string\", e);\n        VToast.error(\"failed to load properties from string\");\n        return;\n    }\n    try {\n        FileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\n        props.store(fos, \"Zookeeper system properties\");\n    } catch (IOException e) {\n        log.error(\"failed to save properties to file\", e);\n        VToast.error(\"failed to save properties to file\");\n    }\n}", "CodeBleu_score": 36.241442030544455}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        logger.error(\"load zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.getBaseBundle().getString(\"message.zookeeper.system.properties.load.error\"));\n        return;\n    }\n    try {\n        FileOutputStream fos = new FileOutputStream(SYS_PROP_PATH);\n        properties.store(fos, \"\");\n        fos.close();\n    } catch (IOException e) {\n        logger.error(\"save zookeeper system properties error\", e);\n        VToast.error(ResourceBundleUtils.getBaseBundle().getString(\"message.zookeeper.system.properties.save.error\"));\n    }\n}", "CodeBleu_score": 42.656497371043784}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder sb = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            sb.append(line);\n        }\n        client.close();\n        return sb.toString();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Error reading from client\", e);\n    }\n}", "CodeBleu_score": 56.70548388093759}, {"code": "private String response(Socket client){\n\t\ttry {\n\t\tBufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n\t\tStringBuilder sb = new StringBuilder();\n\t\tString line;\n\t\twhile ((line = in.readLine()) != null) {\n\t\t\tsb.append(line);\n\t\t}\n\t\tin.close();\n\t\tclient.close();\n\t\treturn sb.toString();\n\t} catch (Exception e) {\n\t\tthrow new IllegalStateException(\"Error while reading response from client\", e);\n\t}\n}", "CodeBleu_score": 51.469673999759365}, {"code": "private String response(Socket client){\n\t    try {\n        BufferedReader in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        StringBuilder sb = new StringBuilder();\n        String line;\n        while ((line = in.readLine()) != null) {\n            sb.append(line);\n        }\n        in.close();\n        client.close();\n        return sb.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 58.76912835522952}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = null;\n    try {\n        RetryPolicy retryPolicy = new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries());\n        client = CuratorFrameworkFactory.builder()\n                .connectString(params.getConnectString())\n                .sessionTimeoutMs(params.getSessionTimeoutMs())\n                .connectionTimeoutMs(params.getConnectionTimeoutMs())\n                .retryPolicy(retryPolicy)\n                .aclProvider(new ACLProvider() {\n                    @Override\n                    public List<ACL> getDefaultAcl() {\n                        return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n                    }\n\n                    @Override\n                    public List<ACL> getAclForPath(String path) {\n                        return ZooDefs.Ids.OPEN_ACL_UNSAFE;\n                    }\n                })\n                .authorization(params.getAuthScheme(), params.getAuthData())\n                .build();\n        client.start();\n        client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n            @Override\n            public void stateChanged(CuratorFramework client, ConnectionState newState) {\n                if (newState == ConnectionState.SUSPENDED || newState == ConnectionState.LOST) {\n                    client.close();\n                }\n            }\n        });\n        client.getCuratorListenable().addListener((client1, event) -> {\n            if (event.getType() == CuratorEventType.EXCEPTION) {\n                client1.close();\n            }\n        });\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            client.close();\n            throw new RuntimeException(\"zookeeper connection failed.\");\n        }\n        return new CuratorZookeeperConnection(client, params.getServerListener());\n    } catch (Exception e) {\n        if (client != null) {\n            client.close();\n        }\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 39.3729689132084}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = createCuratorClient(params);\n    try {\n        client.start();\n        if (!client.blockUntilConnected(5, TimeUnit.SECONDS)) {\n            client.close();\n            throw new ZookeeperException(\"Zookeeper connection failed\");\n        }\n    } catch (InterruptedException e) {\n        client.close();\n        throw new ZookeeperException(\"Zookeeper connection failed\");\n    }\n    return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 69.83291589088549}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    RetryPolicy retryPolicy = new ExponentialBackoffRetry(params.getBaseSleepTimeMs(), params.getMaxRetries());\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(params.getConnectString())\n            .sessionTimeoutMs(params.getSessionTimeoutMs())\n            .connectionTimeoutMs(params.getConnectionTimeoutMs())\n            .retryPolicy(retryPolicy)\n            .authorization(params.getAuthInfo())\n            .aclProvider(params.getAclProvider())\n            .build();\n    client.start();\n    try {\n        client.blockUntilConnected(params.getConnectionTimeoutMs(), TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        client.close();\n        throw new IllegalStateException(e);\n    }\n    return new CuratorZookeeperConnection(client, params.getServerListener());\n}", "CodeBleu_score": 40.36602482415665}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = zookeeperConnection.getConnectionString();\n    if (isSyncInProgress.get()) {\n        LOGGER.info(\"Synchronization already in progress. Skipping synchronization.\");\n        return;\n    }\n    LOGGER.info(\"Starting synchronization with Zookeeper connection string: {}\", connectionString);\n    TreeCache treeCache = new TreeCache(zookeeperConnection.getClient(), \"/\");\n    treeCache.getListenable().addListener((client, event) -> {\n        if (event.getData() == null) {\n            return;\n        }\n        switch (event.getType()) {\n            case NODE_ADDED:\n                for (ZookeeperNodeListener listener : listeners) {\n                    listener.onNodeAdded(event.getData().getPath(), event.getData().getData());\n                }\n                break;\n            case NODE_UPDATED:\n                for (ZookeeperNodeListener listener : listeners) {\n                    listener.onNodeUpdated(event.getData().getPath(), event.getData().getData());\n                }\n                break;\n            case NODE_REMOVED:\n                for (ZookeeperNodeListener listener : listeners) {\n                    listener.onNodeRemoved(event.getData().getPath());\n                }\n                break;\n            default:\n                break;\n        }\n    });\n    try {\n        treeCache.start();\n        isSyncInProgress.set(true);\n    } catch (Exception e) {\n        LOGGER.error(\"Error while starting synchronization with Zookeeper connection string: {}\", connectionString, e);\n        try {\n            treeCache.close();\n        } catch (Exception ex) {\n            LOGGER.error(\"Error while closing synchronization with Zookeeper connection string: {}\", connectionString, ex);\n        }\n    }\n}", "CodeBleu_score": 40.375998789489294}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = zookeeperConnection.getConnectionString();\n    if (connectionString == null) {\n        log.warn(\"Zookeeper connection string is null\");\n        return;\n    }\n\n    if (syncInProgress.getAndSet(true)) {\n        log.info(\"Zookeeper sync already in progress\");\n        return;\n    }\n\n    log.info(\"Start zookeeper sync, connection string: {}\", connectionString);\n\n    try {\n        treeCache = TreeCache.newBuilder(client, \"/\")\n                .setCacheData(true)\n                .setCacheData(false)\n                .setExecutor(executor)\n                .build();\n\n        treeCache.getListenable().addListener((client, event) -> {\n            try {\n                switch (event.getType()) {\n                    case NODE_ADDED:\n                        nodeAdded(event);\n                        break;\n                    case NODE_UPDATED:\n                        nodeUpdated(event);\n                        break;\n                    case NODE_REMOVED:\n                        nodeRemoved(event);\n                        break;\n                    case INITIALIZED:\n                        initialized();\n                        break;\n                    default:\n                        break;\n                }\n            } catch (Exception e) {\n                log.error(\"Zookeeper sync error\", e);\n            }\n        });\n\n        treeCache.start();\n    } catch (Exception e) {\n        log.error(\"Zookeeper sync error\", e);\n        closeTreeCache();\n    }\n}", "CodeBleu_score": 39.05842806300508}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    if (syncInProgress.get()) {\n        LOGGER.info(\"Synchronization is already in progress.\");\n        return;\n    }\n    LOGGER.info(\"Synchronizing nodes...\");\n    try {\n        TreeCache treeCache = new TreeCache(getConnection().getClient(), \"/\");\n        treeCache.getListenable().addListener(new CuratorTreeCacheListener(listeners));\n        treeCache.start();\n        syncInProgress.set(true);\n    } catch (Exception e) {\n        LOGGER.error(\"An error occurred while synchronizing nodes.\", e);\n        close();\n    }\n}", "CodeBleu_score": 49.31353423132296}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    // \u521b\u5efa\u4e00\u4e2aCuratorFramework\u5b9e\u4f8b\n    CuratorFramework client = CuratorFrameworkFactory.newClient(Constant.ZK_CONNECT_STRING, new ExponentialBackoffRetry(1000, 3));\n    // \u5f00\u542fCuratorFramework\u5b9e\u4f8b\n    client.start();\n    // \u521b\u5efa\u4e00\u4e2aPathChildrenCache\n    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    // \u542f\u52a8PathChildrenCache\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    // \u6dfb\u52a0PathChildrenCacheListener\u76d1\u542c\u5668\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 64.2530040508914}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache pathChildrenCache = new PathChildrenCache(this.client, path, true);\n    pathChildrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathChildrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 72.36256939005969}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    CuratorFramework client = CuratorFrameworkFactory.newClient(Constant.ZK_CONNECTION_STRING, new ExponentialBackoffRetry(1000, 3));\n    client.start();\n    PathChildrenCache pathCache = new PathChildrenCache(client, path, true);\n    pathCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    pathCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 66.41755604967783}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t    logger.info(\"Unregistering services...\");\n    try {\n        List<String> paths = new ArrayList<String>();\n        for (Map.Entry<String, RpcServiceInfo> entry : serviceInfoMap.entrySet()) {\n            String path = entry.getKey();\n            paths.add(path);\n        }\n        for (String path : paths) {\n            try {\n                curatorClient.delete(path);\n            } catch (Exception e) {\n                logger.error(\"Error deleting path: \" + path, e);\n            }\n        }\n        logger.info(\"Unregistered services.\");\n    } catch (Exception e) {\n        logger.error(\"Error unregistering services.\", e);\n    }\n}", "CodeBleu_score": 30.156255940024668}, {"code": "public void unregisterService(){\n\t    try {\n        logger.info(\"Unregistering service...\");\n        for (String path : servicePaths) {\n            try {\n                curatorClient.delete(path);\n            } catch (Exception e) {\n                logger.error(\"Error deleting path: \" + path + \". Error message: \" + e.getMessage());\n            }\n        }\n        logger.info(\"Service unregistered.\");\n    } finally {\n        curatorClient.close();\n    }\n}", "CodeBleu_score": 49.51320059354071}, {"code": "public void unregisterService(){\n\t    logger.info(\"Unregistering service...\");\n    List<String> servicePaths = new ArrayList<>();\n    for (Map.Entry<String, RpcServiceInfo> entry : serviceMap.entrySet()) {\n        String serviceName = entry.getKey();\n        String servicePath = Constant.ZK_REGISTRY_PATH + \"/\" + serviceName;\n        servicePaths.add(servicePath);\n    }\n    for (String servicePath : servicePaths) {\n        try {\n            curatorClient.delete(servicePath);\n        } catch (Exception e) {\n            logger.error(\"Error while unregistering service: \" + e.getMessage());\n        }\n    }\n    logger.info(\"Service unregistered successfully.\");\n    curatorClient.close();\n}", "CodeBleu_score": 34.335371091518255}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture<Void> future = new CompletableFuture<>();\n    try {\n        makeClientReady(future);\n    } catch (Exception e) {\n        future.completeExceptionally(e);\n    }\n    future.thenAccept(aVoid -> {\n        try {\n            client.subscribeStateChanges(listener);\n        } catch (Exception e) {\n            logger.error(\"Error subscribing listener to state changes\", e);\n        }\n    });\n}", "CodeBleu_score": 28.335334838303304}, {"code": "public void addListener(IZkStateListener listener){\n\t    try {\n        makeClientReady().get(30, TimeUnit.SECONDS);\n        client.subscribeStateChanges(listener);\n    } catch (Exception e) {\n        LOG.error(\"Error while adding listener\", e);\n    }\n}", "CodeBleu_score": 28.94232837032531}, {"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture<ZkClient> future = new CompletableFuture<>();\n    future.thenAccept(zkClient -> {\n        zkClient.subscribeStateChanges(listener);\n        LOG.info(\"Subscribed listener {} to state changes in Zookeeper client\", listener);\n    });\n    makeClientReady(future);\n}", "CodeBleu_score": 33.71465354860911}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.client = CuratorFrameworkFactory.builder()\n            .connectString(serverAddr)\n            .retryPolicy(new RetryNTimes(1, 1000))\n            .connectionTimeoutMs(10000)\n            .build();\n    this.client.getConnectionStateListenable().addListener(new ConnectionStateListener() {\n        @Override\n        public void stateChanged(CuratorFramework client, ConnectionState newState) {\n            if (newState == ConnectionState.LOST) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.DISCONNECTED);\n            } else if (newState == ConnectionState.CONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.CONNECTED);\n            } else if (newState == ConnectionState.RECONNECTED) {\n                CuratorZookeeperClient.this.stateChanged(StateListener.RECONNECTED);\n            }\n        }\n    });\n    this.client.start();\n    try {\n        if (this.client.checkExists().forPath(\"/\") == null) {\n            this.client.create().forPath(\"/\");\n        }\n    } catch (Exception e) {\n        throw new IllegalStateException(e.getMessage(), e);\n    }\n}", "CodeBleu_score": 69.55772859218466}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this(serverAddr, authority, 10000, new RetryNTimes(3, 1000));\n}", "CodeBleu_score": 3.4330769083914414}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this(serverAddr, authority, 10000);\n}", "CodeBleu_score": 3.410257367346581}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    ConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            zookeeperClient.removeTargetChildListener(path, targetListener);\n        }\n    }\n}", "CodeBleu_score": 81.17079988198324}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    if (listener == null) {\n        throw new IllegalArgumentException(\"listener == null\");\n    }\n    ConcurrentMap<ChildListener, TargetChildListener> listeners = childListeners.get(path);\n    if (listeners != null) {\n        TargetChildListener targetListener = listeners.remove(listener);\n        if (targetListener != null) {\n            targetListener.getListeners().remove(listener);\n            if (targetListener.getListeners().isEmpty()) {\n                childListeners.remove(path);\n                try {\n                    zookeeper.getChildren(path, targetListener);\n                } catch (Exception e) {\n                    logger.warn(e.getMessage(), e);\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 66.79848483907686}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Set<ChildListener> listeners = zkListeners.get(path);\n    if (listeners != null) {\n        listeners.remove(listener);\n    }\n    if (listeners != null && listeners.isEmpty()) {\n        zkListeners.remove(path);\n        try {\n            zookeeper.remove", "CodeBleu_score": 46.1126264122849}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t\n    int ret = QCONF_ERR_OTHER;\n\n    if (zh == NULL) {\n        QCONF_LOG_ERROR(\"Invalid zk handle\");\n        return QCONF_ERR_OTHER;\n    }\n\n    char *idc = NULL;\n    char *zk_host = NULL;\n\n    ret = qconf_get_idc_by_handle(zh, &idc);\n    if (QCONF_OK != ret) {\n        QCONF_LOG_ERROR(\"Get idc by handle failed\");\n        return ret;\n    }\n\n    ret = qconf_get_zk_host_by_handle(zh, &zk_host);\n    if (QCONF_OK != ret) {\n        QCONF_LOG_ERROR(\"Get zk host by handle failed\");\n        return ret;\n    }\n\n    qconf_delete_idc_by_handle(zh);\n    qconf_delete_zk_host_by_handle(zh);\n\n    qconf_destroy_handle(zh);\n\n    ret = qconf_init_handle(idc, zk_host);\n    if (QCONF_OK != ret) {\n        QCONF_LOG_ERROR(\"Init handle failed\");\n        return ret;\n    }\n\n    ret = qconf_init_env();\n    if (QCONF_OK != ret) {\n        QCONF_LOG_ERROR(\"Init env failed\");\n        return ret;\n    }\n\n    ret = qconf_init_table_watcher();\n    if (QCONF_OK != ret) {\n        QCONF_LOG_ERROR(\"Init table watcher failed\");\n        return ret;\n    }\n\n    return QCONF_OK;\n}", "CodeBleu_score": 37.357893357892074}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    char idc_host_path[QCONF_MAX_BUF_LEN] = {0};\n    char idc_host_content[QCONF_MAX_BUF_LEN] = {0};\n    char *idc_host_content_ptr = NULL;\n    int idc_host_content_len = 0;\n    char *idc_host_ptr = NULL;\n    char *host_ptr = NULL;\n    int ret = 0;\n    int host_len = 0;\n    int idc_len = 0;\n\n    if (NULL == zh) {\n        return QCONF_ERR_OTHER;\n    }\n\n    ret = qconf_get_idc_host(idc_host_path, QCONF_MAX_BUF_LEN);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_get_host(idc_host_path, idc_host_content, QCONF_MAX_BUF_LEN, &idc_host_content_len);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_host(idc_host_path);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_idc(idc_host_path);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_idc_host(idc_host_path);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_idc_host_list(idc_host_path);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_idc_host_list_lock(idc_host_path);\n    if (QCONF_OK != ret) {\n        return ret;\n    }\n\n    ret = qconf_delete_idc_", "CodeBleu_score": 31.79675345942537}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t    int ret = QCONF_ERR_OTHER;\n    char idc[QCONF_HOST_MAX_SIZE] = {0};\n    char host[QCONF_HOST_MAX_SIZE] = {0};\n    char port[QCONF_PORT_MAX_SIZE] = {0};\n    char path[QCONF_PATH_MAX_SIZE] = {0};\n    char *idc_host_info = NULL;\n    char *idc_host_info_head = NULL;\n    char *idc_host_info_tail = NULL;\n    char *host_info = NULL;\n    char *host_info_head = NULL;\n    char *host_info_tail = NULL;\n    char *host_info_end = NULL;\n    int host_info_len = 0;\n    int idc_host_info_len = 0;\n    int idc_host_info_len_head = 0;\n    int idc_host_info_len_tail = 0;\n    int idc_host_info_len_head_old = 0;\n    int idc_host_info_len_tail_old = 0;\n    int idc_host_info_len_head_new = 0;\n    int idc_host_info_len_tail_new = 0;\n    int idc_host_info_len_head_tmp = 0;\n    int idc_host_info_len_tail_tmp = 0;\n    int idc_host_info_len_head_tmp_old = 0;\n    int idc_host_info_len_tail_tmp_old = 0;\n    int idc_host_info_len_head_tmp_new = 0;\n    int idc_host_info_len_tail_tmp_new = 0;\n    int idc_host_info_len_head_tmp_new_old = 0;\n    int idc_host_info_len_tail_tmp_new_old = 0;\n    int idc_host_info_len_head_tmp_new_new = 0;\n    int idc", "CodeBleu_score": 15.388846691275116}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n    // update the zk handle info\n    zk_handle_map.insert(make_pair(zh, idc_host));\n\n    // check the connection state of the zk handle\n    if (ZOO_CONNECTED_STATE != zoo_state(zh)) {\n        return;\n    }\n\n    // register the current host on the Zookeeper server\n    string path = ZK_PATH_PREFIX + \"/\" + idc + \"/\" + ZK_HOST_NODE;\n    zoo_create(zh, path.c_str(), \"\", 0, &ZOO_OPEN_ACL_UNSAFE, 0, 0, 0);\n\n    // set a watcher on the notify node\n    path = ZK_PATH_PREFIX + \"/\" + idc + \"/\" + ZK_NOTIFY_NODE;\n    zoo_wget(zh, path.c_str(), watcher_notify_node, 0, 0, 0);\n\n    // check the result of setting the watcher\n    if (ZOK != zoo_state(zh)) {\n        // add the IDC to a gray list\n        gray_list.insert(idc);\n        // log an error\n        QCONF_LOG_ERR(\"set watcher on notify node failed: %s\", zerror(zoo_state(zh)));\n    }\n}", "CodeBleu_score": 42.25855973967758}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    int rc = zoo_state(zh);\n\n    if (ZOO_CONNECTED_STATE != rc) {\n        QCONF_FATAL_LOG(\"zoo_state() failed, rc:%d, idc:%s\", rc, idc.c_str());\n        return;\n    }\n\n    // set watcher\n    char buf[QCONF_HOST_LENGTH_MAX];\n    sprintf(buf, \"%s/%s\", QCONF_GRAY_NODE, idc.c_str());\n    rc = zoo_wget(zh, buf, qconf_watcher_gray_callback, NULL);\n    if (ZOK != rc) {\n        QCONF_FATAL_LOG(\"zoo_wget() failed, rc:%d, idc:%s\", rc, idc.c_str());\n        return;\n    }\n\n    // register current host\n    char host[QCONF_HOST_LENGTH_MAX];\n    rc = gethostname(host, sizeof(host));\n    if (0 != rc) {\n        QCONF_FATAL_LOG(\"gethostname() failed, rc:%d, idc:%s\", rc, idc.c_str());\n        return;\n    }\n\n    sprintf(buf, \"%s/%s/%s\", QCONF_GRAY_NODE, idc.c_str(), host);\n    rc = zoo_create(zh, buf, NULL, 0, &ZOO_OPEN_ACL_UNSAFE, 0, NULL, 0);\n    if (ZOK != rc && ZNODEEXISTS != rc) {\n        QCONF_FATAL_LOG(\"zoo_create() failed, rc:%d, idc:%s\", rc, idc.c_str());\n        return;\n    }\n\n    // add idc to gray list\n    if (ZNODEEXISTS == rc) {\n        gray_list_add(idc);\n    }\n}", "CodeBleu_score": 41.55337099268818}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t\n    if (zh == NULL) {\n        return;\n    }\n\n    // Update the internal tables with the handle and host information\n    zk_hosts_map.insert(make_pair(zh, idc_host));\n\n    // Check the connection state of the Zookeeper handle\n    if (zk_connected(zh) == 0) {\n\n        // Register the current host on the Zookeeper server\n        if (zk_register_host(zh, idc) != 0) {\n            QCONF_LOG_ERR(\"Register host:%s on idc:%s failed!\", idc_host.c_str(), idc.c_str());\n            return;\n        }\n\n        // Set a watcher on the notify node\n        if (zk_set_watcher(zh, idc) != 0) {\n            QCONF_LOG_ERR(\"Set watcher on idc:%s failed!\", idc.c_str());\n            return;\n        }\n\n        // Add the IDC to a gray list if the operation fails\n        if (zk_get_watcher(zh) != 0) {\n            QCONF_LOG_ERR(\"Get watcher on idc:%s failed!\", idc.c_str());\n            zk_gray_list.insert(idc);\n        }\n    }\n}", "CodeBleu_score": 40.967826758661765}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    return \"{}:{}\".format(\n        username,\n        b64encode(\n            hashlib.sha1(\n                \"{}:{}\".format(username, password).encode(\"utf-8\")\n            ).digest()\n        ).decode(\"utf-8\")\n    )\n\n", "CodeBleu_score": 27.576945258753877}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    return \"{}:{}\".format(username, b64encode(hashlib.sha1(password.encode()).digest()).decode())\n\n", "CodeBleu_score": 16.625494782352668}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    hashed = hashlib.sha1(f\"{username}:{password}\".encode(\"utf-8\")).digest()\n    return f\"{username}:{b64encode(hashed).decode('utf-8')}\"\n\n", "CodeBleu_score": 20.620566278303816}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n\n    lock_path = self.processing_element.get_lock_path()\n    try:\n        lock_value, stat = self.client.client.get(lock_path)\n    except NoNodeError:\n        return False\n\n    if lock_value.decode() == self.instance_id:\n        return True\n    else:\n        return False\n\n", "CodeBleu_score": 43.131268693589256}, {"code": "def holds_lock(self)\n\t\n    if not self.processing_element:\n        return False\n    lock_path = self.processing_element.lock_path\n    try:\n        lock_value = self.client.get(lock_path)[0]\n    except NoNodeError:\n        return False\n    return lock_value == self.instance_id\n\n", "CodeBleu_score": 37.24221201025636}, {"code": "def holds_lock(self)\n\t\n    if self.processing_element is None:\n        return False\n    try:\n        lock_value = self.zk_client.get(self.processing_element.lock_path)[0]\n        return lock_value.decode() == self.instance_id\n    except NoNodeError:\n        return False\n\n", "CodeBleu_score": 38.17983095306168}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing is not None and self.lock.is_acquired:\n        try:\n            self.zk.transaction(self.delete_lock_and_entry)\n            self.processing = None\n            return True\n        except (NoNodeError, NodeExistsError):\n            return False\n    return False\n\n", "CodeBleu_score": 24.43772140179097}, {"code": "def consume(self)\n\t\n    if self.processing_element is None or not self.lock.is_acquired:\n        return False\n    try:\n        self.zk.transaction(\n            [\n                self.zk.delete(self.lock.path),\n                self.zk.delete(self.path),\n            ]\n        )\n        self.processing_element = None\n        return True\n    except (NoNodeError, NodeExistsError):\n        return False\n\n", "CodeBleu_score": 35.39910922066138}, {"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.lock_held:\n        try:\n            self.zk.transaction(\n                lambda txn: [\n                    txn.delete(self.lock_path),\n                    txn.delete(self.entry_path),\n                ]\n            )\n        except (NoNodeError, NodeExistsError):\n            return False\n        except ForceRetryError:\n            return False\n        else:\n            self.processing_element = None\n            self.lock_held = False\n            return True\n    return False\n\n", "CodeBleu_score": 36.80038339486917}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    if not self.connected_event.is_set():\n        raise ConnectionDropped(\n            \"Connection is no longer valid. \"\n            \"Current state: %s\" % self.state\n        )\n    if self.state == KeeperState.CLOSED:\n        raise ConnectionDropped(\"Connection is closed\")\n\n    if self.state == KeeperState.CONNECTING:\n        self._handle_connect()\n\n    if self.state == KeeperState.CONNECTED_RO or self.state == KeeperState.CONNECTED_READ_ONLY:\n        self._handle_read_only()\n\n    # This is a bit of a hack. We want to be able to test\n    # the read_timeout logic, but we don't want to actually\n    # wait for the timeout.\n    if read_timeout == 0:\n        read_timeout = 1\n\n    # We need to read the header first\n    header = self._read_length(4)\n    if not header:\n        raise ConnectionDropped(\"Socket closed\")\n\n    length = int_struct.unpack(header)[0]\n    if length < 4:\n        raise ValueError(\"Invalid length: %s\" % length)\n\n    # Now read the rest of the buffer\n    buffer = self._read_length(length - 4)\n    if not buffer:\n        raise ConnectionDropped(\"Socket closed\")\n\n    # Now we can process the message\n    header = ReplyHeader.deserialize(header + buffer)\n    if header.xid == Ping.XID:\n        self._handle_ping(header)\n    elif header.xid == SASL.XID:\n        self._handle_sasl(header)\n    elif header.xid == Watch.XID:\n        self._handle_watch(header)\n    elif header.xid == Auth.XID:\n        self._handle_auth(header)\n    elif header.xid == Exists.XID:\n        self._handle_exists(header)\n    elif header.xid == GetChildren.XID:\n        self._handle_get_children(header)\n    elif", "CodeBleu_score": 32.51457858710367}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = self._read_header(read_timeout)\n        if header.xid == Ping.XID:\n            self._handle_ping()\n        elif header.xid == Auth.XID:\n            self._handle_auth(header)\n        elif header.xid == Watch.XID:\n            self._handle_watch(header)\n        else:\n            self._handle_response(header)\n    except (socket.timeout, socket.error):\n        raise ConnectionDropped(\"Socket read timed out\")\n\n", "CodeBleu_score": 23.372746690275964}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        # Read the header\n        header = self._read_response(ReplyHeader)\n\n        if header.xid == Ping.XID:\n            # We got a ping, so clear the outstanding ping flag\n            self._clear_watcher_flag()\n            return\n\n        if header.xid == Auth.XID:\n            # We got an auth response\n            if header.zxid == -1:\n                # Authentication failed\n                self._state = KeeperState.AUTH_FAILED\n                raise AuthFailedError(header.err)\n            else:\n                # Authentication succeeded\n                self._state = KeeperState.CONNECTED\n                self._retry.stop()\n                self._auth_data = self._read_response(Auth)\n                return\n\n        if header.xid == Watch.XID:\n            # We got a watch event\n            event = self._read_response(WatchedEvent)\n            if event.type == EVENT_TYPE_MAP[\"None\"]:\n                # The watch was removed\n                self._remove_watcher(event.watcher)\n            else:\n                # The watch was triggered\n                event.watcher(event)\n            return\n\n        # We got a response, so clear the outstanding ping flag\n        self._clear_watcher_flag()\n\n        if header.xid in self._requests:\n            # We got a response to an outstanding request\n            cb = self._requests[header.xid]\n            del self._requests[header.xid]\n            cb(header, self._read_buffer(header.length))\n        else:\n            # We got an unexpected response\n            logging.warning(\"Received unexpected response: %s\", header)\n\n    except socket.timeout:\n        # We timed out reading from the socket\n        if self._state == KeeperState.CONNECTED:\n            # We were connected, so this is an unexpected timeout\n            logging.warning(\"Unexpected timeout while reading from socket\")\n            self._retry.stop()\n            self._state = KeeperState.CONNECTION_LOST\n            self._event.set()\n        else:\n            # We were", "CodeBleu_score": 32.51584043764845}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.logger.debug(\"Starting zk_loop\")\n    self.connection_stopped.clear()\n    while not self.stopped:\n        try:\n            self.connect()\n        except Exception as e:\n            self.logger.warning(\"Connection attempt failed: %s\", e)\n        else:\n            break\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED)\n    self.logger.debug(\"Stopped zk_loop\")\n\n", "CodeBleu_score": 36.849321558454164}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting zookeeper loop\")\n    self.connection_stopped.clear()\n    while not self.stopped:\n        try:\n            self.retry(self.connect)\n            self.session_callback(KeeperState.CONNECTED)\n            break\n        except Exception as e:\n            self.logger.warning(\"Connection failed: %s\", e)\n            self.session_callback(KeeperState.CONNECTING)\n            if self.stopped:\n                break\n            time.sleep(random.uniform(0.5, 1.0))\n    self.connection_stopped.set()\n    self.session_callback(KeeperState.CLOSED)\n    self.logger.info(\"Stopping zookeeper loop\")\n\n", "CodeBleu_score": 47.57581564554126}, {"code": "def zk_loop(self)\n\t\n    self.logger.debug(\"Starting Zookeeper loop\")\n    self.connection_stopped.clear()\n    while not self.stopped:\n        try:\n            self.retry(self.connect)\n        except Exception:\n            self.logger.warning(\"Connection failed, retrying\", exc_info=True)\n        else:\n            break\n\n    self.logger.debug(\"Zookeeper loop stopped\")\n    self.session_callback(KeeperState.CLOSED)\n    self.connection_stopped.set()\n\n", "CodeBleu_score": 38.43735958147973}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members.sort()\n    partitions.sort()\n    try:\n        index = members.index(identifier)\n    except ValueError:\n        raise ValueError('Identifier not found in member list')\n    return [partitions[i] for i in range(index, len(partitions), len(members))]\n\n", "CodeBleu_score": 44.372586078753216}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    members = sorted(members)\n    partitions = sorted(partitions)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    sorted_members = sorted(members)\n    sorted_partitions = sorted(partitions)\n    member_index = sorted_members.index(identifier)\n    return sorted_partitions[member_index::len(sorted_members)]\n\n", "CodeBleu_score": 34.32776522517974}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    if not self.participating:\n        return\n\n    # Check if we are the last node to leave\n    try:\n        self.client.delete(self.path)\n    except NoNodeError:\n        pass\n\n    # Check if all nodes have left\n    while self.client.exists(self.path):\n        try:\n            self.client.ensure_path(self.path)\n        except KazooException:\n            pass\n\n    self.participating = False\n\n", "CodeBleu_score": 44.63831026930364}, {"code": "def leave(self)\n\t\n    self.participating = False\n    try:\n        self.client.delete(self.path)\n    except NoNodeError:\n        pass\n    except KazooException as e:\n        self.logger.exception(\n            \"Exception during leave: %s. Performing best-effort cleanup.\", e)\n        try:\n            self.client.delete(self.path)\n        except NoNodeError:\n            pass\n\n", "CodeBleu_score": 41.10091867378273}, {"code": "def leave(self)\n\t\n    try:\n        self.participating = False\n        self.barrier.remove_listener(self.on_barrier_event)\n        self.barrier.remove(self.session_id)\n        self.barrier.delete()\n    except KazooException:\n        self.participating = False\n        self.barrier.remove_listener(self.on_barrier_event)\n\n", "CodeBleu_score": 38.55869167392477}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t    if (hFtpService.getStatus() == HFtpService.Status.RUNNING) {\n        return Result.success(\"HDFS over FTP server is running\");\n    }\n    try {\n        hFtpService.start();\n        return Result.success(\"HDFS over FTP server started successfully\");\n    } catch (Exception e) {\n        return Result.error(e.getMessage());\n    }\n}", "CodeBleu_score": 34.48990999390358}, {"code": "public Result start(){\n\t    try {\n        if (!hFtpService.isRunning()) {\n            hFtpService.start();\n        }\n        Map<String, Object> result = new HashMap<>();\n        result.put(\"status\", \"success\");\n        return Result.success(result);\n    } catch (Exception e) {\n        logger.error(\"start error\", e);\n        return Result.error(e.getMessage());\n    }\n}", "CodeBleu_score": 37.731035041661364}, {"code": "public Result start(){\n\t    if (serverStatus.get() == 1) {\n        return Result.error(\"The server is already running\");\n    }\n    try {\n        hftpService.start();\n        serverStatus.set(1);\n        return Result.success(\"Start the server successfully\");\n    } catch (Exception e) {\n        log.error(\"Start the server error\", e);\n        return Result.error(\"Start the server error\");\n    }\n}", "CodeBleu_score": 33.99462052339365}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t    if (!hFtpService.isRunning()) {\n        return Result.failure(\"FTP server is not running.\");\n    }\n    hFtpService.stop();\n    return Result.success(\"FTP server stopped successfully.\");\n}", "CodeBleu_score": 20.77695042363762}, {"code": "public Result stop(){\n\t    try {\n        if (ftpService.isRunning()) {\n            ftpService.stop();\n            Map<String, Object> data = new HashMap<>();\n            data.put(\"message\", \"success\");\n            return Result.success(data);\n        }\n        Map<String, Object> data = new HashMap<>();\n        data.put(\"message\", \"failed\");\n        return Result.success(data);\n    } catch (Exception e) {\n        LOG.error(\"stop error\", e);\n        Map<String, Object> data = new HashMap<>();\n        data.put(\"message\", \"failed\");\n        return Result.success(data);\n    }\n}", "CodeBleu_score": 31.66320637822543}, {"code": "public Result stop(){\n\t    try {\n        if (ftpService.isRunning()) {\n            ftpService.stop();\n            Map<String, Object> map = new HashMap<>();\n            map.put(\"message\", \"FTP server is stopped successfully.\");\n            return Result.success(map);\n        } else {\n            Map<String, Object> map = new HashMap<>();\n            map.put(\"message\", \"FTP server is not running.\");\n            return Result.success(map);\n        }\n    } catch (Exception e) {\n        logger.error(\"FTP server stop error.\", e);\n        Map<String, Object> map = new HashMap<>();\n        map.put(\"message\", \"FTP server stop error.\");\n        return Result.fail(map);\n    }\n}", "CodeBleu_score": 31.328317215508463}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    User user = request.getUser();\n    Authority authority = null;\n    List<Authority> authorities = user.getAuthorities();\n    if (authorities == null || authorities.size() == 0) {\n        return null;\n    }\n    for (Authority a : authorities) {\n        try {\n            authority = a;\n            request = authority.authorize(request);\n            if (request == null) {\n                return null;\n            }\n        } catch (Exception e) {\n            log.error(\"Error while authorizing user \" + user.getName(), e);\n            return null;\n        }\n    }\n    return request;\n}", "CodeBleu_score": 45.075573095969105}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\tif (authorities.isEmpty()) {\n\t\treturn null;\n\t}\n\tfor (Authority authority : authorities) {\n\t\tif (authority.canAuthorize(request)) {\n\t\t\ttry {\n\t\t\t\tauthority.authorize(request);\n\t\t\t} catch (Exception e) {\n\t\t\t\tlog.warn(\"Authorization failed\", e);\n\t\t\t\treturn null;\n\t\t\t}\n\t\t}\n\t}\n\treturn request;\n}", "CodeBleu_score": 30.64235121019008}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t\n    // Get the user object\n    User user = request.getUser();\n\n    // Get the list of authorities\n    List<Authority> authorities = user.getAuthorities();\n\n    // If there are no authorities, return null\n    if (authorities == null || authorities.size() == 0) {\n        return null;\n    }\n\n    // Iterate through the authorities\n    for (Authority authority : authorities) {\n\n        // Get the updated request\n        AuthorizationRequest updatedRequest = authority.authorize(request);\n\n        // If the request was not updated, return null\n        if (updatedRequest == null) {\n            return null;\n        }\n\n        // Update the request\n        request = updatedRequest;\n    }\n\n    // Return the updated request\n    return request;\n}", "CodeBleu_score": 48.32997900071296}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t    try {\n        if (fileSystem.mkdirs(fullPath)) {\n            return true;\n        }\n    } catch (IOException e) {\n        LOG.error(\"mkdir failed\", e);\n    }\n    return false;\n}", "CodeBleu_score": 35.0311887654259}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        fs.mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 69.62827924082899}, {"code": "public boolean mkdir(){\n\t    try {\n        FileSystem fs = getHdfsUser().getFileSystem();\n        Path fullPath = new Path(getFullPath());\n        return fs.mkdirs(fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.38677499540661}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        fs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.21561514114013}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        Path fullPath = new Path(getFullPath());\n        if (fs.exists(fullPath)) {\n            fs.delete(fullPath, true);\n        }\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 59.40090641164469}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        return fs.delete(fullPath, true);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 61.04497569565361}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t    if (ftpFile instanceof HdfsFile) {\n        HdfsFile hdfsFile = (HdfsFile) ftpFile;\n        User user = hdfsFile.getUser();\n        if (user instanceof HdfsUser) {\n            HdfsUser hdfsUser = (HdfsUser) user;\n            FileSystem fs = hdfsUser.getFileSystem();\n            Path oldPath = hdfsFile.getFilePath();\n            Path newPath = new Path(oldPath.getParent(), ftpFile.getName());\n            try {\n                fs.rename(oldPath, newPath);\n                return true;\n            } catch (IOException e) {\n                e.printStackTrace();\n            }\n        }\n    }\n    return false;\n}", "CodeBleu_score": 48.545004279572545}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        HdfsUser user = (HdfsUser) getUser();\n        FileSystem fs = user.getFileSystem();\n        Path source = new Path(ftpFile.getAbsolutePath());\n        Path destination = new Path(ftpFile.getParent(), ftpFile.getName());\n        fs.rename(source, destination);\n        return true;\n    } catch (IOException e) {\n        LOG.error(\"Error moving file\", e);\n        return false;\n    }\n}", "CodeBleu_score": 51.00292418599637}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = ((HdfsUser) user).getFileSystem();\n        String parentPath = ftpFile.getParent();\n        String newPath = parentPath + \"/\" + ftpFile.getName();\n        fs.rename(new Path(ftpFile.getAbsolutePath()), new Path(newPath));\n        return true;\n    } catch (IOException e) {\n        LOG.error(\"Could not move file {} to {}\", ftpFile.getAbsolutePath(), ftpFile.getAbsolutePath() + \"/\" + ftpFile.getName(), e);\n        return false;\n    }\n}", "CodeBleu_score": 50.851410864509994}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getHdfsFileSystem();\n        Path path = new Path(getAbsolutePath());\n        FileStatus[] statuses = fs.listStatus(path);\n        FtpFile[] files = new FtpFile[statuses.length];\n        for (int i = 0; i < statuses.length; i++) {\n            files[i] = new HdfsFile(fs, statuses[i]);\n        }\n        return Collections.unmodifiableList(Arrays.asList(files));\n    } catch (IOException e) {\n        LOG.error(\"Could not list files: {}\", e.getMessage());\n        return null;\n    }\n}", "CodeBleu_score": 42.57802069679766}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getHdfsFileSystem();\n        FileStatus[] statuses = fs.listStatus(new Path(getAbsolutePath()));\n        FtpFile[] files = new FtpFile[statuses.length];\n        for (int i = 0; i < statuses.length; i++) {\n            files[i] = new HdfsFtpFile(statuses[i], this);\n        }\n        return Collections.unmodifiableList(Arrays.asList(files));\n    } catch (IOException e) {\n        LOG.error(\"Unable to list files in directory {}\", getAbsolutePath(), e);\n        return null;\n    }\n}", "CodeBleu_score": 39.57018146716902}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        if (fs != null) {\n            FileStatus[] files = fs.listStatus(new Path(getAbsolutePath()));\n            if (files != null) {\n                FtpFile[] ftpFiles = new FtpFile[files.length];\n                for (int i = 0; i < files.length; i++) {\n                    ftpFiles[i] = new FtpFile(files[i], getAbsolutePath());\n                }\n                return Collections.unmodifiableList(Arrays.asList(ftpFiles));\n            }\n        }\n    } catch (IOException e) {\n        LOG.error(\"Error listing files\", e);\n    }\n    return null;\n}", "CodeBleu_score": 39.392688231066856}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t    if (isConfigured()) {\n        return;\n    }\n\n    // load user data\n    File userDataFile = getUserDataFile();\n    if (userDataFile.exists()) {\n        try {\n            FileInputStream fis = new FileInputStream(userDataFile);\n            try {\n                BaseProperties userData = new BaseProperties();\n                userData.load(fis);\n                setUserData(userData);\n            } finally {\n                IoUtils.close(fis);\n            }\n        } catch (IOException ex) {\n            throw new FtpServerConfigurationException(\"Failed to load user data file [\" + userDataFile.getAbsolutePath() + \"]\", ex);\n        }\n    }\n\n    // convert deprecated properties\n    convertDeprecatedProperties();\n\n    // set configured state\n    setConfigured(true);\n}", "CodeBleu_score": 47.75141988176191}, {"code": "public void configure(){\n\t    if (isConfigured()) {\n        return;\n    }\n\n    try {\n        // load properties\n        loadProperties();\n\n        // convert deprecated properties\n        convertDeprecatedProperties();\n\n        // check if user data file exists\n        File userDataFile = new File(getUserManager().getUserDataFile());\n        if (!userDataFile.exists()) {\n            throw new FtpServerConfigurationException(\n                    \"User data file does not exist: \" + userDataFile.getAbsolutePath());\n        }\n\n        // set the configuration state\n        setConfigured(true);\n    } catch (IOException ex) {\n        throw new FtpServerConfigurationException(\n                \"Failed to load user data file: \" + getUserManager().getUserDataFile(), ex);\n    }\n}", "CodeBleu_score": 32.43668735845107}, {"code": "public void configure(){\n\t    // set configuration state\n    setConfigurationState(true);\n\n    // load user data file\n    File file = new File(getUserManager().getUserFilePath());\n    if (file.exists()) {\n        try {\n            FileInputStream fis = new FileInputStream(file);\n            try {\n                BaseProperties props = new BaseProperties(fis);\n                setUserProperties(props);\n            } finally {\n                IoUtils.close(fis);\n            }\n        } catch (IOException ex) {\n            throw new FtpServerConfigurationException(\n                    \"Failed to load user data file: \" + file.getAbsolutePath(), ex);\n        }\n    }\n\n    // convert deprecated properties\n    convertDeprecatedProperties();\n}", "CodeBleu_score": 49.11978992106676}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t    File parent = userDataFile.getParentFile();\n    if (parent != null && !parent.exists()) {\n        if (!parent.mkdirs()) {\n            throw new FtpServerConfigurationException(\"Failed to create user data file parent directory: \" + parent.getAbsolutePath());\n        }\n    }\n\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        userManager.save(fos);\n    } catch (IOException e) {\n        LOG.error(\"Failed to save user data file\", e);\n        throw new FtpException(\"Failed to save user data file\", e);\n    } finally {\n        IoUtils.close(fos);\n    }\n}", "CodeBleu_score": 52.572114811334316}, {"code": "private void saveUserData() throws FtpException{\n\t    File userDataFile = new File(userDataFilePath);\n    File userDataFileParent = userDataFile.getParentFile();\n    if (userDataFileParent != null && !userDataFileParent.exists()) {\n        if (!userDataFileParent.mkdirs()) {\n            throw new FtpServerConfigurationException(\"Failed to create parent directory of user data file: \" + userDataFilePath);\n        }\n    }\n\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        userManager.save(fos);\n    } catch (IOException e) {\n        LOG.error(\"Failed to write user data to file: \" + userDataFilePath, e);\n        throw new FtpException(\"Failed to write user data to file: \" + userDataFilePath, e);\n    } finally {\n        IoUtils.close(fos);\n    }\n}", "CodeBleu_score": 49.930351485712485}, {"code": "private void saveUserData() throws FtpException{\n\t    File userDataFile = new File(userDataFilePath);\n    File userDataFileParent = userDataFile.getParentFile();\n    if (userDataFileParent != null) {\n        if (!userDataFileParent.exists()) {\n            if (!userDataFileParent.mkdirs()) {\n                throw new FtpServerConfigurationException(\"Unable to create parent directory for user data file: \" + userDataFilePath);\n            }\n        }\n    }\n    FileOutputStream fos = null;\n    try {\n        fos = new FileOutputStream(userDataFile);\n        BaseProperties.store(userData, fos);\n    } catch (IOException e) {\n        LOG.error(\"Unable to save user data\", e);\n        throw new FtpException(\"Unable to save user data\");\n    } finally {\n        IoUtils.close(fos);\n    }\n}", "CodeBleu_score": 50.4963089580577}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        UserFactory userFactory = new UserFactory();\n        User user1 = userFactory.createUser(user);\n        user1.setPassword(new Md5PasswordEncryptor().encryptPassword(user1.getPassword()));\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.delete(user1);\n        return Result.success(\"\u5220\u9664\u7528\u6237\u6210\u529f\");\n    } catch (Exception e) {\n        logger.error(\"\u5220\u9664\u7528\u6237\u5931\u8d25\", e);\n        return Result.failure(\"\u5220\u9664\u7528\u6237\u5931\u8d25\");\n    }\n}", "CodeBleu_score": 41.1765771560283}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager userManager = new HdfsUserManager();\n        userManager.setFile(new File(\"users.properties\"));\n        userManager.delete(user);\n        return new Result(200, \"Success\", \"User deleted successfully\");\n    } catch (Exception e) {\n        logger.error(e);\n        return new Result(400, \"Failure\", \"User deletion failed\");\n    }\n}", "CodeBleu_score": 46.86058637679158}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        File file = new File(System.getProperty(\"user.dir\") + \"/users.properties\");\n        HdfsUserManager hdfsUserManager = new HdfsUserManager(file);\n        hdfsUserManager.delete(user);\n        return Result.success(\"User deleted successfully\");\n    } catch (Exception e) {\n        logger.error(\"Delete user failed\", e);\n        return Result.failure(\"Delete user failed\");\n    }\n}", "CodeBleu_score": 41.39763344899608}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"open path: {} bufferSize: {}\", path, bufferSize);\n    }\n    try {\n        return new FSDataInputStream(new SeaweedInputStream(path, bufferSize, getConf()));\n    } catch (FileNotFoundException fnfe) {\n        LOG.warn(\"File not found: {}\", path, fnfe);\n        return null;\n    } catch (IOException ioe) {\n        LOG.warn(\"IOException: {}\", path, ioe);\n        return null;\n    }\n}", "CodeBleu_score": 35.50125135967516}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    LOG.info(\"open file \" + path + \" with bufferSize \" + bufferSize);\n    Path qualifiedPath = qualify(path);\n    LOG.info(\"open file \" + qualifiedPath + \" with bufferSize \" + bufferSize);\n    try {\n        return new FSDataInputStream(new SeaweedInputStream(this, qualifiedPath, bufferSize));\n    } catch (FileNotFoundException e) {\n        LOG.warn(\"File \" + qualifiedPath + \" not found: \" + e.getMessage());\n        return null;\n    }\n}", "CodeBleu_score": 31.187100126531874}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    checkOpen();\n    statistics.incrementReadOps(1);\n    Path qualifiedPath = makeQualified(path);\n    LOG.debug(\"opening file {} with buffer size {}\", qualifiedPath, bufferSize);\n    return new FSDataInputStream(new SeaweedInputStream(getFileStatus(qualifiedPath), bufferSize, statistics));\n}", "CodeBleu_score": 21.628600215443075}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    if (LOG.isDebugEnabled()) {\n        LOG.debug(\"Rename {} to {}\", src, dst);\n    }\n    if (src.isRoot()) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    final FileStatus dstStatus;\n    try {\n        dstStatus = getFileStatus(dst);\n    } catch (FileNotFoundException e) {\n        dstStatus = null;\n    }\n    if (dstStatus != null) {\n        if (dstStatus.isDirectory()) {\n            dst = new Path(dst, src.getName());\n        } else {\n            throw new IOException(\"Rename destination \" + dst + \" is a file\");\n        }\n    }\n    final FileStatus srcStatus = getFileStatus(src);\n    final Path srcQualified = makeQualified(src);\n    final Path dstQualified = makeQualified(dst);\n    return store.rename(srcQualified, dstQualified, srcStatus.isDirectory());\n}", "CodeBleu_score": 54.045648506714414}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    if (src.isRoot()) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    FileStatus dstStatus = null;\n    try {\n        dstStatus = getFileStatus(dst);\n    } catch (FileNotFoundException e) {\n        // ignore\n    }\n    if (dstStatus != null) {\n        if (dstStatus.isDirectory()) {\n            dst = new Path(dst, src.getName());\n        } else {\n            delete(dst, false);\n        }\n    }\n    return store.rename(qualify(src), qualify(dst));\n}", "CodeBleu_score": 43.14919450685891}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t    if (isRoot(src)) {\n        return false;\n    }\n    if (src.equals(dst)) {\n        return true;\n    }\n    FileStatus dstStatus = null;\n    try {\n        dstStatus = getFileStatus(dst);\n    } catch (FileNotFoundException e) {\n        // ignore\n    }\n    if (dstStatus != null) {\n        if (dstStatus.isDirectory()) {\n            dst = new Path(dst, src.getName());\n        } else {\n            throw new IOException(\"Rename destination \" + dst + \" is a file\");\n        }\n    }\n    final Path absF = fixRelativePart(src);\n    final Path absT = fixRelativePart(dst);\n    if (!store.rename(absF.toUri().getPath(), absT.toUri().getPath())) {\n        throw new IOException(\"Rename failed for \" + src + \" to \" + dst);\n    }\n    return true;\n}", "CodeBleu_score": 49.9680222441141}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t    if (capability == null) {\n        return false;\n    }\n    String lowerCaseCapability = capability.toLowerCase(Locale.ROOT);\n    if (lowerCaseCapability.equals(StreamCapabilities.HSYNC.getValue())) {\n        return supportFlush;\n    } else if (lowerCaseCapability.equals(StreamCapabilities.HFLUSH.getValue())) {\n        return supportFlush;\n    }\n    return false;\n}", "CodeBleu_score": 37.85883256290201}, {"code": "public boolean hasCapability(String capability){\n\t    return capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HSYNC.getValue()) ||\n            capability.toLowerCase(Locale.ENGLISH).equals(StreamCapabilities.HFLUSH.getValue());\n}", "CodeBleu_score": 47.97083899219903}, {"code": "public boolean hasCapability(String capability){\n\t    return StreamCapabilities.HSYNC.equals(capability.toLowerCase(Locale.ENGLISH))\n            || StreamCapabilities.HFLUSH.equals(capability.toLowerCase(Locale.ENGLISH));\n}", "CodeBleu_score": 47.63363130177307}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t  try {\n    if (offset < this.lastFlushOffset) {\n      throw new IOException(\"The offset to flush must be greater than the last flush offset.\");\n    }\n\n    if (offset == this.lastFlushOffset) {\n      return;\n    }\n\n    if (offset > this.lastFlushOffset + this.buffer.position()) {\n      throw new IOException(\"The offset to flush must be less than the last flush offset plus the current buffer position.\");\n    }\n\n    this.buffer.flip();\n\n    final ByteBuffer metadata = ByteBuffer.allocate(8);\n    metadata.putLong(offset);\n    metadata.flip();\n\n    this.filerClient.write(this.path, metadata, this.lastFlushOffset, this.buffer, this.lastFlushOffset + this.buffer.position());\n\n    this.buffer.clear();\n\n    this.lastFlushOffset = offset;\n  } catch (final IOException e) {\n    this.logger.error(\"Failed to flush written bytes to the service.\", e);\n    throw e;\n  }\n}", "CodeBleu_score": 39.40249794812283}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t  if (offset < 0) {\n    throw new IllegalArgumentException(\"Offset cannot be negative\");\n  }\n  if (offset > this.fileSize) {\n    throw new IllegalArgumentException(\"Offset cannot be greater than the file size\");\n  }\n  if (this.lastFlushOffset >= offset) {\n    return;\n  }\n  if (this.lastFlushOffset < 0) {\n    // If this is the first flush, we need to flush the entire file.\n    this.lastFlushOffset = 0;\n  }\n  // Flush the data.\n  final long length = offset - this.lastFlushOffset;\n  if (length > 0) {\n    // Flush the data.\n    final ByteBuffer buffer = this.buffer.duplicate();\n    buffer.position((int) this.lastFlushOffset).limit((int) (offset));\n    this.lastFlushOffset = offset;\n    this.filerClient.write(this.fileId, buffer, this.lastFlushOffset);\n  }\n  // Flush the metadata.\n  this.filerClient.flush(this.fileId);\n}", "CodeBleu_score": 32.480207735242885}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    // flush written bytes to the service starting from a specified offset\n    if (offset > this.lastFlushOffset) {\n        // synchronize the operation\n        synchronized (this) {\n            // write metadata to the filer client\n            try {\n                this.filerClient.writeMetadata(this.filePath, offset, this.lastFlushOffset, this.metadata);\n            } catch (IOException e) {\n                throw e;\n            } catch (Exception e) {\n                throw new IOException(e);\n            }\n            // update the last flush offset\n            this.lastFlushOffset = offset;\n        }\n    }\n}", "CodeBleu_score": 51.68167777665084}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\t// Flip the buffer to prepare for reading.\n\tbufferToWrite.flip();\n\t// Calculate the byte length.\n\tint bufferLength = bufferToWrite.limit();\n\t// Ensure the task queue is not overloaded.\n\twhile (bufferLength + writeOperationQueue.size() > maxWriteOperationQueueSize) {\n\t\ttry {\n\t\t\t// Wait for a write operation to complete.\n\t\t\twriteOperationQueue.take();\n\t\t} catch (InterruptedException e) {\n\t\t\tthrow new InterruptedIOException();\n\t\t}\n\t}\n\t// Submit a write task to the completion service.\n\twriteOperationQueue.add(writeCompletionService.submit(new Callable<Integer>() {\n\t\t@Override\n\t\tpublic Integer call() throws Exception {\n\t\t\t// Write the data and release the buffer.\n\t\t\tint bytesWritten = write(bufferToWrite, writePosition);\n\t\t\tbufferToWrite.clear();\n\t\t\treturn bytesWritten;\n\t\t}\n\t}));\n\treturn bufferLength;\n}", "CodeBleu_score": 29.260035937188572}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    if (bufferToWrite.position() == 0) {\n        return 0;\n    }\n\n    final long writeLength = bufferToWrite.position();\n    final long writeEndPosition = writePosition + writeLength;\n\n    bufferToWrite.flip();\n\n    if (writeEndPosition > this.fileSize) {\n        this.fileSize = writeEndPosition;\n    }\n\n    if (this.writeOperationQueue.size() > 0) {\n        final WriteOperation lastWriteOperation = this.writeOperationQueue.getLast();\n        final long lastWriteEndPosition = lastWriteOperation.getWritePosition() + lastWriteOperation.getWriteLength();\n        if (writePosition == lastWriteEndPosition) {\n            lastWriteOperation.setWriteLength(lastWriteOperation.getWriteLength() + writeLength);\n            this.writeOperationQueue.removeLast();\n            this.writeOperationQueue.add(lastWriteOperation);\n            return writeLength;\n        }\n    }\n\n    final WriteOperation writeOperation = new WriteOperation(bufferToWrite, writePosition, writeLength);\n    this.writeOperationQueue.add(writeOperation);\n\n    this.writeService.submit(new Callable<Void>() {\n        @Override\n        public Void call() throws Exception {\n            try {\n                writeOperation.write();\n            } catch (IOException e) {\n                LOG.error(\"write operation failed\", e);\n                writeOperation.setException(e);\n            }\n            return null;\n        }\n    });\n\n    return writeLength;\n}", "CodeBleu_score": 34.274946936570835}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    int bytesWritten = 0;\n    try {\n        // Flip the buffer to prepare for reading\n        bufferToWrite.flip();\n        // Calculate the byte length\n        bytesWritten = bufferToWrite.limit();\n        // Ensure the task queue is not overloaded\n        if (bytesWritten > MAX_WRITE_BUFFER_SIZE) {\n            throw new IOException(\"ByteBuffer size exceeds the maximum write buffer size of \" + MAX_WRITE_BUFFER_SIZE + \".\");\n        }\n        // Submit a write task to the completion service\n        final long writePositionToUse = writePosition;\n        final ByteBuffer bufferToWriteToUse = bufferToWrite;\n        Future<Integer> writeTask = writeCompletionService.submit(new Callable<Integer>() {\n            @Override\n            public Integer call() throws Exception {\n                try {\n                    // Write the data\n                    writeData(bufferToWriteToUse, writePositionToUse);\n                    // Release the buffer\n                    bufferToWriteToUse.clear();\n                    return bytesWritten;\n                } catch (IOException e) {\n                    throw new Exception(e);\n                }\n            }\n        });\n        // Add the write task to the write task queue\n        writeTasks.add(writeTask);\n        // Increment the write operation count\n        writeOperations.incrementAndGet();\n        // Wait for the write operation to complete\n        while (writeTask.isDone() == false) {\n            Thread.sleep(1);\n        }\n        // Remove the write task from the write task queue\n        writeTasks.remove();\n        // Decrement the write operation count\n        writeOperations.decrementAndGet();\n        // Get the result of the write operation\n        bytesWritten = writeTask.get();\n    } catch (InterruptedException e) {\n        throw new InterruptedIOException();\n    } catch (ExecutionException e) {\n        throw new IOException(e.getCause());\n    }\n    return bytesWritten;\n}", "CodeBleu_score": 34.817802412502594}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (true) {\n            Future<byte[]> future = completionService.take();\n            if (future.isDone()) {\n                try {\n                    byte[] result = future.get();\n                    if (result != null) {\n                        // Write the result to the output stream\n                        out.write(result);\n                    }\n                    break;\n                } catch (ExecutionException e) {\n                    if (e.getCause() instanceof InterruptedIOException) {\n                        throw (InterruptedIOException) e.getCause();\n                    } else {\n                        throw new IOException(e);\n                    }\n                }\n            }\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 27.488601628631855}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    if (completionService.poll() != null) {\n        return;\n    }\n    try {\n        completionService.take().get();\n    } catch (InterruptedException e) {\n        throw new InterruptedIOException(e.getMessage());\n    } catch (ExecutionException e) {\n        throw new IOException(e.getMessage());\n    }\n}", "CodeBleu_score": 31.125193568838828}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    Future<Integer> future = null;\n    try {\n        future = completionService.take();\n    } catch (InterruptedException e) {\n        throw new InterruptedIOException(e.getMessage());\n    }\n    try {\n        future.get();\n    } catch (InterruptedException e) {\n        throw new InterruptedIOException(e.getMessage());\n    } catch (ExecutionException e) {\n        throw new IOException(e.getMessage());\n    }\n}", "CodeBleu_score": 34.75015305405557}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    long currentOffset = -1;\n    while (true) {\n        if (writeOperationQueue.isEmpty()) {\n            break;\n        }\n        WriteOperation op = writeOperationQueue.peek();\n        if (op.isDone()) {\n            try {\n                writeOperationQueue.remove();\n                currentOffset = op.getLength();\n            } catch (ExecutionException e) {\n                if (e.getCause() instanceof IOException) {\n                    throw (IOException) e.getCause();\n                } else {\n                    throw new IOException(e);\n                }\n            } catch (InterruptedException e) {\n                throw new InterruptedIOException(e.getMessage());\n            }\n        } else {\n            break;\n        }\n    }\n    if (currentOffset != -1) {\n        this.totalAppended += currentOffset;\n    }\n}", "CodeBleu_score": 32.571357520445325}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    // Iterate through the queue and remove completed write operations.\n    while (!writeOperationQueue.isEmpty()) {\n        // Get the next operation from the queue.\n        WriteOperation operation = writeOperationQueue.peek();\n\n        // Check if the operation is done.\n        if (operation.isDone()) {\n            // Remove the operation from the queue.\n            writeOperationQueue.remove();\n\n            // Update the total append offset.\n            totalAppendOffset += operation.getLength();\n        } else {\n            // If the operation is not done, then we are done.\n            break;\n        }\n    }\n\n    // Check if there are any exceptions to rethrow.\n    if (exception != null) {\n        // Rethrow the exception.\n        throw new IOException(exception);\n    }\n}", "CodeBleu_score": 34.907847685097224}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    final long start = System.nanoTime();\n    IOException exception = null;\n    long totalLength = 0;\n    while (!writeOperationQueue.isEmpty()) {\n        final Future<Long> future = writeOperationQueue.peek();\n        if (future.isDone()) {\n            try {\n                totalLength += future.get();\n            } catch (ExecutionException e) {\n                if (e.getCause() instanceof IOException) {\n                    exception = (IOException) e.getCause();\n                } else {\n                    exception = new IOException(e.getCause());\n                }\n            } catch (InterruptedException e) {\n                exception = new InterruptedIOException();\n            }\n            writeOperationQueue.poll();\n        } else {\n            break;\n        }\n    }\n    if (exception != null) {\n        throw exception;\n    }\n    if (totalLength > 0) {\n        final long newOffset = currentOffset.addAndGet(totalLength);\n        if (newOffset > maxOffset.get()) {\n            maxOffset.set(newOffset);\n        }\n        logger.debug(\"shrinkWriteOperationQueue: {} operations completed, {} bytes appended, new offset: {}\", writeOperationQueue.size(), totalLength, newOffset);\n    }\n    writeOperationQueueShrinkTime.update(System.nanoTime() - start);\n}", "CodeBleu_score": 25.48224248394443}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"User must not be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"User home directory must not be null\");\n  }\n  this.user = user;\n  this.homePath = new Path(user.getHomeDirectory());\n}", "CodeBleu_score": 68.71139822435156}, {"code": "protected HdfsFileSystemView(User user){\n\t  if (user == null) {\n    throw new IllegalArgumentException(\"User may not be null\");\n  }\n  if (user.getHomeDirectory() == null) {\n    throw new IllegalArgumentException(\"User home directory may not be null\");\n  }\n  homePath = user.getHomeDirectory();\n  this.user = user;\n}", "CodeBleu_score": 71.40553673424388}, {"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null) {\n\t\tthrow new IllegalArgumentException(\"user can not be null\");\n\t}\n\tif (user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"user home directory can not be null\");\n\t}\n\tthis.user = user;\n\thomePath = new Path(user.getHomeDirectory());\n}", "CodeBleu_score": 72.8308187707262}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir == null) {\n        return false;\n    }\n    FileSystemView view = getFileSystemView();\n    if (view == null) {\n        return false;\n    }\n    FtpFile file = null;\n    if (dir.equals(\"..\")) {\n        file = view.getParent(getFileSystemView().getWorkingDirectory());\n    } else {\n        file = view.getFile(getAbsolutePath(dir));\n    }\n    if (file == null) {\n        return false;\n    }\n    if (file.isDirectory()) {\n        setFileSystemView(file);\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 29.47054788740263}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir.equals(\".\")) {\n        return true;\n    }\n    if (dir.equals(\"..\")) {\n        return false;\n    }\n    Path path = new Path(dir);\n    if (path.isAbsolute()) {\n        if (path.equals(root)) {\n            currentPath = root;\n            return true;\n        }\n        else {\n            return false;\n        }\n    }\n    else {\n        currentPath = new Path(currentPath, dir);\n        return true;\n    }\n}", "CodeBleu_score": 28.65390862072666}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir.equals(\"..\")) {\n        return false;\n    }\n    if (dir.equals(\".\")) {\n        return true;\n    }\n    Path path = new Path(getCurrentDirectory(), dir);\n    if (getFileSystem().isDirectory(path)) {\n        setCurrentDirectory(path);\n        return true;\n    }\n    return false;\n}", "CodeBleu_score": 18.504531783268664}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.accessMode = conf.get(ACCESS_MODE, \"filerProxy\");\n    this.filerGrpcAddress = host + \":\" + grpcPort;\n    this.filerAddress = host + \":\" + port;\n    this.filerUrl = \"http://\" + filerAddress;\n    this.filerGrpcUrl = \"filerGrpc://\" + filerGrpcAddress;\n    this.filerClient = new FilerClient(filerGrpcUrl, conf);\n    this.filerClient.setGrpcMaxSize(conf.getInt(GRPC_MAX_SIZE, 100 * 1024 * 1024));\n    this.filerClient.setGrpcChunkSizeLimit(conf.getInt(GRPC_CHUNK_SIZE_LIMIT, 1024 * 1024));\n    this.filerClient.setGrpcChunkBufferSize(conf.getInt(GRPC_CHUNK_BUFFER_SIZE, 1024 * 1024));\n    this.filerClient.setGrpcKeepaliveTimeMs(conf.getInt(GRPC_KEEPALIVE_TIME_MS, 300000));\n    this.filerClient.setGrpcKeepaliveTimeoutMs(conf.getInt(GRPC_KEEPALIVE_TIMEOUT_MS, 30000));\n    this.filerClient.setGrpcPerRpcBufferLimit(conf.getInt(GRPC_PER_RPC_BUFFER_LIMIT, 1024 * 1024));\n    this.filerClient.setGrpcMaxHeaderListSize(conf.getInt(GRPC_MAX_HEADER_LIST_SIZE, 1024 * 1024));\n    this.filerClient.setGrpcMaxCallRecvMsgSize(conf.getInt(GRPC_MAX_CALL_RECV_MSG_SIZE, 1024 * ", "CodeBleu_score": 30.65455245386859}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.accessMode = conf.get(ACCESS_MODE_KEY, \"direct\");\n    this.filerGrpcAddress = conf.get(FILER_GRPC_ADDRESS_KEY, \"localhost:\" + grpcPort);\n    this.filerGrpcAddress = conf.get(FILER_GRPC_ADDRESS_KEY, \"localhost:\" + grpcPort);\n    this.filerAddress = conf.get(FILER_ADDRESS_KEY, \"localhost:\" + port);\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY, \"http://\" + filerAddress + \"/\");\n    this.filerUrl = conf.get(FILER_URL_KEY,", "CodeBleu_score": 26.882974671041282}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.host = host;\n    this.port = port;\n    this.grpcPort = grpcPort;\n    this.conf = conf;\n    this.accessMode = conf.get(ACCESS_MODE, \"direct\");\n    this.filerGrpcAddress = host + \":\" + grpcPort;\n    this.filerAddress = host + \":\" + port;\n    this.filerUrl = \"http://\" + filerAddress + \"/\";\n    this.filerGrpcAddress = \"grpc://\" + filerGrpcAddress;\n    this.filerUrl = \"http://\" + filerAddress + \"/\";\n    this.filerGrpcUrl = \"grpc://\" + filerGrpcAddress;\n    this.filerProxy = conf.get(FILER_PROXY, \"\");\n    this.filerProxyGrpc = conf.get(FILER_PROXY_GRPC, \"\");\n    this.publicUrl = conf.get(PUBLIC_URL, \"\");\n    this.publicGrpcUrl = conf.get(PUBLIC_GRPC_URL, \"\");\n    this.collection = conf.get(COLLECTION, \"\");\n    this.replication = conf.get(REPLICATION, \"000\");\n    this.ttlSec = conf.getInt(TTL_SEC, 0);\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.filerClient.setChunkSizeLimit(conf.getLong(CHUNK_SIZE_LIMIT, 0));\n    this.filerClient.setChunkSize(conf.getLong(CHUNK_SIZE, 0));\n    this.filerClient.setCacheControl(conf.get(CACHE_CONTROL, \"\"));\n    this.filerClient.setCacheable(conf.getBoolean(CACHEABLE, false));\n    this.filerClient.setCipherSuite(conf.get(CIPHER_SUITE, \"\"));\n    this.filerClient.setCompression(conf.get(COMPRESSION, \"\"));\n    this.filerClient.setPaginationSize(conf", "CodeBleu_score": 35.15590895553646}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"openFileForRead: {}\", path);\n    SeaweedFileStatus fileStatus = getFileStatus(path);\n    if (fileStatus == null) {\n        throw new FileNotFoundException(\"File \" + path + \" does not exist.\");\n    }\n    return new SeaweedHadoopInputStream(this, fileStatus, statistics);\n}", "CodeBleu_score": 50.082583853839104}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"openFileForRead: {}\", path);\n    String key = pathToKey(path);\n    SeaweedFileStatus fileStatus = lookupFileStatus(key);\n    if (fileStatus == null) {\n        throw new FileNotFoundException(\"File not found: \" + path);\n    }\n    return new SeaweedHadoopInputStream(key, fileStatus, statistics, filerClient, filerProtobufClient, fileSystemMasterClient, fileSystemPBClient);\n}", "CodeBleu_score": 63.648919845249516}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"Opening file for read: {}\", path);\n    FileEntry fileEntry = getFileEntry(path);\n    if (fileEntry == null) {\n        throw new FileNotFoundException(\"File \" + path + \" not found.\");\n    }\n    return new SeaweedHadoopInputStream(fileEntry, statistics, filerClient, path);\n}", "CodeBleu_score": 61.567589974318736}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        localHostName = InetAddress.getLocalHost().getHostName();\n    } catch (Exception e) {\n        localHostName = \"localhost\";\n    }\n    numThreadsPerMap = conf.getInt(\"num.threads.per.map\", 1);\n    filesPerThread = conf.getInt(\"files.per.thread\", 1);\n    threadPool = Executors.newFixedThreadPool(numThreadsPerMap);\n    for (int i = 0; i < numThreadsPerMap; i++) {\n        threadPool.submit(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(Long.MAX_VALUE);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        });\n    }\n}", "CodeBleu_score": 44.19994218841789}, {"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        hostname = InetAddress.getLocalHost().getHostName();\n    } catch (Exception e) {\n        hostname = \"localhost\";\n    }\n    threadsPerMap = conf.getInt(\"threads.per.map\", 1);\n    filesPerThread = conf.getInt(\"files.per.thread\", 1);\n    executorService = Executors.newFixedThreadPool(threadsPerMap);\n    for (int i = 0; i < threadsPerMap; i++) {\n        executorService.submit(new Runnable() {\n            @Override\n            public void run() {\n                try {\n                    Thread.sleep(10000);\n                } catch (InterruptedException e) {\n                    e.printStackTrace();\n                }\n            }\n        });\n    }\n}", "CodeBleu_score": 46.28657519808299}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  this.hostName = \"localhost\";\n  try {\n    this.hostName = InetAddress.getLocalHost().getHostName();\n  } catch (Exception e) {\n    LOG.warn(\"Unable to retrieve local host name, defaulting to \\\"localhost\\\"\");\n  }\n  this.threadsPerMap = conf.getInt(\"mapred.map.threads\", 1);\n  this.filesPerThread = conf.getInt(\"mapred.map.files.per.thread\", 1);\n  this.threadPool = Executors.newFixedThreadPool(threadsPerMap);\n  for (int i = 0; i < threadsPerMap; i++) {\n    threadPool.submit(new Thread(new Runnable() {\n      public void run() {\n        while (true) {\n          try {\n            Thread.sleep(1000);\n          } catch (InterruptedException e) {\n            LOG.warn(\"Thread interrupted\");\n          }\n          if (Thread.currentThread().isInterrupted()) {\n            break;\n          }\n        }\n      }\n    }));\n  }\n}", "CodeBleu_score": 35.91655425803793}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    String trashRoot = TrashPolicy.getCurrentTrashDir(uri, conf).toString();\n    String trashCheckpoint = trashRoot + TRASH_CHECKPOINT_FILE;\n    String trashInterval = conf.get(TRASH_INTERVAL, TRASH_INTERVAL_DEFAULT);\n    String trashExpunge = conf.get(TRASH_EXPUNGE_INTERVAL, TRASH_EXPUNGE_INTERVAL_DEFAULT);\n\n    try {\n        UserGroupInformation.setConfiguration(conf);\n        UserGroupInformation ugi = UserGroupInformation.getCurrentUser();\n        ugi.doAs(new PrivilegedExceptionAction<Object>() {\n            @Override\n            public Object run() throws Exception {\n                try {\n                    FileSystem fs = FileSystem.get(uri, conf);\n                    if (!fs.exists(new Path(trashCheckpoint))) {\n                        fs.mkdirs(new Path(trashCheckpoint));\n                    }\n                    if (fs.exists(new Path(trashRoot))) {\n                        LOG.info(\"Trash checkpoint directory already exists: \" + trashRoot);\n                    } else {\n                        fs.mkdirs(new Path(trashRoot));\n                    }\n                    TrashPolicy trashPolicy = TrashPolicy.getInstance(uri, conf, fs);\n                    long interval = Long.parseLong(trashInterval);\n                    long expunge = Long.parseLong(trashExpunge);\n                    TrashEmptier.schedule(fs, trashPolicy, interval, expunge);\n                } catch (IOException e) {\n                    LOG.error(\"Failed to start trash emptier\", e);\n                    throw e;\n                }\n                return null;\n            }\n        });\n    } catch (InterruptedException e) {\n        LOG.error(\"Failed to start trash emptier\", e);\n        throw new IOException(\"Failed to start trash emptier\", e);\n    }\n}", "CodeBleu_score": 35.81065582133832}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    // 1. Check if the trash emptier is already running for the specified host.\n    if (BgTaskUtil.isTrashEmptierRunning(uri, conf)) {\n        LOG.info(\"Trash emptier is already running for \" + uri);\n        return;\n    }\n\n    // 2. Create a superuser and initialize a JuiceFileSystemImpl instance as the superuser.\n    UserGroupInformation superUser = UserGroupInformation.getCurrentUser();\n    UserGroupInformation proxyUser = UserGroupInformation.createProxyUser(superUser.getShortUserName(), superUser);\n    final FileSystem fs = proxyUser.doAs((PrivilegedExceptionAction<FileSystem>) () -> {\n        try {\n            return FileSystem.get(uri, conf);\n        } catch (IOException e) {\n            throw new RuntimeException(e);\n        }\n    });\n\n    // 3. Start the trash emptier task using the initialized file system and the trash configuration, scheduling it to run every 10 minutes.\n    try {\n        BgTaskUtil.startTrashEmptier(uri, conf, fs);\n    } catch (Exception e) {\n        throw new IOException(\"Failed to start trash emptier for \" + uri, e);\n    }\n}", "CodeBleu_score": 48.56327496205448}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t  // Check if the trash emptier is already running for the specified host\n  if (BgTaskUtil.isTrashEmptierRunning(uri)) {\n    return;\n  }\n\n  // Create a superuser\n  UserGroupInformation superUser = UserGroupInformation.getCurrentUser();\n  final String superUserUsername = superUser.getUserName();\n  final String superUserPrincipal = superUser.getUserName();\n\n  // Initialize a JuiceFileSystemImpl instance as the superuser\n  final FileSystem fs = FileSystem.get(uri, conf, superUserUsername);\n  final FileSystem superUserFS = superUser.doAs(new PrivilegedExceptionAction<FileSystem>() {\n    @Override\n    public FileSystem run() throws Exception {\n      return fs;\n    }\n  });\n\n  // Start the trash emptier task using the initialized file system and the trash configuration\n  BgTaskUtil.startTrashEmptier(superUserFS, superUserPrincipal, conf, 10, TimeUnit.MINUTES);\n}", "CodeBleu_score": 37.8435926398463}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t    CallerContext callerContext = CallerContext.getCurrent();\n    if (callerContext == null || !callerContext.isValid()) {\n        callerContext = new CallerContext.Builder(context).build();\n    } else {\n        if (callerContext.getSignature() == null && !callerContext.getContext().contains(context)) {\n            callerContext.append(context);\n        }\n    }\n    CallerContext.setCurrent(callerContext);\n}", "CodeBleu_score": 42.57176257284297}, {"code": "public static void setContext(String context) throws Exception{\n\t    CallerContext callerContext = CallerContext.getCurrent();\n    if (callerContext == null || !callerContext.isValid()) {\n        callerContext = new CallerContext.Builder(context).build();\n    } else if (!callerContext.getSignature().equals(\"\")) {\n        if (!callerContext.getContext().contains(context)) {\n            callerContext = new CallerContext.Builder(callerContext.getContext() + context).build();\n        }\n    } else {\n        callerContext = new CallerContext.Builder(callerContext.getContext() + context).build();\n    }\n    CallerContext.setCurrent(callerContext);\n}", "CodeBleu_score": 49.317548885388376}, {"code": "public static void setContext(String context) throws Exception{\n\t  CallerContext currentCallerContext = CallerContext.getCurrent();\n  if (currentCallerContext == null) {\n    CallerContext newCallerContext = CallerContext.create(context, null);\n    CallerContext.setCurrent(newCallerContext);\n  } else if (!currentCallerContext.isValid()) {\n    CallerContext newCallerContext = CallerContext.create(context, null);\n    CallerContext.setCurrent(newCallerContext);\n  } else {\n    String currentContext = currentCallerContext.getContext();\n    if (currentContext == null || currentContext.isEmpty()) {\n      CallerContext newCallerContext = CallerContext.create(context, null);\n      CallerContext.setCurrent(newCallerContext);\n    } else if (!currentContext.contains(context)) {\n      String newContext = currentContext + \" \" + context;\n      CallerContext newCallerContext = CallerContext.create(newContext, null);\n      CallerContext.setCurrent(newCallerContext);\n    }\n  }\n}", "CodeBleu_score": 39.83963813985494}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t\n    // Check if the URI is valid\n    if (!uri.is_valid()) {\n        return LOG_STATUS(Status::HDFSError(\n            \"Cannot remove file; Invalid URI\"));\n    }\n\n    // Check if the URI is for HDFS\n    if (uri.to_string().find(\"hdfs://\") != 0) {\n        return LOG_STATUS(Status::HDFSError(\n            \"Cannot remove file; Not an HDFS URI\"));\n    }\n\n    // Connect to HDFS\n    hdfsFS fs = hdfsConnect(uri.host().c_str(), uri.port());\n    if (!fs) {\n        return LOG_STATUS(Status::HDFSError(\n            \"Cannot remove file; Could not connect to HDFS\"));\n    }\n\n    // Delete the file\n    if (hdfsDelete(fs, uri.path().c_str(), 0) == -1) {\n        return LOG_STATUS(Status::HDFSError(\n            \"Cannot remove file; HDFS delete failed\"));\n    }\n\n    // Disconnect from HDFS\n    if (hdfsDisconnect(fs) == -1) {\n        return LOG_STATUS(Status::HDFSError(\n            \"Cannot remove file; HDFS disconnect failed\"));\n    }\n\n    return Status::Ok();\n}", "CodeBleu_score": 48.058585005570734}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  // Connect to the HDFS file system\n  hdfsFS file_system = hdfsConnect(uri.hostname().c_str(), uri.port());\n  if(!file_system) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Failed to connect to HDFS file system; \" + uri.to_string()));\n  }\n\n  // Delete the file\n  int rc = hdfsDelete(file_system, uri.path().c_str(), 0);\n  if(rc) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Failed to delete file; \" + uri.to_string()));\n  }\n\n  // Disconnect from the HDFS file system\n  hdfsDisconnect(file_system);\n\n  return Status::Ok();\n}", "CodeBleu_score": 49.96383216394321}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  // TODO: Implement this function\n  return Status::OK();\n}", "CodeBleu_score": 7.412438854187908}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t    // Check if the file exists\n    if (!exists(uri)) {\n        return Status::OK();\n    }\n\n    // Open the file\n    std::unique_ptr<File> file = open(uri, \"wa\");\n    if (!file) {\n        return Status::IOError(\"Failed to open file \" + uri.toString());\n    }\n\n    // Flush the file\n    Status status = file->flush();\n    if (!status.ok()) {\n        return Status::IOError(\"Failed to flush file \" + uri.toString());\n    }\n\n    // Close the file\n    status = file->close();\n    if (!status.ok()) {\n        return Status::IOError(\"Failed to close file \" + uri.toString());\n    }\n\n    return Status::OK();\n}", "CodeBleu_score": 32.15798567945055}, {"code": "Status HDFS::sync(const URI& uri){\n\t  // Check if the file exists\n  if (!exists(uri)) {\n    return Status::OK();\n  }\n\n  // Open the file\n  std::unique_ptr<File> file;\n  RETURN_NOT_OK(File::open(uri, &file));\n\n  // Flush the file\n  RETURN_NOT_OK(file->sync());\n\n  // Close the file\n  return file->close();\n}", "CodeBleu_score": 15.620678589415398}, {"code": "Status HDFS::sync(const URI& uri){\n\t  LOG_TRACE(\"HDFS::sync\");\n\n  if(!uri.is_hdfs()) {\n    return LOG_STATUS(\n        Status::HDFSError(\"Cannot sync; URI is not an HDFS URI\"));\n  }\n\n  // Connect to HDFS\n  hdfsFS hdfs_fs = hdfsConnect(uri.hostname().c_str(), uri.port());\n  if(hdfs_fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; error connecting to HDFS: \")));\n  }\n\n  // Check if the file exists\n  int exists = hdfsExists(hdfs_fs, uri.path().c_str());\n  if(exists == -1) {\n    hdfsDisconnect(hdfs_fs);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; error checking if file exists: \")));\n  }\n\n  // If the file does not exist, do nothing\n  if(exists == 0) {\n    hdfsDisconnect(hdfs_fs);\n    return Status::Ok();\n  }\n\n  // Open the file in write and append mode\n  hdfsFile hdfs_file = hdfsOpenFile(\n      hdfs_fs, uri.path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if(hdfs_file == nullptr) {\n    hdfsDisconnect(hdfs_fs);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; error opening file: \")));\n  }\n\n  // Flush the file\n  int rc = hdfsFlush(hdfs_fs, hdfs_file);\n  if(rc == -1) {\n    hdfsDisconnect(hdfs_fs);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot sync; error flushing file: \")));\n  }\n\n  // Close the file\n  rc = hdfsCloseFile(hdfs_fs, hdfs_file);\n  if(rc == -1) {\n", "CodeBleu_score": 48.96387579535212}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Get a file info struct\n  hdfsFileInfo* hdfs_file_info = hdfsGetPathInfo(file_system_, uri.c_str());\n  if (hdfs_file_info == NULL) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Cannot get file info; File may not exist or may be a directory\"));\n  }\n\n  // Check that the file is not a directory\n  if (hdfs_file_info->mKind == kObjectKindDirectory) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Cannot get file size; Path is a directory\"));\n  }\n\n  // Set the size in bytes\n  *nbytes = hdfs_file_info->mSize;\n\n  // Free the file info struct\n  hdfsFreeFileInfo(hdfs_file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 38.98795553656624}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Get a file info object\n  hdfsFileInfo* file_info = hdfsGetPathInfo(file_system_, uri.c_str());\n  if (file_info == nullptr) {\n    *nbytes = 0;\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot retrieve file info for '\") + uri.c_str() +\n        \"'; HDFS error message: \" + hdfsGetLastError()));\n  }\n\n  // Check that the path is a file\n  if (file_info->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(file_info, 1);\n    *nbytes = 0;\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot retrieve file size; Path '\") + uri.c_str() +\n        \"' is not a file\"));\n  }\n\n  // Set the file size\n  *nbytes = (uint64_t)file_info->mSize;\n\n  // Free the file info object\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 49.400789907140854}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  // Connect to HDFS\n  hdfsFS hdfs_fs = hdfsConnect(uri.hostname().c_str(), uri.port());\n  if (hdfs_fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot connect to HDFS file system: \" + uri.to_string())));\n  }\n\n  // Get file information\n  hdfsFileInfo* hdfs_file_info = hdfsGetPathInfo(hdfs_fs, uri.path().c_str());\n  if (hdfs_file_info == nullptr) {\n    hdfsDisconnect(hdfs_fs);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot get HDFS file information: \" + uri.to_string())));\n  }\n\n  // Check if the path is a file\n  if (hdfs_file_info->mKind != kObjectKindFile) {\n    hdfsFreeFileInfo(hdfs_file_info, 1);\n    hdfsDisconnect(hdfs_fs);\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot get file size; HDFS path is not a file: \" +\n                    uri.to_string())));\n  }\n\n  // Set file size\n  *nbytes = hdfs_file_info->mSize;\n\n  // Free file info and disconnect from HDFS\n  hdfsFreeFileInfo(hdfs_file_info, 1);\n  hdfsDisconnect(hdfs_fs);\n\n  return Status::Ok();\n}", "CodeBleu_score": 48.53889343398556}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String[] hbaseCfg = hbaseCfgString.split(\",\");\n    String quorum = hbaseCfg[0];\n    String znodeParent = HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT;\n    if (hbaseCfg.length > 1) {\n        znodeParent = hbaseCfg[1];\n    }\n    if (quorum.indexOf(\":\") == -1) {\n        quorum = quorum + \":2181\";\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 29.638984240909522}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String zkQuorum = null;\n    String znodeParent = null;\n    if (hbaseCfgString != null && !hbaseCfgString.isEmpty()) {\n        // The hbaseCfgString should be in the format of:\n        // hbase.zookeeper.quorum:hbase.zookeeper.property.clientPort:hbase.zookeeper.znode.parent\n        String[] hbaseCfgStringSplit = hbaseCfgString.split(\":\");\n        if (hbaseCfgStringSplit.length > 0) {\n            zkQuorum = hbaseCfgStringSplit[0];\n        }\n        if (hbaseCfgStringSplit.length > 1) {\n            zkQuorum = zkQuorum + \":\" + hbaseCfgStringSplit[1];\n        }\n        if (hbaseCfgStringSplit.length > 2) {\n            znodeParent = hbaseCfgStringSplit[2];\n        }\n    }\n    if (zkQuorum == null || zkQuorum.isEmpty()) {\n        throw new IllegalArgumentException(\"HBase Zookeeper quorum must be provided\");\n    }\n    if (znodeParent == null || znodeParent.isEmpty()) {\n        znodeParent = HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT;\n    }\n    return new Pair<String, String>(zkQuorum, znodeParent);\n}", "CodeBleu_score": 40.635565945940705}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    String quorum = null;\n    String znodeParent = null;\n    if (StringUtils.isNotBlank(hbaseCfgString)) {\n        String[] configs = hbaseCfgString.split(\";\");\n        for (String config : configs) {\n            String[] entry = config.split(\"=\");\n            if (entry.length != 2) {\n                throw new IllegalArgumentException(\"Invalid HBase configuration string: \" + hbaseCfgString);\n            }\n            if (entry[0].equalsIgnoreCase(\"hbase.zookeeper.quorum\")) {\n                quorum = entry[1];\n            } else if (entry[0].equalsIgnoreCase(\"hbase.zookeeper.property.clientPort\")) {\n                if (StringUtils.isBlank(quorum)) {\n                    throw new IllegalArgumentException(\"Invalid HBase configuration string: \" + hbaseCfgString);\n                }\n                quorum += \":\" + entry[1];\n            } else if (entry[0].equalsIgnoreCase(\"zookeeper.znode.parent\")) {\n                znodeParent = entry[1];\n            }\n        }\n    }\n    if (StringUtils.isBlank(quorum)) {\n        throw new IllegalArgumentException(\"Invalid HBase configuration string: \" + hbaseCfgString);\n    }\n    if (StringUtils.isBlank(znodeParent)) {\n        znodeParent = HConstants.DEFAULT_ZOOKEEPER_ZNODE_PARENT;\n    }\n    return new Pair<>(quorum, znodeParent);\n}", "CodeBleu_score": 27.714738411455066}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    String tableName = cfg.getTable();\n    String namespace = cfg.getNamespace();\n    String[] columns = cfg.getColumns();\n    String[] columnTypes = cfg.getColumnTypes();\n    String[] columnValues = cfg.getColumnValues();\n\n    // Check the number of columns\n    if (columns.length != columnTypes.length) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                \"The number of columns and column types must be equal\");\n    }\n\n    // Check the number of columns\n    if (columns.length != columnValues.length) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                \"The number of columns and column values must be equal\");\n    }\n\n    // Check the table existence\n    Connection connection = null;\n    Statement statement = null;\n    ResultSet resultSet = null;\n    try {\n        Class.forName(cfg.getDriverName());\n        connection = DriverManager.getConnection(cfg.getJdbcUrl(), cfg.getUsername(), cfg.getPassword());\n        statement = connection.createStatement();\n        resultSet = statement.executeQuery(\"SELECT * FROM \" + tableName);\n    } catch (ClassNotFoundException | SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                \"Failed to connect to HBase, please check the configuration\", e);\n    } finally {\n        if (resultSet != null) {\n            try {\n                resultSet.close();\n            } catch (SQLException e) {\n                LOG.warn(\"Failed to close result set\");\n            }\n        }\n        if (statement != null) {\n            try {\n                statement.close();\n            } catch (SQLException e) {\n                LOG.warn(\"Failed to close statement\");\n            }\n        }\n        if (connection != null) {\n            try {\n                connection.close();\n            } catch (SQLException e) {\n                LOG.warn(\"Failed to close connection\");\n            }\n        }\n    }\n\n    // Check the column", "CodeBleu_score": 40.79324226976988}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    String tableName = cfg.getTable();\n    String namespace = cfg.getNamespace();\n    String column = cfg.getColumn();\n    String filter = cfg.getFilter();\n    String rowkey = cfg.getRowkey();\n    String range = cfg.getRange();\n    String rangeStart = cfg.getRangeStart();\n    String rangeEnd = cfg.getRangeEnd();\n    String rangeLimit = cfg.getRangeLimit();\n    String rangeOffset = cfg.getRangeOffset();\n    String rangeMode = cfg.getRangeMode();\n    String rangeOrder = cfg.getRangeOrder();\n    String rangeColumn = cfg.getRangeColumn();\n    String rangeTimeUnit = cfg.getRangeTimeUnit();\n    String rangeTimePoint = cfg.getRangeTimePoint();\n    String rangeTimeRange = cfg.getRangeTimeRange();\n    String rangeTimeInterval = cfg.getRangeTimeInterval();\n    String rangeTimeLimit = cfg.getRangeTimeLimit();\n    String rangeTimeOffset = cfg.getRangeTimeOffset();\n    String rangeTimeMode = cfg.getRangeTimeMode();\n    String rangeTimeOrder = cfg.getRangeTimeOrder();\n    String rangeTimeColumn = cfg.getRangeTimeColumn();\n    String rangeTimeRangeColumn = cfg.getRangeTimeRangeColumn();\n    String rangeTimeRangeTimeUnit = cfg.getRangeTimeRangeTimeUnit();\n    String rangeTimeRangeTimePoint = cfg.getRangeTimeRangeTimePoint();\n    String rangeTimeRangeTimeRange = cfg.getRangeTimeRangeTimeRange();\n    String rangeTimeRangeTimeInterval = cfg.getRangeTimeRangeTimeInterval();\n    String rangeTimeRangeTimeLimit = cfg.getRangeTimeRangeTimeLimit();\n    String rangeTimeRangeTimeOffset = cfg.getRangeTimeRangeTimeOffset();\n    String rangeTimeRangeTimeMode = cfg.getRangeTimeRangeTimeMode();\n    String rangeTimeRangeTimeOrder = cfg.getRangeTimeRangeTimeOrder();\n    String rangeTimeRangeTimeColumn = cfg.getRangeTimeRangeTimeColumn();\n    String rangeTimeRangeTimeRangeColumn = cfg.getRangeTimeRangeTimeRangeColumn();\n    String rangeTimeRangeTimeRangeTime", "CodeBleu_score": 21.704233054295436}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    String jdbcUrl = cfg.getJdbcUrl();\n    String table = cfg.getTable();\n    String namespace = cfg.getNamespace();\n    String[] columns = cfg.getColumns();\n    String username = cfg.getUsername();\n    String password = cfg.getPassword();\n    String kerberosKeytabFilePath = cfg.getKerberosKeytabFilePath();\n    String kerberosPrincipal = cfg.getKerberosPrincipal();\n    String hadoopConfig = cfg.getHadoopConfig();\n\n    LOG.info(\"Begin to validate configuration.\");\n\n    // 1. Validate jdbcUrl.\n    if (StringUtils.isBlank(jdbcUrl)) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The jdbcUrl is required.\");\n    }\n\n    // 2. Validate table.\n    if (StringUtils.isBlank(table)) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The table is required.\");\n    }\n\n    // 3. Validate columns.\n    if (columns == null || columns.length == 0) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The columns is required.\");\n    }\n\n    // 4. Validate kerberos authentication.\n    if (StringUtils.isNotBlank(kerberosKeytabFilePath) && StringUtils.isNotBlank(kerberosPrincipal)) {\n        LOG.info(\"Begin to authenticate kerberos.\");\n        try {\n            UserGroupInformation.setConfiguration(getHadoopConfiguration(hadoopConfig));\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n        LOG.info(\"Finish authenticating kerberos.\");\n    }\n\n    // 5. Validate table existence.\n", "CodeBleu_score": 35.2561799953784}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    try {\n        if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n            Configuration conf = new Configuration();\n            conf.set(HConstants.ZOOKEEPER_QUORUM, HBaseConstant.DEFAULT_ZK_QUORUM);\n            conf.set(HConstants.ZOOKEEPER_CLIENT_PORT, HBaseConstant.DEFAULT_ZK_PORT);\n            conf.set(HConstants.ZOOKEEPER_ZNODE_PARENT, HBaseConstant.DEFAULT_ZK_ZNODE_PARENT);\n            UserGroupInformation.setConfiguration(conf);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        }\n    } catch (IOException e) {\n        throw AddaxException.asAddaxException(HBase11xReaderErrorCode.GET_USER_GROUP_INFORMATION_ERROR, e);\n    }\n}", "CodeBleu_score": 47.251480418369326}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        LOG.info(\"[kerberosAuthentication] Attempting to authenticate with Kerberos using the provided principal and keytab file.\");\n        try {\n            Configuration conf = new Configuration();\n            conf.set(HConstants.ZOOKEEPER_QUORUM, HBaseConstant.DEFAULT_ZOOKEEPER_QUORUM);\n            conf.set(HConstants.ZOOKEEPER_ZNODE_PARENT, HBaseConstant.DEFAULT_ZOOKEEPER_ZNODE_PARENT);\n            UserGroupInformation.setConfiguration(conf);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n            LOG.info(\"[kerberosAuthentication] Successfully authenticated with Kerberos using the provided principal and keytab file.\");\n        } catch (IOException e) {\n            LOG.error(\"[kerberosAuthentication] Failed to authenticate with Kerberos using the provided principal and keytab file. \" + e.getMessage());\n            throw AddaxException.asAddaxException(HBase11xHelperErrorCode.GET_HBASE_CONNECTION_ERROR, e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 47.01236823360808}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (StringUtils.isNotBlank(kerberosPrincipal) && StringUtils.isNotBlank(kerberosKeytabFilePath)) {\n        // Set the configuration for UserGroupInformation\n        UserGroupInformation.setConfiguration(HBaseConstant.getConfiguration());\n        try {\n            // Attempt to log in using the principal and keytab file\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            String message = \"Kerberos login error\";\n            LOG.error(message);\n            throw AddaxException.asAddaxException(HBase11xReaderErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 51.29641656634194}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    ResultSetMetaData rsmd = rs.getMetaData();\n    int columnCount = rsmd.getColumnCount();\n    Map<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<>();\n    for (int i = 1; i <= columnCount; i++) {\n        String columnName = rsmd.getColumnName(i);\n        String columnType = rsmd.getColumnTypeName(i);\n        if (StringUtils.isBlank(columnName) || StringUtils.isBlank(columnType)) {\n            throw new SQLException(\"Column name or type is null.\");\n        }\n        PDataType pDataType = PDataType.fromSqlTypeName(columnType);\n        columns.put(columnName, new ThinClientPTable.ThinClientPColumn(columnName, pDataType));\n    }\n    return columns;\n}", "CodeBleu_score": 41.43977979730961}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    Map<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<>();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int count = rsmd.getColumnCount();\n    for (int i = 1; i <= count; i++) {\n        String columnName = rsmd.getColumnLabel(i);\n        String type = rsmd.getColumnTypeName(i);\n        if (columnName == null || type == null) {\n            throw new SQLException(\"Column name or type is null\");\n        }\n        columns.put(columnName, new ThinClientPTable.ThinClientPColumn(columnName, PDataType.fromSqlTypeName(type)));\n    }\n    return columns;\n}", "CodeBleu_score": 39.365929760024706}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        ResultSetMetaData rsmd = rs.getMetaData();\n        Map<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<>();\n        for (int i = 1; i <= rsmd.getColumnCount(); i++) {\n            String columnName = rsmd.getColumnLabel(i);\n            if (columnName == null) {\n                throw new SQLException(\"Column name is null\");\n            }\n            String columnType = rsmd.getColumnClassName(i);\n            if (columnType == null) {\n                throw new SQLException(\"Column type is null\");\n            }\n            columns.put(columnName, new ThinClientPTable.ThinClientPColumn(PDataType.fromTypeId(rsmd.getColumnType(i)), rsmd.isNullable(i) == ResultSetMetaData.columnNullable));\n        }\n        return columns;\n    }", "CodeBleu_score": 40.85952807267106}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        Admin admin = conn.unwrap(PhoenixConnection.class).getQueryServices().getAdmin();\n        if (admin.tableExists(TableName.valueOf(tableName))) {\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.truncateTable(TableName.valueOf(tableName), false);\n            LOG.debug(\"Truncated table: \" + tableName);\n        }\n        admin.close();\n    } catch (IOException e) {\n        throw new RuntimeException(\"Unable to close HBase Admin connection.\", e);\n    }\n}", "CodeBleu_score": 36.1434522657043}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        PhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = pconn.getQueryServices().getAdmin();\n        try {\n            if (admin.tableExists(TableName.valueOf(tableName))) {\n                admin.disableTable(TableName.valueOf(tableName));\n                admin.truncateTable(TableName.valueOf(tableName), true);\n                LOG.debug(\"Truncated table: \" + tableName);\n            }\n        } finally {\n            try {\n                admin.close();\n            } catch (IOException e) {\n                LOG.warn(\"Unable to close HBase admin.\", e);\n            }\n        }\n    } catch (SQLException e) {\n        throw new RuntimeException(\"Unable to truncate table: \" + tableName, e);\n    }\n}", "CodeBleu_score": 46.31471203969946}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try (Admin admin = ((PhoenixConnection) conn).getQueryServices().getAdmin()) {\n        if (admin.tableExists(TableName.valueOf(tableName))) {\n            admin.disableTable(TableName.valueOf(tableName));\n            admin.truncateTable(TableName.valueOf(tableName), true);\n            LOG.debug(\"Truncated table \" + tableName);\n        }\n        else {\n            LOG.debug(\"Table \" + tableName + \" does not exist. Skipping truncate.\");\n        }\n    }\n    catch (IOException e) {\n        throw new RuntimeException(\"Error while truncating table \" + tableName, e);\n    }\n}", "CodeBleu_score": 28.61523343180948}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    String fileType = getFileType(filePath);\n    if (fileType.equalsIgnoreCase(this.fileType)) {\n        LOG.info(\"Adding file [{}] to source files list.\", filePath);\n        this.sourceFiles.add(filePath);\n    } else {\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE,\n                String.format(\"The file type of [%s] is not supported. The supported file type is [%s].\", filePath, this.fileType));\n    }\n}", "CodeBleu_score": 31.688180319294695}, {"code": "private void addSourceFileByType(String filePath){\n\t    String fileType = getFileType(filePath);\n    if (fileType.equals(this.fileType)) {\n        LOG.info(\"Adding file to source files list: {}\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        LOG.error(\"Unsupported file type: {}\", fileType);\n        throw AddaxException.asAddaxException(\n                StorageReaderErrorCode.UNSUPPORTED_FILE_TYPE,\n                String.format(\"Unsupported file type: %s\", fileType));\n    }\n}", "CodeBleu_score": 30.349214561353037}, {"code": "private void addSourceFileByType(String filePath){\n\t    String fileType = getFileType(filePath);\n    if (fileType.equals(fileType)) {\n        LOG.info(\"Adding file [{}] to source files list.\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        LOG.error(\"File [{}] does not match the file type [{}].\", filePath, fileType);\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE,\n                String.format(\"File [%s] does not match the file type [%s].\", filePath, fileType));\n    }\n}", "CodeBleu_score": 31.410138163021163}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"Start to read sequence file [{}]...\", sourceSequenceFilePath);\n        Path path = new Path(sourceSequenceFilePath);\n        FileSystem fs;\n        try {\n            fs = path.getFileSystem(hadoopConf);\n            SequenceFile.Reader reader = new SequenceFile.Reader(fs, path, hadoopConf);\n            Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), hadoopConf);\n            Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), hadoopConf);\n            LongWritable offset = new LongWritable();\n            LongWritable length = new LongWritable();\n            Text textKey = new Text();\n            Text textValue = new Text();\n            while (reader.next(key, value)) {\n                if (key instanceof LongWritable) {\n                    offset = (LongWritable) key;\n                    length = (LongWritable) value;\n                    textKey.set(offset.toString());\n                    textValue.set(length.toString());\n                } else if (key instanceof Text) {\n                    textKey = (Text) key;\n                    textValue = (Text) value;\n                } else {\n                    throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE,\n                            \"The sequence file key type only supports LongWritable and Text, but is \" + key.getClass().getName());\n                }\n                Record record = recordSender.createRecord();\n                Column columnKey = record.addColumn(textKey.toString());\n                Column columnValue = record.addColumn(textValue.toString());\n                recordSender.sendToWriter(record);\n            }\n            reader.close();\n        } catch (Exception e) {\n            LOG.error(\"Read sequence file [{}] failed, please check configuration and status.\", sourceSequenceFilePath);\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n        }\n    }", "CodeBleu_score": 45.81159387137396}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"Start to read sequence file [{}]...\", sourceSequenceFilePath);\n    // \u6253\u5f00SequenceFile\n    Path path = new Path(sourceSequenceFilePath);\n    FileSystem fs;\n    try {\n        fs = FileSystem.get(path.toUri(), hadoopConf);\n    } catch (IOException e) {\n        String message = String.format(\"\u83b7\u53d6FileSystem\u65f6\u53d1\u751fI/O\u5f02\u5e38,\u8bf7\u68c0\u67e5\u60a8\u7684\u7f51\u7edc\u662f\u5426\u6b63\u5e38!\u9519\u8bef\u4fe1\u606f: [{}]\", e.getMessage());\n        LOG.error(message);\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.OPEN_FILE_ERROR, e);\n    }\n    SequenceFile.Reader reader = null;\n    LongWritable key = new LongWritable();\n    Text value = new Text();\n    try {\n        reader = new SequenceFile.Reader(fs, path, hadoopConf);\n        while (reader.next(key, value)) {\n            // \u8bfb\u53d6\u4e00\u884c\u5185\u5bb9\n            if (StringUtils.isBlank(value.toString())) {\n                continue;\n            }\n            // \u5904\u7406\u4e00\u884c\u5185\u5bb9\n            StorageReaderUtil.transportOneRecord(recordSender, value.toString(), readerSliceConfig,\n                    taskPluginCollector);\n            // \u53d1\u9001\u4e00\u884c\u5185\u5bb9\n        }\n    } catch (Exception e) {\n        String message = String.format(\"\u8bfb\u53d6SequenceFile\u6587\u4ef6\u65f6\u53d1\u751fI/O\u5f02\u5e38,\u8bf7\u68c0\u67e5\u60a8\u7684\u7f51\u7edc\u662f\u5426\u6b63\u5e38!\u9519\u8bef\u4fe1\u606f: [{}]\", e.getMessage());\n        LOG.error(message);\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.READ_FILE_IO_ERROR, e);\n    } finally {\n        IOUtils.closeStream(reader);\n    }\n    LOG.info(\"Finish to read sequence file [{}]...\", sourceSequenceFilePath);\n}", "CodeBleu_score": 54.920441008938056}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t        LOG.info(\"Start to read sequence file [{}]...\", sourceSequenceFilePath);\n\n        SimpleDateFormat dateFormat = new SimpleDateFormat(\"yyyy-MM-dd HH:mm:ss\");\n\n        Path path = new Path(sourceSequenceFilePath);\n        FileSystem fs;\n        try {\n            fs = path.getFileSystem(hdfsConf);\n        } catch (IOException e) {\n            String message = String.format(\"\u83b7\u53d6FileSystem\u65f6\u53d1\u751fI/O\u5f02\u5e38,\u8bf7\u68c0\u67e5\u60a8\u7684\u7f51\u7edc\u662f\u5426\u6b63\u5e38!HDFS\u5730\u5740\uff1a[%s]\", sourceSequenceFilePath);\n            LOG.error(message);\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.CONNECT_HDFS_IO_ERROR, e);\n        }\n\n        if (!fs.exists(path)) {\n            String message = String.format(\"\u60a8\u8bbe\u5b9a\u7684path: [%s]\u4e0d\u5b58\u5728, \u8bf7\u786e\u5b9a\u60a8\u7684\u914d\u7f6e\u9879\u662f\u5426\u6b63\u786e.\", sourceSequenceFilePath);\n            LOG.error(message);\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.FILE_NOT_EXISTS, message);\n        }\n\n        if (fs.isFile(path)) {\n            LOG.info(\"Start to read sequence file [{}]...\", sourceSequenceFilePath);\n            SequenceFile.Reader reader = null;\n            try {\n                reader = new SequenceFile.Reader(fs, path, hdfsConf);\n                Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), hdfsConf);\n                Writable value = (Writable) ReflectionUtils.newInstance(reader.getValueClass(), hdfsConf);\n                while (reader.next(key, value)) {\n                    Text k = (Text) key;\n                    Text v = (Text) value;\n                    if (StringUtils.isBlank(k.toString()) && StringUtils.isBlank(v.toString())) {\n                        continue;\n                    }\n\n                    StorageReaderUtil.transportOneRecord(recordSender, readerSliceConfig,\n                            dateFormat.format(new Date()), k", "CodeBleu_score": 52.634544139931926}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new org.apache.hadoop.conf.Configuration());\n        if (fs.exists(new Path(filepath))) {\n            if (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n                return checkOrcFileType(fs, filepath);\n            } else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n                return checkRCFileType(fs, filepath);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n                return checkSequenceFileType(fs, filepath);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n                return checkParquetFileType(fs, filepath);\n            } else if (specifiedFileType.equalsIgnoreCase(\"CSV\")) {\n                return checkCsvFileType(fs, filepath);\n            } else if (specifiedFileType.equalsIgnoreCase(\"Text\")) {\n                return checkTextFileType(fs, filepath);\n            } else {\n                return false;\n            }\n        } else {\n            LOG.error(\"File does not exist: {}\", filepath);\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.FILE_NOT_EXISTS, \"File does not exist: \" + filepath);\n        }\n    } catch (Exception e) {\n        LOG.error(\"Exception occurs when checking file type: \", e);\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.CHECK_FILE_TYPE_FAIL, \"Exception occurs when checking file type: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 41.322598658753925}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new URI(filepath), new Configuration());\n        FileStatus fileStatus = fs.getFileStatus(new Path(filepath));\n        if (fileStatus.isDirectory()) {\n            return false;\n        }\n        FSDataInputStream inputStream = fs.open(new Path(filepath));\n        if (specifiedFileType.equalsIgnoreCase(\"ORC\")) {\n            return OrcFile.isOrcFile(new Path(filepath), fs.getConf());\n        } else if (specifiedFileType.equalsIgnoreCase(\"RC\")) {\n            return RCFile.isSplitable(fs, new Path(filepath), fs.getConf());\n        } else if (specifiedFileType.equalsIgnoreCase(\"Sequence\")) {\n            return SequenceFile.isSequenceFile(fs, new Path(filepath), fs.getConf());\n        } else if (specifiedFileType.equalsIgnoreCase(\"Parquet\")) {\n            ParquetReader.Builder<Group> builder = ParquetReader.builder(new GroupReadSupport(), HadoopInputFile.fromPath(new Path(filepath), fs.getConf()));\n            ParquetReader<Group> parquetReader = builder.build();\n            Group group = parquetReader.read();\n            return group != null;\n        } else if (specifiedFileType.equalsIgnoreCase(\"CSV\") || specifiedFileType.equalsIgnoreCase(\"Text\")) {\n            return true;\n        } else {\n            return false;\n        }\n    } catch (Exception e) {\n        LOG.error(e.getMessage());\n        throw AddaxException.asAddaxException(StorageReaderErrorCode.READ_FILE_ERROR, e);\n    }\n}", "CodeBleu_score": 42.48637805525942}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        Path path = new Path(filepath);\n        FileStatus fileStatus = fs.getFileStatus(path);\n        if (fileStatus.isDir()) {\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The filepath is a directory, not a file.\");\n        }\n        if (fileStatus.getLen() == 0) {\n            throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The filepath is an empty file.\");\n        }\n        switch (specifiedFileType.toUpperCase()) {\n            case \"ORC\":\n                Reader orcReader = OrcFile.createReader(new Path(filepath), OrcFile.readerOptions(new Configuration()));\n                MessageType orcSchema = orcReader.getSchema();\n                if (orcSchema == null) {\n                    throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The file is not an ORC file.\");\n                }\n                break;\n            case \"RC\":\n                RCFile.Reader rcReader = new RCFile.Reader(fs, path);\n                if (rcReader == null) {\n                    throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The file is not an RC file.\");\n                }\n                break;\n            case \"SEQUENCE\":\n                SequenceFile.Reader sequenceReader = new SequenceFile.Reader(fs, path, new Configuration());\n                if (sequenceReader == null) {\n                    throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The file is not a Sequence file.\");\n                }\n                break;\n            case \"PARQUET\":\n                ParquetReader<Group> parquetReader = ParquetReader.builder(new GroupReadSupport(), HadoopInputFile.fromPath(path, new Configuration())).build();\n                if (parquetReader == null) {\n                    throw AddaxException.asAddaxException(StorageReaderErrorCode.ILLEGAL_VALUE, \"The file", "CodeBleu_score": 29.39161543386288}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t    if (null != hConnection) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw AddaxException.asAddaxException(HBaseConstant.CONNECT_HBASE_IO_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 77.33699093656655}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.HBASE_16_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 51.72518104904659}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.HBASE_16_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 51.72518104904659}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t    if (admin != null) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw new AddaxException(HBaseConstant.HBASE_11_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 51.918235644161705}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (null != admin) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw AddaxException.asAddaxException(HBase20xSQLWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 78.13048352220372}, {"code": "public static void closeAdmin(Admin admin){\n\t    if (null != admin) {\n        try {\n            admin.close();\n        } catch (IOException e) {\n            throw AddaxException.asAddaxException(HBase20xSQLWriterErrorCode.CLOSE_HBASE_ADMIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 78.92324772508668}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        // Get the row key and timestamp from the cell\n        String rowKey = Bytes.toString(CellUtil.cloneRow(cell));\n        long timestamp = cell.getTimestamp();\n\n        // Get the column family and qualifier from the cell\n        String[] columnInfo = getColumnInfo(cell);\n        String family = columnInfo[0];\n        String qualifier = columnInfo[1];\n\n        // Get the column value from the cell\n        String value = Bytes.toString(CellUtil.cloneValue(cell));\n\n        // Determine the type and format of the row key\n        String rowKeyType = getRowKeyType(family);\n        String rowKeyFormat = getRowKeyFormat(family);\n\n        // Determine the type and format of the column value\n        String columnType = getColumnType(family, qualifier);\n        String columnFormat = getColumnFormat(family, qualifier);\n\n        // Convert the row key to the appropriate type\n        Object rowKeyValue = convertType(rowKey, rowKeyType, rowKeyFormat);\n\n        // Convert the column value to the appropriate type\n        Object columnValue = convertType(value, columnType, columnFormat);\n\n        // Add the row key, column family, qualifier, timestamp, and column value to the record\n        record.addColumn(new LongColumn(rowKeyValue));\n        record.addColumn(new StringColumn(family));\n        record.addColumn(new StringColumn(qualifier));\n        record.addColumn(new LongColumn(timestamp));\n        record.addColumn(new StringColumn(columnValue));\n    }", "CodeBleu_score": 36.234505854349344}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        byte[] rowkey = CellUtil.cloneRow(cell);\n        byte[] family = CellUtil.cloneFamily(cell);\n        byte[] qualifier = CellUtil.cloneQualifier(cell);\n        byte[] value = CellUtil.cloneValue(cell);\n        long timestamp = cell.getTimestamp();\n\n        String rowkeyString = Bytes.toString(rowkey);\n        String familyString = Bytes.toString(family);\n        String qualifierString = Bytes.toString(qualifier);\n        String valueString = Bytes.toString(value);\n\n        String rowkeyFormat = rowkeyType.get(rowkeyString);\n        String valueFormat = valueType.get(valueString);\n\n        if (rowkeyFormat == null) {\n            rowkeyFormat = \"STRING\";\n        }\n\n        if (valueFormat == null) {\n            valueFormat = \"STRING\";\n        }\n\n        String rowkeyType = rowkeyFormat.toUpperCase();\n        String valueType = valueFormat.toUpperCase();\n\n        if (rowkeyType.equals(HBaseConstant.STRING)) {\n            record.addColumn(new StringColumn(rowkeyString));\n        } else if (rowkeyType.equals(HBaseConstant.LONG)) {\n            record.addColumn(new LongColumn(Long.parseLong(rowkeyString)));\n        } else if (rowkeyType.equals(HBaseConstant.DOUBLE)) {\n            record.addColumn(new DoubleColumn(Double.parseDouble(rowkeyString)));\n        } else {\n            throw DataXException.asDataXException(Hbase11xReaderErrorCode.ILLEGAL_VALUE,\n                    String.format(\"The rowkey type is not supported. rowkey:%s, type:%s\",\n                            rowkeyString, rowkeyType));\n        }\n\n        record.addColumn(new StringColumn(familyString));\n        record.addColumn(new StringColumn(qualifierString));\n        record.addColumn(new LongColumn(timestamp));\n\n        if (valueType.equals(HBaseConstant.STRING)) {\n            record.addColumn(new StringColumn(valueString));\n        } else if (valueType.equals(HBaseConstant.L", "CodeBleu_score": 39.737295557210736}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        byte[] rowKey = CellUtil.cloneRow(cell);\n        String rowKeyString = Bytes.toString(rowKey);\n        record.addColumn(new LongColumn(rowKeyString));\n        long timestamp = cell.getTimestamp();\n        record.addColumn(new LongColumn(timestamp));\n        byte[] family = CellUtil.cloneFamily(cell);\n        String familyString = Bytes.toString(family);\n        record.addColumn(new StringColumn(familyString));\n        byte[] qualifier = CellUtil.cloneQualifier(cell);\n        String qualifierString = Bytes.toString(qualifier);\n        record.addColumn(new StringColumn(qualifierString));\n        byte[] value = CellUtil.cloneValue(cell);\n        String valueString = Bytes.toString(value);\n        record.addColumn(new StringColumn(valueString));\n    }", "CodeBleu_score": 31.314276283282933}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(userStartRowkey)) {\n        return HConstants.EMPTY_BYTE_ARRAY;\n    }\n    return convertRowkey(userStartRowkey, configuration);\n}", "CodeBleu_score": 49.50883531501404}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String userStartRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(userStartRowkey)) {\n        return HConstants.EMPTY_BYTE_ARRAY;\n    }\n    if (configuration.getBool(HBaseKey.ROW_KEY_IS_BINARY, false)) {\n        return Bytes.toBytesBinary(userStartRowkey);\n    } else {\n        return Bytes.toBytes(userStartRowkey);\n    }\n}", "CodeBleu_score": 53.17071726190055}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return HConstants.EMPTY_BYTE_ARRAY;\n    }\n    return convertRowkey(startRowkey, configuration);\n}", "CodeBleu_score": 54.191057911163455}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return HConstants.EMPTY_BYTE_ARRAY;\n    }\n    return Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 79.99135978724676}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return HConstants.EMPTY_BYTE_ARRAY;\n    }\n    return Bytes.toBytes(startRowkey);\n}", "CodeBleu_score": 79.99135978724676}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.getString(HBaseKey.START_ROW_KEY, null);\n    if (startRowkey == null) {\n        return HConstants.EMPTY_START_ROW;\n    } else {\n        return Bytes.toBytesBinary(startRowkey);\n    }\n}", "CodeBleu_score": 60.75615475404214}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new DefaultTbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.65240826036944}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new DefaultTbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.65240826036944}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new DefaultTbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 43.65240826036944}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(\n            tbKafkaSettings,\n            tbKafkaSettings.getProducer().getDefaultTopic(),\n            clientId + \"TransportNotificationsMsgProducer\",\n            new TbKafkaEncoder<>(ToTransportMsg.class),\n            tbKafkaProducerStats,\n            tbKafkaAdmin\n    );\n}", "CodeBleu_score": 24.06169804113958}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> template =\n            new TbKafkaProducerTemplate<>(\n                    tbKafkaSettings,\n                    clientId + \"-\" + ServiceType.TRANSPORT_NOTIFICATIONS.name(),\n                    tbKafkaSettings.getTopic(TbQueueTransportNotificationSettings.NOTIFICATIONS_TOPIC),\n                    partitionCount,\n                    tbKafkaSettings.getProducer());\n    template.setAdmin(tbKafkaAdmin);\n    return template;\n}", "CodeBleu_score": 40.830416093836}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate<TbProtoQueueMsg<ToTransportMsg>> producerTemplate =\n            new TbKafkaProducerTemplate<>(\n                    kafkaSettings,\n                    new TbKafkaTopicConfigs(\n                            tbQueueTransportNotificationSettings.getNotificationsTopic(),\n                            tbQueueTransportNotificationSettings.getNotificationsPartitions()),\n                    clientId + \"2transport\",\n                    new TbProtoQueueMsgSerializer<>(ToTransportMsg.class),\n                    kafkaAdmin);\n    return new TbKafkaProducerTemplate<>(producerTemplate, kafkaTopicConfigsCache);\n}", "CodeBleu_score": 36.2771708444536}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = new TbKafkaConsumerTemplate<>(\n            tbKafkaSettings,\n            tbKafkaTopicConfigs.getNotificationsTopic(),\n            tbKafkaTopicConfigs.getNotificationsTopic() + \"-\" + serviceInfoProvider.getServiceId(),\n            tbKafkaTopicConfigs.getNotificationsGroupId(),\n            new TbKafkaDecoder<>(ToCoreNotificationMsg.class),\n            getConsumerStatsService(),\n            getConsumerStatsService(),\n            tbKafkaSettings.getMaxPollRecords(),\n            tbKafkaSettings.getPollTimeoutMs(),\n            tbKafkaSettings.getMaxPollNoRecordsStallsIntervalsNs(),\n            tbKafkaSettings.getStatsPrintIntervalMs()\n    );\n    consumer.setAutoCommit(false);\n    return consumer;\n}", "CodeBleu_score": 33.350113568804126}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumer = new TbKafkaConsumerTemplate<>(\n        tbKafkaSettings,\n        tbKafkaTopicConfigs.getNotificationsTopic(),\n        \"NotificationsMsgConsumer\",\n        new TbKafkaDecoder<>(ToCoreNotificationMsg.class),\n        getNotificationsMsgConsumerGroupName(),\n        getNotificationsMsgListener()\n    );\n    consumer.setAdmin(tbKafkaAdmin);\n    consumer.setConsumerStatsService(consumerStatsService);\n    return consumer;\n}", "CodeBleu_score": 33.41740009074794}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerTemplate =\n            new TbKafkaConsumerTemplate<>(\n                    kafkaSettings,\n                    new TbKafkaDecoder<>(ToCoreNotificationMsg.class),\n                    tbKafkaAdmin,\n                    tbKafkaConsumerStatsService,\n                    ToCoreNotificationMsg.class.getSimpleName());\n\n    return consumerTemplate;\n}", "CodeBleu_score": 24.347392650048853}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"[{}] No topics to subscribe. Unsubscribing.\", consumerGroupId);\n        consumer.unsubscribe();\n    } else {\n        log.info(\"[{}] Subscribing to topics: {}\", consumerGroupId, topicNames);\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 55.869886668767975}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"[{}] No topics provided. Unsubscribing consumer from all topics...\", consumerGroup);\n        consumer.unsubscribe();\n        return;\n    }\n    log.info(\"[{}] Subscribing consumer to topics: {}\", consumerGroup, topicNames);\n    if (admin != null) {\n        admin.createTopics(topicNames);\n    }\n    consumer.subscribe(topicNames);\n}", "CodeBleu_score": 50.62325503602976}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"[{}] No topics provided. Unsubscribing consumer.\", consumerName);\n        consumer.unsubscribe();\n    } else {\n        log.info(\"[{}] Subscribing consumer to topics: {}\", consumerName, topicNames);\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 55.39830833588536}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    StopWatch stopWatch = new StopWatch();\n    stopWatch.start();\n    log.debug(\"Polling topic [{}] for up to {} ms.\", topic, durationInMillis);\n    ConsumerRecords<String, byte[]> records = consumer.poll(Duration.ofMillis(durationInMillis));\n    stopWatch.stop();\n    log.debug(\"Polled topic [{}] for {} ms. Found {} record(s).\", topic, stopWatch.getTotalTimeMillis(), records.count());\n    if (records.isEmpty()) {\n        return Collections.emptyList();\n    } else {\n        List<ConsumerRecord<String, byte[]>> result = new ArrayList<>(records.count());\n        for (ConsumerRecord<String, byte[]> record : records) {\n            result.add(record);\n        }\n        return result;\n    }\n}", "CodeBleu_score": 71.65988262291143}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    StopWatch stopWatch = new StopWatch();\n    stopWatch.start();\n    log.debug(\"Polling topic: {}, duration: {} ms\", topic, durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    try {\n        ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\n        if (consumerRecords.isEmpty()) {\n            return Collections.emptyList();\n        }\n        for (ConsumerRecord<String, byte[]> record : consumerRecords) {\n            records.add(record);\n        }\n        return records;\n    } catch (Exception e) {\n        log.error(\"Failed to poll topic: {}\", topic, e);\n        return Collections.emptyList();\n    } finally {\n        stopWatch.stop();\n        log.debug(\"Polled topic: {}, records: {}, duration: {} ms\", topic, records.size(), stopWatch.getTotalTimeMillis());\n    }\n}", "CodeBleu_score": 60.35932468015021}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    StopWatch stopWatch = new StopWatch();\n    stopWatch.start();\n    log.debug(\"Polling topic {} for up to {} ms.\", topic, durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    ConsumerRecords<String, byte[]> consumerRecords;\n    try {\n        consumerRecords = consumer.poll(Duration.ofMillis(durationInMillis));\n        if (consumerRecords.count() > 0) {\n            records.addAll(consumerRecords.records(topic));\n        }\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to poll topic {} for up to {} ms\", consumerGroup, topic, durationInMillis, e);\n    }\n    stopWatch.stop();\n    log.debug(\"Polled topic {} for up to {} ms. Found {} records. Polling took {} ms.\", topic, durationInMillis, records.size(), stopWatch.getTotalTimeMillis());\n    return records;\n}", "CodeBleu_score": 58.40424200453474}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (initError) {\n        ctx.tellFailure(msg, new RuntimeException(\"Kafka producer failed to initialize!\"));\n        return;\n    }\n    String topic = getTopic(msg);\n    String key = getKey(msg);\n    byte[] data = getData(msg);\n    RecordMetadata metadata = null;\n    try {\n        RecordHeaders headers = new RecordHeaders();\n        for (String headerName : msg.getMetaData().getData().keySet()) {\n            String headerValue = msg.getMetaData().getData().get(headerName);\n            headers.add(new RecordHeader(headerName, headerValue.getBytes(StandardCharsets.UTF_8)));\n        }\n        ProducerRecord<String, byte[]> record = new ProducerRecord<>(topic, key, data, headers);\n        metadata = producer.send(record).get();\n    } catch (Exception e) {\n        log.error(\"[{}] Failed to publish message to Kafka topic: {}\", msg.getId(), topic, e);\n        ctx.tellFailure(msg, e);\n        return;\n    }\n    log.debug(\"[{}] Published message to Kafka topic: {} with offset: {}\", msg.getId(), topic, metadata.offset());\n    ctx.ack(msg);\n}", "CodeBleu_score": 35.37648191097594}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (producer == null) {\n        ctx.logError(\"Producer is not initialized!\");\n        ctx.ack(msg);\n        return;\n    }\n    String topic = getTopic(msg);\n    if (topic == null) {\n        ctx.logError(\"Topic is null!\");\n        ctx.ack(msg);\n        return;\n    }\n    String key = getKey(msg);\n    String data = getData(msg);\n    if (data == null) {\n        ctx.logError(\"Data is null!\");\n        ctx.ack(msg);\n        return;\n    }\n    Headers headers = getHeaders(msg);\n    ProducerRecord<String, String> record = new ProducerRecord<>(topic, key, data, headers);\n    try {\n        producer.send(record, (metadata, exception) -> {\n            if (exception != null) {\n                ctx.logError(\"Failed to publish message to Kafka topic: \" + topic, exception);\n                ctx.ack(msg);\n            } else {\n                ctx.ack(msg);\n            }\n        });\n    } catch (Exception e) {\n        ctx.logError(\"Failed to publish message to Kafka topic: \" + topic, e);\n        ctx.ack(msg);\n    }\n}", "CodeBleu_score": 35.340128595921335}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (initError) {\n        ctx.tellFailure(msg, new RuntimeException(\"Kafka producer was not initialized!\"));\n        return;\n    }\n    String topic = getTopic(msg);\n    String key = getKey(msg);\n    String msgBody = getMsgBody(msg);\n    ProducerRecord<String, String> producerRecord = new ProducerRecord<>(topic, key, msgBody);\n    producerRecord.headers().add(new RecordHeader(THINGSBOARD_MSG_ID, msg.getId().getBytes(StandardCharsets.UTF_8)));\n    if (msg.getMetaData().getTenantId() != null) {\n        producerRecord.headers().add(new RecordHeader(THINGSBOARD_TENANT_ID, msg.getMetaData().getTenantId().getBytes(StandardCharsets.UTF_8)));\n    }\n    if (msg.getMetaData().getCustomerId() != null) {\n        producerRecord.headers().add(new RecordHeader(THINGSBOARD_CUSTOMER_ID, msg.getMetaData().getCustomerId().getBytes(StandardCharsets.UTF_8)));\n    }\n    if (msg.getMetaData().getOriginator() != null) {\n        producerRecord.headers().add(new RecordHeader(THINGSBOARD_ORIGINATOR_ID, msg.getMetaData().getOriginator().getId().getBytes(StandardCharsets.UTF_8)));\n    }\n    if (msg.getMetaData().getOriginatorType() != null) {\n        producerRecord.headers().add(new RecordHeader(THINGSBOARD_ORIGINATOR_TYPE, msg.getMetaData().getOriginatorType().getBytes(StandardCharsets.UTF_8)));\n    }\n    if (msg.getMetaData().getRuleChainId() != null) {\n        producerRecord.headers().add(new RecordHeader(THINGSBOARD_RULE_CHAIN_ID, msg.getMetaData().getRuleChainId().getBytes(StandardCharsets.UTF_8)));\n    }\n    if (msg.getMetaData().getRuleNodeId() != null) {\n        producerRecord.headers", "CodeBleu_score": 30.28127553423675}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    String metadata = metadataStr;\n    if (BooleanUtils.toBoolean(metadata)) {\n        Headers headers = new RecordHeaders();\n        TbMsgMetaData metaData = msg.getMetaData();\n        if (metaData.getData() != null) {\n            for (String key1 : metaData.getData().keySet()) {\n                headers.add(new RecordHeader(key1, metaData.getData().get(key1).getBytes(StandardCharsets.UTF_8)));\n            }\n        }\n        ctx.getKafkaTemplate().send(topic, key, headers, msg.getData());\n    } else {\n        ctx.getKafkaTemplate().send(topic, key, msg.getData());\n    }\n}", "CodeBleu_score": 32.272334337755574}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    if (metadataAsHeaders) {\n        Headers headers = new RecordHeaders();\n        TbMsgMetaData metaData = msg.getMetaData();\n        if (metaData.getData() != null) {\n            for (String key1 : metaData.getData().keySet()) {\n                headers.add(new RecordHeader(key1, metaData.getData().get(key1).getBytes(StandardCharsets.UTF_8)));\n            }\n        }\n        if (msg.getCallback() != null) {\n            producer.send(new ProducerRecord<>(topic, key, msg.getData(), headers), new Callback(ctx, msg));\n        } else {\n            producer.send(new ProducerRecord<>(topic, key, msg.getData(), headers));\n        }\n    } else {\n        if (msg.getCallback() != null) {\n            producer.send(new ProducerRecord<>(topic, key, msg.getData()), new Callback(ctx, msg));\n        } else {\n            producer.send(new ProducerRecord<>(topic, key, msg.getData()));\n        }\n    }\n}", "CodeBleu_score": 39.96132786377759}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    if (metadataAsHeader) {\n        Headers headers = new RecordHeaders();\n        for (TbMsgMetaData.Entry entry : msg.getMetaData().getData().entrySet()) {\n            headers.add(new RecordHeader(entry.getKey(), entry.getValue().getBytes(StandardCharsets.UTF_8)));\n        }\n        send(ctx, msg, topic, key, headers, null);\n    } else {\n        send(ctx, msg, topic, key, null, null);\n    }\n}", "CodeBleu_score": 30.448311322124056}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"Failed to close Kafka producer\", e);\n        }\n    }\n}", "CodeBleu_score": 71.42565466358049}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            log.error(\"[{}] Failed to close Kafka producer\", getName(), e);\n        }\n    }\n}", "CodeBleu_score": 63.266607267382}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    return new TbKafkaProducerTemplate<>(\n        tbKafkaSettings,\n        tbKafkaSettings.getProducer().getMaxRequestSize(),\n        new TbKafkaTopicConfigs(\n            tbKafkaSettings.getTopic(),\n            tbKafkaSettings.getTopic() + \"_\" + ServiceType.TB_RULE_ENGINE.name() + \"-\" + serviceInfoProvider.getServiceId(),\n            tbKafkaSettings.getTopic() + \"_\" + ServiceType.TB_RULE_ENGINE.name() + \"-\" + serviceInfoProvider.getServiceId() + \"-acks\"),\n        ToRuleEngineMsg.class,\n        tbKafkaSettings.getProducer().getMaxInFlightRequests(),\n        tbKafkaSettings.getProducer().getAcks(),\n        tbKafkaSettings.getProducer().getRetries(),\n        tbKafkaSettings.getProducer().getBatchSize(),\n        tbKafkaSettings.getProducer().getLingerMs(),\n        tbKafkaSettings.getProducer().getMaxRequestSize(),\n        tbKafkaSettings.getProducer().getCompressionType(),\n        tbKafkaSettings.getProducer().getIdempotence(),\n        tbKafkaSettings.getProducer().getProperties(),\n        tbKafkaSettings.getProducer().getKeySerializer(),\n        tbKafkaSettings.getProducer().getValueSerializer(),\n        tbKafkaSettings.getProducer().getInterceptor(),\n        tbKafkaAdmin\n    );\n}", "CodeBleu_score": 32.58075857414434}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> builder = TbKafkaProducerTemplate.builder();\n    builder.settings(kafkaSettings);\n    builder.clientId(\"tb-rule-engine-\" + serviceInfoProvider.getServiceId());\n    builder.defaultTopic(tbKafkaSettings.getTopicRuleEngineNotifications());\n    builder.admin(tbKafkaAdmin);\n    return builder.build();\n}", "CodeBleu_score": 66.5743962381059}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder builder = TbKafkaProducerTemplate.builder();\n    builder.settings(ruleEngineSettings.getProducer());\n    builder.clientId(\"tb-rule-engine-producer-\" + serviceInfoProvider.getServiceId());\n    builder.defaultTopic(ruleEngineSettings.getTopic());\n    builder.admin(kafkaAdmin);\n    return builder.build();\n}", "CodeBleu_score": 63.66276959766757}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t    if (logScheduler != null) {\n        return;\n    }\n    logScheduler = Executors.newSingleThreadScheduledExecutor(ThingsBoardThreadFactory.forName(\"kafka-consumer-group-monitor\"));\n    logScheduler.scheduleWithFixedDelay(() -> {\n        try {\n            if (logStatistics) {\n                logConsumerGroupStatistics();\n            }\n        } catch (Exception e) {\n            log.warn(\"[{}] Failed to log consumer group statistics\", groupId, e);\n        }\n    }, logStatisticsIntervalSec, logStatisticsIntervalSec, TimeUnit.SECONDS);\n}", "CodeBleu_score": 15.036846783719424}, {"code": "private void startLogScheduling(){\n\t    if (logScheduling != null) {\n        logScheduling.shutdownNow();\n    }\n    logScheduling = Executors.newSingleThreadScheduledExecutor(ThingsBoardThreadFactory.forName(\"kafka-consumer-log-scheduling\"));\n    logScheduling.scheduleWithFixedDelay(this::logStatistics, logPeriodMs, logPeriodMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 10.690794144345633}, {"code": "private void startLogScheduling(){\n\t    if (logScheduler != null) {\n        return;\n    }\n    logScheduler = Executors.newSingleThreadScheduledExecutor(ThingsBoardThreadFactory.forName(\"kafka-consumer-log-scheduler\"));\n    logScheduler.scheduleWithFixedDelay(this::logStats, 0, logStatsPeriodMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 5.509721374077715}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.69084212730418}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, getBootstrapServers());\n    props.put(AdminClientConfig.RETRIES_CONFIG, 0);\n    return props;\n}", "CodeBleu_score": 73.4619413386689}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, 0);\n    return props;\n}", "CodeBleu_score": 82.54321802981079}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String[] groupNames = group.getScopeComponents();\n    String[] metricNameParts = metricName.split(Pattern.quote(AbstractMetricGroup.METRIC_GROUP_DELIMITER));\n    String[] tags = new String[groupNames.length + metricNameParts.length - 1];\n    System.arraycopy(groupNames, 0, tags, 0, groupNames.length);\n    System.arraycopy(metricNameParts, 1, tags, groupNames.length, metricNameParts.length - 1);\n    String scopedName = group.getMetricIdentifier(metricName);\n    MetricEvent event = new MetricEvent(scopedName, tags);\n    if (metric instanceof Counter) {\n        counters.put(scopedName, (Counter) metric);\n        counterEvents.put(scopedName, event);\n    } else if (metric instanceof Gauge) {\n        gauges.put(scopedName, (Gauge) metric);\n        gaugeEvents.put(scopedName, event);\n    } else if (metric instanceof Histogram) {\n        histograms.put(scopedName, (Histogram) metric);\n        histogramEvents.put(scopedName, event);\n    } else if (metric instanceof Meter) {\n        meters.put(scopedName, (Meter) metric);\n        meterEvents.put(scopedName, event);\n    } else {\n        LOG.warn(\"Metric type {} is not supported. Skipping metric {}.\", metric.getClass().getSimpleName(), metricName);\n    }\n}", "CodeBleu_score": 43.0022979480683}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String groupName = group.getMetricIdentifier(\"user\", \"\");\n    String scopedName = group.getMetricIdentifier(\"user\", metricName);\n    Map<String, String> tags = group.getAllVariables();\n\n    if (metric instanceof Counter) {\n        Counter counter = (Counter) metric;\n        counterMap.put(scopedName, counter);\n        counterEvents.put(scopedName, new MetricEvent(scopedName, tags, counter.getCount()));\n    } else if (metric instanceof Gauge) {\n        Gauge<?> gauge = (Gauge<?>) metric;\n        gaugeMap.put(scopedName, gauge);\n        gaugeEvents.put(scopedName, new MetricEvent(scopedName, tags, gauge.getValue()));\n    } else if (metric instanceof Histogram) {\n        Histogram histogram = (Histogram) metric;\n        histogramMap.put(scopedName, histogram);\n        histogramEvents.put(scopedName, new MetricEvent(scopedName, tags, histogram.getStatistics()));\n    } else if (metric instanceof Meter) {\n        Meter meter = (Meter) metric;\n        meterMap.put(scopedName, meter);\n        meterEvents.put(scopedName, new MetricEvent(scopedName, tags, meter.getRate()));\n    } else {\n        LOG.warn(\"Metric type {} is not supported\", metric.getClass().getName());\n    }\n}", "CodeBleu_score": 44.084726118504946}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String[] groupNames = group.getScopeComponents();\n    String[] metricNameParts = metricName.split(\"\\\\.\");\n    String[] metricNamePartsWithoutScope = new String[metricNameParts.length - groupNames.length];\n    System.arraycopy(metricNameParts, groupNames.length, metricNamePartsWithoutScope, 0, metricNamePartsWithoutScope.length);\n    String scopedMetricName = String.join(\".\", metricNamePartsWithoutScope);\n\n    Map<String, String> tags = new HashMap<>();\n    for (int i = 0; i < groupNames.length - 1; i++) {\n        tags.put(groupNames[i], metricNameParts[i]);\n    }\n    tags.put(groupNames[groupNames.length - 1], metricNameParts[groupNames.length - 1]);\n\n    if (metric instanceof Counter) {\n        Counter counter = (Counter) metric;\n        MetricEvent metricEvent = new MetricEvent(scopedMetricName, counter.getCount(), tags);\n        this.metricEvents.get(Counter.class).add(metricEvent);\n    } else if (metric instanceof Gauge) {\n        Gauge<?> gauge = (Gauge<?>) metric;\n        MetricEvent metricEvent = new MetricEvent(scopedMetricName, gauge.getValue(), tags);\n        this.metricEvents.get(Gauge.class).add(metricEvent);\n    } else if (metric instanceof Histogram) {\n        Histogram histogram = (Histogram) metric;\n        Snapshot snapshot = histogram.getSnapshot();\n        Map<String, String> tagsWithHistogram = new HashMap<>(tags);\n        tagsWithHistogram.put(\"statistic\", \"count\");\n        MetricEvent metricEvent = new MetricEvent(scopedMetricName, snapshot.size(), tagsWithHistogram);\n        this.metricEvents.get(Histogram.class).add(metricEvent);\n        tagsWithHistogram.put(\"statistic\", \"max\");\n        metricEvent = new MetricEvent(scopedMetricName, snapshot.getMax(), tagsWithHistogram);\n       ", "CodeBleu_score": 35.07518029190906}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Map<String, String> fields = metricEvent.getFields();\n    if (fields == null) {\n        fields = new HashMap<>();\n    }\n    fields.put(field, String.valueOf(gauge.getValue()));\n    return new MetricEvent(metricEvent.getMetric(), metricEvent.getTimestamp(), fields);\n}", "CodeBleu_score": 30.520358395380477}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Map<String, String> fields = metricEvent.getFields();\n    if (fields == null) {\n        fields = new HashMap<>();\n    }\n    fields.put(field, String.valueOf(gauge.getValue()));\n    metricEvent.setFields(fields);\n    return metricEvent;\n}", "CodeBleu_score": 32.877479681452634}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (metricEvent.getFields() == null) {\n        Map<String, String> fields = new HashMap<>();\n        fields.put(field, value.toString());\n        metricEvent.setFields(fields);\n    } else {\n        metricEvent.getFields().put(field, value.toString());\n    }\n    return metricEvent;\n}", "CodeBleu_score": 38.895723628245726}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String[] metricNameComponents = metricEvent.getMetricName().split(\"\\\\.\");\n    String topic = metricNameComponents[1];\n    String group = metricNameComponents[2];\n    String metricName = metricNameComponents[3];\n\n    String kafkaLagMetricName = String.format(\"kafka.%s.%s.%s\", topic, group, metricName);\n\n    // If the metric is not in the map, add it and set the event's timestamp\n    if (!kafkaLagTimes.containsKey(kafkaLagMetricName)) {\n        kafkaLagTimes.put(kafkaLagMetricName, timestamp);\n    }\n\n    // If the metric is in the map, check if the timestamp has changed\n    else if (kafkaLagTimes.get(kafkaLagMetricName) != timestamp) {\n        kafkaLagTimes.put(kafkaLagMetricName, timestamp);\n    }\n\n    // If the timestamp has changed, update the event's timestamp\n    else {\n        metricEvent.setTimestamp(timestamp);\n    }\n\n    // Get the value of the Kafka lag metric\n    Object value = gauge.getValue();\n\n    // If the value is a string, split it into components\n    if (value instanceof String) {\n        String[] valueComponents = ((String) value).split(\"\\\\|\");\n        String currentOffset = valueComponents[0];\n        String dataTimestamp = valueComponents[1];\n        String committedOffset = valueComponents[2];\n\n        // Update the event's fields with the current offsets, data timestamp, and committed offsets\n        metricEvent.getFields().put(\"currentOffset\", currentOffset);\n        metricEvent.getFields().put(\"dataTimestamp\", dataTimestamp);\n        metricEvent.getFields().put(\"committedOffset\", committedOffset);\n    }\n\n    return metricEvent;\n}", "CodeBleu_score": 35.493288913298}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t\tString[] metricNameComponents = metricEvent.getMetricName().split(\"\\\\.\");\n\tString groupName = metricNameComponents[0];\n\tString topicName = metricNameComponents[1];\n\tString metricName = metricNameComponents[2];\n\n\tMap<String, Long> kafkaLagTimes = new HashMap<>();\n\tMap<String, Long> kafkaLagOffsets = new HashMap<>();\n\tMap<String, Long> kafkaLagCommittedOffsets = new HashMap<>();\n\tMap<String, Long> kafkaLagTimesDiff = new HashMap<>();\n\n\tif (metricName.equals(\"current-offset\")) {\n\t\tkafkaLagTimes.put(topicName, timestamp);\n\t\tkafkaLagOffsets.put(topicName, (Long) gauge.getValue());\n\t}\n\n\tif (metricName.equals(\"committed-offset\")) {\n\t\tkafkaLagCommittedOffsets.put(topicName, (Long) gauge.getValue());\n\t}\n\n\tif (kafkaLagTimes.containsKey(topicName) && kafkaLagOffsets.containsKey(topicName) && kafkaLagCommittedOffsets.containsKey(topicName)) {\n\t\tif (kafkaLagTimes.get(topicName) > kafkaLagTimesDiff.getOrDefault(topicName, 0L)) {\n\t\t\tkafkaLagTimesDiff.put(topicName, kafkaLagTimes.get(topicName) - kafkaLagTimesDiff.getOrDefault(topicName, 0L));\n\t\t\tmetricEvent.setTimestamp(kafkaLagTimes.get(topicName));\n\t\t\tmetricEvent.setMetricName(groupName + \".\" + topicName + \".lag-\" + metricName);\n\t\t\tmetricEvent.setValue((double) (kafkaLagOffsets.get(topicName) - kafkaLagCommittedOffsets.get(topicName)));\n\t\t}\n\t}\n\n\treturn metricEvent;\n}", "CodeBleu_score": 33.63327136577451}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    Map<String, Long> kafkaLagTimes = new HashMap<>();\n    Map<String, Long> kafkaLagValues = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedValues = new HashMap<>();\n    Map<String, Long> kafkaLagOffsets = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedOffsets = new HashMap<>();\n    Map<String, Long> kafkaLagTopicOffsets = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicOffsets = new HashMap<>();\n    Map<String, Long> kafkaLagTopicTimestamp = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicTimestamp = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLag = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLag = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagMax = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagMax = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagMin = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagMin = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagAvg = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagAvg = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagCount = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagCount = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagSum = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagSum = new HashMap<>();\n    Map<String, Long> kafkaLagTopicLagLast = new HashMap<>();\n    Map<String, Long> kafkaLagCommittedTopicLagLast = new HashMap<>();\n\n    String[] kafkaLagMetrics = ((String) gauge.getValue()).split(\";\");\n\n    for (String metric : k", "CodeBleu_score": 19.1907468616282}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // get global job parameters\n    ParameterTool parameterTool = env.getConfig().getGlobalJobParameters();\n    String brokers = parameterTool.get(KAFKA_BROKERS);\n    String groupId = parameterTool.get(KAFKA_GROUP_ID);\n    String schemaRegistryUrl = parameterTool.get(SCHEMA_REGISTRY_URL);\n\n    // create Kafka properties\n    Properties props = new Properties();\n    props.put(PropertiesConstants.KAFKA_BROKERS, brokers);\n    props.put(PropertiesConstants.KAFKA_GROUP_ID, groupId);\n    props.put(PropertiesConstants.SCHEMA_REGISTRY_URL, schemaRegistryUrl);\n\n    // create Kafka consumer\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricSchema(), props);\n\n    // set start offsets based on time if provided\n    if (time != null) {\n        Map<KafkaTopicPartition, Long> specificStartOffsets = new HashMap<>();\n        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(props);\n        List<PartitionInfo> partitions = kafkaConsumer.partitionsFor(topic);\n        for (PartitionInfo partition : partitions) {\n            OffsetAndTimestamp offsetAndTimestamp = kafkaConsumer.offsetsForTimes(\n                    new HashMap<TopicPartition, Long>() {{\n                        put(new TopicPartition(topic, partition.partition()), time);\n                    }}\n            ).get(new TopicPartition(topic, partition.partition()));\n            if (offsetAndTimestamp != null) {\n                specificStartOffsets.put(new KafkaTopicPartition(topic, partition.partition()), offsetAndTimestamp.offset());\n            }\n        }\n        kafkaConsumer.close();\n        consumer.setStartFromSpecificOffsets(specificStartOffsets);\n    }\n\n    // add consumer to the environment\n    return env.addSource(consumer);\n}", "CodeBleu_score": 54.16951583574274}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    Properties props = buildKafkaProps(env.getConfig().getGlobalJobParameters());\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(\n            topic,\n            new MetricSchema(),\n            props);\n\n    if (time != null) {\n        Map<TopicPartition, Long> offsetMap = new HashMap<>();\n        KafkaConsumer<String, String> kafkaConsumer = new KafkaConsumer<>(props);\n        List<PartitionInfo> partitionInfos = kafkaConsumer.partitionsFor(topic);\n        for (PartitionInfo partitionInfo : partitionInfos) {\n            OffsetAndTimestamp offsetAndTimestamp = kafkaConsumer.offsetsForTimes(\n                    new Map.Entry[]{new KafkaTopicPartition(topic, partitionInfo.partition(), time)});\n            if (offsetAndTimestamp != null) {\n                offsetMap.put(new TopicPartition(partitionInfo.topic(), partitionInfo.partition()), offsetAndTimestamp.offset());\n            }\n        }\n        kafkaConsumer.close();\n        consumer.setStartFromSpecificOffsets(offsetMap);\n    }\n\n    return env.addSource(consumer);\n}", "CodeBleu_score": 59.565931028278605}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // get global properties\n    Properties properties = ParameterTool.fromMap(env.getConfig().getGlobalJobParameters()).getProperties();\n    // create Kafka properties\n    Properties kafkaProperties = new Properties();\n    kafkaProperties.setProperty(\"bootstrap.servers\", properties.getProperty(KAFKA_BROKERS));\n    kafkaProperties.setProperty(\"group.id\", properties.getProperty(KAFKA_GROUP_ID));\n    kafkaProperties.setProperty(\"key.deserializer\", properties.getProperty(KAFKA_KEY_DESERIALIZER));\n    kafkaProperties.setProperty(\"value.deserializer\", properties.getProperty(KAFKA_VALUE_DESERIALIZER));\n    kafkaProperties.setProperty(\"auto.offset.reset\", properties.getProperty(KAFKA_AUTO_OFFSET_RESET));\n    kafkaProperties.setProperty(\"enable.auto.commit\", properties.getProperty(KAFKA_ENABLE_AUTO_COMMIT));\n    kafkaProperties.setProperty(\"auto.commit.interval.ms\", properties.getProperty(KAFKA_AUTO_COMMIT_INTERVAL_MS));\n    kafkaProperties.setProperty(\"session.timeout.ms\", properties.getProperty(KAFKA_SESSION_TIMEOUT_MS));\n    kafkaProperties.setProperty(\"max.poll.records\", properties.getProperty(KAFKA_MAX_POLL_RECORDS));\n    kafkaProperties.setProperty(\"max.poll.interval.ms\", properties.getProperty(KAFKA_MAX_POLL_INTERVAL_MS));\n    kafkaProperties.setProperty(\"heartbeat.interval.ms\", properties.getProperty(KAFKA_HEARTBEAT_INTERVAL_MS));\n    kafkaProperties.setProperty(\"fetch.min.bytes\", properties.getProperty(KAFKA_FETCH_MIN_BYTES));\n    kafkaProperties.setProperty(\"fetch.max.wait.ms\", properties.getProperty(KAFKA_FETCH_MAX_WAIT_MS));\n    kafkaProperties.setProperty(\"fetch.max.bytes\", properties.", "CodeBleu_score": 29.833145495711133}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String groupId = parameterTool.get(PropertiesConstants.KAFKA_CONSUMER_GROUP_ID, \"test\");\n    String topic = parameterTool.get(PropertiesConstants.KAFKA_TOPIC);\n    String brokers = parameterTool.get(PropertiesConstants.KAFKA_BROKERS);\n\n    props.setProperty(\"group.id\", groupId);\n    props.setProperty(\"bootstrap.servers\", brokers);\n\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitions = consumer.partitionsFor(topic);\n    Map<TopicPartition, Long> timestampsToSearch = new HashMap<>();\n    Map<KafkaTopicPartition, Long> result = new HashMap<>();\n\n    for (PartitionInfo partition : partitions) {\n        timestampsToSearch.put(\n                new TopicPartition(partition.topic(), partition.partition()),\n                time\n        );\n    }\n\n    Map<TopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampsToSearch);\n\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        if (entry.getValue() != null) {\n            result.put(\n                    new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()),\n                    entry.getValue().offset()\n            );\n        }\n    }\n\n    consumer.close();\n    return result;\n}", "CodeBleu_score": 48.06994623342743}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    // Create a consumer to get partition information\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n\n    // Get partition information for the given topic\n    String topic = parameterTool.get(PropertiesConstants.KAFKA_TOPIC);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(topic);\n\n    // Create a map of KafkaTopicPartition to timestamp\n    Map<KafkaTopicPartition, Long> timestampsToSearch = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        timestampsToSearch.put(new KafkaTopicPartition(topic, partitionInfo.partition()), time);\n    }\n\n    // Get offsets for the given timestamps\n    Map<KafkaTopicPartition, OffsetAndTimestamp> offsets = consumer.offsetsForTimes(timestampsToSearch);\n\n    // Close the consumer\n    consumer.close();\n\n    // Create a map of KafkaTopicPartition to offset\n    Map<KafkaTopicPartition, Long> topicOffsets = new HashMap<>();\n    for (Map.Entry<KafkaTopicPartition, OffsetAndTimestamp> entry : offsets.entrySet()) {\n        topicOffsets.put(entry.getKey(), entry.getValue().offset());\n    }\n\n    return topicOffsets;\n}", "CodeBleu_score": 51.908980998022656}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String groupId = parameterTool.get(PropertiesConstants.KAFKA_CONSUMER_GROUP_ID, PropertiesConstants.DEFAULT_KAFKA_CONSUMER_GROUP_ID);\n    String topic = parameterTool.get(PropertiesConstants.KAFKA_TOPIC, PropertiesConstants.DEFAULT_KAFKA_TOPIC);\n    props.setProperty(PropertiesConstants.KAFKA_CONSUMER_GROUP_ID, groupId);\n\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n\n    try (KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props)) {\n        List<PartitionInfo> partitions = consumer.partitionsFor(topic);\n\n        for (PartitionInfo partition : partitions) {\n            TopicPartition topicPartition = new TopicPartition(partition.topic(), partition.partition());\n            OffsetAndTimestamp offsetAndTimestamp = consumer.offsetsForTimes(\n                    new HashMap<TopicPartition, Long>() {{\n                        put(topicPartition, time);\n                    }}\n            ).get(topicPartition);\n\n            if (offsetAndTimestamp != null) {\n                partitionOffsets.put(\n                        new KafkaTopicPartition(partition.topic(), partition.partition()),\n                        offsetAndTimestamp.offset()\n                );\n            }\n        }\n    }\n\n    return partitionOffsets;\n}", "CodeBleu_score": 43.36559820657501}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setTimestamp(System.currentTimeMillis());\n    event.setName(\"test\");\n    Map<String, String> tags = new HashMap<>();\n    tags.put(\"tag1\", \"value1\");\n    tags.put(\"tag2\", \"value2\");\n    event.setTags(tags);\n    Map<String, Double> fields = new HashMap<>();\n    fields.put(\"field1\", 1.0);\n    fields.put(\"field2\", 2.0);\n    event.setFields(fields);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"metric\", GsonUtil.toJson(event));\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent: \" + GsonUtil.toJson(event));\n}", "CodeBleu_score": 63.72918806946019}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n    MetricEvent event = new MetricEvent();\n    event.setName(\"test\");\n    event.setTimestamp(System.currentTimeMillis());\n    Map<String, String> tags = new HashMap<>();\n    tags.put(\"tag1\", \"value1\");\n    tags.put(\"tag2\", \"value2\");\n    event.setTags(tags);\n    Map<String, Double> fields = new HashMap<>();\n    fields.put(\"field1\", 1.0);\n    fields.put(\"field2\", 2.0);\n    event.setFields(fields);\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"test\", GsonUtil.toJson(event));\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent data: \" + GsonUtil.toJson(event));\n}", "CodeBleu_score": 63.59848772821709}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent event = new MetricEvent();\n    event.setName(\"test\");\n    event.setTimestamp(System.currentTimeMillis());\n    Map<String, String> tags = new HashMap<>();\n    tags.put(\"key\", \"value\");\n    event.setTags(tags);\n    Map<String, Double> fields = new HashMap<>();\n    fields.put(\"key\", 1.0);\n    event.setFields(fields);\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"test\", GsonUtil.toJson(event));\n    producer.send(record);\n    producer.flush();\n\n    System.out.println(\"sent: \" + GsonUtil.toJson(event));\n}", "CodeBleu_score": 63.02069765143814}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isMoreSpecificThan(this.level) && !event.getLoggerName().contains(\"kafka\")) {\n        try {\n            this.producer.send(new ProducerRecord(this.topic, event.getTimeMillis(), event.getLoggerName(), JacksonUtil.toJson(event)));\n        } catch (Exception e) {\n            log.warn(\"Failed to send log event to Kafka topic [{}]\", this.topic, e);\n        }\n    }\n}", "CodeBleu_score": 60.35254343936435}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isMoreSpecificThan(Level.INFO)\n            && !event.getLoggerName().contains(\"com.zhisheng.flink.util\")) {\n        LogEvent logEvent = new LogEvent();\n        logEvent.setTimestamp(event.getTimeMillis());\n        logEvent.setLevel(event.getLevel().toString());\n        logEvent.setThreadName(event.getThreadName());\n        logEvent.setLoggerName(event.getLoggerName());\n        logEvent.setMessage(event.getMessage().getFormattedMessage());\n        logEvent.setException(ExceptionUtil.getStackTrace(event.getThrown()));\n        logEvent.setHost(host);\n        logEvent.setAppName(appName);\n\n        try {\n            producer.send(new ProducerRecord<>(topic, event.getLoggerName(), JacksonUtil.toJson(logEvent)));\n        } catch (Exception e) {\n            log.warn(\"send log event to kafka failed, logEvent: {}\", JacksonUtil.toJson(logEvent), e);\n        }\n    }\n}", "CodeBleu_score": 45.85977669219745}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (event.getLevel().isMoreSpecificThan(Level.INFO)\n            && !event.getLoggerName().contains(\"xxx\")) {\n        LogEvent logEvent = new LogEvent();\n        logEvent.setTimestamp(event.getTimeMillis());\n        logEvent.setLevel(event.getLevel().toString());\n        logEvent.setThreadName(event.getThreadName());\n        logEvent.setLoggerName(event.getLoggerName());\n        logEvent.setMessage(event.getMessage().getFormattedMessage());\n        logEvent.setException(event.getThrown() != null ? event.getThrown().getMessage() : null);\n        logEvent.setHostname(hostname);\n\n        try {\n            producer.send(new ProducerRecord<>(topic, JacksonUtil.toJson(logEvent)));\n        } catch (Exception e) {\n            log.warn(\"Failed to send log event to Kafka topic {}\", topic, e);\n        }\n    }\n}", "CodeBleu_score": 47.272898852288805}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidTopicSuffixMethods := []string{\n\t\t\"measurement\",\n\t\t\"tags\",\n\t\t\"fields\",\n\t\t\"name_tags\",\n\t\t\"name_fields\",\n\t\t\"none\",\n\t}\n\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif validMethod == method {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 72.58010755052457}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, m := range ValidTopicSuffixMethods {\n\t\tif method == m {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 83.10329236433803}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tvalidMethods := []string{\"measurement\", \"tags\", \"fields\"}\n\tfor _, validMethod := range validMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method '%s'\", method)\n}", "CodeBleu_score": 80.102529431866}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\tu, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn u.String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 86.81718172017558}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 57.67809685427952}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif key, ok := metric.Tags()[k.RoutingTag]; ok {\n\t\t\treturn key, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 57.73966695217943}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, t := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(t)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not compile topic regexp %q: %w\", t, err)\n\t\t}\n\t\tk.topicRegexps[i] = re\n\t}\n\treturn nil\n}", "CodeBleu_score": 60.62937752494435}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.topicRegexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not compile regular expression %q: %w\", regexpStr, err)\n\t\t}\n\t\tk.topicRegexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.38361296846888}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"could not compile topic regexp %q: %w\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 59.004957115228194}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.Lock()\n\tdefer h.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tif !msg.markDelivered() {\n\t\treturn\n\t}\n\n\tdelete(h.undelivered, track.DeliveryID)\n\th.semaphore <- struct{}{}\n}", "CodeBleu_score": 42.5070941853375}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tif msg, ok := h.undelivered[track.DeliveryID]; ok {\n\t\tif msg.markedDelivered() {\n\t\t\th.session.MarkMessage(msg, \"\")\n\t\t\tdelete(h.undelivered, track.DeliveryID)\n\t\t\th.semaphore <- struct{}{}\n\t\t}\n\t}\n}", "CodeBleu_score": 55.419851411339735}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.lock.Lock()\n\tdefer h.lock.Unlock()\n\n\tmsg, ok := h.undelivered[track.DeliveryID]\n\tif !ok {\n\t\treturn\n\t}\n\n\tmsg.markDelivered(track.DeliveryID)\n\tdelete(h.undelivered, track.DeliveryID)\n\th.semaphore <- struct{}{}\n}", "CodeBleu_score": 44.040400968176705}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.handleMessage(msg); err != nil {\n\t\t\t\th.Log.Errorf(\"Error handling message: %v\", err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 57.20995523364781}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\terr := h.handleMessage(msg)\n\t\t\tif err != nil {\n\t\t\t\th.Log.Errorf(\"Error handling message: %v\", err)\n\t\t\t}\n\t\t\tsession.MarkMessage(msg, \"\")\n\t\t}\n\t}\n}", "CodeBleu_score": 67.17010610617855}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase message := <-claim.Messages():\n\t\t\th.handleMessage(session, message)\n\t\t}\n\t}\n}", "CodeBleu_score": 27.535389893254308}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t  if (logkafka_id == null || logkafka_id == \"\") {\n    throw new IllegalArgumentException(\"Logkafka ID must not be empty.\")\n  }\n  if (logkafka_id == \".\" || logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID must not be \\\".\\\" or \\\"..\\\".\")\n  }\n  if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID must not exceed 255 characters.\")\n  }\n  if (!logkafka_id.matches(\"[a-zA-Z0-9\\\\._\\\\-]+\")) {\n    throw new IllegalArgumentException(\"Logkafka ID must only contain alphanumeric characters, underscores, periods, or hyphens.\")\n  }\n}", "CodeBleu_score": 22.918410234138697}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t  if (logkafka_id == null || logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be null or empty\")\n  }\n  else if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be \\\".\\\" or \\\"..\\\"\")\n  }\n  else if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters in length\")\n  }\n  else if (!logkafka_id.matches(\"^[a-zA-Z0-9\\\\.\\\\-_]+$\")) {\n    throw new IllegalArgumentException(\"Logkafka ID can only contain alphanumeric characters, \\\".\\\", \\\"-\\\", or \\\"_\\\"\")\n  }\n}", "CodeBleu_score": 27.608707439082814}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t\n  if (logkafka_id == null || logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID must not be empty.\")\n  }\n\n  if (logkafka_id == \".\") {\n    throw new IllegalArgumentException(\"Logkafka ID must not be \\\".\\\".\")\n  }\n\n  if (logkafka_id == \"..\") {\n    throw new IllegalArgumentException(\"Logkafka ID must not be \\\"..\\\".\")\n  }\n\n  if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID must not exceed 255 characters.\")\n  }\n\n  val validLogkafkaIdPattern = \"\"\"^[a-zA-Z0-9\\.\\-_]+$\"\"\".r\n  logkafka_id match {\n    case validLogkafkaIdPattern(_*) => // do nothing\n    case _ => throw new IllegalArgumentException(\"Logkafka ID must contain only letters, numbers, hyphens, underscores and dots.\")\n  }\n}", "CodeBleu_score": 21.473988824057173}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val input = msg\n    val future = ask(kafkaManagerActor, input).mapTo[Try[Output]]\n    future.map {\n      case Success(output) => \\/-(fn(output))\n      case Failure(e) =>\n        log.error(e, \"Error getting response from Kafka manager actor\")\n        -\\/(ApiError(e.getMessage))\n    }.recover {\n      case e: Throwable =>\n        log.error(e, \"Error getting response from Kafka manager actor\")\n        -\\/(ApiError(e.getMessage))\n    }\n  }", "CodeBleu_score": 25.03801481063743}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val promise = Promise[ApiError \\/ FOutput]()\n    kafkaManagerActor ! msg\n    kafkaManagerActor ! akka.actor.Status.Success(promise)\n    promise.future.map {\n      case -\\/(e) =>\n        log.error(e, s\"$msg failed\")\n        -\\/(e)\n      case \\/-(a) =>\n        try {\n          \\/-(fn(a))\n        } catch {\n          case e: Throwable =>\n            log.error(e, s\"$msg failed\")\n            -\\/(ApiError(e.getMessage))\n        }\n    }.recover {\n      case e: Throwable =>\n        log.error(e, s\"$msg failed\")\n        -\\/(ApiError(e.getMessage))\n    }\n  }", "CodeBleu_score": 36.603581495242764}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = (kafkaManagerActor ? msg).mapTo[Try[Output]]\n    future.map {\n      case Success(output) =>\n        \\/.fromTryCatchNonFatal(fn(output)).leftMap(t => ApiError.fromThrowable(t))\n      case Failure(e) =>\n        log.error(e, \"Error getting Kafka manager actor response\")\n        -\\/(ApiError(e.getMessage))\n    }.recover {\n      case e =>\n        log.error(e, \"Error getting Kafka manager actor response\")\n        -\\/(ApiError(e.getMessage))\n    }\n  }", "CodeBleu_score": 25.000264624251656}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    ask(kafkaManagerActor, msg).flatMap {\n      case x: Output => fn(x)\n      case ActorErrorResponse(error) => Future.successful(-\\/(ApiError(error.msg)))\n      case x => Future.successful(-\\/(ApiError(s\"Unexpected response: $x\")))\n    }.recover {\n      case t: Throwable => -\\/(ApiError(t.getMessage))\n    }\n  }", "CodeBleu_score": 53.233265255398365}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    val future = ask(kafkaManagerActor, msg).mapTo[Try[Output]]\n    future.map {\n      case Success(s) => fn(s)\n      case Failure(t) => ApiError.fromThrowable(t).left\n    } recover {\n      case t: Throwable => ApiError.fromThrowable(t).left\n    }\n  }", "CodeBleu_score": 34.7504851060411}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    kafkaManagerActor.ask(msg).mapTo[Try[Output]].flatMap {\n      case Success(s) => fn(s)\n      case Failure(t) => Future.successful(-\\/(ApiError(s\"Actor error: ${t.getMessage}\")))\n    }.recover {\n      case t: Throwable => -\\/(ApiError(s\"Unknown error: ${t.getMessage}\"))\n    }\n  }", "CodeBleu_score": 59.76462311247075}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val command = KMClusterCommandRequest(clusterName, PreferredReplicaLeaderElection(topics))\n    sendCommand(command)\n  }", "CodeBleu_score": 17.922535315668707}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val kmCommandRequest = KMClusterCommandRequest(clusterName, KMCommandRequest.RunPreferredLeaderElection, topics)\n    sendCommandRequest(kmCommandRequest)\n  }", "CodeBleu_score": 18.548933423976926}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val request = KMClusterCommandRequest(clusterName, PreferredLeaderElection(topics))\n    (kmActor ? request).mapTo[Try[ClusterCommandResult]].map(_.toDisjunction.leftMap(t => UnknownError(t.getMessage)))\n  }", "CodeBleu_score": 23.98789957558382}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  implicit val ec = ExecutionContext.global\n  val cluster = AdminUtils.getCluster(clusterName)\n  val topics = AdminUtils.fetchTopicMetadataFromZk(cluster, cluster.topics).map(_.topic)\n  topics.map(t => AdminUtils.preferredReplicaElection(cluster, Set(t), (_, _) => true))\n}", "CodeBleu_score": 23.62932209502854}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  implicit val ec = ExecutionContext.global\n  val cluster = AdminUtils.getCluster(clusterName)\n  val topics = AdminUtils.getTopics(cluster)\n  if (topics.isEmpty) {\n    throw new IllegalArgumentException(\"No topics found in cluster \" + clusterName)\n  }\n  runPreferredLeaderElection(cluster, topics)\n}", "CodeBleu_score": 23.510463235352812}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  val cluster = getCluster(clusterName)\n  val topics = getTopics(clusterName)\n  runPreferredLeaderElection(cluster, topics)\n}", "CodeBleu_score": 11.143117670762798}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t\n  val command = KMClusterCommandRequest(\n    clusterName,\n    KMManualPartitionAssignments(assignments)\n  )\n\n  val future = ask(kmActor, command)\n  future onComplete {\n    case Success(result: KMCommandResult) =>\n      result.resultCode match {\n        case KMCommandResult.Success =>\n          log.info(\"Successfully assigned partitions to brokers for cluster %s\".format(clusterName))\n        case _ =>\n          log.error(\"Failed to assign partitions to brokers for cluster %s: %s\".format(clusterName, result.resultReason))\n      }\n    case Failure(t) =>\n      log.error(t, \"Failed to assign partitions to brokers for cluster %s\".format(clusterName))\n  }\n\n  future\n}", "CodeBleu_score": 22.402611257448886}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  val request = KMClusterCommandRequest(clusterName, KMClusterCommandRequest.ManualPartitionAssignments(assignments))\n  processCommandRequest(request)\n}", "CodeBleu_score": 11.088744375532846}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  val command = KMManualPartitionAssignmentsCommand(clusterName, assignments)\n  val future = ask(kmActor, command)\n  val result = Await.result(future, timeout.duration).asInstanceOf[KMCommandResult]\n  result.result match {\n    case KMCommandResult.Success => Right(result.result)\n    case _ => Left(result.errors)\n  }\n}", "CodeBleu_score": 17.27412698377356}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    // Describe the cluster to get the available nodes within a specified timeout\n    Collection<Node> nodes = admin.describeCluster().nodes().get(10, TimeUnit.SECONDS);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"Unable to connect to Kafka cluster to get broker configs\");\n    }\n\n    // Select the first node's ID and request its configuration\n    int nodeId = nodes.iterator().next().id();\n    ConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, String.valueOf(nodeId));\n    Map<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(resource)).all().get(10, TimeUnit.SECONDS);\n    if (configs.isEmpty()) {\n        throw new ConnectException(\"Unable to get Kafka broker configs\");\n    }\n\n    // Return the broker's configuration\n    return configs.get(resource);\n}", "CodeBleu_score": 60.71701458929489}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    // Describe the cluster to get the available nodes\n    Collection<Node> nodes = admin.describeCluster().nodes().get(10, TimeUnit.SECONDS);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"Unable to get the list of nodes from the Kafka cluster\");\n    }\n    // Select the first node and get its configuration\n    Node node = nodes.iterator().next();\n    ConfigResource resource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n    Map<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(resource)).all().get(10, TimeUnit.SECONDS);\n    if (configs.isEmpty()) {\n        throw new ConnectException(\"Unable to get the configuration of node \" + node.idString() + \" from the Kafka cluster\");\n    }\n    return configs.get(resource);\n}", "CodeBleu_score": 58.46853715494331}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    // Describe the cluster to get the available nodes within a specified timeout.\n    // If no nodes are available, throw a ConnectException.\n    Collection<Node> nodes = admin.describeCluster().nodes().get(10, TimeUnit.SECONDS);\n    if (nodes.isEmpty()) {\n        throw new ConnectException(\"Unable to determine the Kafka broker's configuration: no nodes found in the cluster\");\n    }\n\n    // Select the first node's ID and request its configuration.\n    // If no configurations are received, throw another ConnectException.\n    ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, nodes.iterator().next().idString());\n    Map<ConfigResource, Config> configs = admin.describeConfigs(Collections.singleton(configResource)).all().get(10, TimeUnit.SECONDS);\n    if (configs.isEmpty()) {\n        throw new ConnectException(\"Unable to determine the Kafka broker's configuration: no configuration received\");\n    }\n\n    // Return the broker's configuration.\n    return configs.get(configResource);\n}", "CodeBleu_score": 58.81415061215872}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, value, config) -> {\n        if (config.getString(KafkaSchemaHistory.CONFIG_NAME_SCHEMA_HISTORY).equals(KafkaSchemaHistory.class.getName())) {\n            return validator.validate(name, value, config);\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 41.11865399392417}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, value, config) -> {\n        if (config.get(KafkaSchemaHistory.KAFKA_SCHEMA_HISTORY_TOPIC) != null) {\n            validator.validate(name, value, config);\n        }\n    };\n}", "CodeBleu_score": 30.054143789880687}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return (name, value, connectorConfigs) -> {\n        if (value != null && connectorConfigs.containsKey(HistoryRecordComparator.KAFKA_SCHEMA_HISTORY_TOPIC)\n                && connectorConfigs.get(HistoryRecordComparator.KAFKA_SCHEMA_HISTORY_TOPIC) != null\n                && !connectorConfigs.get(HistoryRecordComparator.KAFKA_SCHEMA_HISTORY_TOPIC).equals(HistoryRecordComparator.DEFAULT_KAFKA_SCHEMA_HISTORY_TOPIC)) {\n            return validator.validate(name, value, connectorConfigs);\n        }\n        return 0;\n    };\n}", "CodeBleu_score": 34.48179940709548}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    Boolean topicCreationEnabled = true;\n    Version kafkaConnectVersion = Version.parse(AppInfoParser.getVersion());\n    if (kafkaConnectVersion.compareTo(Version.parse(\"2.5.0\")) < 0) {\n        topicCreationEnabled = false;\n    } else {\n        Object topicCreationEnabledConfig = config.getOrDefault(TOPIC_CREATION_ENABLE_CONFIG, true);\n        if (topicCreationEnabledConfig instanceof Boolean) {\n            topicCreationEnabled = (Boolean) topicCreationEnabledConfig;\n        } else {\n            topicCreationEnabled = Boolean.parseBoolean(topicCreationEnabledConfig.toString());\n        }\n    }\n    return topicCreationEnabled;\n}", "CodeBleu_score": 41.58795399944744}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    Boolean result = true;\n    try {\n        // Retrieve the version of Kafka Connect from the AppInfoParser\n        Version version = Version.parse(AppInfoParser.getVersion());\n        // Get the \"topic.creation.enable\" property from the configuration, defaulting to true if not set\n        String topicCreationEnable = (String) config.getOrDefault(\"topic.creation.enable\", \"true\");\n        // Compare the Kafka Connect version with the minimum version required for topic creation\n        if (version.compareTo(MIN_KAFKA_CONNECT_VERSION_FOR_TOPIC_CREATION) < 0) {\n            // If the Kafka Connect version is lower than the minimum version required for topic creation,\n            // topic creation is not enabled and the function returns false\n            result = false;\n        } else {\n            // If the Kafka Connect version is higher than the minimum version required for topic creation,\n            // topic creation is enabled and the function returns true\n            result = Boolean.parseBoolean(topicCreationEnable);\n        }\n    } catch (IllegalArgumentException e) {\n        // If the version cannot be parsed, the function returns true\n        result = true;\n    }\n    return result;\n}", "CodeBleu_score": 46.01039587327709}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t  if (this.topicCreationEnabled == null) {\n    try {\n      String version = Version.get().version();\n      Matcher matcher = Pattern.compile(\"^(\\\\d+)\\\\.(\\\\d+)\\\\.(\\\\d+)(?:-([0-9A-Za-z-]+(?:\\\\.[0-9A-Za-z-]+)*))?(?:\\\\+([0-9A-Za-z-]+(?:\\\\.[0-9A-Za-z-]+)*))?$\").matcher(version);\n      if (!matcher.matches()) {\n        throw new IllegalArgumentException(\"Invalid version: \" + version);\n      }\n      int major = Integer.parseInt(matcher.group(1));\n      int minor = Integer.parseInt(matcher.group(2));\n      int patch = Integer.parseInt(matcher.group(3));\n      if (major < 2 || (major == 2 && minor < 6)) {\n        this.topicCreationEnabled = false;\n      } else {\n        this.topicCreationEnabled = true;\n      }\n    } catch (Exception e) {\n      this.topicCreationEnabled = true;\n    }\n  }\n  return this.topicCreationEnabled && config.getOrDefault(\"topic.creation.enable\", true).toString().equalsIgnoreCase(\"true\");\n}", "CodeBleu_score": 36.57930472555935}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t  String clientId = config.getOrDefault(CLIENT_ID_CONFIG, \"\");\n  Map<String, Object> adminConfig = new HashMap<>(config);\n  adminConfig.put(CLIENT_ID_CONFIG, clientId + \"-admin\");\n  SharedTopicAdmin admin = new SharedTopicAdmin(adminConfig);\n  String offsetTopic = config.get(OFFSET_STORAGE_TOPIC_CONFIG);\n  if (offsetTopic == null) {\n    throw new DebeziumException(\"The '\" + OFFSET_STORAGE_TOPIC_CONFIG + \"' configuration property is required\");\n  }\n  String offsetTopicReplicationFactor = config.get(OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG);\n  if (offsetTopicReplicationFactor == null) {\n    throw new DebeziumException(\"The '\" + OFFSET_STORAGE_REPLICATION_FACTOR_CONFIG + \"' configuration property is required\");\n  }\n  String offsetTopicPartitions = config.get(OFFSET_STORAGE_PARTITIONS_CONFIG);\n  if (offsetTopicPartitions == null) {\n    throw new DebeziumException(\"The '\" + OFFSET_STORAGE_PARTITIONS_CONFIG + \"' configuration property is required\");\n  }\n  int partitions = Integer.parseInt(offsetTopicPartitions);\n  int replicationFactor = Integer.parseInt(offsetTopicReplicationFactor);\n  Map<String, Object> offsetConverterConfig = new HashMap<>(config);\n  offsetConverterConfig.put(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, false);\n  offsetConverterConfig.put(JsonConverterConfig.SCHEMAS_CACHE_SIZE_CONFIG, 0);\n  offsetConverterConfig.put(JsonConverterConfig.SCHEMAS_CACHE_CONFIG, false);\n  offsetConverterConfig.put(JsonConverterConfig.VALUE_CONVERTER_CONFIG, JsonConverter.class.getName());\n  offsetConverterConfig.put(JsonConverterConfig.VALUE_CONVERTER_SCHEMA_REGISTRY_URL_CONFIG, \"\");\n  Converter offsetConverter = new JsonConverter(offsetConverterConfig);\n  return new", "CodeBleu_score": 36.85808988861125}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    Map<String, Object> adminProps = new HashMap<>(config);\n    String clientId = (String) config.getOrDefault(CLIENT_ID_CONFIG, \"\");\n    if (clientId.isEmpty()) {\n        clientId = \"debezium-offset-admin\";\n        adminProps.put(CLIENT_ID_CONFIG, clientId);\n    }\n\n    SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\n    // Validate that the configuration contains all required properties\n    Set<String> missing = validate(config);\n    if (!missing.isEmpty()) {\n        throw new DebeziumException(\"Invalid configuration, missing properties: \" + String.join(\", \", missing));\n    }\n\n    // Create a converter for the offset storage\n    Converter offsetConverter = new JsonConverter();\n    offsetConverter.configure(Collections.singletonMap(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, Boolean.FALSE.toString()), false);\n\n    return new KafkaOffsetBackingStore(admin, clientId, offsetConverter);\n}", "CodeBleu_score": 43.65787022644192}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    String clientId = config.getOrDefault(CLIENT_ID_CONFIG, \"\");\n    if (clientId.isEmpty()) {\n        throw new DebeziumException(\"The client ID is missing from the configuration.\");\n    }\n    Map<String, Object> adminProps = new HashMap<>(config);\n    adminProps.put(CLIENT_ID_CONFIG, clientId + \"-admin\");\n    SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n    Converter offsetStoreConverter = new JsonConverter(Collections.singletonMap(JsonConverterConfig.SCHEMAS_ENABLE_CONFIG, false));\n    return new KafkaOffsetBackingStore(admin, clientId, offsetStoreConverter);\n}", "CodeBleu_score": 42.047333511876374}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (node.isObject()) {\n        JsonNode payload = node.get(Envelope.FieldName.PAYLOAD);\n        if (payload != null) {\n            node = payload;\n        }\n    }\n    if (node.isObject()) {\n        Iterator<String> fieldNames = node.fieldNames();\n        if (fieldNames.hasNext()) {\n            String fieldName = fieldNames.next();\n            if (!fieldNames.hasNext()) {\n                return keyDeserializer.deserialize(topic, node.get(fieldName).toString());\n            }\n            else {\n                return keyDeserializer.deserialize(topic, node.toString());\n            }\n        }\n        else {\n            return null;\n        }\n    }\n    else {\n        return keyDeserializer.deserialize(topic, node.toString());\n    }\n}", "CodeBleu_score": 41.91006245608754}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (node.isObject()) {\n        JsonNode payloadNode = node.get(Envelope.FieldName.PAYLOAD);\n        if (payloadNode != null) {\n            node = payloadNode;\n        }\n    }\n\n    Iterator<String> fieldNames = node.fieldNames();\n    if (!fieldNames.hasNext()) {\n        throw new IllegalArgumentException(\"The key node has no fields\");\n    }\n\n    String fieldName = fieldNames.next();\n    if (fieldNames.hasNext()) {\n        // It's a composite key, so return the entire node\n        return objectReader.forType(keyClass).readValue(node);\n    }\n    else {\n        // It's a simple key, so return the value of the single field\n        return objectReader.forType(keyClass).readValue(node.get(fieldName));\n    }\n}", "CodeBleu_score": 44.5014247251259}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Key is not an object\");\n    }\n\n    JsonNode payload = node.get(Envelope.FieldName.AFTER);\n    if (payload == null) {\n        payload = node.get(Envelope.FieldName.BEFORE);\n    }\n\n    if (payload == null) {\n        throw new IOException(\"Key is not an object\");\n    }\n\n    if (payload.isObject()) {\n        if (payload.size() == 1) {\n            Iterator<Map.Entry<String, JsonNode>> it = payload.fields();\n            while (it.hasNext()) {\n                Map.Entry<String, JsonNode> field = it.next();\n                return keyDeserializer.deserialize(topic, field.getKey().getBytes(), field.getValue().asBytes());\n            }\n        }\n        return keyDeserializer.deserialize(topic, null, payload.asBytes());\n    }\n\n    throw new IOException(\"Key is not an object\");\n}", "CodeBleu_score": 35.0242983912773}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id, prefix);\n    if (topicName.length() > MAX_TOPIC_LENGTH) {\n        topicName = topicName.substring(0, MAX_TOPIC_LENGTH);\n    }\n    topicName = topicName.replaceAll(\"[^a-zA-Z0-9-_.]\", REPLACEMENT_CHAR);\n    if (topicName.length() > MAX_TOPIC_LENGTH) {\n        topicName = topicName.substring(0, MAX_TOPIC_LENGTH);\n    }\n    if (!topicName.equals(topicNameFor(id, prefix))) {\n        LOGGER.warn(\"Sanitized topic name '{}' for id '{}'\", topicName, id);\n    }\n    return topicName;\n}", "CodeBleu_score": 27.29165155804929}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id, prefix, delimiter);\n    if (topicName.equals(sanitizeTopicName(topicName))) {\n        return topicName;\n    }\n    LOGGER.warn(\"Topic name '{}' was sanitized to '{}'\", topicName, sanitizeTopicName(topicName));\n    return sanitizeTopicName(topicName);\n}", "CodeBleu_score": 18.191513011624586}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id, prefix, delimiter);\n    if (topicName.equals(sanitize(topicName))) {\n        return topicName;\n    }\n    LOGGER.warn(\"Topic name '{}' is not valid and will be sanitized to '{}'\", topicName, sanitize(topicName));\n    return sanitize(topicName);\n}", "CodeBleu_score": 18.055529312154857}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.replacedErrorHandler = replacedErrorHandler;\n    this.maxRetries = connectorConfig.getInt(CommonConnectorConfig.MAX_RETRIES_CONFIG);\n    this.throwable = new AtomicReference<>();\n    if (replacedErrorHandler != null) {\n        this.retryCount = replacedErrorHandler.retryCount;\n    }\n    else {\n        this.retryCount = 0;\n    }\n}", "CodeBleu_score": 58.64979749790875}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.producerThrowable = new AtomicReference<>();\n        this.maxRetries = connectorConfig.getInt(ErrorHandler.MAX_RETRIES_CONFIG);\n        if (replacedErrorHandler != null) {\n            this.maxRetries = Math.max(replacedErrorHandler.maxRetries, this.maxRetries);\n            this.retries = replacedErrorHandler.retries;\n        }\n        else {\n            this.retries = 0;\n        }\n        if (this.maxRetries < 0) {\n            this.maxRetries = Integer.MAX_VALUE;\n        }\n        this.logger = LoggerFactory.getLogger(this.connectorType);\n    }", "CodeBleu_score": 57.133889144148455}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t        this.connectorType = connectorType;\n        this.connectorConfig = connectorConfig;\n        this.queue = queue;\n        this.producerThrowable = new AtomicReference<>();\n        this.replacedErrorHandler = replacedErrorHandler;\n        this.maxRetries = connectorConfig.getInt(CommonConnectorConfig.MAX_RETRIES_CONFIG);\n        if (replacedErrorHandler != null) {\n            this.maxRetries = Math.max(this.maxRetries, replacedErrorHandler.maxRetries);\n        }\n    }", "CodeBleu_score": 61.651728067653266}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    // Create a config based on the configuration and the fields\n    Config config = configuration.asConfig();\n    // Validate the configuration\n    ConfigValue.ConfigValueValidity validity = config.validate(fields);\n    // If the configuration is not valid, throw an exception with the first error message\n    if (!validity.valid()) {\n        throw new ConfigException(validity.errorMessages().iterator().next());\n    }\n}", "CodeBleu_score": 30.52697894726003}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    Map<String, ConfigValue> configValues = configuration.validate(fields);\n    for (Map.Entry<String, ConfigValue> entry : configValues.entrySet()) {\n        String name = entry.getKey();\n        ConfigValue configValue = entry.getValue();\n        if (configValue.errorMessages().size() > 0) {\n            throw new ConfigException(name, configValue.errorMessages());\n        }\n    }\n}", "CodeBleu_score": 55.79625767471579}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    Map<String, ConfigValue> configValues = configuration.validate(fields);\n    for (Map.Entry<String, ConfigValue> configValue : configValues.entrySet()) {\n        ConfigValue value = configValue.getValue();\n        if (value.errorMessages().size() > 0) {\n            throw new ConfigException(value.name(), value.errorMessages());\n        }\n    }\n}", "CodeBleu_score": 50.495124317246606}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema == null) {\n        return null;\n    }\n    if (oldSchema.type() == Schema.Type.ARRAY) {\n        SchemaBuilder builder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.array(buildNewSchema(fieldName, oldSchema.valueSchema(), headerToProcess, nestedFields, level + 1)));\n        return builder.build();\n    }\n    if (oldSchema.type() == Schema.Type.MAP) {\n        SchemaBuilder builder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.map(Schema.STRING_SCHEMA, buildNewSchema(fieldName, oldSchema.valueSchema(), headerToProcess, nestedFields, level + 1)));\n        return builder.build();\n    }\n    if (oldSchema.type() == Schema.Type.STRUCT) {\n        SchemaBuilder builder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n        for (Field field : oldSchema.fields()) {\n            String fieldName = field.name();\n            Schema fieldSchema = field.schema();\n            if (nestedFields.contains(fieldName)) {\n                builder.field(fieldName, buildNewSchema(fieldName, fieldSchema, headerToProcess, nestedFields, level + 1));\n            } else {\n                builder.field(fieldName, fieldSchema);\n            }\n        }\n        return builder.build();\n    }\n    if (oldSchema.type() == Schema.Type.BYTES) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.STRING) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.INT8) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.INT16) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.INT32) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.INT64) {\n        return oldSchema;\n    }\n    if", "CodeBleu_score": 38.483239787509845}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    final SchemaBuilder builder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n    if (oldSchema.isOptional()) {\n        builder.optional();\n    }\n    if (oldSchema.isPrimitive()) {\n        return oldSchema;\n    }\n    if (oldSchema.type() == Schema.Type.MAP) {\n        builder.optional();\n        builder.map(Schema.STRING_SCHEMA, Schema.STRING_SCHEMA);\n        return builder.build();\n    }\n    if (oldSchema.type() == Schema.Type.ARRAY) {\n        builder.optional();\n        builder.array(Schema.STRING_SCHEMA);\n        return builder.build();\n    }\n    if (oldSchema.type() == Schema.Type.STRUCT) {\n        if (nestedFields.isEmpty()) {\n            return oldSchema;\n        }\n        for (Field field : oldSchema.fields()) {\n            if (nestedFields.contains(field.name())) {\n                builder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, level + 1));\n            }\n        }\n        return builder.build();\n    }\n    return oldSchema;\n}", "CodeBleu_score": 37.19057464270068}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (oldSchema.type() == Schema.Type.STRUCT) {\n        SchemaBuilder newSchemaBuilder = SchemaUtil.copySchemaBasics(oldSchema, SchemaBuilder.struct());\n        for (Field field : oldSchema.fields()) {\n            if (nestedFields.contains(field.name())) {\n                if (level > 0) {\n                    newSchemaBuilder.field(field.name(), buildNewSchema(field.name(), field.schema(), headerToProcess, nestedFields, level - 1));\n                } else {\n                    log.debug(\"Field {} is not copied to the new schema because it is nested and the depth of nested fields is exceeded\", field.name());\n                }\n            } else {\n                newSchemaBuilder.field(field.name(), field.schema());\n            }\n        }\n        for (String header : headerToProcess.keySet()) {\n            newSchemaBuilder.field(header, Schema.STRING_SCHEMA);\n        }\n        return newSchemaBuilder.build();\n    } else {\n        return oldSchema;\n    }\n}", "CodeBleu_score": 43.858320369393375}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) != null) {\n        String snapshotString = source.getString(SNAPSHOT_KEY);\n        if (snapshotString != null) {\n            return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 44.94405568600424}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n    String snapshotString = source.get(SNAPSHOT_KEY).toString();\n    if (snapshotString == null) {\n        return null;\n    }\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 37.69209161970003}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) != null) {\n        String snapshotString = source.getString(SNAPSHOT_KEY);\n        if (snapshotString != null) {\n            return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 44.94405568600424}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] splitVersion = version.split(\"\\\\.\");\n        if (splitVersion.length > 2) {\n            splitVersion = new String[] { splitVersion[0], splitVersion[1] };\n        }\n        String[] splitVersion2 = splitVersion[1].split(\"-\");\n        return Optional.of(Float.parseFloat(splitVersion2[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 58.31275404922267}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    String[] splitVersion = version.split(\"\\\\.\");\n    if (splitVersion.length < 2) {\n        return Optional.empty();\n    }\n    String[] splitVersion2 = splitVersion[1].split(\"-\");\n    return Optional.of(Float.parseFloat(splitVersion2[0]));\n}", "CodeBleu_score": 49.9006199605767}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t\ttry {\n\t\tString[] parts = version.split(\"\\\\.\");\n\t\tif (parts.length > 2) {\n\t\t\tparts = new String[] { parts[0], parts[1] };\n\t\t}\n\t\tString[] subParts = parts[1].split(\"-\");\n\t\treturn Optional.of(Float.parseFloat(subParts[0]));\n\t} catch (Exception e) {\n\t\treturn Optional.empty();\n\t}\n}", "CodeBleu_score": 65.16433796446127}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t  return accessService.validate(\n      AccessContext.of(\n          clusterName,\n          connectName,\n          Set.of(ConnectAction.CREATE_CONNECTOR)\n      ),\n      exchange\n  )\n      .flatMap(\n          access -> kafkaConnectService.createConnector(clusterName, connectName, connector)\n      )\n      .doOnNext(\n          connectorDTO -> auditService.createAudit(\n              access,\n              AuditSignal.of(AuditContext.CONNECTOR, AuditType.CREATE, connectorDTO.getName())\n          )\n      )\n      .map(ResponseEntity::ok);\n}", "CodeBleu_score": 30.269265949177797}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return Mono.zip(\n        accessService.validateAction(\n            AccessContext.builder()\n                .resourceType(KafkaConnectApi.RESOURCE_TYPE)\n                .resourceName(connectName)\n                .action(ConnectAction.CREATE_CONNECTOR)\n                .additionalParams(Map.of(\"cluster\", clusterName))\n                .build(),\n            exchange\n        ),\n        connector\n    ).map(tuple -> {\n        var context = tuple.getT1();\n        var newConnector = tuple.getT2();\n        var connectorDTO = kafkaConnectService.createConnector(clusterName, connectName, newConnector);\n        auditService.audit(context, \"createConnector\", newConnector);\n        return connectorDTO;\n    }).map(ResponseEntity::ok);\n}", "CodeBleu_score": 39.216663067560745}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    AccessContext context = new AccessContext(clusterName, connectName, CREATE_CONNECTOR, connector);\n    return accessService.validate(context)\n        .flatMap(access -> kafkaConnectService.createConnector(clusterName, connectName, connector))\n        .map(ResponseEntity::ok)\n        .onErrorMap(KafkaConnectService.ConnectorAlreadyExistsException.class,\n            e -> new KafkaConnectService.ConnectorAlreadyExistsException(e.getConnectorName()))\n        .doOnNext(response -> auditService.createAudit(context, exchange, CREATE_CONNECTOR, response));\n}", "CodeBleu_score": 33.369406448893336}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t  AccessContext accessContext = AccessContext.builder()\n      .clusterName(clusterName)\n      .connectName(connectName)\n      .connectorName(connectorName)\n      .action(ConnectAction.DELETE)\n      .build();\n  return rbacService.validate(exchange, accessContext)\n      .flatMap(aclContext -> kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n      .map(ResponseEntity::ok)\n      .onErrorResume(e -> Mono.just(ResponseEntity.status(e.getHttpStatus()).build()));\n}", "CodeBleu_score": 47.505454217129596}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    return Mono.just(AccessContext.builder()\n            .withClusterName(clusterName)\n            .withConnectName(connectName)\n            .withRequiredActions(Set.of(ConnectAction.DELETE_CONNECTOR))\n            .build())\n            .flatMap(accessControlService::validate)\n            .flatMap(ac -> kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n            .map(ResponseEntity::ok)\n            .onErrorResume(e -> Mono.just(ResponseEntity.status(e.getStatus()).build()))\n            .doOnNext(e -> auditService.report(exchange,\n                    KafkaConnectApi.DELETE_CONNECTOR,\n                    Map.of(\"clusterName\", clusterName,\n                            \"connectName\", connectName,\n                            \"connectorName\", connectorName),\n                    e.getStatusCode()));\n}", "CodeBleu_score": 29.66354818651991}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    return Mono.defer(() -> {\n        AccessContext accessContext = new AccessContext(exchange);\n        accessContext.setClusterName(clusterName);\n        accessContext.setConnectName(connectName);\n        accessContext.setConnectorName(connectorName);\n        accessContext.setActions(Set.of(ConnectAction.DELETE_CONNECTOR));\n        return accessService.validate(accessContext)\n            .flatMap(acl -> kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n            .map(ResponseEntity::ok)\n            .doOnError(e -> log.error(\"Failed to delete connector {}\", connectorName, e));\n    });\n}", "CodeBleu_score": 28.864747718294957}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return Mono.just(clusterName)\n        .map(cluster -> new AccessContext.Builder(cluster, exchange)\n            .withOperationName(\"updateConnectorState\")\n            .withAction(ConnectAction.UPDATE)\n            .withParams(Map.of(\"connectName\", connectName, \"connectorName\", connectorName, \"action\", action))\n            .build())\n        .flatMap(accessContext -> accessService.isAllowed(accessContext)\n            .flatMap(isAllowed -> {\n                if (isAllowed) {\n                    return kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action);\n                } else {\n                    return Mono.error(new ClusterNotFoundException(clusterName));\n                }\n            }))\n        .doOnNext(signal -> auditService.createAudit(accessContext, signal));\n}", "CodeBleu_score": 30.254459365621837}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t  var connect = getConnect(clusterName, connectName);\n  var context = AccessContext.builder()\n      .clusterName(clusterName)\n      .connectName(connectName)\n      .connect(connect)\n      .action(action.getAction())\n      .operationName(action.getOperationName())\n      .params(Map.of(\"connectorName\", connectorName))\n      .build();\n  return checkAccess(context)\n      .flatMap(ignored -> kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action))\n      .doOnNext(ignored -> audit(context, exchange))\n      .map(ResponseEntity::ok)\n      .onErrorResume(e -> Mono.just(ResponseEntity.badRequest().build()));\n}", "CodeBleu_score": 48.40942143156841}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t  AccessContext context = AccessContext.builder()\n      .clusterName(clusterName)\n      .connectName(connectName)\n      .connectActions(Set.of(ConnectAction.UPDATE_CONNECTOR_STATE))\n      .operationName(\"updateConnectorState\")\n      .params(Map.of(\"connectorName\", connectorName, \"action\", action))\n      .build();\n  return accessControlService.validate(context, exchange)\n      .then(Mono.fromCallable(() -> kafkaConnectService.updateConnectorState(clusterName, connectName, connectorName, action)))\n      .doOnSuccess(v -> auditService.audit(context, exchange))\n      .onErrorResume(e -> Mono.fromCallable(() -> {\n        auditService.audit(context, exchange, e);\n        throw e;\n      }));\n}", "CodeBleu_score": 45.546996904293316}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    @Valid Mono<NewConnectorDTO> connectorDTO,\n    ServerWebExchange exchange\n}", "CodeBleu_score": 14.177348221209716}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    @Valid NewConnectorDTO connector,\n    ServerWebExchange exchange\n}", "CodeBleu_score": 13.788109868470649}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    String clusterName,\n    String connectName,\n    String connectorName,\n    @Valid ConnectorPluginDTO connectorPluginDTO\n}", "CodeBleu_score": 30.07835003066267}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigOperations());\n    return builder.run(args);\n}", "CodeBleu_score": 44.59179617110393}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    var app = new SpringApplicationBuilder(KafkaUiApplication.class)\n        .initializers(new DynamicConfigInitializer())\n        .build(args);\n    return app.run(args);\n}", "CodeBleu_score": 47.49822987283681}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigInitializer());\n    return builder.run(args);\n}", "CodeBleu_score": 44.80461734176172}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t  if (search == null) {\n    return (connector) -> true;\n  }\n  return (connector) -> {\n    String connectorName = connector.getName();\n    String connectorClass = connector.getConnectorClass();\n    String connectorState = connector.getState();\n    String connectorType = connector.getType();\n    String connectorTopic = connector.getTopic();\n    return StringUtils.containsIgnoreCase(connectorName, search) ||\n        StringUtils.containsIgnoreCase(connectorClass, search) ||\n        StringUtils.containsIgnoreCase(connectorState, search) ||\n        StringUtils.containsIgnoreCase(connectorType, search) ||\n        StringUtils.containsIgnoreCase(connectorTopic, search);\n  };\n}", "CodeBleu_score": 52.754379350510085}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t  if (search == null) {\n    return (connector) -> true;\n  }\n  return (connector) -> {\n    String connectorName = connector.getName();\n    String connectorClass = connector.getConfig().get(\"connector.class\");\n    String connectorTopics = connector.getTopics().get(0);\n    return StringUtils.containsIgnoreCase(connectorName, search)\n        || StringUtils.containsIgnoreCase(connectorClass, search)\n        || StringUtils.containsIgnoreCase(connectorTopics, search);\n  };\n}", "CodeBleu_score": 54.99495734297132}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t  if (search == null) {\n    return x -> true;\n  }\n  return connector -> Stream.of(\n      connector.getName(),\n      connector.getConnector().getClass(),\n      connector.getConnector().getState(),\n      connector.getConnector().getWorkerId(),\n      connector.getConnector().getConnector().get(\"name\"),\n      connector.getConnector().getConnector().get(\"connector.class\"),\n      connector.getConnector().getConnector().get(\"state\"),\n      connector.getConnector().getConnector().get(\"worker_id\")\n  ).anyMatch(s -> StringUtils.containsIgnoreCase(s, search));\n}", "CodeBleu_score": 54.82954848151338}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> result = new HashMap<>();\n    if (propertiesMap == null) {\n      return result;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = StringUtils.isEmpty(prefix) ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        result.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        result.put(newKey, value);\n      }\n    }\n    return result;\n  }", "CodeBleu_score": 51.86272932719112}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return null;\n    }\n    Map<String, Object> flattened = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newPrefix = prefix == null ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newPrefix, (Map<String, Object>) value));\n      } else {\n        flattened.put(newPrefix, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 55.932012055057925}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    if (propertiesMap == null) {\n      return new HashMap<>();\n    }\n    Map<String, Object> flattenedMap = new HashMap<>();\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix == null ? key : prefix + \".\" + key;\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(newKey, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(newKey, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 52.88416924797221}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    final ConfigDef configDef = new ConfigDef();\n    configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SSL key password\");\n    configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SSL keystore password\");\n    configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SSL truststore password\");\n    configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SSL key password\");\n    configDef.define(SaslConfigs.SASL_JAAS_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SASL JAAS config\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_KINIT_CMD, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SASL Kerberos kinit command\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_KEYTAB, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SASL Kerberos keytab\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_SERVICE_NAME, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SASL Kerberos service name\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_PRINCIPAL_FROM_KEYTAB, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"SASL Kerberos principal from keytab\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_PRINCIPAL, ConfigDef.Type.PASSWORD", "CodeBleu_score": 47.70584915121977}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t   final ConfigDef configDef = new ConfigDef();\n   configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, \"SSL key password\");\n   configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, \"SSL keystore password\");\n   configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, \"SSL truststore password\");\n   configDef.define(SaslConfigs.SASL_JAAS_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, \"SASL JAAS config\");\n   configDef.define(SaslConfigs.SASL_KERBEROS_KINIT_CMD, ConfigDef.Type.PASSWORD, ConfigDef.Importance.HIGH, \"SASL Kerberos kinit command\");\n   configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR, ConfigDef.Type.DOUBLE, ConfigDef.Importance.HIGH, \"SASL Kerberos ticket renew window factor\");\n   configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_JITTER, ConfigDef.Type.DOUBLE, ConfigDef.Importance.HIGH, \"SASL Kerberos ticket renew jitter\");\n   configDef.define(SaslConfigs.SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN, ConfigDef.Type.LONG, ConfigDef.Importance.HIGH, \"SASL Kerberos min time before relogin\");\n   configDef.define(SaslConfigs.SASL_KERBEROS_PRINCIPAL_TO_LOCAL_RULES, ConfigDef.Type.LIST, ConfigDef.Importance.", "CodeBleu_score": 47.86157724377099}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    final ConfigDef configDef = new ConfigDef();\n    configDef.define(SslConfigs.SSL_KEY_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SslConfigs.SSL_KEYSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SslConfigs.SSL_TRUSTSTORE_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_JAAS_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_PASSWORD_CONFIG, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_KINIT_CMD, ConfigDef.Type.PASSWORD, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_WINDOW_FACTOR_CONFIG, ConfigDef.Type.DOUBLE, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_TICKET_RENEW_JITTER_CONFIG, ConfigDef.Type.DOUBLE, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_KERBEROS_MIN_TIME_BEFORE_RELOGIN, ConfigDef.Type.LONG, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(SaslConfigs.SASL_LOGIN_CALLBACK_HANDLER_CLASS, ConfigDef.Type.CLASS, ConfigDef.Importance.MEDIUM, \"\");\n    configDef.define(Sas", "CodeBleu_score": 47.84663336748721}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return adminClient.describeAcls()\n        .map(Map::keySet)\n        .map(Set::stream)\n        .map(stream -> stream.map(acl -> acl.operation()))\n        .map(stream -> stream.collect(ArrayList::new, ArrayList::add, ArrayList::addAll))\n        .map(operations -> operations.contains(AclOperation.ALTER) || operations.contains(AclOperation.ALL))\n        .filter(allowed -> allowed)\n        .flatMap(allowed -> adminClient.describeCluster()\n            .map(ClusterDescription::isAclEnabled)\n            .filter(enabled -> enabled)\n            .map(enabled -> ClusterFeature.KAFKA_ACL_EDIT))\n        .switchIfEmpty(Mono.empty());\n}", "CodeBleu_score": 32.0012842617519}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    List<AclOperation> authorizedOperations = clusterDescription.getAuthorizedOperations();\n    boolean aclViewEnabled = clusterDescription.isAclViewEnabled();\n    boolean hasAllPermissions = authorizedOperations.contains(AclOperation.ALL);\n    boolean hasAlterPermissions = authorizedOperations.contains(AclOperation.ALTER);\n    boolean hasDescribePermissions = authorizedOperations.contains(AclOperation.DESCRIBE);\n    boolean hasClusterPermissions = authorizedOperations.contains(AclOperation.CLUSTER);\n    boolean hasDescribeConfigPermissions = authorizedOperations.contains(AclOperation.DESCRIBE_CONFIGS);\n    boolean hasCreatePermissions = authorizedOperations.contains(AclOperation.CREATE);\n    boolean hasDeletePermissions = authorizedOperations.contains(AclOperation.DELETE);\n    boolean hasAlterConfigPermissions = authorizedOperations.contains(AclOperation.ALTER_CONFIGS);\n    boolean hasDescribeAclsPermissions = authorizedOperations.contains(AclOperation.DESCRIBE_ACLS);\n    boolean hasAllAclsPermissions = authorizedOperations.contains(AclOperation.ALL_ACLS);\n    boolean hasAlterAclsPermissions = authorizedOperations.contains(AclOperation.ALTER_ACLS);\n\n    if (aclViewEnabled && hasAllPermissions) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n    }\n    if (aclViewEnabled && hasAlterPermissions) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n    }\n    if (aclViewEnabled && hasDescribePermissions) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n    }\n    if (aclViewEnabled && hasClusterPermissions) {\n        return Mono.just(ClusterFeature.KAFKA_ACL_EDIT);\n    }\n    if (aclViewEnabled && hasDescribeConfigPermissions) {\n        return Mono.just(ClusterFeature.KAFK", "CodeBleu_score": 34.21044696671225}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return Mono.just(adminClient)\n        .flatMap(ac -> ac.describeAcls())\n        .map(Map::values)\n        .map(Set::stream)\n        .flatMap(stream -> stream.findFirst())\n        .map(acl -> {\n            if (acl.getPermissions().contains(AclOperation.ALTER)\n                && acl.getPermissions().contains(AclOperation.ALL)\n                && clusterDescription.getFeatures().contains(ClusterFeature.ACL_VIEW)) {\n                return ClusterFeature.KAFKA_ACL_EDIT;\n            } else {\n                return null;\n            }\n        })\n        .filter(Predicate.notNull());\n}", "CodeBleu_score": 26.988367678983288}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    var nextRange = new TreeMap<TopicPartition, FromToOffset>();\n    var offsets = new TreeMap<TopicPartition, Long>();\n    var partitions = new TreeMap<TopicPartition, Long>();\n\n    // initialize offsets\n    for (var entry : prevRange.entrySet()) {\n        var topicPartition = entry.getKey();\n        var fromToOffset = entry.getValue();\n        var from = fromToOffset.getFrom();\n        var to = fromToOffset.getTo();\n        if (from != null && to != null) {\n            offsets.put(topicPartition, from);\n            partitions.put(topicPartition, to - from);\n        } else {\n            offsets.put(topicPartition, null);\n            partitions.put(topicPartition, null);\n        }\n    }\n\n    // apply seek operations\n    for (var seekOperation : seekOperations.getSeekOperations()) {\n        var topicPartition = seekOperation.getTopicPartition();\n        var seekTo = seekOperation.getSeekTo();\n        if (seekTo != null) {\n            offsets.put(topicPartition, seekTo);\n            partitions.put(topicPartition, null);\n        }\n    }\n\n    // calculate the number of messages to poll per partition\n    var messagesPerPartition = this.messagesPerRequest.get();\n    var messagesPerPartitionOrDefault = messagesPerPartition == null ? DEFAULT_MESSAGES_PER_REQUEST : messagesPerPartition;\n    var messagesPerPartitionOrDefaultLong = (long) messagesPerPartitionOrDefault;\n    var messagesPerPartitionOrDefaultDouble = (double) messagesPerPartitionOrDefault;\n    var messagesPerPartitionOrDefaultDoublePlusOne = messagesPerPartitionOrDefaultDouble + 1;\n\n    // for each topic partition, determine the start offset and adjust it based on the number of messages to poll, ensuring it does not go below the beginning offset\n    for (var entry : offsets.entrySet()) {\n        var topicPartition = entry.getKey();\n        var offset = entry.getValue();\n        var partition = partitions.get(topicPartition);\n        var partitionOrDefault =", "CodeBleu_score": 29.082279736948102}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t  var result = new TreeMap<TopicPartition, FromToOffset>(Comparator.comparing(TopicPartition::topic)\n                                                                   .thenComparing(TopicPartition::partition));\n  var offsetsToRead = new TreeMap<TopicPartition, Long>(Comparator.comparing(TopicPartition::topic)\n                                                                  .thenComparing(TopicPartition::partition));\n  var seekOffsets = new TreeMap<TopicPartition, Long>(Comparator.comparing(TopicPartition::topic)\n                                                                 .thenComparing(TopicPartition::partition));\n\n  // Initialize offsets to read from based on the previous range or the offsets from seek operations if the previous range is empty\n  if (prevRange.isEmpty()) {\n    offsetsToRead.putAll(seekOperations.getSeekOffsets());\n  } else {\n    offsetsToRead.putAll(prevRange.entrySet().stream()\n                                  .collect(Collectors.toMap(Map.Entry::getKey,\n                                                            entry -> entry.getValue().getToOffset() + 1)));\n  }\n\n  var maxPollRecords = config.getMaxPollRecords();\n  var maxPollRecordsPerPartition = config.getMaxPollRecordsPerPartition();\n\n  // For each topic partition, it determines the start offset and adjusts it based on the number of messages to poll, ensuring it does not go below the beginning offset\n  for (var entry : offsetsToRead.entrySet()) {\n    var topicPartition = entry.getKey();\n    var offset = entry.getValue();\n    var topic = topicPartition.topic();\n    var partition = topicPartition.partition();\n    var endOffset = consumer.endOffsets(Set.of(topicPartition)).get(topicPartition);\n    var beginningOffset = consumer.beginningOffsets(Set.of(topicPartition)).get(topicPartition);\n    var messagesToPoll = Math.min(maxPollRecords, maxPollRecordsPerPartition);\n    var startOffset = Math.max(offset, beginningOffset);\n", "CodeBleu_score": 37.551036891516645}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    var pollingRange = new TreeMap<TopicPartition, FromToOffset>();\n    var seekOffsetMap = seekOperations.getSeekOffsets();\n    var seekPartitions = seekOffsetMap.keySet();\n\n    for (var partition : prevRange.keySet()) {\n        var prevRangeForPartition = prevRange.get(partition);\n        var seekOffsetForPartition = seekOffsetMap.get(partition);\n\n        var startOffset = prevRangeForPartition.getToOffset();\n        if (startOffset == null) {\n            startOffset = seekOffsetForPartition;\n        }\n\n        var endOffset = consumerPositionSupplier.get().get(partition).getOffset();\n        var count = Math.min(endOffset - startOffset, maxMessagesPerPartition);\n\n        var fromOffset = startOffset;\n        var toOffset = startOffset + count;\n        if (toOffset > endOffset) {\n            toOffset = endOffset;\n            fromOffset = endOffset - count;\n        }\n\n        pollingRange.put(partition, new FromToOffset(fromOffset, toOffset));\n    }\n\n    for (var partition : seekPartitions) {\n        if (!prevRange.containsKey(partition)) {\n            var startOffset = seekOffsetMap.get(partition);\n            var endOffset = consumerPositionSupplier.get().get(partition).getOffset();\n            var count = Math.min(endOffset - startOffset, maxMessagesPerPartition);\n\n            var fromOffset = startOffset;\n            var toOffset = startOffset + count;\n            if (toOffset > endOffset) {\n                toOffset = endOffset;\n                fromOffset = endOffset - count;\n            }\n\n            pollingRange.put(partition, new FromToOffset(fromOffset, toOffset));\n        }\n    }\n\n    return pollingRange;\n}", "CodeBleu_score": 29.17352178929536}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t    if (legacyMode) {\n        validateLegacyConfiguration();\n\n        if (legacyMode) {\n            final ZooKeeperBasedInputLauncher launcher = new ZooKeeperBasedInputLauncher(input, kafkaZookeeperConnect, topic, groupId, legacyMode, legacyZookeeperConnect, legacyZookeeperPath, legacyZookeeperChroot, legacyZookeeperSessionTimeout, legacyZookeeperConnectionTimeout, legacyZookeeperSyncTime, legacyZookeeperRetryAttempts, legacyZookeeperRetryInterval, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme, legacyZookeeperAuthScheme,", "CodeBleu_score": 22.54420108523099}, {"code": "public void doLaunch(final MessageInput input){\n\t    final String mode = configuration.getString(CONFIG_MODE);\n    if (mode.equals(MODE_LEGACY)) {\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_ZOOKEEPER_CONNECT))) {\n            throw new IllegalArgumentException(\"Zookeeper connection string is missing.\");\n        }\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_GROUP_ID))) {\n            throw new IllegalArgumentException(\"Group ID is missing.\");\n        }\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_TOPICS))) {\n            throw new IllegalArgumentException(\"Topics are missing.\");\n        }\n        launchLegacyInput(input);\n    } else if (mode.equals(MODE_CONSUMER)) {\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_BOOTSTRAP_SERVERS))) {\n            throw new IllegalArgumentException(\"Bootstrap servers are missing.\");\n        }\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_GROUP_ID))) {\n            throw new IllegalArgumentException(\"Group ID is missing.\");\n        }\n        if (Strings.isNullOrEmpty(configuration.getString(CONFIG_TOPICS))) {\n            throw new IllegalArgumentException(\"Topics are missing.\");\n        }\n        launchConsumerInput(input);\n    } else {\n        throw new IllegalArgumentException(\"Invalid mode: \" + mode);\n    }\n}", "CodeBleu_score": 33.82895720916283}, {"code": "public void doLaunch(final MessageInput input){\n\t    final KafkaInput kafkaInput = (KafkaInput) input;\n    final KafkaInput.KafkaInputConfiguration config = kafkaInput.getConfig();\n\n    // Legacy mode\n    if (config.mode == KafkaInput.KafkaInputConfiguration.Mode.LEGACY) {\n        // ZooKeeper mode\n        if (config.zookeeperConnect != null && !config.zookeeperConnect.isEmpty()) {\n            if (!config.zookeeperConnect.startsWith(\"zookeeper:\")) {\n                throw new IllegalArgumentException(\"ZooKeeper connect string must start with \\\"zookeeper:\\\"\");\n            }\n\n            if (config.zookeeperConnect.split(\":\").length < 3) {\n                throw new IllegalArgumentException(\"ZooKeeper connect string must be in the form \\\"zookeeper:hostname:port\\\"\");\n            }\n\n            if (config.zookeeperConnect.split(\":\").length > 3) {\n                throw new IllegalArgumentException(\"ZooKeeper connect string must be in the form \\\"zookeeper:hostname:port\\\"\");\n            }\n        }\n\n        // Bootstrap mode\n        if (config.bootstrapServers != null && !config.bootstrapServers.isEmpty()) {\n            if (!config.bootstrapServers.startsWith(\"broker:\")) {\n                throw new IllegalArgumentException(\"Bootstrap servers must start with \\\"broker:\\\"\");\n            }\n\n            if (config.bootstrapServers.split(\":\").length < 3) {\n                throw new IllegalArgumentException(\"Bootstrap servers must be in the form \\\"broker:hostname:port\\\"\");\n            }\n\n            if (config.bootstrapServers.split(\":\").length > 3) {\n                throw new IllegalArgumentException(\"Bootstrap servers must be in the form \\\"broker:hostname:port\\\"\");\n            }\n        }\n    }\n\n    // Consumer mode\n    if (config.mode == KafkaInput.KafkaInputConfiguration.Mode.CONSUMER) {\n        // Check if at least one topic is configured\n        if (config.topics.isEmpty()) {\n            throw new IllegalArgumentException(\"No topics configured\");\n        }\n", "CodeBleu_score": 32.36845011591196}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String customPropertiesString = getConfiguration().getString(KafkaInput.CONFIG_CUSTOM_PROPERTIES);\n        if (!Strings.isNullOrEmpty(customPropertiesString)) {\n            Properties customProperties = new Properties();\n            customProperties.load(new ByteArrayInputStream(customPropertiesString.getBytes(StandardCharsets.UTF_8)));\n            props.putAll(customProperties);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Unable to load custom properties\", e);\n    }\n}", "CodeBleu_score": 57.009693254868225}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        Properties customProperties = new Properties();\n        customProperties.load(new ByteArrayInputStream(getConfiguration().getString(CUSTOM_PROPERTIES_CONFIG).getBytes(StandardCharsets.UTF_8)));\n        props.putAll(customProperties);\n    } catch (IOException e) {\n        LOG.error(\"Failed to load custom properties: {}\", e.getMessage());\n    }\n}", "CodeBleu_score": 51.31891560936923}, {"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        String customPropertiesString = configuration.getString(CUSTOM_PROPERTIES);\n        if (!Strings.isNullOrEmpty(customPropertiesString)) {\n            Properties customProperties = new Properties();\n            customProperties.load(new ByteArrayInputStream(customPropertiesString.getBytes(StandardCharsets.UTF_8)));\n            props.putAll(customProperties);\n        }\n    } catch (IOException e) {\n        LOG.error(\"Could not load custom properties from configuration.\", e);\n    }\n}", "CodeBleu_score": 52.0865914321234}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t  if (entries == null || entries.isEmpty()) {\n    return;\n  }\n\n  final List<Journal.Entry> journalEntries = entries.stream()\n      .filter(Objects::nonNull)\n      .map(this::mapToJournalEntry)\n      .collect(Collectors.toList());\n\n  final AtomicLong totalBytes = new AtomicLong();\n  journalEntries.forEach(entry -> totalBytes.addAndGet(entry.getPayload().length));\n\n  final Retryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n      .retryIfResult(result -> !result)\n      .withWaitStrategy(WaitStrategies.exponentialWait(100, 2000, TimeUnit.MILLISECONDS))\n      .withStopStrategy(StopStrategies.stopAfterAttempt(5))\n      .build();\n\n  try {\n    retryer.call(() -> {\n      try {\n        journal.write(journalEntries);\n        return true;\n      } catch (Exception e) {\n        LOG.error(\"Failed to write to journal. Retrying...\", e);\n        return false;\n      }\n    });\n  } catch (ExecutionException | RetryException e) {\n    throw new MessageQueueException(\"Failed to write to journal.\", e);\n  }\n\n  messagesWritten.mark(journalEntries.size());\n  bytesWritten.mark(totalBytes.get());\n}", "CodeBleu_score": 58.60721878641784}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t  if (entries == null || entries.isEmpty()) {\n    return;\n  }\n\n  final List<Journal.Entry> journalEntries = entries.stream().filter(Objects::nonNull).map(this::mapToJournalEntry).collect(Collectors.toList());\n  final long totalMessageBytes = journalEntries.stream().mapToLong(Journal.Entry::getTotalMessageBytes).sum();\n  final long totalMessages = journalEntries.size();\n\n  try {\n    retryer.call(() -> {\n      journal.write(journalEntries);\n      return null;\n    });\n  } catch (ExecutionException | RetryException e) {\n    throw new MessageQueueException(\"Failed to write messages to journal.\", e);\n  }\n\n  this.messagesWritten.addAndGet(totalMessages);\n  this.messageBytesWritten.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 47.158737612626766}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    final long start = System.nanoTime();\n    final List<RawMessageEvent> filtered = entries.stream().filter(Objects::nonNull).collect(Collectors.toList());\n    final List<Journal.Entry> journalEntries = filtered.stream().map(RawMessageEvent::toJournalEntry).collect(Collectors.toList());\n    final long totalBytes = filtered.stream().mapToLong(RawMessageEvent::getTotalBytes).sum();\n    final AtomicLong writtenBytes = new AtomicLong();\n\n    final Retryer<Boolean> retryer = RetryerBuilder.<Boolean>newBuilder()\n            .retryIfResult(result -> !result)\n            .withWaitStrategy(WaitStrategies.exponentialWait(500, 10000, TimeUnit.MILLISECONDS))\n            .withStopStrategy(StopStrategies.stopAfterAttempt(10))\n            .build();\n\n    try {\n        retryer.call(() -> {\n            final long bytesWritten = journal.write(journalEntries);\n            writtenBytes.addAndGet(bytesWritten);\n            return bytesWritten == totalBytes;\n        });\n    } catch (ExecutionException | RetryException e) {\n        throw new MessageQueueException(\"Failed to write messages to journal\", e);\n    }\n\n    final long end = System.nanoTime();\n    final long duration = TimeUnit.NANOSECONDS.toMicros(end - start);\n    final long writtenMessages = filtered.size();\n    final long writtenBytesCount = writtenBytes.get();\n\n    messagesWritten.mark(writtenMessages);\n    bytesWritten.mark(writtenBytesCount);\n    writeDuration.update(duration);\n    logger.debug(\"Wrote {} messages ({} bytes) to journal in {} ms\", writtenMessages, writtenBytesCount, duration);\n}", "CodeBleu_score": 49.22099735988855}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t    final Optional<Long> maxMessageQueueId = messages.stream()\n            .map(Message::getMessageQueueId)\n            .filter(messageQueueId -> messageQueueId != null)\n            .max(Long::compareTo);\n\n    maxMessageQueueId.ifPresent(messageQueueId -> {\n        messageQueueAcknowledger.acknowledge(messageQueueId);\n        metrics.markAcknowledged(messages.size());\n    });\n}", "CodeBleu_score": 46.57640107080328}, {"code": "public void acknowledge(List<Message> messages){\n\t    final Optional<Long> maxMessageQueueId = messages.stream().map(Message::getMessageQueueId).max(Long::compareTo);\n    maxMessageQueueId.ifPresent(messageQueueAcknowledger::acknowledge);\n    messages.forEach(message -> {\n        if (message.getMessageQueueId() != null) {\n            metrics.messagesAcknowledged();\n        }\n    });\n}", "CodeBleu_score": 38.58927473711502}, {"code": "public void acknowledge(List<Message> messages){\n\t    final Optional<Long> maxMessageQueueId = messages.stream().map(Message::getMessageQueueId).max(Long::compareTo);\n    final long maxMessageQueueIdToAcknowledge = maxMessageQueueId.orElse(0L);\n    if (maxMessageQueueIdToAcknowledge > 0) {\n        messageQueueAcknowledger.acknowledge(maxMessageQueueIdToAcknowledge);\n        messagesAcknowledged.mark(messages.size());\n    }\n}", "CodeBleu_score": 41.94777642472187}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    for (Map.Entry<String, com.codahale.metrics.Metric> entry : metricRegistry.getMetrics().entrySet()) {\n        if (entry.getKey().startsWith(LocalKafkaJournal.class.getName())) {\n            String legacyName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"kafka.journal\");\n            try {\n                metricRegistry.register(legacyName, entry.getValue());\n            } catch (IllegalArgumentException e) {\n                LOG.warn(\"Failed to register legacy metric {}: {}\", legacyName, e.getMessage());\n            }\n        }\n    }\n}", "CodeBleu_score": 43.81666061669525}, {"code": "private void registerLegacyMetrics(){\n\t    final MetricFilter filter = new MetricFilter() {\n        @Override\n        public boolean matches(String name, Metric metric) {\n            return name.startsWith(\"org.graylog.plugins.kafka.journal.LocalKafkaJournal\");\n        }\n    };\n\n    final Map<String, Metric> legacyMetrics = metricRegistry.getMetrics(filter);\n    for (Map.Entry<String, Metric> entry : legacyMetrics.entrySet()) {\n        final String legacyMetricName = entry.getKey();\n        final Metric metric = entry.getValue();\n\n        final String[] parts = legacyMetricName.split(\"\\\\.\");\n        final String newMetricName = name(parts[0], parts[1], parts[2], parts[3], parts[4], parts[5]);\n        try {\n            metricRegistry.register(newMetricName, metric);\n        } catch (IllegalArgumentException e) {\n            LOG.warn(\"Failed to register legacy metric '{}' as '{}'.\", legacyMetricName, newMetricName, e);\n        }\n    }\n}", "CodeBleu_score": 34.60331579220184}, {"code": "private void registerLegacyMetrics(){\n\t    final MetricRegistry registry = metricRegistry;\n    final MetricFilter filter = new MetricFilter() {\n        @Override\n        public boolean matches(String name, Metric metric) {\n            return name.startsWith(LocalKafkaJournal.class.getName());\n        }\n    };\n    final Set<String> legacyMetricNames = Sets.newHashSet(\n            \"kafka.log.Log.LogCleaner.cleanableRatio\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferUtilization\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferWaitTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoWaitTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoWriteTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoReadTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferSize\",\n            \"kafka.log.Log.LogCleaner.cleanerIoMaxBufferSize\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadTimeMs\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoads\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsFailed\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsAwaited\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsRetries\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsRetriesFailed\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsRetriesAwaited\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsRetriesTimedOut\",\n            \"kafka.log.Log.LogCleaner.cleanerIoBufferLoadsTimedOut\",\n            \"kafka.log", "CodeBleu_score": 29.45389610223129}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t  try {\n    metricRegistry.register(name, (Gauge<Integer>) () -> {\n      int uncommitted = 0;\n      Iterable<Log> logs = logManager.allLogs();\n      for (Log log : logs) {\n        if (log.config().maxSegmentBytes() != 0) {\n          uncommitted += log.numberOfUncommittedMessages();\n        }\n      }\n      return uncommitted;\n    });\n  } catch (IllegalArgumentException e) {\n    // Ignore\n  }\n}", "CodeBleu_score": 37.72756464463899}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t  try {\n    metricRegistry.register(name, (Gauge<Integer>) () -> {\n      final Option<Log> logOption = logManager.getLog(topicPartition);\n      if (logOption.isEmpty()) {\n        return 0;\n      }\n      final Log log = logOption.get();\n      final long logEndOffset = log.logEndOffset();\n      final long logStartOffset = log.logStartOffset();\n      final long committedOffset = log.getLastOffset();\n      if (committedOffset == Log.UNDEFINED_OFFSET) {\n        return Ints.saturatedCast(logEndOffset - logStartOffset);\n      }\n      return Ints.saturatedCast(logEndOffset - committedOffset);\n    });\n  } catch (IllegalArgumentException ignored) {\n  }\n}", "CodeBleu_score": 46.16704970571082}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.register(name, new Gauge<Long>() {\n            @Override\n            public Long getValue() {\n                long uncommitted = 0;\n                Log log = logManager.getLog(name);\n                if (log != null) {\n                    long endOffset = log.logEndOffset();\n                    long startOffset = log.logStartOffset();\n                    if (startOffset == 0) {\n                        return 0;\n                    }\n                    if (endOffset == 0) {\n                        return 0;\n                    }\n                    if (committed.get(name) == null) {\n                        uncommitted = endOffset - startOffset;\n                    } else {\n                        uncommitted = endOffset - committed.get(name).get();\n                    }\n                }\n                return uncommitted;\n            }\n        });\n    } catch (IllegalArgumentException e) {\n        // ignore\n    }\n}", "CodeBleu_score": 42.831407852383485}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        logger.debug(\"Attempted to flush empty message list\");\n        return 0;\n    }\n\n    ByteBufferMessageSet byteBufferMessageSet = new ByteBufferMessageSet(JavaConversions.asScalaBuffer(messages));\n    logger.debug(\"Flushing {} messages to log\", messages.size());\n    logger.trace(\"Flushing message set of size {} bytes\", byteBufferMessageSet.sizeInBytes());\n\n    LogAppendInfo appendInfo = log.append(byteBufferMessageSet);\n    long lastOffset = appendInfo.firstOffset.get();\n    logger.debug(\"Write of {} bytes and {} messages to log with first offset {} and last offset {} completed\",\n            byteBufferMessageSet.sizeInBytes(), messages.size(), appendInfo.firstOffset.get(), lastOffset);\n    logger.trace(\"Flushed message set of size {} bytes\", byteBufferMessageSet.sizeInBytes());\n\n    messagesWritten.mark(messages.size());\n    bytesWritten.mark(byteBufferMessageSet.sizeInBytes());\n    payloadSizeMetric.mark(payloadSize);\n    return lastOffset;\n}", "CodeBleu_score": 50.98039003680586}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        logger.debug(\"No messages to flush\");\n        return -1;\n    }\n\n    final ByteBufferMessageSet messageSet = new ByteBufferMessageSet(\n            JavaConversions.asScalaBuffer(messages).toSeq()\n    );\n    logger.debug(\"Flushing {} messages to log {}-{} with payload size {} bytes\",\n            messages.size(), topicPartition.topic, topicPartition.partition, payloadSize);\n    final LogAppendInfo appendInfo = log.append(messageSet);\n    final long lastOffset = appendInfo.firstOffset.get();\n    logger.debug(\"Flushed messages to log {}-{} with last offset {}\",\n            topicPartition.topic, topicPartition.partition, lastOffset);\n    numMessages.addAndGet(messages.size());\n    return lastOffset;\n}", "CodeBleu_score": 57.4891693179736}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        LOG.debug(\"No messages to flush\");\n        return -1;\n    }\n\n    final ByteBufferMessageSet messageSet = new ByteBufferMessageSet(messages);\n    LOG.trace(\"Flushing {} messages with payload size {} bytes\", messages.size(), payloadSize);\n\n    final LogAppendInfo appendInfo = log.append(messageSet);\n    final long lastOffset = appendInfo.firstOffset.get();\n\n    if (appendInfo.firstOffset.isDefined()) {\n        final long firstOffset = appendInfo.firstOffset.get();\n        final long lastOffset = appendInfo.lastOffset.get();\n        final long numMessages = appendInfo.numMessages.get();\n\n        LOG.trace(\"Appended {} messages to log {} with first offset {} and last offset {}.\",\n                numMessages, log.name(), firstOffset, lastOffset);\n\n        numMessagesInBuffer.addAndGet(numMessages);\n        numBytesInBuffer.addAndGet(payloadSize);\n    } else {\n        LOG.trace(\"Appended {} messages to log {} with no offset.\", messages.size(), log.name());\n    }\n\n    return lastOffset;\n}", "CodeBleu_score": 52.03270896836213}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    synchronized (kafkaAdminClientMap) {\n        List<AdminClient> clientList = kafkaAdminClientMap.get(clusterPhyId);\n        if (clientList == null) {\n            return;\n        }\n        LOGGER.info(\"Close kafka admin client, clusterPhyId: {}\", clusterPhyId);\n        for (AdminClient adminClient : clientList) {\n            try {\n                adminClient.close(Duration.ofSeconds(10));\n            } catch (Exception e) {\n                LOGGER.error(\"Close kafka admin client failed, clusterPhyId: {}, error: {}\", clusterPhyId, e);\n            }\n        }\n        kafkaAdminClientMap.remove(clusterPhyId);\n        LOGGER.info(\"Close kafka admin client success, clusterPhyId: {}\", clusterPhyId);\n    }\n}", "CodeBleu_score": 47.393059742338814}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    ILog logger = LogFactory.getLog(getClass());\n    logger.info(\"Start closing Kafka AdminClient for clusterPhyId: \" + clusterPhyId);\n    List<AdminClient> adminClientList = null;\n    synchronized (adminClientMap) {\n        adminClientList = adminClientMap.get(clusterPhyId);\n        if (adminClientList == null) {\n            return;\n        }\n        adminClientMap.remove(clusterPhyId);\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka AdminClient for clusterPhyId: \" + clusterPhyId, e);\n        }\n    }\n    logger.info(\"Successfully closed Kafka AdminClient for clusterPhyId: \" + clusterPhyId);\n}", "CodeBleu_score": 45.863304882890354}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    ILog log = LogFactory.getLog(getClass());\n    List<AdminClient> adminClients = new ArrayList<>();\n    synchronized (clusterPhyIdToAdminClientMap) {\n        if (clusterPhyIdToAdminClientMap.containsKey(clusterPhyId)) {\n            log.info(\"start closing Kafka AdminClient for clusterPhyId: \" + clusterPhyId);\n            adminClients = clusterPhyIdToAdminClientMap.remove(clusterPhyId);\n        } else {\n            log.info(\"no Kafka AdminClient found for clusterPhyId: \" + clusterPhyId);\n            return;\n        }\n    }\n    for (AdminClient adminClient : adminClients) {\n        try {\n            adminClient.close(Duration.ofSeconds(10));\n        } catch (Exception e) {\n            log.error(\"failed to close Kafka AdminClient for clusterPhyId: \" + clusterPhyId, e);\n        }\n    }\n    log.info(\"successfully closed Kafka AdminClient for clusterPhyId: \" + clusterPhyId);\n}", "CodeBleu_score": 42.84266937232347}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\"closeAdminClientList error, clusterPhyId: \" + clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 75.74010376437971}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            success = false;\n            LOGGER.error(\"Close admin client failed, clusterPhyId:{}\", clusterPhyId, e);\n        }\n    }\n    return success;\n}", "CodeBleu_score": 74.9160330960574}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            LOGGER.error(\"[closeAdminClientList] close admin client failed, clusterPhyId: \" + clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 76.32520332723236}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t    if (app != null) {\n        app.stop();\n        int attempts = 5;\n        while (app.isRunning() && attempts > 0) {\n            try {\n                Thread.sleep(1000);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(\"Thread interrupted while waiting for app to stop\");\n            }\n            attempts--;\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 61.65711432271155}, {"code": "public void stop() {\n\t  if (app != null) {\n    app.stop();\n    int attempts = 0;\n    while (app.isRunning()) {\n      try {\n        Thread.sleep(1000);\n      } catch (InterruptedException e) {\n        throw new IllegalStateException(\"Interrupted while waiting for app to stop\");\n      }\n      attempts++;\n      if (attempts > 5) {\n        throw new IllegalStateException(\"App failed to stop after 5 attempts\");\n      }\n    }\n    app = null;\n  }\n}", "CodeBleu_score": 58.198074073376674}, {"code": "public void stop() {\n\t    if (this.app == null) {\n        return;\n    }\n    try {\n        this.app.stop();\n    } catch (Exception e) {\n        throw new IllegalStateException(\"Failed to stop application\", e);\n    }\n    int attempts = 0;\n    while (this.app.isRunning()) {\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            throw new IllegalStateException(\"Interrupted while waiting for app to stop\", e);\n        }\n        attempts++;\n        if (attempts > 5) {\n            throw new IllegalStateException(\"Application did not stop within 5 seconds\");\n        }\n    }\n    this.app = null;\n}", "CodeBleu_score": 36.62975478062337}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner runner = new EurekaServerRunner(config);\n    runner.enableTls();\n    runner.setKeyStore(\"src/test/resources/test.jks\", \"changeit\");\n    runner.setTrustStore(\"src/test/resources/test.jks\", \"changeit\");\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 38.939940253227164}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config);\n    server.enableSelfPreservation();\n    server.setExpectedKeyStore(KEYSTORE_FILE, KEYSTORE_PASSWORD, KEYSTORE_TYPE);\n    server.setExpectedTrustStore(TRUSTSTORE_FILE, TRUSTSTORE_PASSWORD, TRUSTSTORE_TYPE);\n    server.start();\n    return server;\n}", "CodeBleu_score": 56.16192433590083}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config);\n    server.enableTlsWithoutClientAuth();\n    server.setKeyStore(getKeyStore(\"serverStore.jks\", \"eureka\"), \"eureka\");\n    server.setTrustStore(getKeyStore(\"serverStore.jks\", \"eureka\"), \"eureka\");\n    server.start();\n    return server;\n}", "CodeBleu_score": 52.88337182081728}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner runner = new EurekaClientRunner(server.getServiceUrl(), \"testservice\", config);\n    runner.enableTls();\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 45.39316685246973}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner runner = new EurekaClientRunner(\n            config,\n            server.getServiceUrl(),\n            \"testservice\");\n    runner.enableTls(server.getKeyStore(), \"password\");\n    runner.start();\n    return runner;\n}", "CodeBleu_score": 39.838753871817424}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t\tEurekaClientRunner client = new EurekaClientRunner(server.getServiceUrl(), \"testservice\", config);\n\tclient.enableTls(true);\n\tclient.start();\n\treturn client;\n}", "CodeBleu_score": 45.9735231560532}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t    // Create a CA key pair\n    KeyTool caKeyTool = new KeyTool(caKey, caCert);\n    caKeyTool.createKeyPair();\n    saveCert(caCert, caKeyTool.getCertificate());\n    saveKeyAndCert(caKey, caKeyTool.getKeyPair(), caCert);\n\n    // Create a server key pair\n    KeyTool serverKeyTool = new KeyTool(serverKey, serverCert);\n    serverKeyTool.createKeyPair();\n    saveCert(serverCert, serverKeyTool.getCertificate());\n    saveKeyAndCert(serverKey, serverKeyTool.getKeyPair(), serverCert);\n\n    // Create a client key pair\n    KeyTool clientKeyTool = new KeyTool(clientKey, clientCert);\n    clientKeyTool.createKeyPair();\n    saveCert(clientCert, clientKeyTool.getCertificate());\n    saveKeyAndCert(clientKey, clientKeyTool.getKeyPair(), clientCert);\n\n    // Create a second CA key pair\n    KeyTool secondCaKeyTool = new KeyTool(secondCaKey, secondCaCert);\n    secondCaKeyTool.createKeyPair();\n    saveCert(secondCaCert, secondCaKeyTool.getCertificate());\n    saveKeyAndCert(secondCaKey, secondCaKeyTool.getKeyPair(), secondCaCert);\n\n    // Create a second client key pair\n    KeyTool secondClientKeyTool = new KeyTool(secondClientKey, secondClientCert);\n    secondClientKeyTool.createKeyPair();\n    saveCert(secondClientCert, secondClientKeyTool.getCertificate());\n    saveKeyAndCert(secondClientKey, secondClientKeyTool.getKeyPair(), secondClientCert);\n\n    // Create a certificate chain for the server\n    KeyTool serverCertChainTool = new KeyTool(serverCertChain, serverCertChain);\n    serverCertChainTool.createCertificateChain(caKeyTool.getCertificate(), serverKeyTool.getCertificate());\n    saveCert(serverCertChain, serverCertChainTool.getCertificate());\n\n    // Create a certificate chain for the second client\n    KeyTool secondClientCertChainTool = new KeyTool(secondClientCertChain, secondClientCertChain);\n    secondClientCertChainTool.createCert", "CodeBleu_score": 19.956540225982707}, {"code": "static void createCertificates() throws Exception{\n\t    // Create a CA certificate and key\n    caKey = KeyTool.genKey(KEY_ALGORITHM, KEY_SIZE, CA_ALIAS);\n    caCert = KeyTool.genCert(caKey, CA_ALIAS, CA_ALIAS, null, -1, true);\n\n    // Create a server certificate and key\n    serverKey = KeyTool.genKey(KEY_ALGORITHM, KEY_SIZE, SERVER_ALIAS);\n    serverCert = KeyTool.genCert(caKey, SERVER_ALIAS, SERVER_ALIAS, null, -1, false);\n\n    // Create a client certificate and key\n    clientKey = KeyTool.genKey(KEY_ALGORITHM, KEY_SIZE, CLIENT_ALIAS);\n    clientCert = KeyTool.genCert(caKey, CLIENT_ALIAS, CLIENT_ALIAS, null, -1, false);\n\n    // Create a second CA certificate and key\n    caKey2 = KeyTool.genKey(KEY_ALGORITHM, KEY_SIZE, CA2_ALIAS);\n    caCert2 = KeyTool.genCert(caKey2, CA2_ALIAS, CA2_ALIAS, null, -1, true);\n\n    // Create a client certificate and key signed by the second CA\n    clientKey2 = KeyTool.genKey(KEY_ALGORITHM, KEY_SIZE, CLIENT2_ALIAS);\n    clientCert2 = KeyTool.genCert(caKey2, CLIENT2_ALIAS, CLIENT2_ALIAS, null, -1, false);\n\n    // Save the CA certificate and key\n    saveCert(caCert, CA_ALIAS);\n    saveKeyAndCert(caKey, caCert, CA_ALIAS);\n\n    // Save the server certificate and key\n    saveCert(serverCert, SERVER_ALIAS);\n    saveKeyAndCert(serverKey, serverCert, SERVER_ALIAS);\n\n    // Save the client certificate and key\n    saveCert(clientCert, CLIENT_ALIAS);\n    saveKeyAndCert(clientKey, clientCert, CLI", "CodeBleu_score": 23.07377818009772}, {"code": "static void createCertificates() throws Exception{\n\t    // Generate a CA certificate and private key\n    KeyTool caKeyTool = new KeyTool(CA_ALIAS, CA_PASSWORD, CA_KEYSTORE_FILE, CA_KEYSTORE_PASSWORD, CA_KEY_ALIAS, CA_KEY_PASSWORD, CA_DN);\n    caKeyTool.generateKeyPair();\n\n    // Generate a server certificate and private key\n    KeyTool serverKeyTool = new KeyTool(SERVER_ALIAS, SERVER_PASSWORD, SERVER_KEYSTORE_FILE, SERVER_KEYSTORE_PASSWORD, SERVER_KEY_ALIAS, SERVER_KEY_PASSWORD, SERVER_DN);\n    serverKeyTool.generateKeyPair();\n\n    // Generate a client certificate and private key\n    KeyTool clientKeyTool = new KeyTool(CLIENT_ALIAS, CLIENT_PASSWORD, CLIENT_KEYSTORE_FILE, CLIENT_KEYSTORE_PASSWORD, CLIENT_KEY_ALIAS, CLIENT_KEY_PASSWORD, CLIENT_DN);\n    clientKeyTool.generateKeyPair();\n\n    // Generate a second CA certificate and private key\n    KeyTool secondCaKeyTool = new KeyTool(SECOND_CA_ALIAS, SECOND_CA_PASSWORD, SECOND_CA_KEYSTORE_FILE, SECOND_CA_KEYSTORE_PASSWORD, SECOND_CA_KEY_ALIAS, SECOND_CA_KEY_PASSWORD, SECOND_CA_DN);\n    secondCaKeyTool.generateKeyPair();\n\n    // Generate a second client certificate and private key\n    KeyTool secondClientKeyTool = new KeyTool(SECOND_CLIENT_ALIAS, SECOND_CLIENT_PASSWORD, SECOND_CLIENT_KEYSTORE_FILE, SECOND_CLIENT_KEYSTORE_PASSWORD, SECOND_CLIENT_KEY_ALIAS, SECOND_CLIENT_KEY_PASSWORD, SECOND_CLIENT_DN);\n    secondClientKeyTool.generateKeyPair();\n\n    // Save the CA certificate and private key\n    caKeyTool.", "CodeBleu_score": 19.10952991719079}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long startTime = System.currentTimeMillis();\n    long timeLimit = startTime + (seconds * 1000);\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }\n    throw new RuntimeException(\"Assertion not satisfied within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 43.335591315664765}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + (seconds * 1000);\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        try {\n            Thread.sleep(100);\n        } catch (InterruptedException e) {\n            throw new RuntimeException(e);\n        }\n    }\n    throw new RuntimeException(\"Assertion failed in \" + seconds + \" seconds\");\n}", "CodeBleu_score": 41.83710898098315}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long start = System.currentTimeMillis();\n    long end = start + (seconds * 1000);\n    while (System.currentTimeMillis() < end) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n    }\n    throw new RuntimeException(\"Assertion failed within \" + seconds + \" seconds\");\n}", "CodeBleu_score": 50.33852003951752}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a certificate builder with the public key and CA information\n    JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(ca),\n            BigInteger.valueOf(1),\n            new Date(),\n            new Date(new Date().getTime() + 1000 * 60 * 60 * 24 * 365),\n            new X500Name(ca),\n            keyPair.getPublic()\n    );\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyCertSign));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n    // Sign the certificate with the private key and return the signed X509 certificate\n    ContentSigner signer = new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(signer);\n    JcaX509CertificateConverter certConverter = new JcaX509CertificateConverter();\n    return certConverter.getCertificate(certHolder);\n}", "CodeBleu_score": 36.755011826956704}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create the certificate builder\n    JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n            new X500Name(\"CN=CA\"),\n            BigInteger.valueOf(1),\n            new Date(),\n            new Date(new Date().getTime() + 365*24*60*60*1000L),\n            new X500Name(\"CN=CA\"),\n            keyPair.getPublic());\n\n    // Add key usage extension\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.keyCertSign | KeyUsage.cRLSign));\n\n    // Add basic constraints extension\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n    // Sign the certificate\n    ContentSigner signer = new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(signer);\n\n    // Convert to X509 certificate\n    JcaX509CertificateConverter certConverter = new JcaX509CertificateConverter();\n    X509Certificate cert = certConverter.getCertificate(certHolder);\n\n    // Return the certificate\n    return cert;\n}", "CodeBleu_score": 38.68842906934127}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a certificate builder with the public key and CA information\n    JcaX509v3CertificateBuilder certBuilder = new JcaX509v3CertificateBuilder(\n        new X500Name(ca),\n        BigInteger.valueOf(new Date().getTime()),\n        new Date(new Date().getTime() + 1000*60*60*24*365),\n        new X500Name(ca),\n        keyPair.getPublic()\n    );\n\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment | KeyUsage.dataEncipherment | KeyUsage.keyAgreement));\n    certBuilder.addExtension(Extension.basicConstraints, true, new BasicConstraints(true));\n\n    // Sign the certificate with the private key\n    ContentSigner signer = new JcaContentSignerBuilder(\"SHA256WithRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(signer);\n\n    // Return the signed X509 certificate\n    return new JcaX509CertificateConverter().setProvider(\"BC\").getCertificate(certHolder);\n}", "CodeBleu_score": 37.94695167739888}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = ReflectionUtils.findField(DiscoveryClient.class, \"registrationClient\");\n            registrationClientField.setAccessible(true);\n            Object registrationClient = registrationClientField.get(this);\n            Field eurekaTransportField = ReflectionUtils.findField(registrationClient.getClass(), \"eurekaTransport\");\n            eurekaTransportField.setAccessible(true);\n            Object eurekaTransport = eurekaTransportField.get(registrationClient);\n            Field eurekaHttpClientField = ReflectionUtils.findField(eurekaTransport.getClass(), \"eurekaHttpClient\");\n            eurekaHttpClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) eurekaHttpClientField.get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            log.error(\"Error accessing EurekaHttpClient\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 50.97862280949077}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = ReflectionUtils.findField(DiscoveryClient.class, \"registrationClient\");\n            ReflectionUtils.makeAccessible(registrationClientField);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(this);\n        } catch (IllegalAccessException e) {\n            logger.error(\"Could not access registrationClient field\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 48.97095129396188}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient != null) {\n        return eurekaHttpClient;\n    }\n    try {\n        Field registrationClientField = ReflectionUtils.findField(DiscoveryClient.class, \"registrationClient\");\n        registrationClientField.setAccessible(true);\n        Object registrationClient = registrationClientField.get(this);\n        Field eurekaHttpClientField = ReflectionUtils.findField(registrationClient.getClass(), \"eurekaHttpClient\");\n        eurekaHttpClientField.setAccessible(true);\n        eurekaHttpClient = (EurekaHttpClient) eurekaHttpClientField.get(registrationClient);\n        return eurekaHttpClient;\n    } catch (IllegalAccessException e) {\n        logger.error(\"Error getting EurekaHttpClient\", e);\n        return null;\n    }\n}", "CodeBleu_score": 49.458660495032305}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t    Applications applications = eurekaClient.getApplications();\n    if (applications == null || applications.getRegisteredApplications().isEmpty()) {\n        return Collections.emptyList();\n    }\n    List<String> serviceNames = new ArrayList<>();\n    for (Application application : applications.getRegisteredApplications()) {\n        if (application.getInstances().size() > 0) {\n            serviceNames.add(application.getName().toLowerCase());\n        }\n    }\n    return serviceNames;\n}", "CodeBleu_score": 55.322175467432686}, {"code": "public List<String> getServices(){\n\t    Applications applications = eurekaClient.getApplications();\n    if (applications == null || applications.getRegisteredApplications() == null\n        || applications.getRegisteredApplications().isEmpty()) {\n        return Collections.emptyList();\n    }\n    List<String> services = new ArrayList<>();\n    for (Application application : applications.getRegisteredApplications()) {\n        if (!application.getInstances().isEmpty()) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 55.34639167587453}, {"code": "public List<String> getServices(){\n\t\tApplications applications = this.eurekaClient.getApplications();\n\tif (applications == null || applications.getRegisteredApplications().isEmpty()) {\n\t\treturn Collections.emptyList();\n\t}\n\tList<String> services = new ArrayList<String>();\n\tfor (Application app : applications.getRegisteredApplications()) {\n\t\tif (app.getInstances().size() > 0) {\n\t\t\tservices.add(app.getName().toLowerCase());\n\t\t}\n\t}\n\treturn services;\n}", "CodeBleu_score": 65.0417836721117}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t\tfor (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n\t\tif (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n\t\t\tDiscoveryCompositeHealthContributor dchc = (DiscoveryCompositeHealthContributor) entry.getValue();\n\t\t\tfor (HealthContributor contributor : dchc.getContributors()) {\n\t\t\t\tif (!(contributor instanceof EurekaHealthIndicator)) {\n\t\t\t\t\tthis.healthContributors.put(entry.getKey() + \".\" + contributor.getName(), contributor);\n\t\t\t\t}\n\t\t\t}\n\t\t} else {\n\t\t\tthis.healthContributors.put(entry.getKey(), entry.getValue());\n\t\t}\n\t}\n}", "CodeBleu_score": 50.782326177797835}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (HealthContributor contributor : compositeHealthContributor.getContributors()) {\n                if (!(contributor instanceof EurekaHealthIndicator)) {\n                    this.healthContributors.put(entry.getKey(), contributor);\n                }\n            }\n        }\n        else {\n            this.healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 49.69553975278263}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    for (Map.Entry<String, HealthContributor> entry : healthContributors.entrySet()) {\n        if (entry.getValue() instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor compositeHealthContributor = (DiscoveryCompositeHealthContributor) entry.getValue();\n            for (HealthContributor healthContributor : compositeHealthContributor.getContributors()) {\n                if (!(healthContributor instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(entry.getKey() + \".\" + healthContributor.getName(), healthContributor);\n                }\n            }\n        }\n        else {\n            healthContributors.put(entry.getKey(), entry.getValue());\n        }\n    }\n}", "CodeBleu_score": 43.7888300375799}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances of provider-application found\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n}", "CodeBleu_score": 49.06188741348873}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No provider-application instances found.\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    RestTemplate restTemplate = new RestTemplate();\n    return restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n}", "CodeBleu_score": 51.05618996951702}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances found of provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri + \"/echo\", \"Hello\", String.class);\n}", "CodeBleu_score": 48.612745940132776}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No service instance found for provider-application\");\n    }\n    URI uri = URI.create(String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort()));\n    return restTemplate.postForObject(uri, \"Hello\", String.class);\n}", "CodeBleu_score": 60.051431927223256}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancerClient.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No instance available for provider-application\");\n    }\n    URI uri = URI.create(String.format(\"http://%s:%s/echo\", instance.getHost(), instance.getPort()));\n    return restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 56.0337347500536}, {"code": "public String world(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No service instance found\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = lbClient.reconstructURI(instance, \"/echo\");\n    return restTemplate.postForObject(uri, \"World\", String.class);\n}", "CodeBleu_score": 48.75780718562483}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Server server = new Server(ip, port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.putIfAbsent(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(server);\n    logger.info(\"Registered service : \" + serviceName + \" with IP : \" + ip + \" and port : \" + port);\n    return true;\n}", "CodeBleu_score": 61.40306007159197}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    if (serviceName == null || ip == null || port == null) {\n        return false;\n    }\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.putIfAbsent(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n    }\n    Server server = new Server(ip, port);\n    serverMap.get(serviceName).add(server);\n    LOGGER.info(\"Registered the service \" + serviceName + \" with the IP address \" + ip + \" and port \" + port);\n    return true;\n}", "CodeBleu_score": 56.870289294794404}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    // Write your code here\n    if (serviceName == null || ip == null || port == null) {\n        return false;\n    }\n\n    if (serverMap.get(serviceName) == null) {\n        serverMap.putIfAbsent(serviceName, Collections.synchronizedSet(new HashSet<Server>()));\n    }\n\n    Server server = new Server(ip, port);\n    serverMap.get(serviceName).add(server);\n    LOGGER.info(\"Registered service: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    return true;\n}", "CodeBleu_score": 58.71845449786505}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Server server = new Server(ip, port);\n    Set<Server> serverSet = serverMap.get(serviceName);\n    if (serverSet != null) {\n        if (serverSet.remove(server)) {\n            log.info(\"Deregistered server: \" + server);\n            return true;\n        }\n    }\n    return false;\n}", "CodeBleu_score": 60.364154575092535}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t\n    Server server = new Server(serviceName, ip, port);\n    Set<Server> serverSet = serverMap.get(serviceName);\n\n    if (serverSet != null) {\n        serverSet.remove(server);\n    }\n\n    if (serverSet != null && serverSet.size() == 0) {\n        serverMap.remove(serviceName);\n    }\n\n    log.info(\"Deregistered server \" + server.toString());\n    return true;\n}", "CodeBleu_score": 61.26878817671554}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    boolean result = false;\n    if (serviceName == null || ip == null || port == null) {\n        logger.error(\"Invalid serviceName, ip, or port parameter.\");\n        return result;\n    }\n    if (serverMap.containsKey(serviceName)) {\n        Set<Server> servers = serverMap.get(serviceName);\n        if (servers.contains(new Server(ip, port))) {\n            logger.info(\"Deregistering server \" + ip + \":\" + port + \" from service \" + serviceName);\n            servers.remove(new Server(ip, port));\n            result = true;\n        }\n    }\n    return result;\n}", "CodeBleu_score": 43.789378532952114}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        String[] clients = (String[]) attributes.get(\"value\");\n        if (clients.length > 0) {\n            for (String client : clients) {\n                registerClientConfiguration(registry, client);\n            }\n        }\n    }\n}", "CodeBleu_score": 46.93521935232471}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        for (Object value : (Object[]) attributes.get(\"value\")) {\n            if (value instanceof AnnotationMetadata) {\n                AnnotationMetadata clientAnnotationMetadata = (AnnotationMetadata) value;\n                Map<String, Object> clientAttributes = clientAnnotationMetadata.getAnnotationAttributes(RibbonClient.class.getName());\n                if (clientAttributes != null) {\n                    String name = (String) clientAttributes.get(\"name\");\n                    if (name == null || name.isEmpty()) {\n                        name = clientAnnotationMetadata.getClassName();\n                    }\n                    BeanDefinitionBuilder builder = BeanDefinitionBuilder.genericBeanDefinition(RibbonClientConfiguration.class);\n                    builder.addConstructorArgValue(clientAnnotationMetadata);\n                    builder.setAutowireMode(AbstractBeanDefinition.AUTOWIRE_BY_TYPE);\n                    builder.setRole(BeanDefinition.ROLE_INFRASTRUCTURE);\n                    registry.registerBeanDefinition(name, builder.getBeanDefinition());\n                }\n            }\n        }\n    }\n}", "CodeBleu_score": 39.31690026942434}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n    if (attributes != null) {\n        registerRibbonClients(attributes, registry);\n    }\n}", "CodeBleu_score": 32.6437114892024}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n    if (loadBalancer == null) {\n        return null;\n    }\n    Server server = loadBalancer.chooseServer(serviceId);\n    if (server == null) {\n        return null;\n    }\n    String host = server.getHost();\n    int port = server.getPort();\n    return new TutuServiceInstance(serviceId, host, port);\n}", "CodeBleu_score": 53.25681408542579}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    if (serviceId == null || serviceId.isEmpty()) {\n        return null;\n    }\n    ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n    if (loadBalancer == null) {\n        return null;\n    }\n    Server server = loadBalancer.chooseServer(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(serviceId, server.getHost(), server.getPort(), server.getMetaInfo().getAppName());\n}", "CodeBleu_score": 46.38031444211834}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    ILoadBalancer loadBalancer = getLoadBalancer(serviceId);\n    if (loadBalancer == null) {\n        return null;\n    }\n    Server server = loadBalancer.chooseServer(serviceId);\n    if (server == null) {\n        return null;\n    }\n    return new TutuServiceInstance(server, serviceId);\n}", "CodeBleu_score": 45.20065654445409}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    if (server == null) {\n        throw new IllegalArgumentException(\"Parameter server must not be null\");\n    }\n    if (original == null) {\n        throw new IllegalArgumentException(\"Parameter original must not be null\");\n    }\n    if (StrUtil.isBlank(original.getScheme())) {\n        throw new IllegalArgumentException(\"Parameter original must include a scheme\");\n    }\n    if (StrUtil.isBlank(original.getHost())) {\n        throw new IllegalArgumentException(\"Parameter original must include a host\");\n    }\n    if (original.getPort() == -1) {\n        throw new IllegalArgumentException(\"Parameter original must include a port\");\n    }\n    String host = server.getHost();\n    int port = server.getPort();\n    String scheme = original.getScheme();\n    String userInfo = original.getUserInfo();\n    String path = original.getPath();\n    String query = original.getQuery();\n    String fragment = original.getFragment();\n    try {\n        URI uri = new URI(scheme, userInfo, host, port, path, query, fragment);\n        return uri;\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 47.69522361423475}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    return reconstructURI(server, original, false);\n}", "CodeBleu_score": 4.63567824171869}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    String scheme = original.getScheme();\n    String host = server.getHost();\n    int port = server.getPort();\n    String path = original.getPath();\n    String query = original.getQuery();\n    String fragment = original.getFragment();\n\n    if (StrUtil.isBlank(host)) {\n        throw new IllegalArgumentException(\"Host of the reconstructed URI is blank\");\n    }\n\n    try {\n        return new URI(scheme, null, host, port, path, query, fragment);\n    } catch (URISyntaxException e) {\n        throw new IllegalArgumentException(e);\n    }\n}", "CodeBleu_score": 41.711843808640324}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    String url = \"http://\" + this.discoveryProperties.getServerAddr() + \"/list\";\n    String result = HttpUtil.get(url, 2000, 2000);\n    List<TutuServer> servers = JSON.parseArray(result, TutuServer.class);\n    return servers;\n}", "CodeBleu_score": 23.559675551322528}, {"code": "private List<TutuServer> getServer(){\n\t    String serverListUrl = this.getServerListUrl();\n    String response = HttpUtil.get(serverListUrl);\n    JSONObject jsonObject = JSON.parseObject(response);\n    List<TutuServer> serverList = jsonObject.getJSONArray(\"serverList\").stream().map(o -> {\n        JSONObject json = (JSONObject) o;\n        return new TutuServer(json.getString(\"ip\"), json.getInteger(\"port\"));\n    }).collect(Collectors.toList());\n    return serverList;\n}", "CodeBleu_score": 39.748256060570135}, {"code": "private List<TutuServer> getServer(){\n\t    String url = this.tutuDiscoveryProperties.getServerAddress() + \"/list?serviceName=\" + this.tutuDiscoveryProperties.getServiceName();\n    String result = HttpUtil.get(url);\n    JSONObject jsonObject = JSON.parseObject(result);\n    List<JSONObject> data = jsonObject.getJSONArray(\"data\").toJavaList(JSONObject.class);\n    List<TutuServer> servers = data.stream().map(json -> {\n        TutuServer server = new TutuServer();\n        server.setIp(json.getString(\"ip\"));\n        server.setPort(json.getInteger(\"port\"));\n        return server;\n    }).collect(Collectors.toList());\n    return servers;\n}", "CodeBleu_score": 39.4897358271935}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (Map.Entry<String, ZuulRoute> routeEntry : this.routes.entrySet()) {\n        String pathPattern = routeEntry.getKey();\n        ZuulRoute route = routeEntry.getValue();\n        if (pathMatcher.match(pathPattern, path)) {\n            String targetPath = pathMatcher.extractPathWithinPattern(pathPattern, path);\n            return new Route(route.getId(), targetPath, route.getServiceId(), route.isStripPrefix(), route.getRetryable(), route.getSensitiveHeaders());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 44.08158354056014}, {"code": "public Route getMatchingRoute(String path){\n\t    PathMatcher pathMatcher = new AntPathMatcher();\n    for (Map.Entry<String, ZuulProperties.ZuulRoute> entry : zuulProperties.getRoutes().entrySet()) {\n        String pattern = entry.getValue().getPath();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = pathMatcher.extractPathWithinPattern(pattern, path);\n            return new Route(entry.getValue().getId(), targetPath);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 51.61077206643236}, {"code": "public Route getMatchingRoute(String path){\n\t    PathMatcher pathMatcher = new AntPathMatcher();\n    for (Map.Entry<String, ZuulRoute> routeEntry : routes.entrySet()) {\n        String pattern = routeEntry.getKey();\n        ZuulRoute route = routeEntry.getValue();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = pathMatcher.extractPathWithinPattern(pattern, path);\n            return new Route(targetPath, route.getServiceId());\n        }\n    }\n    return null;\n}", "CodeBleu_score": 49.3593514727046}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    Set<Class<?>> annotatedClasses = ClassUtil.scanPackageByAnnotation(importingClassMetadata.getClassName(), FeignClient.class);\n    for (Class<?> annotatedClass : annotatedClasses) {\n        GenericBeanDefinition beanDefinition = new GenericBeanDefinition();\n        beanDefinition.setBeanClass(FeignClientFactoryBean.class);\n        beanDefinition.getPropertyValues().add(\"type\", annotatedClass);\n        beanDefinition.getPropertyValues().add(\"contextId\", annotatedClass.getName());\n        registry.registerBeanDefinition(annotatedClass.getName(), beanDefinition);\n    }\n}", "CodeBleu_score": 41.96443570021753}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    Set<Class<?>> annotatedClasses = ClassUtil.scanPackageByAnnotation(ClassUtils.getPackageName(importingClassMetadata.getClassName()), FeignClient.class);\n    for (Class<?> clazz : annotatedClasses) {\n        GenericBeanDefinition definition = new GenericBeanDefinition();\n        definition.setBeanClass(FeignClientFactoryBean.class);\n        definition.getPropertyValues().add(\"type\", clazz);\n        definition.getPropertyValues().add(\"contextId\", clazz.getName());\n        definition.setAutowireMode(GenericBeanDefinition.AUTOWIRE_BY_TYPE);\n        registry.registerBeanDefinition(clazz.getName(), definition);\n    }\n}", "CodeBleu_score": 43.95538653877038}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\n    Set<Class<?>> annotatedClasses = ClassUtil.scanPackageByAnnotation(ClassUtils.getPackageName(importingClassMetadata.getClassName()), FeignClient.class);\n    for (Class<?> annotatedClass : annotatedClasses) {\n        GenericBeanDefinition definition = new GenericBeanDefinition();\n        definition.setBeanClass(FeignClientFactoryBean.class);\n        definition.getConstructorArgumentValues().addGenericArgumentValue(annotatedClass);\n        definition.setAutowireMode(GenericBeanDefinition.AUTOWIRE_BY_TYPE);\n        definition.setLazyInit(false);\n        String className = annotatedClass.getSimpleName();\n        String beanName = className.substring(0, 1).toLowerCase() + className.substring(1);\n        registry.registerBeanDefinition(beanName, definition);\n    }\n}", "CodeBleu_score": 44.05340235608992}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
