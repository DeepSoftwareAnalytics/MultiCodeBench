{"instance_id": "ba8707e206f9", "generation_result": [{"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    wait, *_ = self._orig_kazoo_connect(*args)\n    wait = max(2, self.loop_wait - 2) * 1000\n    return wait, *_\n\n", "CodeBleu_score": 52.28295311795279}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    return (max(2, self.loop_wait - 2) * 1000, self._orig_kazoo_connect(*args))\n\n", "CodeBleu_score": 50.448820048867674}, {"code": "def _kazoo_connect(self, *args: Any) -> Tuple[Union[int, float], Union[int, float]]\n\t\n    return_value = self._orig_kazoo_connect(*args)\n    wait_time = max(2, self.loop_wait - 2)\n    return wait_time * 1000, return_value[1]\n\n", "CodeBleu_score": 48.11199199513829}]}
{"instance_id": "88e24a7c26a4", "generation_result": [{"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.get_config()\n\n    self.set_retry_timeout(config.get('retry_timeout', self.retry_timeout))\n    self.set_connect_timeout(config.get('connect_timeout', self.connect_timeout))\n    self.set_ttl(config.get('ttl', self.ttl))\n\n", "CodeBleu_score": 29.708861168308783}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        self.config = config\n    else:\n        self.config = Config(config)\n    self.set_retry_timeout(self.config.retry_timeout)\n    self.set_connect_timeout(self.config.connect_timeout)\n    self.set_ttl(self.config.ttl)\n    if self.config.loop_wait != self.loop_wait:\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.set_connect_timeout(self.config.connect_timeout)\n        if self.ttl != self.config.ttl:\n            self.close()\n\n", "CodeBleu_score": 37.79195474478508}, {"code": "def reload_config(self, config: Union['Config', Dict[str, Any]]) -> None\n\t\n    if isinstance(config, Config):\n        config = config.get_config()\n    self.set_retry_timeout(config['retry_timeout'])\n    self.set_connect_timeout(config['connect_timeout'])\n    if self.loop_wait_time != config['loop_wait_time']:\n        self.loop_wait_time = config['loop_wait_time']\n        if isinstance(self.handler, PatroniSequentialThreadingHandler):\n            self.handler.set_connect_timeout(config['connect_timeout'])\n        if not self.set_ttl(config['ttl']):\n            self.close()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 42.884246408677555}]}
{"instance_id": "2af7d7b3c887", "generation_result": [{"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    try:\n        with open(path, \"r\") as f:\n            data = json.loads(f.read())\n    except FileNotFoundError:\n        return Cluster(None, None, None, None, None, None, None, None)\n\n    try:\n        init_state = InitializationState.from_node(data)\n    except KeyError:\n        init_state = None\n\n    try:\n        config = ClusterConfig.from_node(data)\n    except KeyError:\n        config = None\n\n    try:\n        timeline_history = TimelineHistory.from_node(data)\n    except KeyError:\n        timeline_history = None\n\n    try:\n        sync_state = SyncState.from_node(data)\n    except KeyError:\n        sync_state = None\n\n    try:\n        members = self.load_members(data)\n    except KeyError:\n        members = None\n\n    try:\n        leader = Leader.from_node(data)\n    except KeyError:\n        leader = None\n\n    try:\n        status = self.get_status(data)\n    except KeyError:\n        status = None\n\n    try:\n        failover = Failover.from_node(data)\n    except KeyError:\n        failover = None\n\n    try:\n        failsafe = Failsafe.from_node(data)\n    except KeyError:\n        failsafe = None\n\n    return Cluster(init_state, config, timeline_history, sync_state, members, leader, status, failover, failsafe)\n\n", "CodeBleu_score": 22.254740876904307}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n\n    # check the existence of the cluster initialization state file\n    if not os.path.exists(path):\n        raise PatroniFatalException(\"The cluster initialization state file does not exist.\")\n\n    # load the cluster initialization state from the initialization state file\n    with open(path) as f:\n        cluster_init_state = ClusterInitState.from_node(f.read())\n\n    # check the existence of the cluster configuration file\n    if not os.path.exists(cluster_init_state.config_file):\n        raise PatroniFatalException(\"The cluster configuration file does not exist.\")\n\n    # load the cluster configuration from the cluster configuration file\n    with open(cluster_init_state.config_file) as f:\n        cluster_config = ClusterConfig.from_node(json.loads(f.read()))\n\n    # check the existence of the cluster timeline history file\n    if not os.path.exists(cluster_init_state.timeline_history_file):\n        raise PatroniFatalException(\"The cluster timeline history file does not exist.\")\n\n    # load the cluster timeline history from the cluster timeline history file\n    with open(cluster_init_state.timeline_history_file) as f:\n        timeline_history = TimelineHistory.from_node(f.read())\n\n    # check the existence of the cluster synchronization state file\n    if not os.path.exists(cluster_init_state.sync_state_file):\n        raise PatroniFatalException(\"The cluster synchronization state file does not exist.\")\n\n    # load the cluster synchronization state from the cluster synchronization state file\n    with open(cluster_init_state.sync_state_file) as f:\n        cluster_sync_state = SyncState.from_node(f.read())\n\n    # check the existence of the cluster members file\n    if not os.path.exists(cluster_init_state.members_file):\n        raise PatroniFatalException(\"The cluster members file does not exist.\")\n\n    # load the cluster members from the cluster members file\n    with open(cluster_init_state.members_file) as f:\n        cluster_members = self.load_members(", "CodeBleu_score": 16.629942808660072}, {"code": "def _postgresql_cluster_loader(self, path: str) -> Cluster\n\t\n    self.log.debug(\"loading cluster configuration from %s\", path)\n\n    cluster = Cluster(self.config)\n    cluster.initialize(path, self.config.get(\"name\"))\n\n    # load cluster configuration\n    self.log.debug(\"loading cluster configuration\")\n    cluster.config = ClusterConfig.from_node(self, cluster.config_path_exists)\n\n    # load cluster timeline history\n    self.log.debug(\"loading cluster timeline history\")\n    cluster.timeline_history = TimelineHistory.from_node(self, cluster.history_path_exists)\n\n    # load cluster synchronization state\n    self.log.debug(\"loading cluster synchronization state\")\n    cluster.sync_state = SyncState.from_node(self, cluster.sync_path_exists)\n\n    # load cluster members\n    self.log.debug(\"loading cluster members\")\n    cluster.members = self.load_members(cluster)\n\n    # load cluster leader\n    self.log.debug(\"loading cluster leader\")\n    cluster.leader = Leader.from_node(self, cluster.leader_path_exists)\n\n    # load cluster status\n    self.log.debug(\"loading cluster status\")\n    cluster.status = self.get_status(cluster)\n\n    # load cluster failover state\n    self.log.debug(\"loading cluster failover state\")\n    cluster.failover = Failover.from_node(self, cluster.failover_path_exists)\n\n    # load cluster failsafe configuration\n    self.log.debug(\"loading cluster failsafe configuration\")\n    cluster.failsafe = Failsafe.from_node(self, cluster.failsafe_path_exists)\n\n    self.log.debug(\"cluster configuration loaded successfully\")\n    return cluster\n\n", "CodeBleu_score": 15.904123563625713}]}
{"instance_id": "43e1bc044d8e", "generation_result": [{"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.lock_path, self.data, acl=self.acl, ephemeral=True, sequence=True)\n        logger.info('Acquired leader lock at %s', self.lock_path)\n        return True\n    except NodeExistsError:\n        logger.info('Failed to acquire leader lock at %s', self.lock_path)\n        return False\n    except Exception as e:\n        logger.error('Unexpected error while attempting to acquire leader lock at %s: %s', self.lock_path, e)\n        return False\n", "CodeBleu_score": 50.72333648992048}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n    try:\n        self.zk.create(self.path, self.value, acl=self.acl, ephemeral=True, sequence=False)\n    except NodeExistsError:\n        logger.info(f\"{self.path} is locked by another instance\")\n        return False\n    except (ConnectionClosedError, RetryFailedError) as e:\n        raise ZooKeeperError(e)\n    except Exception as e:\n        logger.error(f\"Unexpected exception when attempting to acquire lock at {self.path}: {e}\")\n        return False\n    logger.info(f\"Lock acquired at {self.path}\")\n    return True\n\n", "CodeBleu_score": 50.48786565595806}, {"code": "def attempt_to_acquire_leader(self) -> bool\n\t\n\n    def create_node_with_retry(zk: KazooClient, path: str, value: bytes) -> bool:\n        \"\"\"This function creates an ephemeral node in ZooKeeper at a specified path. It uses a retry mechanism to handle transient issues. If successful, it returns True. If the connection to ZooKeeper is closed or retries fail, it raises a ZooKeeperError. For other exceptions, it logs an error and returns False.\"\"\"\n        while True:\n            try:\n                zk.create(path, value, ephemeral=True, makepath=True)\n            except KazooException:\n                logger.error(f\"Exception while creating node at path {path}.\")\n                return False\n            except Exception as e:\n                if isinstance(e, NodeExistsError):\n                    logger.info(f\"Node at path {path} already exists.\")\n                    return False\n                else:\n                    logger.error(f\"Exception while creating node at path {path}.\")\n                    return False\n            else:\n                return True\n\n    while True:\n        try:\n            zk = KazooClient(hosts=self.zk_hosts, timeout=self.zk_timeout)\n            zk.start()\n            if create_node_with_retry(zk, self.zk_path, self.zk_value):\n                return True\n        except KazooException:\n            logger.error(f\"Exception while connecting to ZooKeeper at {self.zk_hosts}.\")\n            raise ZooKeeperError\n        except Exception:\n            logger.error(f\"Exception while connecting to ZooKeeper at {self.zk_hosts}.\")\n            raise ZooKeeperError\n        else:\n            logger.info(f\"Failed to acquire lock at path {self.zk_path}.\")\n            return False\n        finally:\n            zk.stop()\n            zk.close()\n\n", "CodeBleu_score": 33.535152599079176}]}
{"instance_id": "93d126ab8a22", "generation_result": [{"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n\n    if leader.session_id != self.client.session_id:\n        logger.warning(\n            \"Leader session ID (%s) does not match current client ID (%s).\",\n            leader.session_id,\n            self.client.session_id,\n        )\n        try:\n            self.client.delete(leader.path)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            logger.warning(\"Failed to delete leader node.\")\n            return False\n\n    try:\n        self.client.create(\n            self.leader_path,\n            data=self.client.session_id.encode(),\n            ephemeral=True,\n            sequence=True,\n        )\n    except (NoNodeError, ConnectionClosedError, RetryFailedError) as e:\n        logger.error(\"Failed to create new leader node: %s\", e)\n        return False\n\n    return True\n\n", "CodeBleu_score": 45.059869626037234}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    try:\n        if leader.client_id != self.client_id:\n            logger.warning(f\"The current client ID {self.client_id} does not match the leader's client ID {leader.client_id}.\")\n            self.delete(self.leader_znode, version=leader.zxid)\n        self.create(self.leader_znode, self.client_id.encode(), ephemeral=True)\n        return True\n    except NoNodeError:\n        logger.warning(f\"The leader ZNode {self.leader_znode} does not exist.\")\n    except ConnectionClosedError:\n        logger.warning(\"The connection to the ZooKeeper server is closed.\")\n    except RetryFailedError:\n        logger.warning(\"The operation could not be completed due to a retry timeout.\")\n    except Exception as e:\n        logger.error(f\"The following error occurred while updating the leader: {e}\")\n    return False\n\n", "CodeBleu_score": 35.70015345819877}, {"code": "def _update_leader(self, leader: Leader) -> bool\n\t\n    if leader.client_id != self.client_id:\n        logger.warning(\"Leader mismatch. Current client ID: %s. Leader client ID: %s\", self.client_id, leader.client_id)\n        try:\n            self.delete(leader.path, version=leader.version)\n        except (NoNodeError, ConnectionClosedError, RetryFailedError):\n            logger.warning(\"Failed to delete leader ZNode. Current client ID: %s. Leader client ID: %s\", self.client_id, leader.client_id)\n        else:\n            logger.info(\"Deleted leader ZNode. Current client ID: %s. Leader client ID: %s\", self.client_id, leader.client_id)\n    try:\n        self.create(self.leader_path, self.client_id.encode(), ephemeral=True, sequence=True)\n    except (ConnectionClosedError, RetryFailedError):\n        logger.error(\"Failed to create leader ZNode. Current client ID: %s\", self.client_id)\n        return False\n    else:\n        logger.info(\"Created leader ZNode. Current client ID: %s\", self.client_id)\n        return True\n\n", "CodeBleu_score": 38.84379301376073}]}
{"instance_id": "f68719982812", "generation_result": [{"code": "def poll(self) -> bool\n\t\n\n    # Check if it's time to poll again\n    if time.time() < self._next_poll_time:\n        return False\n\n    # Get the status of the exhibitors\n    self._query_exhibitors()\n\n    # Check if the connection string has changed\n    if self._connection_string != self._exhibitor_connection_string:\n        # Log the change\n        logger.info(\"Connection string changed from '%s' to '%s'\", self._connection_string, self._exhibitor_connection_string)\n\n        # Update the connection string\n        self._connection_string = self._exhibitor_connection_string\n\n        # Update the ZooKeeper connection string\n        self._zk.set_connection_string(self._connection_string)\n\n        # Update the next poll time\n        self._next_poll_time = time.time() + self._poll_interval\n\n        # Return True to indicate a change occurred\n        return True\n\n    # Update the next poll time\n    self._next_poll_time = time.time() + self._poll_interval\n\n    # Return False to indicate no change occurred\n    return False\n", "CodeBleu_score": 27.91448785715589}, {"code": "def poll(self) -> bool\n\t\n    if self._last_poll is None or time.time() - self._last_poll >= self._poll_interval:\n        self._last_poll = time.time()\n        self._query_exhibitors()\n        if self._exhibitors is None:\n            logger.info(\"No exhibitors available, skipping poll\")\n            return False\n        if self._exhibitors == self._last_exhibitors:\n            logger.info(\"No change in exhibitors, skipping poll\")\n            return False\n        logger.info(\"Exhibitors changed, polling\")\n        self._last_exhibitors = self._exhibitors\n        self._connect_string = self._build_connect_string()\n        return True\n    return False\n\n", "CodeBleu_score": 29.152722657192044}, {"code": "def poll(self) -> bool\n\t\n    if self._query_exhibitors:\n        self._query_exhibitors = False\n        self._query_exhibitors_time = time.time() + self._query_exhibitors_interval\n\n        logger.info(\"Polling exhibitors for ZooKeeper connection string.\")\n        try:\n            exhibitors = self._exhibitors.get_exhibitors()\n            if exhibitors is None:\n                logger.warning(\"No exhibitors returned from query.\")\n                return False\n\n            self._exhibitors.set_exhibitors(exhibitors)\n            self._update_connection_string()\n            return True\n        except Exception as e:\n            logger.exception(\"Exception while querying exhibitors.\")\n            return False\n\n    if time.time() > self._query_exhibitors_time:\n        self._query_exhibitors = True\n\n    return False\n\n", "CodeBleu_score": 30.233771026125}]}
{"instance_id": "022ed3721913", "generation_result": [{"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.load_ensemble()\n        self.hosts = self.ensemble_provider.hosts\n\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 60.02686100106677}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.update_hosts(self.hosts)\n\n    return super(EnsembleProvider, self)._load_cluster(path, loader)\n\n", "CodeBleu_score": 64.02270086681625}, {"code": "def _load_cluster(\n            self, path: str, loader: Callable[[str], Union[Cluster, Dict[int, Cluster]]]\n    ) -> Union[Cluster, Dict[int, Cluster]]\n\t\n    if self.ensemble_provider is not None:\n        self.ensemble_provider.load_ensemble(path)\n        self.hosts = self.ensemble_provider.get_ensemble()\n    return super()._load_cluster(path, loader)\n\n", "CodeBleu_score": 58.99031765217718}]}
{"instance_id": "c7d2e1db0cda", "generation_result": [{"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t    this.nodeCache = nodeCache;\n    this.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 81.45633845775137}, {"code": "public ZookeeperListener(NodeCache nodeCache, NodeCacheListener nodeCacheListener){\n\t\tthis.nodeCache = nodeCache;\n\tthis.nodeCacheListener = nodeCacheListener;\n}", "CodeBleu_score": 78.53464624293271}]}
{"instance_id": "c779f567d3e2", "generation_result": [{"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String dataId = getDataId();\n    String group = getGroup();\n    logUnsubscribeStarted(dataId, group);\n    try {\n        zookeeperListener.unsubscribeConfig(dataId, group);\n    } catch (Exception e) {\n        logUnsubscribeFailed(dataId, group, e);\n    }\n}", "CodeBleu_score": 72.72542302786142}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n\n    String group = getGroup();\n    String dataId = getDataId();\n\n    logUnsubscribeStarted(group, dataId);\n\n    try {\n        zookeeperListener.unsubscribeConfig(dataId, group);\n    } catch (Exception e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 79.73467508504312}, {"code": "public void destroy(){\n\t    if (zookeeperListener == null) {\n        return;\n    }\n    String group = getGroup();\n    String dataId = getDataId();\n    logUnsubscribeStarted(group, dataId);\n    try {\n        zookeeperListener.unsubscribeConfig(dataId, group);\n    } catch (Exception e) {\n        logUnsubscribeFailed(group, dataId, e);\n    }\n}", "CodeBleu_score": 79.73467508504312}]}
{"instance_id": "7f0ce4db487b", "generation_result": [{"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 60.38280052230495}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    Map<String, String> metadata = new HashMap<>();\n    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        metadata.put(\"zk.version\", zkServer.getPayload().getVersion());\n        metadata.put(\"zk.avg.latency\", zkServer.getPayload().getAvgLatency());\n        metadata.put(\"zk.max.latency\", zkServer.getPayload().getMaxLatency());\n        metadata.put(\"zk.min.latency\", zkServer.getPayload().getMinLatency());\n        metadata.put(\"zk.packets.received\", zkServer.getPayload().getPacketsReceived());\n        metadata.put(\"zk.packets.sent\", zkServer.getPayload().getPacketsSent());\n        metadata.put(\"zk.num.alive_connections\", zkServer.getPayload().getNumAliveConnections());\n        metadata.put(\"zk.outstanding_requests\", zkServer.getPayload().getOutstandingRequests());\n        metadata.put(\"zk.server_state\", zkServer.getPayload().getServerState());\n        metadata.put(\"zk.znode_count\", zkServer.getPayload().getZnodeCount());\n        metadata.put(\"zk.watch_count\", zkServer.getPayload().getWatchCount());\n        metadata.put(\"zk.ephemerals_count\", zkServer.getPayload().getEphemeralsCount());\n        metadata.put(\"zk.approximate_data_size\", zkServer.getPayload().getApproximateDataSize());\n        metadata.put(\"zk.open_file_descriptor_count\", zkServer.getPayload().getOpenFileDescriptorCount());\n        metadata.put(\"zk.max_file_descriptor_count\", zkServer.getPayload().getMaxFileDescriptorCount());\n    }\n    return metadata;\n}", "CodeBleu_score": 40.63812121620314}, {"code": "public Map<String, String> getServerMetadata(Server server){\n\t    if (server instanceof ZookeeperServer) {\n        ZookeeperServer zkServer = (ZookeeperServer) server;\n        return zkServer.getPayload().getServerMetadata();\n    }\n    return Collections.emptyMap();\n}", "CodeBleu_score": 60.40264897176878}]}
{"instance_id": "7365d194b7ee", "generation_result": [{"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = getConfigPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(curatorFramework, path);\n    nodeCache.start();\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String config = new String(nodeCache.getCurrentData().getData());\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    zookeeperListenerMap.put(path, zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 74.59943762608046}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = getConfigPath(group, serviceId);\n    NodeCache nodeCache = new NodeCache(curatorFramework, path);\n    NodeCacheListener nodeCacheListener = new NodeCacheListener() {\n        @Override\n        public void nodeChanged() throws Exception {\n            String config = new String(nodeCache.getCurrentData().getData());\n            zookeeperSubscribeCallback.callback(config);\n        }\n    };\n    nodeCache.getListenable().addListener(nodeCacheListener);\n    nodeCache.start();\n    ZookeeperListener zookeeperListener = new ZookeeperListener(nodeCache, nodeCacheListener);\n    listeners.add(zookeeperListener);\n    return zookeeperListener;\n}", "CodeBleu_score": 75.06930241388588}, {"code": "public ZookeeperListener subscribeConfig(String group, String serviceId, ZookeeperSubscribeCallback zookeeperSubscribeCallback) throws Exception{\n\t    String path = Constants.ZOOKEEPER_CONFIG_PATH + \"/\" + group + \"/\" + serviceId;\n    NodeCache nodeCache = new NodeCache(client, path);\n    nodeCache.start();\n    ZookeeperSubscribeCallback callback = zookeeperSubscribeCallback;\n    ZookeeperListener listener = new ZookeeperListener(nodeCache, callback);\n    nodeCache.getListenable().addListener(listener);\n    return listener;\n}", "CodeBleu_score": 37.09456575803821}]}
{"instance_id": "6f492670162b", "generation_result": [{"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator(config, serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setLoadBalanceListenerExecutor(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>()));\n    serverList.setServiceId(config.getClientName());\n    return serverList;\n}", "CodeBleu_score": 75.42537488220553}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ServerList<?> serverList = new ZookeeperServerListDecorator(config, serviceDiscovery);\n    serverList.initWithNiwsConfig(config);\n    serverList.setServiceId(config.getClientName());\n    serverList.setLoadBalanceListenerExecutor(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>()));\n    return serverList;\n}", "CodeBleu_score": 65.08704438376014}, {"code": "public ServerList<?> ribbonServerList(IClientConfig config, ServiceDiscovery<ZookeeperInstance> serviceDiscovery){\n\t    ZookeeperServerListDecorator serverList = new ZookeeperServerListDecorator();\n    serverList.initWithNiwsConfig(config);\n    serverList.setServiceDiscovery(serviceDiscovery);\n    serverList.setLoadBalanceListenerExecutor(new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue<Runnable>()));\n    serverList.setServiceId(serverList.getClientName());\n    return serverList;\n}", "CodeBleu_score": 56.76811494430724}]}
{"instance_id": "17c01a5f8ef8", "generation_result": [{"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        getBean().onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 42.05354947145942}, {"code": "public void register(ZookeeperRegistration registration){\n\t\ttry {\n\t\tRegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n\t\texecutor.onRegister(registration);\n\t} catch (BeansException e) {\n\t\t// ignore\n\t}\n\tserviceRegistry.register(registration);\n}", "CodeBleu_score": 60.607431044921434}, {"code": "public void register(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor executor = getBean(RegisterListenerExecutor.class);\n        executor.onRegister(registration);\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.register(registration);\n}", "CodeBleu_score": 64.50374947026486}]}
{"instance_id": "99392dfa2335", "generation_result": [{"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor executor = (RegisterListenerExecutor) getBean(\"registerListenerExecutor\");\n        executor.onDeregister(registration);\n    } catch (BeansException e) {\n        // ignore\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 59.31923912527763}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        logger.warn(\"No RegisterListenerExecutor bean found in the application context. Ignoring...\");\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 61.96647711538683}, {"code": "public void deregister(ZookeeperRegistration registration){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = getBean(RegisterListenerExecutor.class);\n        registerListenerExecutor.onDeregister(registration);\n    } catch (BeansException e) {\n        log.warn(\"Failed to get RegisterListenerExecutor bean from application context\", e);\n    }\n    serviceRegistry.remove(registration);\n}", "CodeBleu_score": 62.44739500590158}]}
{"instance_id": "02a835946e90", "generation_result": [{"code": "public void close(){\n\t    try {\n        getBean(RegisterListenerExecutor.class).onClose();\n    } catch (BeansException e) {\n        // Ignore\n    }\n    serviceRegistry.close();\n}", "CodeBleu_score": 43.34607641837411}, {"code": "public void close(){\n\t    try {\n        RegisterListenerExecutor registerListenerExecutor = (RegisterListenerExecutor) getBean(\"registerListenerExecutor\");\n        registerListenerExecutor.onClose();\n    } catch (BeansException e) {\n        LOG.warn(\"Failed to retrieve the RegisterListenerExecutor bean from the application context. Ignoring.\", e);\n    }\n\n    serviceRegistry.close();\n}", "CodeBleu_score": 60.377934221132314}, {"code": "public void close(){\n\t\ttry {\n\t\tgetBean(RegisterListenerExecutor.class).onClose();\n\t} catch (BeansException e) {\n\t\t// ignore\n\t}\n\tserviceRegistry.close();\n}", "CodeBleu_score": 39.9315447818781}]}
{"instance_id": "64cf817f5945", "generation_result": [{"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? config.globalConfigGroup : config.group\n    String dataId = globalConfig ? config.globalConfigDataId : config.dataId\n    log.info(\"Subscribing to config: group: ${group}, dataId: ${dataId}\")\n\n    try {\n        ZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, {\n            log.info(\"Config updated: group: ${group}, dataId: ${dataId}\")\n            callbackConfig()\n        })\n        return listener\n    } catch (Exception e) {\n        log.error(\"Failed to subscribe to config: group: ${group}, dataId: ${dataId}\", e)\n        return null\n    }\n}", "CodeBleu_score": 31.93953156584139}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? GLOBAL_CONFIG : APP_CONFIG;\n    String dataId = globalConfig ? GLOBAL_DATA_ID : APP_DATA_ID;\n    log.info(\"Subscribing to config for group: ${group}, dataId: ${dataId}\");\n\n    try {\n        ZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, { config ->\n            log.info(\"Received config update for group: ${group}, dataId: ${dataId}, config: ${config}\");\n        } as ConfigChangeCallback);\n\n        return listener;\n    } catch (Exception e) {\n        log.error(\"Failed to subscribe to config for group: ${group}, dataId: ${dataId}\", e);\n        return null;\n    }\n}", "CodeBleu_score": 32.63759196863867}, {"code": "private ZookeeperListener subscribeConfig(boolean globalConfig){\n\t    String group = globalConfig ? this.globalConfigGroup : this.localConfigGroup;\n    String dataId = globalConfig ? this.globalConfigDataId : this.localConfigDataId;\n    log.info(\"Subscribing to \" + group + \"/\" + dataId);\n    try {\n        ZookeeperListener listener = zookeeperOperation.subscribeConfig(group, dataId, new ConfigChangeCallback() {\n            @Override\n            public void callback(String config) {\n                log.info(\"Configuration changed to \" + config);\n                if (globalConfig) {\n                    globalConfig = config;\n                } else {\n                    localConfig = config;\n                }\n            }\n        });\n        log.info(\"Subscribed to \" + group + \"/\" + dataId);\n        return listener;\n    } catch (Exception e) {\n        log.error(\"Failed to subscribe to \" + group + \"/\" + dataId, e);\n        return null;\n    }\n}", "CodeBleu_score": 42.37184658647857}]}
{"instance_id": "be408acc71f6", "generation_result": [{"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(\"zookeeper.connectString\");\n    if (connectString.isEmpty()) {\n        throw new DiscoveryException(\"Zookeeper connection string is empty\");\n    }\n    int retryCount = getProperty(\"zookeeper.retryCount\", 3);\n    int sleepTime = getProperty(\"zookeeper.sleepTime\", 1000);\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(sleepTime, retryCount);\n\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 38.97005376091148}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(\"zookeeper.connectString\");\n    if (connectString.isEmpty()) {\n        throw new DiscoveryException(\"zookeeper.connectString is empty\");\n    }\n\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(\n            Integer.parseInt(getProperty(\"zookeeper.baseSleepTimeMs\")),\n            Integer.parseInt(getProperty(\"zookeeper.maxRetries\")));\n\n    CuratorFramework builder = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n\n    builder.start();\n\n    return builder;\n}", "CodeBleu_score": 33.4494856458214}, {"code": "public CuratorFramework curatorFramework(){\n\t    String connectString = getProperty(\"ZK_CONNECT_STRING\");\n    if (connectString == null || connectString.isEmpty()) {\n        throw new DiscoveryException(\"ZK_CONNECT_STRING is empty\");\n    }\n    int retryCount = Integer.parseInt(getProperty(\"ZK_RETRY_COUNT\", \"3\"));\n    int retrySleepTime = Integer.parseInt(getProperty(\"ZK_RETRY_SLEEP_TIME\", \"1000\"));\n    RetryPolicy retryPolicy = new ExponentialBackoffRetry(retrySleepTime, retryCount);\n    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(connectString)\n            .retryPolicy(retryPolicy)\n            .build();\n    client.start();\n    return client;\n}", "CodeBleu_score": 40.86314608517461}]}
{"instance_id": "3628d7b6f0a5", "generation_result": [{"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t@Bean\n\t@ConditionalOnMissingBean(GatewayStrategyRouteZookeeperProcessor.class)\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor() {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor();\n\t}\n\n}", "CodeBleu_score": 53.95587489940241}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t@Bean\n\t@ConditionalOnMissingBean(GatewayStrategyRouteZookeeperProcessor.class)\n\t@ConditionalOnProperty(prefix = \"spring.cloud.gateway.discovery.locator\", name = \"enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(CuratorFramework curatorFramework,\n\t\t\tObjectProvider<List<GatewayStrategyRouteZookeeperProcessorCustomizer>> customizers) {\n\t\tGatewayStrategyRouteZookeeperProcessor processor = new GatewayStrategyRouteZookeeperProcessor(curatorFramework);\n\t\tcustomizers.ifAvailable(processor::setCustomizers);\n\t\treturn processor;\n\t}\n\n}", "CodeBleu_score": 28.683219768795265}, {"code": "protected static class GatewayRouteZookeeperConfiguration{\n\t\n\t@Bean\n\t@ConditionalOnProperty(name = \"spring.cloud.gateway.discovery.locator.enabled\", havingValue = \"false\", matchIfMissing = true)\n\tpublic GatewayStrategyRouteZookeeperProcessor gatewayStrategyRouteZookeeperProcessor(CuratorFramework curator,\n\t\t\tObjectProvider<List<RouteDefinitionLocator>> definitionLocators,\n\t\t\tObjectProvider<List<GatewayProperties>> gatewayProperties,\n\t\t\tObjectProvider<List<GatewayFilter>> gatewayFilters,\n\t\t\tObjectProvider<List<RouteLocator>> routeLocators,\n\t\t\tObjectProvider<List<GatewayStrategy>> gatewayStrategies) {\n\t\treturn new GatewayStrategyRouteZookeeperProcessor(curator, definitionLocators, gatewayProperties,\n\t\t\t\tgatewayFilters, routeLocators, gatewayStrategies);\n\t}\n\n}", "CodeBleu_score": 35.38667461624975}]}
{"instance_id": "68a13b54ad7c", "generation_result": [{"code": "public  CuratorFramework createCuratorFramework(){\n\t    // 1. Initialize a CuratorFramework instance.\n    CuratorFramework builder = CuratorFrameworkFactory.builder()\n        .connectString(getZkHosts())\n        .sessionTimeoutMs(getSessionTimeout())\n        .namespace(getNamespace())\n        .retryPolicy(retryPolicy)\n        .build();\n\n    // 2. Start the CuratorFramework instance.\n    builder.start();\n\n    // 3. Return the CuratorFramework instance.\n    return builder;\n}", "CodeBleu_score": 37.61370725323495}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    CuratorFrameworkBuilder builder = CuratorFrameworkFactory.builder();\n    String zkHosts = getZkHosts();\n    builder.connectString(zkHosts);\n    int sessionTimeoutMs = getSessionTimeout();\n    builder.sessionTimeoutMs(sessionTimeoutMs);\n    RetryPolicy retryPolicy = getRetryPolicy();\n    builder.retryPolicy(retryPolicy);\n    CuratorFramework curatorFramework = builder.build();\n    curatorFramework.start();\n    return curatorFramework;\n}", "CodeBleu_score": 39.599268448322725}, {"code": "public  CuratorFramework createCuratorFramework(){\n\t    // Create a CuratorFramework instance and set the properties\n    CuratorFramework curatorFramework = builder.build();\n    // Set the retry policy\n    curatorFramework.setRetryPolicy(retryPolicy);\n    // Start the CuratorFramework instance\n    curatorFramework.start();\n    // Return the initialized CuratorFramework instance\n    return curatorFramework;\n}", "CodeBleu_score": 22.85324529886464}]}
{"instance_id": "018a3d7b5f59", "generation_result": [{"code": "public void lock(String path) throws DistributedLockException{\n\t    try {\n        InterProcessMutex lock = locksMap.get(path);\n        if (lock == null) {\n            lock = new InterProcessMutex(getZkCleint(), path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } else {\n            lock.acquire();\n        }\n    } catch (Exception e) {\n        throw new DistributedLockException(e);\n    }\n}", "CodeBleu_score": 29.462828927054396}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    lock(path, -1);\n}", "CodeBleu_score": 4.590252655418355}, {"code": "public void lock(String path) throws DistributedLockException{\n\t    if (locksMap.containsKey(path)) {\n        // If the current thread already holds a lock for the given path, re-acquire the lock.\n        // This is necessary to prevent the lock from being released by another thread while this thread is still using it.\n        try {\n            locksMap.get(path).acquire();\n        } catch (Exception e) {\n            throw new DistributedLockException(String.format(\"Error acquiring lock for path %s\", path), e);\n        }\n    } else {\n        // If the current thread does not already hold a lock, create a new InterProcessMutex and acquire the lock.\n        try {\n            InterProcessMutex lock = new InterProcessMutex(getZkCleint(), path);\n            lock.acquire();\n            locksMap.put(path, lock);\n        } catch (Exception e) {\n            throw new DistributedLockException(String.format(\"Error acquiring lock for path %s\", path), e);\n        }\n    }\n}", "CodeBleu_score": 38.73531247341744}]}
{"instance_id": "2068af09c973", "generation_result": [{"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    String nodePath = getNodePath(curatorFramework, dtpProperties);\n    ConfigType configType = dtpProperties.getConfigType();\n    if (configType == ConfigType.PROPERTIES) {\n        return genPropertiesTypeMap(curatorFramework, nodePath);\n    } else if (configType == ConfigType.JSON) {\n        String configKey = getConfigKey(dtpProperties);\n        String configVal = getVal(curatorFramework, nodePath, configKey);\n        return ConfigHandler.parseConfig(configVal);\n    } else {\n        throw new DtpException(\"Unsupported config type: \" + configType);\n    }\n}", "CodeBleu_score": 44.02195357499349}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    String nodePath = getNodePath(curatorFramework, dtpProperties);\n    ConfigType configType = getConfigType(dtpProperties);\n    Map<Object, Object> propertiesMap;\n    switch (configType) {\n        case PROPERTIES:\n            propertiesMap = genPropertiesTypeMap(curatorFramework, nodePath);\n            break;\n        case JSON:\n            String configKey = getConfigKey(dtpProperties);\n            String val = getVal(curatorFramework, makePath(nodePath, configKey));\n            propertiesMap = ConfigHandler.parseConfig(val);\n            break;\n        default:\n            throw new IllegalArgumentException(\"Invalid config type: \" + configType);\n    }\n    return propertiesMap;\n}", "CodeBleu_score": 41.58026533220616}, {"code": "public static Map<Object, Object> genPropertiesMap(DtpProperties dtpProperties){\n\t    CuratorFramework curatorFramework = getCuratorFramework(dtpProperties);\n    String nodePath = getNodePath(dtpProperties, curatorFramework);\n\n    switch (dtpProperties.getConfigType()) {\n        case PROPERTIES:\n            return genPropertiesTypeMap(curatorFramework, nodePath);\n        case JSON:\n            String configKey = getConfigKey(dtpProperties);\n            String val = getVal(curatorFramework, makePath(nodePath, configKey));\n            return ConfigHandler.parseConfig(val);\n        default:\n            throw new IllegalArgumentException(\"Invalid configuration type: \" + dtpProperties.getConfigType());\n    }\n}", "CodeBleu_score": 43.33322782990636}]}
{"instance_id": "3d3c9020d299", "generation_result": [{"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = getInstance();\n    Binder.get(environment).bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n    Map<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n    checkPropertyExist(environment, propertiesMap);\n    createZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 50.142514823983085}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = getInstance();\n    Binder.get(environment).bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n    Map<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n    checkPropertyExist(environment, propertiesMap);\n    createZkPropertySource(environment, propertiesMap);\n}", "CodeBleu_score": 50.142514823983085}, {"code": "public void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application){\n\t    DtpProperties dtpProperties = getInstance(DtpProperties.class);\n    Binder.get(environment).bind(\"dtp\", Bindable.ofInstance(dtpProperties));\n    Map<String, Object> propertiesMap = genPropertiesMap(dtpProperties);\n    checkPropertyExist(propertiesMap, environment);\n    createZkPropertySource(propertiesMap, environment);\n}", "CodeBleu_score": 52.45395372826663}]}
{"instance_id": "0a934e7885be", "generation_result": [{"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    //\u6ce8\u518c\u65e5\u5fd7\n    builder.RegisterType<DefaultLogger<ZooKeeperServiceRouteManager>>().As<ILogger<ZooKeeperServiceRouteManager>>().SingleInstance();\n    //\u6ce8\u518c\u5e8f\u5217\u5316\u5668\n    builder.RegisterType<JsonSerializer>().As<ISerializer<byte[]>>().SingleInstance();\n    builder.RegisterType<JsonSerializer>().As<ISerializer<string>>().SingleInstance();\n    //\u6ce8\u518c\u8def\u7531\u5de5\u5382\n    builder.RegisterType<ServiceRouteFactory>().As<IServiceRouteFactory>().SingleInstance();\n    //\u6ce8\u518czookeeper\u5ba2\u6237\u7aef\n    builder.RegisterType<ZookeeperClientProvider>().As<IZookeeperClientProvider>().WithParameter(\"configInfo\", configInfo).SingleInstance();\n    return this;\n}", "CodeBleu_score": 47.74649795749005}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    builder.Register(provider => {\n        var logger = provider.GetRequiredService<ILogger<ZooKeeperServiceRouteManager>>();\n        var serializer = provider.GetRequiredService<ISerializer<byte[]>>();\n        var routeFactory = provider.GetRequiredService<IServiceRouteFactory>();\n        var stringSerializer = provider.GetRequiredService<ISerializer<string>>();\n        var clientProvider = provider.GetRequiredService<IZookeeperClientProvider>();\n        return new ZooKeeperServiceRouteManager(clientProvider, logger, serializer, routeFactory, stringSerializer, configInfo);\n    }).As<IServiceRouteManager>().SingleInstance();\n    return this;\n}", "CodeBleu_score": 50.2416084779987}, {"code": "public ZookeeperModule UseZooKeeperRouteManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t    var services = builder.Services;\n    var configuration = builder.Configuration;\n\n    services.Configure<ZooKeeperConfig>(configuration.GetSection(\"ZooKeeper\"));\n    services.AddSingleton<IZookeeperClientProvider, ZookeeperClientProvider>();\n    services.AddSingleton<IRouteManager, ZooKeeperServiceRouteManager>();\n    services.AddSingleton<IServiceRouteFactory, DefaultServiceRouteFactory>();\n    services.AddSingleton<ISerializer<byte[]>, DefaultJsonBytesSerializer>();\n    services.AddSingleton<ISerializer<string>, DefaultJsonStringSerializer>();\n    services.AddSingleton<ILogger<ZooKeeperServiceRouteManager>, EmptyLogger<ZooKeeperServiceRouteManager>>();\n\n    return this;\n}", "CodeBleu_score": 36.133261319385824}]}
{"instance_id": "c30a17587331", "generation_result": [{"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            builder.Register(provider => {\n                var result = new ZookeeperServiceCommandManager(\n                    provider.GetRequiredService<ISerializer<byte[]>>(),\n                    provider.GetRequiredService<ISerializer<string>>(),\n                    provider.GetRequiredService<ILogger<ZookeeperServiceCommandManager>>(),\n                    provider.GetRequiredService<IServiceRouteManager>(),\n                    provider.GetRequiredService<IZookeeperClientProvider>(),\n                    configInfo\n                    );\n                return result;\n            }).SingleInstance();\n            return this;\n        }", "CodeBleu_score": 61.85470690193511}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t            if (configInfo == null)\n                throw new ArgumentNullException(nameof(configInfo));\n            builder.RegisterType(typeof(ZookeeperServiceCommandManager)).As(typeof(IServiceCommandManager))\n                .WithParameter(new TypedParameter(typeof(ConfigInfo), configInfo)).SingleInstance();\n            return this;\n        }", "CodeBleu_score": 28.53546880825739}, {"code": " public ZookeeperModule UseZooKeeperCommandManager(ContainerBuilderWrapper builder, ConfigInfo configInfo){\n\t\n            builder.RegisterType<ZookeeperServiceCommandManager>()\n                .As<IServiceCommandManager>()\n                .WithParameter(TypedParameter.From(configInfo))\n                .SingleInstance();\n            return this;\n        }", "CodeBleu_score": 22.878826711663883}]}
{"instance_id": "213cc4aa9b19", "generation_result": [{"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(string.IsNullOrEmpty(path), \"path must be a non-empty string\");\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n    }\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange,\n        ReloadDelay = TimeSpan.FromSeconds(1)\n    };\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 65.85754707894888}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t    Check.NotNull(builder, nameof(builder));\n    Check.CheckCondition(() => !string.IsNullOrEmpty(path), string.Format(\"The {0} argument must be a non-empty string.\", nameof(path)));\n\n    if (provider == null && Path.IsPathRooted(path)) {\n        provider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n    }\n\n    var source = new ZookeeperConfigurationSource {\n        FileProvider = provider,\n        Path = path,\n        Optional = optional,\n        ReloadOnChange = reloadOnChange\n    };\n\n    builder.Add(source);\n    return builder;\n}", "CodeBleu_score": 70.76976426708713}, {"code": "public static IConfigurationBuilder AddZookeeperFile(this IConfigurationBuilder builder, IFileProvider provider, string path, bool optional, bool reloadOnChange){\n\t\tCheck.NotNull(builder, nameof(builder));\n\tCheck.CheckCondition(string.IsNullOrEmpty(path), \"Zookeeper configuration path must be a rooted path or a relative path starting with a valid provider name.\");\n\n\tif (provider == null && Path.IsPathRooted(path)) {\n\t\tprovider = new PhysicalFileProvider(Path.GetDirectoryName(path));\n\t}\n\n\tvar source = new ZookeeperConfigurationSource {\n\t\tFileProvider = provider,\n\t\tPath = path,\n\t\tOptional = optional,\n\t\tReloadOnChange = reloadOnChange,\n\t\tReloadDelay = TimeSpan.FromSeconds(10)\n\t};\n\n\tbuilder.Add(source);\n\treturn builder;\n}", "CodeBleu_score": 62.45123359567209}]}
{"instance_id": "15bbffa82a13", "generation_result": [{"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t\t// Get the current routes\n\tvar Routes = await GetRoutesAsync();\n\t// Remove the addresses from each route\n\tforeach (var Route in Routes) {\n\t\tRoute.Address.Except(Address);\n\t}\n\t// Update the routes\n\tawait base.SetRoutesAsync(Routes);\n}", "CodeBleu_score": 45.27361074850457}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t  var routes = await GetRoutesAsync();\n  foreach (var route in routes) {\n    route.Address.Except(Address);\n  }\n  await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 62.36481576309893}, {"code": "public override async Task RemveAddressAsync(IEnumerable<AddressModel> Address){\n\t    var routes = await GetRoutesAsync();\n    foreach(var route in routes) {\n        route.Address.RemoveAll(x => Address.Any(y => y.Equals(x)));\n    }\n    await base.SetRoutesAsync(routes);\n}", "CodeBleu_score": 54.370237872865914}]}
{"instance_id": "125d23de2a60", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routeIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeperClients) {\n        var path = _configInfo.RoutePath + \"/\" + zooKeeper.Item1;\n        var oldRouteIds = (await zooKeeper.Item2.getChildrenAsync(path)).ToArray();\n        var newRouteIds = routeIds.Where(i => i.EndsWith(zooKeeper.Item1)).Select(i => i.Remove(i.Length - 8)).ToArray();\n        var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n        foreach (var deletedRouteId in deletedRouteIds) {\n            var addresses = await zooKeeper.Item2.getChildrenAsync($\"{path}/{deletedRouteId}\");\n            if (addresses.Contains(hostAddr.ToString())) {\n                await zooKeeper.Item2.deleteAsync($\"{path}/{deletedRouteId}/{hostAddr}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 51.883236273130585}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var path = _configInfo.RoutePath;\n    var zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n    var oldRouteIds = await zooKeeper.Item1.getChildrenAsync(path);\n    var newRouteIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var deletedRouteIds = oldRouteIds.Except(newRouteIds).ToArray();\n    foreach (var deletedRouteId in deletedRouteIds) {\n        var routePath = $\"{path}{_configInfo.Separator}{deletedRouteId}\";\n        var addresses = (await zooKeeper.Item1.getDataAsync(routePath)).ToArray().ToJson().ToObject<IReadOnlyList<IpAddressModel>>();\n        if (addresses.Contains(hostAddr)) {\n            await zooKeeper.Item2.deleteAsync(routePath);\n        }\n    }\n}", "CodeBleu_score": 46.19822770121647}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<ServiceRoute> routes, AddressModel hostAddr){\n\t    var routeIds = routes.Select(i => i.ServiceDescriptor.Id).ToArray();\n    var zooKeeperClients = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeeperClients) {\n        var path = _configInfo.RoutePath + \"/\" + zooKeeper.Item1;\n        var addresses = (await zooKeeper.Item2.getChildrenAsync(path)).ToArray();\n        var oldRouteIds = addresses.Except(routeIds).ToArray();\n        foreach (var deletedRouteId in oldRouteIds) {\n            var routePath = $\"{path}/{deletedRouteId}\";\n            var routeAddresses = (await zooKeeper.Item2.getChildrenAsync(routePath)).ToArray();\n            if (routeAddresses.Contains(hostAddr.ToString())) {\n                await zooKeeper.Item2.deleteAsync(routePath);\n            }\n        }\n    }\n}", "CodeBleu_score": 46.991953912653734}]}
{"instance_id": "b020a235d57f", "generation_result": [{"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    _logger.LogDebug($\"Retrieved route data:\n{Encoding.UTF8.GetString(data)}\");\n\n    var descriptor = await _serializer.Deserialize(data)\n        .ConfigureAwait(false);\n\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 41.57873892107901}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Getting route from data: {Encoding.UTF8.GetString(data)}\");\n    }\n\n    var descriptor = await _serializer.Deserialize(data);\n    return (await CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 46.29714890854734}, {"code": "private async Task<ServiceRoute> GetRoute(byte[] data){\n\t    if (data == null) {\n        return null;\n    }\n\n    if (_logger.IsEnabled(LogLevel.Debug)) {\n        _logger.LogDebug($\"Received route data: {Encoding.UTF8.GetString(data)}\");\n    }\n\n    var descriptor = JsonConvert.DeserializeObject<ServiceRouteDescriptor>(Encoding.UTF8.GetString(data));\n    return (await _serviceRouteFactory.CreateServiceRoutesAsync(new[] { descriptor })).First();\n}", "CodeBleu_score": 52.699787681712685}]}
{"instance_id": "169ed4cc2ad4", "generation_result": [{"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData))\n        return;\n\n    var newRoute = await _deserializer.Deserialize(newData).ConfigureAwait(false);\n\n    lock (_routesLock) {\n        var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n                        .Concat(new[] { newRoute }).ToArray();\n    }\n\n    await OnChanged(newRoute, oldRoute).ConfigureAwait(false);\n}", "CodeBleu_score": 72.51215863823901}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    if (DataEquals(oldData, newData)) return;\n\n    var newRoute = await _serializer.DeserializeAsync<ServiceRoute>(newData);\n    if (newRoute == null) return;\n\n    var oldRoute = _routes.FirstOrDefault(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id);\n    if (oldRoute == null) return;\n\n    lock (_routesLock) {\n        _routes = _routes\n            .Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n            .Concat(new[] { newRoute }).ToArray();\n    }\n\n    OnChanged(new ServiceRouteChangedEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 84.73097335416779}, {"code": "public async Task NodeChange(byte[] oldData, byte[] newData){\n\t    var oldRoute = _serializer.Deserialize<ServiceRoute>(oldData);\n    var newRoute = _serializer.Deserialize<ServiceRoute>(newData);\n    if (DataEquals(oldRoute, newRoute))\n        return;\n\n    lock (_routesLock) {\n        _routes = _routes.Where(i => i.ServiceDescriptor.Id != newRoute.ServiceDescriptor.Id)\n                        .Concat(new[] { newRoute }).ToArray();\n    }\n\n    await OnChanged(new ServiceRouteChangedEventArgs(newRoute, oldRoute));\n}", "CodeBleu_score": 64.06389530082969}]}
{"instance_id": "af01261d3199", "generation_result": [{"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    if (subscribers == null)\n        throw new ArgumentNullException(nameof(subscribers));\n\n    var serviceSubscribers = await GetSubscribers();\n\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToArray();\n        }\n        else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 65.65799756097107}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await base.GetSubscribersAsync();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToArray();\n        }\n        else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 68.52332263254766}, {"code": "public override async Task SetSubscribersAsync(IEnumerable<ServiceSubscriber> subscribers){\n\t    var serviceSubscribers = await base.GetSubscribersAsync();\n    foreach (var subscriber in subscribers) {\n        var existingSubscriber = serviceSubscribers.Where(p => p.ServiceDescriptor.Id == subscriber.ServiceDescriptor.Id).FirstOrDefault();\n        if (existingSubscriber != null) {\n            existingSubscriber.Address = existingSubscriber.Address.Concat(subscriber.Address.Except(existingSubscriber.Address)).ToList();\n        }\n        else {\n            serviceSubscribers.Add(subscriber);\n        }\n    }\n    await base.SetSubscribersAsync(serviceSubscribers);\n}", "CodeBleu_score": 68.55010315551911}]}
{"instance_id": "fda02cec3296", "generation_result": [{"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t            var subscribers = new List<ServiceSubscriber>();\n            foreach (var child in childrens) {\n                var path = $\"{rootPath}{child}\";\n                _logger.LogDebug($\"Retrieving subscriber information for node: {path}\");\n                var subscriber = await _zookeeper.GetDataAsync<ServiceSubscriber>(path);\n                subscribers.Add(subscriber);\n            }\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 39.95922008048893}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t            if\n_logger.IsEnabled\n            {\n_logger.LogDebug\n            }\n\n            var subscribers = new List<ServiceSubscriber>();\n\n            foreach (var child in childrens) {\n                if\n_logger.IsEnabled\n                {\n_logger.LogDebug\n                }\n\n                var fullPath = GetFullPath(child);\n                var subscriber = await _zooKeeperClient.GetDataAsync<ServiceSubscriber>(fullPath).ConfigureAwait(false);\n\n                subscribers.Add(subscriber);\n            }\n\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 44.936975130490595}, {"code": "private async Task<ServiceSubscriber[]> GetSubscribers(IEnumerable<string> childrens){\n\t\n            var subscribers = new List<ServiceSubscriber>();\n\n            foreach (var child in childrens) {\n                _logger.LogDebug(\"Retrieving subscriber information for child {Child}.\", child);\n                var fullPath = $\"{_rootPath}{child}\";\n                var subscriber = await _zookeeperClient.GetDataAsync<ServiceSubscriber>(fullPath);\n                subscribers.Add(subscriber);\n            }\n\n            return subscribers.ToArray();\n        }", "CodeBleu_score": 41.375539931996606}]}
{"instance_id": "6c3018ff0c0d", "generation_result": [{"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var zooKeeper = await GetZooKeeper();\n    if (zooKeeper.Item1.WaitOne(zooKeeper.Item2.SessionTimeout)) {\n        var result = await zooKeeper.Item2.existsAsync(_subscriberPath);\n        if (result.ResultCode == KeeperException.Code.OK) {\n            var children = (await zooKeeper.Item2.getChildrenAsync(_subscriberPath)).Children.ToArray();\n            _subscribers = await Task.WhenAll(children.Select(c => GetSubscriber(c)));\n        } else {\n            _logger.LogWarning($\"The path {_subscriberPath} does not exist.\");\n            _subscribers = Array.Empty<Subscriber>();\n        }\n    } else {\n        _logger.LogWarning(\"Unable to connect to ZooKeeper.\");\n        _subscribers = Array.Empty<Subscriber>();\n    }\n}", "CodeBleu_score": 51.767826170773}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var zooKeeper = await GetZooKeeper();\n    await zooKeeper.Item2.existsAsync(SubscribersPath);\n    if (zooKeeper.Item2.getChildrenAsync(SubscribersPath).Result.Children.ToArray().Length == 0) {\n        _logger.LogWarning(\"Subscribers path {0} does not exist. Setting _subscribers to an empty array.\", SubscribersPath);\n        _subscribers = Array.Empty<Subscriber>();\n    } else {\n        _subscribers = await GetSubscribers(zooKeeper);\n    }\n}", "CodeBleu_score": 49.72279877329826}, {"code": "private async Task EnterSubscribers(){\n\t    if (_subscribers != null) {\n        return;\n    }\n    var zooKeeper = await GetZooKeeper();\n    var result = await zooKeeper.Item2.existsAsync(SubscriberPath);\n    if (result.ResultCode == KeeperException.Code.OK) {\n        var children = await zooKeeper.Item2.getChildrenAsync(SubscriberPath);\n        var subscribers = await Task.WhenAll(children.Children.Select(GetSubscriber));\n        _subscribers = subscribers.ToArray();\n    }\n    else {\n        _logger.LogWarning(\"Subscriber path {SubscriberPath} does not exist\", SubscriberPath);\n        _subscribers = Array.Empty<Subscriber>();\n    }\n}", "CodeBleu_score": 49.66867448710081}]}
{"instance_id": "60ff973ba60a", "generation_result": [{"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t            var oldCommand = ServiceCommand.FromData(oldData);\n            var newCommand = ServiceCommand.FromData(newData);\n            if (oldCommand.ServiceId != newCommand.ServiceId) {\n                throw new InvalidOperationException(\"The service ID of the new command must be the same as the old one.\");\n            }\n            if (oldCommand.Equals(newCommand)) {\n                return;\n            }\n            lock (this) {\n                var commands = this.commands.Where(i => i.ServiceId != newCommand.ServiceId).ToArray();\n                commands = commands.Concat(new[] { newCommand }).ToArray();\n                this.commands = commands;\n            }\n            this.OnChanged?.Invoke(newCommand, oldCommand);\n        }", "CodeBleu_score": 47.99307152275705}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t            var oldCommand = ParseServiceCommand(oldData);\n            var newCommand = ParseServiceCommand(newData);\n            if (oldCommand != null && newCommand != null && oldCommand.ServiceId != newCommand.ServiceId) {\n                // \u30b5\u30fc\u30d3\u30b9ID\u304c\u5909\u308f\u3063\u305f\u5834\u5408\u306f\u3001\u53e4\u3044\u30b5\u30fc\u30d3\u30b9ID\u306e\u30b3\u30de\u30f3\u30c9\u3092\u524a\u9664\u3059\u308b\n                ServiceCommands = ServiceCommands.Where(i => i.ServiceId != oldCommand.ServiceId).ToArray();\n            }\n            if (oldCommand != null && newCommand != null && oldCommand.DataEquals(newCommand)) {\n                // \u30b5\u30fc\u30d3\u30b9\u30b3\u30de\u30f3\u30c9\u304c\u5909\u308f\u3063\u3066\u3044\u306a\u3044\u5834\u5408\u306f\u4f55\u3082\u3057\u306a\u3044\n                return;\n            }\n            if (newCommand != null) {\n                // \u65b0\u3057\u3044\u30b5\u30fc\u30d3\u30b9\u30b3\u30de\u30f3\u30c9\u3092\u8ffd\u52a0\u3059\u308b\n                ServiceCommands = ServiceCommands.Where(i => i.ServiceId \n!= newCommand.ServiceId)\n                        .Concat(new[] { newCommand }).ToArray();\n            }\n            // \u30b5\u30fc\u30d3\u30b9\u30b3\u30de\u30f3\u30c9\u5909\u66f4\u30a4\u30d9\u30f3\u30c8\u3092\u767a\u751f\u3055\u305b\u308b\n            OnChanged(oldCommand, newCommand);\n        }", "CodeBleu_score": 61.67481769076636}, {"code": "public void NodeChange(byte[] oldData, byte[] newData){\n\t            var oldCommand = GetServiceCommand(oldData);\n            var newCommand = GetServiceCommand(newData);\n            if (oldCommand != newCommand) {\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219\u66f4\u65b0\u547d\u4ee4\u5217\u8868\u3002\n                // \u5982\u679c\u65b0\u65e7\u547d\u4ee4\u4e0d\u540c\uff0c\u5219", "CodeBleu_score": 14.575001179952334}]}
{"instance_id": "4597b75f2b3d", "generation_result": [{"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    var zooKeeper = _zooKeeperCall();\n    var currentData = _watcher.CurrentData;\n    var newData = await zooKeeper.Item2.getDataAsync(watchedEvent.getPath(), true);\n    _watcher.SetCurrentData(newData.Item1);\n    _action(currentData, newData.Item1);\n}", "CodeBleu_score": 47.49453341810607}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        var zooKeeperCall = _zooKeeperCall();\n        var currentData = watchedEvent.get_Data();\n        var newData = await zooKeeperCall.Item2.getDataAsync(zooKeeperCall.Item1, zooKeeperCall.Item2).ConfigureAwait(false);\n        _action(currentData, newData);\n        _watcher.SetCurrentData(newData);\n    }\n}", "CodeBleu_score": 29.929110739917963}, {"code": "protected override async Task ProcessImpl(WatchedEvent watchedEvent){\n\t    if (watchedEvent.get_Type() == EventType.NodeDataChanged) {\n        var zooKeeper = _zooKeeperCall();\n        var currentData = _watcher.GetCurrentData();\n        var newData = await zooKeeper.Item2.getDataAsync(watchedEvent.get_Path(), true).ConfigureAwait(false);\n        _action(currentData, newData);\n        _watcher.SetCurrentData(newData);\n    }\n}", "CodeBleu_score": 30.04402878433622}]}
{"instance_id": "cb4f0e22a0d5", "generation_result": [{"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    if (builder == null) {\n        throw new ArgumentNullException(nameof(builder));\n    }\n    if (configInfo == null) {\n        throw new ArgumentNullException(nameof(configInfo));\n    }\n    if (string.IsNullOrEmpty(configInfo.ConnectionString)) {\n        throw new ArgumentNullException(nameof(configInfo.ConnectionString));\n    }\n    var provider = builder.Services;\n    provider.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 73.30960227522183}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 91.7811603739314}, {"code": "public static IServiceBuilder UseZookeeperClientProvider(this IServiceBuilder builder, ConfigInfo configInfo){\n\t    builder.Services.Register(provider =>\n        new DefaultZookeeperClientProvider(\n            GetConfigInfo(configInfo),\n            provider.Resolve<IHealthCheckService>(),\n            provider.Resolve<IZookeeperAddressSelector>(),\n            provider.Resolve<ILogger<DefaultZookeeperClientProvider>>())).As<IZookeeperClientProvider>().SingleInstance();\n    return builder;\n}", "CodeBleu_score": 91.7811603739314}]}
{"instance_id": "80709a4b2b69", "generation_result": [{"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    _logger.LogInformation($\"Setting {routes.Count()} routes.\");\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        await zooKeeper.CreateNodeAsync(\n            _confi\n\n", "CodeBleu_score": 10.383708794502597}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n\n    foreach (var zooKeeper in zooKeepers) {\n        try {\n            var routePath = _configInfo.RoutePath;\n            var rootPath = _configInfo.RootPath;\n\n            if (!await zooKeeper.ExistsAsync(rootPath)) {\n                await zooKeeper.CreateAsync(rootPath, rootPath.ToUtf8Bytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n\n            if (!await zooKeeper.ExistsAsync(routePath)) {\n                await zooKeeper.CreateAsync(routePath, routePath.ToUtf8Bytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n\n            foreach (var serviceRoute in routes) {\n                var nodePath = $\"{routePath}/{serviceRoute.Id}\";\n                if (await zooKeeper.ExistsAsync(nodePath)) {\n                    var bytes = (await zooKeeper.GetDataAsync(nodePath)).ToArray();\n                    var route = bytes.FromUtf8Bytes<MqttServiceDescriptor>();\n                    if (route.Address != serviceRoute.Address || route.Port != serviceRoute.Port) {\n                        await zooKeeper.SetDataAsync(nodePath, serviceRoute.ToUtf8Bytes());\n                        _logger.LogInformation($\"Set route {serviceRoute.Id} => {serviceRoute.Address}:{serviceRoute.Port}\");\n                    }\n                }\n                else {\n                    await zooKeeper.CreateAsync(nodePath, serviceRoute.ToUtf8Bytes(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.EPHEMERAL);\n                    _logger.LogInformation($\"Add route {serviceRoute.Id} => {serviceRoute.Address}:{serviceRoute.Port}\");\n                }\n            }\n        }\n        catch (Exception ex) {\n            _logger.LogError(ex, $\"Set route to zookeeper {zoo", "CodeBleu_score": 53.46300813266812}, {"code": "protected override async Task SetRoutesAsync(IEnumerable<MqttServiceDescriptor> routes){\n\t    var zooKeeper = await _zooKeeperProvider.GetZooKeeperAsync();\n    var serviceRoutes = routes as MqttServiceDescriptor[] ?? routes.ToArray();\n\n    _logger.LogInformation($\"\u51c6\u5907\u6dfb\u52a0\u8def\u7531\uff0c\u5171{serviceRoutes.Length}\u6761\");\n\n    foreach (var serviceRoute in serviceRoutes) {\n        var nodePath = $\"{_configInfo.RoutePath}{serviceRoute.Id}\";\n        if (await zooKeeper.existsAsync(nodePath) == null) {\n            _logger.LogInformation($\"\u8282\u70b9\uff1a{nodePath}\u4e0d\u5b58\u5728\uff0c\u8fdb\u884c\u521b\u5efa...\");\n            await zooKeeper.createAsync(nodePath, Data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            _logger.LogInformation($\"\u8282\u70b9\uff1a{nodePath}\u521b\u5efa\u6210\u529f\");\n        }\n\n        var onlineData = _mqttServiceRouteFactory.Create(serviceRoute);\n        var onlineBytes = _serializer.Serialize(onlineData);\n        if (await zooKeeper.existsAsync($\"{nodePath}/{_configInfo.OnlineDataIdentifier}\") == null) {\n            _logger.LogInformation($\"\u8282\u70b9\uff1a{nodePath}/{_configInfo.OnlineDataIdentifier}\u4e0d\u5b58\u5728\uff0c\u8fdb\u884c\u521b\u5efa...\");\n            await zooKeeper.createAsync($\"{nodePath}/{_configInfo.OnlineDataIdentifier}\", onlineBytes, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            _logger.LogInformation($\"\u8282\u70b9\uff1a{nodePath}/{_configInfo.OnlineDataIdentifier}\u521b\u5efa\u6210\u529f\");\n        }\n        else {\n            var updateResult = await zooKeeper.setDataAsync($\"{nodePath}/{_configInfo.OnlineDataIdentifier}\", onlineBytes);\n            _logger.LogInformation($\"\u8def\u7531\u6570\u636e\u66f4\u65b0\u6210\u529f\uff0c\u8282\u70b9\uff1a{nodePath}/{_configInfo.OnlineDataIdentifier}\");\n        }\n    }\n\n    _logger.LogInformation(\"\u8def\u7531\u6dfb\u52a0\u6210\u529f\");", "CodeBleu_score": 56.799552187977696}]}
{"instance_id": "69ff4d3427cd", "generation_result": [{"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    var zooKeeper = _zookeeperClientProvider.GetZooKeepers();\n    foreach (var (item1, item2) in zooKeeper) {\n        foreach (var deletedRouteTopic in deletedRouteTopics) {\n            var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n            if (deletedRoute != null && deletedRoute.Addresses.Contains(hostAddr)) {\n                await item2.deleteAsync($\"{_configInfo.MqttRoutePath}{deletedRouteTopic}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 60.003247676331206}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    // 1.\n    var oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    // 2.\n    var zooKeeper = await _zookeeperClientProvider.GetZooKeepers();\n    foreach (var topic in deletedRouteTopics) {\n        var addresses = _routes.Where(p => p.MqttDescriptor.Topic == topic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (addresses != null && addresses.Contains(hostAddr)) {\n            await zooKeeper.Item2.deleteAsync($\"{_configInfo.MqttRoutePath}/{topic}\");\n        }\n    }\n}", "CodeBleu_score": 53.146003832962265}, {"code": "private async Task RemoveExceptRoutesAsync(IEnumerable<MqttServiceRoute> routes, AddressModel hostAddr){\n\t    var oldRouteTopics = _routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var newRouteTopics = routes.Select(i => i.MqttDescriptor.Topic).ToArray();\n    var deletedRouteTopics = oldRouteTopics.Except(newRouteTopics).ToArray();\n    foreach (var deletedRouteTopic in deletedRouteTopics) {\n        var deletedRoute = _routes.Where(p => p.MqttDescriptor.Topic == deletedRouteTopic).Select(p => p.MqttEndpoint).FirstOrDefault();\n        if (deletedRoute != null && deletedRoute.Addresses.Contains(hostAddr)) {\n            var zooKeeper = _zookeeperClientProvider.GetZooKeepers().FirstOrDefault();\n            if (zooKeeper != null) {\n                await zooKeeper.Item2.deleteAsync($\"{_configInfo.RoutePath}{deletedRouteTopic}\");\n            }\n        }\n    }\n}", "CodeBleu_score": 57.00496759100937}]}
{"instance_id": "8856055e4872", "generation_result": [{"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\n        \"Setting caches for service descriptors: {cacheDescriptors}\",\n        cacheDescriptors);\n\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        var cachePath = _zooKeeperPaths.GetCachePath();\n        await zooKeeper.CreateIfNotExistsAsync(cachePath, Array.Empty<byte>(), ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var nodePath = _zooKeeperPaths.GetCacheDescriptorPath(cacheDescriptor.ServiceName);\n            var data = Serialize(cacheDescriptor);\n            if (await istsAsync(nodePath) == null) {\n                await zooKeeper.CreateAsync(nodePath, data, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            } else if (!DataEquals(nodeData, data)) {\n                await zooKeeper.SetDataAsync(nodePath, data);\n            }\n        }\n    }\n\n    _logger.LogInformation(\n        \"Successfully set caches for service descriptors: {cacheDescriptors}\",\n        cacheDescriptors);\n}", "CodeBleu_score": 45.80186566327335}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    var cacheDescriptorArray = cacheDescriptors.ToArray();\n\n    if (!cacheDescriptorArray.Any()) {\n        return;\n    }\n\n    var nodePath = await GetCachePathAsync();\n\n    _logger.LogInformation(\n        \"Setting {CacheDescriptorCount} caches for service {ServiceId} at {NodePath}\",\n        cacheDescriptorArray.Length,\n        _serviceId,\n        nodePath);\n\n    foreach (var zooKeeper in _zooKeeperProvider.GetZooKeepers()) {\n        await EnsurePathAsync(zooKeeper, nodePath);\n\n        foreach (var cacheDescriptor in cacheDescriptorArray) {\n            var cacheDescriptorPath = $\"{nodePath}/{cacheDescriptor.CacheId}\";\n            var cacheDescriptorBytes = Serialize(cacheDescriptor);\n\n            if (await istsAsync(zooKeeper, cacheDescriptorPath) == null) {\n                await CreateNodeAsync(\n                    zooKeeper,\n                    cacheDescriptorPath,\n                    cacheDescriptorBytes,\n                    ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                    CreateMode.PERSISTENT);\n            } else if (!DataEquals(await GetDataAsync(zooKeeper, cacheDescriptorPath), cacheDescriptorBytes)) {\n                await SetDataAsync(zooKeeper, cacheDescriptorPath, cacheDescriptorBytes);\n            }\n        }\n    }\n\n    _logger.LogInformation(\n        \"Successfully set {CacheDescriptorCount} caches for service {ServiceId} at {NodePath}\",\n        cacheDescriptorArray.Length,\n        _serviceId,\n        nodePath);\n}", "CodeBleu_score": 46.292999572823824}, {"code": "public override async Task SetCachesAsync(IEnumerable<ServiceCacheDescriptor> cacheDescriptors){\n\t    _logger.LogInformation(\"Setting caches\");\n    var zooKeepers = _zooKeeperProvider.GetZooKeepers();\n    foreach (var zooKeeper in zooKeepers) {\n        await zooKeeper.CreateAsync(\n            path: _confi\n            createParents: true,\n            mode: ZooDefs.Ids.OPEN_ACL_UNSAFE,\n            data: new byte[0]\n        );\n\n        foreach (var cacheDescriptor in cacheDescriptors) {\n            var cachePath = $\"{_confi\n            var data = JsonConvert.SerializeObject(cacheDescriptor);\n            var nodePath = $\"{cachePath}/{cacheDescriptor.ServiceName}\";\n            if (await zooKeeper.ExistsAsync(nodePath) == null) {\n                await zooKeeper.CreateAsync(\n                    path: nodePath,\n                    createParents: true,\n                    mode: ZooDefs.Ids.OPEN_ACL_UNSAFE,\n                    data: data\n                );\n            } else {\n                var existingData = (await zooKeeper.GetDataAsync(nodePath)).ToArray();\n                if (!DataEquals(existingData, data)) {\n                    await zooKeeper.SetDataAsync(nodePath, data);\n                }\n            }\n        }\n    }\n\n    _logger.LogInformation(\"Successfully set caches\");\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n", "CodeBleu_score": 48.97755521806732}]}
{"instance_id": "57d92c17de83", "generation_result": [{"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    _logger.LogInformation($\"Waiting for the Zookeeper client to be ready\");\n    zooKeeper.Item1.WaitOne();\n    _logger.LogInformation($\"Checking if the path {path} exists\");\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation($\"Creating the path {path}\");\n        var pathParts = path.Split('/');\n        var currentPath = \"\";\n        for (var i = 1; i < pathParts.Length; i++) {\n            currentPath += \"/\" + pathParts[i];\n            _logger.LogInformation($\"Creating subdirectory {currentPath}\");\n            await zooKeeper.Item2.createAsync(currentPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n        }\n    }\n}", "CodeBleu_score": 56.41655768426299}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    _logger.LogInformation(\"Waiting for manual reset event\");\n    zooKeeper.Item1.WaitOne();\n    _logger.LogInformation(\"Checking if path exists\");\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation(\"Path does not exist\");\n        string[] pathParts = path.Split('/');\n        string subdirectoryPath = \"\";\n        for (int i = 1; i < pathParts.Length; i++) {\n            subdirectoryPath += \"/\" + pathParts[i];\n            _logger.LogInformation(\"Checking if subdirectory path exists\");\n            if (await zooKeeper.Item2.existsAsync(subdirectoryPath) == null) {\n                _logger.LogInformation(\"Subdirectory path does not exist\");\n                _logger.LogInformation(\"Creating subdirectory path\");\n                await zooKeeper.Item2.createAsync(subdirectoryPath, null, ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 50.60532883948441}, {"code": "private async Task CreateSubdirectory((ManualResetEvent, ZooKeeper) zooKeeper, string path){\n\t    zooKeeper.Item1.WaitOne();\n    if (await zooKeeper.Item2.existsAsync(path) == null) {\n        _logger.LogInformation(\"Creating node path {Path}\", path);\n        var pathParts = path.Split('/');\n        var nodePath = \"\";\n        foreach (var pathPart in pathParts) {\n            nodePath += \"/\" + pathPart;\n            if (await zooKeeper.Item2.existsAsync(nodePath) == null) {\n                await zooKeeper.Item2.createAsync(nodePath, new byte[0], ZooDefs.Ids.OPEN_ACL_UNSAFE, CreateMode.PERSISTENT);\n            }\n        }\n    }\n}", "CodeBleu_score": 60.26480772642723}]}
{"instance_id": "b276a07da453", "generation_result": [{"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _addresses) {\n        var healthCheckResult = await _healthCheckService.IsHealth(address);\n        if (healthCheckResult) {\n            var zooKeeper = CreateZooKeeper(address);\n            result.Add((zooKeeper.WaitHandle, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 73.27017926178465}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    var tasks = new List<Task>();\n    foreach (var address in _zooKeeperAddresses) {\n        var healthCheckTask = _healthCheckService.IsHealth(address);\n        tasks.Add(healthCheckTask);\n        healthCheckTask.ContinueWith(async task => {\n            var isHealth = task.Result;\n            if (isHealth) {\n                var zooKeeper = await CreateZooKeeper(address);\n                result.Add((new ManualResetEvent(false), zooKeeper));\n            }\n        });\n    }\n    await Task.WhenAll(tasks);\n    return result;\n}", "CodeBleu_score": 62.979727082061544}, {"code": "public async ValueTask<IEnumerable<(ManualResetEvent, ZooKeeper)>> GetZooKeepers(){\n\t    var result = new List<(ManualResetEvent, ZooKeeper)>();\n    foreach (var address in _zooKeeperAddresses) {\n        var healthCheckResult = await _healthCheckService.IsHealth(address);\n        if (healthCheckResult.IsHealthy) {\n            var zooKeeper = CreateZooKeeper(address);\n            result.Add((healthCheckResult.ResetEvent, zooKeeper));\n        }\n    }\n    return result;\n}", "CodeBleu_score": 72.11357854577304}]}
{"instance_id": "dbb6463e7ee8", "generation_result": [{"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    if (zooKeeper == null) {\n        synchronized (this) {\n            if (zooKeeper == null) {\n                zooKeeper = newZooKeeper();\n            }\n        }\n    }\n    return zooKeeper;\n}", "CodeBleu_score": 23.234651361629687}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t    synchronized (this) {\n        if (zk == null) {\n            zk = newZooKeeper();\n        }\n        return zk;\n    }\n}", "CodeBleu_score": 16.83156755220737}, {"code": "ZooKeeper getZooKeeper() throws Exception{\n\t\tsynchronized(this) {\n\t\tif (zooKeeper == null) {\n\t\t\tzooKeeper = newZooKeeper();\n\t\t}\n\t\treturn zooKeeper;\n\t}\n}", "CodeBleu_score": 11.626648689545231}]}
{"instance_id": "0d9f311aa482", "generation_result": [{"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    if (zk == null) {\n        return;\n    }\n\n    Watcher dummyWatcher = new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            // ignore\n        }\n    };\n\n    try {\n        zk.register(dummyWatcher);\n        zk.close();\n        if (waitForShutdownTimeoutMs > 0) {\n            zk.waitForShutdown(waitForShutdownTimeoutMs);\n        }\n    } catch (InterruptedException e) {\n        Thread.currentThread().interrupt();\n    } finally {\n        zk = null;\n    }\n}", "CodeBleu_score": 47.806324189492486}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    if (zooKeeper == null) {\n        return;\n    }\n    ZooKeeper oldZooKeeper = zooKeeper;\n    zooKeeper = null;\n    oldZooKeeper.register(new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            // do nothing\n        }\n    });\n    oldZooKeeper.close();\n    if (waitForShutdownTimeoutMs > 0) {\n        try {\n            oldZooKeeper.waitForShutdown(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        }\n    }\n}", "CodeBleu_score": 37.81423893462025}, {"code": "private void internalClose(int waitForShutdownTimeoutMs) throws Exception{\n\t    if (zk != null) {\n        try {\n            // We use a dummy watcher to clear the default watcher, preventing new events from being processed\n            zk.register(new Watcher() {\n                @Override\n                public void process(WatchedEvent event) {\n                }\n            });\n            if (waitForShutdownTimeoutMs > 0) {\n                zk.close(waitForShutdownTimeoutMs);\n            } else {\n                zk.close();\n            }\n        } catch (InterruptedException e) {\n            Thread.currentThread().interrupt();\n        }\n    }\n}", "CodeBleu_score": 41.80824611267603}]}
{"instance_id": "d57ef4592303", "generation_result": [{"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    // Start tracing the connection process\n    startAdvancedTracer();\n\n    // Check if the client is started\n    if (!isStarted()) {\n        // Log the error and return false\n        logError(\"The client is not started\");\n        return false;\n    }\n\n    // Log the start of the operation\n    logInfo(\"Blocking execution until the client is connected or a timeout occurs\");\n\n    // Block execution until the client is connected or a timeout occurs\n    internalBlockUntilConnectedOrTimedOut();\n\n    // Check if the client is connected\n    if (!isConnected()) {\n        // Log the error and return false\n        logError(\"The client is not connected\");\n        return false;\n    }\n\n    // Log the end of the operation\n    logInfo(\"The client is connected\");\n\n    // Return true\n    return true;\n}", "CodeBleu_score": 30.12135212415547}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    final String operation = \"blockUntilConnectedOrTimedOut\";\n    logger.entering(CLASS_NAME, operation);\n\n    boolean isConnected = false;\n    long startTime = System.currentTimeMillis();\n    long currentTime = startTime;\n    long timeout = startTime + connectionTimeout;\n    while (currentTime < timeout) {\n        if (isConnected()) {\n            isConnected = true;\n            break;\n        }\n        Thread.sleep(100);\n        currentTime = System.currentTimeMillis();\n    }\n\n    logger.exiting(CLASS_NAME, operation, isConnected);\n    return isConnected;\n}", "CodeBleu_score": 33.94378503162485}, {"code": "public boolean blockUntilConnectedOrTimedOut() throws InterruptedException{\n\t    if (isConnected()) {\n        return true;\n    }\n\n    if (!isStarted()) {\n        throw new IllegalStateException(\"Client is not started.\");\n    }\n\n    if (this.isConnectedOrTimedOut.get()) {\n        return true;\n    }\n\n    this.logger.info(\"blockUntilConnectedOrTimedOut: start\");\n    this.isConnectedOrTimedOut.block();\n    this.logger.info(\"blockUntilConnectedOrTimedOut: end\");\n\n    return this.isConnectedOrTimedOut.get();\n}", "CodeBleu_score": 32.79349340427659}]}
{"instance_id": "d722f6d0beb6", "generation_result": [{"code": "public void close(int waitForShutdownTimeoutMs){\n\t    log.info(\"Shutting down service...\");\n    this.started.set(false);\n    try {\n        this.executor.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        log.error(\"Interrupted while waiting for executor to terminate.\", e);\n        Thread.currentThread().interrupt();\n    }\n}", "CodeBleu_score": 36.80193703794139}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    log.info(\"Shutting down service\");\n    started = false;\n    try {\n        closeResources();\n        executor.shutdown();\n        executor.awaitTermination(waitForShutdownTimeoutMs, TimeUnit.MILLISECONDS);\n    } catch (InterruptedException e) {\n        log.warn(\"Shutdown interrupted\");\n        checkInterrupted();\n    } catch (IOException e) {\n        log.error(\"Error closing service\", e);\n        checkInterrupted();\n    }\n}", "CodeBleu_score": 38.98644919987152}, {"code": "public void close(int waitForShutdownTimeoutMs){\n\t    if (this.started) {\n        this.started = false;\n        try {\n            this.serverSocket.close();\n        } catch (IOException e) {\n            if (Thread.currentThread().isInterrupted()) {\n                this.logger.warn(\"Interrupted while closing server socket.\", e);\n            } else {\n                this.logger.error(\"Error while closing server socket.\", e);\n            }\n        }\n    }\n}", "CodeBleu_score": 29.781810105657257}]}
{"instance_id": "8492e37ce46e", "generation_result": [{"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    final int timeout = 5000;\n    final int sleepTime = 100;\n    final int maxSleeps = timeout / sleepTime;\n    int sleeps = 0;\n    while (sleeps++ < maxSleeps && !isConnected()) {\n        Thread.sleep(sleepTime);\n    }\n}", "CodeBleu_score": 10.18377245373197}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t    if (isConnected()) {\n        return;\n    }\n\n    long waitTime = connectionTimeout;\n    long startTime = System.currentTimeMillis();\n    long endTime = startTime + waitTime;\n    long currentTime = startTime;\n    long remainingTime = waitTime;\n    CountDownLatch latch = new CountDownLatch(1);\n\n    Watcher watcher = new Watcher() {\n        @Override\n        public void process(WatchedEvent event) {\n            if (event.getState() == Event.KeeperState.SyncConnected) {\n                latch.countDown();\n            }\n        }\n    };\n\n    addWatcher(watcher);\n    while (!isConnected() && currentTime < endTime) {\n        latch.await(remainingTime, TimeUnit.MILLISECONDS);\n        currentTime = System.currentTimeMillis();\n        remainingTime = endTime - currentTime;\n    }\n    removeWatcher(watcher);\n}", "CodeBleu_score": 46.03427423377917}, {"code": "public void internalBlockUntilConnectedOrTimedOut() throws InterruptedException {\n\t\tlong startTime = System.currentTimeMillis();\n\tlong remainingTime = this.connectionTimeout;\n\tlong endTime = startTime + remainingTime;\n\tCountDownLatch countDownLatch = new CountDownLatch(1);\n\twhile (true) {\n\t\tif (this.isConnected()) {\n\t\t\tbreak;\n\t\t}\n\t\tif (System.currentTimeMillis() >= endTime) {\n\t\t\tbreak;\n\t\t}\n\t\tif (remainingTime <= 0) {\n\t\t\tbreak;\n\t\t}\n\t\tthis.addConnectionWatcher(countDownLatch);\n\t\tcountDownLatch.await(remainingTime, TimeUnit.MILLISECONDS);\n\t\tcountDownLatch.countDown();\n\t\tthis.removeConnectionWatcher(countDownLatch);\n\t\tremainingTime = endTime - System.currentTimeMillis();\n\t}\n}", "CodeBleu_score": 25.8225625345871}]}
{"instance_id": "4a01f5365731", "generation_result": [{"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode.isEphemeral()) {\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client.getSessionId();\n        client", "CodeBleu_score": 17.28514307665905}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode.isEphemeral()) {\n        if (client.getSessionId() != client.getZooKeeper().getSessionId()) {\n            client.logError(\"Session has changed\");\n            client.getFailedDeleteManager().addFailedDelete(foundNode);\n            client.getZooKeeper().delete(foundNode, -1);\n            client.setSessionId(client.getZooKeeper().getSessionId());\n        }\n    }\n    return foundNode;\n}", "CodeBleu_score": 29.214019640965}, {"code": "String validateFoundNode(CuratorFrameworkImpl client, CreateMode createMode, String foundNode) throws Exception{\n\t    if (createMode.isEphemeral()) {\n        String sessionId = client.getSessionId();\n        String oldNode = client.getFailedDeleteManager().getAndClearOldNode(foundNode);\n        if (oldNode != null) {\n            client.logError(\"Session has changed. Old ephemeral node: \" + oldNode);\n            client.delete().forPath(oldNode);\n        }\n        if (oldNode == null && sessionId != null) {\n            client.getFailedDeleteManager().addFailedDelete(foundNode);\n        }\n        client.getZooKeeper().getSessionId();\n    }\n    return foundNode;\n}", "CodeBleu_score": 41.01905789307385}]}
{"instance_id": "126d0922a699", "generation_result": [{"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final Trace trace = getTrace();\n    trace.startAdvancedTrace(\"setACL\");\n    trace.addAttribute(\"path\", path);\n\n    Stat stat = null;\n    boolean isDone = false;\n    int retryCount = 0;\n    while (!isDone) {\n        try {\n            stat = getZooKeeper().setACL(path, aclList, -1);\n            isDone = true;\n        } catch (Exception e) {\n            retryCount++;\n            if (retryCount > 3) {\n                throw e;\n            }\n            Thread.sleep(retryCount * 1000);\n        }\n    }\n\n    trace.addAttribute(\"status\", stat);\n    trace.commitAdvancedTrace();\n    return stat;\n}", "CodeBleu_score": 31.10479913657553}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final Trace trace = getTracer().startAdvancedTrace(\"Set ACL for \" + path, \"ZooKeeper\");\n    final Stat stat = new Stat();\n\n    // Retry loop\n    boolean success = false;\n    for (int retry = 0; retry < 3; retry++) {\n        try {\n            stat.setAcl(getZooKeeper().setACL(path, aclList, stat.getAversion()));\n            success = true;\n            break;\n        } catch (KeeperException.BadVersionException e) {\n            // Version conflict\n            trace.addInfo(\"Retrying because of version conflict\");\n        }\n    }\n\n    // Commit trace\n    trace.setStatus(success ? Trace.SUCCESS : Trace.FAILURE);\n    trace.addInfo(\"Path\", path);\n    trace.addInfo(\"ACL\", aclList);\n    trace.commit();\n\n    return stat;\n}", "CodeBleu_score": 32.36414903437228}, {"code": "private Stat pathInForeground(final String path, final List<ACL> aclList) throws Exception{\n\t    final Trace trace = getTracer().buildSpan(\"setACL\").start();\n    final Scope scope = getTracer().activateSpan(trace);\n    trace.setTag(\"path\", path);\n    trace.setTag(\"aclList\", aclList);\n    trace.setTag(\"operation\", \"setACL\");\n    trace.setTag(\"span.kind\", \"client\");\n    trace.setTag(\"component\", \"zookeeper\");\n    trace.setTag(\"peer.service\", \"zookeeper\");\n\n    Stat stat = null;\n    boolean isDone = false;\n    int retryCount = 0;\n    while (!isDone) {\n        try {\n            stat = getZooKeeper().setACL(path, aclList, -1);\n            isDone = true;\n        } catch (final Exception e) {\n            retryCount++;\n            trace.setTag(\"error\", true);\n            trace.setTag(\"retryCount\", retryCount);\n            trace.setTag(\"error.object\", e);\n            trace.setTag(\"error.message\", e.getMessage());\n            trace.log(ImmutableMap.of(\"event\", \"error\", \"error.object\", e));\n\n            // retry logic\n            if (retryCount > 3) {\n                throw e;\n            }\n        }\n    }\n\n    trace.finish();\n    scope.close();\n    return stat;\n}", "CodeBleu_score": 33.99881946310833}]}
{"instance_id": "e07b079ff61f", "generation_result": [{"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t  checkNotNull(client, \"client cannot be null\");\n  checkNotNull(membershipPath, \"membershipPath cannot be null\");\n  checkNotNull(thisId, \"thisId cannot be null\");\n  checkNotNull(payload, \"payload cannot be null\");\n  this.client = client;\n  this.membershipPath = membershipPath;\n  this.thisId = thisId;\n  this.payload = payload;\n  this.cache = CuratorCache.builder(client, membershipPath).build();\n  this.cache.start();\n  this.member = new PersistentNode(client, PersistentNode.Mode.EPHEMERAL, membershipPath, payload);\n  this.member.start();\n}", "CodeBleu_score": 49.97116365801003}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    Preconditions.checkNotNull(client, \"client cannot be null\");\n    Preconditions.checkNotNull(membershipPath, \"membershipPath cannot be null\");\n    Preconditions.checkNotNull(thisId, \"thisId cannot be null\");\n    Preconditions.checkNotNull(payload, \"payload cannot be null\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    if (thisId.contains(\"/\")) {\n        throw new IllegalArgumentException(\"thisId cannot contain a /\");\n    }\n\n    // Set up a CuratorCache for the membership path\n    this.cache = CuratorCache.build(client, membershipPath);\n    this.cache.listenable().addListener(this);\n    this.cache.start();\n\n    // Create a PersistentNode with ephemeral mode for the member using the provided payload\n    this.member = new PersistentNode(client, PersistentNode.Mode.EPHEMERAL, membershipPath + \"/\" + thisId, payload);\n}", "CodeBleu_score": 48.0459492123157}, {"code": "public GroupMember(CuratorFramework client, String membershipPath, String thisId, byte[] payload){\n\t    checkNotNull(client, \"client\");\n    checkNotNull(membershipPath, \"membershipPath\");\n    checkNotNull(thisId, \"thisId\");\n    checkNotNull(payload, \"payload\");\n\n    this.client = client;\n    this.membershipPath = membershipPath;\n    this.thisId = thisId;\n    this.payload = payload;\n\n    this.cache = CuratorCache.build(client, membershipPath);\n    this.cache.listenable().addListener(this);\n\n    this.member = new PersistentNode(client, PersistentNode.Mode.EPHEMERAL, membershipPath, payload);\n}", "CodeBleu_score": 45.865665255784776}]}
{"instance_id": "d11c76b2b912", "generation_result": [{"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).inBackground(\n        (CuratorFramework cf, CuratorEvent event) -> {\n            handleWatchedStage(cf, event);\n        }).forPath(path);\n}", "CodeBleu_score": 25.711988750187498}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).inBackground(\n        (CuratorFramework cf, CuratorEvent event) -> {\n            handleWatchedStage(cf, event);\n        }\n    ).forPath(path);\n}", "CodeBleu_score": 26.073595772292148}, {"code": "public static void createThenWatch(CuratorFramework client, String path) {\n\t    client.create().creatingParentsIfNeeded().withMode(CreateMode.EPHEMERAL).inBackground(\n        (CuratorFramework cf, CuratorEvent ce) -> {\n            if (ce.getResultCode() == KeeperException.Code.OK.intValue()) {\n                handleWatchedStage(client, path);\n            } else {\n                System.out.println(\"Exception during node creation: \" + ce.getResultCode());\n                System.out.println(ce.getPath() + \": \" + new String(ce.getData()));\n            }\n        }\n    ).forPath(path, \"\".getBytes());\n}", "CodeBleu_score": 37.632323718443885}]}
{"instance_id": "4571de52ad5d", "generation_result": [{"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = zooKeeper.multi(ops);\n    OpResult result = results.get(0);\n    if (result instanceof OpResult.ErrorResult) {\n        OpResult.ErrorResult errorResult = (OpResult.ErrorResult) result;\n        throw KeeperException.create(KeeperException.Code.get(errorResult.getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 34.41148582511389}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = getZooKeeper().multi(multi);\n    if (results.get(0).getErr() != 0) {\n        throw KeeperException.create(KeeperException.Code.get(results.get(0).getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 18.41802827889906}, {"code": "private List<OpResult> doOperation() throws Exception{\n\t    List<OpResult> results = zooKeeper.multi(operations);\n    OpResult result = results.get(0);\n    if (result instanceof OpResult.ErrorResult) {\n        OpResult.ErrorResult errorResult = (OpResult.ErrorResult) result;\n        throw KeeperException.create(KeeperException.Code.get(errorResult.getErr()));\n    }\n    return results;\n}", "CodeBleu_score": 34.704628660452194}]}
{"instance_id": "99263700ce6d", "generation_result": [{"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        List<String> serviceNames = serviceDiscovery.queryForNames().get();\n        for (String serviceName : serviceNames) {\n            print(serviceName);\n            List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName).get();\n            for (ServiceInstance<InstanceDetails> instance : instances) {\n                outputInstance(instance);\n            }\n        }\n    } catch (ExecutionException e) {\n        if (e.getCause() instanceof NoNodeException) {\n            println(\"No instances registered\");\n        } else {\n            throw e;\n        }\n    }\n    closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 57.402380284153665}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t    try {\n        List<String> serviceNames = serviceDiscovery.queryForNames().get();\n        for (String serviceName : serviceNames) {\n            List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(serviceName).get();\n            println(\"Instances for serviceName \" + serviceName + \" are:\");\n            for (ServiceInstance<InstanceDetails> instance : instances) {\n                outputInstance(instance);\n            }\n        }\n    } catch (ExecutionException e) {\n        if (e.getCause() instanceof NoNodeException) {\n            println(\"No instances are registered\");\n        } else {\n            throw e;\n        }\n    }\n    closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 54.496270820993956}, {"code": "private static void listInstances(ServiceDiscovery<InstanceDetails> serviceDiscovery) throws Exception{\n\t  try {\n    List<String> serviceNames = serviceDiscovery.queryForNames().get();\n    for (String name : serviceNames) {\n      List<ServiceInstance<InstanceDetails>> instances = serviceDiscovery.queryForInstances(name).get();\n      println(name + \" has \" + instances.size() + \" instances\");\n      for (ServiceInstance<InstanceDetails> instance : instances) {\n        outputInstance(instance);\n      }\n    }\n  } catch (ExecutionException e) {\n    if (e.getCause() instanceof NoNodeException) {\n      println(\"No service names have been registered\");\n    } else {\n      throw e;\n    }\n  }\n  closeQuietly(serviceDiscovery);\n}", "CodeBleu_score": 52.5928497752208}]}
{"instance_id": "891a390fa04d", "generation_result": [{"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children\n        .stream()\n        .filter({ child -> !child.equals(READY_NODE) })\n        .sorted()\n        .collect(Collectors.toList())\n}", "CodeBleu_score": 17.872032800431192}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream()\n        .filter(child -> !child.equals(READY_NODE))\n        .sorted()\n        .collect(Collectors.toList());\n}", "CodeBleu_score": 17.147894291902148}, {"code": "private List<String> filterAndSortChildren(List<String> children){\n\t    return children.stream()\n        .filter(c -> !c.equals(READY_NODE))\n        .sorted()\n        .collect(Collectors.toList());\n}", "CodeBleu_score": 16.732422596743074}]}
{"instance_id": "f25af95a13b6", "generation_result": [{"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n\n    zk = new ZooKeeper(newHost, timeout, this);\n}", "CodeBleu_score": 21.433614360947157}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t    if (zk != null) {\n        zk.close();\n    }\n    zk = new ZooKeeper(newHost, timeout, this);\n}", "CodeBleu_score": 21.433614360947157}, {"code": "protected void connectToZK(String newHost) throws InterruptedException, IOException{\n\t  if (zk != null) {\n    LOG.debug(\"Closing current ZooKeeper connection \" + zk);\n    zk.close();\n  }\n  LOG.debug(\"Opening new ZooKeeper connection to \" + newHost);\n  zk = new ZooKeeper(newHost, timeout, this);\n  if (getOption(\"readonly\")) {\n    zk.setAcl(rootZnode, ZooDefs.Ids.OPEN_ACL_UNSAFE, -1);\n    zk.addAuthInfo(\"digest\", \"pat:test\".getBytes());\n  }\n}", "CodeBleu_score": 33.03391397965578}]}
{"instance_id": "269eaac5cec6", "generation_result": [{"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acl;\n    if (aclString.charAt(0) != '[') {\n        throw new IOException(\"Missing ACL start token. Expected '[' at the beginning.\");\n    } else if (aclString.charAt(aclString.length() - 1) != ']') {\n        throw new IOException(\"Missing ACL end token. Expected ']' at the end.\");\n    }\n    aclString = aclString.substring(1, aclString.length() - 1);\n    if (aclString.isEmpty()) {\n        throw new IOException(\"Empty ACL string\");\n    }\n    acl = new ArrayList<ACL>();\n    String[] aclItems = aclString.split(\",\");\n    for (String aclItem : aclItems) {\n        String[] aclParts = aclItem.split(\":\");\n        if (aclParts.length != 3) {\n            LOG.error(\"Invalid ACL format: \" + aclItem);\n            continue;\n        }\n        ACL newAcl = new ACL();\n        newAcl.setId(new Id(aclParts[0], aclParts[1]));\n        newAcl.setPerms(getPermFromString(aclParts[2]));\n        acl.add(newAcl);\n    }\n    return acl;\n}", "CodeBleu_score": 39.23515328384314}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acl;\n    if (aclString.charAt(0) == '[') {\n        aclString = aclString.substring(1, aclString.length() - 1);\n    }\n    StringTokenizer st = new StringTokenizer(aclString, \",\");\n    acl = new ArrayList<ACL>();\n    while (st.hasMoreTokens()) {\n        String s = st.nextToken().trim();\n        int firstColon = s.indexOf(':');\n        int lastColon = s.lastIndexOf(':');\n        if (firstColon == -1 || lastColon == -1 || firstColon == lastColon) {\n            LOG.error(\"Error: unexpected ACL string format: \" + s);\n            continue;\n        }\n        ACL newAcl = new ACL();\n        newAcl.setId(new Id(s.substring(0, firstColon), s.substring(firstColon + 1, lastColon)));\n        newAcl.setPerms(getPermFromString(s.substring(lastColon + 1)));\n        acl.add(newAcl);\n    }\n    return acl;\n}", "CodeBleu_score": 60.319768220320434}, {"code": "private List<ACL> parseACLs(String aclString) throws IOException{\n\t    List<ACL> acl;\n    if (aclString.charAt(0) == '[') {\n        aclString = aclString.substring(1, aclString.length() - 1);\n    }\n    acl = new ArrayList<ACL>();\n    String[] aclEntries = aclString.split(\",\");\n    for (String aclEntry : aclEntries) {\n        int firstColon = aclEntry.indexOf(':');\n        int lastColon = aclEntry.lastIndexOf(':');\n        if (firstColon == -1 || lastColon == -1 || firstColon == lastColon) {\n            LOG.error(\"Error parsing ACL entry: \" + aclEntry);\n            continue;\n        }\n        ACL newAcl = new ACL();\n        newAcl.setId(new Id(aclEntry.substring(0, firstColon), aclEntry.substring(firstColon + 1, lastColon)));\n        newAcl.setPerms(getPermFromString(aclEntry.substring(lastColon + 1)));\n        acl.add(newAcl);\n    }\n    return acl;\n}", "CodeBleu_score": 63.764470749150284}]}
{"instance_id": "c25db637a176", "generation_result": [{"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    requireNonNull(pathList);\n    assertZookeeperExists(serverId);\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(serverId, path);\n        }\n    } else {\n        deleteAsync(serverId, pathList);\n    }\n}", "CodeBleu_score": 63.54515055365175}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    assertZookeeperExists(serverId);\n    if (pathList != null && !pathList.isEmpty()) {\n        if (pathList.size() < 20) {\n            for (String path : pathList) {\n                get(serverId).delete(path, -1);\n            }\n        } else {\n            for (String path : pathList) {\n                deleteAsync(serverId, path);\n            }\n        }\n    }\n}", "CodeBleu_score": 68.58282050430091}, {"code": "public void delete(String serverId, List<String> pathList) throws Exception{\n\t    assertZookeeperExists(serverId);\n    if (pathList == null || pathList.isEmpty()) {\n        return;\n    }\n    if (pathList.size() < 20) {\n        for (String path : pathList) {\n            delete(serverId, path);\n        }\n    } else {\n        for (String path : pathList) {\n            deleteAsync(serverId, path);\n        }\n    }\n}", "CodeBleu_score": 66.19454578002923}]}
{"instance_id": "3ecb1ce78f90", "generation_result": [{"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t  writer.write(\"Connecting to Zookeeper instance at \" + url + \"\n\");\n  CuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory(url);\n  connectionFactory.setTimeout(30000);\n  connectionFactory.setRetryPolicy(new RetryNTimes(5, 1000));\n  connectionFactory.setSessionTimeout(10000);\n  CuratorFramework connection = connectionFactory.newConnection();\n  connection.start();\n  connection.blockUntilConnected();\n  writer.write(\"Successfully connected to Zookeeper instance at \" + url + \"\n\");\n  ZooKeeper client = connection.getZookeeperClient().getZooKeeper();\n  return new Terminal(id, url, connection, new ZooKeeperMain(client));\n}", "CodeBleu_score": 36.02579131812694}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t  writer.write(\"Connecting to Zookeeper instance at \" + url + \"...\n\");\n  CuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory(url);\n  CuratorFramework connection = connectionFactory.create();\n  connection.start();\n  ZooKeeper zooKeeper = connection.getZookeeperClient().getZooKeeper();\n  writer.write(\"Connected to Zookeeper instance at \" + url + \".\n\");\n  ZooKeeperMain zooKeeperMain = new ZooKeeperMain(zooKeeper);\n  return new Terminal(id, url, connection, zooKeeperMain);\n}", "CodeBleu_score": 42.30500375114277}, {"code": "public Terminal createTerminal(String id, String url, StringWriter writer) throws Exception{\n\t    writer.write(\"Connecting to Zookeeper instance at \" + url + \".\n\");\n    CuratorZookeeperConnectionFactory connectionFactory = new CuratorZookeeperConnectionFactory(url);\n    Connection connection = connectionFactory.create();\n    ZooKeeper client = connection.getClient();\n    writer.write(\"Successfully connected to Zookeeper instance at \" + url + \".\n\");\n    ZooKeeperMain main = new ZooKeeperMain(client);\n    return new Terminal(id, url, connection, main);\n}", "CodeBleu_score": 40.46880070267468}]}
{"instance_id": "a3606e777eb5", "generation_result": [{"code": "public void blockUntilConnected(){\n\t    int retries = 0;\n    while (!isConnected()) {\n        try {\n            connect();\n        } catch (Exception e) {\n            log.error(\"Exception while trying to connect to SSH tunnel.\", e);\n            close();\n            throw new IllegalStateException(\"Failed to connect to SSH tunnel.\", e);\n        }\n        if (retries > 6) {\n            close();\n            throw new IllegalStateException(\"Failed to connect to SSH tunnel.\");\n        }\n        retries++;\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            log.error(\"Interrupted while trying to connect to SSH tunnel.\", e);\n        }\n    }\n}", "CodeBleu_score": 41.69525500490121}, {"code": "public void blockUntilConnected(){\n\t    int attempts = 0;\n    while (!isConnected()) {\n        try {\n            connect();\n            attempts++;\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(e);\n        }\n        if (attempts > 6) {\n            close();\n            throw new IllegalStateException(\"Failed to establish a connection after 6 attempts.\");\n        }\n        sleep(1000);\n    }\n}", "CodeBleu_score": 47.02803279581911}, {"code": "public void blockUntilConnected(){\n\t    int retry = 0;\n    while (retry < 6) {\n        try {\n            if (!isConnected()) {\n                open();\n            }\n            if (isConnected()) {\n                break;\n            }\n        } catch (Exception e) {\n            close();\n            throw new IllegalStateException(\"Failed to establish SSH tunnel connection\", e);\n        }\n        retry++;\n        log.info(\"Failed to establish SSH tunnel connection. Retrying in 1 second. Attempt #\" + retry);\n        try {\n            Thread.sleep(1000);\n        } catch (InterruptedException e) {\n            log.error(\"Failed to sleep\", e);\n        }\n    }\n    if (retry == 6) {\n        close();\n        throw new IllegalStateException(\"Failed to establish SSH tunnel connection after 6 attempts\");\n    }\n}", "CodeBleu_score": 44.431995477703666}]}
{"instance_id": "a4e5b886b72b", "generation_result": [{"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        LOG.error(\"Failed to delete node\", e);\n        throw new IllegalStateException(e);\n    }\n}", "CodeBleu_score": 84.30292324654613}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"Failed to delete Zookeeper node\", e);\n        throw new IllegalStateException(\"Failed to delete Zookeeper node\", e);\n    }\n}", "CodeBleu_score": 66.9378806963991}, {"code": "public void deleteNode(String serverId, List<String> pathList){\n\t    try {\n        zookeeperDomainService.deleteNode(serverId, pathList);\n    } catch (Exception e) {\n        logger.error(\"Error deleting nodes from Zookeeper\", e);\n        throw new IllegalStateException(\"Error deleting nodes from Zookeeper\", e);\n    }\n}", "CodeBleu_score": 66.0212454904792}]}
{"instance_id": "4fdbc9ec2e75", "generation_result": [{"code": "public void disconnect(String id){\n\t    runLater(() -> {\n        ServerConfiguration server = getById(id);\n        if (server == null) {\n            return;\n        }\n        server.disconnect();\n        remove(server);\n    });\n}", "CodeBleu_score": 30.815515900078832}, {"code": "public void disconnect(String id){\n\t    runLater(() -> {\n        Server server = getById(id);\n        if (server != null) {\n            server.disconnect();\n            remove(server);\n        }\n    });\n}", "CodeBleu_score": 27.207206682948204}, {"code": "public void disconnect(String id){\n\t    Platform.runLater(() -> {\n        try {\n            ServerConfiguration server = getById(id);\n            if (server != null) {\n                server.disconnect();\n                remove(server);\n            }\n        } catch (Exception e) {\n            LOGGER.error(\"Failed to disconnect from Zookeeper\", e);\n        }\n    });\n}", "CodeBleu_score": 36.312289148793774}]}
{"instance_id": "6bf0d7ac9390", "generation_result": [{"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId);\n    String url = getTerminalUrl(server);\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 20.883714512267517}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverService.getById(serverId);\n    String url = server.getSshTunnelEnabled() ? \"ssh://\" + server.getHost() + \":\" + server.getPort() : \"tcp://\" + server.getHost() + \":\" + server.getPort();\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 45.286603650064414}, {"code": "public void startTerminal(String serverId, StringWriter stream){\n\t    Server server = serverRepository.getById(serverId);\n    String url = server.getSshTunnelEnabled() ?\n        \"ssh://\" + server.getHost() + \":\" + server.getPort() :\n        \"telnet://\" + server.getHost() + \":\" + server.getPort();\n    zookeeperDomainService.startTerminal(serverId, url, stream);\n}", "CodeBleu_score": 46.978057821592984}]}
{"instance_id": "635dea120e55", "generation_result": [{"code": "public void executeCommand(String id, String command){\n\t    try {\n        execute(id, command);\n    } catch (Exception e) {\n        log.error(\"Error while executing command \" + command + \" on server \" + id, e);\n        display(\"Command execution failed. Please retry.\");\n    }\n}", "CodeBleu_score": 55.41037549986453}, {"code": "public void executeCommand(String id, String command){\n\t    try {\n        execute(id, command);\n    } catch (Exception e) {\n        System.out.println(\"Command execution failed. Please try again.\");\n        log.error(\"Error executing command \" + command + \" on Zookeeper server \" + id, e);\n    }\n}", "CodeBleu_score": 54.762106028408176}, {"code": "public void executeCommand(String id, String command){\n\t  try {\n    execute(id, command);\n  } catch (Exception e) {\n    println \"Command execution failed for server \" + id + \" and command \" + command + \". Retrying...\";\n    error(id, command);\n  }\n}", "CodeBleu_score": 55.17507479851492}]}
{"instance_id": "8627d161f5fc", "generation_result": [{"code": "public Properties loadZookeeperSystemProperties(){\n\t\tdef zookeeperProperties = new Properties()\n\tdef zookeeperPropertiesFile = new File(ZOOKEEPER_SYSTEM_PROPERTIES_FILE)\n\tif (zookeeperPropertiesFile.exists()) {\n\t\ttry {\n\t\t\tzookeeperProperties.load(new FileInputStream(zookeeperPropertiesFile))\n\t\t\tlog.info(\"Loaded Zookeeper system properties from ${ZOOKEEPER_SYSTEM_PROPERTIES_FILE}\")\n\t\t\tlog.info(\"Zookeeper system properties: ${zookeeperProperties}\")\n\t\t} catch (IOException e) {\n\t\t\tlog.error(\"Error loading Zookeeper system properties from ${ZOOKEEPER_SYSTEM_PROPERTIES_FILE}\")\n\t\t}\n\t} else {\n\t\tlog.error(\"Zookeeper system properties file does not exist at ${ZOOKEEPER_SYSTEM_PROPERTIES_FILE}\")\n\t}\n\treturn zookeeperProperties\n}", "CodeBleu_score": 40.217386961625216}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    def props = new Properties()\n    def file = new File(System.getProperty(\"zookeeper.properties.file\"))\n    if (file.exists()) {\n        try {\n            props.load(new FileInputStream(file))\n            log.info(\"Loaded Zookeeper system properties from ${file.absolutePath}\")\n        } catch (IOException e) {\n            log.error(\"Error loading Zookeeper system properties from ${file.absolutePath}: ${e.message}\")\n        }\n    } else {\n        log.error(\"No Zookeeper system properties file found at ${file.absolutePath}\")\n    }\n    return props\n}", "CodeBleu_score": 39.316346791639575}, {"code": "public Properties loadZookeeperSystemProperties(){\n\t    def propertiesFile = new File(System.getProperty(\"user.home\") + \"/zookeeper.properties\")\n    Properties properties = new Properties()\n    if (propertiesFile.exists()) {\n        try {\n            properties.load(new FileInputStream(propertiesFile))\n            log.info(\"Loaded zookeeper properties from \" + propertiesFile.getAbsolutePath())\n        } catch (IOException e) {\n            log.error(\"Failed to load zookeeper properties from \" + propertiesFile.getAbsolutePath())\n            properties = new Properties()\n        }\n    } else {\n        log.info(\"No zookeeper properties file found at \" + propertiesFile.getAbsolutePath())\n        properties = new Properties()\n    }\n    return properties\n}", "CodeBleu_score": 39.68723116865325}]}
{"instance_id": "dce20e143e04", "generation_result": [{"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n        properties.store(new FileOutputStream(SYS_PROP_PATH), \"Zookeeper system properties\");\n        getInfo().showNotification(\"Zookeeper system properties saved to \" + SYS_PROP_PATH);\n    } catch (IOException e) {\n        getInfo().showNotification(\"Failed to save Zookeeper system properties to \" + SYS_PROP_PATH);\n        getInfo().showError(e);\n    }\n}", "CodeBleu_score": 25.787181246094733}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties props = new Properties();\n    try {\n        props.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Failed to load Zookeeper system properties from content\", e);\n        showNotification(\"Failed to load Zookeeper system properties from content\", e);\n        return;\n    }\n    try {\n        props.store(new FileOutputStream(SYS_PROP_PATH), \"\");\n    } catch (IOException e) {\n        log.error(\"Failed to save Zookeeper system properties to file\", e);\n        showNotification(\"Failed to save Zookeeper system properties to file\", e);\n    }\n}", "CodeBleu_score": 31.506803380497345}, {"code": "public void saveZookeeperSystemProperties(String content){\n\t    Properties properties = new Properties();\n    try {\n        properties.load(new StringReader(content));\n    } catch (IOException e) {\n        log.error(\"Could not load properties from content\", e);\n        showNotification(\"Could not load properties from content\");\n        return;\n    }\n\n    try {\n        properties.store(new FileOutputStream(SYS_PROP_PATH), null);\n    } catch (IOException e) {\n        log.error(\"Could not save properties to file\", e);\n        showNotification(\"Could not save properties to file\");\n        return;\n    }\n}", "CodeBleu_score": 33.45992655271674}]}
{"instance_id": "d89f8e6bfb31", "generation_result": [{"code": "private String response(Socket client){\n\t    BufferedReader reader;\n    StringBuilder builder = new StringBuilder();\n    try {\n        reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        String line;\n        while ((line = reader.readLine()) != null) {\n            builder.append(line);\n        }\n        client.close();\n    } catch (IOException e) {\n        throw new IllegalStateException(\"Error reading response\", e);\n    }\n    return builder.toString();\n}", "CodeBleu_score": 57.64519925938315}, {"code": "private String response(Socket client){\n\t    BufferedReader reader = null;\n    StringBuilder response = new StringBuilder();\n    try {\n        reader = new BufferedReader(new InputStreamReader(client.getInputStream()));\n        String line;\n        while ((line = reader.readLine()) != null) {\n            response.append(line);\n        }\n        return response.toString();\n    } catch (IOException e) {\n        throw new IllegalStateException(\"Error reading from socket\", e);\n    } finally {\n        cleanup(reader, client);\n    }\n}", "CodeBleu_score": 59.29621871874039}, {"code": "private String response(Socket client){\n\t  BufferedReader in = null;\n  StringBuilder response = new StringBuilder();\n  try {\n    in = new BufferedReader(new InputStreamReader(client.getInputStream()));\n    String line;\n    while ((line = in.readLine()) != null) {\n      response.append(line);\n    }\n    return response.toString();\n  } catch (IOException e) {\n    throw new IllegalStateException(e);\n  } finally {\n    if (in != null) {\n      try {\n        in.close();\n      } catch (IOException e) {\n        throw new IllegalStateException(e);\n      }\n    }\n  }\n}", "CodeBleu_score": 54.639767546607956}]}
{"instance_id": "b0a277c5e3c0", "generation_result": [{"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = CuratorFrameworkFactory.builder()\n            .connectString(params.getConnectionString())\n            .retryPolicy(new ExponentialBackoffRetry(1000, 3))\n            .build();\n    client.start();\n    try {\n        blockUntilConnected(client, 5, TimeUnit.SECONDS);\n    } catch (InterruptedException | TimeoutException e) {\n        client.close();\n        throw new RuntimeException(e);\n    }\n    return new CuratorZookeeperConnection(client, params.getNamespace());\n}", "CodeBleu_score": 45.69172512015386}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = CuratorFrameworkFactory.builder()\n        .connectString(params.getConnectString())\n        .retryPolicy(new RetryNTimes(params.getRetryCount(), params.getRetryWaitMs()))\n        .build();\n    client.start();\n    try {\n        client.blockUntilConnected(5, TimeUnit.SECONDS);\n    } catch (InterruptedException | TimeoutException e) {\n        client.close();\n        throw new RuntimeException(\"Failed to connect to Zookeeper\", e);\n    }\n    return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 51.890280340776094}, {"code": "public ZookeeperConnection<CuratorFramework> create(ZookeeperParams params){\n\t    CuratorFramework client = CuratorFrameworkFactory.builder()\n        .connectString(params.getConnectString())\n        .retryPolicy(new RetryNTimes(params.getRetryCount(), params.getRetryWaitMs()))\n        .build();\n\n    client.start();\n    try {\n        blockUntilConnected(client, params.getConnectionTimeoutMs(), TimeUnit.MILLISECONDS);\n    } catch (InterruptedException | TimeoutException e) {\n        close(client);\n        throw new RuntimeException(e);\n    }\n\n    return new CuratorZookeeperConnection(client, params);\n}", "CodeBleu_score": 44.81973887642718}]}
{"instance_id": "b144bcd67462", "generation_result": [{"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getCurrentConnectionString();\n    if (this.zookeeperSyncInProgress.putIfAbsent(connectionString, Boolean.TRUE) == null) {\n        log.debug(\"Starting Zookeeper synchronization for connection string: {}\", connectionString);\n        CuratorTreeCacheListener listener = new CuratorTreeCacheListener() {\n            @Override\n            public void childEvent(CuratorFramework client, TreeCacheEvent event) throws Exception {\n                log.debug(\"Zookeeper event: {}\", event);\n                if (event.getType() == TreeCacheEvent.Type.NODE_ADDED || event.getType() == TreeCacheEvent.Type.NODE_REMOVED || event.getType() == TreeCacheEvent.Type.NODE_UPDATED) {\n                    String path = event.getData().getPath();\n                    log.debug(\"Zookeeper path: {}\", path);\n                    for (ZookeeperNodeListener listener : listeners) {\n                        listener.nodeChanged(path);\n                    }\n                }\n            }\n        };\n        try {\n            this.treeCache.getListenable().addListener(listener);\n            this.treeCache.start();\n        } catch (Exception e) {\n            log.error(\"Error starting Zookeeper synchronization\", e);\n            try {\n                this.treeCache.close();\n            } catch (IOException ioe) {\n                log.error(\"Error closing Zookeeper synchronization\", ioe);\n            }\n        }\n    } else {\n        log.info(\"Zookeeper synchronization already in progress for connection string: {}\", connectionString);\n    }\n}", "CodeBleu_score": 40.42941516999764}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getCurrentConnectionString();\n    if (connectionString == null) {\n        return;\n    }\n    if (isSyncInProgress(connectionString)) {\n        LOG.info(\"Synchronization already in progress for \" + connectionString);\n        return;\n    }\n    LOG.debug(\"Starting synchronization for \" + connectionString);\n    CuratorFramework client = getZookeeperClient(connectionString);\n    TreeCache cache = new TreeCache(client, \"/\");\n    CuratorListener listener = new CuratorListener(cache, listeners);\n    cache.getListenable().addListener(listener);\n    try {\n        cache.start();\n    } catch (Exception e) {\n        LOG.error(\"Error starting synchronization for \" + connectionString, e);\n        try {\n            cache.close();\n        } catch (IOException e1) {\n            LOG.error(\"Error closing cache for \" + connectionString, e1);\n        }\n    }\n}", "CodeBleu_score": 40.840117008814616}, {"code": "public void sync(List<ZookeeperNodeListener> listeners){\n\t    String connectionString = getZookeeperClient().getCurrentConnectionString();\n    if (getListenable().getCurrentlySyncing().contains(connectionString)) {\n        logger.info(\"Synchronization already in progress for connection string: \" + connectionString);\n        return;\n    }\n    logger.debug(\"Starting synchronization for connection string: \" + connectionString);\n    getListenable().getCurrentlySyncing().add(connectionString);\n    try {\n        for (ZookeeperNodeListener listener : listeners) {\n            get().addListener(listener);\n        }\n        get().start();\n    } catch (Exception e) {\n        logger.error(\"Error synchronizing Zookeeper nodes\", e);\n        close();\n    }\n}", "CodeBleu_score": 43.358521823393744}]}
{"instance_id": "6452f272f2d7", "generation_result": [{"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(client, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 73.84492591071368}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache cache = new PathChildrenCache(zkClient, path, true);\n    cache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    cache.getListenable().addListener(listener);\n}", "CodeBleu_score": 61.61525132234349}, {"code": "public void watchPathChildrenNode(String path, PathChildrenCacheListener listener) throws Exception{\n\t    PathChildrenCache childrenCache = new PathChildrenCache(client, path, true);\n    childrenCache.start(PathChildrenCache.StartMode.BUILD_INITIAL_CACHE);\n    childrenCache.getListenable().addListener(listener);\n}", "CodeBleu_score": 76.48205891453128}]}
{"instance_id": "17f786e147c3", "generation_result": [{"code": "public void unregisterService(){\n\t  info(\"Unregistering services\");\n  for (String path : paths) {\n    try {\n      deletePath(path);\n    } catch (Exception e) {\n      error(getMessage(e));\n    }\n  }\n  close();\n}", "CodeBleu_score": 34.95468944291773}, {"code": "public void unregisterService(){\n\t    logger.info(\"Unregistering services...\");\n    for (String path : paths) {\n        try {\n            deletePath(path);\n        } catch (Exception e) {\n            logger.error(getMessage(e));\n        }\n    }\n    close();\n}", "CodeBleu_score": 49.560826760808254}, {"code": "public void unregisterService(){\n\t    logger.info(\"Unregistering service\");\n    for (String path : paths) {\n        try {\n            deletePath(path);\n        } catch (Exception e) {\n            logger.error(getMessage(e));\n        }\n    }\n    close();\n}", "CodeBleu_score": 50.887038839717405}]}
{"instance_id": "32fec6cfa353", "generation_result": [{"code": "public void addListener(IZkStateListener listener){\n\t    makeClientReady().whenComplete((zkClient, throwable) -> {\n        if (throwable == null) {\n            subscribeStateChanges(listener);\n        } else {\n            LOG.error(\"Unable to add listener to Zookeeper client\", throwable);\n        }\n    });\n}", "CodeBleu_score": 32.95726781151951}, {"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture.runAsync(() -> makeClientReady())\n        .exceptionally(e -> {\n            LOG.error(\"Error while making client ready\", e);\n            return null;\n        })\n        .thenRun(() -> subscribeStateChanges(listener));\n}", "CodeBleu_score": 19.9303947766785}, {"code": "public void addListener(IZkStateListener listener){\n\t    CompletableFuture.runAsync(this::makeClientReady)\n            .thenRun(() -> subscribeStateChanges(listener));\n}", "CodeBleu_score": 13.184573698084574}]}
{"instance_id": "619d57562a76", "generation_result": [{"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    this.serverAddr = serverAddr;\n    this.authority = authority;\n    this.client = CuratorFrameworkFactory.newClient(serverAddr, new ExponentialBackoffRetry(1000, 3));\n    this.client.getConnectionTimeoutMs();\n    if (authority != null) {\n        this.client.getAuthScheme();\n    }\n    this.client.getConnectionStateListenable().addListener(this);\n    this.client.start();\n    try {\n        this.client.blockUntilConnected();\n    } catch (InterruptedException e) {\n        throw new IllegalStateException(\"Failed to connect to Zookeeper server: \" + serverAddr, e);\n    }\n}", "CodeBleu_score": 20.418022299038725}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    // Initialize the CuratorFramework client\n    client = CuratorFrameworkFactory.builder()\n        .connectString(serverAddr)\n        .connectionTimeoutMs(1000)\n        .retryPolicy(new RetryNTimes(5, 1000))\n        .authorization(authority != null ? \"digest:\" + authority : null)\n        .build();\n\n    // Set up a listener to handle connection state changes\n    client.getConnectionStateListenable().addListener(this);\n\n    // Start the client\n    client.start();\n\n    // Handle any exceptions that may have occurred during initialization\n    if (client.getState() == CuratorFrameworkState.LATENT) {\n        throw new IllegalStateException(\"Failed to initialize Curator client\");\n    }\n}", "CodeBleu_score": 30.142995972150743}, {"code": "public CuratorZookeeperClient(String serverAddr, String authority){\n\t    // Initialize the CuratorFramework client\n    this.client = CuratorFrameworkFactory.newClient(serverAddr, new ExponentialBackoffRetry(1000, 3));\n\n    // Set up a retry policy and connection timeout\n    this.client.getCuratorListenable().addListener(this);\n    this.client.getConnectionStateListenable().addListener(this);\n    this.client.getUnhandledErrorListenable().addListener(this);\n\n    // Set up optional authentication\n    if (authority != null) {\n        this.client.getAuthSchemeBuilder().digest(authority.getBytes());\n    }\n\n    // Start the client and check for exceptions\n    this.client.start();\n    if (!this.client.getZookeeperClient().blockUntilConnectedOrTimedOut()) {\n        throw new IllegalStateException(\"Zookeeper client failed to connect\");\n    }\n}", "CodeBleu_score": 19.449822417036895}]}
{"instance_id": "9e7fb18946e4", "generation_result": [{"code": "public void removeChildListener(String path, ChildListener listener){\n\t    if (listener == null) {\n        return;\n    }\n    if (path == null) {\n        return;\n    }\n    if (path.isEmpty()) {\n        return;\n    }\n    synchronized (listeners) {\n        List<ChildListener> childListeners = listeners.get(path);\n        if (childListeners == null) {\n            return;\n        }\n        if (!childListeners.remove(listener)) {\n            return;\n        }\n        if (childListeners.isEmpty()) {\n            listeners.remove(path);\n        }\n        removeTargetChildListener(path, listener);\n    }\n}", "CodeBleu_score": 46.41978766906841}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> childListenerMap = childListenerMap.get(path);\n    if (childListenerMap == null) {\n        return;\n    }\n    TargetChildListener targetChildListener = childListenerMap.remove(listener);\n    if (targetChildListener == null) {\n        return;\n    }\n    targetChildListener.remove();\n    if (childListenerMap.size() == 0) {\n        childListenerMap.remove(path);\n    }\n}", "CodeBleu_score": 50.174952784565306}, {"code": "public void removeChildListener(String path, ChildListener listener){\n\t    Map<ChildListener, TargetChildListener> listenerMap = childListeners.get(path);\n    if (listenerMap != null) {\n        TargetChildListener targetListener = listenerMap.remove(listener);\n        if (targetListener != null) {\n            removeTargetChildListener(path, targetListener);\n        }\n    }\n}", "CodeBleu_score": 82.28136100742057}]}
{"instance_id": "2c3fae642654", "generation_result": [{"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t  int rc = 0;\n  idc_host_info_t *host_info = NULL;\n  char *idc_host = NULL;\n  if (zh == NULL) {\n    return ZCONNECTIONLOSS;\n  }\n  host_info = (idc_host_info_t *)zoo_get_context(zh);\n  if (host_info == NULL) {\n    return ZCONNECTIONLOSS;\n  }\n  idc_host = host_info->idc_host;\n  if (idc_host == NULL) {\n    return ZCONNECTIONLOSS;\n  }\n  zookeeper_close(zh);\n  rc = deserialize_from_idc_host(idc_host, &host_info);\n  if (rc != ZOK) {\n    return rc;\n  }\n  rc = init_env_for_zk(host_info, &zh);\n  if (rc != ZOK) {\n    return rc;\n  }\n  if (host_info->table_watcher != NULL) {\n    rc = host_info->table_watcher(host_info->table_watcher_ctx, zh, ZOO_SESSION_EVENT, NULL);\n    if (rc != ZOK) {\n      return rc;\n    }\n  }\n  return ZOK;\n}", "CodeBleu_score": 29.91464839618502}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t  int rc;\n  char *idc_host;\n  char *idc_host_port;\n  char *host_port;\n  char *idc_host_port_copy;\n  char *host_port_copy;\n  struct String_vector hosts;\n  struct String_vector *hosts_ptr;\n  int hosts_count;\n  int i;\n\n  if (zh == NULL) {\n    return ZCONNECTIONLOSS;\n  }\n\n  idc_host = (char *)zoo_get_context(zh);\n  if (idc_host == NULL) {\n    return ZCONNECTIONLOSS;\n  }\n\n  idc_host_port = strdup(idc_host);\n  if (idc_host_port == NULL) {\n    free(idc_host);\n    return ZSYSTEMERROR;\n  }\n\n  host_port = strchr(idc_host_port, ':');\n  if (host_port == NULL) {\n    free(idc_host_port);\n    free(idc_host);\n    return ZSYSTEMERROR;\n  }\n  *host_port = '\\0';\n  host_port++;\n\n  idc_host_port_copy = strdup(idc_host_port);\n  if (idc_host_port_copy == NULL) {\n    free(idc_host_port);\n    free(idc_host);\n    return ZSYSTEMERROR;\n  }\n\n  host_port_copy = strdup(host_port);\n  if (host_port_copy == NULL) {\n    free(idc_host_port_copy);\n    free(idc_host_port);\n    free(idc_host);\n    return ZSYSTEMERROR;\n  }\n\n  zookeeper_close(zh);\n\n  hosts_ptr = &hosts;\n  rc = deserialize_from_idc_host(idc_host_port_copy, hosts_ptr, &hosts_count);\n  if (rc != ZOK) {\n    free(host_port_copy);\n    free(idc_host", "CodeBleu_score": 38.411782185224396}, {"code": "static int watcher_reconnect_to_zookeeper(zhandle_t *zh){\n\t  char *idc_host;\n  char *host;\n  int rc;\n  struct String_vector str_vec;\n  struct Stat stat;\n\n  if (zh == NULL) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: zh is NULL\");\n    return ZCONNECTIONLOSS;\n  }\n\n  rc = lock_ht_find(zh, &idc_host, &host);\n  if (rc != 0) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: lock_ht_find returned %d\", rc);\n    return rc;\n  }\n\n  rc = lock_ht_delete(zh);\n  if (rc != 0) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: lock_ht_delete returned %d\", rc);\n    return rc;\n  }\n\n  zookeeper_close(zh);\n\n  rc = deserialize_from_idc_host(idc_host, host, &str_vec);\n  if (rc != 0) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: deserialize_from_idc_host returned %d\", rc);\n    return rc;\n  }\n\n  rc = zookeeper_init(&zh, str_vec.data[0], watcher, 10000, 0, 0, 0);\n  if (rc != 0) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: zookeeper_init returned %d\", rc);\n    return rc;\n  }\n\n  rc = init_env_for_zk(zh, idc_host, host);\n  if (rc != 0) {\n    log_message(LOG_ERR, \"watcher_reconnect_to_zookeeper: init_env_for_zk returned %d\", rc);\n    return rc;\n  }\n\n  rc = zoo_exists(zh,", "CodeBleu_score": 36.083885710572716}]}
{"instance_id": "0b5ab34e1dd9", "generation_result": [{"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t  // Update the host table with the handle and host information\n  update_host_table(zh, idc_host, idc);\n\n  // Check if the handle is connected\n  if (!is_connected(zh)) {\n    // If not, exit early\n    return;\n  }\n\n  // Register the current host on the Zookeeper server\n  zoo_state state = zoo_register_ephemeral(zh, idc_host.c_str(), idc.c_str());\n  if (state != ZOO_CONNECTED) {\n    // If the operation fails, log an error\n    LOG_FATAL_ERR(\"Failed to register ephemeral node %s on Zookeeper server\", idc_host.c_str());\n    return;\n  }\n\n  // Set a watcher on the notify node\n  zoo_state watch_state = watch_notify_node(zh);\n  if (watch_state == ZOO_CONNECTED) {\n    // If the operation succeeds, exit\n    return;\n  } else if (watch_state == ZOO_CONNECTED_READ_ONLY) {\n    // If the operation succeeds but the handle is in read-only mode, add the IDC to a gray list\n    add_gray_idc(idc);\n    return;\n  } else {\n    // If the operation fails, log an error\n    LOG_FATAL_ERR(\"Failed to set watcher on notify node on Zookeeper server\");\n    return;\n  }\n}", "CodeBleu_score": 50.32322027709091}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t    // TODO:\n    // 1. \u5728\u5185\u90e8\u8868\u4e2d\u66f4\u65b0handle\u548chost\u4fe1\u606f\n    // 2. \u68c0\u67e5handle\u7684\u8fde\u63a5\u72b6\u6001\n    // 3. \u5982\u679chandle\u672a\u8fde\u63a5\uff0c\u76f4\u63a5\u9000\u51fa\n    // 4. \u5982\u679chandle\u5df2\u8fde\u63a5\uff0c\u5219\u5728Zookeeper\u670d\u52a1\u5668\u4e0a\u6ce8\u518c\u5f53\u524dhost\uff0c\u5e76\u8bbe\u7f6enotify\u8282\u70b9\u7684watcher\n    // 5. \u6839\u636e\u8bbe\u7f6ewatcher\u7684\u7ed3\u679c\uff0c\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 6. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 7. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 8. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 9. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 10. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 11. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 12. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c\u5219\u53ef\u80fd\u4f1a\u5c06IDC\u6dfb\u52a0\u5230\u7070\u540d\u5355\u6216\u8005\u8bb0\u5f55\u9519\u8bef\u65e5\u5fd7\uff08\u5982\u679c\u64cd\u4f5c\u5931\u8d25\uff09\n    // 13. \u5982\u679c\u8bbe\u7f6ewatcher\u5931\u8d25\uff0c", "CodeBleu_score": 6.2578392412969945}, {"code": "static void init_env_for_zk(zhandle_t *zh, const string &idc_host, const string &idc){\n\t  if (zh == NULL) {\n    LOG_FATAL_ERR(\"Zookeeper handle is NULL\");\n    return;\n  }\n\n  /*\n   * Update the internal table with the handle and host information.\n   */\n  lock_ht_update(zh, idc_host);\n\n  /*\n   * Check the connection state of the Zookeeper handle.\n   */\n  zookeeper_state state = zoo_state(zh);\n  if (state != ZOO_CONNECTED_STATE) {\n    LOG_INFO(\"Zookeeper handle is not connected\");\n    return;\n  }\n\n  /*\n   * Register the current host on the Zookeeper server.\n   */\n  int ret = zk_register_ephemeral(zh, idc_host, idc);\n  if (ret != ZOK) {\n    LOG_FATAL_ERR(\"Failed to register ephemeral node for host %s\", idc_host.c_str());\n    return;\n  }\n\n  /*\n   * Set a watcher on the notify node.\n   */\n  ret = watch_notify_node(zh, idc_host, idc);\n  if (ret != ZOK) {\n    /*\n     * If the operation fails, add the IDC to a gray list.\n     */\n    add_gray_idc(idc);\n    LOG_INFO(\"Failed to set watcher on notify node for host %s\", idc_host.c_str());\n    return;\n  }\n}", "CodeBleu_score": 51.20587372133383}]}
{"instance_id": "19fc5847a7c5", "generation_result": [{"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + base64.b64encode(cred_hash).strip().decode()\n\n", "CodeBleu_score": 37.58816462139186}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()\n\n", "CodeBleu_score": 35.40205632581216}, {"code": "def make_digest_acl_credential(username, password)\n\t\n    cred_hash = hashlib.sha1(username.encode() + b\":\" + password.encode()).digest()\n    return username + \":\" + b64encode(cred_hash).decode().strip()\n\n", "CodeBleu_score": 35.40205632581216}]}
{"instance_id": "4a062391deb0", "generation_result": [{"code": "def holds_lock(self)\n\t\n    if self.pe is None:\n        return False\n    lock_path = self.pe.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get_data(lock_path)\n    return lock_value == self.pe.id\n\n", "CodeBleu_score": 35.647144705944314}, {"code": "def holds_lock(self)\n\t\n    if not self.pe:\n        return False\n    lock_path = self.pe.get_lock_path()\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)\n    return lock_value == self.pe.id\n\n", "CodeBleu_score": 31.212864340168196}, {"code": "def holds_lock(self)\n\t\n    if not self.pe:\n        return False\n    lock_path = self.lock_path(self.pe)\n    self.zk.sync(lock_path)\n    lock_value = self.zk.get(lock_path)[0]\n    return lock_value == self.pe.id\n", "CodeBleu_score": 33.7349963785026}]}
{"instance_id": "aaac7523d2b5", "generation_result": [{"code": "def consume(self)\n\t\n    if self.processing_element is not None and self.holds_lock:\n        with transaction:\n            self.processing_element.process(self.entry)\n            self.delete()\n            self.processing_element = None\n        return True\n    return False\n", "CodeBleu_score": 31.038179886107354}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    else:\n        with self.transaction:\n            self.delete()\n            self.processing_element = None\n        return True\n\n", "CodeBleu_score": 18.7589705490811}, {"code": "def consume(self)\n\t\n    if self.processing_element is None:\n        return False\n    if not self.holds_lock:\n        return False\n    with self.transaction:\n        self.processing_element.process(self.entry)\n        self.delete()\n    self.processing_element = None\n    return True\n", "CodeBleu_score": 26.76912387660545}]}
{"instance_id": "bed0c998ac4c", "generation_result": [{"code": "def _read_socket(self, read_timeout)\n\t\n    if self.sock is None:\n        raise ConnectionDroppedError()\n    try:\n        if self._outstanding_ping:\n            self._outstanding_ping = False\n            self._ping_start = None\n            self._ping_end = None\n            self._ping_rtt = None\n            self._ping_round_trip_time_avg.add_sample(self._ping_rtt)\n            self._ping_round_trip_time_var.add_sample(self._ping_rtt)\n            self._ping_round_trip_time_avg.calculate()\n            self._ping_round_trip_time_var.calculate()\n            self._ping_rtt_max = max(self._ping_rtt_max, self._ping_rtt)\n            self._ping_rtt_min = min(self._ping_rtt_min, self._ping_rtt)\n            self._ping_rtt_total += self._ping_rtt\n            self._ping_rtt_count += 1\n            self._ping_rtt_avg = self._ping_rtt_total / self._ping_rtt_count\n            self._ping_rtt_var = self._ping_rtt_total / self._ping_rtt_count\n        header = await self._read_header(read_timeout)\n        if header.xid == PING_XID:\n            self._logger.debug(\"Received PING response\")\n            return\n        elif header.xid == AUTH_XID:\n            await self._read_auth_response(header)\n        elif header.xid == WATCH_XID:\n            await self._read_watch_event(header)\n        else:\n            await self._read_response(header)\n    except Exception as e:\n        self._logger.exception(\"Error reading from socket\")\n        self._exception = e\n        self._close()\n\n", "CodeBleu_score": 40.06750420957786}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n        if header is None:\n            return\n        buffer = await self._read_buffer(header, read_timeout)\n        if buffer is None:\n            return\n        if header.xid == PING_XID:\n            # received a ping response\n            self.log.debug('Received ping response')\n            self._outstanding_pings.clear()\n        elif header.xid == AUTH_XID:\n            # received authentication response\n            if header.err == 0:\n                self.log.debug('Authentication successful')\n                self._auth_completed.set()\n            else:\n                self.log.debug('Authentication failed')\n                self._auth_completed.set_exception(AuthFailedError())\n        elif header.xid == WATCH_XID:\n            # received a watch event\n            await self._read_watch_event(header, buffer)\n        else:\n            # received a response\n            self.log.debug('Received response %s', header)\n            await self._read_response(header, buffer)\n    except Exception as e:\n        self.log.exception('Exception while reading from socket')\n        self.close()\n        self._session_callback.set_exception(e)\n\n", "CodeBleu_score": 39.10028736524084}, {"code": "def _read_socket(self, read_timeout)\n\t\n    try:\n        header = await self._read_header(read_timeout)\n    except SessionExpiredError:\n        self._session_callback(self._session_id)\n        return\n    if header.xid == PING_XID:\n        self._logger.debug('Received ping')\n        self._outstanding_pings.clear()\n    elif header.xid == AUTH_XID:\n        await self._read_auth(header.zxid)\n    elif header.xid == WATCH_XID:\n        event = await self._read_watch_event()\n        self._watch_callback(event)\n    else:\n        self._logger.debug('Received header: %r', header)\n        response = await self._read_response(header)\n        self._queue[header.xid].set(response)\n\n", "CodeBleu_score": 39.67062168154443}]}
{"instance_id": "b10e2c2c410b", "generation_result": [{"code": "def zk_loop(self)\n\t\n    self.log(INFO, \"Starting zk_loop\")\n    self.clear(self.connection_stopped)\n    while not self.connection_stopped.is_set():\n        try:\n            self.retry(self.connect)\n        except RetryFailedError:\n            self.log(WARN, \"Connection retry attempts failed, closing connection\")\n        else:\n            self.log(INFO, \"Connection closed, stopping zk_loop\")\n        finally:\n            self.connection_stopped.set()\n            self.session_callback(CLOSED)\n            self.log(INFO, \"Stopping zk_loop\")\n\n", "CodeBleu_score": 41.86684156358727}, {"code": "def zk_loop(self)\n\t\n    self.log(\"starting zk_loop\")\n    self.clear(\"connection_stopped\")\n    while not self.is_set(\"connection_stopped\"):\n        try:\n            self.retry(self.connect)\n        except Exception as e:\n            self.warning(\"zk_loop: failed to connect to Zookeeper: %s\" % e)\n        else:\n            self.log(\"zk_loop: connected to Zookeeper\")\n            self.set(\"connected\")\n            self.clear(\"connection_stopped\")\n            self.set(\"connection_stopped\", self.zk.wait_for_connection())\n            self.clear(\"connected\")\n            self.log(\"zk_loop: connection to Zookeeper lost\")\n    self.log(\"stopping zk_loop\")\n    self.set(\"connection_stopped\")\n    self.clear(\"connected\")\n    self.session_callback(self.zk, \"closed\", None)\n\n", "CodeBleu_score": 37.07868512199921}, {"code": "def zk_loop(self)\n\t\n    self.logger.info(\"Starting zk_loop\")\n    self.connection_stopped.clear()\n    while not self.connection_stopped.is_set():\n        try:\n            self.zk.start()\n        except Exception as e:\n            self.logger.warning(\"Connection to Zookeeper failed: %s\", e)\n            self.zk.close()\n            self.zk = None\n            self.retry(self.connect_to_zookeeper)\n        else:\n            break\n    self.connection_stopped.set()\n    self.session_callback(self.zk, KazooState.CLOSED)\n    self.logger.info(\"Stopping zk_loop\")\n\n", "CodeBleu_score": 44.16164704722916}]}
{"instance_id": "42b3d26a3540", "generation_result": [{"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    idx = members.index(identifier)\n    return [partitions[i] for i in range(idx, len(partitions), len(members))]\n\n", "CodeBleu_score": 37.96854908675098}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    workers = len(members)\n    index = members.index(identifier)\n    return [partitions[i] for i in range(index, len(partitions), workers)]\n\n", "CodeBleu_score": 37.33537003707749}, {"code": "def _partitioner(self, identifier, members, partitions)\n\t\n    partitions = sorted(partitions)\n    members = sorted(members)\n    index = members.index(identifier)\n    return partitions[index::len(members)]\n\n", "CodeBleu_score": 39.65957835883439}]}
{"instance_id": "738974d4e9c0", "generation_result": [{"code": "def leave(self)\n\t\n    try:\n        self._leave()\n    except Exception:\n        self._best_effort_cleanup()\n        raise\n    finally:\n        self._participating = False\n\n", "CodeBleu_score": 40.926910566451234}, {"code": "def leave(self)\n\t\n    self._best_effort_cleanup\n    retry\n    self.participating = False\n\n", "CodeBleu_score": 16.519137928506865}, {"code": "def leave(self)\n\t\n    self._best_effort_cleanup\n    retry\n    self._participating = False\n\n", "CodeBleu_score": 14.870822112145305}]}
{"instance_id": "a321fef7d100", "generation_result": [{"code": "public Result start(){\n\t    Result result = status();\n    if (result.getStatus() == \"success\") {\n        return result;\n    }\n    try {\n        String[] cmd = {\"/bin/sh\", \"-c\", \"sudo /usr/local/hadoop-2.7.7/sbin/start-dfs.sh\"};\n        ProcessBuilder pb = new ProcessBuilder(cmd);\n        pb.redirectErrorStream(true);\n        Process p = pb.start();\n        InputStream in = p.getInputStream();\n        BufferedReader reader = new BufferedReader(new InputStreamReader(in));\n        String line = null;\n        while ((line = reader.readLine()) != null) {\n            log.info(line);\n        }\n        return new Result(\"success\", \"Started HDFS over FTP server.\");\n    } catch (Exception e) {\n        log.error(e.getMessage());\n        return new Result(\"error\", e.getMessage());\n    }\n}", "CodeBleu_score": 33.70887232588377}, {"code": "public Result start(){\n\t    Result result = status();\n    if (result.getStatus().equals(\"Running\")) {\n        return result;\n    } else {\n        try {\n            ProcessBuilder builder = new ProcessBuilder();\n            builder.command(\"./start-server.sh\");\n            builder.directory(new File(\"/opt/hadoop-ftp-server\"));\n            Process process = builder.start();\n            int exitCode = process.waitFor();\n            if (exitCode == 0) {\n                result.setStatus(\"Running\");\n                result.setMessage(\"The HDFS over FTP server started successfully.\");\n                return result;\n            } else {\n                result.setStatus(\"Error\");\n                result.setMessage(\"The HDFS over FTP server failed to start.\");\n                return result;\n            }\n        } catch (Exception e) {\n            result.setStatus(\"Error\");\n            result.setMessage(e.getMessage());\n            return result;\n        }\n    }\n}", "CodeBleu_score": 26.997184114074834}, {"code": "public Result start(){\n\t    Result result = status();\n    if (result.getStatus() == \"success\") {\n        return result;\n    } else {\n        return startServer();\n    }\n}", "CodeBleu_score": 23.833251428644168}]}
{"instance_id": "24b088689114", "generation_result": [{"code": "public Result stop(){\n\t    if (isRunning()) {\n        try {\n            ftpServer.stop();\n            return new Result(true, \"Server stopped successfully\");\n        } catch (Exception e) {\n            logger.error(\"An error occurred while stopping the server\", e);\n            return new Result(false, \"An error occurred while stopping the server\");\n        }\n    } else {\n        return new Result(false, \"The server is not running\");\n    }\n}", "CodeBleu_score": 31.524522540213773}, {"code": "public Result stop(){\n\t    if (isRunning()) {\n        try {\n            ftpServer.stop();\n            return new Result(Result.SUCCESS, \"FTP server stopped successfully\");\n        } catch (Exception e) {\n            logger.error(\"Failed to stop FTP server\", e);\n            return new Result(Result.FAILURE, \"Failed to stop FTP server\");\n        }\n    } else {\n        return new Result(Result.SUCCESS, \"FTP server is not running\");\n    }\n}", "CodeBleu_score": 31.766573700758343}, {"code": "public Result stop(){\n\t    Result result = new Result();\n    try {\n        if (statusServer()) {\n            FTPServerFactory.createServer().stop();\n            result.setSuccess(true);\n            result.setMessage(\"Server stopped successfully.\");\n        } else {\n            result.setSuccess(false);\n            result.setMessage(\"Server is not running.\");\n        }\n    } catch (Exception e) {\n        result.setSuccess(false);\n        result.setMessage(\"Error stopping server: \" + e.getMessage());\n        error(result.getMessage());\n    }\n    return result;\n}", "CodeBleu_score": 32.67453551121289}]}
{"instance_id": "af0884ffda66", "generation_result": [{"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities.isEmpty()) {\n        return null;\n    }\n    for (GrantedAuthority authority : authorities) {\n        request = authority.authorize(request);\n        if (request == null) {\n            return null;\n        }\n    }\n    return request;\n}", "CodeBleu_score": 38.53319625351504}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities.isEmpty()) {\n        return null;\n    }\n    for (GrantedAuthority authority : authorities) {\n        request = authority.authorize(request);\n        if (request == null) {\n            return null;\n        }\n    }\n    return request;\n}", "CodeBleu_score": 38.53319625351504}, {"code": "public AuthorizationRequest authorize(AuthorizationRequest request){\n\t    if (authorities.isEmpty()) {\n        return null;\n    }\n    for (GrantedAuthority authority : authorities) {\n        request = authority.authorize(request);\n        if (request == null) {\n            return null;\n        }\n    }\n    return request;\n}", "CodeBleu_score": 38.53319625351504}]}
{"instance_id": "920d28a0fe76", "generation_result": [{"code": "public boolean mkdir(){\n\t    try {\n        return getDfs().mkdirs(fullPath);\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 48.09462545320303}, {"code": "public boolean mkdir(){\n\t    try {\n        getDfs().mkdirs(fullPath);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 52.84388821792289}, {"code": "public boolean mkdir(){\n\t  try {\n    getDfs().mkdirs(fullPath);\n    return true;\n  } catch (IOException e) {\n    e.printStackTrace();\n    return false;\n  }\n}", "CodeBleu_score": 52.528831765165584}]}
{"instance_id": "a2b04232d387", "generation_result": [{"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getDfs();\n        fs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.84145906408062}, {"code": "public boolean delete(){\n\t    try {\n        getDfs().delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 53.327192459344964}, {"code": "public boolean delete(){\n\t    try {\n        FileSystem fs = getDfs();\n        fs.delete(fullPath, true);\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.84145906408062}]}
{"instance_id": "3407087c9af6", "generation_result": [{"code": "public boolean move(FtpFile ftpFile){\n\t\ttry {\n\t\tFileSystem fs = FileSystem.get(conf);\n\t\tPath path = new Path(getParent(ftpFile) + \"/\" + getName(ftpFile));\n\t\tfs.rename(path, new Path(getDfs(ftpFile)));\n\t\treturn true;\n\t} catch (IOException e) {\n\t\te.printStackTrace();\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 61.65630456481024}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = FileSystem.get(conf);\n        fs.rename(new Path(ftpFile.getPath()), new Path(ftpFile.getParent() + \"/\" + ftpFile.getName()));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 66.7718768588604}, {"code": "public boolean move(FtpFile ftpFile){\n\t    try {\n        FileSystem fs = getFileSystem();\n        String newPath = getParent(ftpFile) + \"/\" + ftpFile.getName();\n        fs.rename(new Path(getDfs(ftpFile)), new Path(newPath));\n        return true;\n    } catch (IOException e) {\n        e.printStackTrace();\n        return false;\n    }\n}", "CodeBleu_score": 63.05267272764531}]}
{"instance_id": "91227000a139", "generation_result": [{"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        FileStatus[] stats = fs.listStatus(getAbsolutePath());\n        List<FtpFile> files = new ArrayList<FtpFile>(stats.length);\n        for (FileStatus stat : stats) {\n            files.add(new HdfsFile(this, stat));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException ex) {\n        LOG.error(\"Failed to list files for \" + this, ex);\n        return null;\n    }\n}", "CodeBleu_score": 26.61598489097025}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = getFileSystem();\n        FileStatus[] files = fs.listStatus(getAbsolutePath());\n        List<FtpFile> ret = new ArrayList<FtpFile>(files.length);\n        for (FileStatus file : files) {\n            ret.add(new HdfsFile(this, file.getPath().getName(), file));\n        }\n        return Collections.unmodifiableList(ret);\n    } catch (IOException e) {\n        LOG.error(\"Failed to list files in directory: \" + getAbsolutePath(), e);\n        return null;\n    }\n}", "CodeBleu_score": 31.418780146282653}, {"code": "public List<FtpFile> listFiles(){\n\t    try {\n        FileSystem fs = FileSystem.get(getHdfsConf());\n        FileStatus[] status = fs.listStatus(new Path(getHdfsPath()));\n        List<FtpFile> files = new ArrayList<FtpFile>();\n        for (FileStatus stat : status) {\n            files.add(new HdfsFile(getHdfsPath() + \"/\" + stat.getPath().getName(), stat.getLen(), stat.getModificationTime(), this));\n        }\n        return Collections.unmodifiableList(files);\n    } catch (IOException e) {\n        log.error(\"Could not list files for path: \" + getHdfsPath(), e);\n        return null;\n    }\n}", "CodeBleu_score": 31.553963646617}]}
{"instance_id": "aec4623134b5", "generation_result": [{"code": "public void configure(){\n\t    isConfigured = true;\n    userDataProperties = new Properties();\n    FileInputStream fis = null;\n    try {\n        fis = new FileInputStream(getAbsolutePath(userDataFile));\n        userDataProperties.load(fis);\n    } catch (IOException ex) {\n        throw new FtpServerConfigurationException(userDataFile, ex);\n    } finally {\n        if (fis != null) {\n            try {\n                fis.close();\n            } catch (IOException ex) {\n                // do nothing\n            }\n        }\n    }\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 56.30336344707557}, {"code": "public void configure(){\n\t    configured = true;\n    initUserDataProperties();\n    try {\n        load();\n    } catch(IOException e) {\n        throw new FtpServerConfigurationException(userDataFile.getAbsolutePath(), e);\n    }\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 20.71449750862907}, {"code": "public void configure(){\n\t    // check if the user data file exists\n    if (!exists()) {\n        throw new FtpServerConfigurationException(\"User data file does not exist: \" + getAbsolutePath());\n    }\n\n    // load the user data file\n    load();\n\n    // convert any deprecated property names\n    convertDeprecatedPropertyNames();\n}", "CodeBleu_score": 9.73136859510801}]}
{"instance_id": "b5a2587f14d0", "generation_result": [{"code": "private void saveUserData() throws FtpException{\n\t\t// Check if the parent directory of the user data file exists\n\t// and create it if necessary\n\tFile parentFile = getParentFile(userDataFile);\n\tif (!parentFile.exists()) {\n\t\tif (!parentFile.mkdirs()) {\n\t\t\tthrow new ConfigurationException(\"Cannot create parent directory for user data file: \" + userDataFile.getAbsolutePath());\n\t\t}\n\t}\n\n\t// Attempt to write the user data to the file\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(userDataFile);\n\t\tstore(fos);\n\t} catch (IOException ex) {\n\t\tlog.error(\"Failed to write user data file: \" + userDataFile.getAbsolutePath(), ex);\n\t\tthrow new FtpException(\"Failed to write user data file: \" + userDataFile.getAbsolutePath());\n\t} finally {\n\t\t// Ensure the FileOutputStream is closed properly\n\t\tclose(fos);\n\t}\n}", "CodeBleu_score": 46.01930842840769}, {"code": "private void saveUserData() throws FtpException{\n\t\tif (!getParentFile().exists()) {\n\t\tif (!getParentFile().mkdirs()) {\n\t\t\tthrow new FtpException(\"Could not create parent directory for user data file\");\n\t\t}\n\t}\n\tFileOutputStream fos = null;\n\ttry {\n\t\tfos = new FileOutputStream(getAbsolutePath());\n\t\tstore(fos);\n\t} catch (IOException e) {\n\t\tLOG.error(\"Could not write user data to file\", e);\n\t\tthrow new FtpException(\"Could not write user data to file\");\n\t} finally {\n\t\tif (fos != null) {\n\t\t\ttry {\n\t\t\t\tfos.close();\n\t\t\t} catch (IOException e) {\n\t\t\t\tLOG.error(\"Could not close FileOutputStream\", e);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 40.70439530458919}, {"code": "private void saveUserData() throws FtpException{\n\t\ttry {\n\t\tFile file = getAbsoluteFile(userDataFile);\n\t\tif (!exists(file)) {\n\t\t\tmkdirs(file.getParentFile());\n\t\t}\n\t\tif (!exists(file.getParentFile())) {\n\t\t\tthrow new FtpException(\"Could not create parent directory for user data file: \" + userDataFile);\n\t\t}\n\t\tFileOutputStream fos = new FileOutputStream(file);\n\t\tstore(fos, userData);\n\t\tfos.close();\n\t} catch (IOException ex) {\n\t\tlog(ex);\n\t\tthrow new FtpException(\"Could not save user data file: \" + userDataFile);\n\t}\n}", "CodeBleu_score": 37.358403296703}]}
{"instance_id": "5cf2989cf513", "generation_result": [{"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    HdfsUserManager manager = new HdfsUserManager();\n    manager.setFile(new File(\"users.properties\"));\n    try {\n        manager.delete(user);\n        return new Result(true, \"User \" + user + \" deleted.\");\n    } catch (Exception e) {\n        e.printStackTrace();\n        return new Result(false, \"Could not delete user \" + user + \".\");\n    }\n}", "CodeBleu_score": 48.94686219462886}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    try {\n        HdfsUserManager hdfsUserManager = new HdfsUserManager();\n        hdfsUserManager.setFile(new File(\"users.properties\"));\n        hdfsUserManager.delete(user);\n        return new Result(true, \"User \" + user + \" deleted successfully.\");\n    } catch (Exception e) {\n        log.error(\"Exception while deleting user\", e);\n        return new Result(false, \"Error while deleting user: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 46.6145540930751}, {"code": "public Result delete(@PathVariable(value = \"user\") String user){\n\t    HdfsUserManager hdfsUserManager = new HdfsUserManager();\n    hdfsUserManager.setFile(\"users.properties\");\n    try {\n        hdfsUserManager.delete(user);\n        return new Result(ResultCode.OK, \"User \" + user + \" deleted.\");\n    } catch (Exception e) {\n        logger.error(\"Error deleting user \" + user + \".\");\n        return new Result(ResultCode.ERROR, \"Error deleting user \" + user + \".\");\n    }\n}", "CodeBleu_score": 48.16941120316526}]}
{"instance_id": "ce383a9a6497", "generation_result": [{"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    debug(\"opening file \" + path + \" with buffer size \" + bufferSize);\n    Path qualifiedPath = qualify(path);\n    int openConf = getConf().getInt(OPEN_CONF, OPEN_CONF_DEFAULT);\n    int openInt = getInt(qualifiedPath, OPEN_CONF, openConf);\n    debug(\"opening file \" + qualifiedPath + \" with open conf \" + openInt);\n    FSDataInputStream stream = null;\n    try {\n        stream = getStore().open(qualifiedPath, openInt, bufferSize);\n    } catch (Exception e) {\n        warn(\"failed to open file \" + qualifiedPath + \" with buffer size \" + bufferSize, e);\n    }\n    return stream;\n}", "CodeBleu_score": 40.244082462614664}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    debug(\"opening file \" + path + \" with buffer size \" + bufferSize);\n    Path qualifiedPath = qualify(path);\n    int openBufferSize = getInt(getConf().get(OPEN_FILE_BUFFER_SIZE_KEY), OPEN_FILE_BUFFER_SIZE_DEFAULT);\n    FSDataInputStream inputStream = null;\n    try {\n        inputStream = openFileForRead(qualifiedPath, openBufferSize);\n    } catch (Exception e) {\n        warn(\"exception opening file \" + qualifiedPath + \" with buffer size \" + openBufferSize, e);\n    }\n    return inputStream;\n}", "CodeBleu_score": 43.540567152537335}, {"code": "public FSDataInputStream open(Path path, int bufferSize) throws IOException{\n\t    debug(\"open: \" + path + \", \" + bufferSize);\n    Path qualifiedPath = qualify(path);\n    int replication = getConf().getInt(\"fs.default.replication\", 1);\n    int blockSize = getConf().getInt(\"fs.default.block.size\", 64 * 1024 * 1024);\n    int bufferSize = getConf().getInt(\"io.file.buffer.size\", 4096);\n    FSDataInputStream inputStream = openFileForRead(qualifiedPath, bufferSize);\n    if (inputStream == null) {\n        warn(\"open: null input stream for \" + path);\n    }\n    return inputStream;\n}", "CodeBleu_score": 36.88614788078861}]}
{"instance_id": "f0fc12072c02", "generation_result": [{"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\t// TODO: Implement this function\n\t// Log the rename operation\n\tLOG.info(\"Rename: \" + src + \" to \" + dst);\n\n\t// Check if the source is the root or if the source and destination are the same\n\tif (src.isRoot()) {\n\t\tLOG.info(\"Cannot rename the root\");\n\t\treturn false;\n\t}\n\tif (src.equals(dst)) {\n\t\tLOG.info(\"Source and destination are the same\");\n\t\treturn true;\n\t}\n\n\t// Lookup the destination entry and adjust the destination path if the entry exists and is a directory\n\tEntry dstEntry = lookupEntry(dst);\n\tif (dstEntry != null) {\n\t\tif (dstEntry.isDirectory()) {\n\t\t\tdst = dst.suffix(src.getName());\n\t\t} else {\n\t\t\tLOG.info(\"Destination already exists and is not a directory\");\n\t\t\treturn false;\n\t\t}\n\t}\n\n\t// Qualify both the source and adjusted destination paths\n\tsrc = src.makeQualified(this.uri, this.workingDir);\n\tdst = dst.makeQualified(this.uri, this.workingDir);\n\n\t// Perform the rename operation using the file system store\n\tboolean result = this.store.rename(src, dst);\n\n\t// Return true if the rename is successful\n\tif (result) {\n\t\tLOG.info(\"Rename successful\");\n\t\treturn true;\n\t} else {\n\t\tLOG.info(\"Rename unsuccessful\");\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 48.539072218269425}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t  if (isRoot(src)) {\n    throw new IOException(\"Cannot rename the root\");\n  }\n  if (src.equals(dst)) {\n    return true;\n  }\n  Path dstParent = dst.getParent();\n  INode dstNode = lookupEntry(dst);\n  if (dstNode != null) {\n    if (dstNode.isDirectory()) {\n      dst = new Path(dst, src.getName());\n    } else {\n      throw new IOException(String.format(\n          \"Failed to rename %s to %s because the destination exists.\", src, dst));\n    }\n  } else {\n    dstParent = dst.getParent();\n    dstNode = lookupEntry(dstParent);\n    if (dstNode == null || !dstNode.isDirectory()) {\n      throw new FileNotFoundException(String.format(\n          \"Failed to rename %s to %s because the parent of the destination does not exist.\",\n          src, dst));\n    }\n  }\n  src = fullyQualify(src);\n  dst = fullyQualify(dst);\n  if (LOG.isDebugEnabled()) {\n    LOG.debug(String.format(\"Renaming %s to %s\", src, dst));\n  }\n  boolean success = mFileSystemStore.rename(src, dst);\n  if (success) {\n    mStatistics.incrementWriteOps(1);\n  }\n  return success;\n}", "CodeBleu_score": 49.64280471160936}, {"code": "public boolean rename(Path src, Path dst) throws IOException{\n\t\t// TODO: 1. Check if the source exists and is a directory\n\t// TODO: 2. Check if the destination exists and is a directory\n\t// TODO: 3. Qualify both source and destination paths\n\t// TODO: 4. Perform the rename operation\n\t// TODO: 5. Return true if the operation is successful\n}", "CodeBleu_score": 4.008281391136642}]}
{"instance_id": "5104c071af46", "generation_result": [{"code": "public boolean hasCapability(String capability){\n\t    capability = capability.toLowerCase();\n    if (capability.equals(\"hsync\")) {\n        return supportFlush;\n    } else if (capability.equals(\"hflush\")) {\n        return supportFlush;\n    } else {\n        return false;\n    }\n}", "CodeBleu_score": 37.938287839991794}, {"code": "public boolean hasCapability(String capability){\n\t  capability = capability.toLowerCase();\n  if (capability.equals(\"hsync\")) {\n    return supportSync;\n  } else if (capability.equals(\"hflush\")) {\n    return supportFlush;\n  } else {\n    return false;\n  }\n}", "CodeBleu_score": 36.04998214693273}, {"code": "public boolean hasCapability(String capability){\n\t\tif (capability.toLowerCase().equals(\"hsync\")) {\n\t\treturn supportFlush;\n\t} else if (capability.toLowerCase().equals(\"hflush\")) {\n\t\treturn supportFlush;\n\t} else {\n\t\treturn false;\n\t}\n}", "CodeBleu_score": 28.193576775419306}]}
{"instance_id": "6989c860c79b", "generation_result": [{"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    try {\n        mFilerClient.writeUserMetadata(mPath, new UserMetadata.Builder().setFlushOffset(offset).build());\n        mLastFlushOffset = offset;\n    } catch (Exception e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 43.77997745417098}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    try {\n        final long lastFlushOffset = mLastFlushOffset;\n        if (lastFlushOffset == offset) {\n            return;\n        }\n        if (lastFlushOffset > offset) {\n            throw new IllegalArgumentException(\n                    String.format(Locale.US,\n                            \"offset(%d) < lastFlushOffset(%d) is not allowed.\", offset, lastFlushOffset));\n        }\n        final long bytesWritten = offset - lastFlushOffset;\n        final int bytesWrittenInt = (int) bytesWritten;\n        if (bytesWrittenInt != bytesWritten) {\n            throw new IllegalArgumentException(\n                    String.format(Locale.US,\n                            \"offset(%d) - lastFlushOffset(%d) > Integer.MAX_VALUE is not allowed.\",\n                            offset, lastFlushOffset));\n        }\n        final int bytesToWrite = mWriteBuffer.position() - bytesWrittenInt;\n        if (bytesToWrite > 0) {\n            final byte[] bytes = new byte[bytesToWrite];\n            mWriteBuffer.get(bytes, 0, bytesToWrite);\n            mFilerClient.write(mFileHandle, bytes, bytesWrittenInt);\n        }\n        mLastFlushOffset = offset;\n        mWriteBuffer.clear();\n        writeMeta();\n    } catch (final IOException e) {\n        throw e;\n    } catch (final Exception e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 28.51234987230461}, {"code": "private synchronized void flushWrittenBytesToServiceInternal(final long offset) throws IOException{\n\t    try {\n        final long flushOffset = mLastFlushOffset.get();\n        if (offset > flushOffset) {\n            // Flush data to service.\n            flushDataToService(flushOffset, offset);\n            // Flush metadata to filer.\n            flushMetadataToFiler(flushOffset, offset);\n            // Update last flush offset.\n            mLastFlushOffset.set(offset);\n        }\n    } catch (final IOException e) {\n        throw e;\n    } catch (final Exception e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 33.784003219977684}]}
{"instance_id": "56e8fb9de5da", "generation_result": [{"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tif (bufferToWrite == null) {\n\t\tthrow new NullPointerException(\"Null bufferToWrite\");\n\t}\n\tif (writePosition < 0) {\n\t\tthrow new IllegalArgumentException(\"Negative writePosition\");\n\t}\n\tif (writePosition + bufferToWrite.limit() > this.size) {\n\t\tthrow new IllegalArgumentException(\"writePosition + bufferToWrite.limit() > this.size\");\n\t}\n\tif (this.position < writePosition) {\n\t\tthrow new IllegalStateException(\"position < writePosition\");\n\t}\n\tif (this.position > writePosition) {\n\t\tthrow new IllegalStateException(\"position > writePosition\");\n\t}\n\tbufferToWrite.flip();\n\tfinal int byteLength = bufferToWrite.limit();\n\tif (byteLength == 0) {\n\t\treturn 0;\n\t}\n\tif (this.writeOperationQueue.size() >= MAX_WRITE_OPERATION_QUEUE_SIZE) {\n\t\tthis.shrinkWriteOperationQueue();\n\t}\n\tif (this.writeOperationQueue.size() >= MAX_WRITE_OPERATION_QUEUE_SIZE) {\n\t\tthis.waitForTaskToComplete();\n\t}\n\tthis.writeOperationQueue.add(new WriteOperation(bufferToWrite, writePosition));\n\tthis.position += byteLength;\n\tthis.array.writeData(bufferToWrite, writePosition);\n\treturn byteLength;\n}", "CodeBleu_score": 26.831715802953372}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t\tif (writePosition < 0) {\n\t\tthrow new IOException(\"Attempt to write to a negative position\");\n\t}\n\tif (writePosition > size) {\n\t\tthrow new IOException(\"Attempt to write past end of file\");\n\t}\n\tif (bufferToWrite.position() != 0) {\n\t\tbufferToWrite.flip();\n\t}\n\tfinal int byteLength = bufferToWrite.limit();\n\tif (byteLength == 0) {\n\t\treturn 0;\n\t}\n\tif (getQueue().remainingCapacity() < 1) {\n\t\tshrinkWriteOperationQueue();\n\t}\n\tfinal long taskId = position.getAndIncrement();\n\tfinal WriteOperation writeOperation = new WriteOperation(taskId, writePosition, byteLength);\n\twriteOperations.put(taskId, writeOperation);\n\tgetQueue().submit(() -> {\n\t\ttry {\n\t\t\twriteData(bufferToWrite, writePosition);\n\t\t} catch (IOException e) {\n\t\t\twriteOperation.setException(e);\n\t\t} finally {\n\t\t\twriteOperation.setComplete();\n\t\t\trelease(bufferToWrite);\n\t\t}\n\t});\n\treturn byteLength;\n}", "CodeBleu_score": 34.882208478804834}, {"code": "private synchronized int submitWriteBufferToService(final ByteBuffer bufferToWrite, final long writePosition) throws IOException {\n\t    // Flip the buffer to prepare for reading\n    bufferToWrite.flip();\n    // Calculate the byte length\n    final int byteLength = bufferToWrite.remaining();\n    // Ensure the task queue is not overloaded\n    waitForTaskToComplete();\n    // Submit a write task to the completion service\n    getQueue().submit(() -> {\n        try {\n            // Write the data\n            writeData(bufferToWrite, writePosition);\n        } finally {\n            // Release the buffer\n            release(bufferToWrite);\n        }\n    });\n    // Record the write operation\n    add(writePosition, byteLength);\n    // Manage the operation queue\n    shrinkWriteOperationQueue();\n    // Return the number of bytes written\n    return byteLength;\n}", "CodeBleu_score": 26.419548412183012}]}
{"instance_id": "bf27d955c38b", "generation_result": [{"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (!completionService.poll().isPresent()) {\n            Thread.sleep(100);\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 21.766024309195277}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    try {\n        while (completionService.poll() != null) {\n            // wait for the next task to complete\n        }\n    } catch (InterruptedException e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 20.0865597141439}, {"code": "private void waitForTaskToComplete() throws IOException{\n\t    while (true) {\n        try {\n            Future<String> future = completionService.poll();\n            if (future != null) {\n                future.get();\n                return;\n            }\n        } catch (InterruptedException e) {\n            throw new IOException(e);\n        } catch (ExecutionException e) {\n            throw new IOException(e);\n        }\n    }\n}", "CodeBleu_score": 32.367878508321404}]}
{"instance_id": "5c7a311273ae", "generation_result": [{"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t  Iterator<WriteOperation> itr = writeOperations.iterator();\n  while (itr.hasNext()) {\n    WriteOperation writeOp = itr.next();\n    if (writeOp.isDone()) {\n      if (writeOp.hasException()) {\n        throw new IOException(writeOp.getException());\n      }\n      writeOp.remove();\n      itr.remove();\n      totalAppendOffset += writeOp.getLength();\n    }\n  }\n}", "CodeBleu_score": 29.34439385071644}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    Iterator<WriteOperation> iter = writeOperations.iterator();\n    while (iter.hasNext()) {\n        WriteOperation op = iter.next();\n        if (op.isDone()) {\n            iter.remove();\n            if (op.getException() != null) {\n                throw new IOException(op.getException());\n            }\n            totalAppendOffset += op.getLength();\n        } else {\n            break;\n        }\n    }\n}", "CodeBleu_score": 30.419738651408846}, {"code": "private synchronized void shrinkWriteOperationQueue() throws IOException{\n\t    int i = 0;\n    while (i < writeOperations.size()) {\n        WriteOperation op = writeOperations.get(i);\n        if (op.isDone()) {\n            writeOperations.remove(i);\n            totalAppendOffset += op.get();\n        } else {\n            i++;\n        }\n    }\n}", "CodeBleu_score": 32.569577159769345}]}
{"instance_id": "d8f07e66f690", "generation_result": [{"code": "protected HdfsFileSystemView(User user){\n\t\tif (user == null || user.getHomeDirectory() == null) {\n\t\tthrow new IllegalArgumentException(\"User or user home directory is null\");\n\t}\n\thomePath = user.getHomeDirectory();\n\tthis.user = user;\n}", "CodeBleu_score": 51.131942853811154}, {"code": "protected HdfsFileSystemView(User user){\n\t    if (user == null || user.getHomeDirectory() == null) {\n        throw new IllegalArgumentException(\"User or user's home directory is null\");\n    }\n    this.homePath = user.getHomeDirectory();\n    this.user = user;\n}", "CodeBleu_score": 55.40022038231386}, {"code": "protected HdfsFileSystemView(User user){\n\t    if (user == null || user.getHomeDirectory() == null) {\n        throw new IllegalArgumentException(\"User or user's home directory is null\");\n    }\n    homePath = user.getHomeDirectory();\n    this.user = user;\n}", "CodeBleu_score": 52.81643567669645}]}
{"instance_id": "27807db0eb0f", "generation_result": [{"code": "public boolean changeWorkingDirectory(String dir){\n\t    // TODO: Implement this method\n    return false;\n}", "CodeBleu_score": 2.1773869450892978}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t    if (dir.equals(\"..\")) {\n        if (this.parent != null) {\n            this.path = this.parent.path;\n            this.parent = this.parent.parent;\n            return true;\n        }\n    } else if (dir.startsWith(\"/\")) {\n        if (dir.length() == 1) {\n            this.path = \"/\";\n            this.parent = null;\n            return true;\n        } else {\n            Path newPath = new Path(dir);\n            if (newPath.isDirectory()) {\n                this.path = newPath.path;\n                this.parent = newPath.parent;\n                return true;\n            } else {\n                return false;\n            }\n        }\n    } else {\n        if (this.path.equals(\"/\")) {\n            if (dir.length() == 0) {\n                return true;\n            } else {\n                Path newPath = new Path(this.path + dir);\n                if (newPath.isDirectory()) {\n                    this.path = newPath.path;\n                    this.parent = newPath.parent;\n                    return true;\n                } else {\n                    return false;\n                }\n            }\n        } else {\n            Path newPath = new Path(this.path + \"/\" + dir);\n            if (newPath.isDirectory()) {\n                this.path = newPath.path;\n                this.parent = newPath.parent;\n                return true;\n            } else {\n                return false;\n            }\n        }\n    }\n    return false;\n}", "CodeBleu_score": 35.00785731681291}, {"code": "public boolean changeWorkingDirectory(String dir){\n\t\tif (dir.startsWith(\"/\")) {\n\t\tPath newPath = new Path(dir);\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t} else {\n\t\tPath newPath = new Path(currentPath.toString() + \"/\" + dir);\n\t\tif (newPath.isDirectory()) {\n\t\t\tcurrentPath = newPath;\n\t\t\treturn true;\n\t\t} else {\n\t\t\treturn false;\n\t\t}\n\t}\n}", "CodeBleu_score": 25.578113600393632}]}
{"instance_id": "be7aba23d184", "generation_result": [{"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    filerClient = new FilerClient(host, port, grpcPort);\n    if (conf.getAccessMode().equals(\"direct\")) {\n        accessVolumeServerByFilerProxy = false;\n        accessVolumeServerByPublicUrl = false;\n    } else if (conf.getAccessMode().equals(\"publicUrl\")) {\n        accessVolumeServerByFilerProxy = false;\n        accessVolumeServerByPublicUrl = true;\n    } else if (conf.getAccessMode().equals(\"filerProxy\")) {\n        accessVolumeServerByFilerProxy = true;\n        accessVolumeServerByPublicUrl = false;\n    } else {\n        throw new IllegalArgumentException(\"Invalid access mode: \" + conf.getAccessMode());\n    }\n}", "CodeBleu_score": 43.12982257193946}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.accessVolumeServerMode = conf.getAccessVolumeServerMode();\n    if (accessVolumeServerMode.equals(AccessVolumeServerMode.DIRECT)) {\n        setAccessVolumeServerByFilerProxy();\n    } else if (accessVolumeServerMode.equals(AccessVolumeServerMode.PUBLICURL)) {\n        setAccessVolumeServerByPublicUrl();\n    } else {\n        setAccessVolumeServerByFilerProxy();\n    }\n}", "CodeBleu_score": 48.09389519339481}, {"code": "public SeaweedFileSystemStore(String host, int port, int grpcPort, Configuration conf){\n\t    this.conf = conf;\n    this.filerClient = new FilerClient(host, port, grpcPort);\n    this.filerClient.setAccessVolumeServerByFilerProxy();\n}", "CodeBleu_score": 29.07959942238072}]}
{"instance_id": "7943a1723c23", "generation_result": [{"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t    LOG.debug(\"Opening file for reading: {}\", path);\n    FileEntry entry = lookupEntry(path);\n    if (entry == null) {\n        throw new FileNotFoundException(path.toString());\n    }\n    return new SeaweedHadoopInputStream(filerClient, statistics, entry.getPath());\n}", "CodeBleu_score": 60.04917606235537}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t  LOG.debug(\"Opening file for reading: {}\", path);\n  final Entry entry = lookupEntry(path);\n  if (entry == null) {\n    throw new FileNotFoundException(path.toString());\n  }\n  return new SeaweedHadoopInputStream(filerClient, statistics, entry);\n}", "CodeBleu_score": 58.142842017343156}, {"code": "public FSInputStream openFileForRead(final Path path, FileSystem.Statistics statistics) throws IOException{\n\t  LOG.debug(\"Opening file for reading: {}\", path);\n  final FilerProto.Entry entry = lookupEntry(path);\n  if (entry == null) {\n    throw new FileNotFoundException(path.toString());\n  }\n  return new SeaweedHadoopInputStream(filerClient, statistics, entry);\n}", "CodeBleu_score": 60.112328829664854}]}
{"instance_id": "36634cee9ed3", "generation_result": [{"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        hostName = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        hostName = \"localhost\";\n    }\n    numThreads = conf.getInt(\"mapreduce.tika.server.threads\", 10);\n    numFilesPerThread = conf.getInt(\"mapreduce.tika.server.filesperthread\", 100);\n    threadPool = Executors.newFixedThreadPool(numThreads);\n    for (int i = 0; i < numThreads; i++) {\n        threadPool.execute(new TikaServerThread(i));\n    }\n}", "CodeBleu_score": 49.81293999443404}, {"code": "public void configure(JobConf conf){\n\t  this.conf = conf;\n  try {\n    hostName = InetAddress.getLocalHost().getHostName();\n  } catch (UnknownHostException e) {\n    hostName = \"localhost\";\n  }\n  numThreads = conf.getInt(\"mapred.tasktracker.map.tasks.maximum\", 2);\n  numFiles = conf.getInt(\"mapred.tasktracker.map.tasks.threads\", 10);\n  threadPool = newFixedThreadPool(numThreads, new ThreadFactoryBuilder()\n      .setDaemon(true).setNameFormat(\"hbase-mapreduce-map-%d\").build());\n}", "CodeBleu_score": 53.44235909086276}, {"code": "public void configure(JobConf conf){\n\t    this.conf = conf;\n    try {\n        this.localHost = InetAddress.getLocalHost().getHostName();\n    } catch (UnknownHostException e) {\n        this.localHost = \"localhost\";\n    }\n    this.threadsPerMap = conf.getInt(\"mapred.threads.per.map\", 1);\n    this.filesPerThread = conf.getInt(\"mapred.files.per.thread\", 1);\n    this.threadPool = Executors.newFixedThreadPool(this.threadsPerMap);\n    for (int i = 0; i < this.threadsPerMap; i++) {\n        this.threadPool.execute(new Thread(new Runnable() {\n            public void run() {\n                while (true) {\n                    try {\n                        int taskId = getInt();\n                        if (taskId == -1) {\n                            break;\n                        }\n                        TaskAttemptID taskAttemptID = new TaskAttemptID(new TaskID(new JobID(conf.get(\"mapred.job.id\"), true), TaskType.MAP, taskId), 0);\n                        FileSplit fileSplit = new FileSplit(new Path(conf.get(\"mapred.input.dir\")), taskId * filesPerThread, filesPerThread, new String[]{localHost});\n                        RecordReader<K, V> recordReader = new LineRecordReader(conf, fileSplit);\n                        recordReader.initialize(fileSplit, conf);\n                        while (recordReader.next(key, value)) {\n                            context.write(key, value);\n                        }\n                        recordReader.close();\n                    } catch (IOException e) {\n                        e.printStackTrace();\n                    } catch (InterruptedException e) {\n                        e.printStackTrace();\n                    }\n                }\n            }\n        }));\n    }\n}", "CodeBleu_score": 29.761489224519565}]}
{"instance_id": "53cd9065153d", "generation_result": [{"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    if (isRunning(uri)) {\n        return;\n    }\n    final String host = getHost(uri);\n    UserGroupInformation ugi = createRemoteUser(host, conf);\n    ugi.doAs(new PrivilegedExceptionAction<Object>() {\n\n        @Override\n        public Object run() throws Exception {\n            final FileSystem fs = getEmptier(uri, conf);\n            final Configuration conf = getConf(fs);\n            final long interval = conf.getLong(TrashPolicy.EMPTY_INTERVAL_KEY, TrashPolicy.DEFAULT_EMPTY_INTERVAL);\n            if (interval > 0) {\n                final Timer timer = new Timer(true);\n                timer.schedule(new TimerTask() {\n\n                    @Override\n                    public void run() {\n                        try {\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL = toMillis(interval);\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL_KEY = TrashPolicy.EMPTY_INTERVAL_KEY;\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL_DEFAULT = TrashPolicy.DEFAULT_EMPTY_INTERVAL;\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL_UNIT = TimeUnit.MINUTES;\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL_UNIT_KEY = TrashPolicy.EMPTY_INTERVAL_UNIT_KEY;\n                            TrashPolicy.EMPTIE_TRASH_INTERVAL_UNIT_DEFAULT = TrashPolicy.DEFAULT_EMPTY_INTERVAL_UNIT;\n                            fs.getTrashRoots(true);\n                            fs.getTrashRoots(false);\n                        } catch (IOException e) {\n                            LOG.warn(\"Failed to run trash emptier\", e);\n                        }\n                    }\n                }, 0, interval);\n            }\n            return null;\n        }\n    });\n}", "CodeBleu_score": 33.40071349762124}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    try {\n        final String host = getHost(uri);\n        if (!isRunning(host)) {\n            LOG.info(\"Starting Trash Emptier for host: \" + host);\n            final UserGroupInformation ugi = createRemoteUser(host, conf);\n            ugi.doAs(new PrivilegedExceptionAction<Object>() {\n                public Object run() throws IOException {\n                    final Configuration newConf = getConf(host, conf);\n                    final FileSystem fs = initialize(host, newConf);\n                    final TrashPolicy tp = fs.getTrashPolicy();\n                    if (tp instanceof TrashPolicyDefault) {\n                        ((TrashPolicyDefault) tp).setConf(newConf);\n                    }\n                    final TrashPolicyDefault trashPolicy = (TrashPolicyDefault) tp;\n                    if (trashPolicy.getEmptier() == null) {\n                        trashPolicy.setEmptier(getEmptier(host, newConf));\n                    }\n                    if (trashPolicy.getEmptier().getConf() == null) {\n                        trashPolicy.getEmptier().setConf(newConf);\n                    }\n                    if (trashPolicy.getEmptier().getConf().get(FS_TRASH_INTERVAL_KEY) == null) {\n                        trashPolicy.getEmptier().getConf().setLong(FS_TRASH_INTERVAL_KEY, toMillis(10, TimeUnit.MINUTES));\n                    }\n                    if (trashPolicy.getEmptier().getConf().get(FS_TRASH_CHECKPOINT_INTERVAL_KEY) == null) {\n                        trashPolicy.getEmptier().getConf().setLong(FS_TRASH_CHECKPOINT_INTERVAL_KEY, toMillis(10, TimeUnit.MINUTES));\n                    }\n                    trashPolicy.getEmptier().start();\n                    return null;\n                }\n            });\n        }\n    } catch (Exception e) {\n        throw new IOException(e);\n    }\n}", "CodeBleu_score": 35.70101683815644}, {"code": "private void startTrashEmptier(URI uri, final Configuration conf) throws IOException{\n\t    String host = getHost(uri);\n    if (!isRunning(host)) {\n        UserGroupInformation ugi = createRemoteUser(host, conf);\n        final JuiceFileSystemImpl fs = getEmptier(ugi, uri, conf);\n        final TrashPolicy tp = getConf(conf);\n        final long interval = toMillis(conf.get(JuiceFileSystem.TRASH_INTERVAL_KEY, JuiceFileSystem.TRASH_INTERVAL_DEFAULT));\n        try {\n            ugi.doAs(new PrivilegedExceptionAction<Object>() {\n                public Object run() throws Exception {\n                    fs.startTrashEmptier(tp, interval);\n                    return null;\n                }\n            });\n        } catch (InterruptedException e) {\n            throw new IOException(e);\n        }\n    }\n}", "CodeBleu_score": 38.712652262348456}]}
{"instance_id": "ede797f6a8f2", "generation_result": [{"code": "public static void setContext(String context) throws Exception{\n\t\tString currentContext = getContext();\n\tif (isContextValid(currentContext)) {\n\t\tif (!currentContext.contains(context)) {\n\t\t\tcurrentContext = currentContext + \".\" + context;\n\t\t\tsetCurrent(currentContext);\n\t\t}\n\t} else {\n\t\tsetCurrent(context);\n\t}\n}", "CodeBleu_score": 19.80446498330272}, {"code": "public static void setContext(String context) throws Exception{\n\t    String currentContext = getCurrent();\n    if (currentContext == null || !isContextValid(currentContext)) {\n        currentContext = build(context);\n    } else if (!currentContext.contains(context)) {\n        currentContext += \":\" + context;\n    }\n    setCurrent(currentContext);\n}", "CodeBleu_score": 25.770276728226726}, {"code": "public static void setContext(String context) throws Exception{\n\t    if (context == null || context.length() == 0) {\n        throw new Exception(\"Context cannot be null or empty\");\n    }\n    String currentContext = getCurrent();\n    if (currentContext == null || currentContext.length() == 0) {\n        build(context);\n    } else {\n        if (isContextValid(currentContext)) {\n            if (!currentContext.endsWith(context)) {\n                currentContext += context;\n                build(currentContext);\n            }\n        } else {\n            build(context);\n        }\n    }\n}", "CodeBleu_score": 28.597601017548037}]}
{"instance_id": "56968a526f6a", "generation_result": [{"code": "Status HDFS::remove_file(const URI& uri){\n\t  if (!uri.is_hdfs()) {\n    return LOG_STATUS(Status_HDFSError(\n        \"Cannot delete file; URI is not an HDFS URI\"));\n  }\n\n  // Establish HDFS connection\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(uri, &fs));\n\n  // Remove file\n  if (hdfsDelete(fs, uri.to_path().c_str(), 0) != 0) {\n    return LOG_STATUS(Status_HDFSError(\n        std::string(\"Cannot delete file; URI: \" + uri.to_string())));\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 57.51678202415853}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  if (!uri.is_hdfs()) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"URI is not an HDFS URI: \" + uri.to_string())));\n  }\n\n  if (uri.is_invalid()) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot remove file; Invalid URI: \" + uri.to_string())));\n  }\n\n  // Connect\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(uri, &fs));\n\n  // Remove file\n  int ret = libhdfs_->hdfsDelete(fs, uri.to_path().c_str(), 0);\n  if (ret < 0) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot remove file; HDFS error: \" + std::string(\n            libhdfs_->hdfsGetLastError()))));\n  }\n\n  // Disconnect\n  RETURN_NOT_OK(disconnect(fs));\n\n  return Status::Ok();\n}", "CodeBleu_score": 64.17186934904308}, {"code": "Status HDFS::remove_file(const URI& uri){\n\t  if (!uri.is_hdfs()) {\n    return LOG_STATUS(Status::HDFSError(\n        \"Cannot delete non-HDFS URI '\" + uri.to_string() + \"'\"));\n  }\n\n  // Get config\n  Config& config = Config::instance();\n\n  // Connect\n  hdfsBuilder* builder = hdfsNewBuilder();\n  hdfsBuilderSetNameNode(builder, config.get(\"vfs.hdfs.name_node\").c_str());\n  hdfsBuilderSetForceNewInstance(builder);\n  hdfsBuilderConfSetStr(\n      builder, \"dfs.client.read.shortcircuit\", config.get(\"vfs.hdfs.read.shortcircuit\").c_str());\n  hdfsBuilderConfSetStr(\n      builder, \"dfs.domain.socket.path\", config.get(\"vfs.hdfs.domain.socket.path\").c_str());\n  hdfsBuilderSetKerbTicketCachePath(builder, config.get(\"vfs.hdfs.kerb.ticket.cache.path\").c_str());\n  hdfsBuilderSetUserName(builder, config.get(\"vfs.hdfs.username\").c_str());\n\n  hdfsFS fs = hdfsBuilderConnect(builder);\n  if (fs == nullptr) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot connect to HDFS URI '\") +\n        config.get(\"vfs.hdfs.name_node\") + \"'; hdfsBuilderConnect error\"));\n  }\n\n  // Delete file\n  int success = hdfsDelete(fs, uri.to_path().c_str(), 0);\n  if (!success) {\n    return LOG_STATUS(Status::HDFSError(\n        std::string(\"Cannot delete HDFS URI '\") + uri.to_string() +\n        \"'; hdfsDelete error\"));\n  }\n\n  // Disconnect\n  hdfsDisconnect(fs);\n\n  return Status::Ok();\n}", "CodeBleu_score": 45.29232291656765}]}
{"instance_id": "f33adb3e8cb6", "generation_result": [{"code": "Status HDFS::sync(const URI& uri){\n\t  // If 'uri' is not an HDFS URI, this is a noop.\n  if (uri.is_hdfs()) {\n    // Get config\n    Config* config = storage_manager_->config();\n    const char* namenode = config->get(\"vfs.hdfs.name_node\", \"default\").c_str();\n    const char* port = config->get(\"vfs.hdfs.name_node_port\", \"default\").c_str();\n    const char* username = config->get(\"vfs.hdfs.username\", \"default\").c_str();\n    const char* kerb_ticket = config->get(\"vfs.hdfs.kerb_ticket_cache_path\", \"default\").c_str();\n\n    // Connect\n    hdfsFS fs = libhdfs_->hdfsConnect(namenode, atoi(port));\n    if (fs == nullptr) {\n      std::stringstream errmsg;\n      errmsg << \"Failed to connect to HDFS: \" << namenode << \":\" << port;\n      return LOG_STATUS(Status_HDFSError(errmsg.str()));\n    }\n\n    // Get file info\n    hdfsFileInfo* file_info = libhdfs_->hdfsGetPathInfo(fs, uri.c_str());\n    if (file_info == nullptr) {\n      // File does not exist - return Ok\n      libhdfs_->hdfsDisconnect(fs);\n      return Status::Ok();\n    }\n\n    // File exists - open it\n    hdfsFile hfile = libhdfs_->hdfsOpenFile(fs, uri.c_str(), O_WRONLY|O_APPEND, 0, 0, 0);\n    if (hfile == nullptr) {\n      std::stringstream errmsg;\n      errmsg << \"Failed to open HDFS file \" << uri.c_str() << \" for sync\";\n      return LOG_STATUS(Status_HDFSError(errmsg.str()));\n    }\n\n    // Flush\n    int rc = libhdfs_->hdfsHFlush(fs, hfile);\n    if (rc != 0) {", "CodeBleu_score": 44.897506138982564}, {"code": "Status HDFS::sync(const URI& uri){\n\t  if (uri.is_file()) {\n    std::string filename = uri.to_path();\n    hdfsFS fs = connect(uri);\n    if (fs == nullptr) {\n      return LOG_STATUS(Status_HDFSError(\n          std::string(\"Cannot connect to HDFS; URI: \" + uri.to_string())));\n    }\n\n    // Check if the file exists\n    if (hdfsExists(fs, filename.c_str()) == 0) {\n      // Open the file for writing and appending\n      hdfsFile file =\n          libhdfs_->hdfsOpenFile(fs, filename.c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n      if (file == nullptr) {\n        return LOG_STATUS(Status_HDFSError(\n            std::string(\"Cannot open HDFS file for syncing; URI: \" +\n                        uri.to_string())));\n      }\n\n      // Flush the file\n      if (libhdfs_->hdfsHFlush(fs, file) != 0) {\n        libhdfs_->hdfsCloseFile(fs, file);\n        return LOG_STATUS(Status_HDFSError(\n            std::string(\"Cannot sync HDFS file; URI: \" + uri.to_string())));\n      }\n\n      // Close file\n      if (libhdfs_->hdfsCloseFile(fs, file) != 0) {\n        return LOG_STATUS(Status_HDFSError(\n            std::string(\"Cannot close HDFS file; URI: \" + uri.to_string())));\n      }\n    }\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 51.6282459934871}, {"code": "Status HDFS::sync(const URI& uri){\n\t  // If the file does not exist, exit\n  if (!is_file(uri))\n    return Status::Ok();\n\n  // Connect\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(uri, &fs));\n\n  // Open the file in write and append mode\n  hdfsFile file = libhdfs_->hdfsOpenFile(\n      fs, uri.to_path().c_str(), O_WRONLY | O_APPEND, 0, 0, 0);\n  if (file == nullptr) {\n    const std::string errmsgs = \"Cannot open HDFS file; \" + uri.c_str();\n    LOG_STATUS(Status_HDFSError(errmsgs));\n    return Status::HDFSError(errmsgs);\n  }\n\n  // Flush the file\n  if (libhdfs_->hdfsHFlush(fs, file) != 0) {\n    const std::string errmsgs = \"Cannot flush HDFS file; \" + uri.c_str();\n    LOG_STATUS(Status_HDFSError(errmsgs));\n    return Status::HDFSError(errmsgs);\n  }\n\n  // Close file\n  if (libhdfs_->hdfsCloseFile(fs, file) != 0) {\n    const std::string errmsgs = \"Cannot close HDFS file; \" + uri.c_str();\n    LOG_STATUS(Status_HDFSError(errmsgs));\n    return Status::HDFSError(errmsgs);\n  }\n\n  // Disconnect\n  RETURN_NOT_OK(disconnect(fs));\n\n  return Status::Ok();\n}", "CodeBleu_score": 58.56742160501949}]}
{"instance_id": "893c46ab9675", "generation_result": [{"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  assert(nbytes);\n  *nbytes = 0;\n\n  // Get config\n  Config config;\n  RETURN_NOT_OK(config.init(uri));\n\n  // Connect\n  hdfsFS fs;\n  RETURN_NOT_OK(connect(config, &fs));\n\n  // Get file info\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    std::string errmsg = std::string(\"Cannot retrieve HDFS file info; \") +\n                         std::string(std::string(hdfsGetLastError()));\n    LOG_STATUS(Status_HDFSError(errmsg));\n    return LOG_STATUS(Status::HDFSError(errmsg));\n  }\n\n  // Check if it is a file\n  if (!file_info->mKind) {\n    std::string errmsg =\n        std::string(\"Cannot retrieve size; URI is not a file: \") +\n        uri.to_string();\n    LOG_STATUS(Status_HDFSError(errmsg));\n    return LOG_STATUS(Status::HDFSError(errmsg));\n  }\n\n  // Set nbytes and free file info\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 52.36876763763504}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  *nbytes = 0;\n\n  if (uri.is_hdfs()) {\n    if (!libhdfs_->hdfsExists(fs_, uri.c_str())) {\n      return LOG_STATUS(Status_HDFSError(\n          \"Cannot retrieve file size; File does not exist\"));\n    }\n\n    hdfsFileInfo* info = libhdfs_->hdfsGetPathInfo(fs_, uri.c_str());\n    if (info == nullptr) {\n      return LOG_STATUS(Status_HDFSError(\n          \"Cannot retrieve file size; File does not exist\"));\n    }\n\n    if (info->mKind == kObjectKindDirectory) {\n      libhdfs_->hdfsFreeFileInfo(info, 1);\n      return LOG_STATUS(Status_HDFSError(\n          \"Cannot retrieve file size; Path is a directory\"));\n    }\n\n    *nbytes = static_cast<uint64_t>(info->mSize);\n    libhdfs_->hdfsFreeFileInfo(info, 1);\n  }\n\n  return Status::Ok();\n}", "CodeBleu_score": 50.652363828729285}, {"code": "Status HDFS::file_size(const URI& uri, uint64_t* nbytes){\n\t  *nbytes = 0;\n\n  // Connect to HDFS\n  hdfsFS fs = nullptr;\n  RETURN_NOT_OK(connect(uri, &fs));\n\n  // Get HDFS file info\n  hdfsFileInfo* file_info = hdfsGetPathInfo(fs, uri.to_path().c_str());\n  if (file_info == nullptr) {\n    std::string errmsg = std::string(\"Cannot retrieve HDFS file info for URI '\") +\n                         uri.to_string() + \"'\";\n    LOG_STATUS(Status_HDFSError(errmsg));\n    return LOG_STATUS(Status::HDFSError(errmsg));\n  }\n\n  // Check that path is a file\n  if (file_info->mKind != kObjectKindFile) {\n    std::string errmsg = std::string(\"URI '\") + uri.to_string() +\n                         \"' is not an HDFS file\";\n    LOG_STATUS(Status_HDFSError(errmsg));\n    return LOG_STATUS(Status::HDFSError(errmsg));\n  }\n\n  // Set nbytes and free file info\n  *nbytes = static_cast<uint64_t>(file_info->mSize);\n  hdfsFreeFileInfo(file_info, 1);\n\n  return Status::Ok();\n}", "CodeBleu_score": 58.74240061590702}]}
{"instance_id": "3da0b4d8ae16", "generation_result": [{"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    if (hbaseCfgString == null || hbaseCfgString.trim().isEmpty()) {\n        throw new IllegalArgumentException(\"hbaseCfgString cannot be null or empty\");\n    }\n    // parse the HBase configuration string\n    Map<String, String> hbaseConfig = parseObject(hbaseCfgString, \"hbaseCfgString\");\n    // extract the Zookeeper quorum\n    String quorum = hbaseConfig.get(\"hbase.zookeeper.quorum\");\n    if (quorum == null || quorum.trim().isEmpty()) {\n        throw new IllegalArgumentException(\"hbase.zookeeper.quorum must be specified\");\n    }\n    // extract the Zookeeper client port\n    String port = hbaseConfig.get(\"hbase.zookeeper.property.clientPort\");\n    if (port == null || port.trim().isEmpty()) {\n        port = \"2181\";\n    }\n    // ensure the quorum includes the port number\n    if (!quorum.contains(\":\")) {\n        quorum = quorum + \":\" + port;\n    }\n    // extract the znode parent\n    String znode = hbaseConfig.get(\"zookeeper.znode.parent\");\n    if (znode == null || znode.trim().isEmpty()) {\n        znode = \"/hbase\";\n    }\n    return new Pair<String, String>(quorum, znode);\n}", "CodeBleu_score": 35.934876756803476}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t  String[] hbaseCfgParts = hbaseCfgString.split(\";\");\n  String zkQuorum = \"\";\n  String znodeParent = \"\";\n  for (String hbaseCfgPart : hbaseCfgParts) {\n    String[] hbaseCfgKV = hbaseCfgPart.split(\"=\");\n    if (hbaseCfgKV[0].equals(\"hbase.zookeeper.quorum\")) {\n      zkQuorum = hbaseCfgKV[1];\n    } else if (hbaseCfgKV[0].equals(\"zookeeper.znode.parent\")) {\n      znodeParent = hbaseCfgKV[1];\n    }\n  }\n  if (!zkQuorum.contains(\":\")) {\n    zkQuorum = zkQuorum + \":2181\";\n  }\n  if (znodeParent.isEmpty()) {\n    znodeParent = \"/hbase\";\n  }\n  return new Pair<String, String>(zkQuorum, znodeParent);\n}", "CodeBleu_score": 37.03787029438973}, {"code": "public static Pair<String, String> getHbaseConfig(String hbaseCfgString){\n\t    if (hbaseCfgString == null) {\n        throw new IllegalArgumentException(\"hbaseCfgString cannot be null\");\n    }\n\n    String[] hbaseCfgArray = hbaseCfgString.split(\",\");\n    String quorum = null;\n    String znode = null;\n    for (String hbaseCfg : hbaseCfgArray) {\n        String[] hbaseCfgParts = hbaseCfg.split(\"=\");\n        if (hbaseCfgParts.length != 2) {\n            throw new IllegalArgumentException(\"Invalid HBase configuration: \" + hbaseCfgString);\n        }\n\n        String hbaseCfgName = hbaseCfgParts[0];\n        String hbaseCfgValue = hbaseCfgParts[1];\n        if (hbaseCfgName.equals(\"hbase.zookeeper.quorum\")) {\n            quorum = hbaseCfgValue;\n        } else if (hbaseCfgName.equals(\"zookeeper.znode.parent\")) {\n            znode = hbaseCfgValue;\n        }\n    }\n\n    if (quorum == null) {\n        throw new IllegalArgumentException(\"hbase.zookeeper.quorum must be specified in hbaseCfgString\");\n    }\n\n    String[] quorumParts = quorum.split(\":\");\n    if (quorumParts.length == 1) {\n        quorum = quorum + \":2181\";\n    }\n\n    if (znode == null) {\n        znode = \"/hbase\";\n    }\n\n    return new Pair<String, String>(quorum, znode);\n}", "CodeBleu_score": 30.019659274733897}]}
{"instance_id": "860cae2bb7f4", "generation_result": [{"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try {\n        // check if the table exists\n        checkTable(cfg);\n\n        // get the table schema\n        List<String> columnNames = getColumns(cfg);\n\n        // check if all configured columns exist\n        for (String columnName : cfg.getColumns()) {\n            if (!columnNames.contains(columnName)) {\n                throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE,\n                        String.format(\"\u60a8\u6240\u914d\u7f6e\u7684\u5217\u540d: [%s] \u4e0d\u5b58\u5728\u4e8e\u8868: [%s].[%s] \u4e2d, \u8bf7\u68c0\u67e5\u60a8\u7684\u914d\u7f6e \u6216\u8005 \u8054\u7cfb Hbase \u7ba1\u7406\u5458.\",\n                                columnName, cfg.getNamespace(), cfg.getTableName()));\n            }\n        }\n    } catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE, e);\n    }\n}", "CodeBleu_score": 25.19510997144644}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t\tif (cfg.getTableName() == null) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The parameter [\" + Key.TABLE + \"] is not set.\");\n\t}\n\n\tif (cfg.getColumn() == null || cfg.getColumn().isEmpty()) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The parameter [\" + Key.COLUMN + \"] is not set.\");\n\t}\n\n\tif (cfg.getNamespace() == null) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The parameter [\" + Key.NAMESPACE + \"] is not set.\");\n\t}\n\n\tif (cfg.getBatchSize() <= 0) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE, \"The parameter [\" + Key.BATCH_SIZE + \"] must be a positive integer.\");\n\t}\n\n\tif (cfg.getBatchSizeBytes() <= 0) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE, \"The parameter [\" + Key.BATCH_SIZE_BYTES + \"] must be a positive integer.\");\n\t}\n\n\tif (cfg.getNullMode() == null) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.REQUIRED_VALUE, \"The parameter [\" + Key.NULL_MODE + \"] is not set.\");\n\t}\n\n\tif (cfg.getNullMode() != null && !cfg.getNullMode().equalsIgnoreCase(\"skip\") && !cfg.getNullMode().equalsIgnoreCase(\"empty\")) {\n\t\tthrow AddaxException.asAddaxException(HbaseSQLWriterErrorCode.ILLEGAL_VALUE, \"The parameter [\" + Key.NULL_MODE + \"] must be one of [skip, empty].\");\n\t}\n\n\tif (cfg.getEncoding() != null && !cfg.getEncoding().equalsIgnoreCase(\"UTF-8\") && !cfg.", "CodeBleu_score": 27.017604579565013}, {"code": "public static void validateConfig(HbaseSQLWriterConfig cfg){\n\t    try {\n        // establish a JDBC connection\n        Connection conn = getJdbcConnection(cfg);\n        try {\n            // check that the specified table exists in the given namespace\n            checkTable(cfg, conn);\n            // retrieve the table schema\n            String tableSchema = getTableSchema(cfg, conn);\n            // ensure that all configured columns exist in the target table\n            getColumns(cfg, tableSchema);\n        } finally {\n            conn.close();\n        }\n    } catch (SQLException e) {\n        throw AddaxException.asAddaxException(HbaseSQLWriterErrorCode.GET_CONNECTION_ERROR, e);\n    }\n}", "CodeBleu_score": 19.14635568259622}]}
{"instance_id": "61721c327cf6", "generation_result": [{"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal != null && !kerberosPrincipal.isEmpty() && kerberosKeytabFilePath != null && !kerberosKeytabFilePath.isEmpty()) {\n        log.info(\"Kerberos authentication enabled, logging in as principal {} with keytab file {}\", kerberosPrincipal, kerberosKeytabFilePath);\n        Configuration hadoopConf = new Configuration();\n        hadoopConf.set(\"hadoop.security.authentication\", \"Kerberos\");\n        UserGroupInformation.setConfiguration(hadoopConf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            log.error(\"Kerberos login failed for principal {} with keytab file {}\", kerberosPrincipal, kerberosKeytabFilePath);\n            throw AddaxException.asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 53.95850520517346}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (kerberosPrincipal != null && kerberosPrincipal.trim().length() > 0 && kerberosKeytabFilePath != null && kerberosKeytabFilePath.trim().length() > 0) {\n        LOG.info(\"Kerberos authentication enabled - logging in as principal [{}] with keytab file [{}]\", kerberosPrincipal, kerberosKeytabFilePath);\n        Configuration hadoopConf = new Configuration();\n        hadoopConf.set(\"hadoop.security.authentication\", \"Kerberos\");\n        UserGroupInformation.setConfiguration(hadoopConf);\n        try {\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            LOG.error(\"Kerberos login failed - {}\", e.getMessage());\n            throw new RuntimeException(\"Kerberos login failed\", e);\n        }\n    }\n}", "CodeBleu_score": 53.24211147310901}, {"code": "private static void kerberosAuthentication(String kerberosPrincipal, String kerberosKeytabFilePath){\n\t    if (isNotBlank(kerberosPrincipal) && isNotBlank(kerberosKeytabFilePath)) {\n        try {\n            Configuration conf = new Configuration();\n            conf.set(\"hadoop.security.authentication\", \"Kerberos\");\n            UserGroupInformation.setConfiguration(conf);\n            UserGroupInformation.loginUserFromKeytab(kerberosPrincipal, kerberosKeytabFilePath);\n        } catch (IOException e) {\n            error(\"Kerberos login error - \" + e.getMessage());\n            throw asAddaxException(HdfsWriterErrorCode.KERBEROS_LOGIN_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 43.48179063516373}]}
{"instance_id": "9ceb7f0bb717", "generation_result": [{"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t        Map<String, ThinClientPTable.ThinClientPColumn> columns = new HashMap<String, ThinClientPTable.ThinClientPColumn>();\n        ResultSetMetaData rsmd = rs.getMetaData();\n        int colCount = rsmd.getColumnCount();\n        for (int i = 1; i <= colCount; i++) {\n            String colName = rsmd.getColumnLabel(i);\n            String colType = rsmd.getColumnTypeName(i);\n            if (colName == null || colType == null) {\n                throw new SQLException(\"Unable to find column name or type for column \" + i);\n            }\n            columns.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n        }\n        return columns;\n    }", "CodeBleu_score": 46.23435230420473}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    Map<String, ThinClientPTable.ThinClientPColumn> columns = Maps.newHashMap();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int numCols = rsmd.getColumnCount();\n    for (int i = 1; i <= numCols; i++) {\n        String colName = rsmd.getColumnLabel(i);\n        if (colName == null || colName.isEmpty()) {\n            throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_NAME_UNKNOWN)\n                .setColumnName(colName).build().buildException();\n        }\n        String colTypeName = rsmd.getColumnTypeName(i);\n        if (colTypeName == null || colTypeName.isEmpty()) {\n            throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_TYPE_UNKNOWN)\n                .setColumnName(colName).build().buildException();\n        }\n        PDataType colType = fromSqlTypeName(colTypeName);\n        columns.put(colName, new ThinClientPTable.ThinClientPColumn(colName, colType));\n    }\n    return columns;\n}", "CodeBleu_score": 45.48198303065074}, {"code": "public static Map<String, ThinClientPTable.ThinClientPColumn> parseColType(ResultSet rs)\n            throws SQLException{\n\t    Map<String, ThinClientPTable.ThinClientPColumn> columns = Maps.newLinkedHashMap();\n    ResultSetMetaData rsmd = rs.getMetaData();\n    int numCols = rsmd.getColumnCount();\n    for (int i = 1; i <= numCols; i++) {\n        String colName = rsmd.getColumnLabel(i);\n        if (colName == null || colName.isEmpty()) {\n            throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_NAME_UNKNOWN)\n                    .setColumnName(colName).build().buildException();\n        }\n        String colTypeName = rsmd.getColumnTypeName(i);\n        if (colTypeName == null || colTypeName.isEmpty()) {\n            throw new SQLExceptionInfo.Builder(SQLExceptionCode.COLUMN_FAMILY_NOT_FOUND)\n                    .setColumnName(colName).build().buildException();\n        }\n        columns.put(colName, new ThinClientPTable.ThinClientPColumn(colName,\n                PDataType.fromSqlTypeName(colTypeName)));\n    }\n    return columns;\n}", "CodeBleu_score": 42.86323747698271}]}
{"instance_id": "247fc8882f6f", "generation_result": [{"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        conn = unwrap(conn);\n        Admin admin = getAdmin(conn);\n        if (checkTable(admin, tableName)) {\n            disableTable(admin, tableName);\n            admin.truncateTable(TableName.valueOf(tableName), true);\n            LOG.debug(\"Truncated table \" + tableName);\n        }\n    } catch (Exception e) {\n        throw asAddaxException(AddaxException.HbaseShadeErrorCode.HBASE_TRUNCATE_ERROR, e);\n    } finally {\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 32.2817852608554}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        // Unwrap the connection to get the PhoenixConnection\n        PhoenixConnection phxConn = conn.unwrap(PhoenixConnection.class);\n        // Get the HBase Admin instance\n        Admin admin = phxConn.getQueryServices().getAdmin();\n        // Check if the table exists\n        checkTable(admin, tableName);\n        // Disable the table\n        disableTable(admin, tableName);\n        // Truncate the table\n        admin.truncateTable(TableName.valueOf(tableName), true);\n        // Log a debug message indicating the table has been truncated\n        debug(\"Table \" + tableName + \" has been truncated.\");\n    } catch (Exception e) {\n        // Throw an exception with a relevant error code and message\n        throw new AddaxException(AddaxErrorCode.RUNTIME_ERROR, e.getMessage());\n    } finally {\n        // Ensure the Admin instance is closed properly\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 43.309189095317954}, {"code": "public static void truncateTable(Connection conn, String tableName){\n\t    try {\n        conn = unwrap(conn);\n        PhoenixConnection pconn = conn.unwrap(PhoenixConnection.class);\n        Admin admin = pconn.getQueryServices().getAdmin();\n        if (!admin.tableExists(TableName.valueOf(tableName))) {\n            throw new AddaxException(AddaxErrorCode.CONF_ERROR,\n                    String.format(\"Table %s does not exist.\", tableName));\n        }\n        disableTable(admin, tableName);\n        admin.truncateTable(TableName.valueOf(tableName), false);\n        LOG.debug(String.format(\"Table %s has been truncated.\", tableName));\n    } catch (Exception e) {\n        throw AddaxException.asAddaxException(\n                Hbase11xWriterErrorCode.TRUNCATE_HBASE_ERROR, e);\n    } finally {\n        closeAdmin(admin);\n    }\n}", "CodeBleu_score": 52.39018517845489}]}
{"instance_id": "ac87e1b9a54e", "generation_result": [{"code": "private void addSourceFileByType(String filePath){\n\t    if (fileType == FileType.CSV) {\n        if (filePath.endsWith(\".csv\")) {\n            info(\"Adding source file: \" + filePath);\n            sourceFiles.add(filePath);\n        } else {\n            error(\"Unsupported file type: \" + filePath);\n            asAddaxException(new Exception(\"Unsupported file type: \" + filePath));\n        }\n    } else if (fileType == FileType.JSON) {\n        if (filePath.endsWith(\".json\")) {\n            info(\"Adding source file: \" + filePath);\n            sourceFiles.add(filePath);\n        } else {\n            error(\"Unsupported file type: \" + filePath);\n            asAddaxException(new Exception(\"Unsupported file type: \" + filePath));\n        }\n    } else if (fileType == FileType.PARQUET) {\n        if (filePath.endsWith(\".parquet\")) {\n            info(\"Adding source file: \" + filePath);\n            sourceFiles.add(filePath);\n        } else {\n            error(\"Unsupported file type: \" + filePath);\n            asAddaxException(new Exception(\"Unsupported file type: \" + filePath));\n        }\n    } else if (fileType == FileType.XML) {\n        if (filePath.endsWith(\".xml\")) {\n            info(\"Adding source file: \" + filePath);\n            sourceFiles.add(filePath);\n        } else {\n            error(\"Unsupported file type: \" + filePath);\n            asAddaxException(new Exception(\"Unsupported file type: \" + filePath));\n        }\n    } else {\n        info(\"Adding source file: \" + filePath);\n        sourceFiles.add(filePath);\n    }\n}", "CodeBleu_score": 17.755308995336705}, {"code": "private void addSourceFileByType(String filePath){\n\t    if (filePath.endsWith(fileType)) {\n        logger.info(\"Adding file: {}\", filePath);\n        sourceFiles.add(filePath);\n    } else {\n        logger.error(\"File type not supported: {}\", filePath);\n        throw new AddaxException(String.format(\"[%s] File type not supported: [%s]\", this.getClass().getName(), filePath));\n    }\n}", "CodeBleu_score": 16.435979508053165}, {"code": "private void addSourceFileByType(String filePath){\n\t    def fileType = getFileType(filePath)\n    if (fileType == this.fileType) {\n        info(\"Adding file \" + filePath + \" to the source files list\")\n        this.sourceFiles.add(filePath)\n    } else {\n        error(\"File \" + filePath + \" has an unsupported file type of \" + fileType)\n        asAddaxException(\"File \" + filePath + \" has an unsupported file type of \" + fileType)\n    }\n}", "CodeBleu_score": 21.24196174889602}]}
{"instance_id": "5e6a66d06162", "generation_result": [{"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"Start Read sequenceFile [{}] .\", sourceSequenceFilePath);\n\n    Path seqFilePath = new Path(sourceSequenceFilePath);\n    SequenceFile.Reader reader = null;\n    try {\n        reader = new SequenceFile.Reader(seqFilePath.getFileSystem(readerSliceConfig), seqFilePath, readerSliceConfig);\n\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Text value = new Text();\n        while (reader.next(key, value)) {\n            if (StringUtils.isNotBlank(value.toString())) {\n                transportOneRecord(recordSender, getKeyClass(key), value.toString(), taskPluginCollector);\n            }\n        }\n    } catch (Exception e) {\n        LOG.error(\"SequenceFileReader read sequence file error: \", e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n    } finally {\n        IOUtils.closeStream(reader);\n    }\n}", "CodeBleu_score": 57.68365931301093}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"Start Read sequence file [{}].\", sourceSequenceFilePath);\n\n    Path seqFilePath = new Path(sourceSequenceFilePath);\n    try {\n        SequenceFile.Reader reader = new SequenceFile.Reader(seqFilePath.getFileSystem(readerSliceConfig), seqFilePath, readerSliceConfig);\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Text value = new Text();\n        while (reader.next(key, value)) {\n            transportOneRecord(recordSender, getKeyClass(key), value, taskPluginCollector);\n        }\n    } catch (Exception e) {\n        LOG.error(\"SequenceFileReader read sequence file:{} error\", sourceSequenceFilePath, e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n    }\n}", "CodeBleu_score": 53.5685453205517}, {"code": "public void sequenceFileStartRead(String sourceSequenceFilePath, Configuration readerSliceConfig,\n            RecordSender recordSender, TaskPluginCollector taskPluginCollector){\n\t    LOG.info(\"Start Read source files[{}].\", sourceSequenceFilePath);\n    Path seqFilePath = new Path(sourceSequenceFilePath);\n    SequenceFile.Reader reader = null;\n    try {\n        reader = new SequenceFile.Reader(seqFilePath.getFileSystem(readerSliceConfig), seqFilePath, readerSliceConfig);\n        Writable key = (Writable) ReflectionUtils.newInstance(reader.getKeyClass(), readerSliceConfig);\n        Text value = new Text();\n        while (reader.next(key, value)) {\n            transportOneRecord(recordSender, getKeyClass(reader), key, value, taskPluginCollector);\n        }\n    } catch (Exception e) {\n        LOG.error(\"Read sequenceFile error\", e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_SEQUENCEFILE_ERROR, e);\n    } finally {\n        IOUtils.closeStream(reader);\n    }\n}", "CodeBleu_score": 52.26437812906429}]}
{"instance_id": "c450f959616c", "generation_result": [{"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    // get the file type from the filepath\n    String fileType = getFileType(filepath);\n\n    // check if the file type matches the specified file type\n    if (fileType.equals(specifiedFileType)) {\n        return true;\n    }\n\n    // if the file type does not match any of the supported types, return false\n    if (fileType.equals(\"\")) {\n        return false;\n    }\n\n    // if the file type does not match the specified file type, throw an exception\n    String errorMessage = \"The specified file type [\" + specifiedFileType + \"] does not match the actual file type [\" + fileType + \"].\";\n    LOG.error(errorMessage);\n    throw AddaxException.asAddaxException(HdfsWriterErrorCode.ILLEGAL_VALUE, errorMessage);\n}", "CodeBleu_score": 17.96336451623613}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    boolean isType = false;\n    try {\n        if (isORCFile(specifiedFileType)) {\n            isType = isORCFile(filepath);\n        } else if (isParquetFile(specifiedFileType)) {\n            isType = isParquetFile(filepath);\n        } else if (isRCFile(specifiedFileType)) {\n            isType = isRCFile(filepath);\n        } else if (isSequenceFile(specifiedFileType)) {\n            isType = isSequenceFile(filepath);\n        } else {\n            isType = format(filepath).equalsIgnoreCase(specifiedFileType);\n        }\n    } catch (Exception e) {\n        LOG.error(\"An error occurred while checking the file type.\", e);\n        throw AddaxException.asAddaxException(HdfsWriterErrorCode.CHECK_HDFS_FILE_TYPE_ERROR, e);\n    }\n    return isType;\n}", "CodeBleu_score": 32.23950699943924}, {"code": "public boolean checkHdfsFileType(String filepath, String specifiedFileType){\n\t    boolean isValidFileType = false;\n    try {\n        FileSystem fs = FileSystem.get(new Configuration());\n        FSDataInputStream inputStream = fs.open(new Path(filepath));\n        isValidFileType = checkFileType(inputStream, specifiedFileType);\n    } catch (IOException e) {\n        String msg = String.format(\"Failed to check the file type of the file %s. Please check the file path and the file system.\", filepath);\n        LOG.error(msg, e);\n        throw AddaxException.asAddaxException(HdfsReaderErrorCode.READ_FILE_ERROR, msg, e);\n    }\n    return isValidFileType;\n}", "CodeBleu_score": 28.104810930166224}]}
{"instance_id": "1bf487d2cc64", "generation_result": [{"code": "public static void closeConnection(Connection hConnection){\n\t\tif (hConnection != null) {\n\t\ttry {\n\t\t\thConnection.close();\n\t\t} catch (IOException e) {\n\t\t\tasAddaxException.addMessage(\"Error closing HBase connection\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 39.87626437880884}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new HbaseException(HbaseErrorCode.HBASE_CLOSE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 53.933707724381065}, {"code": "public static void closeConnection(Connection hConnection){\n\t    if (hConnection != null) {\n        try {\n            hConnection.close();\n        } catch (IOException e) {\n            throw new AsAddaxException(Hbase1xWriterErrorCode.CLOSE_HBASE_CONNECTION_ERROR, e);\n        }\n    }\n}", "CodeBleu_score": 55.87244139549005}]}
{"instance_id": "680728cbc3ec", "generation_result": [{"code": "public static void closeAdmin(Admin admin){\n\t  if (admin != null) {\n    try {\n      admin.close();\n    } catch (IOException e) {\n      throw new AddaxException(HBase11xHelperErrorCode.CLOSE_ADMIN_ERROR, e);\n    }\n  }\n}", "CodeBleu_score": 51.08594146707568}, {"code": "public static void closeAdmin(Admin admin){\n\t\tif (admin != null) {\n\t\ttry {\n\t\t\tadmin.close();\n\t\t} catch (IOException e) {\n\t\t\tthrow new RuntimeException(\"Error closing HBase Admin\", e);\n\t\t}\n\t}\n}", "CodeBleu_score": 40.78540314946987}, {"code": "public static void closeAdmin(Admin admin){\n\t  if (admin != null) {\n    try {\n      admin.close();\n    } catch (IOException e) {\n      throw new HBaseException(\"Unable to close HBase Admin instance\", e);\n    }\n  }\n}", "CodeBleu_score": 45.30985323505733}]}
{"instance_id": "ce50bd53abef", "generation_result": [{"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n        // Get the row key\n        byte[] rowKeyBytes = cell.getRowArray();\n        int rowKeyOffset = cell.getRowOffset();\n        int rowKeyLength = cell.getRowLength();\n        String rowKey = getRowKey(rowKeyBytes, rowKeyOffset, rowKeyLength);\n\n        // Get the column family\n        byte[] familyBytes = cell.getFamilyArray();\n        int familyOffset = cell.getFamilyOffset();\n        int familyLength = cell.getFamilyLength();\n        String family = getFamily(familyBytes, familyOffset, familyLength);\n\n        // Get the column qualifier\n        byte[] qualifierBytes = cell.getQualifierArray();\n        int qualifierOffset = cell.getQualifierOffset();\n        int qualifierLength = cell.getQualifierLength();\n        String qualifier = getQualifier(qualifierBytes, qualifierOffset, qualifierLength);\n\n        // Get the timestamp\n        long timestamp = cell.getTimestamp();\n\n        // Get the column value\n        byte[] valueBytes = cell.getValueArray();\n        int valueOffset = cell.getValueOffset();\n        int valueLength = cell.getValueLength();\n        Object value = getValue(valueBytes, valueOffset, valueLength,\n                cell.getTypeByte());\n\n        // Add the row key as a column\n        record.setValue(rowKey, rowKey);\n\n        // Add the column family as a column\n        record.setValue(family, family);\n\n        // Add the column qualifier as a column\n        record.setValue(qualifier, qualifier);\n\n        // Add the timestamp as a column\n        record.setValue(getTimestamp(), timestamp);\n\n        // Add the column value as a column\n        record.setValue(qualifier, value);\n\n    }", "CodeBleu_score": 31.44711909283059}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t\n        // Get the row key from the cell\n        byte[] rowKey = cell.getRowArray();\n\n        // Get the timestamp from the cell\n        long timestamp = cell.getTimestamp();\n\n        // Get the column family and qualifier from the cell\n        byte[] family = cell.getFamilyArray();\n        byte[] qualifier = cell.getQualifierArray();\n\n        // Get the column value from the cell\n        byte[] value = cell.getValueArray();\n\n        // Get the type and format for the row key\n        String rowKeyType = getByTypeName(rowKeyTypeName);\n        String rowKeyFormat = getByTypeName(rowKeyFormatName);\n\n        // Get the type and format for the column value\n        String valueType = getByTypeName(valueTypeName);\n        String valueFormat = getByTypeName(valueFormatName);\n\n        // Add the row key as a column to the record\n        add(record, rowKeyType, rowKeyFormat, rowKey, rowKeyTypeName, rowKeyFormatName);\n\n        // Add the column family as a column to the record\n        add(record, \"string\", null, family, \"string\", null);\n\n        // Add the column qualifier as a column to the record\n        add(record, \"string\", null, qualifier, \"string\", null);\n\n        // Add the timestamp as a column to the record\n        add(record, \"long\", null, timestamp, \"long\", null);\n\n        // Add the column value as a column to the record\n        add(record, valueType, valueFormat, value, valueTypeName, valueFormatName);\n    }", "CodeBleu_score": 28.205504604097158}, {"code": "private void convertCellToLine(Cell cell, Record record)\n            throws Exception{\n\t        // Get the row key from the cell.\n        byte[] rowKey = cell.getRowArray();\n        // Get the column family from the cell.\n        byte[] family = cell.getFamilyArray();\n        // Get the column qualifier from the cell.\n        byte[] qualifier = cell.getQualifierArray();\n        // Get the value from the cell.\n        byte[] value = cell.getValueArray();\n        // Get the timestamp from the cell.\n        long timestamp = cell.getTimestamp();\n        // Get the type name for the row key.\n        String rowKeyTypeName = getTypeName(rowKey);\n        // Get the type name for the column value.\n        String valueTypeName = getTypeName(value);\n        // Get the type name for the column family.\n        String familyTypeName = getTypeName(family);\n        // Get the type name for the column qualifier.\n        String qualifierTypeName = getTypeName(qualifier);\n        // Get the type name for the timestamp.\n        String timestampTypeName = getTypeName(timestamp);\n        // Convert the row key to the appropriate type.\n        Object rowKeyObject = convertBytesToAssignType(rowKey, rowKeyTypeName);\n        // Convert the column value to the appropriate type.\n        Object valueObject = convertBytesToAssignType(value, valueTypeName);\n        // Convert the column family to the appropriate type.\n        Object familyObject = convertBytesToAssignType(family, familyTypeName);\n        // Convert the column qualifier to the appropriate type.\n        Object qualifierObject = convertBytesToAssignType(qualifier, qualifierTypeName);\n        // Convert the timestamp to the appropriate type.\n        Object timestampObject = convertBytesToAssignType(timestamp, timestampTypeName);\n        // Add the row key to the record.\n        record.set(rowKeyTypeName, rowKeyObject);\n        // Add the column family to the record.\n        record.set(familyTypeName, familyObject);\n        // Add the column qualifier to the record.\n        record.set(qualifierTypeName, qualifierObject);\n        // Add the timestamp to the record.\n        record.set(timestampTypeName, timestampObject);\n        // Add the column value to the", "CodeBleu_score": 31.873679061081116}]}
{"instance_id": "29e8f3a99f0c", "generation_result": [{"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowKey = getString(configuration, \"startRowKey\");\n    if (isBlank(startRowKey)) {\n        return new byte[0];\n    }\n    return stringToBytes(startRowKey, configuration);\n}", "CodeBleu_score": 26.12318951354129}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowKey = configuration.get(ConfigurationKeys.START_ROW_KEY);\n    if (isBlank(startRowKey)) {\n        return new byte[0];\n    }\n    return stringToBytes(startRowKey, configuration);\n}", "CodeBleu_score": 39.2862583626158}, {"code": "public static byte[] convertUserStartRowkey(Configuration configuration){\n\t    String startRowKey = configuration.get(HConstants.START_ROW_KEY);\n    return isBlank(startRowKey) ? new byte[0] : convertRowKey(startRowKey);\n}", "CodeBleu_score": 29.894232799255537}]}
{"instance_id": "f5ad51545b10", "generation_result": [{"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowKey = configuration.get(START_ROWKEY);\n    if (startRowKey == null) {\n        return new byte[0];\n    }\n    if (startRowKey.isEmpty()) {\n        return new byte[0];\n    }\n    return startRowKey.getBytes(StandardCharsets.UTF_8);\n}", "CodeBleu_score": 42.9861096388132}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowKey = configuration.get(START_ROW_KEY);\n    if (startRowKey == null || startRowKey.trim().isEmpty()) {\n        return new byte[0];\n    }\n    return startRowKey.getBytes(StandardCharsets.UTF_8);\n}", "CodeBleu_score": 45.23250791902501}, {"code": "public static byte[] convertInnerStartRowkey(Configuration configuration){\n\t    String startRowkey = configuration.get(ConfigurationKeys.START_ROWKEY);\n    if (StringUtils.isBlank(startRowkey)) {\n        return new byte[0];\n    }\n    return Bytes.toBytesBinary(startRowkey);\n}", "CodeBleu_score": 67.56223109064567}]}
{"instance_id": "8618eef8b0e9", "generation_result": [{"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new TbQueueMsgHeaders();\n    record.headers().iterator().forEachRemaining(header -> {\n        headers.put(header.key(), header.value());\n    });\n    this.data = record.value();\n}", "CodeBleu_score": 63.62006618336942}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.headers = new KafkaTbQueueMsgHeaders(record.headers());\n    this.data = record.value();\n}", "CodeBleu_score": 42.98408197495899}, {"code": "public KafkaTbQueueMsg(ConsumerRecord<String, byte[]> record){\n\t    this.key = UUID.fromString(record.key());\n    this.value = record.value();\n    this.headers = new TbQueueMsgHeaders(record.headers());\n}", "CodeBleu_score": 41.0526947199551}]}
{"instance_id": "46484df184dd", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToTransportMsg>> builder = TbKafkaProducerTemplate.builder();\n    builder.settings(kafkaSettings);\n    builder.clientId(getServiceId());\n    builder.defaultTopic(getNotificationsTopic());\n    builder.admin(admin);\n    return builder.build();\n}", "CodeBleu_score": 57.05181536976403}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return createTbQueueProducerTemplate(transportNotificationSettings.getNotificationsTopic(),\n            new TbKafkaProducerTemplate<>(transportNotificationSettings.getTopic(),\n                    new TbKafkaEncoder<>()));\n}", "CodeBleu_score": 19.172597182580688}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToTransportMsg>> createTransportNotificationsMsgProducer(){\n\t    return createTbQueueProducerTemplate(\n            transportNotificationSettings.getNotificationsTopic(),\n            transportNotificationSettings.getServiceId(),\n            transportNotificationSettings.getMaxPendingMessages(),\n            transportNotificationSettings.getMaxPendingMessages());\n}", "CodeBleu_score": 25.732308662840488}]}
{"instance_id": "4ac56ef9f89a", "generation_result": [{"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate\n        .builder();\n    consumerBuilder.settings(settings);\n    consumerBuilder.topic(getNotificationsTopic());\n    consumerBuilder.clientId(clientId);\n    consumerBuilder.groupId(groupId);\n    consumerBuilder.decoder(msg -> new TbProtoQueueMsg<>(msg.getKey(), ToCoreNotificationMsg.parseFrom(msg.getData())));\n    consumerBuilder.admin(admin);\n    consumerBuilder.statsService(statsService);\n    return consumerBuilder.build();\n}", "CodeBleu_score": 52.85218555053489}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate\n            .builder()\n            .settings(this.settings)\n            .topic(this.getNotificationsTopic())\n            .clientId(this.getServiceId())\n            .groupId(this.getServiceId());\n    consumerBuilder.messageDecoder(new TbProtoQueueMsg<ToCoreNotificationMsg>(ToCoreNotificationMsg.getDefaultInstance()) {\n        @Override\n        public ToCoreNotificationMsg parseTo(byte[] data) throws InvalidProtocolBufferException {\n            return ToCoreNotificationMsg.parseFrom(data);\n        }\n    });\n    consumerBuilder.admin(this.admin);\n    consumerBuilder.statsService(this.statsService);\n    return consumerBuilder.build();\n}", "CodeBleu_score": 43.064889787135975}, {"code": "public TbQueueConsumer<TbProtoQueueMsg<ToCoreNotificationMsg>> createToCoreNotificationsMsgConsumer(){\n\t    TbKafkaConsumerTemplate.TbKafkaConsumerTemplateBuilder<TbProtoQueueMsg<ToCoreNotificationMsg>> consumerBuilder = TbKafkaConsumerTemplate\n            .builder();\n    consumerBuilder.settings(settings);\n    consumerBuilder.topic(getNotificationsTopic());\n    consumerBuilder.clientId(clientId);\n    consumerBuilder.groupId(groupId);\n    consumerBuilder.decoder(msg -> {\n        try {\n            return new TbProtoQueueMsg<>(UUID.randomUUID(), ToCoreNotificationMsg.parseFrom(msg.getData()));\n        } catch (InvalidProtocolBufferException e) {\n            log.warn(\"Failed to decode device attributes response\", e);\n            throw new RuntimeException(\"Failed to decode device attributes response\", e);\n        }\n    });\n    consumerBuilder.admin(admin);\n    consumerBuilder.statsService(statsService);\n    return consumerBuilder.build();\n}", "CodeBleu_score": 53.95550953764514}]}
{"instance_id": "e13a82b26338", "generation_result": [{"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (!topicNames.isEmpty()) {\n        // Create topics if necessary\n        for (String topicName : topicNames) {\n            // Create topic if necessary\n            if (!kafkaTemplate.topicExists(topicName)) {\n                kafkaTemplate.createTopic(topicName);\n                logger.info(\"Created topic: \" + topicName);\n            }\n        }\n        // Subscribe to topics\n        kafkaTemplate.subscribe(topicNames, this);\n        logger.info(\"Subscribed to topics: \" + topicNames);\n    } else {\n        // Unsubscribe from all topics\n        kafkaTemplate.unsubscribe();\n        logger.info(\"Unsubscribed from all topics\");\n    }\n}", "CodeBleu_score": 56.78513242596364}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        info(\"Unsubscribing from all topics\");\n        consumer.unsubscribe();\n    } else {\n        info(\"Subscribing to topics: {}\", topicNames);\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 58.95740064449407}, {"code": "protected void doSubscribe(List<String> topicNames){\n\t    if (topicNames.isEmpty()) {\n        log.info(\"Unsubscribing from all topics\");\n        consumer.unsubscribe();\n    } else {\n        log.info(\"Subscribing to topics: {}\", topicNames);\n        for (String topicName : topicNames) {\n            ensureTopicExists(topicName);\n        }\n        consumer.subscribe(topicNames);\n    }\n}", "CodeBleu_score": 57.85539431025166}]}
{"instance_id": "8a20d0b48703", "generation_result": [{"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = start(\"Polling for records from topic \" + getTopic() + \" for \" + durationInMillis + \"ms\");\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    try {\n        ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(ofMillis(durationInMillis));\n        if (isEmpty(consumerRecords)) {\n            trace(\"No records found\");\n            return emptyList();\n        }\n        forEach(consumerRecords, records::add);\n    } finally {\n        stop(stopwatch, \"Poll completed in \" + getTotalTimeMillis(stopwatch) + \"ms\");\n    }\n    return records;\n}", "CodeBleu_score": 46.4319050225447}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling {} for {} milliseconds\", getTopic(), durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    consumer.poll(ofMillis(durationInMillis)).forEach(records::add);\n    stopwatch.stop();\n    log.trace(\"Polled {} for {} milliseconds ({} total)\", getTopic(), durationInMillis, getTotalTimeMillis(stopwatch));\n    if (records.isEmpty()) {\n        return emptyList();\n    }\n    return records;\n}", "CodeBleu_score": 47.87028423037711}, {"code": "protected List<ConsumerRecord<String, byte[]>> doPoll(long durationInMillis){\n\t    Stopwatch stopwatch = Stopwatch.createStarted();\n    log.trace(\"Polling {} for {} millis\", getTopic(), durationInMillis);\n    List<ConsumerRecord<String, byte[]>> records = new ArrayList<>();\n    ConsumerRecords<String, byte[]> consumerRecords = consumer.poll(durationInMillis);\n    stopwatch.stop();\n    log.trace(\"Polled {} records from {} in {} millis\", consumerRecords.count(), getTopic(), stopwatch.elapsed(TimeUnit.MILLISECONDS));\n    if (consumerRecords.isEmpty()) {\n        return emptyList();\n    }\n    consumerRecords.forEach(records::add);\n    return records;\n}", "CodeBleu_score": 52.452948918750245}]}
{"instance_id": "328e4c39a8e1", "generation_result": [{"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        String topic = getTopicPattern(ctx, msg);\n        String key = getKeyPattern(ctx, msg);\n        ctx.tellSuccess(msg);\n        ctx.getExternalCallExecutor().execute(() -> publish(ctx, msg, topic, key));\n    } catch (Exception e) {\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 24.739567032522064}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    try {\n        if (initError != null) {\n            ctx.tellFailure(msg, initError);\n            return;\n        }\n        String topicPattern = getTopicPattern(ctx, msg);\n        String keyPattern = getKeyPattern(ctx, msg);\n        ctx.getExternalCallExecutor().executeAsync(() -> publish(ctx, msg, topicPattern, keyPattern));\n    } catch (Exception e) {\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 32.95767050069192}, {"code": "public void onMsg(TbContext ctx, TbMsg msg){\n\t    if (error != null) {\n        ctx.tellFailure(msg, error);\n        return;\n    }\n    try {\n        String topicPattern = getTopicPattern(ctx, msg);\n        String keyPattern = getKeyPattern(ctx, msg);\n        ctx.getExternalCallExecutor().executeAsync(() -> {\n            try {\n                publish(ctx, msg, topicPattern, keyPattern);\n            } catch (Exception e) {\n                log.error(\"Failed to publish message to Kafka\", e);\n                ctx.tellFailure(msg, e);\n            }\n        });\n    } catch (Exception e) {\n        log.error(\"Failed to process message\", e);\n        ctx.tellFailure(msg, e);\n    }\n}", "CodeBleu_score": 39.028812323048825}]}
{"instance_id": "35f835e8c387", "generation_result": [{"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        ProducerRecord<String, byte[]> record;\n        if (addMetadata) {\n            record = new ProducerRecord<>(topic, null, key, msg.getData(), createHeaders(msg));\n        } else {\n            record = new ProducerRecord<>(topic, null, key, msg.getData());\n        }\n        producer.send(record, (recordMetadata, e) -> processRecord(ctx, msg, recordMetadata, e));\n    } catch (Exception e) {\n        log.debug(\"[{}] Failed to publish msg {} to topic {}\", ctx.getSelfId(), msg.getId(), topic, e);\n    }\n}", "CodeBleu_score": 46.33840807418952}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    try {\n        if (ctx.getMetaData().getValue(\"addMetadataToKafkaHeaders\") != null) {\n            ProducerRecord<byte[], byte[]> record = new ProducerRecord<>(topic, null, msg.getId().getBytes(StandardCharsets.UTF_8), msg.getData(), this.getHeaders(msg));\n            this.getProducer().send(record, (recordMetadata, e) -> processRecord(ctx, msg, recordMetadata, e));\n        } else {\n            ProducerRecord<byte[], byte[]> record = new ProducerRecord<>(topic, null, msg.getId().getBytes(StandardCharsets.UTF_8), msg.getData());\n            this.getProducer().send(record, (recordMetadata, e) -> processRecord(ctx, msg, recordMetadata, e));\n        }\n    } catch (Exception e) {\n        log.debug(\"[{}][{}] Failed to publish message to topic [{}]\", ctx.getTenantId(), ctx.getSelfId(), topic, e);\n    }\n}", "CodeBleu_score": 49.42934954892562}, {"code": "protected void publish(TbContext ctx, TbMsg msg, String topic, String key){\n\t    if (metadataConfigs.isEmpty()) {\n        send(msg, topic, key);\n    } else {\n        add(msg, topic, key, getMetaData(msg));\n    }\n}", "CodeBleu_score": 14.576639134322402}]}
{"instance_id": "111a11189434", "generation_result": [{"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close the Kafka producer: \" + e);\n        }\n    }\n}", "CodeBleu_score": 63.12274792558317}, {"code": "public void destroy(){\n\t    try {\n        if (producer != null) {\n            producer.close();\n        }\n    } catch (Exception e) {\n        log.error(\"Failed to close the Kafka producer. Exception: {}\", e);\n    }\n}", "CodeBleu_score": 68.76096458372183}, {"code": "public void destroy(){\n\t    if (producer != null) {\n        try {\n            producer.close();\n        } catch (Exception e) {\n            logger.error(\"Failed to close Kafka producer. Exception: {}\", e);\n        }\n    }\n}", "CodeBleu_score": 68.59440359795202}]}
{"instance_id": "f5d2487100a9", "generation_result": [{"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplateBuilder = TbKafkaProducerTemplate\n            .builder();\n    ruleEngineProducerTemplateBuilder.settings(kafkaSettings);\n    ruleEngineProducerTemplateBuilder.clientId(clientId);\n    ruleEngineProducerTemplateBuilder.defaultTopic(defaultTopic);\n    ruleEngineProducerTemplateBuilder.admin(admin);\n    return ruleEngineProducerTemplateBuilder.build();\n}", "CodeBleu_score": 60.04486034919333}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplateBuilder = TbKafkaProducerTemplate\n        .builder();\n    ruleEngineProducerTemplateBuilder.settings(kafkaSettings);\n    ruleEngineProducerTemplateBuilder.clientId(\"tb-core-rule-engine-\" + serviceInfoProvider.getServiceId());\n    ruleEngineProducerTemplateBuilder.defaultTopic(PartitionService.TO_RULE_ENGINE_TOPIC);\n    ruleEngineProducerTemplateBuilder.admin(kafkaAdmin);\n    return ruleEngineProducerTemplateBuilder.build().create();\n}", "CodeBleu_score": 62.13814729653501}, {"code": "public TbQueueProducer<TbProtoQueueMsg<ToRuleEngineMsg>> createRuleEngineMsgProducer(){\n\t    TbKafkaProducerTemplate.TbKafkaProducerTemplateBuilder<TbProtoQueueMsg<ToRuleEngineMsg>> ruleEngineProducerTemplateBuilder = TbKafkaProducerTemplate\n            .builder();\n    ruleEngineProducerTemplateBuilder\n            .settings(kafkaSettings)\n            .clientId(clientId)\n            .defaultTopic(TbRuleEngineQueueConfiguration.TOPIC_RULE_ENGINE)\n            .admin(admin);\n\n    return ruleEngineProducerTemplateBuilder.build();\n}", "CodeBleu_score": 46.12131679912038}]}
{"instance_id": "886264f5ca27", "generation_result": [{"code": "private void startLogScheduling(){\n\t    Duration timeoutDuration = Duration.ofMillis(getKafkaResponseTimeoutMs());\n    long delay = getPrintIntervalMs();\n    ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor();\n    executor.scheduleWithFixedDelay(new Runnable() {\n        public void run() {\n            try {\n                if (isStatsPrintRequired()) {\n                    for (String groupId : getKeySet()) {\n                        List<TopicStatsWithLag> topicsStatsWithLag = getTopicsStatsWithLag(groupId);\n                        if (!topicsStatsWithLag.isEmpty()) {\n                            log.info(\"Consumer group {} has lagging topics: {}\", groupId, topicsStatsWithLag);\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Consumer group {} - {}\", groupId, e.getMessage());\n                log.warn(getMessage(e));\n            }\n        }\n    }, 0, delay, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 29.234751902025284}, {"code": "private void startLogScheduling(){\n\t    long timeoutMs = getKafkaResponseTimeoutMs();\n    long delayMs = timeoutMs / 2;\n    long initialDelayMs = timeoutMs;\n    ScheduledExecutorService executor = Executors.newSingleThreadScheduledExecutor();\n    executor.scheduleWithFixedDelay(new Runnable() {\n        @Override\n        public void run() {\n            try {\n                if (isStatsPrintRequired()) {\n                    Map<String, TopicsStatsWithLag> topicsStatsWithLag = getTopicsStatsWithLag();\n                    if (!topicsStatsWithLag.isEmpty()) {\n                        for (Map.Entry<String, TopicsStatsWithLag> entry : topicsStatsWithLag.entrySet()) {\n                            String groupId = entry.getKey();\n                            TopicsStatsWithLag stats = entry.getValue();\n                            if (stats.getLaggingTopics().size() > 0) {\n                                log.warn(\"Consumer group {} has lagging topics: {}\", groupId, stats.getLaggingTopics());\n                            }\n                        }\n                    }\n                }\n            } catch (Exception e) {\n                log.warn(\"Exception occurred while printing consumer group statistics: {}\", e.getMessage());\n                log.warn(\"Exception details:\", e);\n            }\n        }\n    }, initialDelayMs, delayMs, TimeUnit.MILLISECONDS);\n}", "CodeBleu_score": 34.57029537500645}, {"code": "private void startLogScheduling(){\n\t    long timeout = getKafkaResponseTimeoutMs();\n    long delay = getPrintIntervalMs();\n    scheduleWithFixedDelay(new Runnable() {\n        @Override\n        public void run() {\n            if (!isStatsPrintRequired()) {\n                return;\n            }\n            for (String groupId : getKeySet()) {\n                try {\n                    Map<String, TopicPartitionStats> topicStats = getTopicsStatsWithLag(groupId);\n                    if (!topicStats.isEmpty()) {\n                        info(\"Consumer group '{}' has lagging topics: {}\", groupId, topicStats);\n                    }\n                } catch (Exception e) {\n                    warn(\"Error while logging consumer group '{}' statistics: {}\", groupId, e.getMessage());\n                    trace(\"Error while logging consumer group '{}' statistics\", groupId, e);\n                }\n            }\n        }\n    }, ofMillis(timeout), ofMillis(delay));\n}", "CodeBleu_score": 28.414797271302504}]}
{"instance_id": "81553181cdc8", "generation_result": [{"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, 5);\n    return props;\n}", "CodeBleu_score": 82.54321802981079}, {"code": "protected Properties toAdminProps(){\n\t  Properties props = toProps();\n  props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n  props.put(AdminClientConfig.RETRIES_CONFIG, 0);\n  return props;\n}", "CodeBleu_score": 81.7031320071059}, {"code": "protected Properties toAdminProps(){\n\t    Properties props = toProps();\n    props.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, bootstrapServers);\n    props.put(AdminClientConfig.RETRIES_CONFIG, retries);\n    return props;\n}", "CodeBleu_score": 91.69084212730418}]}
{"instance_id": "3c8bf3ff31b7", "generation_result": [{"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String scopedName = getName(metricName, group);\n    Map<String, String> tags = getTags(metricName, group);\n    MetricEvent event = new MetricEvent(metric, scopedName, tags);\n\n    if (metric instanceof Counter) {\n        counters.add(event);\n    } else if (metric instanceof Gauge) {\n        gauges.add(event);\n    } else if (metric instanceof Histogram) {\n        histograms.add(event);\n    } else if (metric instanceof Meter) {\n        meters.add(event);\n    } else {\n        warn(metric, \"Unknown metric type: \" + metric.getClass());\n    }\n}", "CodeBleu_score": 48.51438549571107}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t  MetricEvent event = new MetricEvent(metricName, group);\n  if (metric instanceof Counter) {\n    counters.put(event, (Counter) metric);\n  } else if (metric instanceof Gauge) {\n    gauges.put(event, (Gauge) metric);\n  } else if (metric instanceof Histogram) {\n    histograms.put(event, (Histogram) metric);\n  } else if (metric instanceof Meter) {\n    meters.put(event, (Meter) metric);\n  } else {\n    log.warn(\"Unknown metric type: {}. This indicates that the metric type is not supported by this reporter.\",\n        metric.getClass().getName());\n  }\n}", "CodeBleu_score": 45.99064019489132}, {"code": "public void notifyOfAddedMetric(Metric metric, String metricName, MetricGroup group){\n\t    String name = getName(metricName, group);\n    MetricEvent event = new MetricEvent(name, getTags(metricName, group));\n    if (metric instanceof Counter) {\n        counters.put(name, (Counter) metric);\n        counterEvents.put(name, event);\n    } else if (metric instanceof Gauge) {\n        gauges.put(name, (Gauge) metric);\n        gaugeEvents.put(name, event);\n    } else if (metric instanceof Histogram) {\n        histograms.put(name, (Histogram) metric);\n        histogramEvents.put(name, event);\n    } else if (metric instanceof Meter) {\n        meters.put(name, (Meter) metric);\n        meterEvents.put(name, event);\n    } else {\n        warn(metric, \"Unknown metric type: %s\", metric.getClass().getName());\n    }\n}", "CodeBleu_score": 50.74876015215687}]}
{"instance_id": "77c6addc9b99", "generation_result": [{"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        return addNumberField(metricEvent, field, (Number) value);\n    } else if (value instanceof String) {\n        return addStringField(metricEvent, field, (String) value);\n    } else {\n        throw new IllegalArgumentException(\"Cannot add field of type \" + value.getClass().getName());\n    }\n}", "CodeBleu_score": 35.599148858056296}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t  Number value = gauge.getValue();\n  if (metricEvent.getFields() != null) {\n    metricEvent.getFields().put(field, value);\n  } else {\n    Map<String, Object> fields = new HashMap<String, Object>();\n    fields.put(field, value);\n    metricEvent.setFields(fields);\n  }\n  return metricEvent;\n}", "CodeBleu_score": 39.59399872589285}, {"code": "static MetricEvent addFields(MetricEvent metricEvent, String field, Gauge<?> gauge){\n\t    Object value = gauge.getValue();\n    if (value instanceof Number) {\n        return addNumberField(metricEvent, field, (Number) value);\n    } else if (value instanceof String) {\n        return addStringField(metricEvent, field, (String) value);\n    } else {\n        throw new IllegalArgumentException(\"Gauge value is not a number or string\");\n    }\n}", "CodeBleu_score": 35.20777329310538}]}
{"instance_id": "a48971ffb3e9", "generation_result": [{"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String[] gaugeValue = gauge.value().toString().split(\":\");\n    String[] lagMetrics = gaugeValue[0].split(\",\");\n    String[] currentOffsets = lagMetrics[0].split(\"\\\\[|\\\\]\");\n    String[] committedOffsets = lagMetrics[1].split(\"\\\\[|\\\\]\");\n    String[] timestampMetrics = gaugeValue[1].split(\",\");\n    String[] dataTimestamp = timestampMetrics[0].split(\"\\\\[|\\\\]\");\n    String[] kafkaLagTimestamp = timestampMetrics[1].split(\"\\\\[|\\\\]\");\n\n    if (kafkaLagTimestamp[0].equals(kafkaLagTimes.get(gauge.name()))) {\n        return metricEvent;\n    }\n\n    metricEvent.put(\"currentOffset\", currentOffsets[1]);\n    metricEvent.put(\"committedOffset\", committedOffsets[1]);\n    metricEvent.put(\"kafkaLag\", currentOffsets[1] - committedOffsets[1]);\n    metricEvent.put(\"dataTimestamp\", dataTimestamp[1]);\n    metricEvent.put(\"kafkaLagTimestamp\", kafkaLagTimestamp[1]);\n    metricEvent.setTimestamp(timestamp);\n\n    kafkaLagTimes.put(gauge.name(), kafkaLagTimestamp[1]);\n    return metricEvent;\n}", "CodeBleu_score": 34.18531629838952}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String[] metricNameComponents = metricEvent.getMetricName().split(\"\\\\.\");\n    String topic = metricNameComponents[2];\n    String partition = metricNameComponents[3];\n    String group = metricNameComponents[4];\n    String clientId = metricNameComponents[5];\n    String metric = metricNameComponents[6];\n    String metricType = metricNameComponents[7];\n    String metricValue = metricNameComponents[8];\n    String lagType = metricNameComponents[9];\n    String offset = metricNameComponents[10];\n\n    Map<String, Long> kafkaLagTimes = metricEvent.getKafkaLagTimes();\n\n    if (kafkaLagTimes.get(topic + \".\" + partition + \".\" + group + \".\" + clientId) == null ||\n            kafkaLagTimes.get(topic + \".\" + partition + \".\" + group + \".\" + clientId) != timestamp) {\n        kafkaLagTimes.put(topic + \".\" + partition + \".\" + group + \".\" + clientId, timestamp);\n        metricEvent.setTimestamp(timestamp);\n        metricEvent.setField(\"topic\", topic);\n        metricEvent.setField(\"partition\", partition);\n        metricEvent.setField(\"group\", group);\n        metricEvent.setField(\"clientId\", clientId);\n        metricEvent.setField(\"metric\", metric);\n        metricEvent.setField(\"metricType\", metricType);\n        metricEvent.setField(\"metricValue\", metricValue);\n        metricEvent.setField(\"lagType\", lagType);\n        metricEvent.setField(\"offset\", offset);\n    }\n    return metricEvent;\n}", "CodeBleu_score": 30.880825532249613}, {"code": "static MetricEvent addKafkaLagMetricFields(MetricEvent metricEvent, Long timestamp, Gauge<?> gauge){\n\t    String[] lagMetric = gauge.getValue().toString().split(\":\");\n    String topic = lagMetric[0];\n    String partition = lagMetric[1];\n    long currentOffset = Long.parseLong(lagMetric[2]);\n    long committedOffset = Long.parseLong(lagMetric[3]);\n    long kafkaLag = currentOffset - committedOffset;\n\n    if (kafkaLagTimes.containsKey(topic)) {\n        if (kafkaLagTimes.get(topic).containsKey(partition)) {\n            if (kafkaLagTimes.get(topic).get(partition).equals(kafkaLag)) {\n                return null;\n            }\n        }\n    }\n\n    metricEvent.put(\"currentOffset\", currentOffset);\n    metricEvent.put(\"committedOffset\", committedOffset);\n    metricEvent.put(\"kafkaLag\", kafkaLag);\n    metricEvent.put(\"timestamp\", timestamp);\n\n    if (!kafkaLagTimes.containsKey(topic)) {\n        kafkaLagTimes.put(topic, new HashMap<String, Long>());\n    }\n    kafkaLagTimes.get(topic).put(partition, kafkaLag);\n    metricEvent.setTimestamp(timestamp);\n    return metricEvent;\n}", "CodeBleu_score": 38.87093059439556}]}
{"instance_id": "c2080c299bb0", "generation_result": [{"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t\n    // Get the global job parameters from the StreamExecutionEnvironment\n    Properties globalJobParameters = getGlobalJobParameters(env);\n\n    // Build the Kafka properties\n    Properties kafkaProperties = buildKafkaProps(globalJobParameters);\n\n    // Create a FlinkKafkaConsumer for MetricEvent\n    FlinkKafkaConsumer<MetricEvent> metricEventConsumer = new FlinkKafkaConsumer<MetricEvent>(\n            topic,\n            new MetricEventSchema(),\n            kafkaProperties\n    );\n\n    // Set the consumer to start from specific offsets based on the given time\n    if (time != null) {\n        metricEventConsumer = setStartFromSpecificOffsets(metricEventConsumer, time, kafkaProperties);\n    }\n\n    // Add the consumer as a source to the StreamExecutionEnvironment\n    DataStreamSource<MetricEvent> metricEventSource = env.addSource(metricEventConsumer);\n\n    return metricEventSource;\n}", "CodeBleu_score": 49.17086446504689}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    // Get the global job parameters\n    Configuration config = getConfig(env);\n    String kafkaServer = config.getString(\"kafka.server\", \"localhost:9092\");\n    String kafkaGroup = config.getString(\"kafka.group\", \"metric-group\");\n    String kafkaClient = config.getString(\"kafka.client\", \"metric-client\");\n    String kafkaFormat = config.getString(\"kafka.format\", \"json\");\n\n    // Build the Kafka properties\n    Properties kafkaProps = buildKafkaProps(kafkaServer, kafkaGroup, kafkaClient, kafkaFormat);\n\n    // Create a Kafka consumer for MetricEvent\n    FlinkKafkaConsumer<MetricEvent> metricConsumer = new FlinkKafkaConsumer<>(\n        topic,\n        new MetricEventSchema(),\n        kafkaProps\n    );\n\n    // Set the consumer to start from a specific offset based on the given time\n    if (time != null) {\n        metricConsumer.setStartFromSpecificOffsets(getStartFromSpecificOffsets(kafkaServer, topic, time));\n    }\n\n    // Add the consumer as a source to the StreamExecutionEnvironment\n    DataStreamSource<MetricEvent> metricSource = env.addSource(metricConsumer);\n\n    return metricSource;\n}", "CodeBleu_score": 49.006085114135075}, {"code": "public static DataStreamSource<MetricEvent> buildSource(StreamExecutionEnvironment env, String topic, Long time) throws IllegalAccessException{\n\t    Map<String, String> globalJobParameters = getGlobalJobParameters(env);\n    Properties kafkaProps = buildKafkaProps(globalJobParameters);\n    FlinkKafkaConsumer<MetricEvent> consumer = new FlinkKafkaConsumer<>(topic, new MetricEventSchema(), kafkaProps);\n    if (time != null) {\n        consumer.setStartFromSpecificOffsets(buildOffsetByTime(globalJobParameters, time));\n    }\n    return env.addSource(consumer);\n}", "CodeBleu_score": 48.14034377480194}]}
{"instance_id": "5e828afbe8e4", "generation_result": [{"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String topic = parameterTool.getRequired(\"topic\");\n    String groupId = parameterTool.getRequired(\"group.id\") + \"-\" + time;\n    props.setProperty(\"group.id\", groupId);\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<>(props);\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(topic);\n    Map<Integer, Long> partitionTimestampMap = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        partitionTimestampMap.put(partitionInfo.partition(), time);\n    }\n    Map<KafkaTopicPartition, Long> partitionOffsetMap = consumer.offsetsForTimes(partitionTimestampMap);\n    consumer.close();\n    return partitionOffsetMap;\n}", "CodeBleu_score": 45.61817653902788}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t\n    // Set the consumer group ID using the provided time\n    props.setProperty(\"group.id\", \"kafka-connect-elasticsearch-group-\" + time);\n\n    // Create a KafkaConsumer with the properties\n    KafkaConsumer<String, String> consumer = new KafkaConsumer<String, String>(props);\n\n    // Retrieve partition information for the specified topic\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(parameterTool.getRequired(\"topic\"));\n\n    // Create a map associating each partition with the timestamp\n    Map<TopicPartition, Long> partitionTimestampMap = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        partitionTimestampMap.put(\n                new TopicPartition(partitionInfo.topic(), partitionInfo.partition()),\n                time);\n    }\n\n    // Fetch offsets for the given times\n    Map<TopicPartition, OffsetAndTimestamp> offsetAndTimestampMap = consumer.offsetsForTimes(partitionTimestampMap);\n\n    // Build a map of KafkaTopicPartition to offsets\n    Map<KafkaTopicPartition, Long> partitionOffsets = new HashMap<>();\n    for (Map.Entry<TopicPartition, OffsetAndTimestamp> entry : offsetAndTimestampMap.entrySet()) {\n        partitionOffsets.put(\n                new KafkaTopicPartition(entry.getKey().topic(), entry.getKey().partition()),\n                entry.getValue().offset());\n    }\n\n    // Close the consumer\n    consumer.close();\n\n    // Return the map of partition offsets\n    return partitionOffsets;\n}", "CodeBleu_score": 57.71080841479647}, {"code": "private static Map<KafkaTopicPartition, Long> buildOffsetByTime(Properties props, ParameterTool parameterTool, Long time){\n\t    String consumerGroup = parameterTool.getRequired(\"application.id\") + \"-\" + time;\n    props.put(\"group.id\", consumerGroup);\n    KafkaConsumer<byte[], byte[]> consumer = new KafkaConsumer<>(props);\n\n    List<PartitionInfo> partitionInfos = consumer.partitionsFor(TOPIC);\n    Map<Integer, Long> partitionToTimestamp = new HashMap<>();\n    for (PartitionInfo partitionInfo : partitionInfos) {\n        partitionToTimestamp.put(partitionInfo.partition(), time);\n    }\n\n    Map<TopicPartition, Long> partitionToOffset = consumer.offsetsForTimes(partitionToTimestamp);\n    Map<KafkaTopicPartition, Long> offsetByPartition = new HashMap<>();\n    for (Map.Entry<TopicPartition, Long> partitionOffset : partitionToOffset.entrySet()) {\n        offsetByPartition.put(\n                new KafkaTopicPartition(partitionOffset.getKey().topic(), partitionOffset.getKey().partition()),\n                partitionOffset.getValue());\n    }\n\n    consumer.close();\n    return offsetByPartition;\n}", "CodeBleu_score": 49.9457694724491}]}
{"instance_id": "28da89f56f67", "generation_result": [{"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n    MetricEvent event = new MetricEvent();\n    event.setName(\"test\");\n    event.setTags(new HashMap<String, String>());\n    event.setTimestamp(currentTimeMillis());\n    event.setFields(new HashMap<String, Object>());\n    event.getFields().put(\"field1\", \"value1\");\n    event.getFields().put(\"field2\", \"value2\");\n    producer.send(new ProducerRecord<String, String>(\"topic\", event.toJson()));\n    println(event.toJson());\n    flush(producer);\n}", "CodeBleu_score": 40.860166258243794}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"acks\", \"all\");\n    props.put(\"retries\", 0);\n    props.put(\"batch.size\", 16384);\n    props.put(\"linger.ms\", 1);\n    props.put(\"buffer.memory\", 33554432);\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    Producer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent metricEvent = new MetricEvent();\n    metricEvent.setName(\"test-event\");\n    metricEvent.setTags(new HashMap<String, String>() {{\n        put(\"test-tag\", \"test-value\");\n    }});\n    metricEvent.setTimestamp(System.currentTimeMillis());\n    metricEvent.setFields(new HashMap<String, Object>() {{\n        put(\"test-field\", \"test-value\");\n    }});\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"test-topic\", metricEvent.toJson());\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent data: \" + metricEvent.toJson());\n}", "CodeBleu_score": 53.18415116254269}, {"code": "public static void writeToKafka() throws InterruptedException{\n\t    Properties props = new Properties();\n    props.put(\"bootstrap.servers\", \"localhost:9092\");\n    props.put(\"key.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n    props.put(\"value.serializer\", \"org.apache.kafka.common.serialization.StringSerializer\");\n\n    KafkaProducer<String, String> producer = new KafkaProducer<>(props);\n\n    MetricEvent me = new MetricEvent();\n    me.setName(\"kafka-write-test\");\n    me.setTags(new HashMap<String, String>() {{\n        put(\"key1\", \"value1\");\n        put(\"key2\", \"value2\");\n    }});\n    me.setTimestamp(System.currentTimeMillis());\n    me.setFields(new HashMap<String, Object>() {{\n        put(\"field1\", \"value1\");\n        put(\"field2\", \"value2\");\n    }});\n\n    ProducerRecord<String, String> record = new ProducerRecord<>(\"metrics\", me.toJson());\n    producer.send(record);\n    producer.flush();\n    System.out.println(\"Sent: \" + me.toJson());\n}", "CodeBleu_score": 49.92750898988097}]}
{"instance_id": "14bffe09c25a", "generation_result": [{"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (levels.contains(event.getLevel()) && !event.getLoggerName().contains(\"xxx\")) {\n        try {\n            send(event);\n        } catch (Exception e) {\n            logger.warn(\"Error sending log event to Kafka\", e);\n        }\n    }\n}", "CodeBleu_score": 45.3019260625305}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (levels.contains(event.getLevel()) && !event.getLoggerName().contains(exclude)) {\n        try {\n            producer.send(new ProducerRecord<String, String>(topic, event.getLevel().toString(), layout.toSerializable(event)));\n        } catch (Exception e) {\n            logger.warn(\"Unable to send log event to Kafka: {}\", e.getMessage());\n        }\n    }\n}", "CodeBleu_score": 52.251924255011915}, {"code": "public void append(org.apache.logging.log4j.core.LogEvent event){\n\t    if (levels.contains(event.getLevel()) && !event.getLoggerName().contains(excludedLoggerName)) {\n        try {\n            producer.send(new ProducerRecord<String, String>(topic, event.getLevel().toString(), event.getMessage().getFormattedMessage()));\n        } catch (Exception e) {\n            logger.warn(\"Unable to send log event to Kafka topic \" + topic, e);\n        }\n    }\n}", "CodeBleu_score": 60.5949141316384}]}
{"instance_id": "a9e0786fb5c1", "generation_result": [{"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\tfor _, validMethod := range validTopicSuffixMethods {\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 89.40480295903943}, {"code": "func ValidateTopicSuffixMethod(method string) error{\n\t\t// Iterate through the list of valid topic suffix methods\n\tfor _, validMethod := range TopicSuffixMethods {\n\t\t// If the method matches one of the valid methods, return nil (no error)\n\t\tif method == validMethod {\n\t\t\treturn nil\n\t\t}\n\t}\n\n\t// If the method is not valid, return an error indicating the unknown topic suffix method\n\treturn fmt.Errorf(\"unknown topic suffix method: %s\", method)\n}", "CodeBleu_score": 88.76723501496981}]}
{"instance_id": "9b88d720d48a", "generation_result": [{"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif v, ok := metric.GetTag(k.RoutingTag); ok {\n\t\t\treturn v, nil\n\t\t}\n\t}\n\tif k.RoutingKey == \"random\" {\n\t\tu, err := uuid.NewV4()\n\t\tif err != nil {\n\t\t\treturn \"\", err\n\t\t}\n\t\treturn u.String(), nil\n\t}\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 86.92270400846459}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t    if k.RoutingTag != \"\" {\n        if value, ok := metric.GetTag(k.RoutingTag); ok {\n            return value, nil\n        }\n    }\n    if k.RoutingKey == \"random\" {\n        uuid, err := uuid.NewV4()\n        if err != nil {\n            return \"\", err\n        }\n        return uuid.String(), nil\n    }\n    return k.RoutingKey, nil\n}", "CodeBleu_score": 82.0550028326918}, {"code": "func (k *Kafka) routingKey(metric telegraf.Metric) (string, error) {\n\t\tif k.RoutingTag != \"\" {\n\t\tif value, ok := metric.Tags()[k.RoutingTag]; ok {\n\t\t\treturn value, nil\n\t\t}\n\t}\n\n\tif k.RoutingKey == \"random\" {\n\t\treturn uuid.NewV4().String(), nil\n\t}\n\n\treturn k.RoutingKey, nil\n}", "CodeBleu_score": 55.04022850822923}]}
{"instance_id": "dc35e80e7f8d", "generation_result": [{"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regex := range k.TopicRegexps {\n\t\tre, err := regexp.Compile(regex)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile regexp %q: %s\", regex, err)\n\t\t}\n\t\tk.regexps[i] = re\n\t}\n\treturn nil\n}", "CodeBleu_score": 61.39084993602977}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, regexpStr := range k.TopicRegexps {\n\t\tcompiledRegexp, err := regexp.Compile(regexpStr)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error compiling topic regexp %s: %s\", regexpStr, err)\n\t\t}\n\t\tk.regexps[i] = compiledRegexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 58.467125592396066}, {"code": "func (k *KafkaConsumer) compileTopicRegexps() error{\n\t\tk.regexps = make([]*regexp.Regexp, len(k.TopicRegexps))\n\tfor i, topicRegexp := range k.TopicRegexps {\n\t\tregexp, err := regexp.Compile(topicRegexp)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"failed to compile topic regexp %s: %s\", topicRegexp, err)\n\t\t}\n\t\tk.regexps[i] = regexp\n\t}\n\treturn nil\n}", "CodeBleu_score": 58.412881114648066}]}
{"instance_id": "daf09ba144b2", "generation_result": [{"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.log.Errorf(\"Message with ID %d not found\", track.ID)\n\t\treturn\n\t}\n\n\tdelete(h.undelivered, track.ID)\n\tmsg.session.MarkMessage(msg, track.Delivered)\n\th.sem.Release(1)\n}", "CodeBleu_score": 63.618988470731374}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tdefer h.mu.Unlock()\n\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\treturn\n\t}\n\tdelete(h.undelivered, track.ID)\n\n\tmsg.session.MarkMessage(msg, true)\n\ttrack.Delivered = true\n\th.log.Errorf(\"Delivery failed: %s\", track.Error)\n\th.sem <- struct{}{}\n}", "CodeBleu_score": 57.70455929375756}, {"code": "func (h *ConsumerGroupHandler) onDelivery(track telegraf.DeliveryInfo){\n\t\th.mu.Lock()\n\tmsg, ok := h.undelivered[track.ID]\n\tif !ok {\n\t\th.mu.Unlock()\n\t\th.log.Errorf(\"Message with ID %d not found\", track.ID)\n\t\treturn\n\t}\n\tmsg.session.MarkMessage(msg.message, track.Delivered)\n\tdelete(h.undelivered, track.ID)\n\th.mu.Unlock()\n\th.sem.Release(1)\n}", "CodeBleu_score": 58.433861920647814}]}
{"instance_id": "8ecf2a1efead", "generation_result": [{"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\n\tfor {\n\t\t// 1. Reserve capacity.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tdefault:\n\t\t\tif !h.Reserve(ctx) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t}\n\n\t\t// 2. Wait for a message or for the context to be done.\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\n\t\t\t// 3. Handle the message.\n\t\t\th.Handle(ctx, msg)\n\t\t}\n\t}\n}", "CodeBleu_score": 55.629528103212266}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn ctx.Err()\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Handle(ctx, msg); err != nil {\n\t\t\t\th.acc.AddError(err)\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 60.73111286738941}, {"code": "func (h *ConsumerGroupHandler) ConsumeClaim(session sarama.ConsumerGroupSession, claim sarama.ConsumerGroupClaim) error{\n\t\tctx := session.Context()\n\tfor {\n\t\tselect {\n\t\tcase <-ctx.Done():\n\t\t\treturn nil\n\t\tcase msg, ok := <-claim.Messages():\n\t\t\tif !ok {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\tif err := h.Reserve(ctx, msg); err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\t\t\th.Handle(ctx, msg)\n\t\t}\n\t}\n}", "CodeBleu_score": 65.73571129497802}]}
{"instance_id": "eba9dafa99ab", "generation_result": [{"code": "def validateLogkafkaId(logkafka_id: String){\n\t  if (logkafka_id.isEmpty) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n  }\n  if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot be \\\".\\\" or \\\"..\\\"\")\n  }\n  if (logkafka_id.length > 255) {\n    throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters\")\n  }\n  val rgx = \"\"\"^[a-zA-Z0-9_-]+$\"\"\".r\n  if (!rgx.findFirstIn(logkafka_id).isDefined) {\n    throw new IllegalCharacterInLogkafkaId(\"Logkafka ID contains invalid characters\")\n  }\n}", "CodeBleu_score": 29.06591424887631}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t    if (logkafka_id.isEmpty) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be empty.\")\n    }\n    if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be '.' or '..'\")\n    }\n    if (logkafka_id.length > 255) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be more than 255 characters.\")\n    }\n    val rgx = \"\"\"^[a-zA-Z0-9\\.\\-\\_\\:]+$\"\"\".r\n    if (!rgx.findFirstIn(logkafka_id).isDefined) {\n        throw new IllegalCharacterInLogkafkaId(\"Logkafka ID can only contain alphanumeric characters, '.', '-', '_' or ':'\")\n    }\n}", "CodeBleu_score": 27.626065818712902}, {"code": "def validateLogkafkaId(logkafka_id: String){\n\t    // Check that the ID is not empty\n    if (logkafka_id.isEmpty) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be empty\")\n    }\n\n    // Check that the ID is not equal to \".\" or \"..\"\n    if (logkafka_id.equals(\".\") || logkafka_id.equals(\"..\")) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot be equal to \\\".\\\" or \\\"..\\\"\")\n    }\n\n    // Check that the ID does not exceed the maximum allowed length\n    if (logkafka_id.length > 255) {\n        throw new IllegalArgumentException(\"Logkafka ID cannot exceed 255 characters\")\n    }\n\n    // Check that the ID contains only valid characters\n    val rgx = \"([a-zA-Z0-9]|[a-zA-Z0-9][a-zA-Z0-9\\\\-]*[a-zA-Z0-9])\"\n    if (!logkafka_id.matches(rgx)) {\n        throw new IllegalArgumentException(\"Logkafka ID can only contain alphanumeric characters and hyphens, and cannot begin or end with a hyphen\")\n    }\n}", "CodeBleu_score": 26.242745926437916}]}
{"instance_id": "45d5aefd3f6c", "generation_result": [{"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n  }", "CodeBleu_score": 67.62408264969089}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).map {\n      case err: ActorErrorResponse => \n        error(s\"Failed on input : $msg\")\n        -\\/(ApiError.from(err))\n      case o: Output =>\n        Try {\n          fn(o)\n        } match {\n          case Failure(t) => \n            error(s\"Failed on input : $msg\")\n            -\\/(ApiError.fromThrowable(t))\n          case Success(foutput) => \\/-(foutput)\n        }\n    }.recover\n  }", "CodeBleu_score": 67.62408264969089}, {"code": "  private[this] def tryWithKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => FOutput)\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t      system.actorSelection(kafkaManagerActor).ask(msg).map {\n        case err: ActorErrorResponse => \n          error(s\"Failed on input : $msg\")\n          -\\/(ApiError.from(err))\n        case o: Output =>\n          Try {\n            fn(o)\n          } match {\n            case Failure(t) => \n              error(s\"Failed on input : $msg\")\n              -\\/(ApiError.fromThrowable(t))\n            case Success(foutput) => \\/-(foutput)\n          }\n      }.recover\n    }", "CodeBleu_score": 67.87501027037392}]}
{"instance_id": "a535ce861222", "generation_result": [{"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t: Throwable => -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 75.0306295608407}, {"code": "  private[this] def withKafkaManagerActor[Input, Output, FOutput](msg: Input)\n    (fn: Output => Future[ApiError \\/ FOutput])\n    (implicit tag: ClassTag[Output]): Future[ApiError \\/ FOutput] ={\n\t    system.actorSelection(kafkaManagerActor).ask(msg).flatMap {\n      case err: ActorErrorResponse => Future.successful(-\\/(ApiError.from(err)))\n      case o: Output =>\n        fn(o)\n    }.recover {\n      case t =>\n        -\\/(ApiError.fromThrowable(t))\n    }\n  }", "CodeBleu_score": 63.84745547685695}]}
{"instance_id": "ad37d3914acc", "generation_result": [{"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val commandRequest = KMClusterCommandRequest(\n      clusterName,\n      CMCommand(\n        CMApi.RunPreferredLeaderElection,\n        Some(CMApi.RunPreferredLeaderElection.toString),\n        Some(CMApi.RunPreferredLeaderElection.toString),\n        Some(CMApi.RunPreferredLeaderElection.toString),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString(\",\")),\n        Some(topics.mkString", "CodeBleu_score": 33.650404895366165}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val cc = ClusterContext(clusterName)\n    val command = KMClusterCommandRequest(cc, PreferredReplicaLeaderElection, Some(topics))\n    kafkaManager.ask(command).mapTo[KMClusterCommandResults].map {\n      case KMClusterCommandSuccess(_, results) => \\/-(cc)\n      case KMClusterCommandError(_, error) => -\\/(ApiError(error.toString))\n    }\n  }", "CodeBleu_score": 21.50106208803578}, {"code": "  def runPreferredLeaderElection(clusterName: String, topics: Set[String]): Future[ApiError \\/ ClusterContext] ={\n\t    val commandRequest = KMClusterCommandRequest(\n      clusterName = clusterName,\n      topics = Some(topics),\n      commandType = CommandType.PreferredLeaderElection,\n      options = None\n    )\n    kafkaManager.ask(commandRequest).mapTo[KMCommandResult].map {\n      case result: KMCommandSuccess =>\n        \\/-(result.result.asInstanceOf[ClusterContext])\n      case result: KMCommandError =>\n        -\\/(ApiError(result.result.asInstanceOf[String]))\n    }\n  }", "CodeBleu_score": 24.73654264915579}]}
{"instance_id": "3ecdb2c1534f", "generation_result": [{"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap {\n    case Right(topicList) => runPreferredLeaderElection(clusterName, topicList)\n    case Left(error) => Future.successful(Left(error))\n  }\n}", "CodeBleu_score": 21.029156673489567}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap { errorOrTopicList =>\n    errorOrTopicList.fold(\n      error => Future.successful(error),\n      topicList => runPreferredLeaderElection(clusterName, topicList)\n    )\n  }\n}", "CodeBleu_score": 29.439583166917444}, {"code": "private def runPreferredLeaderElectionWithAllTopics(clusterName: String) ={\n\t  getTopicList(clusterName).flatMap { errorOrTopicList =>\n    errorOrTopicList.fold(\n      error => Future.successful(error),\n      topicList => runPreferredLeaderElection(clusterName, topicList)\n    )\n  }\n}", "CodeBleu_score": 29.439583166917444}]}
{"instance_id": "5955ade118b9", "generation_result": [{"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  implicit val ec = context.dispatcher\n  val results = tryWithKafkaManagerActor ? KMClusterCommandRequest (\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n  results.map { result \u21d2\n    result.result.collect {\n      case ApiError(errorMsg) \u21d2 errorMsg\n    }\n  }\n}", "CodeBleu_score": 28.042702735937496}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  implicit val ec = scala.concurrent.ExecutionContext.Implicits.global\n\n  val results = tryWithKafkaManagerActor ? KMClusterCommandRequest(\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n\n  results.map {\n    case ApiError(msg) => Left(msg)\n    case result =>\n      result.result.collect {\n        case -\\/(error) => error.toString\n      } match {\n        case Nil => Right(())\n        case errors => Left(errors.mkString(\", \"))\n      }\n  }\n}", "CodeBleu_score": 33.26565742049547}, {"code": "def manualPartitionAssignments(clusterName: String,\n                                 assignments: List[(String, List[(Int, List[Int])])]) = {\n\t  implicit val ec = context.dispatcher\n  val results = tryWithKafkaManagerActor ? KMClusterCommandRequest (\n    clusterName,\n    CMManualPartitionAssignments(assignments)\n  )\n  results.map {\n    case ApiError(error) =>\n      error\n    case _ =>\n      \"Success\"\n  }\n}", "CodeBleu_score": 27.218003332418373}]}
{"instance_id": "26fbc2ba1d28", "generation_result": [{"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    try {\n        // Describe the cluster to get the available nodes within a specified timeout\n        DescribeClusterResult describeClusterResult = admin.describeCluster();\n        Collection<Node> nodes = describeClusterResult.nodes().get(5, TimeUnit.SECONDS);\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"Could not retrieve any nodes from the cluster\");\n        }\n        // Select the first node's ID and request its configuration\n        Node node = nodes.iterator().next();\n        ConfigResource configResource = new ConfigResource(ConfigResource.Type.BROKER, node.idString());\n        DescribeConfigsResult describeConfigsResult = admin.describeConfigs(Collections.singleton(configResource));\n        // If no configurations are received, throw an exception\n        Map<ConfigResource, Config> configs = describeConfigsResult.all().get(5, TimeUnit.SECONDS);\n        if (configs.isEmpty()) {\n            throw new ConnectException(\"Could not retrieve any configurations from the cluster\");\n        }\n        return configs.get(configResource);\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        throw new ConnectException(\"Could not retrieve the broker configuration\", e);\n    }\n}", "CodeBleu_score": 53.6293031932658}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    try {\n        DescribeClusterResult clusterResult = admin.describeCluster();\n        Collection<Node> nodes = clusterResult.nodes().get();\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found\");\n        }\n        Node broker = nodes.iterator().next();\n        DescribeConfigsResult configsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, broker.idString())));\n        Map<ConfigResource, Config> configs = configsResult.all().get();\n        if (configs.isEmpty()) {\n            throw new ConnectException(\"No configs found\");\n        }\n        return configs.get(new ConfigResource(ConfigResource.Type.BROKER, broker.idString()));\n    } catch (ExecutionException | InterruptedException e) {\n        throw new ConnectException(\"Failed to get broker config\", e);\n    }\n}", "CodeBleu_score": 54.85899762954413}, {"code": "private Config getKafkaBrokerConfig(AdminClient admin) throws Exception{\n\t    Collection<ConfigEntry> configs = new ArrayList<>();\n\n    try {\n        DescribeClusterResult clusterResult = admin.describeCluster();\n        Collection<Node> nodes = clusterResult.nodes().get(10, TimeUnit.SECONDS);\n\n        if (nodes.isEmpty()) {\n            throw new ConnectException(\"No nodes found in the cluster\");\n        }\n\n        Node node = nodes.iterator().next();\n        DescribeConfigsResult configsResult = admin.describeConfigs(Collections.singleton(new ConfigResource(ConfigResource.Type.BROKER, node.idString())));\n        Map<ConfigResource, Config> results = configsResult.all().get(10, TimeUnit.SECONDS);\n\n        if (results.isEmpty()) {\n            throw new ConnectException(\"No configs found for the node \" + node.idString());\n        }\n\n        configs = results.get(new ConfigResource(ConfigResource.Type.BROKER, node.idString())).entries();\n    } catch (InterruptedException | ExecutionException | TimeoutException e) {\n        throw new ConnectException(\"Failed to get the broker's configuration\", e);\n    }\n\n    return new Config(configs);\n}", "CodeBleu_score": 53.37405799249153}]}
{"instance_id": "adf40b68c93e", "generation_result": [{"code": "private static Validator forKafka(final Validator validator){\n\t    return new Validator() {\n        @Override\n        public ValidationResult validate(final String subject, final Schema schema, final Iterable<byte[]> records) {\n            if (SchemaHistory.KAFKA_SCHEMA_HISTORY.equals(schema.getSchemaHistory())) {\n                return validator.validate(subject, schema, records);\n            } else {\n                return new ValidationResult(0);\n            }\n        }\n    };\n}", "CodeBleu_score": 26.903296084957233}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return new Validator() {\n        @Override\n        public void validate(final String subject, final Schema schema, final Iterable<ValidationResult> results) {\n            if (schema.getSchemaHistory() == SchemaHistory.KafkaSchemaHistory) {\n                validator.validate(subject, schema, results);\n            }\n        }\n    };\n}", "CodeBleu_score": 27.896421604646825}, {"code": "private static Validator forKafka(final Validator validator){\n\t    return new Validator() {\n        @Override\n        public void validate(final String subject, final Schema schema, final Iterable<ValidationError> errors) {\n            if (schema.getSchemaType() == SchemaType.AVRO) {\n                final AvroSchema avroSchema = (AvroSchema) schema;\n                if (avroSchema.getSchemaHistory() == SchemaHistory.KAFKA_SCHEMA_HISTORY) {\n                    validator.validate(subject, schema, errors);\n                }\n            }\n        }\n    };\n}", "CodeBleu_score": 30.074582011931927}]}
{"instance_id": "07ff1ca41c93", "generation_result": [{"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (kafkaConnectVersion == null) {\n        kafkaConnectVersion = getVersion(config.get(CONNECTOR_VERSION_CONFIG).toString());\n    }\n    return kafkaConnectVersion.compareTo(MIN_TOPIC_CREATION_VERSION) >= 0 && parseBoolean(config.get(TOPIC_CREATION_ENABLE_CONFIG).toString());\n}", "CodeBleu_score": 30.742472946823398}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (kafkaConnectVersion == null) {\n        kafkaConnectVersion = getKafkaConnectVersion(config);\n    }\n    return kafkaConnectVersion.compareTo(MIN_TOPIC_CREATION_VERSION) >= 0 && getBoolean(config, TOPIC_CREATION_ENABLE_CONFIG, true);\n}", "CodeBleu_score": 21.26490178734016}, {"code": "private synchronized Boolean isTopicCreationEnabled(Map<String, ?> config){\n\t    if (topicCreationEnabled == null) {\n        topicCreationEnabled = false\n        String topicCreationEnable = (String) config.get(\"topic.creation.enable\")\n        if (topicCreationEnable == null) {\n            topicCreationEnable = \"true\"\n        }\n        topicCreationEnabled = parseBoolean(topicCreationEnable)\n        if (topicCreationEnabled) {\n            String connectVersion = getVersion()\n            if (connectVersion != null) {\n                if (compareTo(connectVersion, \"0.10.0.0\") < 0) {\n                    log.warn(\"topic.creation.enable is not supported in Kafka Connect versions older than 0.10.0.0. Disabling topic creation.\")\n                    topicCreationEnabled = false\n                }\n            }\n        }\n    }\n    return topicCreationEnabled\n}", "CodeBleu_score": 39.83889176507319}]}
{"instance_id": "e2cc420e1e63", "generation_result": [{"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    // check for mandatory configuration options\n    if (!config.containsKey(KafkaConfig.BOOTSTRAP_SERVERS_CONFIG)) {\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires the \" + KafkaConfig.BOOTSTRAP_SERVERS_CONFIG + \" configuration to be set.\");\n    }\n    if (!config.containsKey(KafkaConfig.APPLICATION_ID_CONFIG)) {\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires the \" + KafkaConfig.APPLICATION_ID_CONFIG + \" configuration to be set.\");\n    }\n    if (!config.containsKey(KafkaConfig.KEY_SERIALIZER_CLASS_CONFIG)) {\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires the \" + KafkaConfig.KEY_SERIALIZER_CLASS_CONFIG + \" configuration to be set.\");\n    }\n    if (!config.containsKey(KafkaConfig.VALUE_SERIALIZER_CLASS_CONFIG)) {\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires the \" + KafkaConfig.VALUE_SERIALIZER_CLASS_CONFIG + \" configuration to be set.\");\n    }\n\n    // set the client ID\n    config.put(KafkaConfig.CLIENT_ID_CONFIG, config.get(KafkaConfig.APPLICATION_ID_CONFIG) + \"-offset-backing-store\");\n\n    // create the shared admin\n    final SharedTopicAdmin admin = new SharedTopicAdmin(config);\n\n    // create the offset store converter\n    final KafkaOffsetBackingStoreConverter converter = new KafkaOffsetBackingStoreConverter(config);\n\n    return new KafkaOffsetBackingStore(admin, config, converter);\n}", "CodeBleu_score": 31.94622461098223}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    if (!config.containsKey(KafkaConfig.CLIENT_ID_CONFIG)) {\n        throw new IllegalArgumentException(KafkaConfig.CLIENT_ID_CONFIG + \" must be specified in the config map\");\n    }\n\n    final String clientId = config.get(KafkaConfig.CLIENT_ID_CONFIG);\n    final Properties adminProps = new Properties();\n    adminProps.put(KafkaConfig.CLIENT_ID_CONFIG, clientId + \"-admin\");\n\n    for (final Map.Entry<String, String> entry : config.entrySet()) {\n        adminProps.put(entry.getKey(), entry.getValue());\n    }\n\n    final SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n\n    return new KafkaOffsetBackingStore(admin, clientId, converterForOffsetStore(config));\n}", "CodeBleu_score": 39.796831934518096}, {"code": "public static final KafkaOffsetBackingStore kafkaOffsetBackingStore(Map<String, String> config){\n\t    if (!config.containsKey(CommonClientConfigs.BOOTSTRAP_SERVERS_CONFIG)) {\n        throw new IllegalArgumentException(\"KafkaOffsetBackingStore requires a bootstrap servers configuration\");\n    }\n    final String clientId = config.getOrDefault(CommonClientConfigs.CLIENT_ID_CONFIG, \"\");\n    final Map<String, Object> adminProps = new HashMap<>(config);\n    adminProps.put(CommonClientConfigs.CLIENT_ID_CONFIG, clientId + \"-admin\");\n    final SharedTopicAdmin admin = new SharedTopicAdmin(adminProps);\n    final String converter = config.getOrDefault(STORE_CONVERTER_CLASS_CONFIG, \"org.apache.kafka.streams.state.internals.Murmur2StringKeyConverter\");\n    final String converterConfig = config.getOrDefault(STORE_CONVERTER_CLASS_DOC, \"\");\n    final KeyConverter keyConverter = Utils.newInstance(converter, converterConfig);\n    return new KafkaOffsetBackingStore(clientId, admin, keyConverter);\n}", "CodeBleu_score": 46.95430048605956}]}
{"instance_id": "4ecb2279231e", "generation_result": [{"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Expected key object, found: \" + node);\n    }\n    JsonNode payload = node.get(PAYLOAD_FIELD);\n    if (payload != null) {\n        node = payload;\n    }\n    Iterator<String> fieldNames = node.fieldNames();\n    if (!fieldNames.hasNext()) {\n        throw new IOException(\"Key object has no fields: \" + node);\n    }\n    String fieldName = fieldNames.next();\n    if (fieldNames.hasNext()) {\n        return readCompositeKey(node, fieldName);\n    }\n    return readSimpleKey(node, fieldName);\n}", "CodeBleu_score": 44.091071257089325}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"The node is not an object.\");\n    }\n\n    // extract payload field if present\n    if (node.has(\"payload\")) {\n        node = node.get(\"payload\");\n    }\n\n    // check if the key is simple or composite\n    final Iterator<String> fieldNames = node.fieldNames();\n    if (!fieldNames.hasNext()) {\n        throw new IOException(\"The node is an empty object.\");\n    }\n\n    final String firstFieldName = fieldNames.next();\n    if (!fieldNames.hasNext()) {\n        // simple key\n        return readValue(node.get(firstFieldName), null);\n    } else {\n        // composite key\n        return readValue(node, null);\n    }\n}", "CodeBleu_score": 44.47252411759693}, {"code": "private T readKey(JsonNode node) throws IOException{\n\t    if (!node.isObject()) {\n        throw new IOException(\"Expected object, found \" + node.getNodeType());\n    }\n    if (node.has(\"payload\")) {\n        node = node.get(\"payload\");\n    }\n    final Iterator<String> fieldNames = node.fieldNames();\n    if (!fieldNames.hasNext()) {\n        throw new IOException(\"Expected at least one field\");\n    }\n    final String keyName = fieldNames.next();\n    if (fieldNames.hasNext()) {\n        return readCompositeKey(node, keyName);\n    }\n    return readSimpleKey(node, keyName);\n}", "CodeBleu_score": 40.114794354157425}]}
{"instance_id": "b8ba1bfc7b5e", "generation_result": [{"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id, prefix, delimiter);\n    String sanitizedName = \"\";\n    boolean isSanitized = false;\n    for (int i = 0; i < topicName.length(); i++) {\n        if (isValidTopicNameCharacter(topicName.charAt(i))) {\n            sanitizedName += topicName.charAt(i);\n        } else {\n            sanitizedName += \"x\";\n            isSanitized = true;\n        }\n    }\n    if (isSanitized) {\n        warn(String.format(\"The topic name %s has been sanitized to %s\", topicName, sanitizedName));\n    }\n    return sanitizedName;\n}", "CodeBleu_score": 43.20883540094898}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = topicNameFor(id, prefix, delimiter);\n    int length = topicName.length();\n    for (int i = 0; i < length; i++) {\n        char c = topicName.charAt(i);\n        if (!isValidTopicNameCharacter(c)) {\n            warn(String.format(\"Invalid character '%s' in topic name '%s'\", c, topicName));\n            return topicName.replace(c, replacementCharacter);\n        }\n    }\n    return topicName;\n}", "CodeBleu_score": 37.81581978584101}, {"code": "public String topicNameFor(I id, String prefix, String delimiter){\n\t    String topicName = generateTopicName(id, prefix, delimiter);\n    String sanitizedTopicName = sanitizeTopicName(topicName);\n    if (sanitizedTopicName.equals(topicName)) {\n        return topicName;\n    }\n    warn(sanitizedTopicName, topicName);\n    return sanitizedTopicName;\n}", "CodeBleu_score": 19.69696687359825}]}
{"instance_id": "9cf0d74c098d", "generation_result": [{"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t\n/**\n * The ErrorHandler constructor initializes an error handler for a source connector.", "CodeBleu_score": 12.902757374447106}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t  this.connectorType = connectorType;\n  this.connectorConfig = connectorConfig;\n  this.queue = queue;\n  this.producerThrowable = new AtomicReference<>();\n  this.maxRetries = connectorConfig.getLong(ConnectorConfig.ERRORS_RETRY_TIMEOUT_CONFIG);\n  if (maxRetries < 0) {\n    this.maxRetries = Long.MAX_VALUE;\n  }\n  if (replacedErrorHandler != null) {\n    this.retries = replacedErrorHandler.retries;\n  }\n}", "CodeBleu_score": 65.28013411016471}, {"code": "public ErrorHandler(Class<? extends SourceConnector> connectorType, CommonConnectorConfig connectorConfig,\n                        ChangeEventQueue<?> queue, ErrorHandler replacedErrorHandler) {\n\t    this.connectorType = connectorType;\n    this.connectorConfig = connectorConfig;\n    this.queue = queue;\n    this.producerThrowableRef = new AtomicReference<>();\n    this.maxRetriesOnError = connectorConfig.getLong(ConnectorConfig.ERRORS_RETRY_TIMEOUT_CONFIG);\n    if (maxRetriesOnError == -1) {\n        maxRetriesOnError = Long.MAX_VALUE;\n    }\n    if (replacedErrorHandler != null) {\n        this.retries = replacedErrorHandler.retries;\n    }\n}", "CodeBleu_score": 61.659115795262935}]}
{"instance_id": "8ab4bf3a4dd8", "generation_result": [{"code": "public void validate(Configuration configuration, Field.Set fields){\n\t  for (Field field : fields) {\n    List<String> messages = field.validate(configuration.get(field.name()));\n    if (messages.isEmpty()) {\n      continue;\n    }\n    throw new ConfigException(field.name(), messages.get(0));\n  }\n}", "CodeBleu_score": 30.48071183039803}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    for (Field field : fields.getFields()) {\n        for (ValidationResult result : field.validate(configuration)) {\n            if (result.hasError()) {\n                throw new ConfigException(result.getErrorMessage());\n            }\n        }\n    }\n}", "CodeBleu_score": 29.98640404358342}, {"code": "public void validate(Configuration configuration, Field.Set fields){\n\t    for (Field field : fields) {\n        String fieldName = field.name();\n        String value = configuration.getString(fieldName);\n        List<String> errorMessages = field.validate(value);\n        if (!errorMessages.isEmpty())\n            throw new ConfigException(fieldName, value, errorMessages.get(0));\n    }\n}", "CodeBleu_score": 41.653618701848565}]}
{"instance_id": "860405dc9abb", "generation_result": [{"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (isPrimitive(oldSchema)) {\n        return oldSchema;\n    }\n    SchemaBuilder newSchemaBuilder = SchemaBuilder.struct();\n    trace(\"Adding fields from existing schema\", level);\n    for (Field oldField : oldSchema.fields()) {\n        if (isContainedIn(oldField.name(), nestedFields)) {\n            trace(\"Adding field from existing schema: \" + oldField.name(), level);\n            newSchemaBuilder.field(oldField.name(), oldField.schema());\n        }\n    }\n    trace(\"Adding fields from headers\", level);\n    for (Header header : headerToProcess.values()) {\n        if (isContainedIn(header.fieldName(), nestedFields)) {\n            trace(\"Adding field from header: \" + header.fieldName(), level);\n            newSchemaBuilder.field(header.fieldName(), header.schema());\n        }\n    }\n    trace(\"Building new schema\", level);\n    return newSchemaBuilder.build();\n}", "CodeBleu_score": 35.67018542693255}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    if (isPrimitive(oldSchema)) {\n        log.debug(\"${\"\".padLeft(level * 2)}${fieldName} is primitive, returning schema\")\n        return oldSchema\n    }\n    log.debug(\"${\"\".padLeft(level * 2)}${fieldName} is complex, building new schema\")\n    SchemaBuilder builder = copySchemaBasics(oldSchema)\n    if (nestedFields.isEmpty()) {\n        log.debug(\"${\"\".padLeft(level * 2)}${fieldName} has no nested fields, adding all headers\")\n        headerToProcess.each { String headerName, Header header ->\n            if (header.isPresent()) {\n                log.debug(\"${\"\".padLeft(level * 2)}${fieldName} adding header ${headerName}\")\n                builder.field(headerName, header.schema())\n            }\n        }\n    } else {\n        log.debug(\"${\"\".padLeft(level * 2)}${fieldName} has nested fields, adding only those headers\")\n        nestedFields.each { String nestedField ->\n            if (headerToProcess.containsKey(nestedField)) {\n                log.debug(\"${\"\".padLeft(level * 2)}${fieldName} adding header ${nestedField}\")\n                Header header = headerToProcess.get(nestedField)\n                if (header.isPresent()) {\n                    builder.field(nestedField, header.schema())\n                }\n            } else {\n                log.debug(\"${\"\".padLeft(level * 2)}${fieldName} header ${nestedField} not found\")\n            }\n        }\n    }\n    return builder.build()\n}", "CodeBleu_score": 30.918291801080045}, {"code": "private Schema buildNewSchema(String fieldName, Schema oldSchema, Map<String, Header> headerToProcess, List<String> nestedFields, int level){\n\t    Schema newSchema;\n    if (oldSchema.isPrimitive()) {\n        newSchema = oldSchema;\n        log.debug(\"${\"\".padLeft(level * 4)}primitive field: ${fieldName}\");\n    } else {\n        SchemaBuilder newSchemaBuilder = copySchemaBasics(oldSchema);\n        for (Field oldField : oldSchema.fields()) {\n            String oldFieldName = oldField.name();\n            if (nestedFields.contains(oldFieldName)) {\n                Schema oldFieldSchema = oldField.schema();\n                Schema newFieldSchema = buildNewSchema(oldFieldName, oldFieldSchema, headerToProcess, nestedFields, level + 1);\n                newSchemaBuilder.field(oldFieldName, newFieldSchema);\n            } else {\n                newSchemaBuilder.field(oldFieldName, oldField.schema());\n            }\n        }\n        for (String headerToProcessKey : headerToProcess.keySet()) {\n            Header header = headerToProcess.get(headerToProcessKey);\n            if (header.isPresent()) {\n                String headerFieldName = header.field();\n                if (nestedFields.contains(headerFieldName)) {\n                    Schema headerSchema = header.schema();\n                    Schema newFieldSchema = buildNewSchema(headerFieldName, headerSchema, headerToProcess, nestedFields, level + 1);\n                    newSchemaBuilder.field(headerFieldName, newFieldSchema);\n                } else {\n                    newSchemaBuilder.field(headerFieldName, header.schema());\n                }\n            }\n        }\n        newSchema = newSchemaBuilder.build();\n    }\n    return newSchema;\n}", "CodeBleu_score": 38.48510709956769}]}
{"instance_id": "681a0415df83", "generation_result": [{"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source == null) {\n        return null;\n    }\n\n    if (source.schema().field(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n\n    String snapshotString = source.getString(SNAPSHOT_KEY);\n    if (snapshotString == null) {\n        return null;\n    }\n\n    return SnapshotRecord.valueOf(snapshotString.toUpperCase());\n}", "CodeBleu_score": 37.663397123426506}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) != null && source.schema().field(SNAPSHOT_KEY).schema().type() == Schema.Type.STRING && source.schema().field(SNAPSHOT_KEY).schema().enumValues().contains(SNAPSHOT_STRING)) {\n        return SnapshotRecord.valueOf(source.getString(SNAPSHOT_KEY).toUpperCase());\n    }\n    return null;\n}", "CodeBleu_score": 38.812891720388244}, {"code": "public static SnapshotRecord fromSource(Struct source){\n\t    if (source.schema().field(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n\n    if (source.schema().field(SNAPSHOT_KEY).schema().type() != Schema.Type.ENUM) {\n        return null;\n    }\n\n    if (source.get(SNAPSHOT_KEY) == null) {\n        return null;\n    }\n\n    return SnapshotRecord.valueOf(source.get(SNAPSHOT_KEY).toString().toUpperCase());\n}", "CodeBleu_score": 37.75467703069608}]}
{"instance_id": "85ef1162e38a", "generation_result": [{"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String[] hyphenParts = parts[parts.length - 1].split(\"-\");\n        return Optional.of(Float.parseFloat(hyphenParts[0]));\n    } catch (NumberFormatException e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 62.93151958724679}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        return Optional.of(Float.parseFloat(version.split(\"\\\\.\")[0].split(\"-\")[0]));\n    } catch (Exception e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 36.9188973665143}, {"code": "public static Optional<Float> parse(String version) throws NumberFormatException{\n\t    try {\n        String[] parts = version.split(\"\\\\.\");\n        if (parts.length > 2) {\n            parts = Arrays.copyOfRange(parts, 0, 2);\n        }\n        String[] hyphenParts = parts[1].split(\"-\");\n        return Optional.of(Float.parseFloat(hyphenParts[0]));\n    } catch (NumberFormatException e) {\n        return Optional.empty();\n    }\n}", "CodeBleu_score": 63.67637095953207}]}
{"instance_id": "64346d69eba0", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return connector.flatMap(connectorDTO -> {\n        AccessContext context = AccessContext.builder()\n                .operationName(operationName)\n                .audit(audit)\n                .createConnector(createConnector)\n                .cluster(cluster)\n                .map(map)\n                .validateAccess(validateAccess)\n                .connectActions(connectActions)\n                .doOnEach(doOnEach)\n                .then(getCluster(clusterName)\n                        .flatMap(cluster -> getConnect(cluster, connectName)\n                                .flatMap(connect -> connect.createConnector(connectorDTO))))\n                .build();\n        return context.run(signal)\n                .map(response -> ResponseEntity.status(HttpStatus.CREATED).body(response));\n    });\n}", "CodeBleu_score": 49.23707682067799}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return this.accessContextBuilder.build(exchange)\n        .flatMap(context ->\n            this.validateAccess(context,\n                () -> this.kafkaConnectService.createConnector(clusterName, connectName, connector.block())\n            )\n        )\n        .flatMap(result ->\n            this.audit.doOnEach(signal ->\n                this.audit.audit(context, \"createConnector\", result.getStatusCode())\n            )\n        )\n        .map(result -> ResponseEntity.status(result.getStatusCode()).body(result.getConnector()));\n}", "CodeBleu_score": 31.978314106718948}, {"code": "public Mono<ResponseEntity<ConnectorDTO>> createConnector(String clusterName, String connectName,\n                                                            @Valid Mono<NewConnectorDTO> connector,\n                                                            ServerWebExchange exchange){\n\t    return connector\n        .map(newConnector -> {\n            var context = AccessContext.builder()\n                .operationName(operationName)\n                .signal(signal)\n                .actor(actor)\n                .resource(Resource.builder()\n                    .clusterName(clusterName)\n                    .connectorName(newConnector.getName())\n                    .build())\n                .build();\n\n            return context;\n        })\n        .flatMap(context -> {\n            return validateAccess(context)\n                .then(getCluster(clusterName))\n                .flatMap(cluster -> {\n                    return getConnect(cluster, connectName)\n                        .flatMap(connect -> {\n                            return connectActions.createConnector(cluster, connect, connector)\n                                .doOnEach(doOnEach(context))\n                                .then(buildResponse(cluster, connect, connector));\n                        });\n                });\n        });\n}", "CodeBleu_score": 47.38072557872518}]}
{"instance_id": "4c446fd64db6", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    return AccessContext.builder()\n            .operationName(operationName)\n            .audit(audit)\n            .connect(connectName)\n            .of(clusterName)\n            .map(cluster -> cluster.getConnect(connectName))\n            .validateAccess(operationParams ->\n                    kafkaConnectService.deleteConnector(operationParams.getCluster(),\n                            operationParams.getConnect(), connectorName))\n            .connectActions(operationParams ->\n                    kafkaConnectService.deleteConnector(operationParams.getCluster(),\n                            operationParams.getConnect(), connectorName))\n            .deleteConnector(operationParams -> connectorName)\n            .doOnEach(audit::doOnEach)\n            .then(ResponseEntity.ok().build())\n            .getCluster(clusterName)\n            .operationParams(operationParams -> operationParams\n                    .setCluster(getCluster(clusterName))\n                    .setConnect(connectName))\n            .build()\n            .builder()\n            .build();\n}", "CodeBleu_score": 28.607304195722616}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext accessContext =\n        AccessContext.builder()\n            .action(Action.DELETE)\n            .resource(Resource.of(ResourceType.CONNECTOR, clusterName, connectName, connectorName))\n            .build();\n    return validateAccess(accessContext, exchange)\n        .then(kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n        .doOnEach(audit::onDeleteConnector)\n        .then(ResponseEntity.noContent().build());\n}", "CodeBleu_score": 44.081888401839606}, {"code": "public Mono<ResponseEntity<Void>> deleteConnector(String clusterName, String connectName,\n                                                    String connectorName,\n                                                    ServerWebExchange exchange){\n\t    AccessContext accessContext = AccessContext.builder()\n        .clusterName(clusterName)\n        .connectName(connectName)\n        .connectorName(connectorName)\n        .action(Action.DELETE_CONNECTOR)\n        .build();\n\n    return validateAccess(accessContext, exchange)\n        .then(kafkaConnectService.deleteConnector(clusterName, connectName, connectorName))\n        .doOnEach(audit::doOnEach)\n        .then(build(clusterName, connectName, connectorName, exchange));\n}", "CodeBleu_score": 49.403620770823395}]}
{"instance_id": "d34a49f3ca1b", "generation_result": [{"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return getCluster(clusterName)\n            .map(cluster -> {\n                ConnectAccessContext context = ConnectAccessContext.builder()\n                        .cluster(cluster)\n                        .connect(connectName)\n                        .connectorName(connectorName)\n                        .operationName(action.getOperationName())\n                        .operationParams(action.getOperationParams())\n                        .build();\n                validateAccess(context, exchange);\n                return context;\n            })\n            .flatMap(context ->\n                    kafkaConnectService.updateConnectorState(context.getCluster(),\n                            context.getConnect(),\n                            context.getConnectorName(),\n                            action)\n                            .doOnEach(doOnEach(context))\n                            .then(Mono.just(context))\n            )\n            .map(context -> ResponseEntity.ok().build())\n            .switchIfEmpty(Mono.just(ResponseEntity.notFound().build()));\n}", "CodeBleu_score": 37.25670322705679}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t    return getCluster(clusterName)\n        .map(cluster -> {\n            KafkaConnectService kafkaConnectService = cluster.getKafkaConnectService();\n            return kafkaConnectService.getConnector(connectName, connectorName)\n                .map(connector -> {\n                    List<ConnectActionDTO> connectActions =\n                        connector.getStatus().getState().getActions().stream()\n                            .filter(a -> a.getAction().equals(action.getAction()))\n                            .collect(Collectors.toList());\n                    if (connectActions.isEmpty()) {\n                        throw new KafkaConnectException(\n                            String.format(\"The connector %s does not have an action %s\",\n                                connectorName, action.getAction()));\n                    }\n                    Map<String, String> operationParams = new HashMap<>();\n                    operationParams.put(\"cluster\", clusterName);\n                    operationParams.put(\"connect\", connectName);\n                    operationParams.put(\"connector\", connectorName);\n                    operationParams.put(\"action\", action.getAction());\n                    AccessContext context =\n                        buildAccessContext(cluster, connectName, connectorName,\n                            connectActions,\n                            \"updateConnectorState\", operationParams);\n                    validateAccess(context, exchange);\n                    return kafkaConnectService.updateConnectorState(connectName, connectorName,\n                        action);\n                });\n        })\n        .flatMap(Function.identity())\n        .doOnEach(doOnEach(audit::onConnectorStateUpdated,\n            (signal, e) -> audit.onConnectorStateUpdatedError(clusterName, connectName,\n                connectorName, action.getAction(), e)))\n        .then(Mono.just(ResponseEntity.noContent().build()));\n}", "CodeBleu_score": 37.77128916324519}, {"code": "public Mono<ResponseEntity<Void>> updateConnectorState(String clusterName, String connectName,\n                                                         String connectorName,\n                                                         ConnectorActionDTO action,\n                                                         ServerWebExchange exchange) {\n\t\n    // get the cluster\n    return getCluster(clusterName)\n        // build the context\n        .map(cluster -> build(cluster, connectName, connectorName, action))\n        // validate access\n        .flatMap(context -> validateAccess(context, exchange))\n        // update the connector state\n        .flatMap(context -> updateConnectorState(context))\n        // audit the operation\n        .flatMap(context -> audit(context, exchange))\n        // return a response entity\n        .map(context -> ResponseEntity.ok().build())\n        // doOnEach\n        .doOnEach(context -> doOnEach(context, exchange));\n}", "CodeBleu_score": 22.014702741026422}]}
{"instance_id": "199cfe41b374", "generation_result": [{"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n        .map(response -> new ResponseEntity<>(response, HttpStatus.OK));\n}", "CodeBleu_score": 27.67822566061293}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n        .map(response -> new ResponseEntity<>(response, HttpStatus.OK));\n}", "CodeBleu_score": 27.67822566061293}, {"code": "public Mono<ResponseEntity<ConnectorPluginConfigValidationResponseDTO>> validateConnectorPluginConfig{\n\t    return kafkaConnectService.validateConnectorPluginConfig(clusterName, connectName, pluginName, requestBody)\n        .map(response -> new ResponseEntity<>(response, HttpStatus.OK));\n}", "CodeBleu_score": 27.67822566061293}]}
{"instance_id": "88380ae300c4", "generation_result": [{"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    SpringApplicationBuilder builder = new SpringApplicationBuilder(KafkaUiApplication.class);\n    builder.initializers(new DynamicConfigPropertiesInitializer());\n    ConfigurableApplicationContext context = builder.run(args);\n    return context;\n}", "CodeBleu_score": 42.106099994181115}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n            .initializers(dynamicConfigPropertiesInitializer())\n            .run(args);\n}", "CodeBleu_score": 43.99171500726811}, {"code": "public static ConfigurableApplicationContext startApplication(String[] args){\n\t    return new SpringApplicationBuilder(KafkaUiApplication.class)\n            .initializers(dynamicConfigPropertiesInitializer())\n            .run(args);\n}", "CodeBleu_score": 43.99171500726811}]}
{"instance_id": "3f022876f737", "generation_result": [{"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return x -> true;\n    }\n    return x -> getStringsForSearch(x).anyMatch(containsIgnoreCase(search));\n}", "CodeBleu_score": 59.17344164331065}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    return search == null ?\n        connectorInfo -> true :\n        connectorInfo -> getStringsForSearch(connectorInfo).anyMatch(string -> containsIgnoreCase(string, search));\n}", "CodeBleu_score": 48.21637016902143}, {"code": "private Predicate<FullConnectorInfoDTO> matchesSearchTerm(@Nullable final String search){\n\t    if (search == null) {\n        return x -> true;\n    }\n    final String searchLower = search.toLowerCase();\n    return x -> getStringsForSearch(x).anyMatch(s -> s.toLowerCase().contains(searchLower));\n}", "CodeBleu_score": 57.17745850121222}]}
{"instance_id": "9754aa1ec96c", "generation_result": [{"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattenedMap = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattenedMap;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      Object value = entry.getValue();\n      if (value instanceof Map) {\n        flattenedMap.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattenedMap.put(key, value);\n      }\n    }\n    return flattenedMap;\n  }", "CodeBleu_score": 51.134673360329785}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      String newKey = prefix != null ? prefix + \".\" + key : key;\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(newKey, (Map) value));\n      } else {\n        flattened.put(newKey, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 51.415445234140634}, {"code": "  private Map<String, Object> flattenClusterProperties(@Nullable String prefix,\n                                                       @Nullable Map<String, Object> propertiesMap){\n\t    Map<String, Object> flattened = new HashMap<>();\n    if (propertiesMap == null) {\n      return flattened;\n    }\n    for (Map.Entry<String, Object> entry : propertiesMap.entrySet()) {\n      String key = entry.getKey();\n      Object value = entry.getValue();\n      if (prefix != null) {\n        key = prefix + \".\" + key;\n      }\n      if (value instanceof Map) {\n        flattened.putAll(flattenClusterProperties(key, (Map<String, Object>) value));\n      } else {\n        flattened.put(key, value);\n      }\n    }\n    return flattened;\n  }", "CodeBleu_score": 55.865047145953994}]}
{"instance_id": "99266677c846", "generation_result": [{"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    ConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys()\n        .values()\n        .stream()\n        .filter(configKey -> configKey.type() == ConfigDef.Type.PASSWORD)\n        .map(ConfigDef.ConfigKey::name)\n        .collect(Collectors.toSet());\n}", "CodeBleu_score": 66.79949964324918}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    ConfigDef configDef = new ConfigDef();\n    addClientSslSupport(configDef);\n    addClientSaslSupport(configDef);\n    return configDef.configKeys().values().stream()\n      .filter(configKey -> configKey.type == ConfigDef.Type.PASSWORD)\n      .map(configKey -> configKey.name)\n      .collect(toSet());\n  }", "CodeBleu_score": 63.45504424459898}, {"code": " private static Set<String> kafkaConfigKeysToSanitize(){\n\t    def configDef = new ConfigDef()\n    addClientSslSupport(configDef)\n    addClientSaslSupport(configDef)\n\n    return configDef.configKeys.values().stream()\n        .filter { configKey -> configKey.type == ConfigDef.Type.PASSWORD }\n        .map { configKey -> configKey.name }\n        .collect(Collectors.toSet())\n}", "CodeBleu_score": 52.046719366597316}]}
{"instance_id": "deebb6fcb0a8", "generation_result": [{"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return adminClient.describeCluster()\n            .map(ClusterDescription::getAuthorizedOperations)\n            .map(aclViewEnabled(clusterDescription))\n            .filter(this::contains)\n            .map(acl -> ClusterFeature.builder().feature(Feature.KAFKA_ACL_EDIT).enabled(true).build())\n            .switchIfEmpty(Mono.just(ClusterFeature.builder().feature(Feature.KAFKA_ACL_EDIT).enabled(false).build()));\n}", "CodeBleu_score": 28.789908448304907}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return adminClient.describeCluster()\n            .map(cluster -> cluster.authorizedOperations())\n            .map(operations -> operations.contains(AclOperation.ALTER) || operations.contains(AclOperation.ALL))\n            .filter(Boolean::booleanValue)\n            .map(aclViewEnabled -> aclViewEnabled ? ClusterFeature.KAFKA_ACL_EDIT : null)\n            .defaultIfEmpty(null);\n}", "CodeBleu_score": 31.643761035554185}, {"code": "private Mono<ClusterFeature> aclEdit(ReactiveAdminClient adminClient, ClusterDescription clusterDescription){\n\t    return contains(clusterDescription.getAuthorizedOperations(), AclOperation.ALTER, AclOperation.ALL)\n            .flatMap(allowed -> allowed ? just(KAFKA_ACL_EDIT) : empty());\n}", "CodeBleu_score": 21.333679302580045}]}
{"instance_id": "a5d8cc77955f", "generation_result": [{"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    TreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n    // Initialize the next range based on the previous range or the seek operations if the previous range is empty\n    if (prevRange.isEmpty()) {\n        for (Entry<TopicPartition, Long> seekEntry : seekOperations.entrySet()) {\n            TopicPartition tp = seekEntry.getKey();\n            Long offset = seekEntry.getValue();\n            nextRange.put(tp, new FromToOffset(offset, offset));\n        }\n    } else {\n        nextRange.putAll(prevRange);\n    }\n\n    // Calculate the number of messages to poll per partition\n    int numMessagesPerPartition = Math.max(1, Math.round(numMessagesPerPoll / (float) nextRange.size()));\n\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll,\n    // ensuring it does not go below the beginning offset\n    for (Entry<TopicPartition, FromToOffset> rangeEntry : nextRange.entrySet()) {\n        TopicPartition tp = rangeEntry.getKey();\n        FromToOffset range = rangeEntry.getValue();\n        long startOffset = range.fromOffset;\n        long endOffset = range.toOffset;\n        long numMessages = endOffset - startOffset;\n        long numMessagesToPoll = Math.min(numMessagesPerPartition, numMessages);\n        long newStartOffset = Math.max(startOffset, endOffset - numMessagesToPoll);\n        nextRange.put(tp, new FromToOffset(newStartOffset, endOffset));\n    }\n\n    return nextRange;\n}", "CodeBleu_score": 36.92402399431384}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    // initialize the range to read from\n    TreeMap<TopicPartition, FromToOffset> range = new TreeMap<>();\n    if (prevRange.isEmpty()) {\n        // initialize the range to read from based on the previous range or the offsets from seek operations if the previous range is empty\n        for (Entry<TopicPartition, FromToOffset> seekEntry : seekOperations.entrySet()) {\n            TopicPartition tp = seekEntry.getKey();\n            FromToOffset fromToOffset = seekEntry.getValue();\n            range.put(tp, new FromToOffset(fromToOffset.getBegin(), fromToOffset.getEnd()));\n        }\n    } else {\n        // initialize the range to read from based on the previous range\n        for (Entry<TopicPartition, FromToOffset> prevEntry : prevRange.entrySet()) {\n            TopicPartition tp = prevEntry.getKey();\n            FromToOffset fromToOffset = prevEntry.getValue();\n            range.put(tp, new FromToOffset(fromToOffset.getBegin(), fromToOffset.getEnd()));\n        }\n    }\n\n    // calculate the number of messages to poll per partition\n    long numMessagesPerPartition = Math.max(1, Math.round(this.maxMessagesPerPartition / (double) range.size()));\n\n    // for each topic partition, determine the start offset and adjust it based on the number of messages to poll, ensuring it does not go below the beginning offset\n    for (Entry<TopicPartition, FromToOffset> rangeEntry : range.entrySet()) {\n        TopicPartition tp = rangeEntry.getKey();\n        FromToOffset fromToOffset = rangeEntry.getValue();\n        long startOffset = fromToOffset.getBegin();\n        long endOffset = fromToOffset.getEnd();\n        long numMessagesToPoll = Math.min(numMessagesPerPartition, endOffset - startOffset);\n        startOffset = Math.max(startOffset, endOffset - numMessagesToPoll);\n        range.put(tp, new FromToOffset(startOffset, endOffset));\n    }\n\n    return range;\n}", "CodeBleu_score": 33.03957774605108}, {"code": "protected TreeMap<TopicPartition, FromToOffset> nextPollingRange(TreeMap<TopicPartition, FromToOffset> prevRange,\n                                                                   SeekOperations seekOperations){\n\t    TreeMap<TopicPartition, FromToOffset> nextRange = new TreeMap<>();\n\n    // If the previous range is empty, initialize the next range with the offsets from seek operations.\n    if (prevRange.isEmpty()) {\n        nextRange.putAll(seekOperations.getBeginOffsets());\n    } else {\n        // If the previous range is not empty, initialize the next range with the previous range.\n        nextRange.putAll(prevRange);\n    }\n\n    // Calculate the number of messages to poll per partition.\n    int numMessagesToPoll = (int) Math.ceil(Math.max(0, (double) (getMaxPollRecords() - getValue().size()) /\n            nextRange.size()));\n\n    // For each topic partition, determine the start offset and adjust it based on the number of messages to poll.\n    for (Map.Entry<TopicPartition, FromToOffset> entry : nextRange.entrySet()) {\n        TopicPartition tp = entry.getKey();\n        FromToOffset fromToOffset = entry.getValue();\n\n        // If the offset to poll from is less than the beginning offset, set the offset to the beginning offset.\n        if (fromToOffset.fromOffset < getBeginOffsets().get(tp)) {\n            fromToOffset.fromOffset = getBeginOffsets().get(tp);\n        }\n\n        // Adjust the offset to poll from based on the number of messages to poll.\n        fromToOffset.toOffset = Math.min(fromToOffset.fromOffset + numMessagesToPoll, getEndOffsets().get(tp));\n\n        // Set the new offset range for the topic partition.\n        nextRange.put(tp, fromToOffset);\n    }\n\n    return nextRange;\n}", "CodeBleu_score": 41.40932424243593}]}
{"instance_id": "c4c657caeba5", "generation_result": [{"code": "public void doLaunch(final MessageInput input){\n\t    final String groupId = getString(input, KafkaInputProperties.ZOOKEEPER_GROUP);\n    final String topic = getString(input, KafkaInputProperties.TOPIC_SELECT);\n    final String brokers = getString(input, KafkaInputProperties.BROKERS);\n    final String zookeeperConnect = getString(input, KafkaInputProperties.ZOOKEEPER_CONNECT);\n    final String zookeeperGroup = getString(input, KafkaInputProperties.ZOOKEEPER_GROUP);\n    final String zookeeperTopic = getString(input, KafkaInputProperties.ZOOKEEPER_TOPIC);\n    final String zookeeperOffset = getString(input, KafkaInputProperties.ZOOKEEPER_OFFSET);\n    final String zookeeperMaxWaitTime = getString(input, KafkaInputProperties.ZOOKEEPER_MAX_WAIT_TIME);\n    final String zookeeperMaxRetries = getString(input, KafkaInputProperties.ZOOKEEPER_MAX_RETRIES);\n    final String zookeeperBackoff = getString(input, KafkaInputProperties.ZOOKEEPER_BACKOFF);\n    final String zookeeperAutoCommit = getString(input, KafkaInputProperties.ZOOKEEPER_AUTO_COMMIT);\n    final String zookeeperAutoCommitInterval = getString(input, KafkaInputProperties.ZOOKEEPER_AUTO_COMMIT_INTERVAL);\n    final String zookeeperFetchSize = getString(input, KafkaInputProperties.ZOOKEEPER_FETCH_SIZE);\n    final String zookeeperDecoder = getString(input, KafkaInputProperties.ZOOKEEPER_DECODER);\n    final String zookeeperDecoderCharset = getString(input, KafkaInputProperties.ZOOKEEPER_DECODER_CHARSET);\n    final String zookeeperDecoderPattern = getString(input, KafkaInputProperties.ZOOKEEPER_DECODER_PATTERN);\n    final String zookeeperDecoderPatternFields = getString(input, KafkaInputProperties.ZOOKE", "CodeBleu_score": 22.729007392898804}, {"code": "public void doLaunch(final MessageInput input){\n\t    // Initialize the input\n    input.initialize();\n\n    // Check if legacy mode is enabled\n    if (input.isLegacyModeEnabled()) {\n        // Validate the legacy mode configuration\n        input.validateLegacyModeConfiguration();\n\n        // Launch the legacy input\n        doLaunchLegacy(input);\n    } else {\n        // Validate the configuration\n        input.validateConfiguration();\n\n        // Launch the consumer input\n        doLaunchConsumer(input);\n    }\n\n    // Wait for the server to be running\n    awaitRunning();\n\n    // Register for server lifecycle events\n    register();\n\n    // Schedule a task to update the last second bytes read every second\n    scheduleAtFixedRate(new Runnable() {\n        @Override\n        public void run() {\n            input.updateLastSecondBytesRead();\n        }\n    }, 1, 1, TimeUnit.SECONDS);\n}", "CodeBleu_score": 17.36885563786615}, {"code": "public void doLaunch(final MessageInput input){\n\t    final String inputName = input.getName();\n    final String inputType = input.getType();\n\n    final boolean isLegacyMode = getBoolean(input, LEGACY_MODE, DEFAULT_LEGACY_MODE);\n    final boolean isZookeeperMode = getBoolean(input, ZOOKEEPER_MODE, DEFAULT_ZOOKEEPER_MODE);\n\n    if (isLegacyMode) {\n        final String bootstrapServers = getString(input, BOOTSTRAP_SERVERS, DEFAULT_BOOTSTRAP_SERVERS);\n        if (isNullOrEmpty(bootstrapServers)) {\n            throw new IllegalStateException(String.format(\n                    \"Bootstrap servers cannot be empty when using %s in legacy mode\", inputType));\n        }\n        doLaunchLegacy(input, bootstrapServers);\n    } else {\n        final String zookeeperConnect = getString(input, ZOOKEEPER_CONNECT, DEFAULT_ZOOKEEPER_CONNECT);\n        if (isNullOrEmpty(zookeeperConnect)) {\n            throw new IllegalStateException(String.format(\n                    \"ZooKeeper connect cannot be empty when using %s in non-legacy mode\", inputType));\n        }\n        if (isZookeeperMode) {\n            doLaunchConsumer(input, zookeeperConnect);\n        } else {\n            doLaunchConsumer(input, zookeeperConnect, getString(input, BOOTSTRAP_SERVERS, DEFAULT_BOOTSTRAP_SERVERS));\n        }\n    }\n\n    // Wait for the server to be running\n    awaitRunning(input);\n\n    // Register for server lifecycle events\n    final LifecycleStateChange listener = new LifecycleStateChange() {\n        @Override\n        public void stateChanged(final LifecycleStateChange.State state) {\n            lifecycleStateChange(input, state);\n        }\n    };\n    register(input, listener);\n\n    // Schedule a task to update the last second bytes read every second\n    scheduleAtFixedRate(input, new Runnable() {\n        @Override\n        public void run() {\n            set(input, LAST_SECOND_BYT", "CodeBleu_score": 37.73136350729365}]}
{"instance_id": "dffe85dbb47b", "generation_result": [{"code": "private void insertCustomProperties(Properties props){\n\t    try {\n        Properties customProps = new Properties();\n        customProps.load(new StringReader(getCustomProperties()));\n        props.putAll(customProps);\n    } catch (IOException e) {\n        error(\"Failed to load custom properties: \" + e.getMessage());\n    }\n}", "CodeBleu_score": 36.90543802121093}, {"code": "private void insertCustomProperties(Properties props){\n\t    String customProps = getString(CUSTOM_PROPERTIES_KEY);\n    if (customProps == null) {\n        return;\n    }\n\n    try {\n        Properties customPropsObj = new Properties();\n        customPropsObj.load(new StringReader(customProps));\n        props.putAll(customPropsObj);\n    } catch (IOException e) {\n        error(\"Failed to load custom properties\", e);\n    }\n}", "CodeBleu_score": 46.89060162865987}, {"code": "private void insertCustomProperties(Properties props){\n\t    String customProps = getString(R.string.custom_properties);\n    if (customProps != null) {\n        try {\n            props.load(new StringReader(customProps));\n        } catch (IOException e) {\n            Log.e(TAG, \"Could not load custom properties.\");\n        }\n    }\n}", "CodeBleu_score": 38.588349003271006}]}
{"instance_id": "ea146a7bc30c", "generation_result": [{"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    List<RawMessageEvent> filtered = entries.stream()\n        .filter(Objects::nonNull)\n        .collect(Collectors.toList());\n\n    if (filtered.isEmpty()) {\n        return;\n    }\n\n    int totalMessageBytes = filtered.stream()\n        .mapToInt(RawMessageEvent::getEncodedRawMessage)\n        .sum();\n\n    try {\n        call(() -> writeToJournal(filtered), \"Write to journal\");\n    } catch (MessageQueueException e) {\n        throw new MessageQueueException(\"Failed to write to journal\", e);\n    }\n\n    writtenMessages.addAndGet(filtered.size());\n    writtenBytes.addAndGet(totalMessageBytes);\n}", "CodeBleu_score": 35.98457142697388}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t    List<JournalEntry> journalEntries = entries.stream()\n            .filter(Objects::nonNull)\n            .map(this::toJournalEntry)\n            .collect(Collectors.toList());\n    int messageBytes = journalEntries.stream()\n            .mapToInt(JournalEntry::getLength)\n            .sum();\n\n    try {\n        call(() -> journal.write(journalEntries), retryPolicy, \"Write to journal failed\");\n    } catch (Exception e) {\n        error(\"Write to journal failed\", e);\n        throw new MessageQueueException(\"Write to journal failed\", e);\n    }\n\n    writtenMessages.addAndGet(journalEntries.size());\n    writtenBytes.addAndGet(messageBytes);\n}", "CodeBleu_score": 41.706332754850216}, {"code": "public void write(List<RawMessageEvent> entries) throws MessageQueueException{\n\t  List<JournalEntry> journalEntries = entries.stream()\n      .filter(Objects::nonNull)\n      .map(this::toJournalEntry)\n      .collect(Collectors.toList());\n\n  int totalMessageBytes = journalEntries.stream()\n      .mapToInt(JournalEntry::getEncodedRawMessage)\n      .sum();\n\n  int retries = 0;\n  while (true) {\n    try {\n      long writtenBytes = writeToJournal(journalEntries);\n      writtenMessages.addAndGet(journalEntries.size());\n      this.writtenBytes.addAndGet(writtenBytes);\n      break;\n    } catch (MessageQueueException e) {\n      if (retries >= MAX_RETRIES) {\n        throw e;\n      }\n      retries++;\n      try {\n        Thread.sleep(RETRY_BACKOFF_MS * retries);\n      } catch (InterruptedException ie) {\n        Thread.currentThread().interrupt();\n        throw new MessageQueueException(ie);\n      }\n    }\n  }\n}", "CodeBleu_score": 44.540185806318284}]}
{"instance_id": "944e77614042", "generation_result": [{"code": "public void acknowledge(List<Message> messages){\n\t    if (messages.isEmpty()) {\n        return;\n    }\n    Message message = messages.get(0);\n    MessageQueueId messageQueueId = message.getQueueId();\n    if (messageQueueId != null) {\n        MessageQueueId max = messageQueueId.max(messages.stream().map(Message::getQueueId).filter(Objects::nonNull).max(MessageQueueId::compareTo).orElse(null));\n        if (max != null) {\n            messageQueueId.getQueue().acknowledge(max);\n        }\n    }\n    metrics.mark(messages.size());\n}", "CodeBleu_score": 45.4567592907978}, {"code": "public void acknowledge(List<Message> messages){\n\t    if (messages.isEmpty()) {\n        return;\n    }\n    Message maxMessage = messages.stream()\n        .max(Comparator.comparing(Message::getQueueId))\n        .orElseThrow(() -> new IllegalStateException(\"No message found\"));\n    if (maxMessage.getQueueId() > 0) {\n        acknowledge(maxMessage.getQueueId());\n    }\n    metrics.mark(messages.size());\n}", "CodeBleu_score": 44.89491170732119}, {"code": "public void acknowledge(List<Message> messages){\n\t    if (messages == null || messages.isEmpty()) {\n        return;\n    }\n    Message lastMessage = messages.get(messages.size() - 1);\n    if (lastMessage.getQueueId() != null) {\n        this.acknowledgedMessages.mark(lastMessage.getQueueId());\n    }\n}", "CodeBleu_score": 25.769738836794332}]}
{"instance_id": "981280879490", "generation_result": [{"code": "private void registerLegacyMetrics(){\n\t    metricRegistry.getMetrics().entrySet().stream()\n        .filter(this::startsWith)\n        .forEach(this::register);\n}", "CodeBleu_score": 7.316305279109447}, {"code": "private void registerLegacyMetrics(){\n\t    getMetrics().entrySet().stream()\n        .filter(entry -> entry.getKey().startsWith(getClass().getName()))\n        .forEach(entry -> {\n            String legacyMetricName = entry.getKey().replace(getClass().getName(), \"kafka.journal.\");\n            try {\n                register(legacyMetricName, entry.getValue());\n            } catch (IllegalArgumentException e) {\n                warn(\"Failed to register legacy metric name \" + legacyMeticName + \" for \" + entry.getKey(), e);\n            }\n        });\n}", "CodeBleu_score": 48.54755702967028}, {"code": "private void registerLegacyMetrics(){\n\t    metricRegistry.getMetrics().entrySet().stream()\n            .filter(entry -> entry.getKey().startsWith(LocalKafkaJournal.class.getName()))\n            .forEach(entry -> {\n                String legacyMetricName = entry.getKey().replace(LocalKafkaJournal.class.getName(), \"org.apache.brooklyn.entity.nosql.kafka.KafkaJournal\");\n                try {\n                    metricRegistry.register(legacyMetricName, entry.getValue());\n                } catch (IllegalArgumentException e) {\n                    LOG.warn(\"Could not register legacy metric: \" + entry.getKey() + \" under \" + legacyMetricName, e);\n                }\n            });\n}", "CodeBleu_score": 60.79910978383314}]}
{"instance_id": "3ca34bfd2d64", "generation_result": [{"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.timer(metricName);\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 21.97987496955459}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.register(metricName, new Timer(new HdrBuilder().withHighestTrackableValue(3600000000000L).withSignificantDigits(3).build()));\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.getTimers().get(metricName);\n    }\n}", "CodeBleu_score": 26.5418893882384}, {"code": "private Timer registerHdrTimer(MetricRegistry metricRegistry, final String metricName){\n\t    try {\n        return metricRegistry.register(metricName, new Timer(new SlidingWindowReservoir(1000)));\n    } catch (IllegalArgumentException e) {\n        return metricRegistry.timer(metricName);\n    }\n}", "CodeBleu_score": 22.995473625402052}]}
{"instance_id": "e1d07a1fa986", "generation_result": [{"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.gauge(name, () -> {\n            if (size() == 0) {\n                return 0;\n            }\n\n            if (getCommittedOffset() == defaultOffset) {\n                return getLogEndOffset() - getLogStartOffset();\n            }\n\n            return getLogEndOffset() - getCommittedOffset();\n        });\n    } catch (IllegalArgumentException e) {\n        // Ignore if already registered.\n    }\n}", "CodeBleu_score": 59.064273880475405}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.gauge(name, () -> {\n            if (size() == 0) {\n                return 0;\n            } else if (committedOffset == defaultOffset) {\n                return getLogEndOffset() - getLogStartOffset();\n            } else {\n                return getLogEndOffset() - committedOffset;\n            }\n        });\n    } catch (IllegalArgumentException e) {\n        log.warn(\"Metric already registered: \" + name);\n    }\n}", "CodeBleu_score": 62.21979657304827}, {"code": "private void registerUncommittedGauge(MetricRegistry metricRegistry, String name){\n\t    try {\n        metricRegistry.register(name, (Gauge<Integer>) () -> {\n            if (size() == 0) {\n                return 0;\n            }\n            if (getCommittedOffset() == 0) {\n                return (int) (getLogEndOffset() - getLogStartOffset());\n            }\n            return (int) (getLogEndOffset() - getCommittedOffset());\n        });\n    } catch (IllegalArgumentException e) {\n        // Ignore if already registered.\n    }\n}", "CodeBleu_score": 53.60420326882842}]}
{"instance_id": "8b30a387069f", "generation_result": [{"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t    if (messages.isEmpty()) {\n        debug(\"No messages to flush for partition {}\", partition)\n        return lastOffset\n    }\n    val messageSet = new ByteBufferMessageSet(NoCompressionCodec, messages: _*)\n    debug(\"Flushing {} messages for partition {}\", messageSet.sizeInBytes, partition)\n    val info = log.append(messageSet, assignOffsets = true)\n    val lastOffset = info.lastOffset\n    debug(\"Flushed {} messages for partition {} with last offset {}\", messageSet.sizeInBytes, partition, lastOffset)\n    markMessagesWritten(messageSet.sizeInBytes)\n    lastOffset\n}", "CodeBleu_score": 37.37986816831182}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t  if (messages.isEmpty()) {\n    debug(\"No messages to flush.\");\n    return lastOffset;\n  }\n\n  val messageSet = new ByteBufferMessageSet(NoCompressionCodec, messages: _*);\n  val messageSetSize = messageSet.sizeInBytes;\n  debug(\"Flushing %d messages of size %d bytes to log %s.\",\n    messages.size, messageSetSize, log.name);\n\n  val offset = log.append(messageSet, assignOffsets = true).lastOffset;\n  debug(\"Flushed %d messages of size %d bytes to log %s with offset %d.\",\n    messages.size, messageSetSize, log.name, offset);\n\n  messagesWritten += messages.size;\n  bytesWritten += messageSetSize;\n\n  return offset;\n}", "CodeBleu_score": 40.072358844973316}, {"code": "private long flushMessages(List<Message> messages, long payloadSize){\n\t  if (messages.isEmpty()) {\n    debug(\"Message set is empty, ignoring\");\n    return lastOffset;\n  }\n  val messageSet = new ByteBufferMessageSet(NoCompressionCodec, messages: _*);\n  debug(\"Writing \" + messages.size + \" messages of \" + payloadSize + \" bytes to log \" + log.name);\n  val info = log.append(messageSet, assignOffsets = true);\n  debug(\"Completed write of \" + messages.size + \" messages of \" + payloadSize + \" bytes with offset \" + info.firstOffset + \" - \" + info.lastOffset + \".\");\n  mark(info.records.size);\n  return info.lastOffset;\n}", "CodeBleu_score": 34.73529329703267}]}
{"instance_id": "ee338b61e75d", "generation_result": [{"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        log.info(\"Closing Kafka AdminClient instances for cluster {}\", clusterPhyId)\n        lock.lock()\n        List<AdminClient> adminClientList = adminClientMap.get(clusterPhyId)\n        if (adminClientList == null) {\n            log.info(\"No Kafka AdminClient instances found for cluster {}\", clusterPhyId)\n            return\n        }\n        log.info(\"Closing {} Kafka AdminClient instances for cluster {}\", adminClientList.size(), clusterPhyId)\n        try {\n            adminClientList.forEach({ adminClient -> adminClient.close() })\n            log.info(\"Successfully closed {} Kafka AdminClient instances for cluster {}\", adminClientList.size(), clusterPhyId)\n        } catch (Exception e) {\n            log.error(\"Failed to close one or more Kafka AdminClient instances for cluster {}\", clusterPhyId, e)\n        }\n    } finally {\n        lock.unlock()\n    }\n}", "CodeBleu_score": 45.36237592304428}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    try {\n        adminClientMapLock.lock()\n        List<AdminClient> clientList = adminClientMap.get(clusterPhyId)\n        if (clientList == null) {\n            adminClientMapLock.unlock()\n            return\n        }\n        LOG.info(\"Closing Kafka AdminClient instances for cluster \" + clusterPhyId)\n        clientList.each { client ->\n            try {\n                client.close()\n            } catch (Exception e) {\n                LOG.error(\"Failed to close Kafka AdminClient instance for cluster \" + clusterPhyId, e)\n            }\n        }\n        adminClientMap.remove(clusterPhyId)\n        adminClientMapLock.unlock()\n    } catch (Exception e) {\n        LOG.error(\"Failed to close Kafka AdminClient instances for cluster \" + clusterPhyId, e)\n    } finally {\n        adminClientMapLock.unlock()\n    }\n}", "CodeBleu_score": 41.38033094449397}, {"code": "private void closeKafkaAdminClient(Long clusterPhyId) {\n\t    def lock = new Object()\n    synchronized (lock) {\n        try {\n            log.info(\"Closing Kafka AdminClient for cluster {}\", clusterPhyId)\n            def adminClientList = getAdminClientList(clusterPhyId)\n            if (!adminClientList) {\n                log.info(\"No Kafka AdminClient instances found for cluster {}\", clusterPhyId)\n                return\n            }\n            adminClientList.each {\n                try {\n                    it.close()\n                } catch (Exception e) {\n                    log.error(\"Failed to close Kafka AdminClient for cluster {}\", clusterPhyId, e)\n                }\n            }\n            log.info(\"Successfully closed all Kafka AdminClient instances for cluster {}\", clusterPhyId)\n        } finally {\n            lock.unlock()\n        }\n    }\n}", "CodeBleu_score": 40.381920599417484}]}
{"instance_id": "6f0b935b971c", "generation_result": [{"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList != null) {\n        for (AdminClient adminClient : adminClientList) {\n            try {\n                adminClient.close(Duration.ofSeconds(30));\n            } catch (Exception e) {\n                success = false;\n                LOG.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e);\n            }\n        }\n    }\n    return success;\n}", "CodeBleu_score": 66.31490932692448}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    if (adminClientList == null) {\n        return true;\n    }\n\n    boolean success = true;\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(ofSeconds(30));\n        } catch (Exception e) {\n            LOG.error(\"Failed to close AdminClient for cluster \" + clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 62.87774175874748}, {"code": "private boolean closeAdminClientList(Long clusterPhyId, List<AdminClient> adminClientList){\n\t    boolean success = true;\n    if (adminClientList == null) {\n        return true;\n    }\n    for (AdminClient adminClient : adminClientList) {\n        try {\n            adminClient.close(Duration.ofSeconds(30));\n        } catch (Exception e) {\n            log.error(\"Failed to close AdminClient for cluster {}\", clusterPhyId, e);\n            success = false;\n        }\n    }\n    return success;\n}", "CodeBleu_score": 79.06858596039407}]}
{"instance_id": "b5475aa94c1a", "generation_result": [{"code": "public void stop() {\n\t\tif (isRunning()) {\n\t\tapp.stop();\n\t\tint attempts = 0;\n\t\twhile (isRunning() && attempts < 5) {\n\t\t\ttry {\n\t\t\t\tThread.sleep(1000);\n\t\t\t} catch (InterruptedException e) {\n\t\t\t\tthrow new IllegalStateException(e);\n\t\t\t}\n\t\t\tattempts++;\n\t\t}\n\t\tapp = null;\n\t}\n}", "CodeBleu_score": 56.04689713675165}, {"code": "public void stop() {\n\t    if (isRunning()) {\n        app.stop();\n        for (int i = 0; i < 5; i++) {\n            if (!app.isRunning()) {\n                break;\n            }\n            try {\n                sleep(1000);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(e);\n            }\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 43.45667222406056}, {"code": "public void stop() {\n\t    if (isRunning()) {\n        app.stop();\n        int attempts = 0;\n        while (isRunning() && attempts < 5) {\n            try {\n                sleep(1000);\n            } catch (InterruptedException e) {\n                throw new IllegalStateException(\"Thread interrupted while waiting for app to stop\", e);\n            }\n            attempts++;\n        }\n        if (isRunning()) {\n            throw new IllegalStateException(\"Application failed to stop after \" + attempts + \" attempts\");\n        }\n        app = null;\n    }\n}", "CodeBleu_score": 43.609189005574855}]}
{"instance_id": "5da405de9e3d", "generation_result": [{"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config);\n    eurekaServerRunner.enableTls();\n    eurekaServerRunner.setKeyStore(keyStoreFile, keyStorePassword);\n    eurekaServerRunner.setTrustStore(trustStoreFile, trustStorePassword);\n    eurekaServerRunner.start();\n    return eurekaServerRunner;\n}", "CodeBleu_score": 40.15450447946925}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner server = new EurekaServerRunner(config)\n    server.enableTls()\n    server.setKeyStore(keyStore, keyStorePassword)\n    server.setTrustStore(trustStore, trustStorePassword)\n    server.start()\n    return server\n}", "CodeBleu_score": 45.080599131095326}, {"code": "static EurekaServerRunner startEurekaServer(Class config){\n\t    EurekaServerRunner eurekaServerRunner = new EurekaServerRunner(config)\n    eurekaServerRunner.enableTls()\n    eurekaServerRunner.setKeyStore(keyStoreFile, keyStorePassword)\n    eurekaServerRunner.setTrustStore(trustStoreFile, trustStorePassword)\n    eurekaServerRunner.start()\n    return eurekaServerRunner\n}", "CodeBleu_score": 33.10197437076081}]}
{"instance_id": "19cbf70751b2", "generation_result": [{"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    def client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTlsClient()\n    client.start()\n    return client\n}", "CodeBleu_score": 50.186866378097235}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\")\n    client.enableTlsClient()\n    client.start()\n    return client\n}", "CodeBleu_score": 52.620036415058436}, {"code": "static EurekaClientRunner startService(EurekaServerRunner server, Class config){\n\t    EurekaClientRunner client = new EurekaClientRunner(config, server, \"testservice\");\n    client.enableTlsClient();\n    client.start();\n    return client;\n}", "CodeBleu_score": 62.55304344056943}]}
{"instance_id": "d6ccff5c0536", "generation_result": [{"code": "static void createCertificates() throws Exception{\n\t    // Create the CA certificate\n    KeyTool caKeyTool = new KeyTool(true);\n    caKeyTool.setAlias(CA_ALIAS);\n    caKeyTool.setKeyAlgorithm(KEY_ALGORITHM);\n    caKeyTool.setKeySize(KEY_SIZE);\n    caKeyTool.setValidity(VALIDITY);\n    caKeyTool.setDistinguishedName(CA_DISTINGUISHED_NAME);\n    caKeyTool.setOutput(OUTPUT_DIR);\n    caKeyTool.setPassword(CA_PASSWORD);\n    caKeyTool.setValidity(VALIDITY);\n    caKeyTool.generateKeyPair();\n    caKeyTool.createCertificate(true);\n    saveCert(caKeyTool);\n    // Create the server certificate\n    KeyTool serverKeyTool = new KeyTool(true);\n    serverKeyTool.setAlias(SERVER_ALIAS);\n    serverKeyTool.setKeyAlgorithm(KEY_ALGORITHM);\n    serverKeyTool.setKeySize(KEY_SIZE);\n    serverKeyTool.setDistinguishedName(SERVER_DISTINGUISHED_NAME);\n    serverKeyTool.setOutput(OUTPUT_DIR);\n    serverKeyTool.setPassword(SERVER_PASSWORD);\n    serverKeyTool.setValidity(VALIDITY);\n    serverKeyTool.generateKeyPair();\n    serverKeyTool.createCertificate(false);\n    sign(caKeyTool, serverKeyTool);\n    saveKeyAndCert(serverKeyTool);\n    // Create the client certificate\n    KeyTool clientKeyTool = new KeyTool(true);\n    clientKeyTool.setAlias(CLIENT_ALIAS);\n    clientKeyTool.setKeyAlgorithm(KEY_ALGORITHM);\n    clientKeyTool.setKeySize(KEY_SIZE);\n    clientKeyTool.setDistinguishedName(CLIENT_DISTINGUISHED_NAME);\n    clientKeyTool.setOutput(OUTPUT_DIR);\n    clientKeyTool.setPassword(CLIENT_PASSWORD);\n    clientKeyTool.setValidity(VALIDITY);\n    clientKeyTool.generateKeyPair();\n    clientKeyTool.createCertificate", "CodeBleu_score": 19.051506164607947}, {"code": "static void createCertificates() throws Exception{\n\t    // Create a CA certificate.\n    KeyTool caKeyTool = new KeyTool(true);\n    caKeyTool.createCertificate(\"ca\", \"ca\", \"ca\", \"ca\", \"ca\");\n    saveCert(caKeyTool, \"ca\", \"ca\");\n\n    // Create a server certificate signed by the CA.\n    KeyTool serverKeyTool = new KeyTool(true);\n    serverKeyTool.createCertificate(\"server\", \"server\", \"server\", \"server\", \"ca\");\n    sign(caKeyTool, serverKeyTool, \"server\", \"server\");\n    saveKeyAndCert(serverKeyTool, \"server\", \"server\");\n\n    // Create a client certificate signed by the CA.\n    KeyTool clientKeyTool = new KeyTool(true);\n    clientKeyTool.createCertificate(\"client\", \"client\", \"client\", \"client\", \"ca\");\n    sign(caKeyTool, clientKeyTool, \"client\", \"client\");\n    saveKeyAndCert(clientKeyTool, \"client\", \"client\");\n\n    // Create a second CA certificate.\n    KeyTool ca2KeyTool = new KeyTool(true);\n    ca2KeyTool.createCertificate(\"ca2\", \"ca2\", \"ca2\", \"ca2\", \"ca2\");\n    saveCert(ca2KeyTool, \"ca2\", \"ca2\");\n\n    // Create a client certificate signed by the second CA.\n    KeyTool client2KeyTool = new KeyTool(true);\n    client2KeyTool.createCertificate(\"client2\", \"client2\", \"client2\", \"client2\", \"ca2\");\n    sign(ca2KeyTool, client2KeyTool, \"client2\", \"client2\");\n    saveKeyAndCert(client2KeyTool, \"client2\", \"client2\");\n}", "CodeBleu_score": 15.849329028029386}, {"code": "static void createCertificates() throws Exception{\n\t    KeyTool keyTool = new KeyTool();\n    // Create a CA certificate and save it in the keystore.\n    keyTool.createCertificate(\"ca\", \"ca\", \"ca\", \"-ext\", \"bca\");\n    saveCert(\"ca\", \"ca\");\n\n    // Create a server certificate signed by the CA and save it in the keystore.\n    keyTool.createCertificate(\"server\", \"ca\", \"server\", \"-ext\", \"bcs\");\n    saveCert(\"server\", \"server\");\n    saveKeyAndCert(\"server\", \"server\");\n\n    // Create a client certificate signed by the CA and save it in the keystore.\n    keyTool.createCertificate(\"client\", \"ca\", \"client\", \"-ext\", \"bcc\");\n    saveCert(\"client\", \"client\");\n    saveKeyAndCert(\"client\", \"client\");\n\n    // Create a second CA certificate and save it in the keystore.\n    keyTool.createCertificate(\"ca2\", \"ca2\", \"ca2\", \"-ext\", \"bca\");\n    saveCert(\"ca2\", \"ca2\");\n\n    // Create a client certificate signed by the second CA and save it in the keystore.\n    keyTool.createCertificate(\"client2\", \"ca2\", \"client2\", \"-ext\", \"bcc\");\n    saveCert(\"client2\", \"client2\");\n    saveKeyAndCert(\"client2\", \"client2\");\n}", "CodeBleu_score": 18.511565815485064}]}
{"instance_id": "d2eeaa6a6bbe", "generation_result": [{"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        Thread.yield();\n    }\n    throw new RuntimeException(\"Condition not met within \" + seconds + \" seconds.\");\n}", "CodeBleu_score": 46.75117008980725}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + (seconds * 1000);\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        Thread.yield();\n    }\n    throw new RuntimeException(\"Condition not met within \" + seconds + \" seconds.\");\n}", "CodeBleu_score": 47.733897658075925}, {"code": "private void assertInSeconds(BooleanSupplier assertion, int seconds){\n\t    long timeLimit = System.currentTimeMillis() + seconds * 1000;\n    while (System.currentTimeMillis() < timeLimit) {\n        if (assertion.getAsBoolean()) {\n            return;\n        }\n        Thread.yield();\n    }\n    throw new RuntimeException(\"Condition not met within time limit\");\n}", "CodeBleu_score": 47.4936926340962}]}
{"instance_id": "6bb261b0e4e1", "generation_result": [{"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create the certificate builder\n    CertificateBuilder certBuilder = getCertBuilder(keyPair.getPublic(), ca);\n\n    // Add key usage and basic constraints extensions\n    certBuilder.addExtension(getExtension(Extension.keyUsage, true, new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment)));\n    certBuilder.addExtension(getExtension(Extension.basicConstraints, true, new BasicConstraints(BasicConstraints.CA)));\n\n    // Sign the certificate\n    return signCert(certBuilder, keyPair.getPrivate());\n}", "CodeBleu_score": 53.654453761214185}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create the certificate builder\n    X509CertificateBuilder certBuilder = new X509CertificateBuilder(\n        ca,\n        BigInteger.valueOf(System.currentTimeMillis()),\n        BigInteger.valueOf(System.currentTimeMillis() + 365L * 24 * 60 * 60 * 1000),\n        keyPair.getPublic()\n    );\n\n    // Add the key usage extension\n    certBuilder.addExtension(\n        ObjectIdentifiers.X509_EXTENSION_KEY_USAGE,\n        true,\n        new KeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment)\n    );\n\n    // Add the basic constraints extension\n    certBuilder.addExtension(\n        ObjectIdentifiers.X509_EXTENSION_BASIC_CONSTRAINTS,\n        true,\n        new BasicConstraints(false)\n    );\n\n    // Sign the certificate\n    ContentSigner signer = new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate());\n    X509CertificateHolder certHolder = certBuilder.build(signer);\n\n    // Return the signed certificate\n    return new JcaX509CertificateConverter().getCertificate(certHolder);\n}", "CodeBleu_score": 34.678326474928845}, {"code": "public X509Certificate createCert(KeyPair keyPair, String ca) throws Exception{\n\t    // Create a certificate builder with the provided public key and CA information\n    X509CertificateBuilder certBuilder = new JcaX509CertificateBuilder(\n        new X509CertificateHolder(ca.getBytes()).getSubject(),\n        BigInteger.valueOf(System.currentTimeMillis()),\n        new Date(),\n        new Date(System.currentTimeMillis() + (1000 * 60 * 60 * 24 * 365)),\n        new X500Principal(\"CN=Client\"),\n        keyPair.getPublic());\n    // Add key usage and basic constraints extensions to the certificate\n    certBuilder.addExtension(\n        new ASN1ObjectIdentifier(\"2.5.29.15\"),\n        true,\n        new JcaX509ExtensionUtils().createKeyUsage(KeyUsage.digitalSignature | KeyUsage.keyEncipherment));\n    certBuilder.addExtension(\n        new ASN1ObjectIdentifier(\"2.5.29.19\"),\n        true,\n        new JcaX509ExtensionUtils().createBasicConstraints(false));\n    // Sign the certificate with the private key\n    ContentSigner contentSigner = new JcaContentSignerBuilder(\"SHA256withRSA\").build(keyPair.getPrivate());\n    return new JcaX509CertificateConverter().getCertificate(certBuilder.build(contentSigner));\n}", "CodeBleu_score": 34.11206423200513}]}
{"instance_id": "e4f9c32a7c9e", "generation_result": [{"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClient = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClient.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClient.get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            logger.error(\"Unable to access registrationClient field from eurekaTransport object\", e);\n        } catch (NoSuchFieldException e) {\n            logger.error(\"Unable to access registrationClient field from eurekaTransport object\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 50.285749065080445}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            eurekaHttpClient = (EurekaHttpClient) getField(eurekaTransport, \"registrationClient\");\n        } catch (IllegalAccessException e) {\n            LOG.error(\"Cannot access registrationClient field\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 30.837069562615078}, {"code": "EurekaHttpClient getEurekaHttpClient(){\n\t    if (eurekaHttpClient == null) {\n        try {\n            Field registrationClientField = eurekaTransport.getClass().getDeclaredField(\"registrationClient\");\n            registrationClientField.setAccessible(true);\n            eurekaHttpClient = (EurekaHttpClient) registrationClientField.get(eurekaTransport);\n        } catch (IllegalAccessException e) {\n            logger.error(\"Failed to access registrationClient field from EurekaTransport\", e);\n        } catch (NoSuchFieldException e) {\n            logger.error(\"Failed to find registrationClient field from EurekaTransport\", e);\n        }\n    }\n    return eurekaHttpClient;\n}", "CodeBleu_score": 51.20296910935884}]}
{"instance_id": "5c404f04e34c", "generation_result": [{"code": "public List<String> getServices(){\n\t    List<String> services = new ArrayList<>();\n    Applications applications = getApplications();\n    if (applications == null) {\n        return emptyList();\n    }\n    for (Application application : applications.getRegisteredApplications()) {\n        if (!application.getInstances().isEmpty()) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 52.05880217387405}, {"code": "public List<String> getServices(){\n\t    ApplicationList applications = eurekaClient.getApplications();\n    if (applications == null) {\n        return emptyList();\n    }\n    List<String> services = new ArrayList<String>();\n    for (Application application : applications.getRegisteredApplications()) {\n        if (application.getInstances().size() > 0) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 52.641908271605246}, {"code": "public List<String> getServices(){\n\t    List<Application> applications = getApplications();\n    if (applications.isEmpty()) {\n        return emptyList();\n    }\n    List<String> services = new ArrayList<>();\n    for (Application application : applications) {\n        List<InstanceInfo> instances = application.getInstances();\n        if (!instances.isEmpty()) {\n            services.add(application.getName().toLowerCase());\n        }\n    }\n    return services;\n}", "CodeBleu_score": 48.82457149149184}]}
{"instance_id": "a21251337ade", "generation_result": [{"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.forEach((k, v) -> {\n        if (v instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) v;\n            discoveryCompositeHealthContributor.getContributors().forEach((k1, v1) -> {\n                if (!(v1 instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(k1, v1);\n                }\n            });\n        } else {\n            healthContributors.put(k, v);\n        }\n    });\n}", "CodeBleu_score": 36.04511657234439}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.forEach((name, contributor) -> {\n        if (contributor instanceof DiscoveryCompositeHealthContributor) {\n            DiscoveryCompositeHealthContributor discoveryCompositeHealthContributor = (DiscoveryCompositeHealthContributor) contributor;\n            discoveryCompositeHealthContributor.getContributors().forEach((key, value) -> {\n                if (!(value instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(key, value);\n                }\n            });\n        } else {\n            healthContributors.put(name, contributor);\n        }\n    });\n}", "CodeBleu_score": 36.71151936508707}, {"code": "void populateHealthContributors(Map<String, HealthContributor> healthContributors){\n\t    healthContributors.each { String key, HealthContributor healthContributor ->\n        if (healthContributor instanceof DiscoveryCompositeHealthContributor) {\n            healthContributor.getContributors().each { String innerKey, HealthContributor innerHealthContributor ->\n                if (!(innerHealthContributor instanceof EurekaHealthIndicator)) {\n                    healthContributors.put(innerKey, innerHealthContributor)\n                }\n            }\n        } else {\n            healthContributors.put(key, healthContributor)\n        }\n    }\n}", "CodeBleu_score": 30.83579818963782}]}
{"instance_id": "998fee829929", "generation_result": [{"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    ServiceInstance serviceInstance = instances.get(0);\n    String baseUrl = serviceInstance.getUri().toString();\n    return restTemplate.postForObject(baseUrl + \"/echo\", null, String.class);\n}", "CodeBleu_score": 52.74977605150729}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instance available for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    String url = instance.getUri().toString() + \"/echo\";\n    return restTemplate.postForObject(url, null, String.class);\n}", "CodeBleu_score": 49.7149326471785}, {"code": "public String hello(){\n\t    List<ServiceInstance> instances = discoveryClient.getInstances(\"provider-application\");\n    if (instances.isEmpty()) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    ServiceInstance instance = instances.get(0);\n    URI uri = instance.getUri();\n    return restTemplate.postForObject(uri + \"/echo\", null, String.class);\n}", "CodeBleu_score": 51.1998506729211}]}
{"instance_id": "31166ae7d3dc", "generation_result": [{"code": "public String world(){\n\t    ServiceInstance serviceInstance = loadBalancerClient.choose(\"provider-application\");\n    if (serviceInstance == null) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n    String url = serviceInstance.getUri().toString() + \"/echo\";\n    return restTemplate.postForObject(url, \"Hello\", String.class);\n}", "CodeBleu_score": 54.084145312076885}, {"code": "public String world(){\n\t    try {\n        ResponseEntity<String> response = restTemplate.postForEntity(lbClient.choose(\"provider-application\") + \"/echo\", \"Hello World\", String.class);\n        return response.getBody();\n    } catch (Exception e) {\n        throw new RuntimeException(\"No instances available for provider-application\");\n    }\n}", "CodeBleu_score": 40.305197298129926}, {"code": "public String world(){\n\t    ServiceInstance instance = loadBalancer.choose(\"provider-application\");\n    if (instance == null) {\n        throw new RuntimeException(\"No service instance found for provider-application\");\n    }\n    String url = String.format(\"%s://%s:%s/echo\", instance.getScheme(), instance.getHost(), instance.getPort());\n    return restTemplate.postForObject(url, \"Hello World\", String.class);\n}", "CodeBleu_score": 56.76896950354252}]}
{"instance_id": "d7714f9cf0e9", "generation_result": [{"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering serviceName: \" + serviceName + \" with IP: \" + ip + \" and port: \" + port);\n    synchronized (serverMap) {\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, new HashSet<Server>());\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n    }\n    return true;\n}", "CodeBleu_score": 48.150281405350974}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    synchronized (serverMap) {\n        if (!serverMap.containsKey(serviceName)) {\n            serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n        }\n        serverMap.get(serviceName).add(new Server(ip, port));\n        log.info(\"Registered \" + serviceName + \" with \" + ip + \":\" + port);\n        return true;\n    }\n}", "CodeBleu_score": 50.79515837744131}, {"code": "public boolean register(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    logger.info(\"Registering service \" + serviceName + \" at \" + ip + \":\" + port);\n    if (!serverMap.containsKey(serviceName)) {\n        serverMap.put(serviceName, Collections.synchronizedSet(new HashSet<>()));\n    }\n    serverMap.get(serviceName).add(new Server(ip, port));\n    return true;\n}", "CodeBleu_score": 53.457126151220315}]}
{"instance_id": "45f91ed1c560", "generation_result": [{"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    String serverKey = ip + \":\" + port;\n    if (serverMap.containsKey(serviceName)) {\n        if (serverMap.get(serviceName).contains(serverKey)) {\n            log.info(\"Deregistering \" + serviceName + \" at \" + serverKey);\n            serverMap.get(serviceName).remove(serverKey);\n            return true;\n        } else {\n            log.info(\"Could not find \" + serviceName + \" at \" + serverKey);\n            return false;\n        }\n    } else {\n        log.info(\"Could not find service \" + serviceName);\n        return false;\n    }\n}", "CodeBleu_score": 33.13934678735977}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Server server = new Server(ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        return false;\n    }\n    boolean removed = servers.remove(server);\n    if (removed) {\n        logger.info(\"Deregistered server \" + server + \" from service \" + serviceName);\n    }\n    return removed;\n}", "CodeBleu_score": 56.27243881943082}, {"code": "public boolean deregister(@RequestParam(\"serviceName\") String serviceName, @RequestParam(\"ip\") String ip, @RequestParam(\"port\") Integer port){\n\t    Server server = new Server(ip, port);\n    Set<Server> servers = serverMap.get(serviceName);\n    if (servers == null) {\n        return false;\n    }\n    boolean removed = servers.remove(server);\n    if (removed) {\n        logger.info(\"Deregistered server \" + server + \" from service \" + serviceName);\n    }\n    return removed;\n}", "CodeBleu_score": 56.27243881943082}]}
{"instance_id": "f671d9564e40", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\n\tMap<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName());\n\tif (attributes == null) {\n\t\treturn;\n\t}\n\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\n\tAnnotationAttributes[] annotationAttributes = (AnnotationAttributes[]) attributes.get(\"value\");\n\tif (annotationAttributes == null) {\n\t\treturn;\n\t}\n\t// \u904d\u5386 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\n\tfor (AnnotationAttributes annotationAttribute : annotationAttributes) {\n\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 configuration \u5c5e\u6027\n\t\tString[] configurations = (String[]) annotationAttribute.get(\"configuration\");\n\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 name \u5c5e\u6027\n\t\tString[] names = (String[]) annotationAttribute.get(\"name\");\n\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 namespace \u5c5e\u6027\n\t\tString namespace = (String) annotationAttribute.get(\"namespace\");\n\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 defaultConfiguration \u5c5e\u6027\n\t\tif (configurations.length == 0 && annotationAttribute.containsKey(\"defaultConfiguration\")) {\n\t\t\tconfigurations = new String[] { (String) annotationAttribute.get(\"defaultConfiguration\") };\n\t\t}\n\t\t// \u904d\u5386 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 configuration \u5c5e\u6027\n\t\tfor (String configuration : configurations) {\n\t\t\t// \u904d\u5386 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 name \u5c5e\u6027\n\t\t\tfor (String name : names) {\n\t\t\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value \u5c5e\u6027\u4e2d\u7684 configuration \u5c5e\u6027\u7684 BeanDefinition\n\t\t\t\tBeanDefinition beanDefinition = this.beanFactory.getBeanDefinition(configuration);\n\t\t\t\t// \u83b7\u53d6 RibbonClients \u6ce8\u89e3\u7684 value ", "CodeBleu_score": 35.984326205463915}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t    Map<String, Object> attributes = metadata.getAnnotationAttributes(RibbonClients.class.getName(), true);\n    if (attributes != null && attributes.containsKey(\"defaultConfiguration\")) {\n        String name = \"com.netflix.client.config.IClientConfig\" +\n                \".\" + metadata.getClassName();\n        registerClientConfiguration(registry, name, attributes.get(\"defaultConfiguration\"));\n    }\n    registerClient(metadata, registry);\n}", "CodeBleu_score": 69.29179503439998}, {"code": "public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry){\n\t\t\tClass<?> declaringClass = metadata.getClassName();\n\t\tAnnotationAttributes attributes = AnnotationAttributes.fromMap(\n\t\t\t\tmetadata.getAnnotationAttributes(RibbonClients.class.getName(), false));\n\t\tif (attributes != null) {\n\t\t\tregisterClientConfiguration(registry, declaringClass, attributes.getString(\"defaultConfiguration\"));\n\t\t\tfor (String name : attributes.getStringArray(\"value\")) {\n\t\t\t\tregisterClientConfiguration(registry, declaringClass, name);\n\t\t\t}\n\t\t\tfor (String name : attributes.getStringArray(\"clients\")) {\n\t\t\t\tregisterClientConfiguration(registry, declaringClass, name);\n\t\t\t}\n\t\t}\n\t}", "CodeBleu_score": 42.834618764457765}]}
{"instance_id": "dbc92d8f146f", "generation_result": [{"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    List<ServiceInstance> instances = getInstances(serviceId);\n    if (instances.isEmpty()) {\n        return null;\n    }\n    return instances.get(new Random().nextInt(instances.size()));\n}", "CodeBleu_score": 29.95528304417496}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    return choose(serviceId, request, null);\n}", "CodeBleu_score": 12.469394230308437}, {"code": "public <T> ServiceInstance choose(String serviceId, Request<T> request) {\n\t    return choose(serviceId, null, request);\n}", "CodeBleu_score": 11.504498186064332}]}
{"instance_id": "362eadbd3c5e", "generation_result": [{"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        String scheme = original.getScheme();\n        String host = original.getHost();\n        String path = original.getRawPath();\n        String query = original.getRawQuery();\n        String newHost = server.getHost();\n        int port = server.getPort();\n\n        StringBuilder sb = new StringBuilder();\n        sb.append(scheme).append(\"://\").append(newHost);\n        if (port != -1) {\n            sb.append(\":\").append(port);\n        }\n        sb.append(path);\n        if (query != null && !query.isEmpty()) {\n            sb.append(\"?\").append(query);\n        }\n        return new URI(sb.toString());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 57.759497069037224}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        URI uri = new URI(original.getScheme(), null, server.getHost(), server.getPort(), original.getPath(), original.getQuery(), null);\n        return uri;\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 35.356168456282774}, {"code": "public URI reconstructURI(ServiceInstance server, URI original) {\n\t    try {\n        String scheme = original.getScheme();\n        String host = original.getHost();\n        int port = original.getPort();\n        String path = original.getRawPath();\n        String query = original.getRawQuery();\n        if (host != null && host.equals(server.getServiceId().getName())) {\n            host = server.getHost();\n            port = server.getPort();\n        }\n        StringBuilder sb = new StringBuilder();\n        sb.append(scheme).append(\"://\").append(host);\n        if (port != -1) {\n            sb.append(\":\").append(port);\n        }\n        sb.append(path);\n        if (query != null) {\n            sb.append(\"?\").append(query);\n        }\n        return new URI(sb.toString());\n    } catch (URISyntaxException e) {\n        throw new RuntimeException(e);\n    }\n}", "CodeBleu_score": 56.30654359104624}]}
{"instance_id": "6801d2b2e4c8", "generation_result": [{"code": "private List<TutuServer> getServer(){\n\t    String serverAddr = getServerAddr();\n    String serviceName = getString(\"serviceName\");\n    String url = serverAddr + \"/list?serviceName=\" + serviceName;\n    String response = stream(url, \"GET\", null, null);\n    List<Map<String, Object>> serverList = parseArray(response);\n    List<TutuServer> tutuServerList = serverList.stream().map(server -> {\n        String ip = getString(server, \"ip\");\n        int port = getInteger(server, \"port\");\n        return new TutuServer(ip, port);\n    }).collect(toList());\n    return tutuServerList;\n}", "CodeBleu_score": 44.85586178679426}, {"code": "private List<TutuServer> getServer(){\n\t    List<TutuServer> servers = new ArrayList<>();\n    try {\n        URL url = new URL(getServerAddr() + \"/list\");\n        HttpURLConnection connection = (HttpURLConnection) url.openConnection();\n        connection.setRequestMethod(\"GET\");\n        connection.setRequestProperty(\"Content-Type\", \"application/json\");\n        connection.setRequestProperty(\"Accept\", \"application/json\");\n        connection.setConnectTimeout(10000);\n        connection.setReadTimeout(10000);\n        connection.connect();\n        int status = connection.getResponseCode();\n        if (status == HttpURLConnection.HTTP_OK) {\n            BufferedReader reader = new BufferedReader(new InputStreamReader(connection.getInputStream()));\n            StringBuilder result = new StringBuilder();\n            String line;\n            while ((line = reader.readLine()) != null) {\n                result.append(line);\n            }\n            reader.close();\n            JSONArray jsonArray = new JSONArray(result.toString());\n            for (int i = 0; i < jsonArray.length(); i++) {\n                JSONObject jsonObject = jsonArray.getJSONObject(i);\n                String ip = jsonObject.getString(\"ip\");\n                int port = jsonObject.getInt(\"port\");\n                TutuServer server = new TutuServer(ip, port);\n                servers.add(server);\n            }\n        }\n    } catch (Exception e) {\n        e.printStackTrace();\n    }\n    return servers;\n}", "CodeBleu_score": 35.29204428639842}, {"code": "private List<TutuServer> getServer(){\n\t    def server = []\n    def params = [serviceName: serviceName]\n    def serverAddr = getServerAddr()\n    def response = stream(method: 'GET', url: serverAddr + \"/list\", query: params)\n    def json = parseArray(response.text)\n    json.each {\n        server.add(new TutuServer(it.ip, it.port))\n    }\n    return server\n}", "CodeBleu_score": 28.17257206311745}]}
{"instance_id": "ab2fb77484fd", "generation_result": [{"code": "public Route getMatchingRoute(String path){\n\t    for (Route route : routes) {\n        String pattern = route.getPattern();\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = path.substring(pattern.length());\n            if (targetPath.startsWith(\"/\")) {\n                targetPath = targetPath.substring(1);\n            }\n            return new Route(route.getServiceId(), targetPath);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 41.9003056531217}, {"code": "public Route getMatchingRoute(String path){\n\t    String[] routes = getRoutes();\n    for (String route : routes) {\n        if (pathMatcher.match(route, path)) {\n            String targetPath = path.substring(route.indexOf('*'));\n            if (!targetPath.startsWith(\"/\")) {\n                targetPath = \"/\" + targetPath;\n            }\n            return new Route(route, getServiceId(route), targetPath);\n        }\n    }\n    return null;\n}", "CodeBleu_score": 35.57058192225844}, {"code": "public Route getMatchingRoute(String path){\n\t    for (String route : routes.keySet()) {\n        String pattern = route;\n        if (pathMatcher.match(pattern, path)) {\n            String targetPath = path.replaceFirst(pattern, routes.get(route));\n            return new Route(targetPath, routes.get(route));\n        }\n    }\n    return null;\n}", "CodeBleu_score": 36.360134299196375}]}
{"instance_id": "822071925513", "generation_result": [{"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tClassPathScanningCandidateComponentProvider scanner = getScanner();\n\tscanner.setResourceLoader(this.resourceLoader);\n\n\tAnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n\tscanner.addIncludeFilter(annotationTypeFilter);\n\n\tfor (String basePackage : getBasePackages(importingClassMetadata)) {\n\t\tSet<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n\t\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\t\tif (candidateComponent instanceof AnnotatedBeanDefinition) {\n\t\t\t\t// verify annotated class is an interface\n\t\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n\t\t\t\tAnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n\t\t\t\tAssert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\");\n\n\t\t\t\tMap<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName());\n\n\t\t\t\tString name = getName(attributes);\n\t\t\t\tString contextId = getContextId(attributes);\n\t\t\t\tString[] configuration = getConfiguration(attributes);\n\n\t\t\t\tregisterClientConfiguration(registry, contextId, configuration);\n\n\t\t\t\tregisterFeignClient(registry, annotationMetadata, contextId);\n\n\t\t\t\tregisterFeignContext(registry, contextId);\n\n\t\t\t\tregisterFeignSpecification(registry, annotationMetadata, contextId);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 26.423390245038863}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t    ClassPathScanningCandidateComponentProvider scanner = getScanner();\n    scanner.setResourceLoader(this.resourceLoader);\n\n    AnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n    scanner.addIncludeFilter(annotationTypeFilter);\n\n    Set<String> basePackages = getBasePackages(importingClassMetadata);\n\n    for (String basePackage : basePackages) {\n        Set<BeanDefinition> candidateComponents = scanner.findCandidateComponents(basePackage);\n        for (BeanDefinition candidateComponent : candidateComponents) {\n            if (candidateComponent instanceof AnnotatedBeanDefinition) {\n                // verify annotated class is an interface\n                AnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n                AnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n                Assert.isTrue(annotationMetadata.isInterface(), \"@FeignClient can only be specified on an interface\");\n\n                Map<String, Object> attributes = annotationMetadata.getAnnotationAttributes(FeignClient.class.getCanonicalName());\n\n                String name = getClientName(attributes);\n                registerClientConfiguration(registry, name, attributes.get(\"configuration\"));\n\n                registerFeignClient(registry, annotationMetadata, attributes);\n            }\n        }\n    }\n\n}", "CodeBleu_score": 29.358558903825273}, {"code": "public void registerBeanDefinitions(AnnotationMetadata importingClassMetadata, BeanDefinitionRegistry registry){\n\t\tClassPathScanningCandidateComponentProvider scanner = getScanner();\n\tscanner.setResourceLoader(this.resourceLoader);\n\n\tAnnotationTypeFilter annotationTypeFilter = new AnnotationTypeFilter(FeignClient.class);\n\tscanner.addIncludeFilter(annotationTypeFilter);\n\n\tfor (String basePackage : getBasePackages(importingClassMetadata)) {\n\t\tSet<BeanDefinition> candidateComponents = scanner\n\t\t\t\t.findCandidateComponents(basePackage);\n\t\tfor (BeanDefinition candidateComponent : candidateComponents) {\n\t\t\tif (candidateComponent instanceof AnnotatedBeanDefinition) {\n\t\t\t\t// verify annotated class is an interface\n\t\t\t\tAnnotatedBeanDefinition beanDefinition = (AnnotatedBeanDefinition) candidateComponent;\n\t\t\t\tAnnotationMetadata annotationMetadata = beanDefinition.getMetadata();\n\t\t\t\tAssert.isTrue(annotationMetadata.isInterface(),\n\t\t\t\t\t\t\"@FeignClient can only be specified on an interface\");\n\n\t\t\t\tMap<String, Object> attributes = annotationMetadata\n\t\t\t\t\t\t.getAnnotationAttributes(\n\t\t\t\t\t\t\t\tFeignClient.class.getCanonicalName());\n\n\t\t\t\tString name = getName(attributes);\n\t\t\t\tString contextId = getContextId(attributes);\n\t\t\t\tString[] configuration = getConfiguration(attributes);\n\n\t\t\t\tregisterClientConfiguration(registry, contextId,\n\t\t\t\t\t\tconfiguration);\n\n\t\t\t\tregisterFeignClient(registry, annotationMetadata, attributes);\n\t\t\t}\n\t\t}\n\t}\n}", "CodeBleu_score": 26.41713099669168}]}
{"instance_id": "3d678e3bf3c8", "generation_result": [{"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t\n    TutuDiscoveryClient tutuDiscoveryClient = new TutuDiscoveryClient(tutuDiscoveryProperties);\n    return tutuDiscoveryClient;\n}", "CodeBleu_score": 29.371446315891237}, {"code": "public TutuDiscoveryClient tutuDiscoveryClient(TutuDiscoveryProperties tutuDiscoveryProperties){\n\t    return new TutuDiscoveryClient(tutuDiscoveryProperties);\n}", "CodeBleu_score": 74.10612186004828}]}
